{"id": "2512.02062", "categories": ["cs.CR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.02062", "abs": "https://arxiv.org/abs/2512.02062", "authors": ["Issa Oe", "Keiichiro Yamamura", "Hiroki Ishikura", "Ryo Hamahira", "Katsuki Fujisawa"], "title": "Superpixel Attack: Enhancing Black-box Adversarial Attack with Image-driven Division Areas", "comment": null, "summary": "Deep learning models are used in safety-critical tasks such as automated driving and face recognition. However, small perturbations in the model input can significantly change the predictions. Adversarial attacks are used to identify small perturbations that can lead to misclassifications. More powerful black-box adversarial attacks are required to develop more effective defenses. A promising approach to black-box adversarial attacks is to repeat the process of extracting a specific image area and changing the perturbations added to it. Existing attacks adopt simple rectangles as the areas where perturbations are changed in a single iteration. We propose applying superpixels instead, which achieve a good balance between color variance and compactness. We also propose a new search method, versatile search, and a novel attack method, Superpixel Attack, which applies superpixels and performs versatile search. Superpixel Attack improves attack success rates by an average of 2.10% compared with existing attacks. Most models used in this study are robust against adversarial attacks, and this improvement is significant for black-box adversarial attacks. The code is avilable at https://github.com/oe1307/SuperpixelAttack.git.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8d85\u50cf\u7d20\u7684\u9ed1\u76d2\u5bf9\u6297\u653b\u51fb\uff0c\u7ed3\u5408\u591a\u6837\u5316\u641c\u7d22\uff08versatile search\uff09\u548c\u8d85\u50cf\u7d20\u6270\u52a8\u533a\u57df\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u6297\u6210\u529f\u7387\uff08\u76f8\u6bd4\u57fa\u4e8e\u77e9\u5f62\u7684\u65b9\u6cd5\u5e73\u5747\u63d0\u5347\u7ea62.1%\uff09\uff0c\u5e76\u7ed9\u51fa\u4ee3\u7801\u5b9e\u73b0\u3002", "motivation": "\u5728\u5b89\u5168\u5173\u952e\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u6613\u53d7\u5bf9\u6297\u6270\u52a8\u5f71\u54cd\uff0c\u73b0\u6709\u9ed1\u76d2\u653b\u51fb\u591a\u4f7f\u7528\u7b80\u5355\u77e9\u5f62\u4f5c\u4e3a\u6270\u52a8\u533a\u57df\uff0c\u96be\u4ee5\u9ad8\u6548\u53d1\u73b0\u9ad8\u8d28\u91cf\u6270\u52a8\u3002\u56e0\u6b64\u9700\u8981\u66f4\u5f3a\u7684\u9ed1\u76d2\u653b\u51fb\u6765\u8bc4\u4f30\u4e0e\u63d0\u5347\u9632\u5fa1\u80fd\u529b\uff1b\u540c\u65f6\u5e0c\u671b\u6270\u52a8\u533a\u57df\u5728\u989c\u8272\u65b9\u5dee\u4e0e\u7d27\u51d1\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "method": "\u5f15\u5165\u4f7f\u7528\u8d85\u50cf\u7d20\u4f5c\u4e3a\u6270\u52a8\u533a\u57df\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u641c\u7d22\u7b56\u7565\uff08versatile search\uff09\uff0c\u5c06\u4e24\u8005\u7ed3\u5408\u5f62\u6210 Superpixel Attack\uff0c\u901a\u8fc7\u9010\u533a\u57df\u4fee\u6539\u6270\u52a8\u6765\u5b9e\u73b0\u5bf9\u6a21\u578b\u7684\u653b\u51fb\u3002", "result": "\u76f8\u8f83\u4e8e\u73b0\u6709\u653b\u51fb\uff0cSuperpixel Attack \u7684\u5e73\u5747\u5bf9\u6297\u6210\u529f\u7387\u63d0\u5347\u7ea62.1%\u3002\u5c3d\u7ba1\u5927\u591a\u6570\u6a21\u578b\u5bf9\u5bf9\u6297\u653b\u51fb\u5177\u6709\u9c81\u68d2\u6027\uff0c\u8be5\u6539\u8fdb\u5bf9\u9ed1\u76d2\u653b\u51fb\u4ecd\u5177\u663e\u8457\u610f\u4e49\u3002\u4ee3\u7801\u516c\u5f00\u53ef\u7528\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8d85\u50cf\u7d20\u5728\u5c40\u90e8\u6270\u52a8\u7684\u8272\u5f69\u4e00\u81f4\u6027\u548c\u533a\u57df\u7d27\u51d1\u6027\u65b9\u9762\u66f4\u5229\u4e8e\u6784\u9020\u6709\u6548\u7684\u5bf9\u6297\u6837\u672c\uff1b\u8be5\u65b9\u6cd5\u4e3a\u8bc4\u4f30\u4e0e\u63d0\u5347\u9632\u5fa1\u63d0\u4f9b\u65b0\u7684\u5de5\u5177\u4e0e\u601d\u8def\uff0c\u5177\u6709\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.02069", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02069", "abs": "https://arxiv.org/abs/2512.02069", "authors": ["Yining Yuan", "Yifei Wang", "Yichang Xu", "Zachary Yahn", "Sihao Hu", "Ling Liu"], "title": "Large Language Model based Smart Contract Auditing with LLMBugScanner", "comment": null, "summary": "This paper presents LLMBugScanner, a large language model (LLM) based framework for smart contract vulnerability detection using fine-tuning and ensemble learning. Smart contract auditing presents several challenges for LLMs: different pretrained models exhibit varying reasoning abilities, and no single model performs consistently well across all vulnerability types or contract structures. These limitations persist even after fine-tuning individual LLMs.\n  To address these challenges, LLMBugScanner combines domain knowledge adaptation with ensemble reasoning to improve robustness and generalization. Through domain knowledge adaptation, we fine-tune LLMs on complementary datasets to capture both general code semantics and instruction-guided vulnerability reasoning, using parameter-efficient tuning to reduce computational cost. Through ensemble reasoning, we leverage the complementary strengths of multiple LLMs and apply a consensus-based conflict resolution strategy to produce more reliable vulnerability assessments.\n  We conduct extensive experiments across multiple popular LLMs and compare LLMBugScanner with both pretrained and fine-tuned individual models. Results show that LLMBugScanner achieves consistent accuracy improvements and stronger generalization, demonstrating that it provides a principled, cost-effective, and extensible framework for smart contract auditing.", "AI": {"tldr": "LLMBugScanner \u5229\u7528\u5fae\u8c03\u548c\u96c6\u6210\u63a8\u7406\uff0c\u5728\u8de8\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u7840\u4e0a\u5bf9\u667a\u80fd\u5408\u7ea6\u6f0f\u6d1e\u8fdb\u884c\u68c0\u6d4b\uff0c\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u9002\u914d\u548c\u5171\u8bc6\u5f0f\u51b2\u7a81\u89e3\u51b3\uff0c\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u9636\u6bb5\u4e0d\u540c\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u63a8\u7406\u80fd\u529b\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u5355\u4e2a\u6a21\u578b\u5f88\u96be\u5bf9\u6240\u6709\u6f0f\u6d1e\u7c7b\u578b\u548c\u5408\u7ea6\u7ed3\u6784\u8868\u73b0\u7a33\u5b9a\uff1b\u5373\u4f7f\u5fae\u8c03\u540e\uff0c\u6a21\u578b\u6027\u80fd\u4ecd\u6709\u9650\uff0c\u4e9f\u9700\u66f4\u7a33\u5065\u7684\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u9886\u57df\u77e5\u8bc6\u9002\u914d\uff0c\u5bf9\u591a\u4e2aLLM\u8fdb\u884c\u8865\u5145\u6570\u636e\u96c6\u5fae\u8c03\uff0c\u91c7\u7528\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u4ee5\u964d\u4f4e\u6210\u672c\uff1b\u901a\u8fc7\u96c6\u6210\u63a8\u7406\uff0c\u7ed3\u5408\u591a\u6a21\u578b\u7684\u4e92\u8865\u4f18\u52bf\u5e76\u4f7f\u7528\u57fa\u4e8e\u5171\u8bc6\u7684\u51b2\u7a81\u89e3\u51b3\u7b56\u7565\uff0c\u4ea7\u51fa\u66f4\u53ef\u9760\u7684\u6f0f\u6d1e\u8bc4\u4f30\u3002", "result": "\u5728\u591a\u79cd\u6d41\u884cLLM\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0cLLMBugScanner \u76f8\u8f83\u4e8e\u5355\u4e00\u7684\u9884\u8bad\u7ec3\u6216\u5fae\u8c03\u6a21\u578b\uff0c\u663e\u793a\u51fa\u4e00\u81f4\u7684\u51c6\u786e\u6027\u63d0\u5347\u548c\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u4e00\u4e2a principled\u3001\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u53ef\u6269\u5c55\u7684\u667a\u80fd\u5408\u7ea6\u5ba1\u8ba1\u6846\u67b6\uff0c\u4e3a\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u6f0f\u6d1e\u68c0\u6d4b\u63d0\u4f9b\u9c81\u68d2\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02082", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.02082", "abs": "https://arxiv.org/abs/2512.02082", "authors": ["Abel C. H. Chen"], "title": "Deterministic Random Bit Generators Based on Ascon for Embedded Systems", "comment": "in Chinese language", "summary": "As the Deterministic Random Bit Generator (DRBG) serves as a fundamental component in random number generation and cryptographic applications, its performance and security are particularly critical in resource-constrained embedded systems, where memory capacity and computational efficiency are limited. Establishing a high-performance and secure DRBG is therefore an important issue for embedded system design. Furthermore, the National Institute of Standards and Technology (NIST) established the Ascon lightweight cryptographic standard in August 2025, which is suitable for use in resource-limited embedded environments. Therefore, this study revises the DRBG standard and proposes three Ascon-driven constructions: the Ascon-Driven Hash-Based DRBG, the Ascon-Driven keyed-Hash Message Authentication Code (HMAC) DRBG, and the Ascon-Driven Counter-mode (CTR) DRBG. In the experiments, these methods are implemented on a Raspberry Pi platform. The experimental results demonstrate that the proposed approaches achieve higher computational efficiency and lower memory usage compared with existing DRBG implementations, making them suitable for deployment in embedded systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e09\u79cd\u4ee5Ascon\u4e3a\u9a71\u52a8\u7684DRBG\u6784\u9020\uff08\u54c8\u5e0c\u3001HMAC\u3001CTR\uff09\uff0c\u5e76\u5728\u6811\u8393\u6d3e\u4e0a\u5b9e\u73b0\u4e0e\u8bc4\u6d4b\uff0c\u663e\u793a\u5728\u5d4c\u5165\u5f0f\u73af\u5883\u4e2d\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u548c\u66f4\u4f4e\u7684\u5185\u5b58\u5360\u7528\uff0c\u4f18\u4e8e\u73b0\u6709DRBG\u5b9e\u73b0\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\uff0cDRBG\u7684\u6027\u80fd\u548c\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\u3002NIST\u57282025\u5e74\u786e\u7acb\u4e86Ascon\u8f7b\u91cf\u7ea7\u52a0\u5bc6\u6807\u51c6\uff0c\u4e3a\u5d4c\u5165\u5f0f\u73af\u5883\u63d0\u4f9b\u4e86\u65b0\u57fa\u7840\u3002\u672c\u7814\u7a76\u62df\u6539\u8fdbDRBG\u6807\u51c6\u5e76\u63d0\u51fa\u57fa\u4e8eAscon\u7684\u65b0\u6784\u9020\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e09\u79cdAscon\u9a71\u52a8\u7684DRBG\uff1aAscon-Driven Hash-Based DRBG\u3001Ascon-Driven HMAC DRBG\u3001\u4ee5\u53caAscon-Driven Counter-mode DRBG\u3002\u5c06\u5b9e\u73b0\u90e8\u7f72\u5728\u6811\u8393\u6d3e\u5e73\u53f0\u4e0a\uff0c\u5e76\u4e0e\u73b0\u6709DRBG\u5b9e\u73b0\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u5185\u5b58\u4f7f\u7528\u65b9\u9762\u4f18\u4e8e\u73b0\u6709DRBG\u5b9e\u73b0\uff0c\u9002\u5408\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u90e8\u7f72\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684Ascon\u9a71\u52a8DRBG\u65b9\u6848\u5177\u6709\u826f\u597d\u7684\u5d4c\u5165\u5f0f\u90e8\u7f72\u6027\uff0c\u7b26\u5408NIST Ascon\u6807\u51c6\u7684\u53d1\u5c55\u65b9\u5411\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2512.02087", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.02087", "abs": "https://arxiv.org/abs/2512.02087", "authors": ["Simone Dutto", "Pietro Mercuri", "Nadir Murru", "Lorenzo Romano"], "title": "A survey about Hidden Subgroup Problem from a mathematical and cryptographic perspective", "comment": null, "summary": "We provide a survey on the Hidden Subgroup Problem (HSP), which plays an important role in studying the security of public-key cryptosystems. We first review the abelian case, where Kitaev's algorithm yields an efficient quantum solution to the HSP, recalling how classical problems (such as order finding, integer factorization, and discrete logarithm) can be formulated as abelian HSP instances. We then examine the current state of the art for non-abelian HSP, where no general efficient quantum solution is known, focusing on some relevant groups including dihedral group (connected to the shortest vector problem), symmetric groups (connected to the graph isomorphism problem), and semidirect product constructions (connected, in a special case, to the code equivalence problem). We also describe the main techniques for addressing the HSP in non-abelian cases, namely Fourier sampling and the black-box approach. Throughout the paper, we highlight the mathematical notions required and exploited in this context, providing a cryptography-oriented perspective.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u9690\u85cf\u5b50\u7fa4\u95ee\u9898\uff08HSP\uff09\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u7cfb\u7edf\u68b3\u7406\u963f\u8d1d\u5c14\u60c5\u5f62\u4e0b\u7684\u9ad8\u6548\u91cf\u5b50\u89e3\u6cd5\u53ca\u975e\u963f\u8d1d\u5c14\u60c5\u5f62\u7684\u90e8\u5206\u8fdb\u5c55\uff0c\u91cd\u70b9\u8ba8\u8bbaDihedral\u3001\u5bf9\u79f0\u7fa4\u53ca\u534a\u76f4\u79ef\u7fa4\u7b49\u4e0e\u6700\u77ed\u5411\u91cf\u95ee\u9898\u3001\u56fe\u540c\u6784\u95ee\u9898\u3001\u7801\u7b49\u4ef7\u95ee\u9898\u7684\u8054\u7cfb\uff0c\u5f52\u7eb3\u5085\u91cc\u53f6\u91c7\u6837\u4e0e\u9ed1\u7bb1\u7fa4\u65b9\u6cd5\u7b49\u6838\u5fc3\u6280\u672f\uff0c\u5e76\u4ece\u5bc6\u7801\u5b66\u89c6\u89d2\u5206\u6790\u76f8\u5173\u6982\u5ff5\u4e0e\u5f00\u653e\u95ee\u9898\u3002", "motivation": "HSP\u662f\u91cf\u5b50\u7b97\u6cd5\u4e0e\u516c\u94a5\u5bc6\u7801\u5b66\u5b89\u5168\u6027\u7814\u7a76\u4e2d\u7684\u6838\u5fc3\u95ee\u9898\u4e4b\u4e00\u3002\u963f\u8d1d\u5c14HSP\u5df2\u6709\u9ad8\u6548\u89e3\u6cd5\uff0c\u800c\u975e\u963f\u8d1d\u5c14HSP\u5c1a\u65e0\u901a\u7528\u9ad8\u6548\u7b97\u6cd5\u3002\u8be5\u8bba\u6587\u65e8\u5728\u7cfb\u7edf\u68b3\u7406\u73b0\u6709\u65b9\u6cd5\u3001\u5173\u952e\u6280\u672f\u53ca\u5728\u91cd\u8981\u7fa4\u4e0a\u7684\u7ed3\u679c\u4e0e\u5c40\u9650\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002", "method": "\u4ee5\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u4e3a\u57fa\u7840\uff0c\u89e3\u6790HSP\u7684\u62bd\u8c61\u6846\u67b6\u53ca\u53ef\u5b9e\u73b0\u7684\u6280\u672f\u5de5\u5177\uff08\u5982\u5085\u91cc\u53f6\u91c7\u6837\u3001\u9ed1\u7bb1\u65b9\u6cd5\uff09\uff0c\u5e76\u5bf9\u5177\u4f53\u7fa4\uff08Dihedral\u3001\u5bf9\u79f0\u7fa4\u3001\u534a\u76f4\u79ef\u7fa4\uff09\u7684\u7ed3\u679c\u3001\u590d\u6742\u5ea6\u53ca\u4e0e\u76f8\u5173\u95ee\u9898\u7684\u7b49\u4ef7/\u5f52\u7ea6\u5173\u7cfb\u8fdb\u884c\u6bd4\u8f83\u4e0e\u5f52\u7eb3\u3002", "result": "\u7ed3\u8bba\u6027\u5730\u6307\u51fa\uff1a\u5728\u963f\u8d1d\u5c14\u60c5\u5f62\u5b58\u5728\u9ad8\u6548\u91cf\u5b50\u89e3\u6cd5\uff1b\u975e\u963f\u8d1d\u5c14\u60c5\u5f62\u6ca1\u6709\u901a\u7528\u9ad8\u6548\u7b97\u6cd5\u3002\u5bf9Dihedral\u7fa4\u5b58\u5728\u5b50\u6307\u6570\u65f6\u95f4\u7684\u91cf\u5b50\u7b97\u6cd5\uff08Kuperberg\u53ca\u6539\u8fdb\u7248\u672c\uff09\uff0c\u5c06HSP\u4e0e\u6700\u77ed\u5411\u91cf\u95ee\u9898\u76f8\u5173\u8054\uff1b\u5bf9\u79f0\u7fa4S_n\u7684HSP\u4e0e\u56fe\u540c\u6784\u95ee\u9898\u76f8\u5173\u4f46\u5c1a\u65e0\u9ad8\u6548\u89e3\u6cd5\uff1b\u534a\u76f4\u79ef\u7fa4\u7684\u7814\u7a76\u63ed\u793a\u5728\u67d0\u4e9b\u60c5\u5f62\u53ef\u5c06HSP\u4e0e\u7801\u7b49\u4ef7\u7b49\u95ee\u9898\u8054\u7cfb\u8d77\u6765\uff0c\u4f46\u603b\u4f53\u4ecd\u7136\u56f0\u96be\u4e14\u591a\u4e3a\u5c40\u90e8\u7ed3\u679c\u3002", "conclusion": "\u603b\u4f53\u800c\u8a00\uff0c\u975e\u963f\u8d1d\u5c14HSP\u4ecd\u662f\u5f00\u653e\u4e14\u9ad8\u5ea6\u6d3b\u8dc3\u7684\u7814\u7a76\u9886\u57df\uff0c\u672a\u6765\u9700\u8981\u53d1\u5c55\u65b0\u7684\u7b97\u6cd5\u5de5\u5177\u3001\u6df1\u5165\u5206\u6790\u7fa4\u7684\u7ed3\u6784\u6027\u7279\u5f81\uff0c\u5e76\u8bc4\u4f30\u5bf9\u5bc6\u7801\u5b66\u53ca\u76f8\u5173\u8ba1\u7b97\u95ee\u9898\u7684\u5f71\u54cd\u3002"}}
{"id": "2512.02025", "categories": ["eess.SP", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02025", "abs": "https://arxiv.org/abs/2512.02025", "authors": ["Aditya Sneh", "Nilesh Kumar Sahu", "Snehil Gupta", "Haroon R. Lone"], "title": "DySTAN: Joint Modeling of Sedentary Activity and Social Context from Smartphone Sensors", "comment": null, "summary": "Accurately recognizing human context from smartphone sensor data remains a significant challenge, especially in sedentary settings where activities such as studying, attending lectures, relaxing, and eating exhibit highly similar inertial patterns. Furthermore, social context plays a critical role in understanding user behavior, yet is often overlooked in mobile sensing research. To address these gaps, we introduce LogMe, a mobile sensing application that passively collects smartphone sensor data (accelerometer, gyroscope, magnetometer, and rotation vector) and prompts users for hourly self-reports capturing both sedentary activity and social context. Using this dual-label dataset, we propose DySTAN (Dynamic Cross-Stitch with Task Attention Network), a multi-task learning framework that jointly classifies both context dimensions from shared sensor inputs. It integrates task-specific layers with cross-task attention to model subtle distinctions effectively. DySTAN improves sedentary activity macro F1 scores by 21.8% over a single-task CNN-BiLSTM-GRU (CBG) model and by 8.2% over the strongest multi-task baseline, Sluice Network (SN). These results demonstrate the importance of modeling multiple, co-occurring context dimensions to improve the accuracy and robustness of mobile context recognition.", "AI": {"tldr": "\u53cc\u6807\u7b7e\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6DySTAN\uff1a\u4ece\u624b\u673a\u4f20\u611f\u6570\u636e\u540c\u65f6\u8bc6\u522b sedentary context \u4e0e social context\uff0c\u901a\u8fc7\u8de8\u4efb\u52a1\u6ce8\u610f\u529b\u4e0e\u5171\u4eab\u8868\u793a\u63d0\u5347\u8bc6\u522b\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u5355\u4efb\u52a1\u548c\u5176\u4ed6\u591a\u4efb\u52a1\u57fa\u7ebf\u3002", "motivation": "\u5728\u5b89\u5750\u573a\u666f\u4e0b\uff0c\u5fae\u5c0f\u7684\u60ef\u6027\u6a21\u5f0f\u96be\u4ee5\u5206\u8fa8\u4e0d\u540c\u6d3b\u52a8\uff1b\u793e\u4f1a\u4e0a\u4e0b\u6587\u5bf9\u7406\u89e3\u7528\u6237\u884c\u4e3a\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5728\u79fb\u52a8\u4f20\u611f\u7814\u7a76\u4e2d\u5e38\u88ab\u5ffd\u89c6\u3002\u56e0\u6b64\u9700\u8981\u8054\u5408\u5efa\u6a21\u548c\u8de8\u4efb\u52a1\u534f\u540c\u4ee5\u63d0\u9ad8\u9c81\u68d2\u6027\u4e0e\u51c6\u786e\u6027\u3002", "method": "LogMe\u5e94\u7528\u88ab\u52a8\u6536\u96c6\u624b\u673a\u4f20\u611f\u5668\u6570\u636e\uff08\u52a0\u901f\u5ea6\u8ba1\u3001\u9640\u87ba\u4eea\u3001\u78c1\u529b\u8ba1\u3001\u65cb\u8f6c\u5411\u91cf\uff09\uff0c\u5e76\u4ee5\u6bcf\u5c0f\u65f6\u81ea\u62a5\u544a\u6355\u6349 sedentary activity \u4e0e social context \u4e24\u4e2a\u7ef4\u5ea6\u3002\u57fa\u4e8e\u6b64\u53cc\u6807\u7b7e\u6570\u636e\u96c6\uff0c\u63d0\u51faDySTAN\uff08Dynamic Cross-Stitch with Task Attention Network\uff09\uff0c\u901a\u8fc7\u5171\u4eab\u8868\u793a\u4e0e\u8de8\u4efb\u52a1\u6ce8\u610f\u529b\u5b9e\u73b0\u5bf9\u4e24\u4e2a\u4efb\u52a1\u7684\u8054\u5408\u5206\u7c7b\u3002\u6a21\u578b\u5305\u542b\u4efb\u52a1\u4e13\u7528\u5206\u652f\u3001\u8de8\u4efb\u52a1\u4ea4\u4e92\u4e0e\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e76\u4ee5CNN-BiLSTM-GRU\u4e3a\u57fa\u7ebf\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u5728 sedentary activity \u7684\u5b8fF1\u5206\u6570\u4e0a\uff0cDySTAN \u76f8\u6bd4\u5355\u4efb\u52a1\u7684CNN-BiLSTM-GRU\u63d0\u534721.8%\uff0c\u76f8\u8f83\u6700\u5f3a\u591a\u4efb\u52a1\u57fa\u7ebfSluice Network\u63d0\u53478.2%\u3002\u8868\u660e\u540c\u65f6\u5efa\u6a21\u591a\u7ef4\u4e0a\u4e0b\u6587\u5bf9\u63d0\u9ad8\u79fb\u52a8\u573a\u666f\u8bc6\u522b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u5177\u6709\u91cd\u8981\u4f5c\u7528\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u5171\u73b0\u7684\u4e0a\u4e0b\u6587\u7ef4\u5ea6\u8fdb\u884c\u8054\u5408\u5efa\u6a21\uff0c\u5e76\u5229\u7528\u8de8\u4efb\u52a1\u6ce8\u610f\u529b\u4e0e\u5171\u4eab\u8868\u793a\uff0cDySTAN\u663e\u8457\u63d0\u5347\u4e86\u5728\u79fb\u52a8\u4f20\u611f\u73af\u5883\u4e0b\u7684\u4e0a\u4e0b\u6587\u8bc6\u522b\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u591a\u4efb\u52a1\u534f\u540c\u548c\u4efb\u52a1\u95f4\u4fe1\u606f\u5171\u4eab\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2512.02149", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02149", "abs": "https://arxiv.org/abs/2512.02149", "authors": ["Cristina Fern\u00e1ndez-C\u00f3rdoba", "Sergi S\u00e1nchez-Arag\u00f3n", "Merc\u00e8 Villanueva"], "title": "Weight distributions of simplex codes over finite chain rings and their Gray map images", "comment": "23 pages", "summary": "A linear code of length $n$ over a finite chain ring $R$ with residue field $\\F_q$ is a $R$-submodule of $R^n$. A $R$-linear code is a code over $\\F_q$ (not necessarily linear) which is the generalized Gray map image of a linear code over $R$. These codes can be seen as a generalization of the linear codes over $\\Z_{p^s}$ with $p$ prime and $s \\geq 1$. In this paper, we present the construction of linear simplex codes over $R$ and their corresponding $R$-linear simplex codes of type $\u03b1$ and $\u03b2$. Moreover, we show the fundamental parameters of these codes, including their minimum Hamming distance, as well as their complete weight distributions. We also study whether these simplex codes are optimal with respect to the Griesmer-type bound.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6709\u9650\u94fe\u73af R \u4e0a\u7ebf\u6027 simplex \u7801\u53ca\u5176 \u03b1\u3001\u03b2 \u578b\u7684\u6784\u9020\uff0c\u5e76\u7ed9\u51fa\u5176\u57fa\u672c\u53c2\u6570\uff08\u6700\u5c0f\u6c49\u660e\u8ddd\u79bb\u3001\u5b8c\u6574\u6743\u91cd\u5206\u5e03\uff09\u4ee5\u53ca\u4e0e Griesmer \u578b\u754c\u7684\u6700\u4f18\u6027\u5206\u6790\u3002", "motivation": "\u6269\u5c55\u5bf9\u73af\u7801\u7684\u7814\u7a76\uff0c\u5c06\u7ebf\u6027\u7801\u901a\u8fc7\u5e7f\u4e49 Gray \u6620\u5c04\u6620\u5c04\u5230 F_q \u4e0a\u7684\u7801\uff0c\u63d0\u51fa\u65b0\u7684 simplex \u7801\u65cf\uff0c\u63ed\u793a\u5176\u53c2\u6570\u4e0e\u5206\u5e03\u7279\u6027\uff0c\u5e76\u8003\u5bdf\u5176\u5728 Griesmer \u578b\u754c\u4e0b\u7684\u6700\u4f18\u6027\u3002", "method": "\u7ed9\u51fa\u5728\u6709\u9650\u94fe\u73af R \u4e0a\u7684\u7ebf\u6027 simplex \u7801\u6784\u9020\uff0c\u533a\u5206 \u03b1\u3001\u03b2 \u578b\uff1b\u5229\u7528\u5e7f\u4e49 Gray \u6620\u5c04\u5c06\u7ebf\u6027\u7801\u4e0e F_q \u4e0a\u7684\u7801\u76f8\u5173\u8054\uff1b\u63a8\u5bfc\u5e76\u8ba1\u7b97\u6700\u5c0f\u6c49\u660e\u8ddd\u79bb\u3001\u5b8c\u6574\u6743\u91cd\u5206\u5e03\uff0c\u5e76\u7814\u7a76\u4e0e Griesmer \u578b\u754c\u7684\u5173\u7cfb\u3002", "result": "\u7ed9\u51fa\u6240\u6784\u9020\u7801\u65cf\u7684\u57fa\u672c\u53c2\u6570\uff08\u5305\u62ec\u6700\u5c0f\u8ddd\u79bb\u548c\u5b8c\u6574\u6743\u91cd\u5206\u5e03\uff09\uff1b\u7ed9\u51fa\u662f\u5426\u8fbe\u5230\u6216\u63a5\u8fd1 Griesmer \u578b\u754c\u7684\u7ed3\u8bba\uff0c\u53ca\u5bf9 \u03b1\u3001\u03b2 \u578b\u7684\u533a\u5206\u6027\u7ed3\u679c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6269\u5c55\u4e86\u73af\u4e0a\u7684 simplex \u7801\u65cf\uff0c\u7ed9\u51fa\u660e\u786e\u7684\u53c2\u6570\u4e0e\u5206\u5e03\u7279\u5f81\uff0c\u5e76\u5bf9\u5176\u5728 Griesmer \u578b\u754c\u7684\u6700\u4f18\u6027\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u4e3a\u540e\u7eed\u5bf9\u4e0d\u540c\u7c7b\u578b\u548c\u5206\u5e03\u7684\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2512.02157", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.02157", "abs": "https://arxiv.org/abs/2512.02157", "authors": ["Aaron Sandoval", "Cody Rushing"], "title": "Factor(T,U): Factored Cognition Strengthens Monitoring of Untrusted AI", "comment": "7 pages body; 19 pages total; 8 figures", "summary": "The field of AI Control seeks to develop robust control protocols, deployment safeguards for untrusted AI which may be intentionally subversive. However, existing protocols that rely on weaker monitors to detect unsafe behavior often fail on complex tasks beyond the monitor's comprehension. We develop control protocols based on factored cognition, in which a trusted model decomposes a task, an untrusted model solves each resultant child task in isolation, and the results are reassembled into a full solution. These protocols may improve safety by several means, such as by simplifying the context for monitors, or by obscuring vulnerabilities in the environment. We implement our protocols in the APPS coding setting and red team them against backdoor attempts from an adversarial GPT-4.1 Nano. We find that: (i) Adding factored cognition to a trusted monitoring protocol can boost safety from 41% to 63%; (ii) Safety improves because monitor performance improves; (iii) Factored cognition makes it no harder for capable LLMs to write backdoors in APPS. While our protocols show low usefulness in APPS, they hold promise for more complex tasks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5206\u89e3\u8ba4\u77e5\u7684\u63a7\u5236\u534f\u8bae\uff1a\u53ef\u4fe1\u6a21\u578b\u5c06\u4efb\u52a1\u5206\u89e3\uff0c\u672a\u4fe1\u4efb\u6a21\u578b\u5bf9\u5404\u5b50\u4efb\u52a1\u72ec\u7acb\u6c42\u89e3\uff0c\u518d\u91cd\u7ec4\u5f62\u6210\u5b8c\u6574\u89e3\uff1b\u4ee5\u63d0\u5347\u5bf9\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u76d1\u63a7\u5b89\u5168\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5f31\u76d1\u63a7\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u96be\u4ee5\u68c0\u6d4b\u6216\u6291\u5236\u4e0d\u5b89\u5168\u884c\u4e3a\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u89e3-\u5e76\u884c\u6c42\u89e3-\u518d\u7ec4\u88c5\u7684\u8ba4\u77e5\u7ed3\u6784\u6765\u964d\u4f4e\u5bf9\u4e0a\u4e0b\u6587\u7684\u4f9d\u8d56\u5e76\u66b4\u9732\u6f5c\u5728\u6f0f\u6d1e\u4ee5\u4fbf\u63a7\u5236\u3002", "method": "\u5728 APPS \u7f16\u7a0b\u73af\u5883\u4e2d\u5b9e\u73b0\u57fa\u4e8e\u5206\u89e3\u8ba4\u77e5\u7684\u63a7\u5236\u534f\u8bae\uff1a\u53ef\u4fe1\u6a21\u578b\u5206\u89e3\u4efb\u52a1\uff0c\u672a\u4fe1\u4efb\u6a21\u578b\u5bf9\u5b50\u4efb\u52a1\u72ec\u7acb\u6c42\u89e3\uff0c\u7ed3\u679c\u518d\u7ec4\u5408\uff1b\u5e76\u5bf9\u6297\u6027\u653b\u51fb\uff08GPT-4.1 Nano\uff09\u4e0b\u7684\u540e\u95e8\u6d4b\u8bd5\u8fdb\u884c\u7ea2\u961f\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff1a\u5c06\u5206\u89e3\u8ba4\u77e5\u52a0\u5165\u53d7\u4fe1\u76d1\u63a7\u53ef\u5c06\u5b89\u5168\u6027\u4ece41%\u63d0\u5347\u523063%\uff1b\u63d0\u5347\u539f\u56e0\u5728\u4e8e\u76d1\u63a7\u6027\u80fd\u63d0\u9ad8\uff1b\u5206\u89e3\u8ba4\u77e5\u5e76\u672a\u63d0\u9ad8\u5f3a\u5927LLMs\u5728APPS\u4e2d\u7f16\u5199\u540e\u95e8\u7684\u96be\u5ea6\uff1b\u5728APPS\u573a\u666f\u4e0b\u603b\u4f53\u5b9e\u7528\u6027\u8f83\u4f4e\uff0c\u4f46\u5728\u66f4\u590d\u6742\u4efb\u52a1\u4e0a\u5177\u6709\u6f5c\u5728\u4ef7\u503c\u3002", "conclusion": "\u5206\u89e3\u8ba4\u77e5\u4e3a\u63d0\u5347\u76d1\u63a7\u5b89\u5168\u63d0\u4f9b\u4e00\u79cd\u6709\u6548\u65b9\u5411\uff0c\u4f46\u5728\u5f53\u524dAPPS\u73af\u5883\u4e0b\u6548\u7528\u6709\u9650\uff0c\u9700\u8981\u5728\u66f4\u590d\u6742\u4efb\u52a1\u4e2d\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e0e\u6269\u5c55\u3002"}}
{"id": "2512.02026", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02026", "abs": "https://arxiv.org/abs/2512.02026", "authors": ["Luis Correas-Naranjo", "Miguel Camacho-S\u00e1nchez", "La\u00ebtitia Launet", "Milena Zuric", "Valery Naranjo"], "title": "Towards Sustainable Precision: Machine Learning for Laser Micromachining Optimization", "comment": null, "summary": "In the pursuit of sustainable manufacturing, ultra-short pulse laser micromachining stands out as a promising solution while also offering high-precision and qualitative laser processing. However, unlocking the full potential of ultra-short pulse lasers requires an optimized monitoring system capable of early detection of defective workpieces, regardless of the preprocessing technique employed. While advances in machine learning can help predict process quality features, the complexity of monitoring data necessitates reducing both model size and data dimensionality to enable real-time analysis. To address these challenges, this paper introduces a machine learning framework designed to enhance surface quality assessment across diverse preprocessing techniques. To facilitate real-time laser processing monitoring, our solution aims to optimize the computational requirements of the machine learning model. Experimental results show that the proposed model not only outperforms the generalizability achieved by previous works across diverse preprocessing techniques but also significantly reduces the computational requirements for training. Through these advancements, we aim to establish the baseline for a more sustainable manufacturing process.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u8d85\u77ed\u8109\u51b2\u6fc0\u5149\u5fae\u52a0\u5de5\u7684\u8f7b\u91cf\u5316\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u8de8\u591a\u79cd\u9884\u5904\u7406\u6280\u672f\u7684\u8868\u9762\u8d28\u91cf\u8bc4\u4f30\u4e0e\u5b9e\u65f6\u76d1\u63a7\uff0c\u517c\u987e\u6cdb\u5316\u4e0e\u8ba1\u7b97\u6210\u672c\u4f18\u5316\u3002", "motivation": "\u5b9e\u73b0\u53ef\u6301\u7eed\u5236\u9020\u4e2d\u5bf9\u9ad8\u7cbe\u5ea6\u8868\u9762\u5904\u7406\u7684\u5b9e\u65f6\u7f3a\u9677\u68c0\u6d4b\uff0c\u9700\u964d\u4f4e\u6570\u636e\u7ef4\u5ea6\u548c\u6a21\u578b\u89c4\u6a21\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u6027\u548c\u8d44\u6e90\u9650\u5236\u3002", "method": "\u8bbe\u8ba1\u4e00\u4e2a\u8de8\u9884\u5904\u7406\u6280\u672f\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u964d\u7ef4\u3001\u7279\u5f81\u63d0\u53d6\u4e0e\u8f7b\u91cf\u5316\u6a21\u578b\u6765\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\uff0c\u5e76\u4f18\u5316\u76d1\u63a7\u7cfb\u7edf\u4ee5\u5b9e\u73b0\u5b9e\u65f6\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u5728\u8de8\u9884\u5904\u7406\u6280\u672f\u573a\u666f\u4e0b\u7684\u6cdb\u5316\u6027\u80fd\u4f18\u4e8e\u5148\u524d\u5de5\u4f5c\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u8fc7\u7a0b\u7684\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5b9e\u73b0\u53ef\u6301\u7eed\u5236\u9020\u4e2d\u7684\u9ad8\u6548\u5b9e\u65f6\u76d1\u63a7\u63d0\u4f9b\u57fa\u7ebf\uff0c\u4fc3\u8fdb\u5728\u4e0d\u540c\u9884\u5904\u7406\u6280\u672f\u4e0b\u7684\u8868\u9762\u8d28\u91cf\u8bc4\u4f30\u7684\u666e\u9002\u6027\u4e0e\u7ecf\u6d4e\u6027\u3002"}}
{"id": "2512.02255", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02255", "abs": "https://arxiv.org/abs/2512.02255", "authors": ["Kunnathully Sadanandan Sanila", "Rickard Nilsson", "Emad Ibrahim", "Neelakandan Rajamohan"], "title": "Low-Power Double RIS-Assisted Mobile LEO Satellite Communications", "comment": "Published in 2025 IEEE Wireless Communications and Networking Conference (WCNC)", "summary": "We propose a low-power mobile low earth orbit (LEO) satellite communication architecture, employing double reconfigurable intelligent surfaces (RIS) to enhance energy efficiency and signal performance. With a distance between RISs that satisfies the far-field requirement, this architecture positions one small RIS each in the near-field of the satellite's antenna and the user on the ground. Moreover, we develop a path loss model for the double-RIS communication link, considering the near-field and far-field effects. Further, with the help of dual-stage beamforming, the proposed system maximizes the signal power and minimizes power consumption. Simulation results show that the proposed architecture can reduce the power consumption with 40 dB in the uplink, with a small $0.25^2$ $\\text{m}^2$ RIS near the user, to communicate in energy-constrained LEO satellite communication circumstances.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53ccRISLEO\u536b\u661f\u901a\u4fe1\u67b6\u6784\uff0c\u901a\u8fc7\u5728\u536b\u661f\u5929\u7ebf\u8fd1\u573a\u548c\u5730\u9762\u8fd1\u7aef\u5404\u8bbe\u4e00\u4e2a\u5c0f\u578bRIS\uff0c\u6ee1\u8db3RIS\u95f4\u8fdc\u573a\u6761\u4ef6\uff0c\u7ed3\u5408\u53cc\u7ea7\u6ce2\u675f\u6210\u5f62\uff0c\u5728\u80fd\u91cf\u53d7\u9650\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u80fd\u6548\uff1b\u4eff\u771f\u8868\u660e\u4e0a\u884c\u529f\u8017\u53ef\u964d\u4f4e\u7ea640 dB\uff0cRIS\u9762\u79ef\u7ea60.0625 m^2\u3002", "motivation": "\u5728\u80fd\u6e90\u53d7\u9650\u7684LEO\u536b\u661f\u901a\u4fe1\u573a\u666f\u4e2d\uff0c\u901a\u8fc7\u88ab\u52a8\u5f0f\u518d\u914d\u7f6e\u8868\u9762\uff08RIS\uff09\u5b9e\u73b0\u9ad8\u6548\u4fe1\u53f7\u5f3a\u5316\u4e0e\u529f\u8017\u964d\u4f4e\uff0c\u63d0\u5347\u7cfb\u7edf\u80fd\u6e90\u6548\u7387\u548c\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u53ccRIS\u67b6\u6784\uff08\u536b\u661f\u7aef\u8fd1\u573aRIS\u4e0e\u5730\u9762\u7aefRIS\uff09\uff0c\u786e\u4fdd\u4e24RIS\u4e4b\u95f4\u6ee1\u8db3\u8fdc\u573a\uff1b\u5efa\u7acb\u53ccRIS\u94fe\u8def\u7684\u8fd1\u573a\u4e0e\u8fdc\u573a\u8026\u5408\u8def\u5f84\u635f\u8017\u6a21\u578b\uff1b\u91c7\u7528\u53cc\u7ea7\u6ce2\u675f\u6210\u5f62\u4ee5\u6700\u5927\u5316\u63a5\u6536\u4fe1\u53f7\u529f\u7387\u5e76\u6700\u5c0f\u5316\u603b\u529f\u8017\uff1b\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u6027\u80fd\u4e0e\u80fd\u6548\u63d0\u5347\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u5728\u4e0a\u884c\u94fe\u8def\u4e2d\u529f\u8017\u53ef\u964d\u4f4e\u7ea640 dB\uff0c\u4f7f\u7528\u9762\u79ef\u7ea6\u4e3a0.0625 m^2\u7684RIS\u5373\u53ef\u5b9e\u73b0\u663e\u8457\u80fd\u6548\u63d0\u5347\uff0c\u9002\u7528\u4e8e\u80fd\u91cf\u53d7\u9650\u7684LEO\u536b\u661f\u901a\u4fe1\u5e94\u7528\u3002", "conclusion": "\u53ccRIS\u4e0e\u53cc\u7ea7\u6ce2\u675f\u6210\u5f62\u7684\u7ec4\u5408\u80fd\u663e\u8457\u63d0\u5347LEO\u536b\u661f\u94fe\u8def\u7684\u80fd\u6548\u4e0e\u4fe1\u53f7\u6027\u80fd\uff0c\u4e3a\u80fd\u91cf\u53d7\u9650\u573a\u666f\u63d0\u4f9b\u53ef\u884c\u7684\u4f4e\u529f\u8017\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02243", "categories": ["cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02243", "abs": "https://arxiv.org/abs/2512.02243", "authors": ["Md Abdul Ahad Minhaz", "Zannatul Zahan Meem", "Md. Shohrab Hossain"], "title": "PhishSnap: Image-Based Phishing Detection Using Perceptual Hashing", "comment": "IEE Standard Formatting, 3 pages, 3 figures", "summary": "Phishing remains one of the most prevalent online threats, exploiting human trust to harvest sensitive credentials. Existing URL- and HTML-based detection systems struggle against obfuscation and visual deception. This paper presents \\textbf{PhishSnap}, a privacy-preserving, on-device phishing detection system leveraging perceptual hashing (pHash). Implemented as a browser extension, PhishSnap captures webpage screenshots, computes visual hashes, and compares them against legitimate templates to identify visually similar phishing attempts. A \\textbf{2024 dataset of 10,000 URLs} (70\\%/20\\%/10\\% train/validation/test) was collected from PhishTank and Netcraft. Due to security takedowns, a subset of phishing pages was unavailable, reducing dataset diversity. The system achieved \\textbf{0.79 accuracy}, \\textbf{0.76 precision}, and \\textbf{0.78 recall}, showing that visual similarity remains a viable anti-phishing measure. The entire inference process occurs locally, ensuring user privacy and minimal latency.", "AI": {"tldr": "PhishSnap \u57fa\u4e8e\u7aef\u4fa7\u611f\u77e5\u54c8\u5e0c\u7684\u89c6\u89c9\u9493\u9c7c\u68c0\u6d4b\u7cfb\u7edf\uff0c\u9690\u79c1\u4fdd\u62a4\u3001\u5728\u8bbe\u5907\u4e0a\u63a8\u7406\u3002\u901a\u8fc7\u622a\u56fe\u54c8\u5e0c\u4e0e\u6a21\u677f\u6bd4\u5bf9\u5b9e\u73b0\u9632\u9493\u9c7c\uff0c2024 \u5e74\u6570\u636e\u96c6\u7ea6 1 \u4e07\u6761 URL\uff0c\u8868\u73b0\u7ea6 0.79 \u7684\u51c6\u786e\u7387\u30010.76 \u7684\u7cbe\u786e\u7387\u30010.78 \u7684\u53ec\u56de\u7387\u3002", "motivation": "\u5e94\u5bf9\u73b0\u6709\u57fa\u4e8e URL/HTML \u7684\u68c0\u6d4b\u5728\u5bf9\u6297\u89c6\u89c9\u6b3a\u9a97\u548c\u4eff\u5192\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u9700\u6c42\u9690\u79c1\u53cb\u597d\u4e14\u80fd\u5728\u7aef\u8bbe\u5907\u4e0a\u8fd0\u884c\u7684\u9493\u9c7c\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u4f5c\u4e3a\u6d4f\u89c8\u5668\u6269\u5c55\u5b9e\u73b0\uff1a\u6355\u83b7\u7f51\u9875\u622a\u56fe\uff0c\u8ba1\u7b97\u89c6\u89c9\u54c8\u5e0c\uff08pHash\uff09\uff0c\u4e0e\u5408\u6cd5\u6a21\u677f\u8fdb\u884c\u76f8\u4f3c\u6027\u6bd4\u8f83\uff1b\u5728\u672c\u5730\u5b8c\u6210\u63a8\u7406\uff0c\u786e\u4fdd\u7528\u6237\u9690\u79c1\uff1b\u6570\u636e\u96c6\u6309 70/20/10 \u7684\u5212\u5206\u7528\u4e8e\u8bad\u7ec3/\u9a8c\u8bc1/\u6d4b\u8bd5\u3002", "result": "\u5728 2024 \u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u7ea6 0.79 \u7684\u51c6\u786e\u7387\u30010.76 \u7684\u7cbe\u786e\u7387\u30010.78 \u7684\u53ec\u56de\u7387\uff1b\u56e0\u5b89\u5168 takedowns \u90e8\u5206\u9493\u9c7c\u9875\u9762\u4e0d\u53ef\u7528\uff0c\u5bfc\u81f4\u6570\u636e\u96c6\u591a\u6837\u6027\u4e0b\u964d\u3002", "conclusion": "\u89c6\u89c9\u76f8\u4f3c\u6027\u8bc1\u5b9e\u4ecd\u662f\u6709\u6548\u7684\u53cd\u9493\u9c7c\u4fe1\u53f7\uff1b\u7aef\u8bbe\u5907\u63a8\u7406\u5e26\u6765\u9690\u79c1\u4e0e\u4f4e\u5ef6\u8fdf\u4f18\u52bf\uff1b\u6570\u636e\u96c6\u5c40\u9650\u53ef\u80fd\u5f71\u54cd\u6cdb\u5316\u6027\uff0c\u672a\u6765\u9700\u63d0\u5347\u6570\u636e\u591a\u6837\u6027\u4e0e\u5bf9\u6297\u6027\u8bc4\u4f30\u3002"}}
{"id": "2512.02257", "categories": ["cs.IT", "math.RT"], "pdf": "https://arxiv.org/pdf/2512.02257", "abs": "https://arxiv.org/abs/2512.02257", "authors": ["Ryan Leal", "Jingtong Sun", "Juan Pablo Vigneaux"], "title": "Entropies associated with orbits of finite groups", "comment": null, "summary": "For certain groups, parabolic subgroups appear as stabilizers of flags of sets or vector spaces. Quotients by these parabolic subgroups represent orbits of flags, and their cardinalities asymptotically reveal entropies (as rates of exponential or superexponential growth). The multiplicative \"chain rules\" that involve these cardinalities induce, asymptotically, additive analogues for entropies. Many traditional formulas in information theory correspond to quotients of symmetric groups, which are a particular kind of reflection group; in this case, the cardinalities of orbits are given by multinomial coefficients and are asymptotically related to Shannon entropy. One can treat similarly quotients of the general linear groups over a finite field; in this case, the cardinalities of orbits are given by $q$-multinomials and are asymptotically related to the Tsallis 2-entropy. In this contribution, we consider other finite reflection groups as well as the symplectic group as an example of a classical group over a finite field (groups of Lie type). In both cases, the groups are classified by Dynkin diagrams into infinite series of similar groups $A_n$, $B_n$, $C_n$, $D_n$ and a finite number of exceptional ones. The $A_n$ series consists of the symmetric groups (reflection case) and general linear groups (Lie case). Some of the other series, studied here from an information-theoretic perspective for the first time, are linked to new entropic functionals.", "AI": {"tldr": "\u901a\u8fc7\u5bf9\u6709\u9650\u7fa4\u53ca\u5176 Lie \u578b\u5bf9\u79f0\u6027\u7684\u5171\u8f6d\u5206\u533a\uff08parabolic \u5b50\u7fa4\u4f5c\u7528\u4ea7\u751f\u7684\u65d7\u7a33\u5b9a\u96c6\u5408\uff09\u4e4b\u8f68\u9053\u8ba1\u6570\u7684\u6e10\u8fd1\u5206\u6790\uff0c\u5c06\u4fe1\u606f\u71b5\u4e0e\u7fa4\u8bba\u4e2d\u7684\u8ba1\u6570\u8054\u7cfb\u8d77\u6765\uff1b\u5728 A_n \u7cfb\uff08\u5bf9\u79f0\u7fa4\u548c GL_n(F_q)\uff09\u4e4b\u5916\uff0c\u62d3\u5c55\u5230 B_n, C_n, D_n \u53ca\u5176\u4ed6\u4f8b\u5916\u578b\uff0c\u63ed\u793a\u4e0d\u540c\u7cfb\u5217\u5bf9\u5e94\u7684\u71b5\u6cdb\u51fd\uff08\u542b\u9999\u519c\u71b5\u3001Tsallis \u71b5\u53ca\u65b0\u578b\u71b5\uff09\u5e76\u7ed9\u51fa\u53ef\u80fd\u7684\u4e58\u6cd5\u89c4\u5219\u7684\u6e10\u8fd1\u7b49\u6548\u3002", "motivation": "\u5c06\u4fe1\u606f\u7406\u8bba\u4e2d\u7684\u4e58\u6cd5\u6cd5\u5219\u4e0e\u7fa4\u4f5c\u7528\u4e0b\u7684\u8f68\u9053\u8ba1\u6570\u8054\u7cfb\u8d77\u6765\uff0c\u63ed\u793a\u65d7\u7a33\u5b9a\u6027\u4e0e\u6d4b\u5ea6\u4e4b\u95f4\u7684\u6df1\u5c42\u7ed3\u6784\u3002\u901a\u8fc7\u628a\u5bf9\u79f0\u7fa4\u3001\u7ebf\u6027\u7fa4\u53ca\u5176\u4ed6 Lie-type \u7fa4\u7684\u8f68\u9053\u6570\u91cf\u7684\u6e10\u8fd1\u589e\u957f\u6620\u5c04\u5230\u71b5\u91cf\u5ea6\uff0c\u7edf\u4e00\u4fe1\u606f\u8bba\u4e0e\u4ee3\u6570\u7ed3\u6784\u7684\u89c6\u89d2\uff0c\u62d3\u5c55\u5bf9\u4e0d\u540c\u7fa4\u7cfb\u5217\u7684\u71b5\u6982\u5ff5\u3002", "method": "\u5206\u6790\u6709\u9650\u53cd\u5c04\u7fa4\u53ca\u5176 Lie \u578b\u7fa4\u5728\u65d7\u96c6\u5408\u4e0a\u7684 parabolic \u5b50\u7fa4\u7a33\u5b9a\u6027\uff0c\u8ba1\u7b97\u5546\u7a7a\u95f4\u7684\u8f68\u9053\u57fa\u6570\uff1b\u5229\u7528 q-\u591a\u9879\u5f0f\u3001q-\u4f4d\u52bf\u7b49\u5de5\u5177\u5f97\u5230\u8f68\u9053\u6570\u91cf\u7684\u6e10\u8fd1\u5bf9\u6570\uff0c\u5e76\u5c06\u5176\u4e0e\u9999\u519c\u71b5\u3001Tsallis \u71b5\u53ca\u65b0\u578b\u71b5\u6cdb\u51fd\u5bf9\u5e94\u8d77\u6765\uff1b\u6309 Dynkin \u56fe\u7684\u7c7b\u578b\u5bf9 A_n, B_n, C_n, D_n \u7cfb\u53ca\u5c11\u6570\u5f02\u5e38\u578b\u9010\u4e00\u5904\u7406\uff0c\u5c55\u793a\u4e0d\u540c\u7cfb\u5217\u7684\u5173\u8054\u71b5\u6027\u8d28\u3002", "result": "\u5f97\u5230\u8f68\u9053\u8ba1\u6570\u7684\u6e10\u8fd1\u8868\u8fbe\u4e0e\u4fe1\u606f\u71b5\u4e4b\u95f4\u7684\u5bf9\u5e94\uff1a\u5728 A_n \u7cfb\uff08\u5bf9\u79f0\u7fa4\u4e0e GL_n(F_q)\uff09\u4e2d\u4e0e\u9999\u519c/\u5b9a\u5e38\u591a\u9879\u5f0f\u76f8\u5173\u7684\u71b5\u5173\u7cfb\u5f97\u5230\u660e\u786e\uff1b\u5728\u5176\u4ed6\u7cfb\u5217\u4e2d\u51fa\u73b0\u4e0e\u4e4b\u4e0d\u540c\u7684 q-\u60df\u71b5\u578b\u5173\u7cfb\uff0c\u6307\u51fa\u5b58\u5728\u65b0\u7684\u4fe1\u606f\u5ea6\u91cf\u6216\u71b5\u6cdb\u51fd\uff1b\u5e76\u4ee5\u8f9b\u7fa4\u4e3a\u4f8b\u8bf4\u660e Lie \u578b\u7fa4\u4e0b\u7684\u666e\u904d\u6027\u4e0e\u5c40\u90e8\u6027\u3002", "conclusion": "\u7ecf\u5178\u4fe1\u606f\u7406\u8bba\u516c\u5f0f\u53ef\u89c6\u4e3a\u5bf9\u79f0\u7fa4\u5546\u7a7a\u95f4\u8f68\u9053\u7684\u8ba1\u6570\u7ed3\u679c\u7684\u4e00\u79cd\u5b9e\u73b0\u3002\u5c06\u5206\u6790\u6269\u5c55\u5230\u5176\u4ed6\u6709\u9650\u53cd\u5c04\u7fa4\u548c Lie \u578b\u7fa4\u4e0d\u4ec5\u4fdd\u6301\u4e86\u4e0e\u71b5\u7684\u8054\u7cfb\uff0c\u8fd8\u63ed\u793a\u4e86\u65b0\u7684\u71b5\u6cdb\u51fd\uff0c\u63d0\u793a\u5728\u4ee3\u6570\u7ed3\u6784\u4e0e\u4fe1\u606f\u91cf\u5ea6\u4e4b\u95f4\u53ef\u5efa\u7acb\u66f4\u5e7f\u6cdb\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u4e3a\u540e\u7eed\u5728\u7fa4\u8bba\u3001\u91cf\u5b50\u4fe1\u606f\u4e0e\u7edf\u8ba1\u7269\u7406\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2512.02285", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.02285", "abs": "https://arxiv.org/abs/2512.02285", "authors": ["Jenna Kline", "Rugved Katole", "Tanya Berger-Wolf", "Christopher Stewart"], "title": "Edge-Native, Behavior-Adaptive Drone System for Wildlife Monitoring", "comment": "Accepted to DroneSys: First Workshop on Autonomous Drone Computing Systems and Applications at the ACM/IEEE Symposium on Edge Computing (SEC) 2025", "summary": "Wildlife monitoring with drones must balance competing demands: approaching close enough to capture behaviorally-relevant video while avoiding stress responses that compromise animal welfare and data validity. Human operators face a fundamental attentional bottleneck: they cannot simultaneously control drone operations and monitor vigilance states across entire animal groups. By the time elevated vigilance becomes obvious, an adverse flee response by the animals may be unavoidable. To solve this challenge, we present an edge-native, behavior-adaptive drone system for wildlife monitoring. This configurable decision-support system augments operator expertise with automated group-level vigilance monitoring. Our system continuously tracks individual behaviors using YOLOv11m detection and YOLO-Behavior classification, aggregates vigilance states into a real-time group stress metric, and provides graduated alerts (alert vigilance to flee response) with operator-tunable thresholds for context-specific calibration. We derive service-level objectives (SLOs) from video frame rates and behavioral dynamics: to monitor 30fps video streams in real-time, our system must complete detection and classification within 33ms per frame. Our edge-native pipeline achieves 23.8ms total inference on GPU-accelerated hardware, meeting this constraint with a substantial margin. Retrospective analysis of seven wildlife monitoring missions demonstrates detection capability and quantifies the cost of reactive control: manual piloting results in 14 seconds average adverse behavior duration with 71.9% usable frames. Our analysis reveals operators could have received actionable alerts 51s before animals fled in 57% of missions. Simulating 5-second operator intervention yields a projected performance of 82.8% usable frames with 1-second adverse behavior duration,a 93% reduction compared to manual piloting.", "AI": {"tldr": "Edge-native, behavior-adaptive drone monitoring for wildlife that automates vigilance monitoring to reduce animal stress and improve data usability; real-time inference at 23.8ms per frame; significant reductions in adverse behaviors compared to manual piloting.", "motivation": "Human operators face attentional bottlenecks when monitoring large animal groups; conventional piloting can trigger stress and fleeing, reducing data validity. The paper aims to balance close monitoring with animal welfare by automating vigilance detection and providing context-specific alerts.", "method": "An edge-native pipeline using YOLOv11m for detection and YOLO-Behavior for behavior classification; aggregates vigilance into a real-time group stress metric; operator-tunable alert thresholds from 30fps video frames; SLO-based performance target (33ms per frame) with GPU-accelerated inference achieving 23.8ms; retrospective mission analysis and simulation of operator interventions.", "result": "Achieved 23.8ms per-frame inference on GPU hardware; retrospective seven-mission analysis shows manual piloting yields 14s average adverse behavior and 71.9% usable frames; actionable alerts could arrive 51s before flee in 57% of missions; simulating 5s operator intervention yields 82.8% usable frames with 1s adverse behavior, a 93% reduction vs manual piloting.", "conclusion": "The system demonstrates that automated vigilance monitoring and context-aware alerting can substantially improve data usability and animal welfare in wildlife drone surveys, enabling proactive interventions and substantial reductions in adverse behavior compared to manual piloting."}}
{"id": "2512.02049", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02049", "abs": "https://arxiv.org/abs/2512.02049", "authors": ["R\u00e9mi Marsal", "St\u00e9phanie Chaillat"], "title": "PIBNet: a Physics-Inspired Boundary Network for Multiple Scattering Simulations", "comment": null, "summary": "The boundary element method (BEM) provides an efficient numerical framework for solving multiple scattering problems in unbounded homogeneous domains, since it reduces the discretization to the domain boundaries, thereby condensing the computational complexity. The procedure first consists in determining the solution trace on the boundaries of the domain by solving a boundary integral equation, after which the volumetric solution can be recovered at low computational cost with a boundary integral representation. As the first step of the BEM represents the main computational bottleneck, we introduce PIBNet, a learning-based approach designed to approximate the solution trace. The method leverages a physics-inspired graph-based strategy to model obstacles and their long-range interactions efficiently. Then, we introduce a novel multiscale graph neural network architecture for simulating the multiple scattering. To train and evaluate our network, we present a benchmark consisting of several datasets of different types of multiple scattering problems. The results indicate that our approach not only surpasses existing state-of-the-art learning-based methods on the considered tasks but also exhibits superior generalization to settings with an increased number of obstacles. github.com/ENSTA-U2IS-AI/pibnet", "AI": {"tldr": "PIBNet provides a learning-based framework to approximate boundary traces in the boundary element method (BEM) for multiple scattering, using physics-inspired graphs and a multiscale graph neural network to improve efficiency and generalization to more obstacles.", "motivation": "The boundary element method reduces discretization to boundaries, but the critical bottleneck is computing the solution trace on boundaries. A data-driven surrogate that efficiently captures long-range interactions among obstacles can accelerate BEM for large-scale scattering problems.", "method": "PIBNet introduces a physics-inspired graph-based model to represent obstacles and their long-range interactions, and a novel multiscale graph neural network architecture to simulate multiple scattering. The network is trained and evaluated on a benchmark comprising diverse multiple-scattering datasets.", "result": "The approach outperforms existing state-of-the-art learning-based methods on the considered tasks and shows superior generalization to settings with more obstacles.", "conclusion": "PIBNet is an effective, scalable learning-based surrogate for the boundary trace in BEM, enabling efficient and accurate boundary-based simulations of multiple scattering with better generalization."}}
{"id": "2512.02259", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02259", "abs": "https://arxiv.org/abs/2512.02259", "authors": ["Derek Garcia", "Briana Lee", "Ibrahim Matar", "David Rickards", "Andrew Zilnicki"], "title": "CVE Breadcrumbs: Tracking Vulnerabilities Through Versioned Apache Libraries", "comment": null, "summary": "The Apache Software Foundation (ASF) ecosystem underpins a vast portion of modern software infrastructure, powering widely used components such as Log4j, Tomcat, and Struts. However, the ubiquity of these libraries has made them prime targets for high-impact security vulnerabilities, as illustrated by incidents like Log4Shell. Despite their widespread adoption, Apache projects are not immune to recurring and severe security weaknesses. We conduct a historical analysis of the Apache ecosystem to follow the \"breadcrumb trail of vulnerabilities\" by compiling a comprehensive dataset of Common Vulnerabilities and Exposures (CVEs) and Common Weakness Enumerations (CWEs). We examine trends in exploit recurrence, disclosure timelines, and remediation practices. Our analysis is guided by four key research questions: (1) What are the most persistent and repeated CWEs in Apache libraries? (2) How long do CVEs persist before being addressed? (3) What is the delay between CVE introduction and official disclosure? and (4) How long after disclosure are CVEs remediated? We present a detailed timeline of vulnerability lifecycle stages across Apache libraries and offer insights to improve secure coding practices, vulnerability monitoring, and remediation strategies. Our contributions include a curated dataset covering 24,285 Apache libraries, 1,285 CVEs, and 157 CWEs, along with empirical findings and developer-focused recommendations.", "AI": {"tldr": "\u5bf9 Apache \u751f\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u6f0f\u6d1e\u8fdb\u884c\u5386\u53f2\u6027\u6570\u636e\u5206\u6790\uff0c\u63ed\u793a\u6700\u5177\u91cd\u590d\u6027\u7684 CWEs\u3001\u6f0f\u6d1e\u7684\u53d1\u73b0\u4e0e\u4fee\u590d\u5ef6\u8fdf\uff0c\u4ee5\u53ca\u4ece\u62ab\u9732\u5230\u4fee\u590d\u7684\u65f6\u95f4\u7ebf\u3002", "motivation": "\u5728\u7ebf\u5f00\u6e90\u751f\u6001\u4e2d\uff0cApache \u7ec4\u4ef6\u5e7f\u6cdb\u4f7f\u7528\u4f46\u6613\u53d7\u6f0f\u6d1e\u5f71\u54cd\uff0c\u9700\u7406\u89e3\u6f0f\u6d1e\u751f\u547d\u5468\u671f\u4ee5\u6539\u8fdb\u5b89\u5168\u5b9e\u8df5\u3002", "method": "\u7ec4\u5efa\u8986\u76d6 24,285 \u4e2a Apache \u5e93\u30011,285 \u4e2a CVEs\u3001157 \u4e2a CWEs \u7684\u6570\u636e\u96c6\uff0c\u7ed3\u5408 CVE \u4e0e CWE \u5206\u7c7b\uff0c\u5206\u6790\u590d\u53d1\u7684\u6f0f\u6d1e\u7c7b\u578b\u3001\u62ab\u9732\u548c\u4fee\u590d\u65f6\u5e8f\uff0c\u7ed9\u51fa\u65f6\u95f4\u7ebf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6700\u6301\u4e45\u548c\u91cd\u590d\u7684 CWEs \u4ee5\u53ca CVE \u7684\u6301\u7eed\u65f6\u95f4\u3001\u4ece\u5f15\u5165\u5230\u62ab\u9732\u7684\u5ef6\u8fdf\u3001\u62ab\u9732\u540e\u5230\u4fee\u590d\u7684\u65f6\u95f4\u7b49\uff0c\u5e76\u7ed9\u51fa\u8de8\u5e93\u7684\u6f0f\u6d1e\u751f\u547d\u5468\u671f\u65f6\u95f4\u7ebf\u3002\u63d0\u4f9b\u4e00\u4e2a\u53ef\u590d\u7528\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u5927\u91cf Apache \u5e93\u3001CVE \u4e0e CWE\uff0c\u5e76\u63d0\u51fa\u9762\u5411\u5f00\u53d1\u8005\u7684\u5b89\u5168\u6539\u8fdb\u5efa\u8bae\u3002", "conclusion": "\u57fa\u4e8e\u5927\u89c4\u6a21\u6570\u636e\u5206\u6790\uff0c\u53ef\u4e3a\u6539\u8fdb\u5b89\u5168\u7f16\u7801\u5b9e\u8df5\u3001\u6f0f\u6d1e\u76d1\u63a7\u548c\u4fee\u590d\u7b56\u7565\u63d0\u4f9b\u8bc1\u636e\uff1b\u6570\u636e\u96c6\u53ef\u7528\u4e8e\u672a\u6765\u7814\u7a76\u4e0e\u5de5\u4e1a\u754c\u7684\u6f0f\u6d1e\u6cbb\u7406\u4f18\u5316\u3002"}}
{"id": "2512.02153", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02153", "abs": "https://arxiv.org/abs/2512.02153", "authors": ["Murat Babek Salman", "Emil Bj\u00f6rnson", "\u00d6zlem Tugfe Demir"], "title": "Hardware Distortion Aware Precoding for ISAC Systems", "comment": "5 pages, 4 figures, Asilomar Conference on Signals, Systems, and Computers, 2025", "summary": "The impact of hardware impairments on the spectral efficiency of communication systems is well studied, but their effect on sensing performance remains unexplored. In this paper, we analyze the influence of hardware impairments on integrated sensing and communication (ISAC) systems in cluttered environments. We derive the sensing signal-to-clutter-plus-noise ratio (SCNR) and show that hardware distortions significantly degrade sensing performance by enhancing clutter-induced noise, which masks target echoes. The isotropic nature of transmit distortion due to multiple stream transmission further complicates clutter suppression. To address this, we propose a distortion- and clutter-aware precoding strategy that minimizes the deviation from the communication-optimized precoder while improving sensing robustness. We also propose an alternative power allocation-based approach that reduces computational complexity. Numerical results confirm the effectiveness of the proposed approaches in overcoming hardware- and clutter-induced limitations, demonstrating significant performance gains over distortion-unaware designs.", "AI": {"tldr": "\u786c\u4ef6\u5931\u771f\u4f1a\u964d\u4f4eISAC\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u611f\u77e5\u6027\u80fd\uff1b\u63d0\u51fa\u9762\u5411\u5931\u771f\u548c\u6742\u6ce2\u7684\u524d\u5411\u5904\u7406\u4e0e\u529f\u7387\u5206\u914d\u7b56\u7565\uff0c\u5728\u63a5\u8fd1\u901a\u4fe1\u6700\u4f18\u9884\u7f16\u7801\u7684\u540c\u65f6\u63d0\u5347\u611f\u77e5\u9c81\u68d2\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u76f8\u5bf9\u4e8e\u4e0d\u8003\u8651\u5931\u771f\u7684\u8bbe\u8ba1\u5177\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "ISAC\u5728\u6742\u6ce2\u73af\u5883\u4e2d\u53d7\u5230\u786c\u4ef6\u5931\u771f\u5f71\u54cd\uff0c\u7136\u800c\u5728\u8003\u8651\u5931\u771f\u4e0b\u7684\u611f\u77e5\u6027\u80fd\u8bc4\u4f30\u4e0e\u9c81\u68d2\u8bbe\u8ba1\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\uff1b\u9700\u8981\u5f00\u53d1\u80fd\u540c\u65f6\u6291\u5236\u5931\u771f\u4e0e\u6742\u6ce2\u7684\u9c81\u68d2\u65b9\u6848\u3002", "method": "\u63a8\u5bfc\u5728\u786c\u4ef6\u5931\u771f\u6761\u4ef6\u4e0b\u7684\u611f\u77e5\u4fe1\u566a\u6bd4SCNR\uff0c\u5206\u6790\u591a\u5929\u7ebf\u53d1\u9001\u5931\u771f\u7684\u5404\u5411\u540c\u6027\u7279\u6027\u5bf9\u6742\u6ce2\u6291\u5236\u7684\u5f71\u54cd\uff1b\u63d0\u51fa\u5931\u771f\u4e0e\u6742\u6ce2\u611f\u77e5\u7684\u524d\u5411\u5904\u7406\u7b56\u7565\uff0c\u5c3d\u91cf\u4fdd\u6301\u4e0e\u9762\u5411\u901a\u4fe1\u4f18\u5316\u7684\u9884\u7f16\u7801\u76f8\u8fd1\uff0c\u540c\u65f6\u63d0\u5347\u611f\u77e5\u9c81\u68d2\u6027\uff1b\u5e76\u7ed9\u51fa\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u7684\u57fa\u4e8e\u529f\u7387\u5206\u914d\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u786c\u4ef6\u5931\u771f\u548c\u6742\u6ce2\u5e26\u6765\u7684\u9650\u5236\uff0c\u76f8\u5bf9\u4e8e\u5ffd\u7565\u5931\u771f\u7684\u8bbe\u8ba1\u5177\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u5931\u771f\u548c\u6742\u6ce2\u4fe1\u606f\u6765\u8bbe\u8ba1\u9c81\u68d2\u7684\u524d\u5411\u5904\u7406\u548c\u529f\u7387\u5206\u914d\uff0cISAC\u7cfb\u7edf\u7684\u611f\u77e5\u6027\u80fd\u5728\u5b58\u5728\u786c\u4ef6\u5931\u771f\u7684\u573a\u666f\u4e0b\u53ef\u4ee5\u5f97\u5230\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2512.02325", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02325", "abs": "https://arxiv.org/abs/2512.02325", "authors": ["Guodong Wang", "Hongwei Liu", "Jinquan Luo"], "title": "New Constructions of Non-GRS MDS Codes, Recovery and Determination Algorithms for GRS Codes", "comment": null, "summary": "In this paper, we propose a new method for constructing a class of non-GRS MDS codes. The lengths of these codes can reach up to $\\frac{q+3}{2}$ (for finite fields of odd characteristic) and $\\frac{q+4}{2}$ (for even characteristic), respectively. Owing to their special structure, we can use the Cauchy matrix method to obtain the necessary and sufficient conditions for these codes to be MDS codes and non-GRS MDS codes. Additionally, the inequivalence between these codes and twisted GRS codes is analyzed. Furthermore, we analyze the relationships among several existing classes of codes used for constructing non-GRS MDS codes, propose explicit constructions, and discuss the lengths of non-GRS MDS codes based on these constructions. Finally, we design two efficient algorithms to address two main problems in GRS code research, i.e., determining whether an unknown code $C$ is a GRS code from its generator matrix $G$, and recovering the key vectors $\\bm\u03b1$ and $\\bm{v}$ such that $C = \\GRS_{n,k}(\\bm\u03b1, \\bm{v})$ if $C$ is indeed a GRS code. A computational complexity comparison of the proposed algorithms ($O(nk+n)$) with that of the Sidelnikov-Shestakov attack (exceeding $O(qk^2n+qk^3)$) shows that our methods offer superior computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u7c7b\u65b0\u7684\u975eGRS MDS\u7801\u6784\u9020\uff0c\u957f\u5ea6\u8fbe\u5230\u7406\u8bba\u4e0a\u754c\uff1b\u7ed9\u51fa\u5229\u7528Cauchy\u77e9\u9635\u7684\u5145\u8981\u6761\u4ef6\u3001\u4e0etwisted GRS\u7801\u7684 inequivalence\u3001\u4e0e\u73b0\u6709\u975eGRS MDS\u7801\u65cf\u7684\u5173\u7cfb\u53ca\u5177\u4f53\u6784\u9020\uff0c\u5e76\u7ed9\u51fa\u4e24\u79cd\u9ad8\u6548\u5224\u5b9a/\u6062\u590d\u53c2\u6570\u7684\u7b97\u6cd5\uff0c\u590d\u6742\u5ea6\u6bd4Sidelnikov-Shestakov\u653b\u51fb\u66f4\u4f18\u3002", "motivation": "\u6269\u5c55\u975eGRS MDS\u7801\u7684\u6784\u9020\u7a7a\u95f4\u4e0e\u8bc6\u522b\u80fd\u529b\uff0c\u63d0\u5347\u53ef\u6784\u9020\u7684\u7801\u957f\u754c\u9650\uff0c\u660e\u786e\u4e0d\u540c\u975eGRS MDS\u7801\u65cf\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u9ad8\u6548\u7684\u53c2\u6570\u6062\u590d\u4e0e\u5224\u5b9a\u7b97\u6cd5\u4ee5\u5bf9\u6297\u6f5c\u5728\u7684\u653b\u51fb\u3002", "method": "\u5229\u7528Cauchy\u77e9\u9635\u7ed3\u6784\u5bfc\u51fa\u5fc5\u8981\u5145\u5206\u6761\u4ef6\u4ee5\u5224\u5b9a\u7801\u662f\u5426\u4e3aMDS\u4e14\u662f\u5426\u975eGRS\uff1b\u5206\u6790\u4e0etwisted GRS\u7801\u7684\u7b49\u4ef7\u6027\u4e0e\u5dee\u5f02\uff1b\u68b3\u7406\u5e76\u6784\u9020\u4e0e\u73b0\u6709\u975eGRS MDS\u7801\u76f8\u5173\u7684\u5173\u7cfb\u7f51\uff0c\u7ed9\u51faExplicit\u6784\u9020\uff1b\u8bbe\u8ba1\u4e24\u79cd\u7b97\u6cd5\u7528\u4e8e\u5224\u65ad\u7ed9\u5b9a\u751f\u6210\u77e9\u9635\u662f\u5426\u5bf9\u5e94GRS\u7801\u4ee5\u53ca\u4ece\u4e2d\u6062\u590d\u03b1\u5411\u91cf\u4e0ev\u5411\u91cf\uff0c\u590d\u6742\u5ea6\u4e3aO(nk+n)\u4e0e\u5bf9\u6bd4\u653b\u51fb\u7684\u590d\u6742\u5ea6\u3002", "result": "\u7ed9\u51fa\u957f\u5ea6\u53ef\u8fbe (q+3)/2\uff08\u5947\u7279\u6027\uff09\u6216 (q+4)/2\uff08\u5076\u7279\u6027\uff09\u7684\u975eGRS MDS\u7801\u7684\u6784\u9020\u548c\u76f8\u5e94\u5145\u8981\u6761\u4ef6\uff1b\u8bc1\u660e\u4e0etwisted GRS\u7801\u4e0d\u7b49\u4ef7\uff1b\u5efa\u7acb\u4e0e\u5176\u4ed6\u975eGRS MDS\u7801\u65cf\u4e4b\u95f4\u7684\u5173\u7cfb\u5e76\u7ed9\u51fa\u5177\u4f53\u6784\u9020\uff1b\u63d0\u51fa\u4e24\u79cd\u9ad8\u6548\u7b97\u6cd5\uff0c\u590d\u6742\u5ea6\u4e3aO(nk+n)\uff0c\u76f8\u8f83Sidelnikov-Shestakov\u653b\u51fb\uff08\u9ad8\u8fbeO(qk^2n+qk^3)\uff09\u66f4\u9ad8\u6548\u3002", "conclusion": "\u672c\u7814\u7a76\u6269\u5927\u4e86\u975eGRS MDS\u7801\u7684\u6784\u9020\u4e0e\u8bc6\u522b\u5de5\u5177\u7bb1\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0e\u7b97\u6cd5\u57fa\u7840\uff0c\u63d0\u5347\u4e86\u5bf9GRS\u7801\u53ca\u5176\u975eGRS\u66ff\u4ee3\u7684\u7406\u89e3\u4e0e\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u4e3a\u540e\u7eed\u5bf9\u6bd4\u4e0e\u653b\u51fb\u7814\u7a76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u4f18\u5316\u8def\u5f84\u3002"}}
{"id": "2512.02298", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.02298", "abs": "https://arxiv.org/abs/2512.02298", "authors": ["Sribalaji C. Anand", "Henrik Sandberg"], "title": "On Frequency-Weighted Extended Balanced Truncation", "comment": "8 pages, conference submission", "summary": "This paper addresses the problem of frequency-weighted extended balanced truncation for discrete and continuous-time linear time-invariant plants. We show that the frequency-weighted discrete-time plant admits block-diagonal solutions to both the Lyapunov inequality and its extended form. A recursive algorithm for extended balanced truncation is proposed, together with corresponding a-priori error bounds. Theoretical results are extended to continuous-time systems and validated through numerical examples.", "AI": {"tldr": "\u63d0\u51fa\u9002\u7528\u4e8e\u79bb\u6563\u4e0e\u8fde\u7eed\u65f6\u95f4\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf\u7684\u9891\u7387\u52a0\u6743\u6269\u5c55\u5e73\u8861\u622a\u65ad\uff0c\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u7684Lyapunov\u4e0d\u7b49\u5f0f\u53ca\u5176\u6269\u5c55\u5f62\u5f0f\u5b58\u5728\u5206\u5757\u5bf9\u89d2\u89e3\uff0c\u7ed9\u51fa\u9012\u5f52\u7b97\u6cd5\u53ca\u5176A priori\u8bef\u5dee\u754c\uff0c\u7406\u8bba\u7ed3\u679c\u63a8\u5e7f\u5230\u8fde\u7eed\u65f6\u95f4\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u4f8b\u9a8c\u8bc1\u3002", "motivation": "\u5728\u9700\u8981\u540c\u65f6\u5173\u6ce8\u7279\u5b9a\u9891\u7387\u5e26\u5185\u6027\u80fd\u7684\u573a\u666f\u4e2d\uff0c\u5bf9\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf\u8fdb\u884c\u9ad8\u6548\u7684\u6a21\u578b\u7b80\u5316\uff0c\u4fdd\u8bc1\u5728\u9891\u7387\u533a\u95f4\u5185\u7684\u4fdd\u771f\u5ea6\uff0c\u540c\u65f6\u517c\u987e\u79bb\u6563\u4e0e\u8fde\u7eed\u65f6\u95f4\u4e24\u7c7b\u7cfb\u7edf\u7684\u53ef\u7528\u6027\u3002", "method": "1) \u8bc1\u660e\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u7684\u9891\u7387\u52a0\u6743\u6269\u5c55\u5e73\u8861\u622a\u65ad\u7684Lyapunov\u4e0d\u7b49\u5f0f\u5177\u6709\u5206\u5757\u5bf9\u89d2\u89e3\uff1b2) \u63d0\u51fa\u7528\u4e8e\u6269\u5c55\u5e73\u8861\u622a\u65ad\u7684\u9012\u5f52\u7b97\u6cd5\uff0c\u5e76\u7ed9\u51faa priori\u8bef\u5dee\u754c\uff1b3) \u5c06\u7406\u8bba\u63a8\u5e7f\u81f3\u8fde\u7eed\u65f6\u95f4\u7cfb\u7edf\uff1b4) \u901a\u8fc7\u6570\u503c\u4f8b\u5b50\u9a8c\u8bc1\u7406\u8bba\u3002", "result": "\u5efa\u7acb\u4e86\u9891\u7387\u52a0\u6743\u6269\u5c55\u5e73\u8861\u622a\u65ad\u7684\u7406\u8bba\u6846\u67b6\uff1a\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u5b58\u5728\u5206\u5757\u5bf9\u89d2\u7684Lyapunov\u89e3\u3001\u9012\u5f52\u7684\u6269\u5c55\u5e73\u8861\u622a\u65ad\u7b97\u6cd5\u53ca\u5176\u8bef\u5dee\u754c\uff1b\u62d3\u5c55\u5230\u8fde\u7eed\u65f6\u95f4\u5e76\u901a\u8fc7\u6570\u503c\u9a8c\u8bc1\u3002", "conclusion": "\u4e3a\u9891\u7387\u52a0\u6743\u4e14\u5e26\u6269\u5c55\u5e73\u8861\u622a\u65ad\u7684\u6a21\u578b\u5316\u7b80\u63d0\u4f9b\u4e86\u4e00\u81f4\u7684\u7406\u8bba\u4e0e\u53ef\u5b9e\u65bd\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u79bb\u6563\u4e0e\u8fde\u7eed\u65f6\u95f4\u7684LTI\u7cfb\u7edf\uff0c\u5e76\u7ed9\u51fa\u660e\u786e\u7684\u8bef\u5dee\u754c\u4e0e\u6570\u503c\u9a8c\u8bc1\u3002"}}
{"id": "2512.02053", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02053", "abs": "https://arxiv.org/abs/2512.02053", "authors": ["M. A. Gameiro"], "title": "Contextual Gating within the Transformer Stack: Synergistic Feature Modulation for Enhanced Lyrical Classification and Calibration", "comment": null, "summary": "This study introduces a significant architectural advancement in feature fusion for lyrical content classification by integrating auxiliary structural features directly into the self-attention mechanism of a pre-trained Transformer. I propose the SFL Transformer, a novel deep learning model that utilizes a Contextual Gating mechanism (an Intermediate SFL) to modulate the sequence of hidden states within the BERT encoder stack, rather than fusing features at the final output layer. This approach modulates the deep, contextualized semantic features (Hseq) using low-dimensional structural cues (Fstruct). The model is applied to a challenging binary classification task derived from UMAP-reduced lyrical embeddings. The SFL Transformer achieved an Accuracy of 0.9910 and a Macro F1 score of 0.9910, significantly improving the state-of-the-art established by the previously published SFL model (Accuracy 0.9894). Crucially, this Contextual Gating strategy maintained exceptional reliability, with a low Expected Calibration Error (ECE = 0.0081) and Log Loss (0.0489). This work validates the hypothesis that injecting auxiliary context mid-stack is the most effective means of synergistically combining structural and semantic information, creating a model with both superior discriminative power and high-fidelity probability estimates.", "AI": {"tldr": "\u5728\u81ea\u6ce8\u610f\u529b\u4e2d\u5f15\u5165\u8f85\u52a9\u7ed3\u6784\u7279\u5f81\u7684SFL Transformer\uff0c\u901a\u8fc7Contextual Gating\u5728BERT\u7f16\u7801\u5668\u6808\u4e2d\u95f4\u5c42\u5b9e\u73b0\u6df1\u5c42\u7279\u5f81\u878d\u5408\uff0c\u663e\u8457\u63d0\u5347\u6b4c\u8bcd\u5206\u7c7b\u7684\u51c6\u786e\u6027\u4e0e\u6982\u7387\u6821\u51c6\u3002", "motivation": "\u89e3\u51b3\u4ec5\u5728\u8f93\u51fa\u5c42\u878d\u5408\u7ed3\u6784\u4fe1\u606f\u5bfc\u81f4\u7684\u8868\u793a\u53d7\u9650\u95ee\u9898\uff0c\u63d0\u51fa\u5728Transformer\u7684\u6df1\u5c42\u4e2d\u95f4\u9636\u6bb5\u8fdb\u884c\u7ed3\u6784\u4e0e\u8bed\u4e49\u4fe1\u606f\u7684\u534f\u540c\u878d\u5408\uff0c\u4ee5\u63d0\u5347\u5224\u522b\u80fd\u529b\u548c\u6982\u7387\u4f30\u8ba1\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u63d0\u51faSFL Transformer\uff0c\u91c7\u7528Contextual Gating\uff08\u4e00\u4e2a\u4e2d\u95f4SFL\uff09\u6765\u8c03\u5236BERT\u7f16\u7801\u5668\u6808\u4e2d\u7684\u9690\u85cf\u72b6\u6001\u5e8f\u5217Hseq\uff0c\u5229\u7528\u4f4e\u7ef4\u7ed3\u6784\u7ebf\u7d22Fstruct\uff1b\u5bf9\u4eceUMAP\u964d\u7ef4\u7684\u6b4c\u8bcd\u5d4c\u5165\u5f97\u5230\u7684\u4e8c\u5206\u7c7b\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728\u4e8c\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fbe\u5230\u51c6\u786e\u73870.9910\u3001Macro F1 0.9910\uff0c\u663e\u8457\u8d85\u8d8a\u524d\u4e00\u4ee3SFL\u6a21\u578b\uff08\u51c6\u786e\u73870.9894\uff09\uff0c\u5e76\u4fdd\u6301\u4f4eECE\uff080.0081\uff09\u548c\u5bf9\u6570\u635f\u59310.0489\u3002\u6570\u636e\u6765\u81ea\u57fa\u4e8eUMAP\u964d\u7ef4\u7684\u6b4c\u8bcd\u5d4c\u5165\u3002", "conclusion": "\u4e2d\u95f4\u9636\u6bb5\u6ce8\u5165\u8f85\u52a9\u4e0a\u4e0b\u6587\u662f\u7ed3\u6784\u4fe1\u606f\u4e0e\u8bed\u4e49\u4fe1\u606f\u7684\u6700\u6709\u6548\u534f\u540c\u878d\u5408\u8def\u5f84\uff0c\u5e26\u6765\u66f4\u5f3a\u7684\u5224\u522b\u80fd\u529b\u4e0e\u9ad8\u4fdd\u771f\u6982\u7387\u4f30\u8ba1\u3002"}}
{"id": "2512.02245", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02245", "abs": "https://arxiv.org/abs/2512.02245", "authors": ["Ashutosh Prajapati", "Prathapasinghe Dharmawansa", "Marco Di Renzo", "Italo Atzeni"], "title": "Wavenumber-Division Multiplexing in Holographic MIMO with NLoS Channels", "comment": "Presented at the Asilomar Conference on Signals, Systems, and Computers 2025", "summary": "Wavenumber-division multiplexing (WDM) was introduced as a counterpart of orthogonal frequency-division multiplexing in the spatial-frequency domain for line-of-sight holographic multiple-input multiple-output (MIMO) systems. In this paper, we extend WDM to holographic MIMO channels with non-line-of-sight (NLoS) propagation. We show that applying WDM to the NLoS channel yields the corresponding angular-domain representation, which we characterize through the power spectral factor and power spectral density. We further obtain a closed-form characterization for the case of isotropic scattering, recovering Jakes' isotropic model. The analysis is complemented by numerical results evaluating the degrees of freedom and ergodic capacity under both isotropic and non-isotropic scattering.", "AI": {"tldr": "\u5c06\u6ce2\u6570\u5206\u590d\u7528\uff08WDM\uff09\u6269\u5c55\u5230\u5e26\u6709NLoS\u4f20\u64ad\u7684\u5168\u606fMIMO\u901a\u9053\uff0c\u7ed9\u51fa\u89d2\u57df\u8868\u793a\u53ca\u5176\u529f\u8c31\u7279\u5f81\uff1b\u5728\u5404\u5411\u540c\u6027\u6563\u5c04\u60c5\u51b5\u4e0b\u7ed9\u51fa\u95ed\u5f0f\u89e3\u5e76\u6062\u590dJakes\u6a21\u578b\uff0c\u4e26\u901a\u8fc7\u6570\u503c\u5206\u6790\u8bc4\u4f30\u81ea\u7531\u5ea6\u4e0e\u904d\u5386\u5bb9\u91cf\u3002", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\u7684NLoS\u4f20\u64ad\u4f7f\u5f97\u7ebf\u6027LOS\u5047\u8bbe\u4e0d\u8db3\uff0c\u9700\u5728\u5168\u606fMIMO\u6846\u67b6\u4e0b\u5efa\u7acbWDM\u7684\u89d2\u57df\u7b49\u6548\u63cf\u8ff0\uff0c\u4ee5\u63ed\u793a\u4fe1\u9053\u7684\u8c31\u7279\u6027\u4e0e\u5bb9\u91cf\u6f5c\u529b\u3002", "method": "\u5c06WDM\u5e94\u7528\u4e8eNLoS\u901a\u9053\uff0c\u63a8\u5bfc\u89d2\u57df\u8868\u793a\u5e76\u5b9a\u4e49\u529f\u8c31\u56e0\u5b50\u548c\u529f\u8c31\u5bc6\u5ea6\uff1b\u5728\u5404\u5411\u540c\u6027\u6563\u5c04\u6761\u4ef6\u4e0b\u7ed9\u51fa\u95ed\u5f0f\u89e3\u5e76\u4e0eJakes\u6a21\u578b\u5bf9\u9f50\uff1b\u901a\u8fc7\u6570\u503c\u4eff\u771f\u8bc4\u4f30\u81ea\u7531\u5ea6\u548c\u904d\u5386\u5bb9\u91cf\uff0c\u6bd4\u8f83\u5404\u5411\u540c\u6027\u4e0e\u975e\u5404\u5411\u540c\u6027\u6563\u5c04\u3002", "result": "\u5f97\u5230NLoS\u4e0b\u7684\u89d2\u57df\u8868\u793a\u53ca\u5176\u529f\u8c31\u7279\u5f81\uff1b\u5728\u5404\u5411\u540c\u6027\u6563\u5c04\u4e0b\u7684\u95ed\u5f0f\u89e3\u6210\u529f\u6062\u590dJakes\u6a21\u578b\uff1b\u5b9e\u73b0\u4e86\u81ea\u7531\u5ea6\u4e0e\u904d\u5386\u5bb9\u91cf\u7684\u6570\u503c\u8bc4\u4f30\uff0c\u63ed\u793a\u6563\u5c04\u7279\u6027\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "WDM\u53ef\u7528\u4e8eNLoS\u5168\u606fMIMO\u7684\u89d2\u57df\u5206\u6790\uff0c\u4e14\u5728\u5404\u5411\u540c\u6027\u6761\u4ef6\u4e0b\u4e0e\u7ecf\u5178\u6a21\u578b\u7b49\u4ef7\uff1b\u8be5\u5206\u6790\u6846\u67b6\u63d0\u4f9b\u5bf9NLoS\u901a\u9053\u8c31\u7279\u6027\u4e0e\u5bb9\u91cf\u7684\u5b9a\u91cf\u6d1e\u5bdf\u3002"}}
{"id": "2512.02332", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02332", "abs": "https://arxiv.org/abs/2512.02332", "authors": ["Yuqing Zhu", "Yuan-Hsun Lo", "Yan Lin", "Yijin Zhang"], "title": "Age of Information for Constrained Scheduling with Imperfect Feedback", "comment": null, "summary": "This paper considers a downlink system where an access point sends the monitored status of multiple sources to multiple users. By jointly accounting for imperfect feedback and constrained transmission rate, which are key limited factors in practical systems, we aim to design scheduling algorithms to optimize the age of information (AoI) over the infinite time horizon. For zero feedback under the generate-at-will traffic, we derive a closed-form lower bound of achievable AoI, which, to the best of our knowledge, reflects the impact of zero feedback for the first time, and propose a policy that achieves this bound in many cases by jointly applying rate splitting and modular arithmetic. For zero feedback under the Bernoulli traffic, we develop a drift-plus-penalty (DPP) policy with a threshold structure based on the theory of Lyapunov optimization and provide a closed-form performance guarantee. Furthermore, we extend the design of this DPP policy to support general imperfect feedback without increasing the online computational complexity. Numerical results verify our theoretical analysis and the AoI advantage of the proposed policies over state-of-the-art policies.", "AI": {"tldr": "\u63d0\u51fa\u5728\u4e0b\u884c\u7cfb\u7edf\u4e2d\u8003\u8651\u4e0d\u5b8c\u7f8e\u53cd\u9988\u4e0e\u4f20\u8f93\u901f\u7387\u53d7\u9650\u7684AoI\u6700\u4f18\u5316\u8c03\u5ea6\uff1a\u5728\u96f6\u53cd\u9988\u4e0b\u7ed9\u51faAoI\u95ed\u5f0f\u4e0b\u754c\u5e76\u8bbe\u8ba1\u53ef\u8fbe\u8be5\u4e0b\u754c\u7684\u7b56\u7565\uff1b\u5728Bernoulli\u6d41\u91cf\u4e0b\u5efa\u7acb\u5e26\u9608\u503c\u7684DPP\u7b56\u7565\u5e76\u7ed9\u51fa\u6027\u80fd\u4fdd\u8bc1\uff1b\u6269\u5c55\u81f3\u4e00\u822c\u4e0d\u5b8c\u7f8e\u53cd\u9988\u4e14\u4fdd\u6301\u76f8\u540c\u5728\u7ebf\u590d\u6742\u5ea6\uff0c\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u7406\u8bba\u4e0eAoI\u4f18\u52bf\u3002", "motivation": "\u73b0\u5b9e\u7cfb\u7edf\u4e2d\u53cd\u9988\u5f80\u5f80\u4e0d\u53ef\u9760\u4e14\u5e26\u5bbd\u6709\u9650\uff0c\u8fd9\u5bf9\u4fe1\u606f\u65b0\u9c9c\u5ea6\uff08AoI\uff09\u4f18\u5316\u5e26\u6765\u6311\u6218\u3002\u7814\u7a76\u5728\u6709\u9650\u53cd\u9988\u4e0e\u901f\u7387\u7ea6\u675f\u4e0b\u7684\u8c03\u5ea6\u7b56\u7565\uff0c\u63d0\u5347AoI\u8868\u73b0\u5e76\u7ed9\u51fa\u7406\u8bba\u4fdd\u8bc1\u3002", "method": "1) \u96f6\u53cd\u9988\u3001generate-at-will\u6d41\u91cf\uff1a\u63a8\u5bfcAoI\u7684\u95ed\u5f0f\u4e0b\u754c\uff0c\u63d0\u51fa\u901a\u8fc7\u901f\u7387\u5206\u5272\u4e0e\u6a21\u7b97\u672f\u76f8\u7ed3\u5408\u7684\u7b56\u7565\u4ee5\u5b9e\u73b0\u4e0b\u754c\uff1b2) \u96f6\u53cd\u9988\u3001Bernoulli\u6d41\u91cf\uff1a\u57fa\u4e8eLyapunov\u4f18\u5316\u7684DPP\u7b56\u7565\uff0c\u5177\u9608\u503c\u7ed3\u6784\u5e76\u7ed9\u51fa\u95ed\u5f0f\u6027\u80fd\u4fdd\u8bc1\uff1b3) \u5c06DPP\u7b56\u7565\u6269\u5c55\u5230\u4e00\u822c\u4e0d\u5b8c\u7f8e\u53cd\u9988\uff0c\u4ecd\u4fdd\u6301\u540c\u7b49\u5728\u7ebf\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5f97\u5230AoI\u4e0b\u754c\uff1b\u8bbe\u8ba1\u7684\u7b56\u7565\u5728\u591a\u79cd\u60c5\u5f62\u63a5\u8fd1\u6216\u8fbe\u5230\u4e0b\u754c\uff1bDPP\u7b56\u7565\u6709\u660e\u786e\u7684\u6027\u80fd\u4fdd\u8bc1\uff1b\u6269\u5c55\u81f3\u4e00\u822c\u4e0d\u5b8c\u7f8e\u53cd\u9988\u4e14\u4e0d\u589e\u52a0\u5728\u7ebf\u590d\u6742\u5ea6\uff1b\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u7406\u8bba\u5206\u6790\u5e76\u663e\u793a\u4f18\u52bf\u3002", "conclusion": "\u7ed9\u51fa\u4e00\u4e2a\u5728\u53cd\u9988\u53d7\u9650\u548c\u5e26\u5bbd\u53d7\u9650\u7684\u73b0\u5b9e\u7cfb\u7edf\u4e2d\u63d0\u5347AoI\u7684\u7efc\u5408\u8c03\u5ea6\u6846\u67b6\uff0c\u517c\u5177\u7406\u8bba\u4fdd\u969c\u4e0e\u53ef\u5b9e\u65bd\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u9a8c\u8bc1\u4e86\u76f8\u5bf9\u4e8e\u73b0\u6709\u7b56\u7565\u7684AoI\u6539\u5584\u3002"}}
{"id": "2512.02367", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.02367", "abs": "https://arxiv.org/abs/2512.02367", "authors": ["Sungjun Seo", "Kooktae Lee"], "title": "On the Convergence of Density-Based Predictive Control for Multi-Agent Non-Uniform Area Coverage", "comment": "Accepted for publication in ASME JDSMC", "summary": "This paper presents Density-based Predictive Control (DPC), a novel multi-agent control strategy for efficient non-uniform area coverage, grounded in optimal transport theory. In large-scale scenarios such as search and rescue or environmental monitoring, traditional uniform coverage fails to account for varying regional priorities. DPC leverages a pre-constructed reference distribution to allocate agents' coverage efforts, spending more time in high-priority or densely sampled regions. We analyze convergence conditions using the Wasserstein distance, derive an analytic optimal control law for unconstrained cases, and propose a numerical method for constrained scenarios. Simulations on first-order dynamics and linearized quadrotor models demonstrate that DPC achieves trajectories closely matching the non-uniform reference distribution, outperforming existing coverage methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bc6\u5ea6\u7684\u9884\u6d4b\u63a7\u5236\uff08DPC\uff09\u7684\u591a\u667a\u80fd\u4f53\u8986\u76d6\u63a7\u5236\u65b9\u6cd5\uff0c\u7ed3\u5408\u6700\u4f18\u4f20\u8f93\u7406\u8bba\u5b9e\u73b0\u5bf9\u975e\u5747\u5300\u53c2\u8003\u5206\u5e03\u7684\u9ad8\u6548\u8986\u76d6\uff1b\u5728Wasserstein\u8ddd\u79bb\u4e0b\u5206\u6790\u6536\u655b\u6027\uff0c\u7ed9\u51fa\u65e0\u7ea6\u675f\u7684\u89e3\u6790\u6700\u4f18\u63a7\u5236\u5f8b\u53ca\u6709\u7ea6\u675f\u573a\u666f\u7684\u6570\u503c\u65b9\u6cd5\uff1b\u4eff\u771f\u8868\u660eDPC\u80fd\u4f7f\u8f68\u8ff9\u63a5\u8fd1\u975e\u5747\u5300\u53c2\u8003\u5206\u5e03\uff0c\u4f18\u4e8e\u73b0\u6709\u8986\u76d6\u65b9\u6cd5\u3002", "motivation": "\u5728\u5927\u89c4\u6a21\u573a\u666f\u4e2d\uff08\u5982\u641c\u6551\u3001\u73af\u5883\u76d1\u6d4b\uff09\uff0c\u5b58\u5728\u533a\u57df\u4f18\u5148\u7ea7\u5dee\u5f02\uff0c\u4f20\u7edf\u7684\u5747\u5300\u8986\u76d6\u65e0\u6cd5\u9ad8\u6548\u5206\u914d\u8d44\u6e90\u3002\u901a\u8fc7\u5229\u7528\u76ee\u6807\u5206\u5e03\uff08\u53c2\u8003\u5206\u5e03\uff09\u5b9e\u73b0\u5bf9\u9ad8\u4f18\u5148\u533a\u57df\u7684\u66f4\u591a\u8986\u76d6\uff0c\u4ece\u800c\u63d0\u5347\u8986\u76d6\u6548\u7387\u4e0e\u6548\u679c\u3002", "method": "\u63d0\u51fa\u5bc6\u5ea6\u57fa\u9884\u6d4b\u63a7\u5236\uff08DPC\uff09\uff0c\u4ee5\u9884\u6784\u5efa\u7684\u53c2\u8003\u5206\u5e03\u4e3a\u76ee\u6807\uff0c\u5206\u914d\u591a\u667a\u80fd\u4f53\u7684\u8986\u76d6\u52aa\u529b\uff1b\u5206\u6790\u57fa\u4e8eWasserstein\u8ddd\u79bb\u7684\u6536\u655b\u6027\uff1b\u5728\u65e0\u7ea6\u675f\u4e0b\u63a8\u5bfc\u89e3\u6790\u6700\u4f18\u63a7\u5236\u5f8b\uff1b\u9488\u5bf9\u6709\u7ea6\u675f\u60c5\u5f62\u63d0\u51fa\u6570\u503c\u6c42\u89e3\u65b9\u6cd5\u3002\u4eff\u771f\u91c7\u7528\u4e00\u9636\u52a8\u529b\u5b66\u548c\u7ebf\u6027\u5316\u56db\u65cb\u7ffc\u6a21\u578b\u3002", "result": "DPC\u7684\u8f68\u8ff9\u80fd\u591f\u8f83\u597d\u5730\u8d34\u5408\u975e\u5747\u5300\u53c2\u8003\u5206\u5e03\uff0c\u8986\u76d6\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1b\u5728\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u7684\u573a\u666f\u4e2d\uff0c\u65b9\u6cd5\u5bf9\u9ad8\u4f18\u5148\u533a\u57df\u7684\u8986\u76d6\u66f4\u5145\u5206\u3002", "conclusion": "DPC\u80fd\u6709\u6548\u5b9e\u73b0\u975e\u5747\u5300\u533a\u57df\u8986\u76d6\uff0c\u4e14\u5728\u6536\u655b\u6027\u5206\u6790\u548c\u65e0\u7ea6\u675f\u89e3\u6790\u89e3\u7684\u57fa\u7840\u4e0a\uff0c\u63d0\u4f9b\u4e86\u9002\u7528\u4e8e\u7ea6\u675f\u60c5\u5f62\u7684\u6570\u503c\u89e3\u6cd5\uff0c\u9002\u5408\u5927\u89c4\u6a21\u641c\u7d22\u4e0e\u76d1\u6d4b\u7b49\u5e94\u7528\uff0c\u5177\u6269\u5c55\u6f5c\u529b\u3002"}}
{"id": "2512.02057", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02057", "abs": "https://arxiv.org/abs/2512.02057", "authors": ["Haoxiang Zhang", "Ruihao Yuan", "Lihui Zhang", "Yushi Luo", "Qiang Zhang", "Pan Ding", "Xiaodong Ren", "Weijie Xing", "Niu Gao", "Jishan Chen", "Chubo Zhang"], "title": "Opening the Black Box: An Explainable, Few-shot AI4E Framework Informed by Physics and Expert Knowledge for Materials Engineering", "comment": null, "summary": "The industrial adoption of Artificial Intelligence for Engineering (AI4E) faces two fundamental bottlenecks: scarce high-quality data and the lack of interpretability in black-box models-particularly critical in safety-sensitive sectors like aerospace. We present an explainable, few-shot AI4E framework that is systematically informed by physics and expert knowledge throughout its architecture. Starting from only 32 experimental samples in an aerial K439B superalloy castings repair welding case, we first augment physically plausible synthetic data through a three-stage protocol: differentiated noise injection calibrated to process variabilities, enforcement of hard physical constraints, and preservation of inter-parameter relationships. We then employ a nested optimization strategy for constitutive model discovery, where symbolic regression explores equation structures while differential evolution optimizes parameters, followed by intensive parameter refinement using hybrid global-local optimization. The resulting interpretable constitutive equation achieves 88% accuracy in predicting hot-cracking tendency. This equation not only provides quantitative predictions but also delivers explicit physical insight, revealing how thermal, geometric, and metallurgical mechanisms couple to drive cracking-thereby advancing engineers' cognitive understanding of the process. Furthermore, the constitutive equation serves as a multi-functional tool for process optimization and high-fidelity virtual data generation, enabling accuracy improvements in other data-driven models. Our approach provides a general blueprint for developing trustworthy AI systems that embed engineering domain knowledge directly into their architecture, enabling reliable adoption in high-stakes industrial applications where data is limited but physical understanding is available.", "AI": {"tldr": "\u4ee5\u7269\u7406\u548c\u4e13\u5bb6\u77e5\u8bc6\u9a71\u52a8\u7684\u5c11\u6837\u672c\u53ef\u89e3\u91caAI4E\u6846\u67b6\uff0c\u9488\u5bf9\u822a\u5929\u5408\u91d1\u88c2\u7eb9\u503e\u5411\u7684\u9884\u6d4b\uff0c\u5229\u752832\u4e2a\u6837\u672c\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u548c\u7b26\u53f7\u56de\u5f52\u53d1\u73b0\u53ef\u89e3\u91ca\u7684\u672c\u6784\u65b9\u7a0b\uff0c\u8fbe\u523088%\u51c6\u786e\u7387\uff0c\u53ef\u7528\u4e8e\u5de5\u827a\u4f18\u5316\u4e0e\u865a\u62df\u6570\u636e\u751f\u6210\u3002", "motivation": "\u5de5\u4e1aAI\u5728\u5de5\u7a0b\u9886\u57df\u7684\u63a8\u5e7f\u53d7\u9650\u4e8e\u6570\u636e\u7a00\u7f3a\u548c\u6a21\u578b\u4e0d\u53ef\u89e3\u91ca\u6027\uff0c\u5c24\u5176\u5728\u5b89\u5168\u654f\u611f\u7684\u9886\u57df\u3002\u9700\u8981\u4e00\u4e2a\u5d4c\u5165\u5de5\u7a0b\u9886\u57df\u77e5\u8bc6\u3001\u53ef\u89e3\u91ca\u4e14\u5bf9\u6570\u636e\u53cb\u597d\u7684\u65b9\u6cd5\u3002", "method": "\u4e09\u9636\u6bb5\u6570\u636e\u589e\u5f3a\uff1a\u4e0d\u540c\u53d8\u91cf\u7684\u566a\u58f0\u6ce8\u5165\u3001\u5f3a\u7269\u7406\u7ea6\u675f\u4e0e\u53d8\u91cf\u5173\u7cfb\u4fdd\u6301\uff1b\u5c42\u7ea7\u4f18\u5316\uff1a\u7b26\u53f7\u56de\u5f52\u63a2\u7d22\u7ed3\u6784\uff0c\u5dee\u5206\u8fdb\u5316\u4f18\u5316\u53c2\u6570\uff0c\u540e\u4ee5\u6df7\u5408\u5168\u5c40\u5c40\u90e8\u4f18\u5316\u7cbe\u7ec6\u5316\u53c2\u6570\uff1b\u901a\u8fc7\u4e00\u4e2a\u5d4c\u5165\u7269\u7406\u77e5\u8bc6\u7684\u591a\u76ee\u6807\u67b6\u6784\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u672c\u6784\u65b9\u7a0b\u3002", "result": "\u5f97\u5230\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u672c\u6784\u65b9\u7a0b\uff0c\u5bf9\u70ed\u88c2\u503e\u5411\u9884\u6d4b\u7684\u51c6\u786e\u7387\u4e3a88%\uff1b\u65b9\u7a0b\u63ed\u793a\u70ed\u3001\u51e0\u4f55\u3001\u51b6\u91d1\u673a\u7406\u8026\u5408\u5bf9\u5f00\u88c2\u7684\u5f71\u54cd\uff0c\u63d0\u4f9b\u5b9a\u91cf\u9884\u6d4b\u4e0e\u7269\u7406\u6d1e\u89c1\uff0c\u540c\u65f6\u53ef\u7528\u4e8e\u5de5\u827a\u4f18\u5316\u548c\u9ad8\u4fdd\u771f\u865a\u62df\u6570\u636e\u751f\u6210\uff0c\u63d0\u5347\u5176\u4ed6\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5728\u6570\u636e\u53d7\u9650\u3001\u4f46\u53ef\u83b7\u53d6\u9886\u57df\u77e5\u8bc6\u7684\u9ad8\u98ce\u9669\u5de5\u4e1a\u5e94\u7528\u4e2d\u843d\u5730\u53ef\u4fe1AI\u63d0\u4f9b\u666e\u9002\u84dd\u672c\uff0c\u63a8\u52a8\u5de5\u7a0b\u77e5\u8bc6\u76f4\u63a5\u5d4c\u5165AI\u67b6\u6784\u4ee5\u5b9e\u73b0\u53ef\u9760\u91c7\u7528\u3002"}}
{"id": "2512.02353", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02353", "abs": "https://arxiv.org/abs/2512.02353", "authors": ["Ruizhe Wang", "Hong Ren", "Cunhua Pan", "Ruisong Weng", "Jiangzhou Wang"], "title": "A Cyclic Shift Embedded Pilot based Channel Estimation for Multi-User MIMO-OTFS systems with fractional delay and Doppler", "comment": null, "summary": "Orthogonal time frequency space (OTFS) modulation has been proposed to meet the demand for reliable communication in high-mobility scenarios for future wireless networks. However, in multi-user OTFS systems, conventional embedded pilot schemes require independent pilot allocation for each user, leading to linearly increasing pilot overhead. To address these issues, in this paper, we investigate the uplink channel estimation and pilot design for multi-user multiple-input multiple-output (MIMO)-OTFS systems. We propose a multi-dimensional decomposition-based channel estimation algorithm. Specifically, the proposed algorithm first estimates the angles of arrivals (AoAs) via subspace decomposition-based method. A spatial projection matrix, constructed from the estimated AOAs, decouples the received signal by propagation path subspace, effectively mitigating inter-path interference. The remaining fractional delay and Doppler can be obtained by a compressed sensing (CS)-based off-grid channel estimation method. Furthermore, to reduce the pilot overhead in multi-user OTFS systems, this paper proposes a novel cyclic shift embedded pilot (CSEP) structure, which can reuse users through cyclic shift-orthogonality of Zadoff-Chu (ZC) sequences. Compared with conventional embedded pilot structures, the CSEP structure can save over 30\\% of pilot overhead. Finally, an imporved channel estimation method based on the CSEP structure is proposed. Simulation results demonstrate that it achieves superior performance in channel estimation. Moreover, the proposed CSEP structure and channel estimation algorithm achieve a favorable balance between computational complexity, estimation accuracy, and bit error rate (BER) performance.", "AI": {"tldr": "\u5728\u591a\u7528\u6237 MIMO-OTFS \u7cfb\u7edf\u4e2d\uff0c\u63d0\u51fa\u57fa\u4e8e\u591a\u7ef4\u5206\u89e3\u7684\u4fe1\u9053\u4f30\u8ba1\u4e0e CSEP \u7ed3\u6784\u7684\u4f4e\u5f00\u9500 Pilot \u65b9\u6848\uff0c\u901a\u8fc7 AoA \u7684\u5b50\u7a7a\u95f4\u4f30\u8ba1\u548c\u7a7a\u95f4\u6295\u5f71\u5b9e\u73b0\u8def\u5f84\u53bb\u5e72\u6270\uff0c\u8f85\u4ee5\u79bb\u6563\u5316\u524d\u6cbf\u7684 CS \u4fe1\u9053\u4f30\u8ba1\uff0c\u4e14\u901a\u8fc7\u5faa\u73af\u79fb\u4f4d\u7684 ZC \u5e8f\u5217\u5b9e\u73b0 Pilot \u590d\u7528\uff0c\u663e\u8457\u964d\u4f4e Pilot \u5f00\u9500\u5e76\u5728 BER/\u8ba1\u7b97\u91cf\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\u3002", "motivation": "OTFS \u5728\u9ad8\u591a\u666e\u52d2/\u9ad8\u79fb\u52a8\u573a\u666f\u4e0b\u7684\u4fe1\u9053\u4f30\u8ba1\u56f0\u96be\uff0c\u4f20\u7edf\u5d4c\u5165\u5f0f Pilot \u9700\u4e3a\u6bcf\u4e2a\u7528\u6237\u5206\u914d\u72ec\u7acb Pilot\uff0c\u5bfc\u81f4 Pilot \u5f00\u9500\u968f\u7528\u6237\u6570\u7ebf\u6027\u589e\u52a0\uff0c\u4e9f\u9700\u964d\u4f4e\u591a\u7528\u6237\u573a\u666f\u7684\u5f00\u9500\u4e0e\u590d\u6742\u5ea6\u3002", "method": "\u63d0\u51fa\u591a\u7ef4\u5206\u89e3\u57fa\u4fe1\u9053\u4f30\u8ba1\uff1a\u5148\u7528\u5b50\u7a7a\u95f4\u65b9\u6cd5\u4f30\u8ba1 AOAs\uff0c\u5e76\u636e\u6b64\u6784\u5efa\u7a7a\u95f4\u6295\u5f71\u77e9\u9635\u5b9e\u73b0\u5bf9\u4f20\u64ad\u8def\u5f84\u5b50\u7a7a\u95f4\u7684\u89e3\u8026\uff0c\u968f\u540e\u5bf9\u5269\u4f59\u7684\u5206\u6570\u65f6\u5ef6\u4e0e\u591a\u666e\u52d2\u8fdb\u884c CS \u7684 off-grid \u4fe1\u9053\u4f30\u8ba1\uff1b\u540c\u65f6\u63d0\u51fa Cyclic Shift Embedded Pilot (CSEP) \u7ed3\u6784\uff0c\u901a\u8fc7 Zadoff-Chu \u5e8f\u5217\u7684\u5faa\u73af\u79fb\u4f4d\u6b63\u4ea4\u6027\u5b9e\u73b0\u591a\u7528\u6237\u7684 Pilot \u590d\u7528\u4ee5\u964d\u4f4e\u5f00\u9500\uff1b\u5e76\u7ed9\u51fa\u57fa\u4e8e CSEP \u7684\u6539\u8fdb\u4fe1\u9053\u4f30\u8ba1\u7b97\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u4fe1\u9053\u4f30\u8ba1\u6027\u80fd\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\uff0cCSEP \u7ed3\u6784\u4e0e\u4f30\u8ba1\u7b97\u6cd5\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u3001\u4f30\u8ba1\u7cbe\u5ea6\u548c BER \u6027\u80fd\u4e4b\u95f4\u8fbe\u5230\u8f83\u597d\u7684\u6298\u8877\uff0cPilot \u5f00\u9500\u81f3\u5c11\u8282\u7701\u7ea6 30%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u591a\u7528\u6237 OTFS \u7cfb\u7edf\u63d0\u4f9b\u4e00\u4e2a\u9ad8\u6548\u3001\u4f4e\u5f00\u9500\u7684\u4fe1\u9053\u4f30\u8ba1\u4e0e Pilot \u8bbe\u8ba1\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u3002"}}
{"id": "2512.02061", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2512.02061", "abs": "https://arxiv.org/abs/2512.02061", "authors": ["Zhenliang Ni", "Xiaowen Ma", "Zhenkai Wu", "Shuai Xiao", "Han Shu", "Xinghao Chen"], "title": "Ada-MoGE: Adaptive Mixture of Gaussian Expert Model for Time Series Forecasting", "comment": null, "summary": "Multivariate time series forecasts are widely used, such as industrial, transportation and financial forecasts. However, the dominant frequencies in time series may shift with the evolving spectral distribution of the data. Traditional Mixture of Experts (MoE) models, which employ a fixed number of experts, struggle to adapt to these changes, resulting in frequency coverage imbalance issue. Specifically, too few experts can lead to the overlooking of critical information, while too many can introduce noise. To this end, we propose Ada-MoGE, an adaptive Gaussian Mixture of Experts model. Ada-MoGE integrates spectral intensity and frequency response to adaptively determine the number of experts, ensuring alignment with the input data's frequency distribution. This approach prevents both information loss due to an insufficient number of experts and noise contamination from an excess of experts. Additionally, to prevent noise introduction from direct band truncation, we employ Gaussian band-pass filtering to smoothly decompose the frequency domain features, further optimizing the feature representation. The experimental results show that our model achieves state-of-the-art performance on six public benchmarks with only 0.2 million parameters.", "AI": {"tldr": "\u63d0\u51fa Ada-MoGE\uff1a\u81ea\u9002\u5e94\u9ad8\u65af\u6df7\u5408\u4e13\u5bb6\u4ee5\u5339\u914d\u8f93\u5165\u6570\u636e\u7684\u9891\u8c31\u5206\u5e03\uff0c\u5e76\u4f7f\u7528\u9ad8\u65af\u5e26\u901a\u6ee4\u6ce2\u5e73\u6ed1\u9891\u57df\u7279\u5f81\uff0c\u4ece\u800c\u5728\u516d\u4e2a\u516c\u5f00\u57fa\u51c6\u4e0a\u5b9e\u73b0 state-of-the-art\uff0c\u4e14\u6a21\u578b\u53c2\u6570\u4ec50.2M\u3002", "motivation": "\u4f20\u7edf MoE \u4f7f\u7528\u56fa\u5b9a\u6570\u91cf\u4e13\u5bb6\uff0c\u96be\u4ee5\u968f\u65f6\u95f4\u5e8f\u5217\u8c31\u5206\u5e03\u7684\u52a8\u6001\u53d8\u5316\u8fdb\u884c\u81ea\u9002\u5e94\uff0c\u5bfc\u81f4\u4fe1\u606f\u88ab\u9057\u6f0f\u6216\u566a\u58f0\u88ab\u5f15\u5165\u3002\u5e0c\u671b\u901a\u8fc7\u81ea\u9002\u5e94\u4e13\u5bb6\u6570\u91cf\u548c\u5e73\u6ed1\u7684\u9891\u57df\u5206\u89e3\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u5c06\u8c31\u5f3a\u5ea6\u4e0e\u9891\u7387\u54cd\u5e94\u7ed3\u5408\uff0c\u7528\u6765\u52a8\u6001\u786e\u5b9a\u4e13\u5bb6\u6570\u91cf\uff1b\u5f15\u5165\u9ad8\u65af\u5e26\u901a\u6ee4\u6ce2\uff0c\u5e73\u6ed1\u5730\u5206\u89e3\u9891\u57df\u7279\u5f81\uff0c\u51cf\u5c11\u76f4\u63a5\u5e26\u622a\u9020\u6210\u7684\u566a\u58f0\u3002", "result": "\u5728\u516d\u4e2a\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u53c2\u6570\u91cf\u7ea6 0.2M\u3002", "conclusion": "\u81ea\u9002\u5e94\u7684\u4e13\u5bb6\u6570\u91cf\u548c\u5149\u6ed1\u7684\u9891\u57df\u7279\u5f81\u5206\u89e3\u63d0\u5347\u4e86\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\uff0c\u8bc1\u660e\u4e86 Ada-MoGE \u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.02398", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02398", "abs": "https://arxiv.org/abs/2512.02398", "authors": ["Zhiyu Zhou", "Xin Zhe Khooi", "Satis Kumar Permal", "Mun Choon Chan"], "title": "ProtO-RU: An O-RAN Split-7.2 Radio Unit using SDRs", "comment": "9 pages, 12 figures", "summary": "We present ProtO-RU, the first open source, software-defined O-RAN Split-7.2 Radio Unit built using SDRs and commodity CPUs. Unlike proprietary hardware-based commercial O-RUs, ProtO-RU is built on the open-source srsRAN software stack, and it is fully programmable. We demonstrate that ProtO-RU integrates with the srsRAN and OpenAirInterface5G CU/DU stacks, supports both TDD and FDD duplexing modes, and interoperates with commercial 5G UEs. Our evaluation shows that ProtO-RU remains stable under sustained load with multiple UEs and delivers throughput comparable to Split-8 and commercial O-RUs. ProtO-RU opens up new opportunities for RU-level innovations and lowers the barrier of entry for end-to-end O-RAN research.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.02301", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.02301", "abs": "https://arxiv.org/abs/2512.02301", "authors": ["Dev Gurung", "Shiva Raj Pokhrel"], "title": "Quantum Vanguard: Server Optimized Privacy Fortified Federated Intelligence for Future Vehicles", "comment": "Under Review", "summary": "This work presents vQFL (vehicular Quantum Federated Learning), a new framework that leverages quantum machine learning techniques to tackle key privacy and security issues in autonomous vehicular networks. Furthermore, we propose a server-side adapted fine-tuning method, ft-VQFL,to achieve enhanced and more resilient performance. By integrating quantum federated learning with differential privacy and quantum key distribution (QKD), our quantum vanguard approach creates a multi-layered defense against both classical and quantum threats while preserving model utility. Extensive experimentation with industry-standard datasets (KITTI, Waymo, and nuScenes) demonstrates that vQFL maintains accuracy comparable to standard QFL while significantly improving privacy guaranties and communication security. Our implementation using various quantum models (VQC, QCNN, and SamplerQNN) reveals minimal performance overhead despite the added security measures. This work establishes a crucial foundation for quantum-resistant autonomous vehicle systems that can operate securely in the post-quantum era while efficiently processing the massive data volumes (20-40TB/day per vehicle) generated by modern autonomous fleets. The modular design of the framework allows for seamless integration with existing vehicular networks, positioning vQFL as an essential component for future intelligent transportation infrastructure.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.02397", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02397", "abs": "https://arxiv.org/abs/2512.02397", "authors": ["Emanuele Bossi", "C. Tyler Diggans", "Abd AlRahman R. AlMomani"], "title": "Boltzmann-Shannon Index: A Geometric-Aware Measure of Clustering Balance", "comment": null, "summary": "We introduce the Boltzmann-Shannon Index (BSI), a normalized measure for clustered continuous data that captures the interaction between frequency-based and geometry-based probability distributions. Building on ideas from geometric coarse-graining and information theory, the BSI quantifies how well a partition reflects both the population of each cluster and its effective geometric extent. We illustrate its behavior on synthetic Gaussian mixtures, the Iris benchmark, and a high-imbalance resource-allocation scenario, showing that the index provides a coherent assessment even when traditional metrics give incomplete or misleading signals. Moreover, in resource-allocation settings, we demonstrate that BSI not only detects severe density-geometry inconsistency with high sensitivity, but also offers a smooth, optimization-ready objective that naturally favors allocations balancing demographic weight with each group's effective spread in the outcome space, while providing a smooth, gradient-friendly regularizer that can be easily embedded in modern policy-making and algorithmic governance optimization frameworks.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u8bc4\u4f30 Boltzmann-Shannon Index (BSI) \u4f5c\u4e3a\u4e00\u4e2a\u7ed3\u5408\u9891\u7387\u5206\u5e03\u4e0e\u51e0\u4f55\u5206\u5e03\u7684\u5f52\u4e00\u5316\u805a\u7c7b\u5ea6\u91cf\uff0c\u5728\u8fde\u7eed\u6570\u636e\u7684\u5206\u533a\u4e2d\u80fd\u53cd\u6620\u7fa4\u96c6\u7684\u4eba\u53e3\u4e0e\u51e0\u4f55\u5c3a\u5ea6\u7684\u4ea4\u4e92\uff0c\u5e76\u5728\u8d44\u6e90\u5206\u914d\u7b49\u573a\u666f\u63d0\u4f9b\u4f18\u5316\u53cb\u597d\u76ee\u6807\u548c\u6b63\u5219\u9879\u3002", "motivation": "\u5e38\u89c4\u805a\u7c7b/\u5206\u533a\u6307\u6807\u5728\u8003\u8651\u6570\u636e\u7684\u51e0\u4f55\u7ed3\u6784\u4e0e\u5206\u5e03\u4fe1\u606f\u65b9\u9762\u5f80\u5f80\u4e92\u76f8\u72ec\u7acb\u6216\u5931\u6548\u3002\u5728\u8fde\u7eed\u6570\u636e\u7684\u805a\u7c7b\u548c\u8d44\u6e90\u5206\u914d\u95ee\u9898\u4e2d\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u540c\u65f6\u8003\u8651\u5bc6\u5ea6\u4e0e\u51e0\u4f55\u6269\u5c55\u7684\u91cf\u5316\u6307\u6807\uff0c\u4ee5\u4fbf\u5728\u51b3\u7b56\u4e2d\u517c\u987e\u4eba\u53e3\u6743\u91cd\u4e0e\u7a7a\u95f4\u5206\u5e03\u3002", "method": "\u5f15\u5165 Boltzmann-Shannon Index\uff0c\u4e0e\u51e0\u4f55\u7c97\u7c92\u5316\u548c\u4fe1\u606f\u7406\u8bba\u7ed3\u5408\uff0c\u5f52\u4e00\u5316\u540e\u5c06\u6bcf\u4e2a\u7c07\u7684\u4eba\u53e3\u4e0e\u5176\u6709\u6548\u51e0\u4f55\u5c3a\u5ea6\u7ed3\u5408\u6210\u4e00\u4e2a\u8054\u5408\u6982\u7387\u5206\u5e03\u5e76\u8ba1\u7b97\u5bf9\u5e94\u7684\u71b5/\u4fe1\u606f\u91cf\uff0c\u5f62\u6210\u5bf9\u5206\u533a\u7684\u8bc4\u4ef7\u3002\u901a\u8fc7\u5bf9\u9ad8\u65af\u6df7\u5408\u3001Iris \u6570\u636e\u96c6\u548c\u9ad8\u4e0d\u5e73\u8861\u8d44\u6e90\u5206\u914d\u573a\u666f\u7684\u5b9e\u9a8c\u6765\u5c55\u793a\u5176\u884c\u4e3a\u548c\u7279\u6027\uff0c\u5e76\u7ed9\u51fa\u5728\u8d44\u6e90\u5206\u914d\u4e2d\u7684\u68af\u5ea6\u53cb\u597d\u76ee\u6807\u4e0e\u6b63\u5219\u9879\u3002", "result": "BSI \u5728\u7ed9\u51fa\u4f20\u7edf\u6307\u6807\u4fe1\u53f7\u4e0d\u8db3\u65f6\u4ecd\u80fd\u63d0\u4f9b\u4e00\u81f4\u4e14\u76f4\u89c2\u7684\u8bc4\u4f30\uff1b\u53ef\u4ee5\u7075\u654f\u68c0\u6d4b\u5bc6\u5ea6-\u51e0\u4f55\u4e0d\u4e00\u81f4\uff1b\u5728\u8d44\u6e90\u5206\u914d\u95ee\u9898\u4e2d\u65e2\u53ef\u4ee5\u4f5c\u4e3a\u4f18\u5316\u76ee\u6807\u3001\u4e5f\u53ef\u4ee5\u4f5c\u4e3a\u5e73\u6ed1\u7684\u6b63\u5219\u9879\uff0c\u6613\u4e8e\u5d4c\u5165\u5230\u7b56\u7565\u5236\u5b9a\u548c\u7b97\u6cd5\u6cbb\u7406\u6846\u67b6\u4e2d\u3002", "conclusion": "BSI \u5c06\u4fe1\u606f\u7406\u8bba\u4e0e\u51e0\u4f55\u76f4\u89c2\u7ed3\u5408\uff0c\u63d0\u4f9b\u4e00\u4e2a\u7a33\u5065\u3001\u53ef\u89e3\u91ca\u7684\u5ea6\u91cf\uff0c\u9002\u7528\u4e8e\u9700\u8981\u540c\u65f6\u8003\u8651\u7fa4\u4f53\u6743\u91cd\u4e0e\u6269\u5c55\u6027\u7684\u805a\u7c7b\u8bc4\u4f30\u4e0e\u6cbb\u7406\u4f18\u5316\u573a\u666f\u3002"}}
{"id": "2512.02452", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.02452", "abs": "https://arxiv.org/abs/2512.02452", "authors": ["Tianyou Xiang", "Cheng Zhao"], "title": "Necessary and Sufficient Conditions for PID Design of MIMO Nonlinear Systems", "comment": null, "summary": "As is well known, classical PID control is ubiquitous in industrial processes, yet a rigorous and explicit design theory for nonlinear uncertain MIMO second-order systems remains underdeveloped. In this paper we consider a class of such systems with both uncertain dynamics and an unknown but strictly positive input gain, where the nonlinear uncertainty is characterized by bounds on the Jacobian with respect to the state variables. We explicitly construct a three-dimensional region for the PID gains that is sufficient to guarantee global stability and asymptotic tracking of constant references for all nonlinearities satisfying these Jacobian bounds. We then derive a corresponding necessary region, thereby revealing the inherent conservatism required to cope with worst-case uncertainties. Moreover, under additional structural assumptions on the nonlinearities, these sufficient and necessary regions coincide, yielding a precise necessary-and-sufficient characterization of all globally stabilizing PID gains. All these regions are given in closed form and depend only on the prescribed Jacobian bounds and the known lower bound of the input gain, in contrast to many qualitative tuning methods in the literature.", "AI": {"tldr": "\u4e3a\u5177\u6709\u672a\u77e5\u8f93\u5165\u589e\u76ca\u548c\u975e\u7ebf\u6027\u4e0d\u786e\u5b9a\u6027\u7684\u591a\u8f93\u5165\u3001\u4e8c\u9636\u7cfb\u7edf\uff0c\u7ed9\u51fa\u5728Jacobian\u8fb9\u754c\u4e0b\u7684\u4e09\u7ef4PID\u589e\u76ca\u533a\u57df\uff0c\u65e2\u5145\u5206\u53c8\u5fc5\u8981\uff0c\u5e76\u5728\u989d\u5916\u7ed3\u6784\u5047\u8bbe\u4e0b\u8fbe\u5230\u5fc5\u8981\u5145\u8db3\u7684\u5b8c\u5907\u6027\uff1b\u533a\u57df\u4e3a\u95ed\u5f0f\uff0c\u4f9d\u8d56Jacobian\u8fb9\u754c\u4e0e\u8f93\u5165\u589e\u76ca\u4e0b\u754c\u3002", "motivation": "\u5f25\u8865\u5bf9\u975e\u7ebf\u6027\u4e0d\u786e\u5b9aMIMO\u4e8c\u9636\u7cfb\u7edf\u7684PID\u8bbe\u8ba1\u7406\u8bba\u4e0d\u8db3\uff0c\u63d0\u4f9b\u663e\u5f0f\u7684\u589e\u76ca\u533a\u95f4\u4ee5\u4fdd\u8bc1\u5168\u5c40\u7a33\u5b9a\u548c\u8ddf\u8e2a\uff0c\u5bf9\u6240\u6709\u6ee1\u8db3Jacobian\u8fb9\u754c\u7684\u4e0d\u786e\u5b9a\u6027\u6210\u7acb\u3002", "method": "\u901a\u8fc7\u5bf9\u7cfb\u7edf\u975e\u7ebf\u6027\u4e0d\u786e\u5b9a\u6027\u5728\u72b6\u6001\u53d8\u91cf\u7684\u96c5\u53ef\u6bd4\u754c\u9650\u8fdb\u884c\u5efa\u6a21\uff0c\u63a8\u5bfc\u51fa\u4e09\u7ef4PID\u589e\u76ca\u7684\u5145\u5206\u533a\uff0c\u8fdb\u4e00\u6b65\u63a8\u5bfc\u5fc5\u8981\u533a\uff1b\u5728\u989d\u5916\u7ed3\u6784\u6027\u5047\u8bbe\u4e0b\uff0c\u5145\u5206\u533a\u4e0e\u5fc5\u8981\u533a\u91cd\u5408\uff0c\u7ed9\u51fa\u5b8c\u5907\u7684\u5fc5\u8981\u5145\u8db3\u8868\u5f81\uff1b\u6240\u6709\u533a\u57df\u5747\u4e3a\u95ed\u5f0f\u8868\u8fbe\uff0c\u4e14\u4ec5\u4f9d\u8d56\u4e8eJacobian\u754c\u548c\u8f93\u5165\u589e\u76ca\u4e0b\u754c\u3002", "result": "\u7ed9\u51fa\u7a33\u5b9a\u6027\u548c\u8ddf\u8e2a\u7684\u95ed\u5f0f\u7684PID\u589e\u76ca\u533a\u57df\uff0c\u5305\u542b\u4e09\u7ef4\u533a\u57df\uff0c\u4e14\u5728\u989d\u5916\u7ed3\u6784\u5047\u8bbe\u4e0b\u8fbe\u5230\u5fc5\u8981\u5145\u8db3\u7684\u4e00\u81f4\u6027\uff1b\u533a\u57df\u4ec5\u4f9d\u8d56\u8fb9\u754c\u91cf\uff0c\u8f83\u4e00\u822c\u8c03\u53c2\u65b9\u6cd5\u66f4\u5177\u53ef\u9a8c\u8bc1\u6027\u3002", "conclusion": "\u63d0\u4f9b\u4e00\u4e2a\u4e25\u683c\u7684\u3001\u663e\u5f0f\u7684PID\u8bbe\u8ba1\u6846\u67b6\uff0c\u7528\u4e8e\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u548c\u672a\u77e5\u8f93\u5165\u589e\u76ca\u7684MIMO\u4e8c\u9636\u7cfb\u7edf\uff0c\u5f25\u5408\u7406\u8bba\u548c\u5b9e\u64cd\u4e4b\u95f4\u7684\u5dee\u8ddd\uff1b\u5728\u5177\u5907\u989d\u5916\u7ed3\u6784\u4fe1\u606f\u65f6\uff0c\u7ed9\u51fa\u5168\u5c40\u7a33\u5b9a\u7684\u5fc5\u8981\u5145\u8db3\u6761\u4ef6\u7684\u7cbe\u786e\u523b\u753b\u3002"}}
{"id": "2512.02070", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02070", "abs": "https://arxiv.org/abs/2512.02070", "authors": ["Li Qianyang", "Zhang Xingjun", "Wang Shaoxun", "Wei Jia"], "title": "DPWMixer: Dual-Path Wavelet Mixer for Long-Term Time Series Forecasting", "comment": null, "summary": "Long-term time series forecasting (LTSF) is a critical task in computational intelligence. While Transformer-based models effectively capture long-range dependencies, they often suffer from quadratic complexity and overfitting due to data sparsity. Conversely, efficient linear models struggle to depict complex non-linear local dynamics. Furthermore, existing multi-scale frameworks typically rely on average pooling, which acts as a non-ideal low-pass filter, leading to spectral aliasing and the irreversible loss of high-frequency transients. In response, this paper proposes DPWMixer, a computationally efficient Dual-Path architecture. The framework is built upon a Lossless Haar Wavelet Pyramid that replaces traditional pooling, utilizing orthogonal decomposition to explicitly disentangle trends and local fluctuations without information loss. To process these components, we design a Dual-Path Trend Mixer that integrates a global linear mapping for macro-trend anchoring and a flexible patch-based MLP-Mixer for micro-dynamic evolution. Finally, An adaptive multi-scale fusion module then integrates predictions from diverse scales, weighted by channel stationarity to optimize synthesis. Extensive experiments on eight public benchmarks demonstrate that our method achieves a consistent improvement over state-of-the-art baselines. The code is available at https://github.com/hit636/DPWMixer.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u9ad8\u6548\u7684\u53cc\u8def\u5f84\u6846\u67b6DPWMixer\uff0c\u7528Lossless Haar\u5c0f\u6ce2\u91d1\u5b57\u5854\u66ff\u4ee3\u6c60\u5316\uff0c\u5206\u79bb\u8d8b\u52bf\u4e0e\u5c40\u90e8\u6ce2\u52a8\uff1b\u901a\u8fc7\u5168\u5c40\u7ebf\u6027\u6620\u5c04\u4e0e\u57fa\u4e8e\u533a\u57df\u7684MLP-Mixer\u5b9e\u73b0\u5b8f\u89c2\u4e0e\u5fae\u89c2\u52a8\u6001\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u591a\u5c3a\u5ea6\u878d\u5408\u5728\u516b\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u83b7\u5f97SOTA\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9762\u4e34\uff1aTransformer\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\u4e0e\u5728\u6570\u636e\u7a00\u758f\u573a\u666f\u4e0b\u6613\u8fc7\u62df\u5408\uff1b\u7ebf\u6027\u6a21\u578b\u96be\u4ee5\u8868\u8fbe\u590d\u6742\u975e\u7ebf\u6027\u5c40\u90e8\u52a8\u6001\uff1b\u591a\u5c3a\u5ea6\u6846\u67b6\u7684\u5e73\u5747\u6c60\u5316\u9020\u6210\u4fe1\u606f\u4e22\u5931\u4e0e\u9891\u8c31\u6df7\u53e0\u3002\u9700\u8981\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u4fdd\u7559\u9ad8\u9891\u4fe1\u606f\u4e0e\u5c40\u90e8\u6ce2\u52a8\u3002", "method": "\u63d0\u51faLossless Haar\u5c0f\u6ce2\u91d1\u5b57\u5854\uff0c\u4ee5\u6b63\u4ea4\u5206\u89e3\u660e\u786e\u5206\u79bb\u8d8b\u52bf\u4e0e\u5c40\u90e8\u6ce2\u52a8\u4e14\u4e0d\u4e22\u5931\u4fe1\u606f\uff1b\u8bbe\u8ba1Dual-Path Trend Mixer\uff0c\u7ed3\u5408\u5168\u5c40\u7ebf\u6027\u6620\u5c04\uff08\u5b8f\u89c2\u8d8b\u52bf\u951a\u5b9a\uff09\u4e0e\u57fa\u4e8e\u5c40\u90e8\u8865\u4e01\u7684MLP-Mixer\uff08\u5fae\u89c2\u52a8\u6001\u6f14\u5316\uff09\uff1b\u63d0\u51fa\u81ea\u9002\u5e94\u591a\u5c3a\u5ea6\u878d\u5408\u6a21\u5757\uff0c\u5bf9\u6765\u81ea\u4e0d\u540c\u5c3a\u5ea6\u7684\u9884\u6d4b\u8fdb\u884c\u901a\u9053\u7a33\u5b9a\u6027\u6743\u91cd\u878d\u5408\u3002", "result": "\u5728\u516b\u4e2a\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cDPWMixer\u5728\u4e0eSOTA\u57fa\u7ebf\u7684\u6bd4\u8f83\u4e2d\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6539\u8fdb\uff0c\u4e14\u5177\u6709\u8f83\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002\u4ee3\u7801\u516c\u5f00\u3002", "conclusion": "DPWMixer\u901a\u8fc7\u65e0\u635f\u5206\u89e3\u548c\u53cc\u8def\u5f84\u8bbe\u8ba1\u5b9e\u73b0\u65e2\u9ad8\u6548\u53c8\u5177\u5f3a\u8868\u8fbe\u529b\u7684\u957f\u65f6\u5e8f\u9884\u6d4b\uff0c\u5b9e\u9a8c\u5145\u5206\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u5c3a\u5ea6\u878d\u5408\u4e2d\u7684\u6709\u6548\u6027\u4e0e\u9c81\u68d2\u6027\u3002"}}
{"id": "2512.02318", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02318", "abs": "https://arxiv.org/abs/2512.02318", "authors": ["Junyu Wang", "Changjia Zhu", "Yuanbo Zhou", "Lingyao Li", "Xu He", "Junjie Xiong"], "title": "COGNITION: From Evaluation to Defense against Multimodal LLM CAPTCHA Solvers", "comment": null, "summary": "This paper studies how multimodal large language models (MLLMs) undermine the security guarantees of visual CAPTCHA. We identify the attack surface where an adversary can cheaply automate CAPTCHA solving using off-the-shelf models. We evaluate 7 leading commercial and open-source MLLMs across 18 real-world CAPTCHA task types, measuring single-shot accuracy, success under limited retries, end-to-end latency, and per-solve cost. We further analyze the impact of task-specific prompt engineering and few-shot demonstrations on solver effectiveness. We reveal that MLLMs can reliably solve recognition-oriented and low-interaction CAPTCHA tasks at human-like cost and latency, whereas tasks requiring fine-grained localization, multi-step spatial reasoning, or cross-frame consistency remain significantly harder for current models. By examining the reasoning traces of such MLLMs, we investigate the underlying mechanisms of why models succeed/fail on specific CAPTCHA puzzles and use these insights to derive defense-oriented guidelines for selecting and strengthening CAPTCHA tasks. We conclude by discussing implications for platform operators deploying CAPTCHA as part of their abuse-mitigation pipeline.Code Availability (https://anonymous.4open.science/r/Captcha-465E/).", "AI": {"tldr": "7\u79cd\u4e3b\u6d41MLLM\u572818\u7c7b\u771f\u5b9e\u4e16\u754c\u9a8c\u8bc1\u7801\u4efb\u52a1\u4e2d\u80fd\u591f\u4ee5\u63a5\u8fd1\u4eba\u7c7b\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u81ea\u52a8\u7834\u89e3\u8bc6\u522b\u5bfc\u5411\u3001\u4f4e\u4ea4\u4e92\u7684\u9a8c\u8bc1\u7801\uff1b\u800c\u5bf9\u9700\u8981\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u3001\u591a\u6b65\u7a7a\u95f4\u63a8\u7406\u6216\u8de8\u5e27\u4e00\u81f4\u6027\u7684\u4efb\u52a1\u5219\u8f83\u96be\u3002\u63d0\u793a\u5de5\u7a0b\u548c\u5c11\u91cf\u793a\u4f8b\u53ef\u63d0\u5347\u6216\u5f71\u54cd\u7834\u89e3\u6548\u679c\uff1b\u8fd9\u5bf9\u9a8c\u8bc1\u7801\u5b89\u5168\u6027\u6784\u6210\u6311\u6218\uff0c\u9700\u4e3a\u5e73\u53f0\u8fd0\u8425\u8005\u63d0\u4f9b\u76f8\u5e94\u7684\u9632\u5fa1\u6027\u6307\u5357\u4e0e\u5f3a\u5316\u4efb\u52a1\u8bbe\u8ba1\u3002", "motivation": "\u7cfb\u7edf\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9CAPTCHA\u4e0a\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u63ed\u793a\u53ef\u88ab\u4f4e\u6210\u672c\u81ea\u52a8\u5316\u653b\u51fb\u5229\u7528\u7684\u653b\u51fb\u9762\uff1b\u901a\u8fc7\u8de8\u6a21\u578b\u3001\u8de8\u4efb\u52a1\u7684\u91cf\u5316\u8bc4\u4f30\u4e0e\u5206\u6790\uff0c\u7406\u89e3\u6a21\u578b\u5728\u4e0d\u540c\u7c7b\u578b\u9a8c\u8bc1\u7801\u4e0a\u7684\u6210\u529f\u4e0e\u5931\u8d25\u539f\u56e0\uff0c\u5e76\u636e\u6b64\u63d0\u51fa\u9632\u5fa1\u6027\u8bbe\u8ba1\u539f\u5219\u4e0e\u4efb\u52a1\u5f3a\u5316\u5efa\u8bae\u3002", "method": "\u5bf97\u79cd\u9886\u5148\u7684\u5546\u4e1a\u548c\u5f00\u6e90MLLM\u8fdb\u884c\u8bc4\u6d4b\uff0c\u8986\u76d618\u79cd\u771f\u5b9e\u4e16\u754c\u7684\u9a8c\u8bc1\u7801\u4efb\u52a1\u7c7b\u578b\uff1b\u91cf\u5316\u5355-shot\u51c6\u786e\u7387\u3001\u6709\u9650\u91cd\u8bd5\u4e0b\u7684\u6210\u529f\u7387\u3001\u7aef\u5230\u7aef\u5ef6\u8fdf\u548c\u6bcf\u6b21\u6c42\u89e3\u6210\u672c\uff1b\u7814\u7a76\u4efb\u52a1\u7279\u5b9a\u63d0\u793a\u5de5\u7a0b\u4e0e\u5c11\u91cf\u793a\u4f8b\u5bf9\u7834\u89e3\u6548\u679c\u7684\u5f71\u54cd\uff1b\u901a\u8fc7\u5bf9\u6a21\u578b\u63a8\u7406\u8f68\u8ff9\u7684\u5206\u6790\uff0c\u63a2\u7a76\u6210\u529f/\u5931\u8d25\u7684\u673a\u5236\uff0c\u5e76\u636e\u6b64\u63d0\u51fa\u9632\u5fa1\u6027\u6307\u5357\uff1b\u5e76\u63d0\u4f9bCode Availability\u94fe\u63a5\u4ee5\u4fbf\u590d\u73b0\u3002", "result": "MLLMs\u80fd\u5728\u8bc6\u522b\u5bfc\u5411\u548c\u4f4e\u4ea4\u4e92\u7684\u9a8c\u8bc1\u7801\u4efb\u52a1\u4e0a\u4ee5\u63a5\u8fd1\u4eba\u7c7b\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u7a33\u5b9a\u7834\u89e3\uff1b\u4f46\u5bf9\u4e8e\u9700\u8981\u7ec6\u7c92\u5ea6\u5b9a\u4f4d\u3001\u8de8\u6b65\u9aa4\u7684\u7a7a\u95f4\u63a8\u7406\u3001\u8de8\u5e27\u4e00\u81f4\u6027\u7684\u4efb\u52a1\uff0c\u5f53\u524d\u6a21\u578b\u4ecd\u663e\u8457\u56f0\u96be\uff1b\u63d0\u793a\u5de5\u7a0b\u4e0e\u5c11\u91cf\u793a\u4f8b\u5bf9\u6548\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff1b\u901a\u8fc7\u5206\u6790\u63a8\u7406\u8f68\u8ff9\u53ef\u89e3\u91ca\u6a21\u578b\u5728\u4e0d\u540c\u9898\u578b\u4e0a\u7684\u6210\u529f/\u5931\u8d25\u539f\u56e0\uff0c\u5e2e\u52a9\u5236\u5b9a\u66f4\u6709\u9488\u5bf9\u6027\u7684\u9a8c\u8bc1\u7801\u8bbe\u8ba1\u4e0e\u9632\u5fa1\u7b56\u7565\u3002", "conclusion": "\u5bf9\u5e73\u53f0\u8fd0\u8425\u8005\u90e8\u7f72\u9a8c\u8bc1\u7801\u4f5c\u4e3a Abuse-Mitigation\u7ba1\u7ebf\u7684\u5f71\u54cd\u6df1\u8fdc\uff0c\u9700\u636e\u6b64\u9009\u53d6\u66f4\u5177\u9c81\u68d2\u6027\u4e14\u5bf9MLLM\u653b\u51fb\u66f4\u5177\u6297\u6027\u7684\u9a8c\u8bc1\u7801\u4efb\u52a1\uff0c\u5e76\u63d0\u51fa\u76f8\u5e94\u7684\u5f3a\u5316\u4e0e\u5bf9\u6297\u7b56\u7565\u4ee5\u63d0\u5347\u9a8c\u8bc1\u7801\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2512.02449", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02449", "abs": "https://arxiv.org/abs/2512.02449", "authors": ["Brendon McBain", "Yi Hong", "Emanuele Viterbo"], "title": "Optimal Handover Strategies in LEO Satellite Networks", "comment": "13 pages, 4 figures. Submitted to IEEE Transactions on Communications", "summary": "Existing theoretical analyses of satellite mega-constellations often rely on restrictive assumptions, such as short serving times, or lack tractability when evaluating realistic handover strategies. Motivated by these limitations, this paper develops a general analytical framework for accurately characterising the ergodic capacity of low Earth orbit (LEO) satellite networks under arbitrary handover strategies. Specifically, we model the transmission link as shadowed-Rician fading and introduce the persistent satellite channel, wherein the channel process is governed by an i.i.d. renewal process under mild assumptions of uncoordinated handover decisions and knowledge of satellite ephemeris and fading parameters. Within this framework, we derive the ergodic capacity (persistent capacity) of the persistent satellite channel using renewal theory and establish its relation to the non-persistent capacity studied in prior work. To address computational challenges, we present closed-form upper and lower bounds on persistent capacity. The optimal handover problem is formulated as a non-linear fractional program, obtaining an explicit decision rule via a variant of Dinkelbach's algorithm. We further demonstrate that a simpler handover strategy maximising serving capacity closely approximates the optimal strategy, providing practical insights for designing high-throughput LEO satellite communication systems.", "AI": {"tldr": "A general analytical framework for ergodic capacity of LEO satellite networks under arbitrary handover strategies, introducing a persistent channel via an i.i.d. renewal process, with closed-form bounds and a practical handover rule close to optimal.", "motivation": "Limitations of existing analyses rely on restrictive assumptions (e.g., short serving times) and lack tractable handover evaluation for realistic LEO networks; a general framework is needed for accurate capacity characterization under uncoordinated handovers with known satellite ephemeris/fading.", "method": "Model the link with shadowed-Rician fading; define the persistent satellite channel governed by an i.i.d. renewal process; apply renewal theory to derive persistent capacity and relate it to non-persistent capacity; derive bounds; formulate a nonlinear fractional program for handover optimization; solve via a variant of Dinkelbach's algorithm; show that a simpler serving-capacity-maximizing strategy closely tracks the optimum.", "result": "Derivation of closed-form upper and lower bounds on persistent capacity; an explicit handover decision rule from the fractional programming; validation that a simpler serving-capacity-maximizing strategy closely approximates the optimal policy.", "conclusion": "The framework enables accurate, tractable analysis of ergodic capacity under arbitrary handovers in LEO constellations, offering practical rules and bounds to guide the design of high-throughput satellite systems."}}
{"id": "2512.02073", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02073", "abs": "https://arxiv.org/abs/2512.02073", "authors": ["Qirui Ji", "Bin Qin", "Yifan Jin", "Yunze Zhao", "Chuxiong Sun", "Changwen Zheng", "Jianwen Cao", "Jiangmeng Li"], "title": "HTG-GCL: Leveraging Hierarchical Topological Granularity from Cellular Complexes for Graph Contrastive Learning", "comment": null, "summary": "Graph contrastive learning (GCL) aims to learn discriminative semantic invariance by contrasting different views of the same graph that share critical topological patterns. However, existing GCL approaches with structural augmentations often struggle to identify task-relevant topological structures, let alone adapt to the varying coarse-to-fine topological granularities required across different downstream tasks. To remedy this issue, we introduce Hierarchical Topological Granularity Graph Contrastive Learning (HTG-GCL), a novel framework that leverages transformations of the same graph to generate multi-scale ring-based cellular complexes, embodying the concept of topological granularity, thereby generating diverse topological views. Recognizing that a certain granularity may contain misleading semantics, we propose a multi-granularity decoupled contrast and apply a granularity-specific weighting mechanism based on uncertainty estimation. Comprehensive experiments on various benchmarks demonstrate the effectiveness of HTG-GCL, highlighting its superior performance in capturing meaningful graph representations through hierarchical topological information.", "AI": {"tldr": "HTG-GCL \u6784\u5efa\u57fa\u4e8e\u591a\u5c3a\u5ea6\u7684\u73af\u72b6\u7ec6\u80de\u590d\u5408\u7269\uff0c\u4ee5\u6355\u83b7\u56fe\u7ed3\u6784\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u7684\u5c42\u6b21\u62d3\u6251\u4fe1\u606f\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u7c92\u5ea6\u6743\u91cd\u673a\u5236\u5b9e\u73b0\u7c92\u5ea6\u81ea\u9002\u5e94\u7684\u5bf9\u6bd4\uff0c\u63d0\u5347\u56fe\u8868\u5f81\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7ed3\u6784\u589e\u5f3a\u7684\u56fe\u5bf9\u6bd4\u5b66\u4e60\u5728\u8bc6\u522b\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u62d3\u6251\u7ed3\u6784\u65b9\u9762\u5e38\u5e38\u53d7\u9650\uff0c\u96be\u4ee5\u9002\u5e94\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u6240\u9700\u7684\u7c97\u5230\u7ec6\u7684\u62d3\u6251\u7c92\u5ea6\u53d8\u5316\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u4ea7\u751f\u591a\u5c3a\u5ea6\u62d3\u6251\u89c6\u56fe\u5e76\u5bf9\u7c92\u5ea6\u8fdb\u884c\u52a0\u6743\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa HTG-GCL\uff0c\u901a\u8fc7\u5bf9\u540c\u4e00\u56fe\u7684\u8f6c\u6362\u751f\u6210\u591a\u5c3a\u5ea6\u7684\u73af\u72b6\u7ec6\u80de\u590d\u5408\u7269\uff0c\u4f53\u73b0\u62d3\u6251\u7c92\u5ea6\u7684\u6982\u5ff5\uff0c\u8fdb\u800c\u4ea7\u751f\u591a\u6837\u5316\u7684\u62d3\u6251\u89c6\u56fe\uff1b\u5f15\u5165\u591a\u7c92\u5ea6\u89e3\u8026\u5bf9\u6bd4\uff0c\u4ee5\u53ca\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u7c92\u5ea6\u7279\u5b9a\u52a0\u6743\u673a\u5236\uff0c\u4ee5\u6291\u5236\u6f5c\u5728\u7684\u8bef\u5bfc\u6027\u7c92\u5ea6\u3002", "result": "\u5728\u591a\u9879\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u7cfb\u7edf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u6355\u83b7\u5c42\u6b21\u62d3\u6251\u4fe1\u606f\uff0c\u63d0\u5347\u56fe\u8868\u793a\u7684\u8d28\u91cf\u4e0e\u4efb\u52a1\u6027\u80fd\uff0c\u4f18\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u7684\u5e38\u89c4\u7ed3\u6784\u589e\u5f3a\u65b9\u6cd5\u3002", "conclusion": "HTG-GCL \u6210\u529f\u5229\u7528\u5206\u5c42\u62d3\u6251\u4fe1\u606f\u6765\u63d0\u5347\u56fe\u8868\u5f81\u80fd\u529b\uff1b\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7684\u7c92\u5ea6\u52a0\u6743\u63d0\u9ad8\u4e86\u5bf9\u6709\u7528\u7c92\u5ea6\u7684\u5173\u6ce8\uff0c\u663e\u793a\u51fa\u826f\u597d\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6f5c\u529b\u3002"}}
{"id": "2512.02455", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02455", "abs": "https://arxiv.org/abs/2512.02455", "authors": ["Pietro Chiavassa", "Stefano Scanzio", "Gianluca Cena"], "title": "Wi-Fi Rate Adaptation for Moving Equipment in Industrial Environments", "comment": "preprint accepted, 4 pages, 2025", "summary": "Wi-Fi is currently considered one of the most promising solutions for interconnecting mobile equipment (e.g., autonomous mobile robots and active exoskeletons) in industrial environments. However, relability requirements imposed by the industrial context, such as ensuring bounded transmission latency, are a major challenge for over-the-air communication. One of the aspects of Wi-Fi technology that greatly affects the probability of a packet reaching its destination is the selection of the appropriate transmission rate. Rate adaptation algorithms are in charge of this operation, but their design and implementation are not regulated by the IEEE 802.11 standard. One of the most popular solutions, available as open source, is Minstrel, which is the default choice for the Linux Kernel. In this paper, Minstrel performance is evaluated for both static and mobility scenarios. Our analysis focuses on metrics of interest for industrial contexts, i.e., latency and packet loss ratio, and serves as a preliminary evaluation for the future development of enhanced rate adaptation algorithms based on centralized digital twins.", "AI": {"tldr": "\u672c\u6587\u5bf9 Minstrel \u53d1\u9001\u901f\u7387\u81ea\u9002\u5e94\u5728\u9759\u6001\u4e0e\u79fb\u52a8\u573a\u666f\u4e0b\u7684\u6027\u80fd\u8fdb\u884c\u8bc4\u4f30\uff0c\u805a\u7126\u5de5\u4e1a\u573a\u666f\u4e2d\u7684\u65f6\u5ef6\u548c\u4e22\u5305\u7387\uff0c\u4f5c\u4e3a\u57fa\u4e8e\u96c6\u4e2d\u5f0f\u6570\u5b57\u5b6a\u751f\u7684\u6539\u8fdb\u901f\u7387\u81ea\u9002\u5e94\u7684\u521d\u6b65\u57fa\u7ebf\u3002", "motivation": "\u5de5\u4e1a\u73af\u5883\u5bf9\u4f20\u8f93\u65f6\u5ef6\u6709\u4e25\u683c\u7684\u8fb9\u754c\u8981\u6c42\uff0c\u4e14 802.11 \u7684\u901f\u7387\u81ea\u9002\u5e94\u8bbe\u8ba1\u5e76\u672a\u7edf\u4e00\u6807\u51c6\uff0cMinstrel \u4f5c\u4e3a Linux \u7684\u9ed8\u8ba4\u5b9e\u73b0\uff0c\u5176\u5728\u9759\u6001\u4e0e\u79fb\u52a8\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u5c1a\u5f85\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u56e0\u6b64\u9700\u8981\u5efa\u7acb\u57fa\u7ebf\u4ee5\u6307\u5bfc\u672a\u6765\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684\u96c6\u4e2d\u5316\u4f18\u5316\u3002", "method": "\u5728 Linux \u5185\u6838\u4e0b\u5bf9 Minstrel \u8fdb\u884c\u5b9e\u9a8c\u6027\u8bc4\u4f30\uff0c\u8bbe\u8ba1\u9759\u6001\u4e0e\u79fb\u52a8\u573a\u666f\uff0c\u91c7\u96c6\u65f6\u5ef6\u3001\u5305\u4e22\u5931\u7387\u7b49\u6307\u6807\uff1b\u901a\u8fc7\u4e0d\u540c\u8ddd\u79bb/\u79fb\u52a8\u901f\u5ea6\u7b49\u6761\u4ef6\uff0c\u5bf9\u6bd4\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u901f\u7387\u9009\u62e9\u4e0e\u4f20\u8f93\u6027\u80fd\uff0c\u4f5c\u4e3a\u521d\u6b65\u57fa\u7ebf\u3002", "result": "\u7ed3\u679c\u8868\u660e\u79fb\u52a8\u573a\u666f\u4e0b\u7684\u65f6\u5ef6\u589e\u5927\u3001\u4e22\u5305\u7387\u4e0a\u5347\uff0c\u9759\u6001\u573a\u666f\u4e0b\u6027\u80fd\u76f8\u5bf9\u7a33\u5b9a\u5e76\u4e14\u66f4\u4f4e\u7684\u65f6\u5ef6\u4e0e\u4e22\u5305\uff1b\u901f\u7387\u81ea\u9002\u5e94\u5728\u9ad8\u79fb\u52a8\u6027\u4e0e\u4fe1\u9053\u53d8\u5316\u5267\u70c8\u65f6\u6ce2\u52a8\u660e\u663e\uff0c\u63d0\u793a\u4ec5\u51ed\u672c\u5730\u5206\u6563\u63a7\u5236\u7684\u901f\u7387\u81ea\u9002\u5e94\u96be\u4ee5\u6ee1\u8db3\u4e25\u683c\u5de5\u4e1a\u5b9e\u65f6\u6027\u8981\u6c42\u3002", "conclusion": "\u63d0\u4f9b\u5bf9 Minstrel \u7684\u57fa\u7ebf\u8bc4\u4f30\uff0c\u652f\u6301\u4ee5\u96c6\u4e2d\u5f0f\u6570\u5b57\u5b6a\u751f\u4e3a\u57fa\u7840\u7684\u6539\u8fdb\u65b9\u5411\uff0c\u672a\u6765\u5de5\u4f5c\u5c06\u63a2\u7d22DT\u9a71\u52a8\u7684\u96c6\u4e2d\u5316\u901f\u7387\u534f\u540c\u3001\u5b9e\u65f6\u53cd\u9988\u4e0e\u591a\u667a\u80fd\u4f53\u534f\u540c\u7b49\u4ee5\u63d0\u5347\u53ef\u9884\u6d4b\u6027\u4e0e\u9c81\u68d2\u6027\u3002"}}
{"id": "2512.02579", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.02579", "abs": "https://arxiv.org/abs/2512.02579", "authors": ["Jesus-Pablo Toledo-Zucco", "Fr\u00e9d\u00e9ric Gouaisbaut", "Gaetan Chapput"], "title": "Reduced-order Smith predictor for state feedback control with guaranteed stability", "comment": null, "summary": "This article deals with the implementation of the Smith Predictor for state feedback control in state space representation. The desired control law, obtained using partial differential equations and backstepping control, contains an integral term that has to be approximated for implementation. In this article, we propose a new way to implement this control law using a dynamic controller. The control law is composed of a state feedback term and a dynamic term that approaches the integral term that has to be estimated for implementation. Using a Lyapunov functional, we provide sufficient conditions, in terms of a linear matrix inequality, to guarantee that the closed-loop system is stable when the proposed control law is applied. We use three examples, taken from the literature, to show the benefits of the proposed approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5c06Smith Predictor\u7528\u4e8e\u72b6\u6001\u53cd\u9988\u63a7\u5236\u7684\u5b9e\u73b0\u65b9\u6cd5\uff0c\u91c7\u7528\u52a8\u6001\u63a7\u5236\u5668\u8fd1\u4f3c\u9700\u8981\u79ef\u5206\u9879\u7684\u63a7\u5236\u5f8b\uff0c\u901a\u8fc7Lyapunov\u4e0eLMIs\u7ed9\u51fa\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u5e76\u5728\u4e09\u4e2a\u5178\u578b\u793a\u4f8b\u4e2d\u9a8c\u8bc1\u4f18\u52bf\u3002", "motivation": "\u5c06\u901a\u8fc7\u504f\u5fae\u5206\u65b9\u7a0b\u548c\u53cd\u6b65\u63a7\u5236\u5f97\u5230\u4e14\u5305\u542b\u9700\u8981\u79bb\u6563\u5b9e\u73b0\u7684\u79ef\u5206\u9879\u7684\u63a7\u5236\u5f8b\uff0c\u8f6c\u5316\u4e3a\u53ef\u5b9e\u73b0\u7684\u52a8\u6001\u63a7\u5236\u5668\uff0c\u540c\u65f6\u4fdd\u6301\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u4e0e\u6027\u80fd\u3002", "method": "\u5c06\u63a7\u5236\u5f8b\u5206\u89e3\u4e3a\u72b6\u6001\u53cd\u9988\u9879\u548c\u4e00\u4e2a\u52a8\u6001\u9879\uff0c\u540e\u8005\u6e10\u8fdb\u903c\u8fd1\u5f85\u4f30\u7684\u79ef\u5206\u9879\uff1b\u6784\u5efa\u4e00\u4e2aLyapunov\u6cdb\u51fd\uff0c\u5e76\u5c06\u7a33\u5b9a\u6027\u6761\u4ef6\u8f6c\u5316\u4e3aLMIs\uff0c\u7ed9\u51fa\u5145\u8981\u6761\u4ef6\uff1b\u901a\u8fc7\u4e09\u7ec4\u6587\u732e\u4e2d\u7684\u793a\u4f8b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u7ed9\u51fa\u95ed\u73af\u7a33\u5b9a\u6027\u7684\u5145\u8981\u6761\u4ef6\uff08\u4ee5LMIs\u5f62\u5f0f\uff09\uff0c\u5e76\u901a\u8fc7\u4e09\u4f8b\u793a\u4f8b\u663e\u793a\u6240\u63d0\u65b9\u6cd5\u5728\u5b9e\u73b0\u6027\u4e0e\u6027\u80fd\u65b9\u9762\u7684\u4f18\u70b9\u3002", "conclusion": "\u6240\u63d0\u52a8\u6001\u5b9e\u73b0\u7684Smith Predictor\u63a7\u5236\u7b56\u7565\u4e3aPDE-Backstepping\u63a8\u5bfc\u7684\u63a7\u5236\u5f8b\u63d0\u4f9b\u4e00\u4e2a\u53ef\u5b9e\u73b0\u4e14\u7a33\u5b9a\u7684\u8bbe\u8ba1\u6846\u67b6\uff0c\u4e14\u5728\u4e09\u79cd\u5178\u578b\u793a\u4f8b\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u5177\u6709\u63a8\u5e7f\u6f5c\u529b\uff0c\u4f46\u9700\u5728\u4e0d\u540c\u7cfb\u7edf\u53c2\u6570\u4e0b\u8fdb\u4e00\u6b65\u8bc4\u4f30\u3002"}}
{"id": "2512.02399", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.02399", "abs": "https://arxiv.org/abs/2512.02399", "authors": ["Xiaoqi Li", "Zongwei Li", "Wenkai Li", "Zeng Zhang", "Lei Xie"], "title": "AtomGraph: Tackling Atomicity Violation in Smart Contracts using Multimodal GCNs", "comment": null, "summary": "Smart contracts are a core component of blockchain technology and are widely deployed across various scenarios. However, atomicity violations have become a potential security risk. Existing analysis tools often lack the precision required to detect these issues effectively. To address this challenge, we introduce AtomGraph, an automated framework designed for detecting atomicity violations. This framework leverages Graph Convolutional Networks (GCN) to identify atomicity violations through multimodal feature learning and fusion. Specifically, driven by a collaborative learning mechanism, the model simultaneously learns from two heterogeneous modalities: extracting structural topological features from the contract's Control Flow Graph (CFG) and uncovering deep semantics from its opcode sequence. We designed an adaptive weighted fusion mechanism to dynamically adjust the weights of features from each modality to achieve optimal feature fusion. Finally, GCN detects graph-level atomicity violation on the contract. Comprehensive experimental evaluations demonstrate that AtomGraph achieves 96.88% accuracy and 96.97% F1 score, outperforming existing tools. Furthermore, compared to the concatenation fusion model, AtomGraph improves the F1 score by 6.4%, proving its potential in smart contract security detection.", "AI": {"tldr": "AtomGraph is an automated framework using Graph Convolutional Networks to detect atomicity violations in smart contracts by combining CFG structural features and opcode semantics via adaptive fusion, achieving high accuracy and F1.", "motivation": "Atomicity violations in smart contracts pose security risks; existing tools lack precision; adopt multimodal learning to improve detection.", "method": "Graph Convolutional Networks with two modalities: CFG structural topological features and opcode sequence semantics; collaborative learning; adaptive weighted fusion; graph-level detection.", "result": "Achieves 96.88% accuracy and 96.97% F1; outperforms existing tools; fusion via AtomGraph improves F1 by 6.4% over concatenation.", "conclusion": "AtomGraph demonstrates strong efficacy for smart contract security detection, showing potential for improving atomicity-violation detection through multimodal graph learning."}}
{"id": "2512.02468", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02468", "abs": "https://arxiv.org/abs/2512.02468", "authors": ["Ioannis Krikidis", "Valentin Gilbert"], "title": "Quantum Optimization in Wireless Communication Systems: Principles and Applications", "comment": "IEEE Communications Magazine, 2026", "summary": "Quantum optimization is poised to play a transformative role in the design of next-generation wireless communication systems by addressing key computational and technological challenges. This paper provides an overview of the principles of adiabatic quantum computing, the foundation of quantum optimization, and explores its two primary computational models: quantum annealing and the gate-based quantum approximate optimization algorithm. By highlighting their core features, performance benefits, limitations, and distinctions, we position these methods as promising tools for advancing wireless communication system design. As a case study, we examine the design of passive reconfigurable intelligent surface beamforming with binary phase-shift resolution, supported by experimental results obtained from real-world quantum hardware.", "AI": {"tldr": "\u672c\u6587\u6982\u8ff0\u91cf\u5b50\u4f18\u5316\u5728\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u6846\u67b6\uff0c\u6bd4\u8f83\u91cf\u5b50\u9000\u706b\u4e0e\u95e8\u57faQAOA\u7684\u7279\u6027\u3001\u4f18\u70b9\u4e0e\u5c40\u9650\uff0c\u5e76\u4ee5\u4e8c\u8fdb\u5f0f\u76f8\u4f4d\u63a7\u5236\u7684\u88ab\u52a8RIS\u6ce2\u675f\u6210\u5f62\u4e3a\u6848\u4f8b\uff0c\u7ed9\u51fa\u6765\u81ea\u91cf\u5b50\u786c\u4ef6\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002", "motivation": "\u89e3\u51b3\u65e0\u7ebf\u901a\u4fe1\u8bbe\u8ba1\u4e2d\u7684\u9ad8\u7ef4\u975e\u7ebf\u6027\u4f18\u5316\u548c\u8ba1\u7b97\u590d\u6742\u6027\u95ee\u9898\uff0c\u63a2\u7d22\u91cf\u5b50\u4f18\u5316\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\u7684\u6f5c\u529b\u4e0e\u8fb9\u754c\u3002", "method": "\u7cfb\u7edf\u7efc\u8ff0\u4e24\u5927\u91cf\u5b50\u4f18\u5316\u6a21\u578b\uff1a\u91cf\u5b50\u9000\u706b\u4e0e\u95e8\u57faQAOA\uff0c\u6bd4\u8f83\u5176\u6838\u5fc3\u7279\u5f81\u3001\u6027\u80fd\u3001\u5c40\u9650\u53ca\u5dee\u5f02\uff1b\u5728\u88ab\u52a8RIS\u6ce2\u675f\u6210\u5f62\u7684\u4e8c\u8fdb\u76f8\u4f4d\u5206\u8fa8\u7387\u6848\u4f8b\u4e2d\u7ed3\u5408\u771f\u5b9e\u91cf\u5b50\u786c\u4ef6\u5b9e\u9a8c\u6570\u636e\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7ed9\u51fa\u4e24\u79cd\u91cf\u5b50\u4f18\u5316\u6a21\u578b\u7684\u5bf9\u6bd4\u5206\u6790\uff0c\u5e76\u5728RIS\u6ce2\u675f\u6210\u5f62\u6848\u4f8b\u4e2d\u5c55\u793a\u5b9e\u9a8c\u53ef\u884c\u6027\u4e0e\u6f5c\u5728\u6027\u80fd\u4f18\u52bf\uff0c\u540c\u65f6\u6307\u51fa\u5b9e\u73b0\u4e0e\u566a\u58f0\u9c81\u68d2\u6027\u7b49\u6311\u6218\u3002", "conclusion": "\u91cf\u5b50\u4f18\u5316\u5728\u65e0\u7ebf\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u5177\u6709\u6f5c\u5728\u663e\u8457\u7684\u5f71\u54cd\u529b\uff0c\u4f46\u9700\u5728\u786c\u4ef6\u5b9e\u73b0\u3001\u7b97\u6cd5\u9002\u914d\u53ca\u7cfb\u7edf\u7ea7\u96c6\u6210\u65b9\u9762\u8fdb\u4e00\u6b65\u653b\u5173\uff0c\u4ee5\u4fc3\u8fdb\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2512.02662", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.02662", "abs": "https://arxiv.org/abs/2512.02662", "authors": ["Gerardo Medrano", "Santiago C\u00f3breces"], "title": "Modal Analysis of Core Inertial Dynamics: Re-evaluating Grid-Forming Control Design Principles", "comment": null, "summary": "This paper employs modal analysis to study the core inertial dynamics of governor-controlled synchronous generators (GC-SG), droop-based grid-forming (GFM) converters, and their most fundamental interactions. The results indicate that even in the simplest cases, the prevailing industry paradigm of emulating legacy GC-SG behaviour in GFM converters (high inertia to slow down the system and large droop to increase damping) could be a suboptimal policy. It is shown that GC-SGs exhibit a fundamental trade-off: adequate damping of the turbine-governor mode requires large droop constants, inevitably increasing steady-state frequency deviation and dependence on secondary regulation. In contrast, droop-based GFM converters invert this relationship: decreasing the droop constant simultaneously reduces steady-state frequency deviations and increases damping, while allowing virtual inertia to be freely chosen. When two GC-SGs are coupled, the poorly damped electromechanical swing mode emerges. Results show that replacing one GC-SG with a GFM converter of equivalent droop and inertia already significantly improves damping of both swing and turbine-governor modes. Counter-intuitively, further and remarkable damping gains are achieved by substantially lowering the GFM virtual inertia constant. These findings suggest that current industry trends may be constraining the potential benefits of Inverter Based Resources (IBRs). Optimal stability and performance are instead obtained with low droop and low virtual inertia, yielding tightly bounded frequency variations and strongly-damped electromechanical modes. The results indicate a need to re-evaluate GFM control design principles and emerging grid-code requirements.", "AI": {"tldr": "\u901a\u8fc7\u6a21\u6001\u5206\u6790\u63ed\u793a GC-SG \u4e0e\u57fa\u4e8e Droop \u7684 GFM \u9006\u53d8\u5668\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u6311\u6218\u201c\u9ad8\u60ef\u6027/\u9ad8\u963b\u5c3c\u201d \u7684\u4f20\u7edf\u505a\u6cd5\uff0c\u63d0\u51fa\u4f4e droop \u4e0e\u4f4e\u865a\u62df\u60ef\u6027\u7684\u7ec4\u5408\u53ef\u5b9e\u73b0\u66f4\u5f3a\u963b\u5c3c\u548c\u66f4\u5c0f\u9891\u7387\u6ce2\u52a8\u3002", "motivation": "\u7406\u89e3\u53d1\u7535\u673a\u7ec4\u8c03\u901f\u5668\u2013\u6c7d\u8f6e\u673a\u52a8\u529b\u5b66\u4e0e droop \u578b GFM \u9006\u53d8\u5668\u7684\u57fa\u672c\u8026\u5408\u4e0e\u6743\u8861\uff0c\u4ee5\u8bc4\u4f30\u5728\u542b\u5927\u91cf IBR \u7684\u73b0\u4ee3\u7535\u7f51\u4e2d\u5bf9\u7a33\u5b9a\u6027\u8bbe\u8ba1\u7684\u6700\u4f18\u7b56\u7565\u3002", "method": "\u5bf9 GC-SG\uff08\u5305\u542b\u6c7d\u8f6e\u673a-\u8c03\u901f\u5668\u6a21\u578b\uff09\u3001\u57fa\u4e8e Droop \u7684 GFM \u9006\u53d8\u5668\u53ca\u5176\u8026\u5408\u8fdb\u884c\u6a21\u6001\u5206\u6790\uff0c\u8003\u5bdf\u6446\u52a8\u6a21\u5f0f\u3001\u6c7d\u8f6e\u673a\u2013\u8c03\u901f\u5668\u6a21\u5f0f\u53ca\u5176\u8026\u5408\u6548\u5e94\u3002", "result": "\u6838\u5fc3\u53d1\u73b0\u5305\u62ec\uff1a1\uff09\u4ee5\u4eff\u771f GC-SG \u884c\u4e3a\u7684\u9ad8\u60ef\u6027/\u9ad8\u963b\u5c3c\u7b56\u7565\u5728\u7b80\u5355\u573a\u666f\u4e0b\u53ef\u80fd\u4e0d\u662f\u6700\u4f18\uff1b2\uff09GC-SG \u7684\u963b\u5c3c\u9700\u8981\u8f83\u5927 droop\uff0c\u7136\u800c\u8fd9\u4f1a\u589e\u5927\u5168\u7a33\u6001\u9891\u504f\u5e76\u4f9d\u8d56\u4e8c\u6b21\u8c03\u8282\uff1b3\uff09GFM \u9006\u53d8\u5668\u4e2d\uff0c\u964d\u4f4e droop \u53ef\u540c\u65f6\u964d\u4f4e\u7a33\u6001\u9891\u504f\u5e76\u589e\u5f3a\u963b\u5c3c\uff0c\u4e14\u865a\u62df\u60ef\u6027\u53ef\u81ea\u7531\u8bbe\u5b9a\uff1b4\uff09\u5f53\u4e24\u53f0 GC-SG \u8026\u5408\u65f6\uff0c\u4f1a\u51fa\u73b0\u963b\u5c3c\u8f83\u5dee\u7684\u673a\u7535\u6446\u632f\u6a21\u5f0f\uff1b5\uff09\u7528 GFM \u66ff\u6362\u5176\u4e2d\u4e4b\u4e00\uff08\u4fdd\u6301\u7b49\u6548\u7684 droop \u548c\u60ef\u6027\uff09\u5373\u53ef\u663e\u8457\u6539\u5584\u6446\u632f\u4e0e\u6c7d\u8f6e\u673a\u2013\u8c03\u901f\u5668\u6a21\u5f0f\u7684\u963b\u5c3c\uff1b6\uff09\u8fdb\u4e00\u6b65\u663e\u8457\u964d\u4f4e GFM \u865a\u62df\u60ef\u6027\u53ef\u83b7\u5f97\u989d\u5916\u963b\u5c3c\u589e\u76ca\uff1b7\uff09\u7efc\u5408\u800c\u8a00\uff0c\u5f53\u524d\u884c\u4e1a\u8d8b\u52bf\u53ef\u80fd\u538b\u7f29 IBR \u7684\u6f5c\u5728\u6536\u76ca\uff0c\u6700\u4f73\u7a33\u5b9a\u6027\u5e94\u901a\u8fc7\u4f4e droop \u4e0e\u4f4e\u865a\u62df\u60ef\u6027\u5b9e\u73b0\uff0c\u9700\u91cd\u65b0\u8bc4\u4f30 GFM \u63a7\u5236\u8bbe\u8ba1\u4e0e\u7f51\u683c\u4ee3\u7801\u8981\u6c42\u3002", "conclusion": "\u9700\u8981\u91cd\u65b0\u8bc4\u4f30 GFM \u63a7\u5236\u8bbe\u8ba1\u539f\u5219\u53ca\u7f51\u683c\u89c4\u7ea6\uff0c\u4e3b\u5f20\u4f4e droop \u4e0e\u4f4e\u865a\u62df\u60ef\u6027\u4ee5\u5b9e\u73b0\u66f4\u7d27\u51d1\u7684\u9891\u7387\u6ce2\u52a8\u8fb9\u754c\u548c\u66f4\u5f3a\u7684\u673a\u7535\u963b\u5c3c\uff0c\u4ece\u800c\u5145\u5206\u91ca\u653e IBR \u7684\u7a33\u5b9a\u6027\u6f5c\u529b\u3002"}}
{"id": "2512.02130", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02130", "abs": "https://arxiv.org/abs/2512.02130", "authors": ["Ahmet Sami Korkmaz", "Selim Coskunuzer", "Md Joshem Uddin"], "title": "Cross-View Topology-Aware Graph Representation Learning", "comment": null, "summary": "Graph classification has gained significant attention due to its applications in chemistry, social networks, and bioinformatics. While Graph Neural Networks (GNNs) effectively capture local structural patterns, they often overlook global topological features that are critical for robust representation learning. In this work, we propose GraphTCL, a dual-view contrastive learning framework that integrates structural embeddings from GNNs with topological embeddings derived from persistent homology. By aligning these complementary views through a cross-view contrastive loss, our method enhances representation quality and improves classification performance. Extensive experiments on benchmark datasets, including TU and OGB molecular graphs, demonstrate that GraphTCL consistently outperforms state-of-the-art baselines. This study highlights the importance of topology-aware contrastive learning for advancing graph representation methods.", "AI": {"tldr": "\u63d0\u51faGraphTCL\uff1a\u4e00\u4e2a\u53cc\u89c6\u89d2\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u57fa\u4e8eGNN\u7684\u7ed3\u6784\u5d4c\u5165\u4e0e\u7531\u6301\u4e45\u6027\u540c\u8c03\u5f97\u5230\u7684\u62d3\u6251\u5d4c\u5165\u8fdb\u884c\u5bf9\u9f50\uff0c\u901a\u8fc7\u8de8\u89c6\u89d2\u5bf9\u6bd4\u635f\u5931\u63d0\u5347\u56fe\u8868\u793a\u5e76\u5728TU\u548cOGB\u5206\u5b50\u56fe\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4f18\u5f02\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "GNNs\u64c5\u957f\u6355\u6349\u5c40\u90e8\u7ed3\u6784\u6a21\u5f0f\uff0c\u4f46\u5f80\u5f80\u5ffd\u7565\u5168\u5c40\u62d3\u6251\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u5bf9\u7a33\u5065\u8868\u793a\u5b66\u4e60\u81f3\u5173\u91cd\u8981\u3002\u5c06\u7ed3\u6784\u4fe1\u606f\u4e0e\u62d3\u6251\u4fe1\u606f\u7ed3\u5408\u5e76\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u8fdb\u884c\u5bf9\u9f50\uff0c\u80fd\u591f\u83b7\u5f97\u66f4\u5177\u9c81\u68d2\u6027\u548c\u533a\u5206\u6027\u7684\u56fe\u8868\u793a\u3002", "method": "\u63d0\u51faGraphTCL\u7684\u53cc\u89c6\u89d2\u6846\u67b6\uff1a1) \u4f7f\u7528GNN\u63d0\u53d6\u56fe\u7684\u7ed3\u6784\u5d4c\u5165\uff1b2) \u901a\u8fc7\u6301\u4e45\u6027\u540c\u8c03\u63d0\u53d6\u62d3\u6251\u5d4c\u5165\uff1b3) \u901a\u8fc7\u8de8\u89c6\u89d2\u5bf9\u6bd4\u635f\u5931\u8fdb\u884c\u5bf9\u9f50\uff0c\u4fc3\u8fdb\u4e24\u4e2a\u89c6\u89d2\u7684\u4e00\u81f4\u6027\uff0c\u4ece\u800c\u63d0\u5347\u56fe\u5206\u7c7b\u6027\u80fd\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\uff08TU\u6570\u636e\u96c6\u548cOGB\u5206\u5b50\u56fe\uff09\u4e0a\uff0cGraphTCL\u7684\u6027\u80fd\u7a33\u5b9a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u62d3\u6251\u611f\u77e5\u5bf9\u6bd4\u5b66\u4e60\u5728\u56fe\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5c06\u62d3\u6251\u7279\u5f81\u7eb3\u5165\u5bf9\u6bd4\u5b66\u4e60\u5e76\u5b9e\u73b0\u8de8\u89c6\u89d2\u5bf9\u9f50\uff0c\u53ef\u4ee5\u63d0\u5347\u56fe\u8868\u793a\u7684\u8d28\u91cf\u4e0e\u9c81\u68d2\u6027\uff0cGraphTCL\u9a8c\u8bc1\u4e86\u62d3\u6251\u611f\u77e5\u5bf9\u6bd4\u5b66\u4e60\u5728\u56fe\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2512.02573", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02573", "abs": "https://arxiv.org/abs/2512.02573", "authors": ["Juan Vidal Alegr\u00eda", "Ashkan Sheikhi", "Ove Edfors"], "title": "Zero-Forcing MU-MIMO Precoding under Power Amplifier Non-Linearities", "comment": "5 pages, 1 figure (2 subfigures). This work has been presented at the Asilomar Conference on Signals, Systems, and Computers. Copyright information may be affected upon publication at the IEEE proceedings", "summary": "In multi-user multiple-input multiple-output (MU-MIMO) systems, the non-linear behavior of the power amplifiers (PAs) may cause degradation of the linear precoding schemes dealing with interference between user equipments (UEs), e.g., the zero-forcing (ZF) precoder. One way to minimize this effect is to use digital-pre-distortion (DPD) modules to linearize the PAs. However, using perfect DPD modules is costly and it may incur significant power consumption. As an alternative, we consider the problem of characterizing non-linearity-aware ZF (NLA-ZF) precoding schemes, hereby defined as linear precoders that achieve perfect interference cancellation in the presence of PA non-linearity by exploiting knowledge of this non-linear response. We provide initial iterative solutions that allow achieving NLA-ZF (up to adjustable tolerance) in a two-UE downlink MU-MIMO scenario where the base station (BS) has an even number of antennas, and each antenna is connected to a PA exhibiting third-order memory-less non-linear behavior. The proposed approach allows for performance gains in scenarios with significant residual interference.", "AI": {"tldr": "\u63d0\u51fa\u975e\u7ebf\u6027\u611f\u77e5\u7684 ZF \u9884\u7f16\u7801\uff08NLA-ZF\uff09\uff0c\u5728\u4e24\u7528\u6237\u3001BS \u5177\u5076\u6570\u5929\u7ebf\u4e14\u6bcf\u6839\u5929\u7ebf\u8fde\u63a5\u4e00\u4e2a\u4e09\u9636\u8bb0\u5fc6\u65e0\u5173\u975e\u7ebf\u6027 PA \u7684 MU-MIMO \u7cfb\u7edf\u4e2d\uff0c\u901a\u8fc7\u521d\u59cb\u8fed\u4ee3\u89e3\u5b9e\u73b0\u5bf9\u5e72\u6270\u7684\u8fd1\u4e4e\u96f6\u62b5\u6d88\uff0c\u5141\u8bb8\u4e00\u5b9a\u7684\u5bb9\u5fcd\u8bef\u5dee\u3002", "motivation": "\u529f\u653e\u975e\u7ebf\u6027\u4f1a\u7834\u574f\u7ebf\u6027\u9884\u7f16\u7801\u7684\u5e72\u6270\u6291\u5236\uff1b\u867d\u7136\u53ef\u4ee5\u901a\u8fc7\u6570\u5b57\u524d\u7f6e\u5931\u771f\uff08DPD\uff09\u7ebf\u6027\u5316\uff0c\u4f46\u6210\u672c\u548c\u529f\u8017\u8f83\u9ad8\u3002\u4e3a\u964d\u4f4e\u6210\u672c\u540c\u65f6\u5b9e\u73b0\u5bf9\u975e\u7ebf\u6027\u5e72\u6270\u7684\u62b5\u6d88\uff0c\u7814\u7a76\u5728\u5df2\u77e5\u975e\u7ebf\u6027\u54cd\u5e94\u7684\u524d\u63d0\u4e0b\u7684\u975e\u7ebf\u6027\u611f\u77e5\u7ebf\u6027\u9884\u7f16\u7801\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4e24\u7528\u6237\u573a\u666f\u3001\u5076\u6570\u5929\u7ebf\u3001\u8bb0\u5fc6\u65e0\u5173\u4e09\u9636\u975e\u7ebf\u6027\u529f\u653e\u7684\u521d\u59cb\u8fed\u4ee3\u89e3\uff0c\u8bbe\u8ba1\u975e\u7ebf\u6027\u611f\u77e5\u7684 ZF \u9884\u7f16\u7801\uff08NLA-ZF\uff09\uff0c\u4ee5\u5728\u975e\u7ebf\u6027\u5b58\u5728\u4e0b\u5b9e\u73b0\u8fd1\u4f3c\u5b8c\u7f8e\u5e72\u6270\u53d6\u6d88\uff0c\u5e76\u7ed9\u51fa\u6536\u655b\u6027\u548c\u5bb9\u5fcd\u5ea6\u65b9\u9762\u7684\u8bbe\u5b9a\u3002", "result": "\u5728\u5b58\u5728\u663e\u8457\u6b8b\u7559\u5e72\u6270\u7684\u573a\u666f\u4e2d\uff0cNLA-ZF \u80fd\u5e26\u6765\u6027\u80fd\u63d0\u5347\uff0c\u4f53\u73b0\u5bf9\u975e\u7ebf\u6027\u5f71\u54cd\u7684\u6709\u6548\u62b5\u6d88\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u5bf9\u529f\u653e\u975e\u7ebf\u6027\u54cd\u5e94\u7684\u77e5\u8bc6\uff0c\u53ef\u4ee5\u5728\u964d\u4f4e\u5bf9 DPD \u4f9d\u8d56\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u5b9e\u7528\u7684\u5e72\u6270\u62b5\u6d88\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u4e24\u7528\u6237\u3001\u5076\u6570\u5929\u7ebf\u3001\u4e09\u9636\u8bb0\u5fc6\u65e0\u5173\u975e\u7ebf\u6027\u7684\u573a\u666f\u3002"}}
{"id": "2512.02679", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.02679", "abs": "https://arxiv.org/abs/2512.02679", "authors": ["Hsien-Ching Chung"], "title": "Off-grid solar energy storage system with lithium iron phosphate (LFP) batteries in high mountains: a case report of Tianchi Lodge in Taiwan", "comment": "6 pages, 3 figures, 1 table", "summary": "Mountain huts are buildings located at high altitude, providing shelter and a place for hikers. Energy supply on mountain huts remains an open issue. Using renewable energies could be an appropriate solution. Tianchi Lodge, a famous mountain hut in Taiwan, has operated an off-grid solar energy storage system with lithium iron phosphate (LFP) batteries since 2020. In this case report, the energy architecture, detailed descriptions, and historical status of the system are provided.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5bf9\u53f0\u6e7e\u5929\u6c60\u5c71\u5e84\u7684\u79bb\u7f51\u592a\u9633\u80fd\u50a8\u80fd\u7cfb\u7edf\u8fdb\u884c\u6848\u4f8b\u5206\u6790\uff0c\u63ed\u793a\u5176\u80fd\u6e90\u67b6\u6784\u3001\u8fd0\u884c\u5386\u53f2\u53ca\u53ef\u6301\u7eed\u6027\u8bc4\u4f30\u3002", "motivation": "\u89e3\u51b3\u9ad8\u6d77\u62d4\u5c71\u820d\u80fd\u6e90\u4f9b\u7ed9\u95ee\u9898\uff0c\u63a2\u8ba8\u5728\u504f\u8fdc\u5730\u533a\u5b9e\u65bd\u53ef\u518d\u751f\u80fd\u6e90\u7684\u53ef\u884c\u6027\u4e0e\u6311\u6218\uff1b\u4ee5\u5929\u6c60\u5c71\u5e84\u4e3a\u5b9e\u8bc1", "method": "\u57fa\u4e8e\u7cfb\u7edf\u67b6\u6784\u63cf\u8ff0\u3001\u5173\u952e\u8bbe\u5907\uff08\u5149\u4f0f\u9635\u5217\u3001\u9502\u94c1\u78f7\u9178\u76d0\u50a8\u80fd\u7535\u6c60\u3001\u9006\u53d8/\u63a7\u5236\u7cfb\u7edf\uff09\u3001\u5bb9\u91cf\u3001\u63a7\u5236\u7b56\u7565\u3001\u8fd0\u7ef4\u8bb0\u5f55\u7b49\uff0c\u68b3\u7406\u81ea2020\u5e74\u6295\u5165\u8fd0\u884c\u4ee5\u6765\u7684\u5386\u53f2\u72b6\u6001\u4e0e\u6027\u80fd\u6570\u636e\u3002", "result": "\u81ea2020\u5e74\u6295\u5165\u8fd0\u884c\uff0c\u7cfb\u7edf\u5b9e\u73b0\u79bb\u7f51\u4f9b\u7535\uff0c\u964d\u4f4e\u5bf9\u5316\u77f3\u71c3\u6599\u4f9d\u8d56\uff1bLFP\u7535\u6c60\u7ec4\u5c55\u73b0\u826f\u597d\u5faa\u73af\u5bff\u547d\u4e0e\u5b89\u5168\u6027\uff1b\u63d0\u4f9b\u5bf9\u80fd\u91cf\u81ea\u7ed9\u80fd\u529b\u3001\u78b3\u51cf\u6392\u548c\u8fd0\u7ef4\u6210\u672c\u7684\u521d\u6b65\u8bc4\u4f30\uff1b\u62a5\u544a\u4e2d\u8fd8\u8ba8\u8bba\u4e86\u7cfb\u7edf\u7a33\u5b9a\u6027\u3001\u7ef4\u62a4\u9700\u6c42\u53ca\u6f5c\u5728\u6539\u8fdb\u65b9\u5411\u3002", "conclusion": "\u5728\u9ad8\u6d77\u62d4\u73af\u5883\u4e0b\uff0c\u57fa\u4e8eLFP\u7684\u79bb\u7f51\u592a\u9633\u80fd\u50a8\u80fd\u7cfb\u7edf\u5728\u5c71\u820d\u5e94\u7528\u4e2d\u5177\u5907\u53ef\u884c\u6027\u4e0e\u53ef\u6301\u7eed\u6027\uff0c\u4f46\u9700\u8003\u8651\u6c14\u5019\u3001\u7ef4\u62a4\u3001\u5907\u4ef6\u4f9b\u5e94\u7b49\u6311\u6218\uff1b\u672c\u6848\u4f8b\u6709\u52a9\u4e8e\u4e3a\u5c71\u533a hut \u4f9b\u80fd\u8bbe\u8ba1\u63d0\u4f9b\u7ecf\u9a8c\u6559\u8bad\u3002"}}
{"id": "2512.02418", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02418", "abs": "https://arxiv.org/abs/2512.02418", "authors": ["Yuexin Xiang", "Yuchen Lei", "SM Mahir Shazeed Rish", "Yuanzhe Zhang", "Qin Wang", "Tsz Hon Yuen", "Jiangshan Yu"], "title": "Leveraging Large Language Models to Bridge On-chain and Off-chain Transparency in Stablecoins", "comment": null, "summary": "Stablecoins such as USDT and USDC aspire to peg stability by coupling issuance controls with reserve attestations. In practice, however, the transparency is split across two worlds: verifiable on-chain traces and off-chain disclosures locked in unstructured text that are unconnected. We introduce a large language model (LLM)-based automated framework that bridges these two dimensions by aligning on-chain issuance data with off-chain disclosure statements. First, we propose an integrative framework using LLMs to capture and analyze on- and off-chain data through document parsing and semantic alignment, extracting key financial indicators from issuer attestations and mapping them to corresponding on-chain metrics. Second, we integrate multi-chain issuance records and disclosure documents within a model context protocol (MCP) framework that standardizes LLMs access to both quantitative market data and qualitative disclosure narratives. This framework enables unified retrieval and contextual alignment across heterogeneous stablecoin information sources and facilitates consistent analysis. Third, we demonstrate the capability of LLMs to operate across heterogeneous data modalities in blockchain analytics, quantifying discrepancies between reported and observed circulation and examining their implications for cross-chain transparency and price dynamics. Our findings reveal systematic gaps between disclosed and verifiable data, showing that LLM-assisted analysis enhances cross-modal transparency and supports automated, data-driven auditing in decentralized finance (DeFi).", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u5c06\u7a33\u5b9a\u5e01\u7684\u94fe\u4e0a\u53d1\u884c\u6570\u636e\u4e0e\u79bb\u7ebf\u62ab\u9732\u6587\u672c\u5bf9\u9f50\uff0c\u4ee5\u63d0\u5347\u8de8\u6a21\u6001\u900f\u660e\u5ea6\u548c\u81ea\u52a8\u5ba1\u8ba1\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7a33\u5b9a\u5e01\u900f\u660e\u6027\u5206\u6563\u5728\u94fe\u4e0a\u53ef\u6838\u9a8c\u6570\u636e\u548c\u79bb\u7ebf\u6587\u672c\u62ab\u9732\u4e4b\u95f4\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u8de8\u6a21\u6001\u5bf9\u9f50\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u6587\u6863\u89e3\u6790\u548c\u8bed\u4e49\u5bf9\u9f50\u63d0\u53d6\u53d1\u884c\u65b9\u7684\u5173\u952e\u91d1\u878d\u6307\u6807\u5e76\u6620\u5c04\u5230\u94fe\u4e0a\u6307\u6807\uff1b\u5728\u591a\u94fe\u53d1\u884c\u8bb0\u5f55\u548c\u62ab\u9732\u6587\u6863\u4e0a\u6784\u5efa\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\uff0c\u5b9e\u73b0\u5bf9\u91cf\u5316\u5e02\u573a\u6570\u636e\u548c\u5b9a\u6027\u62ab\u9732\u6587\u672c\u7684\u7edf\u4e00\u8bbf\u95ee\u4e0e\u68c0\u7d22\uff1b\u6f14\u793a\u8de8\u6a21\u6001\u6570\u636e\u5206\u6790\u80fd\u529b\uff0c\u91cf\u5316\u62ab\u9732\u4e0e\u89c2\u6d4b\u6d41\u901a\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u5e76\u8bc4\u4f30\u5bf9\u4ef7\u683c\u52a8\u6001\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u62ab\u9732\u6570\u636e\u4e0e\u53ef\u9a8c\u8bc1\u6570\u636e\u4e4b\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u8ddd\uff0cLLM\u8f85\u52a9\u5206\u6790\u63d0\u5347\u8de8\u6a21\u6001\u900f\u660e\u5ea6\uff0c\u652f\u6301\u81ea\u52a8\u5316\u3001\u6570\u636e\u9a71\u52a8\u7684\u5ba1\u8ba1\u5728DeFi\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c55\u793a\u4e86LLM\u5728\u591a\u6a21\u6001\u3001\u8de8\u94fe\u7a33\u5b9a\u5e01\u4fe1\u606f\u6574\u5408\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u8de8\u6e90\u900f\u660e\u5ea6\u4e0e\u5408\u89c4\u6027\u5206\u6790\u63d0\u4f9b\u65b0\u8def\u5f84\u3002"}}
{"id": "2512.02747", "categories": ["cs.IT", "math.CO", "math.NT"], "pdf": "https://arxiv.org/pdf/2512.02747", "abs": "https://arxiv.org/abs/2512.02747", "authors": ["Jiaxu Hu", "Kenneth J. Roche"], "title": "Digit-Indexed q-ary SEC-DED Codes with Near-Hamming Overhead", "comment": "13 pages, 1 figure, 3 tables. Interactive demo: https://sltracer.github.io/ECC_Paper_Website_Demo/index_SEC_TED_en.html", "summary": "We present a simple $q$-ary family of single-error-correcting, double-error-detecting (SEC--DED) linear codes whose parity checks are tied directly to the base-$p$ ($q=p$ prime) digits of the coordinate index. For blocklength $n=p^r$ the construction uses only $r+1$ parity checks -- \\emph{near-Hamming} overhead -- and admits an index-based decoder that runs in a single pass with constant-time location and magnitude recovery from the syndromes. Based on the prototype, we develop two extensions: Code A1, which removes specific redundant trits to achieve higher information rate and support variable-length encoding; and Code A2, which incorporates two group-sum checks together with a 3-wise XOR linear independence condition on index subsets, yielding a ternary distance-4 (SEC--TED) variant. Furthermore, we demonstrate how the framework generalizes via $n$-wise XOR linearly independent sets to construct codes with distance $d = n + 1$, notably recovering the ternary Golay code for $n = 5$ -- showing both structural generality and a serendipitous link to optimal classical codes.\n  Our contribution is not optimality but \\emph{implementational simplicity} and an \\emph{array-friendly} structure: the checks are digitwise and global sums, the mapping from syndromes to error location is explicit, and the SEC--TED upgrade is modular. We position the scheme against classical $q$-ary Hamming and SPC/product-code baselines and provide a small comparison of parity overhead, decoding work, and two-error behavior.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u57fa\u6570\u5c55\u5f00\u7684q\u8fdb\u5236\u5355\u9519\u8bef\u66f4\u6b63\u53cc\u9519\u68c0\uff08SEC-DED\uff09\u7ebf\u6027\u7801\uff0c\u91c7\u7528\u5750\u6807\u7d22\u5f15\u7684\u57fa\u5e95\u4f4d\u6570\u6765\u6784\u9020\u68c0\u9a8c\u77e9\u9635\uff0c\u5728\u957f\u5ea6n=p^r\u65f6\u4ec5\u9700\u8981r+1\u4e2a\u6821\u9a8c\u4f4d\uff0c\u4e14\u89e3\u7801\u4ee5\u5e38\u91cf\u65f6\u95f4\u3001\u5355\u904d\u901a\u8fc7 syndromes \u76f4\u63a5\u5b9a\u4f4d\u548c\u5e45\u5ea6\u6062\u590d\uff0c\u7ed3\u6784\u63a5\u8fd1\u54c8\u660e\u7801\u4f46\u5f00\u9500\u66f4\u5c0f\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u5728\u5b9e\u73b0\u5c42\u9762\u8ffd\u6c42\u7b80\u5355\u6027\u3001\u9635\u5217\u53cb\u597d\u6027\u548c\u53ef\u5b9e\u73b0\u7684\u89e3\u7801\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u89c2\u7684\u9519\u8bef\u7ea0\u6b63\u80fd\u529b\u3002\u901a\u8fc7\u5c06\u68c0\u9a8c\u6761\u4ef6\u7ed1\u5b9a\u5230\u5750\u6807\u7d22\u5f15\u7684\u57fa\u6570\u5b57\uff0c\u83b7\u53d6\u900f\u660e\u3001\u660e\u786e\u7684 syndrome \u5230\u9519\u8bef\u5b9a\u4f4d\u7684\u6620\u5c04\uff0c\u4ece\u800c\u5b9e\u73b0\u9010\u4f4d\u3001\u4f4e\u5f00\u9500\u7684\u89e3\u7801\u6d41\u7a0b\u3002", "method": "\u6838\u5fc3\u6784\u9020\u5229\u7528\u5750\u6807\u7d22\u5f15\u7684 base-p \u6570\u5b57\u6765\u5b9a\u4e49 q \u8fdb\u5236\u7684\u6821\u9a8c\u5173\u7cfb\uff0c\u5728 n=p^r \u65f6\u4ec5\u9700 r+1 \u4e2a\u7ebf\u6027\u68c0\u9a8c\uff0c\u5f62\u6210\u8fd1\u54c8\u660e(overhead near-Hamming)\u7684\u7ed3\u6784\u3002\u63d0\u51fa Code A1 \u53bb\u9664\u5197\u4f59 trit \u63d0\u9ad8\u4fe1\u606f\u901f\u7387\u5e76\u652f\u6301\u53d8\u957f\u7f16\u7801\uff1bCode A2 \u5f15\u5165\u4e24\u7ec4\u7ec4\u548c\u68c0\u9a8c\uff0c\u4ee5\u53ca\u5bf9\u7d22\u5f15\u5b50\u96c6\u7684\u4e09\u5143 XOR \u7ebf\u6027\u72ec\u7acb\u6027\u6761\u4ef6\uff0c\u4ee5\u83b7\u5f97\u4e09\u503c\u8ddd\u79bb\u4e3a 4 \u7684 SEC-TED \u53d8\u4f53\u3002\u8fdb\u4e00\u6b65\u63a8\u5e7f\u81f3 n-wise XOR \u7684\u7ebf\u6027\u72ec\u7acb\u96c6\u5408\uff0c\u4ece\u800c\u83b7\u5f97\u8ddd\u79bb d=n+1 \u7684\u7801\uff0c\u5c24\u5176\u80fd\u6062\u590d\u4e09\u8fdb\u5236 Golay \u7801\uff08n=5\uff09\u3002", "result": "\u6784\u9020\u51fa\u5b9e\u73b0\u7b80\u5355\u3001\u9635\u5217\u53cb\u597d\u7684 q \u8fdb\u5236 SEC-DED \u7801\u65cf\uff0c\u68c0\u9a8c\u90fd\u662f\u6309\u4f4d\u6570\u5b57\u548c\u5168\u5c40\u548c\u5b9e\u73b0\uff0csyndrome \u5230\u9519\u8bef\u5b9a\u4f4d\u7684\u6620\u5c04\u660e\u786e\u4e14\u5355\u904d\u89e3\u7801\u53ef\u884c\uff1bCode A1/Code A2 \u63d0\u9ad8\u4fe1\u606f\u7387\u548c\u6539\u8fdb\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\uff1b\u901a\u8fc7 n-wise XOR \u6846\u67b6\u53ef\u63a8\u5e7f\u5230\u9ad8\u8ddd\u79bb\uff0c\u5e76\u4e0e\u7ecf\u5178\u7801\uff08\u5982 Golay\uff09\u5b58\u5728\u7ed3\u6784\u6027\u8054\u7cfb\u3002\u4e0e\u4f20\u7edf\u7684 q \u8fdb\u5236 Hamming \u53ca SPC/\u4e58\u79ef\u7801\u57fa\u7ebf\u76f8\u6bd4\uff0c\u7ed9\u51fa parity \u5f00\u9500\u3001\u89e3\u7801\u5de5\u4f5c\u91cf\u548c\u4e24\u9519\u884c\u4e3a\u7684\u5bf9\u6bd4\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5e76\u975e\u8ffd\u6c42\u6700\u4f18\u6027\uff0c\u800c\u662f\u5f3a\u8c03\u5b9e\u73b0\u7b80\u6613\u6027\u4e0e\u9635\u5217\u53cb\u597d\u6027\uff1a\u68c0\u9a8c\u4e3a\u9010\u4f4d\u6570\u5b57\u548c\u5168\u5c40\u548c\uff0csyndrome \u5230\u5b9a\u4f4d\u7684\u6620\u5c04\u663e\u5f0f\uff0cSEC-DED \u7684\u5347\u7ea7\u53ef\u6a21\u5757\u5316\u5b9e\u73b0\uff1b\u540c\u65f6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u80fd\u5c06\u8ddd\u79bb\u63d0\u5347\u5230 d=n+1\uff0c\u5e76\u4e0e\u7ecf\u5178\u9ad8\u6548\u7801\u6709\u7ed3\u6784\u4e0a\u7684\u8054\u7cfb\u3002"}}
{"id": "2512.02797", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.02797", "abs": "https://arxiv.org/abs/2512.02797", "authors": ["Sebastian Zieglmeier", "Mathias Hudoba de Badyn", "Narada D. Warakagoda", "Thomas R. Krogstad", "Paal Engelstad"], "title": "Gain-Scheduling Data-Enabled Predictive Control for Nonlinear Systems with Linearized Operating Regions", "comment": "8 pages, 3 figures, 2 tables", "summary": "This paper presents a Gain-Scheduled Data-Enabled Predictive Control (GS-DeePC) framework for nonlinear systems based on multiple locally linear data representations. Instead of relying on a single global Hankel matrix, the operating range of a measurable scheduling variable is partitioned into regions, and regional Hankel matrices are constructed from persistently exciting data. To ensure smooth transitions between linearization regions and suppress region-induced chattering, composite regions are introduced, merging neighboring data sets and enabling a robust switching mechanism. The proposed method maintains the original DeePC problem structure and can achieve reduced computational complexity by requiring only short, locally informative data sequences. Extensive experiments on a nonlinear DC-motor with an unbalanced disc demonstrate the significantly improved control performance compared to standard DeePC.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u591a\u5c40\u90e8\u7ebf\u6027\u6570\u636e\u8868\u793a\u7684\u589e\u76ca\u8c03\u5ea6\u6570\u636e\u9a71\u52a8\u9884\u6d4b\u63a7\u5236\uff08GS-DeePC\uff09\uff0c\u7528\u533a\u57dfHankel\u77e9\u9635\u66ff\u4ee3\u5168\u5c40\u77e9\u9635\uff0c\u901a\u8fc7\u7ec4\u5408\u533a\u57df\u5b9e\u73b0\u5e73\u6ed1\u5207\u6362\u5e76\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5728\u975e\u7ebf\u6027DC\u7535\u673a\u5b9e\u9a8c\u4e2d\u663e\u8457\u4f18\u4e8e\u6807\u51c6DeePC\u3002", "motivation": "\u73b0\u6709\u7684DeePC\u4f9d\u8d56\u5355\u4e00\u5168\u5c40Hankel\u77e9\u9635\uff0c\u96be\u4ee5\u8986\u76d6\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u5e7f\u8303\u56f4\u884c\u4e3a\uff0c\u4e14\u5207\u6362\u533a\u57df\u5bb9\u6613\u5f15\u53d1\u6296\u632f\u5e76\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u3002\u901a\u8fc7\u5bf9\u5de5\u4f5c\u57df\u8fdb\u884c\u533a\u57df\u5316\u3001\u91c7\u7528\u5c40\u90e8\u6570\u636e\u8868\u793a\u5e76\u5408\u5e76\u5f62\u6210\u590d\u5408\u533a\u57df\uff0c\u53ef\u4ee5\u63d0\u5347\u5efa\u6a21\u7075\u6d3b\u6027\u3001\u5207\u6362\u9c81\u68d2\u6027\u548c\u5b9e\u65f6\u6027\u3002", "method": "\u5c06\u5de5\u4f5c\u8303\u56f4\u6309\u53ef\u6d4b\u8c03\u8282\u53d8\u91cf\u5206\u5272\u6210\u591a\u4e2a\u5c40\u90e8\u533a\u57df\uff0c\u4e3a\u6bcf\u4e2a\u533a\u57df\u6784\u5efa\u5c40\u90e8\u53ef\u6301\u7eed\u6fc0\u52b1\u6570\u636e\u5f97\u5230\u7684Hankel\u77e9\u9635\uff1b\u5f15\u5165\u590d\u5408\u533a\u57df\u5c06\u76f8\u90bb\u6570\u636e\u96c6\u5408\u5e76\u4ee5\u5e73\u6ed1\u533a\u57df\u5207\u6362\uff0c\u907f\u514d\u533a\u57df\u95f4\u6296\u632f\uff1b\u4fdd\u6301DeePC\u539f\u6709\u95ee\u9898\u7ed3\u6784\uff0c\u4ec5\u4f7f\u7528\u77ed\u4e14\u5c40\u90e8\u4fe1\u606f\u91cf\u7684\u6570\u636e\u4ee5\u964d\u4f4e\u8ba1\u7b97\u8d1f\u62c5\u3002", "result": "\u5728\u5177\u6709\u4e0d\u5e73\u8861\u8f6c\u5b50\u7684\u4e00\u9636\u975e\u7ebf\u6027\u76f4\u6d41\u7535\u673a\u7b49\u590d\u6742\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u5b9e\u9a8c\u4e2d\uff0c\u6240\u63d0\u51fa\u7684GS-DeePC\u76f8\u8f83\u6807\u51c6DeePC\u8868\u73b0\u51fa\u663e\u8457\u7684\u63a7\u5236\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u533a\u57df\u5316\u7684\u5c40\u90e8\u7ebf\u6027\u6570\u636e\u8868\u793a\u4e0e\u590d\u5408\u533a\u57df\u7684\u5207\u6362\u7b56\u7565\uff0cGS-DeePC\u5728\u4fdd\u6301DeePC\u6846\u67b6\u7684\u540c\u65f6\u5b9e\u73b0\u66f4\u597d\u7684\u9c81\u68d2\u6027\u548c\u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u9002\u7528\u4e8e\u5e7f\u57df\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u9884\u6d4b\u63a7\u5236\u3002"}}
{"id": "2512.02180", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02180", "abs": "https://arxiv.org/abs/2512.02180", "authors": ["Yuxuan Shu", "Peter H. Charlton", "Fahim Kawsar", "Jussi Hernesniemi", "Mohammad Malekzadeh"], "title": "CLEF: Clinically-Guided Contrastive Learning for Electrocardiogram Foundation Models", "comment": "The code is available at https://github.com/Nokia-Bell-Labs/ecg-foundation-model", "summary": "The electrocardiogram (ECG) is a key diagnostic tool in cardiovascular health. Single-lead ECG recording is integrated into both clinical-grade and consumer wearables. While self-supervised pretraining of foundation models on unlabeled ECGs improves diagnostic performance, existing approaches do not incorporate domain knowledge from clinical metadata. We introduce a novel contrastive learning approach that utilizes an established clinical risk score to adaptively weight negative pairs: clinically-guided contrastive learning. It aligns the similarities of ECG embeddings with clinically meaningful differences between subjects, with an explicit mechanism to handle missing metadata. On 12-lead ECGs from 161K patients in the MIMIC-IV dataset, we pretrain single-lead ECG foundation models at three scales, collectively called CLEF, using only routinely collected metadata without requiring per-sample ECG annotations. We evaluate CLEF on 18 clinical classification and regression tasks across 7 held-out datasets, and benchmark against 5 foundation model baselines and 3 self-supervised algorithms. When pretrained on 12-lead ECG data and tested on lead-I data, CLEF outperforms self-supervised foundation model baselines: the medium-sized CLEF achieves average AUROC improvements of at least 2.6% in classification and average reductions in MAEs of at least 3.2% in regression. Comparing with existing self-supervised learning algorithms, CLEF improves the average AUROC by at least 1.8%. Moreover, when pretrained only on lead-I data for classification tasks, CLEF performs comparably to the state-of-the-art ECGFounder, which was trained in a supervised manner. Overall, CLEF enables more accurate and scalable single-lead ECG analysis, advancing remote health monitoring. Code and pretrained CLEF models are available at: github.com/Nokia-Bell-Labs/ecg-foundation-model.", "AI": {"tldr": "\u63d0\u51fa\u4e34\u5e8a\u6307\u5357\u5bf9\u6bd4\u5b66\u4e60CLEF\uff1a\u901a\u8fc7\u5229\u7528\u4e34\u5e8a\u98ce\u9669\u8bc4\u5206\u5bf9\u8d1f\u6837\u672c\u8fdb\u884c\u81ea\u9002\u5e94\u52a0\u6743\uff0c\u7ed3\u5408\u7f3a\u5931\u5143\u6570\u636e\u5904\u7406\uff0c\u5728MIMIC-IV\u6570\u636e\u4e0a\u5bf912\u5bfcECG\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5e76\u57287\u4e2a Held-out \u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4f18\u4e8e\u81ea\u76d1\u7763\u57fa\u7ebf\uff1b\u5728\u5355\u5bfcECG\u5206\u6790\u4e0a\u5177\u6709\u7ade\u4e89\u529b\uff0c\u4ee3\u7801\u53ef\u83b7\u53d6\u3002", "motivation": "\u73b0\u6709\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u672a\u5145\u5206\u5229\u7528\u4e34\u5e8a\u5143\u6570\u636e\u4e2d\u7684\u9886\u57df\u77e5\u8bc6\uff0c\u96be\u4ee5\u5c06ECG\u5d4c\u5165\u4e0e\u4e34\u5e8a\u5dee\u5f02\u5bf9\u9f50\uff1b\u9700\u8981\u4e00\u79cd\u80fd\u6574\u5408\u4e34\u5e8a\u98ce\u9669\u4fe1\u606f\u3001\u5e76\u5bf9\u7f3a\u5931\u5143\u6570\u636e\u9c81\u68d2\u7684\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e34\u5e8a\u5f15\u5bfc\u7684\u5bf9\u6bd4\u5b66\u4e60\uff08CLEF\uff09\uff0c\u4f7f\u7528\u5df2\u786e\u7acb\u7684\u4e34\u5e8a\u98ce\u9669\u5206\u6570\u81ea\u9002\u5e94\u52a0\u6743\u8d1f\u6837\u672c\uff0c\u786e\u4fddECG\u5d4c\u5165\u7684\u76f8\u4f3c\u6027\u4e0e\u4e34\u5e8a\u5dee\u5f02\u5bf9\u9f50\uff0c\u4e14\u5177\u5907\u5904\u7406\u7f3a\u5931\u5143\u6570\u636e\u7684\u673a\u5236\uff1b\u5728MIMIC-IV\u7684161K\u60a3\u8005\u768412\u5bfcECG\u6570\u636e\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5f97\u5230\u5305\u62ec\u5355\u5bfcECG\u7684\u4e09\u79cd\u89c4\u6a21\u6a21\u578b\uff1b\u572818\u4e2a\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u30017\u4e2aHold-out\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4e0e5\u4e2a\u57fa\u7ebf\u4e0e3\u4e2a\u81ea\u76d1\u7763\u7b97\u6cd5\u6bd4\u8f83\u3002", "result": "\u5728\u752812\u5bfcECG\u6570\u636e\u9884\u8bad\u7ec3\u5e76\u5728Lead-I\u4e0a\u6d4b\u8bd5\u65f6\uff0cCLEF\u4f18\u4e8e\u81ea\u76d1\u7763\u57fa\u7ebf\uff1a\u4e2d\u7b49\u89c4\u6a21\u7684CLEF\u5206\u7c7b\u4efb\u52a1\u7684\u5e73\u5747AUROC\u63d0\u5347\u22652.6%\uff0c\u56de\u5f52MAE\u4e0b\u964d\u22653.2%\uff1b\u76f8\u8f83\u4e8e\u73b0\u6709\u81ea\u76d1\u7763\u7b97\u6cd5\uff0cCLEF\u5e73\u5747AUROC\u63d0\u5347\u22651.8%\u3002\u4ec5\u5728Lead-I\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\u7528\u4e8e\u5206\u7c7b\u65f6\uff0cCLEF\u4e0e\u76d1\u7763\u5b66\u4e60\u7684ECGFounder\u76f8\u5f53\u3002", "conclusion": "CLEF\u63d0\u5347\u4e86\u5355\u5bfcECG\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u63a8\u52a8\u8fdc\u7a0b\u5065\u5eb7\u76d1\u6d4b\u7684\u53d1\u5c55\uff0c\u8bc1\u660e\u5c06\u4e34\u5e8a\u5143\u6570\u636e\u6574\u5408\u8fdb\u81ea\u76d1\u7763\u5b66\u4e60\u53ef\u5e26\u6765\u66f4\u4f18\u7684\u8868\u5f81\uff1b\u4ee3\u7801\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\u53ef\u5728GitHub\u83b7\u53d6\u3002"}}
{"id": "2512.02767", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02767", "abs": "https://arxiv.org/abs/2512.02767", "authors": ["Rostislav Matveev", "Andrei Romashchenko"], "title": "Structural Properties of Entropic Vectors and Stability of the Ingleton Inequality", "comment": "25 pages", "summary": "We study constrained versions of the Ingleton inequality in the entropic setting and quantify its stability under small violations of conditional independence. Although the classical Ingleton inequality fails for general entropy profiles, it is known to hold under certain exact independence constraints. We focus on the regime where selected conditional mutual information terms are small (but not zero), and the inequality continues to hold up to controlled error terms. A central technical tool is a structural lemma that materializes part of the mutual information between two random variables, implicitly capturing the effect of infinitely many non-Shannon--type inequalities. This leads to conceptually transparent proofs without explicitly invoking such infinite families. Some of our bounds recover, in a unified way, what can also be deduced from the infinite families of inequalities of Mat\u00fa\u0161 (2007) and of Dougherty--Freiling--Zeger (2011), while others appear to be new.", "AI": {"tldr": "\u5728\u8fd1\u4f3c\u72ec\u7acb\u6761\u4ef6\u4e0b\u7814\u7a76 Ingleton \u4e0d\u7b49\u5f0f\u7684\u53d7\u9650\u7248\u672c\uff0c\u7ed9\u51fa\u7a33\u5b9a\u6027\u754c\u5e76\u901a\u8fc7\u7ed3\u6784\u6027\u5f15\u7406\u5728\u4e0d\u663e\u5f0f\u4f7f\u7528\u65e0\u9650\u975eShannon\u578b\u4e0d\u7b49\u5f0f\u7684\u60c5\u51b5\u4e0b\u63ed\u793a\u4e92\u4fe1\u606f\u7684\u4f5c\u7528\u3002", "motivation": "Ingleton \u4e0d\u7b49\u5f0f\u5e76\u975e\u5bf9\u6240\u6709\u71b5\u5206\u5e03\u90fd\u6210\u7acb\uff0c\u4f46\u5728\u67d0\u4e9b\u4e25\u683c\u72ec\u7acb\u6027\u7ea6\u675f\u4e0b\u6210\u7acb\u3002\u672c\u5de5\u4f5c\u62df\u5728\u201c\u8f83\u5c0f\u4f46\u975e\u96f6\u201d\u7684\u6761\u4ef6\u4e92\u4fe1\u606f\u60c5\u5f62\u4e0b\u63a2\u7a76\u5176\u7a33\u5b9a\u6027\uff0c\u7406\u89e3\u8fd1\u4f3c\u72ec\u7acb\u6027\u5bf9\u4e0d\u7b49\u5f0f\u7684\u5f71\u54cd\u53ca\u754c\u9650\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u6784\u6027\u5f15\u7406\uff0c\u663e\u5f0f\u5730\u5448\u73b0\u4e24\u4e2a\u53d8\u91cf\u4e4b\u95f4\u90e8\u5206\u4e92\u4fe1\u606f\u7684\u7ed3\u6784\uff0c\u9690\u542b\u5730\u6355\u6349\u5927\u91cf\u975eShannon\u578b\u4e0d\u7b49\u5f0f\u7684\u6548\u5e94\u4f46\u4e0d\u76f4\u63a5\u4f9d\u8d56\u4e8e\u5b83\u4eec\uff1b\u5728\u6b64\u6846\u67b6\u4e2d\u63a8\u5bfc\u51fa\u5f53\u82e5\u5e72\u6761\u4ef6\u4e92\u4fe1\u606f\u5f88\u5c0f\u65f6\uff0cIngleton \u4e0d\u7b49\u5f0f\u4ecd\u6210\u7acb\u4e14\u5e26\u6709\u53ef\u63a7\u8bef\u5dee\uff1b\u5e76\u5c06\u7ed3\u679c\u4e0e Mat\u00fa\u0161 (2007) \u548c Dougherty\u2013Freiling\u2013Zeger (2011) \u7684\u65e0\u7a77\u65cf\u4e0d\u7b49\u5f0f\u8054\u7cfb\u8d77\u6765\u3002", "result": "\u7ed9\u51fa\u5728\u67d0\u4e9b\u6761\u4ef6\u4e92\u4fe1\u606f\u5c0f\u7684\u60c5\u5f62\u4e0b\uff0cIngleton \u4e0d\u7b49\u5f0f\u4fdd\u6709\u7a33\u5b9a\u6027\uff08\u542b\u8bef\u5dee\u9879\uff09\u7684\u754c\uff1b\u90e8\u5206\u7ed3\u8bba\u7edf\u4e00\u4e86\u5148\u524d\u53ef\u7531\u65e0\u7a77\u65cf\u4e0d\u7b49\u5f0f\u63a8\u5bfc\u51fa\u7684\u7ed3\u679c\uff0c\u540c\u65f6\u4e5f\u7ed9\u51fa\u82e5\u5e72\u65b0\u7684\u754c\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u6027\u5f15\u7406\u5b9e\u73b0\u5bf9\u8fd1\u4f3c\u72ec\u7acb\u6027\u4e0b Ingleton \u6761\u4ef6\u7684\u900f\u660e\u8bc1\u660e\u4e0e\u7a33\u5b9a\u6027\u5206\u6790\uff0c\u907f\u514d\u76f4\u63a5\u8bc9\u8bf8\u5927\u91cf\u65e0\u7a77\u65cf\u4e0d\u7b49\u5f0f\uff1b\u8fd9\u4e0d\u4ec5\u7edf\u4e00\u4e86\u76f8\u5173\u7ed3\u679c\uff0c\u4e5f\u7ed9\u51fa\u65b0\u754c\uff0c\u4e3a\u71b5\u4e0d\u7b49\u5f0f\u7684\u8fd1\u4f3c\u6210\u7acb\u63d0\u4f9b\u65b0\u5de5\u5177\u4e0e\u89c6\u89d2\u3002"}}
{"id": "2512.02194", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02194", "abs": "https://arxiv.org/abs/2512.02194", "authors": ["Sophie L. Wang", "Alex Quach", "Nithin Parsan", "John J. Yang"], "title": "Enforcing Orderedness to Improve Feature Consistency", "comment": null, "summary": "Sparse autoencoders (SAEs) have been widely used for interpretability of neural networks, but their learned features often vary across seeds and hyperparameter settings. We introduce Ordered Sparse Autoencoders (OSAE), which extend Matryoshka SAEs by (1) establishing a strict ordering of latent features and (2) deterministically using every feature dimension, avoiding the sampling-based approximations of prior nested SAE methods. Theoretically, we show that OSAEs resolve permutation non-identifiability in settings of sparse dictionary learning where solutions are unique (up to natural symmetries). Empirically on Gemma2-2B and Pythia-70M, we show that OSAEs can help improve consistency compared to Matryoshka baselines.", "AI": {"tldr": "OSAE introduces an explicit ordering of latent features and deterministic use of all dimensions to improve identifiability and reproducibility of sparse autoencoders, with theoretical guarantees and improved consistency over Matryoshka baselines on large models.", "motivation": "Sparse autoencoders offer interpretability but feature representations vary with seeds and hyperparameters due to permutation non-identifiability and sampling in nested methods. A stable, ordered, fully-utilized latent representation is desirable for reproducibility and interpretability.", "method": "Propose Ordered Sparse Autoencoders (OSAE) by extending Matryoshka SAEs with (1) a strict ordering constraint on latent features and (2) deterministic usage of every feature dimension, removing sampling-based approximations. Provide theoretical analysis showing resolution of permutation non-identifiability in sparse dictionary learning where solutions are unique up to symmetries. Empirically evaluate on Gemma2-2B and Pythia-70M against Matryoshka baselines.", "result": "Theoretical: OSAEs resolve permutation non-identifiability in settings with unique solutions (up to natural symmetries). Empirical: on Gemma2-2B and Pythia-70M, OSAEs improve consistency vs Matryoshka baselines.", "conclusion": "OSAE offers more stable, interpretable representations by enforcing latent-feature ordering and deterministic utilization, reducing seed/hyperparameter-induced variability; demonstrated effectiveness on large-scale datasets."}}
{"id": "2512.02598", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.02598", "abs": "https://arxiv.org/abs/2512.02598", "authors": ["Keum-Bae Cho"], "title": "Equilibrium SAT based PQC: New aegis against quantum computing", "comment": "8 pages, 5 figures", "summary": "Public-key cryptography algorithms have evolved towards increasing computational complexity to hide desired messages, which is accelerating with the development of the Internet and quantum computing. This paper introduces a novel public-key cryptography algorithm that generates ciphertexts by counting the number of elements in randomly extracted subsets from a multiset. After explaining the novel cryptographic concept, the process of mathematically refining it using satisfiability problems is described. The advantages of the proposed algorithm are: first, it is significantly faster than other public-key algorithms; second, it does not require big numbers, making it executable on any devices; and third, it can be easily extended into a public-key cryptosystem using a single public key and multiple private keys while maintaining quantum resistance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u516c\u94a5\u5bc6\u7801\u4f53\u5236\uff1a\u901a\u8fc7\u4ece\u591a\u91cd\u96c6\u5408\u4e2d\u968f\u673a\u62bd\u53d6\u5b50\u96c6\u5e76\u8ba1\u6570\u5176\u5143\u7d20\u6765\u751f\u6210\u5bc6\u6587\uff1b\u4f7f\u7528\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u5bf9\u8be5\u6982\u5ff5\u8fdb\u884c\u6570\u5b66 refine\uff1b\u58f0\u79f0\u5728\u91cf\u5b50\u6297\u6027\u6761\u4ef6\u4e0b\u5177\u6709\u8f83\u9ad8\u901f\u5ea6\u3001\u65e0\u9700\u5927\u6574\u6570\u4e14\u53ef\u6269\u5c55\u4e3a\u5355\u516c\u94a5\u548c\u591a\u79c1\u94a5\u7684\u4f53\u7cfb\u3002", "motivation": "\u5728\u4e92\u8054\u7f51\u548c\u91cf\u5b50\u8ba1\u7b97\u5feb\u901f\u53d1\u5c55\u80cc\u666f\u4e0b\uff0c\u73b0\u6709\u516c\u94a5\u7b97\u6cd5\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u5bf9\u5927\u6574\u6570\u8fd0\u7b97\u7684\u4f9d\u8d56\u6210\u4e3a\u74f6\u9888\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u4e14\u5bf9\u8d44\u6e90\u53cb\u597d\u7684\u91cf\u5b50\u6297\u6027\u65b9\u6848\u3002", "method": "\u6838\u5fc3\u601d\u60f3\u662f\u901a\u8fc7\u8ba1\u6570\u4ece\u591a\u91cd\u96c6\u5408\u4e2d\u968f\u673a\u62bd\u53d6\u7684\u5b50\u96c6\u5143\u4ef6\u6570\u6765\u4ea7\u751f\u5bc6\u6587\uff0c\u5e76\u4ee5\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\uff08SAT\uff09\u4e3a\u5de5\u5177\u5bf9\u8be5\u6982\u5ff5\u8fdb\u884c\u6570\u5b66 Refinement\uff1b\u63d0\u51fa\u5728\u6b64\u57fa\u7840\u4e0a\u5f62\u6210\u4e00\u4e2a\u5305\u542b\u5355\u4e00\u516c\u94a5\u548c\u591a\u79c1\u94a5\u7684\u516c\u94a5\u4f53\u7cfb\u6846\u67b6\u3002", "result": "\u58f0\u79f0\u8be5\u7b97\u6cd5\u663e\u8457\u5feb\u4e8e\u73b0\u6709\u516c\u94a5\u7b97\u6cd5\u3001\u65e0\u9700\u5927\u6574\u6570\u3001\u53ef\u5728\u4efb\u4f55\u8bbe\u5907\u4e0a\u5b9e\u73b0\uff0c\u4e14\u53ef\u6269\u5c55\u4e3a\u5177\u6709\u91cf\u5b50\u6297\u6027\u7684\u516c\u94a5\u7cfb\u7edf\uff0c\u4e14\u53ef\u7528\u5355\u516c\u94a5\u4e0e\u591a\u79c1\u94a5\u7ec4\u5408\u5b9e\u73b0\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u7684\u601d\u8def\u5177\u6709\u6f5c\u5728\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u548c\u9700\u8981\u91cf\u5b50\u6297\u6027\u7684\u573a\u666f\uff1b\u4f46\u4ecd\u9700\u8fdb\u884c\u4e25\u683c\u7684\u5b89\u5168\u6027\u5206\u6790\u3001\u5b9e\u73b0\u9a8c\u8bc1\u53ca\u5bf9\u53ef\u80fd\u7684\u653b\u51fb\u8def\u5f84\u8fdb\u884c\u8bc4\u4f30\u3002"}}
{"id": "2512.02757", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02757", "abs": "https://arxiv.org/abs/2512.02757", "authors": ["Yunzhe Zhu", "Xuewen Liao", "Zhenzhen Gao", "Yong Zeng"], "title": "Channel Knowledge Map Construction via Physics-Inspired Diffusion Model Without Prior Observations", "comment": null, "summary": "The ability to construct Channel Knowledge Map (CKM) with high precision is essential for environment awareness in 6G wireless systems. However, most existing CKM construction methods formulate the task as an image super-resolution or generation problem, thereby employing models originally developed for computer vision. As a result, the generated CKMs often fail to capture the underlying physical characteristics of wireless propagation. In this paper, we focus on the construction of CKM for large-scale fading scenarios and design three physics-based constraint terms to characterize the spatial distribution patterns of large-scale fading. By integrating these physical constraints with a state-of-the-art diffusion model that possesses superior generative capability, a physics-inspired diffusion model for CKM construction is proposed. Following this motivation, we derive the loss function of the diffusion model augmented with physics-based constraint terms and further design the training and generation framework for the proposed physics-inspired CKM generation diffusion model. Extensive experiments show that our approach outperforms all existing methods in terms of construction accuracy. Moreover, the proposed model provides a unified and effective framework with strong potential for generating diverse, accurate, and physically consistent CKM.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5c06\u7269\u7406\u7ea6\u675f\u878d\u5165\u6269\u6563\u6a21\u578b\u7684CKM\u6784\u5efa\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u9879\u7269\u7406\u7ea6\u675f\u63cf\u8ff0\u5927\u5c3a\u5ea6\u8870\u843d\u7684\u7a7a\u95f4\u5206\u5e03\uff0c\u5e76\u5728\u6269\u6563\u6a21\u578b\u6846\u67b6\u4e0b\u5b9e\u73b0CKM\u7684\u9ad8\u7cbe\u5ea6\u751f\u6210\uff0c\u8fbe\u5230\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6784\u5efa\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524dCKM\u591a\u5c06\u4efb\u52a1\u89c6\u4e3a\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\u6216\u751f\u6210\u95ee\u9898\uff0c\u91c7\u7528\u901a\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\uff0c\u672a\u80fd\u6355\u6349\u65e0\u7ebf\u4f20\u64ad\u7684\u7269\u7406\u7279\u6027\uff0c\u5bfc\u81f4CKM\u7684\u7269\u7406\u4e00\u81f4\u6027\u4e0d\u8db3\u3002\u9700\u8981\u5728\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\uff0c\u786e\u4fddCKM\u4e0e\u7269\u7406\u4f20\u64ad\u89c4\u5f8b\u7684\u4e00\u81f4\u6027\uff0c\u63d0\u5347\u73af\u5883\u611f\u77e5\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e09\u9879\u4e0e\u5927\u5c3a\u5ea6\u8870\u843d\u76f8\u5173\u7684\u7269\u7406\u7ea6\u675f\u9879\u6765\u523b\u753b\u5176\u7a7a\u95f4\u5206\u5e03\uff0c\u901a\u8fc7\u5c06\u8fd9\u4e9b\u7ea6\u675f\u4e0e\u6700\u5148\u8fdb\u7684\u6269\u6563\u6a21\u578b\u7ed3\u5408\uff0c\u6784\u5efa\u4e00\u4e2a\u7269\u7406\u542f\u53d1\u7684CKM\u6269\u6563\u751f\u6210\u6846\u67b6\u3002\u63a8\u5bfc\u5e26\u6709\u7269\u7406\u7ea6\u675f\u9879\u7684\u6269\u6563\u6a21\u578b\u635f\u5931\u51fd\u6570\uff0c\u5e76\u8bbe\u8ba1CKM\u7684\u8bad\u7ec3\u4e0e\u751f\u6210\u6d41\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728CKM\u6784\u5efa\u7cbe\u5ea6\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5177\u6709\u7edf\u4e00\u6027\u548c\u5f3a\u6f5c\u529b\uff0c\u80fd\u591f\u751f\u6210\u591a\u6837\u3001\u51c6\u786e\u4e14\u7269\u7406\u4e00\u81f4\u7684CKM\u3002", "conclusion": "\u7269\u7406\u542f\u53d1\u7684CKM\u6269\u6563\u6a21\u578b\u4e3a\u5927\u5c3a\u5ea6\u8870\u843dCKM\u7684\u9ad8\u7cbe\u5ea6\u6784\u5efa\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u4e00\u81f4\u6027\u4e0e\u6cdb\u5316\u80fd\u529b\uff0c\u5f62\u6210\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u751f\u6210\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u672a\u67656G\u73af\u5883\u611f\u77e5\u9700\u6c42\u3002"}}
{"id": "2512.02941", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02941", "abs": "https://arxiv.org/abs/2512.02941", "authors": ["Wittawat Kositwattanarerk", "Gretchen L. Matthews", "Emily McMillon", "Tunchanok Yutitumsatit"], "title": "Pseudocodewords of quantum, quasi-cyclic, and spatially-coupled LDPC codes: a fundamental cone perspective", "comment": null, "summary": "While low-density parity-check (LDPC) codes are near capacity-achieving when paired with iterative decoders, these decoders may not output a codeword due to the existence of pseudocodewords. Thus, pseudocodewords have been studied to give insight into the performance of modern decoders including iterative and linear programming decoders. These pseudocodewords are found to be dependent on the parity-check matrix of the code and the particular decoding algorithm used. In this paper, we consider LP decoding, which has been linked to graph cover decoding, providing functions which capture these pseudocodewords. In particular, we analyze the underlying structure of pseudocodewords from quantum stabilizer codes that arise from LP decoding, quasi-cyclic LDPC codes, and spatially-coupled LDPC codes.", "AI": {"tldr": "\u672c\u8bba\u6587\u4eceLP\u89e3\u7801\u89c6\u89d2\u7cfb\u7edf\u5206\u6790\u4f2a\u7801\u5b57\u5728\u4e0d\u540cLDPC\u7ed3\u6784\u4e2d\u7684\u5f62\u6210\u4e0e\u7279\u5f81\uff0c\u4ee5\u53ca\u5b83\u4eec\u5bf9\u89e3\u7801\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u4f2a\u7801\u5b57\u662f\u963b\u788dLDPC\u8fd1\u4f3c\u5bb9\u91cf\u6027\u80fd\u5b9e\u73b0\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4e14\u5176\u5f62\u6001\u53d7\u6821\u9a8c\u77e9\u9635\u548c\u89e3\u7801\u7b97\u6cd5\u5f71\u54cd\uff1bLP\u89e3\u7801\u4e0e\u56fe\u8986\u76d6\u89e3\u7801\u6709\u7d27\u5bc6\u8054\u7cfb\uff0c\u5206\u6790\u4f2a\u7801\u5b57\u6709\u52a9\u4e8e\u7406\u89e3\u548c\u6539\u8fdb\u89e3\u7801\u7b56\u7565\uff0c\u5c24\u5176\u9488\u5bf9\u91cf\u5b50\u7a33\u5b9a\u7801\u3001\u51c6\u5faa\u73afLDPC\u4e0e\u65f6\u7a7a\u8026\u5408LDPC\u7b49\u7ed3\u6784\u3002", "method": "\u901a\u8fc7\u7814\u7a76LP\u89e3\u7801\u6846\u67b6\u4e2d\u7684\u4f2a\u7801\u5b57\uff0c\u7ed3\u5408\u56fe\u8986\u76d6\u89e3\u7801\u7684\u7b49\u4ef7\u63cf\u8ff0\uff0c\u5206\u6790\u6765\u81ea\u91cf\u5b50\u7a33\u5b9a\u7801\u3001\u51c6\u5faa\u73afLDPC\u548c\u65f6\u7a7a\u8026\u5408LDPC\u7684\u4f2a\u7801\u5b57\u7684\u5e95\u5c42\u7ed3\u6784\u7279\u5f81\u53ca\u5176\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u63ed\u793a\u4e86\u4f2a\u7801\u5b57\u7ed3\u6784\u5728\u4e0d\u540c\u7801\u578b\u4e2d\u7684\u5171\u6027\u4e0e\u5dee\u5f02\uff0c\u6307\u51fa\u4f2a\u7801\u5b57\u5bf9LP\u89e3\u7801\u53ca\u76f8\u5173\u89e3\u7801\u5668\u6027\u80fd\u7684\u5f71\u54cd\u673a\u5236\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u66f4\u9c81\u68d2\u7684LDPC\u7801\u4e0e\u89e3\u7801\u7b97\u6cd5\u63d0\u4f9b\u7ed3\u6784\u6027\u7ebf\u7d22\u3002", "conclusion": "\u5728LP\u89e3\u7801\u53ca\u56fe\u8986\u76d6\u89e3\u7801\u6846\u67b6\u4e0b\u7406\u89e3\u4f2a\u7801\u5b57\u7684\u7ed3\u6784\u6709\u52a9\u4e8e\u7edf\u4e00\u5206\u6790\u5e76\u6307\u5bfc\u672a\u6765\u7684\u7801\u8bbe\u8ba1\uff0c\u5c24\u5176\u5728\u91cf\u5b50\u7a33\u5b9a\u7801\u3001\u51c6\u5faa\u73afLDPC\u4e0e\u65f6\u7a7a\u8026\u5408LDPC\u7684\u5e94\u7528\u573a\u666f\u4e2d\u3002"}}
{"id": "2512.02823", "categories": ["eess.SY", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.02823", "abs": "https://arxiv.org/abs/2512.02823", "authors": ["Menno van Zutphen", "Domagoj Herceg", "Giannis Delimpaltadakis", "Duarte J. Antunes"], "title": "Tempering the Bayes Filter towards Improved Model-Based Estimation", "comment": null, "summary": "Model-based filtering is often carried out while subject to an imperfect model, as learning partially-observable stochastic systems remains a challenge. Recent work on Bayesian inference found that tempering the likelihood or full posterior of an imperfect model can improve predictive accuracy, as measured by expected negative log likelihood. In this paper, we develop the tempered Bayes filter, improving estimation performance through both of the aforementioned, and one newly introduced, modalities. The result admits a recursive implementation with a computational complexity no higher than that of the original Bayes filter. Our analysis reveals that -- besides the well-known fact in the field of Bayesian inference that likelihood tempering affects the balance between prior and likelihood -- full-posterior tempering tunes the level of entropy in the final belief distribution. We further find that a region of the tempering space can be understood as interpolating between the Bayes- and MAP filters, recovering these as special cases. Analytical results further establish conditions under which a tempered Bayes filter achieves improved predictive performance. Specializing the results to the linear Gaussian case, we obtain the tempered Kalman filter. In this context, we interpret how the parameters affect the Kalman state estimate and covariance propagation. Empirical results confirm that our method consistently improves predictive accuracy over the Bayes filter baseline.", "AI": {"tldr": "\u63d0\u51fa\u4e86 tempered Bayes \u8fc7\u6ee4\u5668\uff0c\u7528\u4e8e\u5728\u6a21\u578b\u4e0d\u5b8c\u5907\u7684\u60c5\u5f62\u4e0b\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u7ed3\u5408\u4f3c\u7136 tempering\u3001\u5168\u540e\u9a8c tempering \u4ee5\u53ca\u4e00\u79cd\u65b0\u6a21\u5f0f\uff0c\u4fdd\u6301\u9012\u5f52\u5b9e\u73b0\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0d\u9ad8\u4e8e\u539f Bayes \u6ee4\u6ce2\u3002", "motivation": "\u5728\u5b66\u4e60\u90e8\u5206\u53ef\u89c2\u6d4b\u968f\u673a\u7cfb\u7edf\u65f6\uff0c\u6a21\u578b\u4e0d\u5b8c\u6ee1\u5e26\u6765\u4f30\u8ba1\u8bef\u5dee\u4e0e\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u5982\u4f55\u5728\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u53ca\u4fe1\u606f\u71b5\u5c42\u9762\u901a\u8fc7\u6e29\u548c\u5316\u6765\u63d0\u5347\u63a8\u65ad\u6027\u80fd\u6210\u4e3a\u5173\u952e\u95ee\u9898\u3002", "method": "\u63d0\u51fa tempered Bayes \u6ee4\u6ce2\u5668\uff0c\u5305\u542b\u4e09\u79cd\u6a21\u6001\uff1a\u4f3c\u7136\u6e29\u548c\u5316\u3001\u5168\u540e\u9a8c\u6e29\u548c\u5316\u4ee5\u53ca\u4e00\u79cd\u65b0\u5f15\u5165\u7684\u6a21\u6001\uff0c\u5f62\u6210\u53ef\u9012\u5f52\u5b9e\u73b0\u7684\u6ee4\u6ce2\u7b97\u6cd5\u3002\u7ed9\u51fa\u5173\u4e8e\u540e\u9a8c\u5206\u5e03\u71b5\u7684\u5206\u6790\uff0c\u6307\u51fa\u6e29\u548c\u5316\u5bf9\u5148\u9a8c\u4e0e\u4f3c\u7136\u7684\u5e73\u8861\u5f71\u54cd\uff0c\u4ee5\u53ca\u5168\u540e\u9a8c\u6e29\u548c\u5316\u5728\u6700\u7ec8\u4fe1\u5ff5\u5206\u5e03\u4e2d\u7684\u71b5\u63a7\u5236\u4f5c\u7528\u3002\u7ed9\u51fa\u4e00\u4e2a\u4ecb\u4e8e Bayes \u4e0e MAP \u4e4b\u95f4\u7684\u6e29\u548c\u5316\u533a\u95f4\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u7279\u4f8b\u6536\u655b\u5230 Bayes\u3001MAP\u3002\u5bf9\u7ebf\u6027\u9ad8\u65af\u60c5\u5f62\u505a\u4e13\u95e8\u5316\uff0c\u5f97\u5230 temper Kalman \u6ee4\u6ce2\u5668\uff0c\u5e76\u89e3\u91ca\u53c2\u6570\u5bf9\u5747\u503c\u4e0e\u534f\u65b9\u5dee\u4f20\u64ad\u7684\u5f71\u54cd\u3002\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\u5728\u9884\u6d4b\u5bf9\u6570\u635f\u5931\uff08\u8d1f\u5bf9\u6570\u4f3c\u7136\uff09\u4e0b\u666e\u904d\u4f18\u4e8e\u57fa\u7ebf Bayes \u6ee4\u6ce2\u5668\u3002", "result": "\u7406\u8bba\u5206\u6790\u7ed9\u51fa\u6e29\u548c\u5316\u6ee4\u6ce2\u5728\u6539\u8fdb\u9884\u6d4b\u6027\u80fd\u65b9\u9762\u7684\u6761\u4ef6\uff1b\u7ebf\u6027\u9ad8\u65af\u60c5\u51b5\u4e0b\u89e3\u91ca\u53c2\u6570\u5bf9\u72b6\u6001\u4f30\u8ba1\u4e0e\u534f\u65b9\u5dee\u66f4\u65b0\u7684\u5f71\u54cd\uff1b\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u5b9e\u76f8\u8f83\u4e8e Bayes \u6ee4\u6ce2\u5668\u57fa\u7ebf\u7684\u6301\u7eed\u6539\u8fdb\u3002", "conclusion": "\u6e29\u548c\u5316\u7684 Bayes \u6ee4\u6ce2\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5728\u65e2\u4fdd\u7559\u9012\u5f52\u5b9e\u73b0\u53c8\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u7684\u6298\u4e2d\uff0c\u4e14\u53ef\u5728\u4e0d\u540c tempering \u4e0b\u6a2a\u8de8 Bayes \u4e0e MAP \u7684\u8c31\u7cfb\uff0c\u7ecf\u7ebf\u6027\u9ad8\u65af\u4e13\u95e8\u5316\u53ef\u5f97\u5230 tempered Kalman \u6ee4\u6ce2\u5668\u3002"}}
{"id": "2512.02765", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02765", "abs": "https://arxiv.org/abs/2512.02765", "authors": ["Alejandro Roig-Herrero", "Luis M. San-Jos\u00e9-Revuelta", "Rafael Navarro-Gonz\u00e1lez", "Rodrigo de Luis-Garc\u00eda", "Vicente Molina"], "title": "Effects of disease duration and antipsychotics on brain age in schizophrenia", "comment": "20 pages; 4 figures; 4 tables", "summary": "Accelerated brain aging has been consistently reported in patients with schizophrenia. Over the past decade, these findings have been replicated using the Brain Age paradigm, which applies machine learning techniques to estimate brain age from neuroimaging data. This approach yields a single index, the Brain Age Gap, defined as the difference between predicted and chronological age. Nevertheless, both the progressive nature of this phenomenon and the potential role of antipsychotic medication remain unclear. To investigate its progression, we compared the Brain Age Gap between individuals experiencing a first episode of psychosis and healthy controls using ANCOVA, adjusting for age, sex, body mass index, and estimated total intracranial volume. To enhance the robustness of our findings, we employed two distinct models: a transformer-inspired model based on harmonized volumetric brain features extracted with FastSurfer, and a previously trained deep learning model. To assess the potential effect of medication, we further compared bipolar patients who received antipsychotic treatment with those who did not. Mann-Whitney U test consistently showed that medicated bipolar patients did not exhibit a significantly larger Brain Age Gap. Both models converge on the conclusion that accelerated brain aging is unlikely to be explained by antipsychotic medication alone. Longitudinal studies are therefore required to clarify the temporal dynamics of brain aging in schizophrenia.", "AI": {"tldr": "\u591a\u6a21\u6001\u8111\u9f84\u5206\u6790\u8868\u660e\uff0c\u7cbe\u795e\u5206\u88c2\u75c7\u60a3\u8005\u7684\u8111\u5e74\u9f84\u52a0\u901f\u5e76\u975e\u4ec5\u7531\u6297\u7cbe\u795e\u75c5\u836f\u7269\u9a71\u52a8\uff0c\u4e14\u6a2a\u622a\u9762\u8bc1\u636e\u4e0d\u8db3\u4ee5\u63ed\u793a\u65f6\u95f4\u52a8\u6001\uff1b\u9700\u8981\u7eb5\u5411\u7814\u7a76\u4ee5\u660e\u786e\u5176\u65f6\u95f4\u6f14\u53d8\u3002", "motivation": "\u63a2\u7a76\u8111\u5e74\u9f84\u5dee\uff08Brain Age Gap, BAG\uff09\u7684\u8fdb\u5c55\u6027\u53ca\u836f\u7269\u66b4\u9732\u7684\u6f5c\u5728\u4f5c\u7528\uff0c\u660e\u786e\u7cbe\u795e\u75c5\u4e0e\u836f\u7269\u66b4\u9732\u5bf9\u8111\u7ed3\u6784\u8001\u5316\u7684\u8d21\u732e\u3002", "method": "\u5bf9\u7b2c\u4e00\u53d1\u4f5c\u7cbe\u795e\u75c5\u60a3\u8005\u4e0e\u5065\u5eb7\u5bf9\u7167\u7ec4\u6bd4\u8f83BAG\uff0c\u63a7\u5236\u5e74\u9f84\u3001\u6027\u522b\u3001BMI\u3001\u9885\u5185\u603b\u4f53\u79ef\uff1b\u91c7\u7528\u4e24\u79cd\u6a21\u578b\uff1a\u57fa\u4e8eFastSurfer\u63d0\u53d6\u7684\u534f\u8c03\u5316\u4f53\u79ef\u7279\u5f81\u7684Transformer\u98ce\u683c\u6a21\u578b\uff0c\u4ee5\u53ca\u5148\u524d\u8bad\u7ec3\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff1b\u836f\u7269\u56e0\u7d20\u65b9\u9762\uff0c\u6bd4\u8f83\u5df2\u7528\u6297\u7cbe\u795e\u75c5\u836f\u7684\u53cc\u76f8\u6291\u90c1\u4eba\u7fa4\u4e0e\u672a\u7528\u836f\u4eba\u7fa4\uff0c\u4f7f\u7528Mann-Whitney U\u68c0\u9a8c\u3002", "result": "\u4e24\u79cd\u6a21\u578b\u90fd\u663e\u793a\uff1a\u836f\u7269\u66b4\u9732\u4e0eBAG\u4e4b\u95f4\u6ca1\u6709\u663e\u8457\u589e\u5927\uff1b\u6574\u4f53\u7ed3\u8bba\u4e3a\uff0c\u8111\u5e74\u9f84\u52a0\u901f\u4e0d\u592a\u53ef\u80fd\u4ec5\u7531\u6297\u7cbe\u795e\u75c5\u836f\u7269\u5f15\u8d77\uff1b\u9700\u8981\u7eb5\u5411\u7814\u7a76\u4ee5\u660e\u786e\u65f6\u95f4\u52a8\u6001\u3002", "conclusion": "\u6a2a\u622a\u9762\u5206\u6790\u63d0\u793a\u836f\u7269\u66b4\u9732\u4e0d\u662f\u552f\u4e00\u89e3\u91ca\u8111\u9f84\u52a0\u901f\u7684\u56e0\u7d20\uff0c\u5efa\u8bae\u5f00\u5c55\u7eb5\u5411\u968f\u8bbf\u7814\u7a76\uff0c\u4ee5\u63ed\u793a\u7cbe\u795e\u5206\u88c2\u75c7\u76f8\u5173\u8111\u8001\u5316\u7684\u65f6\u95f4\u8fc7\u7a0b\u53ca\u836f\u7269\u5bf9\u5176\u7684\u6f5c\u5728\u4f5c\u7528\u3002"}}
{"id": "2512.02858", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.02858", "abs": "https://arxiv.org/abs/2512.02858", "authors": ["Mahrokh Ghoddousi Boroujeni", "Clara Luc\u00eda Galimberti", "Andreas Krause", "Giancarlo Ferrari-Trecate"], "title": "PAC-Bayesian Optimal Control with Stability and Generalization Guarantees", "comment": null, "summary": "Stochastic Nonlinear Optimal Control (SNOC) seeks to minimize a cost function that accounts for random disturbances acting on a nonlinear dynamical system. Since the expectation over all disturbances is generally intractable, a common surrogate is the empirical cost, obtained by averaging over a finite dataset of sampled noise realizations. This substitution, however, introduces the challenge of guaranteeing performance under unseen disturbances. The issue is particularly severe when the dataset is limited, as the trained controllers may overfit, leading to substantial gaps between their empirical cost and the deployment cost. In this work, we develop a PAC-Bayesian framework that establishes rigorous generalization bounds for SNOC. Building on these bounds, we propose a principled controller design method that balances empirical performance and prior knowledge. To ensure tractability, we derive computationally efficient relaxations of the bounds and employ approximate inference methods. Our framework further leverages expressive neural controller parameterizations, guaranteeing closed-loop stability. Through simulated examples, we highlight how prior knowledge can be incorporated into control design and how more reliable controllers can be synthesized for cooperative robotics.", "AI": {"tldr": "\u5f15\u5165\u57fa\u4e8ePAC-Bayes\u7684\u6cdb\u5316\u6846\u67b6\u6765\u4e3a\u968f\u673a\u975e\u7ebf\u6027\u6700\u4f18\u63a7\u5236\uff08SNOC\uff09\u63d0\u4f9b\u4e25\u683c\u7684\u6cdb\u5316\u754c\u9650\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u4e00\u4e2a\u4ee5\u5148\u9a8c\u77e5\u8bc6\u4e3a\u7ea6\u675f\u3001\u517c\u987e\u7ecf\u9a8c\u6027\u80fd\u4e0e\u4e0d\u786e\u5b9a\u6027\u9c81\u68d2\u6027\u7684\u63a7\u5236\u5668\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u8f85\u4ee5\u53ef\u8ba1\u7b97\u7684\u677e\u5f1b\u548c\u8fd1\u4f3c\u63a8\u65ad\uff0c\u4ee5\u53ca\u795e\u7ecf\u63a7\u5236\u5668\u7684\u95ed\u73af\u7a33\u5b9a\u6027\u4fdd\u8bc1\u3002\u901a\u8fc7\u4eff\u771f\u5c55\u793a\u5728\u5c0f\u6837\u672c\u60c5\u5f62\u4e0b\u7684\u9c81\u68d2\u6027\u63d0\u5347\uff0c\u5c24\u5176\u5728\u5408\u4f5c\u673a\u5668\u4eba\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5728SNOC\u4e2d\uff0c\u7531\u4e8e\u5bf9\u968f\u673a\u6270\u52a8\u7684\u671f\u671b\u901a\u5e38\u4e0d\u53ef\u76f4\u63a5\u8ba1\u7b97\uff0c\u901a\u5e38\u7528\u6709\u9650\u6270\u52a8\u6837\u672c\u7684\u7ecf\u9a8c\u4ee3\u4ef7\u6765\u8fd1\u4f3c\u3002\u4f46\u6709\u9650\u6570\u636e\u6613\u5bfc\u81f4\u8fc7\u62df\u5408\uff0c\u4ece\u800c\u5728\u672a\u89c1\u6270\u52a8\u4e0b\u7684\u90e8\u7f72\u4ee3\u4ef7\u4e0e\u7ecf\u9a8c\u4ee3\u4ef7\u4e4b\u95f4\u51fa\u73b0\u663e\u8457\u5dee\u8ddd\u3002\u9700\u8981\u4e00\u4e2a\u53ef\u4ee5\u5bf9\u672a\u89c1\u6270\u52a8\u63d0\u4f9b\u4e25\u683c\u6cdb\u5316\u4fdd\u8bc1\u7684\u6846\u67b6\u3002", "method": "\u5efa\u7acb\u57fa\u4e8ePAC-Bayes\u7684SNOC\u6cdb\u5316\u754c\u9650\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u63a7\u5236\u5668\u8bbe\u8ba1\u76ee\u6807\uff0c\u517c\u987e\u7ecf\u9a8c\u4ee3\u4ef7\u4e0e\u5148\u9a8c\u4fe1\u606f\u7684\u6743\u8861\uff1b\u63a8\u5bfc\u8ba1\u7b97\u53cb\u597d\u7684\u754c\u9650\u677e\u5f1b\u548c\u8fd1\u4f3c\u63a8\u65ad\u65b9\u6cd5\uff1b\u91c7\u7528\u8868\u8fbe\u6027\u5f3a\u7684\u795e\u7ecf\u63a7\u5236\u5668\u53c2\u6570\u5316\uff0c\u786e\u4fdd\u95ed\u73af\u7a33\u5b9a\u6027\u3002", "result": "\u7ed9\u51faSNOC\u7684PAC-Bayes\u6cdb\u5316\u754c\u9650\u53ca\u5176\u53ef\u64cd\u4f5c\u7684\u8bbe\u8ba1\u6846\u67b6\uff0c\u63d0\u4f9b\u754c\u9650\u7684\u677e\u5f1b\u4e0e\u8fd1\u4f3c\u63a8\u65ad\u4ee5\u5b9e\u73b0\u53ef\u8ba1\u7b97\u6027\uff1b\u5728\u4eff\u771f\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u5982\u4f55\u628a\u5148\u9a8c\u77e5\u8bc6\u878d\u5165\u8bbe\u8ba1\u5e76\u63d0\u9ad8\u5728\u5408\u4f5c\u673a\u5668\u4eba\u7b49\u573a\u666f\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5PAC-Bayes\u6846\u67b6\u4e3aSNOC\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u672a\u89c1\u6270\u52a8\u60c5\u5f62\u4e0b\u7684\u6027\u80fd\u4fdd\u8bc1\uff0c\u4e14\u901a\u8fc7\u5148\u9a8c\u4fe1\u606f\u548c\u795e\u7ecf\u63a7\u5236\u5668\u7684\u7ed3\u5408\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u63a7\u5236\u5668\u5408\u6210\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u53ef\u884c\u6027\u4e0e\u95ed\u73af\u7a33\u5b9a\u6027\u3002"}}
{"id": "2512.02206", "categories": ["cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2512.02206", "abs": "https://arxiv.org/abs/2512.02206", "authors": ["Orr Paradise", "Pranav Muralikrishnan", "Liangyuan Chen", "Hugo Flores Garc\u00eda", "Bryan Pardo", "Roee Diamant", "David F. Gruber", "Shane Gero", "Shafi Goldwasser"], "title": "WhAM: Towards A Translative Model of Sperm Whale Vocalization", "comment": "NeurIPS 2025", "summary": "Sperm whales communicate in short sequences of clicks known as codas. We present WhAM (Whale Acoustics Model), the first transformer-based model capable of generating synthetic sperm whale codas from any audio prompt. WhAM is built by finetuning VampNet, a masked acoustic token model pretrained on musical audio, using 10k coda recordings collected over the past two decades. Through iterative masked token prediction, WhAM generates high-fidelity synthetic codas that preserve key acoustic features of the source recordings. We evaluate WhAM's synthetic codas using Fr\u00e9chet Audio Distance and through perceptual studies with expert marine biologists. On downstream classification tasks including rhythm, social unit, and vowel classification, WhAM's learned representations achieve strong performance, despite being trained for generation rather than classification. Our code is available at https://github.com/Project-CETI/wham", "AI": {"tldr": "WhAM, a transformer-based generator for sperm whale codas, fine-tuned from VampNet on 10k codas, producing high-fidelity synthetic codas; evaluated with Fr\u00e9chet Audio Distance and expert perceptual studies; representations good for rhythm, social unit, and vowel classification; code released.", "motivation": "Address the lack of generative models for sperm whale codas and explore whether transfer learning from musical audio can yield high-quality bioacoustic generation and useful representations for downstream tasks.", "method": "Fine-tune a masked acoustic token model (VampNet) on ~10k coda recordings; employ iterative masked token prediction to generate codas; utilize transformer-based generation; evaluate with Fr\u00e9chet Audio Distance and perceptual tests by expert marine biologists; assess learned representations on rhythm, social unit, and vowel classification.", "result": "WhAM can generate high-fidelity synthetic codas that preserve key acoustic features of source recordings; learned representations achieve strong performance on downstream tasks (rhythm, social unit, vowel classification); code available at GitHub.", "conclusion": "Demonstrates feasibility of transformer-based generation for marine mammal codas, with potential applications in data augmentation and exploratory bioacoustics; encourages further work on generalization, ecological validity, and broader evaluation."}}
{"id": "2512.02603", "categories": ["cs.CR", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02603", "abs": "https://arxiv.org/abs/2512.02603", "authors": ["Daniel Camaz\u00f3n-Portela", "Juan Antonio L\u00f3pez-Ramos"], "title": "Semigroup action based on skew polynomial evaluation with applications to Cryptography", "comment": "Submitted to the International Journal of Computer Mathematics: Computer Systems Theory in March 2025", "summary": "Through this work we introduce an action of the skew polynomial ring $\\mathbb{F}_{q}\\left[X; \u03c3, \u03b4\\right]$ over $\\mathbb{F}_{q}$ based on its polynomial valuation and the concept of left skew product of functions. This lead us to explore the construction of a certain subset $\\mathcal{T}(X)\\subset\\mathbb{F}_{q}\\left[X; \u03c3, \u03b4\\right]$ that allow us to control the non-commutativity of this ring, and exploit this fact in order to build a public key exchange protocol that is secure in Canetti and Krawczyk model.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5728\u6709\u9650\u57df F_q \u4e0a\u7684\u4f2a\u591a\u9879\u5f0f\u73af F_q[X; \u03c3, \u03b4] \u7684\u4e00\u4e2a\u4f5c\u7528\uff0c\u57fa\u4e8e\u591a\u9879\u5f0f\u4f30\u503c\u548c\u5de6\u5411\u504f\u659c\u79ef\uff0c\u6784\u9020\u96c6\u5408 T(X) \u4ee5\u63a7\u5236\u975e\u4ea4\u6362\u6027\uff0c\u5e76\u7531\u6b64\u8bbe\u8ba1\u5728 Canetti-Krawczyk \u6a21\u578b\u4e0b\u5b89\u5168\u7684\u516c\u94a5\u4ea4\u6362\u534f\u8bae\u3002", "motivation": "\u7814\u7a76\u504f\u659c\u591a\u9879\u5f0f\u73af\u7684\u975e\u4ea4\u6362\u6027\u5bf9\u5bc6\u7801\u5b66\u534f\u8bae\u7684\u6f5c\u5728\u4f5c\u7528\uff0c\u63d0\u4f9b\u4e00\u79cd\u5728 CK \u6a21\u578b\u4e0b\u5177\u53ef\u884c\u6027\u7684\u65b0\u516c\u94a5\u4ea4\u6362\u65b9\u6848\u3002", "method": "\u5b9a\u4e49\u57fa\u4e8e\u591a\u9879\u5f0f\u4f30\u503c\u548c\u5de6\u5411\u504f\u659c\u79ef\u7684\u4f5c\u7528\uff1b\u6784\u9020\u5b50\u96c6 T(X) \u6765\u63a7\u5236\u975e\u4ea4\u6362\u6027\u5e76\u5206\u6790\u5176\u6027\u8d28\uff1b\u57fa\u4e8e\u8be5\u7ed3\u6784\u8bbe\u8ba1\u516c\u94a5\u4ea4\u6362\u534f\u8bae\u5e76\u8ba8\u8bba\u5b89\u5168\u6027\u8981\u70b9\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u64cd\u4f5c\u7684\u6846\u67b6\u4e0e\u96c6\u5408 T(X)\uff0c\u7528\u4e8e\u628a\u63a7\u975e\u4ea4\u6362\u6027\uff0c\u5e76\u636e\u6b64\u6784\u5efa\u4e00\u4e2a\u5728 CK \u6a21\u578b\u4e0b\u7684\u516c\u94a5\u4ea4\u6362\u534f\u8bae\uff0c\u7ed9\u51fa\u8bbe\u8ba1\u601d\u8def\u4e0e\u53ef\u884c\u6027\u5206\u6790\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u5229\u7528\u504f\u659c\u591a\u9879\u5f0f\u73af\u975e\u4ea4\u6362\u6027\u7684\u5bc6\u7801\u5b66\u6846\u67b6\uff0c\u4e3a\u57fa\u4e8e\u975e\u5bf9\u79f0\u4ee3\u6570\u7684\u516c\u94a5\u4ea4\u6362\u63d0\u4f9b\u65b0\u7684\u65b9\u5411\uff0c\u672a\u6765\u9700\u8fdb\u884c\u4e25\u683c\u7684\u5b89\u5168\u8bc1\u660e\u4e0e\u53c2\u6570\u8bbe\u8ba1\u3002"}}
{"id": "2512.02768", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02768", "abs": "https://arxiv.org/abs/2512.02768", "authors": ["Hefei Gao", "Tianyao Huang", "Letian Guo", "Jie He", "Yonina C. Eldar"], "title": "Diffusion-Prior Split Gibbs Sampling for Synthetic Aperture Radar Imaging under Incomplete Measurements", "comment": null, "summary": "Synthetic aperture radar (SAR) imaging plays a critical role in all-weather, day-and-night remote sensing, yet reconstruction is often challenged by noise, undersampling, and complex scattering scenarios. Conventional methods, including matched filtering and sparsity-based compressed sensing, are limited in capturing intricate scene structures and frequently suffer from artifacts, elevated sidelobes, and loss of fine details. Recent diffusion models have demonstrated superior capability in representing high-order priors; however, existing diffusion-based SAR methods still yield degraded reconstructions due to oversimplified likelihood approximations in guided sampling. In this work, we propose a diffusion-driven split Gibbs sampling framework for SAR reconstruction, rigorously integrating measurement fidelity with learned diffusion priors. By alternately performing likelihood- and prior-driven updates via proximal sampling, this method ensures progressive convergence toward the true posterior while fully leveraging the expressive power of diffusion priors. Extensive experiments on simulated and Sentinel-1A datasets demonstrate substantial performance improvements: over 7 dB average PSNR gain in simulations, along with significant sidelobe suppression (MPLSR +2.96 dB, MISLR +11.5 dB) with respect to the best baseline result. On real-world Sentinel-1A data, the method achieves an average PSNR gain of 1.6 dB while effectively reducing artifacts and preserving scene details, including ridges, edges, and fine textures. These results underscore the potential of the adapted framework as a robust and generalizable solution for high-fidelity SAR imaging across diverse sensing scenarios.", "AI": {"tldr": "A diffusion-driven split Gibbs sampling framework for SAR reconstruction that fuses measurement fidelity with learned diffusion priors, achieving state-of-the-art PSNR gains and sidelobe suppression on simulated and Sentinel-1A data.", "motivation": "SAR imaging is hampered by noise, undersampling, and complex scattering; conventional methods struggle with artifacts and loss of detail. Although diffusion models offer strong high-order priors, prior diffusion-based SAR methods rely on oversimplified likelihoods, leading to degraded reconstructions. A rigorous posterior-guided approach is needed.", "method": "Propose a diffusion-driven split Gibbs sampling framework. Alternate likelihood- and prior-driven updates via proximal sampling to progressively approximate the true posterior, integrating measurement fidelity with learned diffusion priors and leveraging diffusion models for priors.", "result": "On simulated data: >7 dB average PSNR gain; significant sidelobe suppression (MPLSR +2.96 dB, MISLR +11.5 dB) vs. best baseline. On real Sentinel-1A data: average PSNR gain ~1.6 dB with reduced artifacts and preserved ridges, edges, and fine textures.", "conclusion": "The framework is robust and generalizable for high-fidelity SAR imaging across diverse sensing scenarios, illustrating the potential of combining diffusion priors with proximal sampling in a split Gibbs scheme to improve reconstruction quality."}}
{"id": "2512.02513", "categories": ["cs.LG", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02513", "abs": "https://arxiv.org/abs/2512.02513", "authors": ["Krishnendu S. Tharakan", "Carlo Fischione"], "title": "Decentralized Fairness Aware Multi Task Federated Learning for VR Network", "comment": "accepted for IEEE Globecom Workshop 2025", "summary": "Wireless connectivity promises to unshackle virtual reality (VR) experiences, allowing users to engage from anywhere, anytime. However, delivering seamless, high-quality, real-time VR video wirelessly is challenging due to the stringent quality of experience requirements, low latency constraints, and limited VR device capabilities. This paper addresses these challenges by introducing a novel decentralized multi task fair federated learning (DMTFL) based caching that caches and prefetches each VR user's field of view (FOV) at base stations (BSs) based on the caching strategies tailored to each BS. In federated learning (FL) in its naive form, often biases toward certain users, and a single global model fails to capture the statistical heterogeneity across users and BSs. In contrast, the proposed DMTFL algorithm personalizes content delivery by learning individual caching models at each BS. These models are further optimized to perform well under any target distribution, while providing theoretical guarantees via Rademacher complexity and a probably approximately correct (PAC) bound on the loss. Using a realistic VR head-tracking dataset, our simulations demonstrate the superiority of our proposed DMTFL algorithm compared to baseline algorithms.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.02872", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.02872", "abs": "https://arxiv.org/abs/2512.02872", "authors": ["Dongyeong Lee", "Eros Avdiaj", "Jef Beerten"], "title": "AC/DC Frequency-Dependent Power Flow Jacobian: Quantifying Grid Support and Stability Implications", "comment": "3 pages, 5 figures", "summary": "This letter proposes an AC/DC frequency-dependent power flow Jacobian analysis to identify the system support capabilities. In addition, the analyses reveal that system support capabilities do not necessarily enhance the system stability margin, suggesting that technical requirements of narrow-frequency-band and AC-side focused specifications may not lead to the expected performance of GFM.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.02213", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02213", "abs": "https://arxiv.org/abs/2512.02213", "authors": ["Mamadou K. Keita", "Sebastien Diarra", "Christopher Homan", "Seydou Diallo"], "title": "InstructLR: A Scalable Approach to Create Instruction Dataset for Under-Resourced Languages", "comment": null, "summary": "Effective text generation and chat interfaces for low-resource languages (LRLs) remain a challenge for state-of-the-art large language models (LLMs) to support. This is mainly due to the difficulty of curating high-quality instruction datasets for LRLs, a limitation prevalent in the languages spoken across the African continent and other regions. Current approaches, such as automated translation and synthetic data generation, frequently yield outputs that lack fluency or even orthographic consistency. In this paper, we introduce InstructLR, a novel framework designed to generate high-quality instruction datasets for LRLs. Our approach integrates LLM-driven text generation with a dual-layer quality filtering mechanism: an automated filtering layer based on retrieval-augmented-generation (RAG)-based n-shot prompting, and a human-in-the-loop validation layer. Drawing inspiration from benchmarks such as MMLU in task definition, InstructLR has facilitated the creation of three multi-domain instruction benchmarks: ZarmaInstruct-50k, BambaraInstruct-50k, and FulfuldeInstruct-50k.", "AI": {"tldr": "\u63d0\u51fa InstructLR \u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408 LLM \u751f\u6210\u4e0e\u53cc\u5c42\u8d28\u91cf\u7b5b\u9009\u6765\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08LRL\uff09\u751f\u6210\u9ad8\u8d28\u91cf\u6307\u4ee4\u6570\u636e\u96c6\uff0c\u4ea7\u51fa\u4e09\u9879 50k \u89c4\u6a21\u7684\u8de8\u57df\u57fa\u51c6\u6570\u636e\u96c6\uff08ZarmaInstruct-50k\u3001BambaraInstruct-50k\u3001FulfuldeInstruct-50k\uff09\u3002", "motivation": "LRL \u7684\u9ad8\u8d28\u91cf\u6307\u4ee4\u6570\u636e\u96c6\u532e\u4e4f\uff0c\u96be\u4ee5\u652f\u6491\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6307\u4ee4\u5f0f\u80fd\u529b\u3002\u81ea\u52a8\u7ffb\u8bd1\u548c\u5408\u6210\u6570\u636e\u5f80\u5f80\u7f3a\u4e4f\u6d41\u7545\u6027\u548c\u6b63\u5b57\u4e00\u81f4\u6027\uff0c\u8feb\u5207\u9700\u8981\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u8d28\u91cf\u53ef\u63a7\u7684\u6570\u636e\u751f\u6210\u4e0e\u7b5b\u9009\u6846\u67b6\u3002\u4ee5 MMLU \u7b49\u57fa\u51c6\u542f\u53d1\uff0c\u5728\u591a\u57df\u573a\u666f\u4e0b\u6784\u5efa\u7a33\u5b9a\u7684\u6307\u4ee4\u6570\u636e\u3002", "method": "\u901a\u8fc7 LLM \u8fdb\u884c\u6587\u672c\u751f\u6210\uff0c\u7ed3\u5408\u4e24\u5c42\u8d28\u91cf\u7b5b\u9009\uff1a\u7b2c\u4e00\u5c42\u662f\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684 n-shot \u63d0\u793a\u8fdb\u884c\u81ea\u52a8\u5316\u7b5b\u9009\uff1b\u7b2c\u4e8c\u5c42\u4e3a\u4eba\u5de5\u5e72\u9884\u7684\u9a8c\u8bc1\u73af\u8282\uff0c\u786e\u4fdd\u6570\u636e\u7684\u53ef\u7528\u6027\u548c\u8bed\u8a00\u89c4\u8303\u6027\u3002\u7531\u6b64\u751f\u6210 ZarmaInstruct-50k\u3001BambaraInstruct-50k\u3001FulfuldeInstruct-50k \u7b49\u591a\u57df\u6307\u4ee4\u57fa\u51c6\u3002", "result": "\u5b9e\u73b0\u4e86\u9762\u5411\u82e5\u5e72\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u9ad8\u8d28\u91cf\u6307\u4ee4\u6570\u636e\u96c6\u751f\u6210\u6846\u67b6\uff0c\u5e76\u4ea7\u51fa\u4e09\u9879 50k \u89c4\u6a21\u7684\u591a\u57df\u6307\u4ee4\u57fa\u51c6\uff0c\u4e3a LR LLM \u652f\u6301\u63d0\u4f9b\u6570\u636e\u652f\u6491\u4e0e\u8bc4\u4f30\u57fa\u51c6\u3002", "conclusion": "InstructLR \u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u4f4e\u8d44\u6e90\u8bed\u8a00\u6307\u4ee4\u6570\u636e\u751f\u6210\u4e0e\u8d28\u91cf\u63a7\u5236\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u81ea\u52a8\u5316\u4e0e\u4eba\u5de5\u6821\u9a8c\uff0c\u964d\u4f4e\u4e86\u9ad8\u8d28\u91cf\u6570\u636e\u7684\u83b7\u53d6\u95e8\u69db\uff0c\u9884\u8ba1\u63d0\u5347 LR LLM \u5728\u6307\u4ee4\u9075\u5faa\u4e0e\u591a\u57df\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2512.02625", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02625", "abs": "https://arxiv.org/abs/2512.02625", "authors": ["Mayar Elfares", "Pascal Reisert", "Tilman Dietz", "Manpa Barman", "Ahmed Zaki", "Ralf K\u00fcsters", "Andreas Bulling"], "title": "CryptoQA: A Large-scale Question-answering Dataset for AI-assisted Cryptography", "comment": null, "summary": "Large language models (LLMs) excel at many general-purpose natural language processing tasks. However, their ability to perform deep reasoning and mathematical analysis, particularly for complex tasks as required in cryptography, remains poorly understood, largely due to the lack of suitable data for evaluation and training. To address this gap, we present CryptoQA, the first large-scale question-answering (QA) dataset specifically designed for cryptography. CryptoQA contains over two million QA pairs drawn from curated academic sources, along with contextual metadata that can be used to test the cryptographic capabilities of LLMs and to train new LLMs on cryptographic tasks. We benchmark 15 state-of-the-art LLMs on CryptoQA, evaluating their factual accuracy, mathematical reasoning, consistency, referencing, backward reasoning, and robustness to adversarial samples. In addition to quantitative metrics, we provide expert reviews that qualitatively assess model outputs and establish a gold-standard baseline. Our results reveal significant performance deficits of LLMs, particularly on tasks that require formal reasoning and precise mathematical knowledge. This shows the urgent need for LLM assistants tailored to cryptography research and development. We demonstrate that, by using CryptoQA, LLMs can be fine-tuned to exhibit better performance on cryptographic tasks.", "AI": {"tldr": "CryptoQA\uff1a\u9996\u4e2a\u7528\u4e8e\u5bc6\u7801\u5b66\u7684\u5927\u89c4\u6a21\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u63ed\u793a\u5927\u6a21\u578b\u5728\u5bc6\u7801\u5b66\u63a8\u7406\u4e0e\u7cbe\u786e\u6570\u5b66\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u663e\u793a\u901a\u8fc7\u4e13\u95e8\u6570\u636e\u53ef\u63d0\u5347\u8be5\u9886\u57df\u6027\u80fd\u3002", "motivation": "\u5bc6\u7801\u5b66\u7814\u7a76\u5bf9\u6df1\u5c42\u63a8\u7406\u548c\u4e25\u683c\u6570\u5b66\u63a8\u7406\u7684\u9700\u6c42\u9ad8\uff0c\u4f46\u73b0\u6709\u6570\u636e\u5bf9\u8bc4\u4f30\u4e0e\u8bad\u7ec3LLMs\u5728\u6b64\u9886\u57df\u7684\u80fd\u529b\u4e0d\u8db3\u3002\u7f3a\u4e4f\u9488\u5bf9\u5bc6\u7801\u5b66\u4efb\u52a1\u7684\u4e13\u4e1a\u6570\u636e\u96c6\u59a8\u788d\u6a21\u578b\u7684\u5f00\u53d1\u4e0e\u5bf9\u6bd4\u3002", "method": "\u6784\u5efaCryptoQA\uff1a\u4ece\u7cbe\u9009\u5b66\u672f\u8d44\u6e90\u4e2d\u62bd\u53d6\u5e76\u751f\u6210\u8d85\u8fc7200\u4e07\u5bf9\u95ee\u7b54\uff0c\u9644\u5e26\u4e0a\u4e0b\u6587\u5143\u6570\u636e\u4ee5\u6d4b\u8bd5\u5e76\u8bad\u7ec3LLMs\u5728\u5bc6\u7801\u5b66\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff1b\u5bf915\u79cd\u524d\u6cbfLLMs\u8fdb\u884c\u5168\u9762\u57fa\u51c6\u8bc4\u4f30\uff0c\u8003\u5bdf\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u6570\u5b66\u63a8\u7406\u3001\u8fde\u8d2f\u6027\u3001\u5f15\u7528\u3001\u5411\u540e\u63a8\u7406\u4ee5\u53ca\u5bf9\u5bf9\u6297\u6837\u672c\u7684\u9c81\u68d2\u6027\uff1b\u63d0\u4f9b\u4e13\u5bb6\u8bc4\u5ba1\u4e0e\u9ec4\u91d1\u57fa\u7ebf\uff0c\u5e76\u5c55\u793a\u901a\u8fc7CryptoQA\u5bf9LLMs\u8fdb\u884c\u5fae\u8c03\u4ee5\u63d0\u5347\u5728\u5bc6\u7801\u5b66\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u6a21\u578b\u5728\u9700\u8981\u4e25\u8c28\u5f62\u5f0f\u5316\u63a8\u7406\u548c\u7cbe\u786e\u6570\u5b66\u77e5\u8bc6\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u663e\u8457\u4e0d\u8db3\uff1b\u901a\u8fc7\u5728CryptoQA\u4e0a\u7684\u5fae\u8c03\uff0cLLMs\u5728\u5bc6\u7801\u5b66\u4efb\u52a1\u4e0a\u6709\u53ef\u89c2\u63d0\u5347\u3002\u6570\u636e\u96c6\u8fd8\u5177\u5907\u8bad\u7ec3\u65b0\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u4e14\u53ef\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u7684\u63a8\u7406\u4e0e\u9c81\u68d2\u6027\u7b49\u7ef4\u5ea6\u3002", "conclusion": "CryptoQA\u8bc1\u660e\u4e86\u4e3a\u5bc6\u7801\u5b66\u4e13\u95e8\u8bbe\u8ba1\u7684LLM\u52a9\u624b\u7684\u8feb\u5207\u6027\uff1b\u8be5\u6570\u636e\u96c6\u4e0d\u4ec5\u662f\u8bc4\u4f30\u57fa\u51c6\uff0c\u4e5f\u662f\u8bad\u7ec3\u8d44\u6e90\uff0c\u80fd\u591f\u63a8\u52a8\u5bc6\u7801\u5b66\u7814\u7a76\u4e0e\u5f00\u53d1\u4e2d\u7684AI\u8f85\u52a9\u5de5\u5177\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.02893", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.02893", "abs": "https://arxiv.org/abs/2512.02893", "authors": ["Yuang Geng", "Thomas Waite", "Trevor Turnquist", "Radoslav Ivanov", "Ivan Ruchkin"], "title": "Statistical-Symbolic Verification of Perception-Based Autonomous Systems using State-Dependent Conformal Prediction", "comment": "The first and second authors contributed equally. The last two authors shared the supervision equally", "summary": "Reachability analysis has been a prominent way to provide safety guarantees for neurally controlled autonomous systems, but its direct application to neural perception components is infeasible due to imperfect or intractable perception models. Typically, this issue has been bypassed by complementing reachability with statistical analysis of perception error, say with conformal prediction (CP). However, existing CP methods for time-series data often provide conservative bounds. The corresponding error accumulation over time has made it challenging to combine statistical bounds with symbolic reachability in a way that is provable, scalable, and minimally conservative. To reduce conservatism and improve scalability, our key insight is that perception error varies significantly with the system's dynamical state. This article proposes state-dependent conformal prediction, which exploits that dependency in constructing tight high-confidence bounds on perception error. Based on this idea, we provide an approach to partition the state space, using a genetic algorithm, so as to optimize the tightness of conformal bounds. Finally, since using these bounds in reachability analysis leads to additional uncertainty and branching in the resulting hybrid system, we propose a branch-merging reachability algorithm that trades off uncertainty for scalability so as to enable scalable and tight verification. The evaluation of our verification methodology on two complementary case studies demonstrates reduced conservatism compared to the state of the art.", "AI": {"tldr": "\u63d0\u51fa\u72b6\u6001\u81ea\u9002\u5e94\u7684 conformal prediction\u3001\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u72b6\u6001\u5206\u533a\uff0c\u4ee5\u53ca\u5206\u652f\u5408\u5e76\u53ef\u8fbe\u6027\u5206\u6790\uff0c\u4ee5\u964d\u4f4e\u611f\u77e5\u8bef\u5dee\u5e26\u6765\u7684\u4fdd\u5b88\u6027\u5e76\u63d0\u5347\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u795e\u7ecf\u611f\u77e5\u7ec4\u4ef6\u5bfc\u81f4\u7684\u4e0d\u53ef\u63a7\u8bef\u5dee\u4f7f\u76f4\u63a5\u7684\u53ef\u8fbe\u6027\u5206\u6790\u4e0d\u53ef\u884c\uff1b\u73b0\u6709\u7684\u65f6\u95f4\u5e8f\u5217 conformal prediction \u5f80\u5f80\u8fc7\u4e8e\u4fdd\u5b88\uff0c\u96be\u4ee5\u4e0e\u7b26\u53f7\u53ef\u8fbe\u6027\u7ed3\u5408\u4e14\u6269\u5c55\u6027\u5dee\u3002\u9700\u8981\u66f4\u7d27\u51d1\u3001\u53ef\u8bc1\u660e\u3001\u53ef\u6269\u5c55\u7684\u8bef\u5dee\u754c\u6765\u652f\u6491\u5b89\u5168\u9a8c\u8bc1\u3002", "method": "1) \u5f15\u5165\u72b6\u6001\u4f9d\u8d56\u7684 conformal prediction\uff0c\u5229\u7528\u7cfb\u7edf\u72b6\u6001\u7684\u53d8\u5316\u6765\u6784\u9020\u66f4\u7d27\u7684\u611f\u77e5\u8bef\u5dee\u754c\uff1b2) \u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u5bf9\u72b6\u6001\u7a7a\u95f4\u8fdb\u884c\u5206\u533a\u4ee5\u4f18\u5316 CP \u8fb9\u754c\u7684\u7d27\u5ea6\uff1b3) \u5c06\u8bef\u5dee\u8fb9\u754c\u7528\u4e8e\u53ef\u8fbe\u6027\u5206\u6790\uff0c\u63d0\u51fa\u5206\u652f\u5408\u5e76\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u964d\u4f4e\u5206\u652f\u6570\u91cf\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u9ad8\u7f6e\u4fe1\u5ea6\u9a8c\u8bc1\u3002", "result": "\u5728\u4e24\u4e2a\u4e92\u8865\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u4fdd\u5b88\u6027\u548c\u66f4\u7d27\u7684\u754c\u9650\uff0c\u5e76\u63d0\u5347\u4e86\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u72b6\u6001\u4f9d\u8d56\u6027\u662f\u964d\u4f4e\u53ef\u8fbe\u6027\u5206\u6790\u4fdd\u5b88\u6027\u7684\u5173\u952e\uff1b\u57fa\u4e8e\u72b6\u6001\u5206\u533a\u7684 CP \u4e0e\u5206\u652f\u5408\u5e76\u7684\u53ef\u8fbe\u6027\u6846\u67b6\u53ef\u63d0\u4f9b\u53ef\u8bc1\u660e\u3001\u53ef\u6269\u5c55\u7684\u5b89\u5168\u9a8c\u8bc1\u3002"}}
{"id": "2512.02994", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02994", "abs": "https://arxiv.org/abs/2512.02994", "authors": ["Abdelgabar Ahmed", "Tarig Ballal", "Xing Liu", "Mohanad Ahmed", "Tareq Y. Al-Naffouri"], "title": "GNSS Array-Based Multipath Detection Employing UKF on Manifolds", "comment": "The paper, was presented at the ION PLANS 2025 meeting (Position, Location, and Navigation Symposium) in Session C1: Multisensor Integrated Systems and Sensor Fusion Technologies, and is published in the conference proceedings", "summary": "Global Navigation Satellite Systems (GNSS) applications are often hindered by various sources of error, with multipath interference being one of the most challenging, particularly in urban environments. In this work, we build on previous research by implementing a GNSS array-based multipath detection algorithm, incorporating real-time attitude estimation for dynamic scenarios. The method fuses GNSS and IMU data using an Unscented Kalman Filter (UKF) on a manifold, enabling continuous attitude tracking. The proposed approach utilizes attitude information from satellite combinations to identify and exclude multipath-affected satellites, improving the accuracy of both positioning and attitude determination. To address computational challenges associated with evaluating large numbers of satellite combinations, we propose the use of the Random Sample Consensus (RANSAC) algorithm, which reduces the number of combinations assessed while maintaining high detection performance. Performance evaluations are conducted using trajectories and IMU readings from the KITTI dataset. GNSS observations are simulated based on ground truth positions and satellite ephemeris. The results demonstrate the effectiveness of the proposed approach in detecting satellites affected by multipath interference. Significant improvements in positioning accuracy are observed, particularly in scenarios where a large portion of the visible satellites are contaminated by severe multipath.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u6d41\u5f62\u4e0a\u7684UKF GNSS/IMU \u878d\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u59ff\u6001\u4fe1\u606f\u7b5b\u9009\u591a\u5f84\u536b\u661f\u5e76\u4f7f\u7528RANSAC\u964d\u4f4e\u536b\u661f\u7ec4\u5408\u6570\u91cf\uff0c\u5728KITTI\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u5728\u5f3a\u591a\u5f84\u573a\u666f\u4e2d\u7684\u5b9a\u4f4d\u4e0e\u59ff\u6001\u7cbe\u5ea6\u3002", "motivation": "\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u591a\u5f84\u5e72\u6270\u662fGNSS \u7cbe\u5ea6\u7684\u4e3b\u8981\u74f6\u9888\u4e4b\u4e00\uff0c\u9700\u8981\u901a\u8fc7\u68c0\u6d4b\u5e76\u5254\u9664\u591a\u5f84\u536b\u661f\u6765\u63d0\u5347\u5b9a\u4f4d\u4e0e\u59ff\u6001\u63a8\u7b97\u7684\u9c81\u68d2\u6027\uff0c\u4e14\u9700\u5728\u5b9e\u65f6\u52a8\u6001\u573a\u666f\u4e2d\u4fdd\u6301\u7a33\u5b9a\u4f30\u8ba1\u3002", "method": "\u5728\u6d41\u5f62\u4e0a\u5bf9GNSS \u4e0eIMU \u8fdb\u884cUKF \u878d\u5408\u4ee5\u5b9e\u73b0\u6301\u7eed\u59ff\u6001\u8ddf\u8e2a\uff1b\u5229\u7528\u536b\u661f\u7ec4\u5408\u4fe1\u606f\u6765\u8bc6\u522b\u88ab\u591a\u5f84\u6c61\u67d3\u7684\u536b\u661f\u5e76\u5254\u9664\uff1b\u4e3a\u964d\u4f4e\u7ec4\u5408\u6570\u91cf\u5e26\u6765\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u91c7\u7528RANSAC \u4ee5\u9009\u53d6\u5177\u6709\u8f83\u597d\u9c81\u68d2\u6027\u7684\u536b\u661f\u7ec4\u5408\u8fdb\u884c\u68c0\u6d4b\uff1b\u89c2\u6d4b\u6570\u636e\u5728KITTI \u573a\u666f\u4e0b\u57fa\u4e8e\u771f\u5b9e\u4f4d\u7f6e\u4fe1\u606f\u548c\u661f\u5386\u8fdb\u884cGNSS \u6a21\u62df\u3002", "result": "\u65b9\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u53d7\u591a\u5f84\u5e72\u6270\u7684\u536b\u661f\uff0c\u5728\u5927\u90e8\u5206\u53ef\u89c1\u536b\u661f\u88ab\u5f3a\u591a\u5f84\u6c61\u67d3\u7684\u573a\u666f\u4e2d\u5b9e\u73b0\u5b9a\u4f4d\u7cbe\u5ea6\u7684\u663e\u8457\u63d0\u5347\uff0c\u5e76\u63d0\u5347\u59ff\u6001\u4f30\u8ba1\u7684\u7a33\u5b9a\u6027\u4e0e\u7cbe\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u5c06\u59ff\u6001\u4fe1\u606f\u4e0eGNSS/IMU \u878d\u5408\u5728\u6d41\u5f62\u4e0a\u7684UKF \u4ee5\u53caRANSAC \u7684\u591a\u536b\u661f\u7ec4\u5408\u7b5b\u9009\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u9c81\u68d2\u7684\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u4e0e\u59ff\u6001\u4f30\u8ba1\u65b9\u6848\uff0c\u5c24\u5176\u5728\u591a\u5f84\u6c61\u67d3\u4e25\u91cd\u7684\u573a\u666f\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2512.02822", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.02822", "abs": "https://arxiv.org/abs/2512.02822", "authors": ["Meir Ariel"], "title": "Decryption thorough polynomial ambiguity: noise-enhanced high-memory convolutional codes for post-quantum cryptography", "comment": "23 pages, 3 figures", "summary": "We present a novel approach to post-quantum cryptography that employs directed-graph decryption of noise-enhanced high-memory convolutional codes. The proposed construction generates random-like generator matrices that effectively conceal algebraic structure and resist known structural attacks. Security is further reinforced by the deliberate injection of strong noise during decryption, arising from polynomial division: while legitimate recipients retain polynomial-time decoding, adversaries face exponential-time complexity. As a result, the scheme achieves cryptanalytic security margins surpassing those of Classic McEliece by factors exceeding 2^(200). Beyond its enhanced security, the method offers greater design flexibility, supporting arbitrary plaintext lengths with linear-time decryption and uniform per-bit computational cost, enabling seamless scalability to long messages. Practical deployment is facilitated by parallel arrays of directed-graph decoders, which identify the correct plaintext through polynomial ambiguity while allowing efficient hardware and software implementations. Altogether, the scheme represents a compelling candidate for robust, scalable, and quantum-resistant public-key cryptography.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u540e\u91cf\u5b50\u516c\u94a5\u5bc6\u7801\u4f53\u5236\uff0c\u5229\u7528\u6709\u5411\u56fe\u89e3\u7801\u7684\u566a\u58f0\u589e\u5f3a\u9ad8\u8bb0\u5fc6\u5377\u79ef\u7801\uff0c\u751f\u6210\u4f2a\u968f\u673a\u751f\u6210\u77e9\u9635\u4ee5\u9690\u85cf\u4ee3\u6570\u7ed3\u6784\u5e76\u62b5\u6297\u7ed3\u6784\u6027\u653b\u51fb\u3002\u901a\u8fc7\u5728\u89e3\u5bc6\u8fc7\u7a0b\u5f15\u5165\u5f3a\u566a\u58f0\uff0c\u5408\u6cd5\u65b9\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u89e3\u7801\uff0c\u800c\u653b\u51fb\u8005\u5219\u9700\u6307\u6570\u65f6\u95f4\u3002\u58f0\u79f0\u5b89\u5168\u88d5\u5ea6\u8d85\u8d8a Classic McEliece \u8d85\u8fc7 2^200\uff0c\u5e76\u652f\u6301\u7ebf\u6027\u65f6\u95f4\u89e3\u5bc6\u3001\u7edf\u4e00\u6bd4\u7279\u5f00\u9500\u4e0e\u957f\u6d88\u606f\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e14\u53ef\u901a\u8fc7\u5e76\u884c\u89e3\u7801\u5668\u786c\u4ef6/\u8f6f\u4ef6\u5b9e\u73b0\u3002", "motivation": "\u5e94\u5bf9\u91cf\u5b50\u8ba1\u7b97\u65f6\u4ee3\u7684\u516c\u94a5\u5bc6\u7801\u5b66\u9700\u6c42\uff0c\u63d0\u5347\u5bf9\u6297\u7ed3\u6784\u6027\u653b\u51fb\u7684\u5b89\u5168\u88d5\u5ea6\uff0c\u63d0\u4f9b\u5bf9\u957f\u671f\u3001\u53ef\u6269\u5c55\u6d88\u606f\u7684\u7ebf\u6027\u65f6\u95f4\u89e3\u5bc6\u80fd\u529b\uff0c\u4ee5\u53ca\u5728\u786c\u4ef6\u5b9e\u73b0\u4e2d\u7684\u9ad8\u6548\u5e76\u884c\u6027\u3002", "method": "\u901a\u8fc7\u6709\u5411\u56fe\u6784\u9020\u751f\u6210\u77e9\u9635\u4ee5\u83b7\u5f97\u968f\u673a\u6027\u5e76\u9690\u85cf\u4ee3\u6570\u7ed3\u6784\uff0c\u5728\u89e3\u5bc6\u9636\u6bb5\u6545\u610f\u6ce8\u5165\u566a\u58f0\uff0c\u4f7f\u5f97\u5bf9\u65b9\u7684\u591a\u9879\u5f0f\u9664\u6cd5\u4ea7\u751f\u7684\u566a\u58f0\u5e72\u6270\u5bfc\u81f4\u9ad8\u590d\u6742\u5ea6\u653b\u51fb\uff1b\u5408\u6cd5\u63a5\u6536\u8005\u80fd\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u89e3\u7801\uff0c\u653b\u51fb\u8005\u5219\u9700\u8981\u6307\u6570\u65f6\u95f4\uff1b\u5229\u7528\u5e76\u884c\u7684\u6709\u5411\u56fe\u89e3\u7801\u5668\u9635\u5217\u5728\u591a\u9879\u5f0f\u6b67\u4e49\u6027\u4e2d\u8bc6\u522b\u6b63\u786e\u660e\u6587\uff0c\u8fbe\u5230\u7ebf\u6027\u65f6\u95f4\u3001\u6309\u4f4d\u4e00\u81f4\u6210\u672c\u548c\u5bf9\u957f\u6d88\u606f\u7684\u53ef\u6269\u5c55\u6027\u3002", "result": "\u58f0\u79f0\u5728\u5bf9\u6bd4 Classic McEliece \u7684\u5b89\u5168\u88d5\u5ea6\u65b9\u9762\u8d85\u51fa2^200\u7684\u56e0\u5b50\uff0c\u4e14\u5177\u6709\u7ebf\u6027\u65f6\u95f4\u89e3\u5bc6\u3001\u7edf\u4e00\u6210\u672c\u3001\u4ee5\u53ca\u53ef\u6269\u5c55\u5230\u5f88\u957f\u6d88\u606f\u957f\u5ea6\u7684\u80fd\u529b\uff0c\u7406\u8bba\u4e0a\u652f\u6301\u5e76\u884c\u5316\u90e8\u7f72\u3002", "conclusion": "\u8be5\u65b9\u6848\u88ab\u63cf\u7ed8\u4e3a\u9c81\u68d2\u3001\u53ef\u6269\u5c55\u4e14\u5177\u91cf\u5b50\u6297\u6027\u516c\u94a5\u5bc6\u7801\u5b66\u7684\u6709\u529b\u5019\u9009\u8005\uff0c\u8bbe\u8ba1\u7075\u6d3b\u6027\u8f83\u9ad8\uff0c\u73b0\u5b9e\u90e8\u7f72\u53ef\u901a\u8fc7\u5e76\u884c\u89e3\u7801\u7ed3\u6784\u5b9e\u73b0\u3002"}}
{"id": "2512.02918", "categories": ["cs.CR", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02918", "abs": "https://arxiv.org/abs/2512.02918", "authors": ["Wanxu Xia", "Ziqiao Kong", "Zhengwei Li", "Yi Lu", "Pan Li", "Liqun Yang", "Yang Liu", "Xiapu Luo", "Shaohua Li"], "title": "Belobog: Move Language Fuzzing Framework For Real-World Smart Contracts", "comment": "Slight revision and under review", "summary": "Move is a research-oriented programming language design for secure and verifiable smart contract development and has been widely used in managing billions of digital assets in blockchains, such as Sui and Aptos. Move features a strong static type system and explicit resource semantics to enforce safety properties such as the prevention of data races, invalid asset transfers, and entry vulnerabilities. However, smart contracts written in Move may still contain certain vulnerabilities that are beyond the reach of its type system. It is thus essential to validate Move smart contracts. Unfortunately, due to its strong type system, existing smart contract fuzzers are ineffective in producing syntactically or semantically valid transactions to test Move smart contracts. This paper introduces the first fuzzing framework, Belobog, for Move smart contracts. Belobog is type-aware and ensures that all generated and mutated transactions are well-typed. More specifically, for a target Move smart contract, Belobog first constructs a type graph based on Move's type system, and then generates or mutates a transaction based on the graph trace derived from the type graph. In order to overcome the complex checks in Move smart contracts, we further design and implement a concolic executor in Belobog. We evaluated Belobog on 109 real-world Move smart contract projects. The experimental results show that Belobog is able to detect 100\\% critical and 79\\% major vulnerabilities manually audited by human experts. We further selected two recent notorious incidents in Move smart contracts, i.e., Cetus and Nemo. Belobog successfully reproduced full exploits for both of them, without any prior knowledge.", "AI": {"tldr": "\u4e00\u79cd\u9762\u5411 Move \u7684\u7c7b\u578b\u611f\u77e5\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6 Belobog\uff0c\u901a\u8fc7\u7c7b\u578b\u56fe\u9a71\u52a8\u4ea4\u6613\u751f\u6210\uff0c\u7ed3\u5408 concolic \u6267\u884c\u5b9e\u73b0\u9ad8\u6548\u6f0f\u6d1e\u68c0\u6d4b\u4e0e\u653b\u51fb\u590d\u73b0\u3002", "motivation": "Move \u7684\u5f3a\u7c7b\u578b\u7cfb\u7edf\u5bf9\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u7684\u6709\u6548\u6027\u6784\u6210\u6311\u6218\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u4ea7\u51fa\u7c7b\u578b\u6b63\u786e\u7684\u4ea4\u6613\u4ee5\u6d4b\u8bd5\u5408\u7ea6\u5b89\u5168\u6027\u7684\u6846\u67b6\uff1b\u540c\u65f6\u9700\u8981\u80fd\u591f\u53d1\u73b0\u7c7b\u578b\u7cfb\u7edf\u5916\u7684\u6f0f\u6d1e\uff0c\u5e76\u80fd\u590d\u73b0\u771f\u5b9e\u653b\u51fb\u3002", "method": "\u57fa\u4e8e Move \u7684\u7c7b\u578b\u7cfb\u7edf\u6784\u5efa\u7c7b\u578b\u56fe\uff1b\u5728\u7c7b\u578b\u56fe\u7684\u8f68\u8ff9\u4e0a\u751f\u6210\u6216\u53d8\u5f02\u4ea4\u6613\uff1b\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u7ed3\u5408\u5177\u4f53\u6267\u884c\u548c\u7b26\u53f7\u6267\u884c\u7684 concolic \u6267\u884c\u5668\uff1b\u5728 109\u4e2a\u771f\u5b9e Move \u5408\u7ea6\u9879\u76ee\u4e0a\u8bc4\u4f30\uff0c\u5c55\u793a\u68c0\u6d4b\u6548\u679c\u548c\u5bf9 Cetus\u3001Nemo \u7684\u653b\u51fb\u590d\u73b0\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d Belobog \u80fd\u53d1\u73b0 100% \u7684\u5173\u952e\u6f0f\u6d1e\u548c 79% \u7684\u4e00\u822c\u6f0f\u6d1e\uff08\u5747\u7ecf\u4eba\u5de5\u5ba1\u8ba1\u786e\u8ba4\uff09\uff0c\u5e76\u80fd\u5728\u65e0\u9700\u5148\u9a8c\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u6210\u529f\u590d\u73b0 Cetus \u4e0e Nemo \u7684\u5b8c\u6574\u5229\u7528\u3002", "conclusion": "\u9762\u5411 Move \u7684\u7c7b\u578b\u611f\u77e5\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86 Move \u5408\u7ea6\u7684\u5b89\u5168\u9a8c\u8bc1\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u7c7b\u578b\u57df\u9a71\u52a8\u7684\u751f\u6210\u548c concolic \u6267\u884c\u5728\u53d1\u73b0\u548c\u590d\u73b0\u5b9e\u9645\u653b\u51fb\u4e2d\u7684\u4ef7\u503c\uff0c\u9002\u7528\u4e8e Move \u751f\u6001\u7684\u5b89\u5168\u5ba1\u8ba1\u3002"}}
{"id": "2512.02740", "categories": ["cs.LG", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02740", "abs": "https://arxiv.org/abs/2512.02740", "authors": ["Waleed El-Geresy", "Deniz G\u00fcnd\u00fcz"], "title": "Adversarial Jamming for Autoencoder Distribution Matching", "comment": "Presented at ICASSP 2024. 5 pages, 3 figures", "summary": "We propose the use of adversarial wireless jamming to regularise the latent space of an autoencoder to match a diagonal Gaussian distribution. We consider the minimisation of a mean squared error distortion, where a jammer attempts to disrupt the recovery of a Gaussian source encoded and transmitted over the adversarial channel. A straightforward consequence of existing theoretical results is the fact that the saddle point of a minimax game - involving such an encoder, its corresponding decoder, and an adversarial jammer - consists of diagonal Gaussian noise output by the jammer. We use this result as inspiration for a novel approach to distribution matching in the latent space, utilising jamming as an auxiliary objective to encourage the aggregated latent posterior to match a diagonal Gaussian distribution. Using this new technique, we achieve distribution matching comparable to standard variational autoencoders and to Wasserstein autoencoders. This approach can also be generalised to other latent distributions.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u5bf9\u6297\u6027\u65e0\u7ebf\u5e72\u6270\u4f5c\u4e3a\u6b63\u5219\u5316\u624b\u6bb5\uff0c\u901a\u8fc7\u4f7f\u6f5c\u5728\u7a7a\u95f4\u5206\u5e03\u63a5\u8fd1\u5bf9\u89d2\u9ad8\u65af\u5206\u5e03\u6765\u5b9e\u73b0\u5206\u5e03\u5339\u914d\uff0c\u4e0e\u6807\u51c6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548cWAE\u7684\u7ed3\u679c\u76f8\u5f53\uff0c\u4e14\u53ef\u63a8\u5e7f\u81f3\u5176\u4ed6\u6f5c\u5728\u5206\u5e03\u3002", "motivation": "\u89e3\u51b3\u6f5c\u5728\u7a7a\u95f4\u5206\u5e03\u5339\u914d\u95ee\u9898\uff1a\u5e0c\u671b\u901a\u8fc7\u5bf9\u6297\u6027\u5e72\u6270\u6765\u5f15\u5bfc\u805a\u5408\u540e\u9a8c\u5206\u5e03\u63a5\u8fd1\u6307\u5b9a\u7684\u5bf9\u89d2\u9ad8\u65af\u5206\u5e03\uff0c\u5e76\u63a2\u7a76\u5728\u7f16\u7801-\u89e3\u7801\u5668-\u5e72\u6270\u5668\u7684\u5bf9\u6297\u6027\u8bbe\u7f6e\u4e0b\u7684\u7406\u8bba\u6700\u4f18\u6027\u4e0e\u53ef\u5e94\u7528\u6027\u3002", "method": "\u5728\u81ea\u7f16\u7801\u5668\u8bad\u7ec3\u4e2d\u5f15\u5165\u5bf9\u6297\u6027\u5e72\u6270\u5668\uff0c\u8be5\u5e72\u6270\u5668\u8f93\u51fa\u5bf9\u89d2\u9ad8\u65af\u566a\u58f0\u4ee5\u5e72\u6270\u7f16\u7801\u540e\u4f20\u8f93\u7684\u9ad8\u65af\u6e90\u7684\u6062\u590d\uff1b\u4ee5\u6700\u5c0f\u5316\u5747\u65b9\u8bef\u5dee\u5931\u771f\u4e3a\u76ee\u6807\uff0c\u540c\u65f6\u901a\u8fc7\u5e72\u6270\u5668\u7684\u5bf9\u6297\u6027\u4fe1\u53f7\u4f5c\u4e3a\u8f85\u52a9\u76ee\u6807\uff0c\u63a8\u52a8\u805a\u96c6\u6f5c\u5728\u540e\u9a8c\u63a5\u8fd1\u5bf9\u89d2\u9ad8\u65af\u5206\u5e03\uff1b\u8be5\u63a8\u7406\u57fa\u4e8e\u76f8\u5173\u6781\u503c\u7406\u8bba\uff0c\u4f5c\u4e3a\u5b9e\u73b0\u6f5c\u5728\u5206\u5e03\u5339\u914d\u7684\u65b0\u624b\u6bb5\u3002", "result": "\u901a\u8fc7\u8be5\u65b9\u6cd5\u5b9e\u73b0\u7684\u6f5c\u5728\u5206\u5e03\u5339\u914d\u4e0e\u6807\u51c6VAE\u548cWAE\u5728\u6027\u80fd\u4e0a\u76f8\u5f53\uff1b\u4e14\u8be5\u65b9\u6cd5\u5177\u6709\u6cdb\u5316\u5230\u5176\u4ed6\u6f5c\u5728\u5206\u5e03\u7684\u6f5c\u529b\u3002", "conclusion": "\u8bc1\u660e\u5c06\u5bf9\u6297\u6027\u566a\u58f0\u4f5c\u4e3a\u6f5c\u5728\u5206\u5e03\u5339\u914d\u7684\u6b63\u5219\u5316\u624b\u6bb5\u662f\u53ef\u884c\u7684\uff0c\u5e76\u4e3a\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u7075\u6d3b\u7684\u5206\u5e03\u5339\u914d\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2512.02265", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.02265", "abs": "https://arxiv.org/abs/2512.02265", "authors": ["Joshua Wolff Anderson", "Shyam Visweswaran"], "title": "The Effect of Enforcing Fairness on Reshaping Explanations in Machine Learning Models", "comment": "10 pages, 3 figures, 2 tables", "summary": "Trustworthy machine learning in healthcare requires strong predictive performance, fairness, and explanations. While it is known that improving fairness can affect predictive performance, little is known about how fairness improvements influence explainability, an essential ingredient for clinical trust. Clinicians may hesitate to rely on a model whose explanations shift after fairness constraints are applied. In this study, we examine how enhancing fairness through bias mitigation techniques reshapes Shapley-based feature rankings. We quantify changes in feature importance rankings after applying fairness constraints across three datasets: pediatric urinary tract infection risk, direct anticoagulant bleeding risk, and recidivism risk. We also evaluate multiple model classes on the stability of Shapley-based rankings. We find that increasing model fairness across racial subgroups can significantly alter feature importance rankings, sometimes in different ways across groups. These results highlight the need to jointly consider accuracy, fairness, and explainability in model assessment rather than in isolation.", "AI": {"tldr": "\u516c\u5e73\u6027\u6539\u8fdb\u53ef\u80fd\u6539\u53d8\u57fa\u4e8eShapley\u7684\u7279\u5f81\u6392\u540d\uff0c\u5f71\u54cd\u8de8\u5b50\u7ec4\u7684\u53ef\u89e3\u91ca\u6027\uff1b\u9700\u8981\u5728\u51c6\u786e\u6027\u3001\u516c\u5e73\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u8fdb\u884c\u8054\u52a8\u8bc4\u4f30\u3002", "motivation": "\u63a2\u7a76\u901a\u8fc7\u504f\u5dee\u7f13\u89e3\u63d0\u9ad8\u516c\u5e73\u6027\u65f6\uff0c\u662f\u5426\u4f1a\u6539\u53d8Shapley\u57fa\u4e8e\u7684\u7279\u5f81\u91cd\u8981\u6027\u6392\u5e8f\uff0c\u4ee5\u53ca\u8fd9\u79cd\u53d8\u5316\u5728\u4e0d\u540c\u79cd\u65cf\u5b50\u7fa4\u548c\u6a21\u578b\u7c7b\u578b\u4e2d\u7684\u5dee\u5f02\u3002\u901a\u8fc7\u4e09\u4e2a\u6570\u636e\u96c6\uff08\u513f\u79d1\u6ccc\u5c3f\u9053\u611f\u67d3\u98ce\u9669\u3001\u76f4\u63a5\u6297\u51dd\u836f\u7269\u51fa\u8840\u98ce\u9669\u3001\u518d\u72af\u98ce\u9669\uff09\u4e0e\u591a\u79cd\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002", "method": "\u5bf9\u4e09\u4e2a\u6570\u636e\u96c6\u5728\u5e94\u7528\u516c\u5e73\u6027\u7ea6\u675f\u524d\u540e\uff0c\u8bc4\u4f30Shapley\u57fa\u4e8e\u7684\u7279\u5f81\u6392\u540d\u7684\u53d8\u5316\uff1b\u6bd4\u8f83\u4e0d\u540c\u65cf\u88d4\u5b50\u7ec4\u4e4b\u95f4\u7684\u6392\u540d\u53d8\u5316\uff1b\u5728\u591a\u79cd\u6a21\u578b\u7c7b\u522b\u4e0a\u6d4b\u8bd5\u53ef\u89e3\u91ca\u6027\u7a33\u5b9a\u6027\uff1b\u91cf\u5316\u6392\u540d\u53d8\u5316\u7684\u7a0b\u5ea6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u63d0\u5347\u8de8\u79cd\u65cf\u7fa4\u4f53\u7684\u516c\u5e73\u6027\u65f6\uff0c\u7279\u5f81\u91cd\u8981\u6027\u6392\u540d\u53ef\u80fd\u663e\u8457\u6539\u53d8\uff0c\u4e14\u53d8\u5316\u5728\u4e0d\u540c\u7fa4\u4f53\u95f4\u5448\u73b0\u5dee\u5f02\uff0c\u65b9\u5411\u751a\u81f3\u53ef\u80fd\u76f8\u53cd\uff1b\u4e0d\u540c\u6a21\u578b\u7684\u6392\u540d\u7a33\u5b9a\u6027\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u5e94\u5728\u6a21\u578b\u8bc4\u4f30\u4e2d\u7efc\u5408\u8003\u8651\u51c6\u786e\u6027\u3001\u516c\u5e73\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u800c\u4e0d\u4ec5\u4ec5\u5355\u72ec\u770b\u5f85\u5176\u4e2d\u4e00\u4e2a\u7ef4\u5ea6\uff1b\u5728\u5e94\u7528\u516c\u5e73\u6027\u7ea6\u675f\u540e\uff0c\u5e94\u6301\u7eed\u5173\u6ce8\u89e3\u91ca\u7684\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\uff0c\u63a8\u52a8\u5efa\u7acb\u66f4\u7a33\u5065\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2512.02279", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2512.02279", "abs": "https://arxiv.org/abs/2512.02279", "authors": ["Jane Lange", "Mingda Qiao"], "title": "Limitations of Membership Queries in Testable Learning", "comment": "Conference: ITCS 2026", "summary": "Membership queries (MQ) often yield speedups for learning tasks, particularly in the distribution-specific setting. We show that in the \\emph{testable learning} model of Rubinfeld and Vasilyan [RV23], membership queries cannot decrease the time complexity of testable learning algorithms beyond the complexity of sample-only distribution-specific learning. In the testable learning model, the learner must output a hypothesis whenever the data distribution satisfies a desired property, and if it outputs a hypothesis, the hypothesis must be near-optimal.\n  We give a general reduction from sample-based \\emph{refutation} of boolean concept classes, as presented in [Vadhan17, KL18], to testable learning with queries (TL-Q). This yields lower bounds for TL-Q via the reduction from learning to refutation given in [KL18]. The result is that, relative to a concept class and a distribution family, no $m$-sample TL-Q algorithm can be super-polynomially more time-efficient than the best $m$-sample PAC learner.\n  Finally, we define a class of ``statistical'' MQ algorithms that encompasses many known distribution-specific MQ learners, such as those based on influence estimation or subcube-conditional statistical queries. We show that TL-Q algorithms in this class imply efficient statistical-query refutation and learning algorithms. Thus, combined with known SQ dimension lower bounds, our results imply that these efficient membership query learners cannot be made testable.", "AI": {"tldr": "\u5728 testable learning \u6a21\u578b\u4e0b\uff0c\u6210\u5458\u67e5\u8be2\uff08MQ\uff09\u65e0\u6cd5\u666e\u904d\u964d\u4f4e\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u4e0d\u80fd\u8d85\u8d8a\u57fa\u4e8e\u6837\u672c\u7684\u6700\u4f18 PAC \u5b66\u4e60\uff1b\u901a\u8fc7\u4ece\u6837\u672c\u8bc1\u4f2a\u5230 TL-Q \u7684\u4e00\u822c\u5316\u5f52\u7ea6\uff0c\u5efa\u7acb\u4e86 TL-Q \u7684\u4e0b\u754c\uff1b\u5e76\u5b9a\u4e49\u4e86\u201c\u7edf\u8ba1\u578b\u201d MQ \u7b97\u6cd5\uff0c\u8868\u660e TL-Q \u82e5\u5b58\u5728\uff0c\u5219\u53ef\u5bfc\u51fa\u9ad8\u6548\u7684 SQ \u8bc1\u4f2a\u4e0e\u5b66\u4e60\uff0c\u4f46\u7ed3\u5408 SQ \u7ef4\u5ea6\u4e0b\u754c\uff0c\u67d0\u4e9b MQ \u5b66\u4e60\u5668\u4e0d\u53ef\u5b9e\u73b0\u53ef\u6d4b\u8bd5\u6027\u3002", "motivation": "\u63a2\u7a76\u6210\u5458\u67e5\u8be2\u5728\u53ef\u6d4b\u8bd5\u5b66\u4e60\u4e2d\u7684\u4ef7\u503c\uff0c\u7279\u522b\u662f\u5728\u5206\u5e03\u7279\u5b9a\u8bbe\u7f6e\u4e0b\u662f\u5426\u80fd\u63d0\u5347\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u4ee5\u53ca\u5b83\u4e0e\u8bc1\u4f2a\u3001\u7edf\u8ba1\u67e5\u8be2\u7b49\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u7ed9\u51fa\u4ece\u6837\u672c\u57fa\u7840\u7684\u5e03\u5c14\u6982\u5ff5\u7c7b\u8bc1\u4f2a\u5230 TL-Q \u7684\u901a\u7528\u5f52\u7ea6\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u5b9a\u4e49\u7edf\u8ba1\u578b MQ \u7b97\u6cd5\u7684\u96c6\u5408\uff0c\u8bc1\u660e TL-Q \u63a8\u5bfc\u51fa\u9ad8\u6548\u7684 SQ \u8bc1\u4f2a\u4e0e\u5b66\u4e60\uff1b\u5229\u7528\u5df2\u77e5\u7684 SQ \u7ef4\u5ea6\u4e0b\u754c\u5f97\u51fa\u4e0d\u53ef\u5b9e\u73b0\u7684\u53ef\u6d4b\u8bd5\u6027\u7ed3\u8bba\u3002", "result": "\u76f8\u5bf9\u4e8e\u7ed9\u5b9a\u6982\u5ff5\u7c7b\u4e0e\u5206\u5e03\u65cf\uff0c\u6ca1\u6709 m-\u6837\u672c\u7684 TL-Q \u7b97\u6cd5\u80fd\u5728\u65f6\u95f4\u4e0a\u591a\u9879\u5f0f\u8d85\u8d8a\u6700\u4f73\u7684 m-\u6837\u672c PAC \u5b66\u4e60\uff1b\u5bf9\u7edf\u8ba1\u578b MQ \u7b97\u6cd5\uff0cTL-Q \u610f\u5473\u7740\u5b58\u5728\u9ad8\u6548\u7684 SQ \u8bc1\u4f2a\u4e0e\u5b66\u4e60\u7b97\u6cd5\uff1b\u7ed3\u5408 SQ \u7ef4\u5ea6\u4e0b\u754c\uff0c\u610f\u5473\u7740\u8fd9\u4e9b\u9ad8\u6548\u7684 MQ \u5b66\u4e60\u5668\u4e0d\u80fd\u88ab\u8f6c\u5316\u4e3a\u53ef\u6d4b\u8bd5\u5b66\u4e60\u3002", "conclusion": "MQ \u5728\u53ef\u6d4b\u8bd5\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\u53d7\u9650\uff0c\u5c24\u5176\u5728\u4e0e\u8bc1\u4f2a\u548c SQ \u7ef4\u5ea6\u4e0b\u754c\u76f8\u7ed3\u5408\u65f6\uff1b\u8fd9\u7c7b\u5de5\u4f5c\u8868\u660e\u8981\u5b9e\u73b0\u53ef\u6d4b\u8bd5\u6027\uff0c\u9700\u8d85\u8d8a\u73b0\u6709\u7684\u7edf\u8ba1\u578b MQ \u6846\u67b6\u6216\u627e\u5230\u65b0\u7684\u7a81\u7834\u6027\u65b9\u6cd5\u3002"}}
{"id": "2512.02303", "categories": ["cs.LG", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2512.02303", "abs": "https://arxiv.org/abs/2512.02303", "authors": ["Max W. Shen", "Ewa Nowara", "Michael Maser", "Kyunghyun Cho"], "title": "Training Dynamics of Learning 3D-Rotational Equivariance", "comment": "Accepted to Transactions on Machine Learning Research (TMLR)", "summary": "While data augmentation is widely used to train symmetry-agnostic models, it remains unclear how quickly and effectively they learn to respect symmetries. We investigate this by deriving a principled measure of equivariance error that, for convex losses, calculates the percent of total loss attributable to imperfections in learned symmetry. We focus our empirical investigation to 3D-rotation equivariance on high-dimensional molecular tasks (flow matching, force field prediction, denoising voxels) and find that models reduce equivariance error quickly to $\\leq$2\\% held-out loss within 1k-10k training steps, a result robust to model and dataset size. This happens because learning 3D-rotational equivariance is an easier learning task, with a smoother and better-conditioned loss landscape, than the main prediction task. For 3D rotations, the loss penalty for non-equivariant models is small throughout training, so they may achieve lower test loss than equivariant models per GPU-hour unless the equivariant ``efficiency gap'' is narrowed. We also experimentally and theoretically investigate the relationships between relative equivariance error, learning gradients, and model parameters.", "AI": {"tldr": "3D\u65cb\u8f6c\u7b49\u53d8\u6027\u5b66\u4e60\u53ef\u4ee5\u5feb\u901f\u5b9e\u73b0\uff0c\u4f7f\u7528\u4e00\u4e2a\u57fa\u4e8e\u635f\u5931\u7684\u7b49\u53d8\u8bef\u5dee\u5ea6\u91cf\uff0c\u57281k-10k\u6b65\u5185\u5c06\u6301\u51fa\u635f\u5931\u4e2d\u7684\u975e\u7b49\u53d8\u90e8\u5206\u964d\u81f3\u22642%\uff0c\u975e\u7b49\u53d8\u6a21\u578b\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u80fd\u4ee5GPU\u65f6\u6548\u7387\u8d85\u8d8a\u7b49\u53d8\u6a21\u578b\uff0c\u4f46\u5b58\u5728\u201c\u6548\u7387\u5dee\u8ddd\u201d\uff1b\u8bba\u6587\u63d0\u51fa\u4e86\u8861\u91cf\u7b49\u53d8\u8bef\u5dee\u7684\u539f\u7406\u6027\u6307\u6807\uff0c\u5e76\u8ba8\u8bba\u5176\u4e0e\u68af\u5ea6\u548c\u53c2\u6570\u7684\u5173\u7cfb\u3002", "motivation": "\u5b9a\u91cf\u8bc4\u4f30\u6a21\u578b\u5bf9\u5bf9\u79f0\u6027\uff08\u5c24\u5176\u662f3D\u65cb\u8f6c\uff09\u5b66\u4e60\u7684\u901f\u5ea6\u548c\u6548\u679c\uff0c\u63d0\u51fa\u7528\u4e8e\u8861\u91cf\u7b49\u53d8\u8bef\u5dee\u7684\u539f\u5219\u6027\u5ea6\u91cf\uff0c\u5e76\u5728\u9ad8\u7ef4\u5206\u5b50\u4efb\u52a1\u4e0a\u63a2\u7d22\u635f\u5931\u666f\u89c2\u4e0e\u5b66\u4e60\u52a8\u6001\u3002", "method": "\u63a8\u5bfc\u7528\u4e8e\u51f8\u635f\u5931\u7684\u7b49\u53d8\u8bef\u5dee\u767e\u5206\u6bd4\u5ea6\u91cf\uff1b\u5728\u6d41\u5f0f\u5339\u914d\u3001\u529b\u573a\u9884\u6d4b\u3001\u53bb\u566a\u4f53\u7d20\u7b493D\u65cb\u8f6c\u7b49\u53d8\u4efb\u52a1\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff1b\u4ece\u7406\u8bba\u548c\u5b9e\u9a8c\u89d2\u5ea6\u7814\u7a76\u7b49\u53d8\u8bef\u5dee\u3001\u68af\u5ea6\u548c\u6a21\u578b\u53c2\u6570\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u57281k-10k\u6b65\u5185\uff0c\u6a21\u578b\u5c06\u7b49\u53d8\u8bef\u5dee\u964d\u81f3\u6301\u51fa\u635f\u5931\u7684\u22642%\uff0c\u5bf9\u6a21\u578b\u5927\u5c0f\u548c\u6570\u636e\u96c6\u89c4\u6a21\u5177\u6709\u9c81\u68d2\u6027\uff1b\u975e\u7b49\u53d8\u6a21\u578b\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u635f\u5931 penalty \u5c0f\uff0c\u53ef\u80fd\u5728\u5355\u4f4dGPU\u5c0f\u65f6\u5185\u53d6\u5f97\u6bd4\u7b49\u53d8\u6a21\u578b\u66f4\u4f4e\u7684\u6d4b\u8bd5\u635f\u5931\uff0c\u4f46\u82e5\u964d\u4f4e\u201c\u6548\u7387\u5dee\u8ddd\u201d\uff0c\u5219\u7b49\u53d8\u65b9\u6cd5\u5177\u4f18\u52bf\uff1b\u8fd8\u7ed9\u51fa\u76f8\u5bf9\u7b49\u53d8\u8bef\u5dee\u3001\u5b66\u4e60\u68af\u5ea6\u548c\u53c2\u6570\u4e4b\u95f4\u5173\u7cfb\u7684\u5b9e\u9a8c\u4e0e\u7406\u8bba\u5206\u6790\u3002", "conclusion": "\u63d0\u4f9b\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u76f8\u5bf9\u7b49\u53d8\u5ea6\u91cf\u7684\u6846\u67b6\u53ca\u5176\u5bf9\u8bad\u7ec3\u52a8\u529b\u5b66\u7684\u6d1e\u89c1\uff1b\u63ed\u793a\u5bf9\u79f0\u6027\u5b66\u4e60\u76f8\u5bf9\u4e3b\u4efb\u52a1\u7684\u6613\u5b66\u6027\uff0c\u5f3a\u8c03\u5728\u8bbe\u8ba1\u6a21\u578b\u65f6\u8003\u8651\u7b49\u53d8\u6548\u7387\u5dee\u8ddd\u4e0e\u635f\u5931\u666f\u89c2\u7279\u5f81\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2512.02323", "categories": ["cs.LG", "quant-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.02323", "abs": "https://arxiv.org/abs/2512.02323", "authors": ["Kentaro Kubo", "Hayato Goto"], "title": "Unlocking the Power of Boltzmann Machines by Parallelizable Sampler and Efficient Temperature Estimation", "comment": "16 pages, 14 figures", "summary": "Boltzmann machines (BMs) are powerful energy-based generative models, but their heavy training cost has largely confined practical use to Restricted BMs (RBMs) trained with an efficient learning method called contrastive divergence. More accurate learning typically requires Markov chain Monte Carlo (MCMC) Boltzmann sampling, but it is time-consuming due to the difficulty of parallelization for more expressive models. To address this limitation, we first propose a new Boltzmann sampler inspired by a quantum-inspired combinatorial optimization called simulated bifurcation (SB). This SB-inspired approach, which we name Langevin SB (LSB), enables parallelized sampling while maintaining accuracy comparable to MCMC. Furthermore, this is applicable not only to RBMs but also to BMs with general couplings. However, LSB cannot control the inverse temperature of the output Boltzmann distribution, which hinders learning and degrades performance. To overcome this limitation, we also developed an efficient method for estimating the inverse temperature during the learning process, which we call conditional expectation matching (CEM). By combining LSB and CEM, we establish an efficient learning framework for BMs with greater expressive power than RBMs. We refer to this framework as sampler-adaptive learning (SAL). SAL opens new avenues for energy-based generative modeling beyond RBMs.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u5e76\u884c\u7684 Langevin SB \u91c7\u6837\uff08LSB\uff09\u7528\u4e8e Boltzmann \u673a\uff0c\u4e0e\u6761\u4ef6\u671f\u671b\u5339\u914d\uff08CEM\uff09\u4e00\u8d77\u5b9e\u73b0 SAL \u6846\u67b6\uff0c\u63d0\u5347\u5bf9\u4e00\u822c\u8026\u5408 Boltzmann \u673a\u7684\u9ad8\u6548\u5b66\u4e60\u80fd\u529b\uff0c\u8d85\u8d8a RBM\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf Boltzmann \u673a\u8bad\u7ec3\u6210\u672c\u9ad8\u3001\u4ec5 RBM \u53ef\u9ad8\u6548\u8bad\u7ec3\u3001\u9700\u8981 MCMC \u91c7\u6837\u4e14\u96be\u4ee5\u5e76\u884c\u5316\u7684\u95ee\u9898\uff1b\u9700\u8981\u53ef\u5e76\u884c\u7684\u9ad8\u8868\u8fbe\u80fd\u529b\u6a21\u578b\uff1b\u9700\u8981\u7a33\u5b9a\u7684\u9006\u6e29\u5ea6\u4f30\u8ba1\u4ee5\u63d0\u5347\u5b66\u4e60\u8d28\u91cf\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u6a21\u62df\u5206\u53c9\u7684 Langevin \u91c7\u6837\uff0cLSB \u4f7f\u5e76\u884c\u5316\u91c7\u6837\u4fdd\u6301\u4e0e MCMC \u76f8\u5f53\u7684\u51c6\u786e\u6027\uff0c\u4e14\u9002\u7528\u4e8e\u4e00\u822c\u8026\u5408\u7684 Boltzmann \u673a\uff1b\u63d0\u51fa\u6761\u4ef6\u671f\u671b\u5339\u914d\uff08CEM\uff09\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u4f30\u8ba1\u9006\u6e29\u5ea6\uff1b\u5c06\u4e24\u8005\u7ed3\u5408\u5f62\u6210 sampler-adaptive learning (SAL)\u3002", "result": "LSB \u80fd\u5728\u5e76\u884c\u73af\u5883\u4e2d\u83b7\u5f97\u4e0e MCMC \u76f8\u5f53\u7684\u7cbe\u5ea6\uff1bCEM \u63d0\u4f9b\u9ad8\u6548\u7684\u9006\u6e29\u5ea6\u4f30\u8ba1\uff1bSAL \u5b9e\u73b0\u5bf9\u6bd4 RBM \u66f4\u5f3a\u8868\u8fbe\u529b\u7684\u80fd\u91cf\u57fa\u751f\u6210\u5efa\u6a21\uff0c\u63d0\u5347\u5b66\u4e60\u6548\u7387\u3002", "conclusion": "SAL \u5f00\u8f9f\u80fd\u91cf\u57fa\u751f\u6210\u5efa\u6a21\u7684\u65b0\u8def\u5f84\uff0c\u8d85\u8d8a RBM\uff0c\u6269\u5c55\u53ef\u5e76\u884c\u7684\u9ad8\u8868\u8fbe\u80fd\u529b Boltzmann \u673a\u7684\u5e94\u7528\u3002"}}
{"id": "2512.02333", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02333", "abs": "https://arxiv.org/abs/2512.02333", "authors": ["Wenzhang Du"], "title": "Retrieval-Augmented Memory for Online Learning", "comment": "11 pages, 3 figures", "summary": "Retrieval-augmented models couple parametric predictors with non-parametric memories, but their use in streaming supervised learning with concept drift is not well understood. We study online classification in non-stationary environments and propose Retrieval-Augmented Memory for Online Learning (RAM-OL), a simple extension of stochastic gradient descent that maintains a small buffer of past examples. At each time step, RAM-OL retrieves a few nearest neighbours of the current input in the hidden representation space and updates the model jointly on the current example and the retrieved neighbours. We compare a naive replay variant with a gated replay variant that constrains neighbours using a time window, similarity thresholds, and gradient reweighting, in order to balance fast reuse of relevant past data against robustness to outdated regimes. From a theoretical perspective, we interpret RAM-OL under a bounded drift model and discuss how retrieval can reduce adaptation cost and improve regret constants when patterns recur over time. Empirically, we instantiate RAM-OL on a simple online multilayer perceptron and evaluate it on three real-world data streams derived from electricity pricing, electricity load, and airline delay data. On strongly and periodically drifting streams, RAM-OL improves prequential accuracy by up to about seven percentage points and greatly reduces variance across random seeds, while on a noisy airline stream the gated variant closely matches the purely online baseline. These results show that retrieval-augmented memory is a practical and robust tool for online learning under concept drift.", "AI": {"tldr": "RAM-OL is a simple online retrieval-augmented learning method for non-stationary streams; it maintains a small buffer of past examples and uses nearest neighbors in the hidden space to augment updates. Two replay variants are studied: naive replay and gated replay with time/window constraints, similarity filters, and gradient reweighting. Theoretical analysis under a bounded drift model suggests retrieval can reduce adaptation cost and improve regret when patterns recur. Empirically, RAM-OL (simple online MLP) improves prequential accuracy on real streams (electricity pricing/load, airline delay) by up to ~7 percentage points and reduces seed variance; gated replay is robust on noisy data and can match purely online baselines. The work argues retrieval-augmented memory is practical for online learning under concept drift.", "motivation": "To improve online classification under concept drift by leveraging a small, non-parametric memory that stores past examples and can be retrieved to assist updates, thereby reducing adaptation cost and stabilizing performance when patterns recur.", "method": "Maintain a small buffer of past examples; at each time step, retrieve a few nearest neighbors of the current input in the hidden representation space and update the model on both the current example and the retrieved neighbors. Compare a naive replay variant with a gated replay variant that constrains neighbors using a time window, similarity thresholds, and gradient reweighting to balance fast reuse vs robustness to outdated regimes.", "result": "Theoretical: under a bounded drift model, retrieval can reduce adaptation cost and improve regret constants when patterns recur. Empirical: on three real streams (electricity pricing, electricity load, airline delay) RAM-OL improves prequential accuracy by up to about 7 percentage points and reduces variance across seeds; on a noisy airline stream, the gated variant closely matches the purely online baseline.", "conclusion": "Retrieval-augmented memory is a practical and robust tool for online learning under concept drift, with RAM-OL offering a simple extension to SGD that leverages past data for better adaptation."}}
{"id": "2512.02337", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02337", "abs": "https://arxiv.org/abs/2512.02337", "authors": ["Zhendong Tan", "Xingjun Zhang", "Chaoyi Hu", "Junjie Peng", "Kun Xia"], "title": "SpecPV: Improving Self-Speculative Decoding for Long-Context Generation via Partial Verification", "comment": null, "summary": "Growing demands from tasks like code generation, deep reasoning, and long-document understanding have made long-context generation a crucial capability for large language models (LLMs). Speculative decoding is one of the most direct and effective approaches for accelerating generation. It follows a draft-verify paradigm, where a lightweight draft model proposes several candidate tokens and the target model verifies them. However, we find that as the context length grows, verification becomes the dominant bottleneck. To further accelerate speculative decoding in long-context generation, we introduce SpecPV, a self-speculative decoding approach that performs fast verification using partial key-value states (KV) and periodically applies full verification to eliminate accumulated errors. We validate SpecPV across multiple long-context benchmarks and models, including LLaMA-3.1-8B-Instruct and Qwen3-series. Experimental results show that SpecPV achieves up to 6x decoding speedup over standard autoregressive decoding with minor degradation.", "AI": {"tldr": "SpecPV \u901a\u8fc7\u81ea\u6211 speculate \u89e3\u7801\u548c\u90e8\u5206\u952e\u503c\u72b6\u6001\u7684\u5feb\u901f\u9a8c\u8bc1\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u751f\u6210\u4e2d\u51cf\u5c11\u9a8c\u8bc1\u6210\u672c\uff0c\u5468\u671f\u6027\u6267\u884c\u5168\u91cf\u9a8c\u8bc1\u4ee5\u7ea0\u6b63\u7d2f\u8ba1\u8bef\u5dee\uff0c\u4ece\u800c\u5728\u591a\u6a21\u578b\u548c\u57fa\u51c6\u4e0a\u5b9e\u73b0\u6700\u9ad8\u7ea66x\u7684\u89e3\u7801\u52a0\u901f\uff0c\u4e14\u7cbe\u5ea6\u4e0b\u964d\u5f88\u5c0f\u3002", "motivation": "\u968f\u7740\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\uff0c\u540e\u9a8c\u9a8c\u8bc1\u6210\u4e3a\u957f\u4e0a\u4e0b\u6587\u751f\u6210\u7684\u74f6\u9888\uff1b\u9700\u8981\u964d\u4f4e\u9a8c\u8bc1\u6210\u672c\u4ee5\u63d0\u5347\u63a8\u7406\u901f\u5ea6\u3002", "method": "\u63d0\u51fa SpecPV\uff1a\u5728 draft-verify \u67b6\u6784\u4e0b\uff0c\u4f7f\u7528\u8f7b\u91cf\u5316\u8349\u6848\u6a21\u578b\u4ea7\u751f\u5019\u9009\u4ee4\u724c\u5e76\u8fdb\u884c\u5feb\u901f\u9a8c\u8bc1\uff0c\u91c7\u7528\u90e8\u5206 KV \u72b6\u6001\u5b9e\u73b0\u5feb\u901f\u9a8c\u8bc1\uff0c\u540c\u65f6\u5b9a\u671f\u8fdb\u884c\u5168\u91cf\u9a8c\u8bc1\u4ee5\u6d88\u9664\u7d2f\u8ba1\u7684\u8bef\u5dee\u3002", "result": "\u5728\u591a\u9879\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u548c\u6a21\u578b\u4e0a\u53d6\u5f97\u52a0\u901f\u6548\u679c\uff0c\u5305\u62ec LLaMA-3.1-8B-Instruct \u548c Qwen3 \u7cfb\u5217\uff0c\u89e3\u7801\u901f\u5ea6\u6700\u9ad8\u63d0\u5347\u7ea6 6 \u500d\uff0c\u4f34\u968f\u5c11\u91cf\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "SpecPV \u5c55\u793a\u4e86\u81ea\u6211 speculate \u9a8c\u8bc1\u5728\u964d\u4f4e\u957f\u4e0a\u4e0b\u6587\u89e3\u7801\u6210\u672c\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u5468\u671f\u6027\u5168\u91cf\u9a8c\u8bc1\u6765\u63a7\u5236\u7d2f\u79ef\u8bef\u5dee\uff0c\u4f7f\u901f\u5ea6\u63d0\u5347\u4e0e\u7cbe\u5ea6\u964d\u5e45\u4fdd\u6301\u5728\u53ef\u63a5\u53d7\u8303\u56f4\u5185\u3002"}}
{"id": "2512.02350", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02350", "abs": "https://arxiv.org/abs/2512.02350", "authors": ["Nan Qiao", "Sheng Yue", "Ju Ren", "Yaoxue Zhang"], "title": "FOVA: Offline Federated Reinforcement Learning with Mixed-Quality Data", "comment": "Accepted by IEEE/ACM ToN", "summary": "Offline Federated Reinforcement Learning (FRL), a marriage of federated learning and offline reinforcement learning, has attracted increasing interest recently. Albeit with some advancement, we find that the performance of most existing offline FRL methods drops dramatically when provided with mixed-quality data, that is, the logging behaviors (offline data) are collected by policies with varying qualities across clients. To overcome this limitation, this paper introduces a new vote-based offline FRL framework, named FOVA. It exploits a \\emph{vote mechanism} to identify high-return actions during local policy evaluation, alleviating the negative effect of low-quality behaviors from diverse local learning policies. Besides, building on advantage-weighted regression (AWR), we construct consistent local and global training objectives, significantly enhancing the efficiency and stability of FOVA. Further, we conduct an extensive theoretical analysis and rigorously show that the policy learned by FOVA enjoys strict policy improvement over the behavioral policy. Extensive experiments corroborate the significant performance gains of our proposed algorithm over existing baselines on widely used benchmarks.", "AI": {"tldr": "\u63d0\u51fa FOVA\uff1a\u4e00\u79cd\u57fa\u4e8e\u6295\u7968\u7684\u79bb\u7ebf\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6295\u7968\u673a\u5236\u5728\u672c\u5730\u7b56\u7565\u8bc4\u4f30\u4e2d\u8bc6\u522b\u9ad8\u6536\u76ca\u884c\u52a8\uff0c\u51cf\u8f7b\u6765\u81ea\u4e0d\u540c\u5ba2\u6237\u7aef\u7684\u4f4e\u8d28\u91cf\u6570\u636e\u7684\u8d1f\u9762\u5f71\u54cd\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u7ed3\u5408\u4f18\u52bf\u52a0\u6743\u56de\u5f52\uff08AWR\uff09\u6784\u5efa\u4e00\u81f4\u7684\u672c\u5730\u4e0e\u5168\u5c40\u8bad\u7ec3\u76ee\u6807\uff0c\u663e\u8457\u63d0\u5347\u7a33\u5b9a\u6027\u4e0e\u6548\u7387\u3002\u7406\u8bba\u4e0a\u8bc1\u660e\u5b66\u4e60\u7b56\u7565\u5bf9\u884c\u4e3a\u7b56\u7565\u5177\u6709\u4e25\u683c\u6539\u8fdb\uff0c\u5b9e\u9a8c\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u5728\u79bb\u7ebf\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u6df7\u5408\u8d28\u91cf\u7684\u6570\u636e\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u4e9f\u9700\u5728\u8de8\u5ba2\u6237\u7aef\u7684\u6570\u636e\u5f02\u8d28\u6027\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9c81\u68d2\u7684\u7b56\u7565\u5b66\u4e60\u4e0e\u805a\u5408\u3002", "method": "\u5728\u672c\u5730\u7b56\u7565\u8bc4\u4f30\u9636\u6bb5\u5f15\u5165\u6295\u7968\u673a\u5236\u4ee5\u8bc6\u522b\u9ad8\u56de\u62a5\u52a8\u4f5c\uff0c\u7f13\u89e3\u4f4e\u8d28\u91cf\u884c\u4e3a\u7684\u5f71\u54cd\uff1b\u57fa\u4e8e\u4f18\u52bf\u52a0\u6743\u56de\u5f52\uff08AWR\uff09\u8bbe\u8ba1\u4e00\u81f4\u7684\u672c\u5730/\u5168\u5c40\u8bad\u7ec3\u76ee\u6807\uff0c\u63d0\u5347\u5b66\u4e60\u7a33\u5b9a\u6027\u4e0e\u6548\u7387\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a FOVA \u5b66\u4e60\u5f97\u5230\u7684\u7b56\u7565\u5bf9\u884c\u4e3a\u7b56\u7565\u5177\u6709\u4e25\u683c\u7684\u6539\u8fdb\u6027\uff1b\u5b9e\u9a8c\u7ed3\u679c\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FOVA \u6709\u6548\u7f13\u89e3\u4e86\u6570\u636e\u8d28\u91cf\u4e0d\u4e00\u81f4\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u63d0\u5347\u79bb\u7ebf FRL \u7684\u7a33\u5b9a\u6027\u4e0e\u6548\u7387\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u4fdd\u969c\u4e0e\u5b9e\u8bc1\u8bc1\u636e\u3002"}}
{"id": "2512.02383", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02383", "abs": "https://arxiv.org/abs/2512.02383", "authors": ["Jonathan Baxter", "Peter L. Bartlett"], "title": "Reinforcement Learning in POMDP's via Direct Gradient Ascent", "comment": null, "summary": "This paper discusses theoretical and experimental aspects of gradient-based approaches to the direct optimization of policy performance in controlled POMDPs. We introduce GPOMDP, a REINFORCE-like algorithm for estimating an approximation to the gradient of the average reward as a function of the parameters of a stochastic policy. The algorithm's chief advantages are that it requires only a single sample path of the underlying Markov chain, it uses only one free parameter $\u03b2\\in [0,1)$, which has a natural interpretation in terms of bias-variance trade-off, and it requires no knowledge of the underlying state. We prove convergence of GPOMDP and show how the gradient estimates produced by GPOMDP can be used in a conjugate-gradient procedure to find local optima of the average reward.", "AI": {"tldr": "\u63d0\u51fa GPOMDP\uff0c\u4e00\u79cd\u7528\u4e8e\u53d7\u63a7\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\u7684\u5e73\u5747\u56de\u62a5\u68af\u5ea6\u4f30\u8ba1\u7684 REINFORCE \u98ce\u683c\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u53ea\u9700\u5355\u6761\u6837\u672c\u8f68\u8ff9\u3001\u53ea\u5f15\u5165\u4e00\u4e2a\u03b2\u53c2\u6570\u4e14\u65e0\u9700\u72b6\u6001\u4fe1\u606f\uff1b\u7ed9\u51fa\u6536\u655b\u6027\u8bc1\u660e\uff0c\u5e76\u5c55\u793a\u5982\u4f55\u5c06\u68af\u5ea6\u4f30\u8ba1\u7528\u4e8e\u5171\u8f6d\u68af\u5ea6\u6cd5\u4ee5\u5bfb\u627e\u5c40\u90e8\u6700\u4f18\u89e3\u3002", "motivation": "\u76f4\u63a5\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u7684\u73af\u5883\u4e2d\u4f18\u5316\u7b56\u7565\u6027\u80fd\uff0c\u907f\u514d\u5bf9\u7cfb\u7edf\u72b6\u6001\u7684\u5b8c\u5168\u77e5\u8bc6\u6216\u591a\u6b21\u91cd\u91c7\u6837\u7684\u9700\u6c42\uff1b\u901a\u8fc7\u5f15\u5165\u5355\u4e00\u7684\u8c03\u53c2 \u03b2 \u5b9e\u73b0\u504f\u5dee-\u65b9\u5dee\u6743\u8861\uff0c\u5e76\u4ee5\u65e0\u6a21\u578b\u3001\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u4f30\u8ba1\u68af\u5ea6\u7684\u65b9\u5f0f\u63d0\u5347\u5b66\u4e60\u6548\u7387\u3002", "method": "\u63d0\u51fa GPOMDP \u7b97\u6cd5\uff1a\u5728\u5e26\u53c2\u6570\u7684\u968f\u673a\u7b56\u7565\u4e0b\uff0c\u901a\u8fc7\u5bf9\u8f68\u8ff9\u8fdb\u884c\u91c7\u6837\uff0c\u5229\u7528\u4e00\u4e2a\u8870\u51cf\u56e0\u5b50 \u03b2(\u2208[0,1)) \u6765\u63a7\u5236\u68af\u5ea6\u4f30\u8ba1\u7684\u504f\u5dee\u4e0e\u65b9\u5dee\uff1b\u4e0d\u9700\u8981\u5bf9\u5e95\u5c42\u72b6\u6001\u7684\u77e5\u8bc6\uff0c\u4ec5\u4f9d\u8d56\u89c2\u6d4b\u4e0e\u5956\u52b1\uff1b\u7ed9\u51fa\u6536\u655b\u6027\u8bc1\u660e\uff0c\u5e76\u7ed9\u51fa\u5c06\u8be5\u68af\u5ea6\u4f30\u8ba1\u7528\u4e8e\u5171\u8f6d\u68af\u5ea6\u65b9\u6cd5\u4ee5\u6c42\u89e3\u5e73\u5747\u56de\u62a5\u7684\u5c40\u90e8\u6700\u4f18\u89e3\u7684\u6d41\u7a0b\u3002", "result": "\u6838\u5fc3\u4f18\u52bf\u5305\u62ec\uff1a\u4ec5\u9700\u8981\u5355\u6761\u6837\u672c\u8f68\u8ff9\u3001\u4ec5\u7528\u4e00\u4e2a \u03b2\u3001\u65e0\u9700\u72b6\u6001\u4fe1\u606f\uff1b\u8bc1\u660e GPOMDP \u7684\u6536\u655b\u6027\uff1b\u5e76\u793a\u610f\u5982\u4f55\u5c06\u68af\u5ea6\u4f30\u8ba1\u7528\u4e8e\u5171\u8f6d\u68af\u5ea6\u4ee5\u5bfb\u627e\u5e73\u5747\u56de\u62a5\u7684\u5c40\u90e8\u6781\u503c\u3002", "conclusion": "GPOMDP \u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u4e14\u6837\u672c\u9ad8\u6548\u7684\u5e73\u5747\u56de\u62a5\u68af\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u90e8\u5206\u53ef\u89c2\u6d4b\u60c5\u666f\u4e0b\u7684\u7b56\u7565\u4f18\u5316\uff1b\u03b2 \u4f5c\u4e3a\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u53c2\u6570\u5b9e\u73b0\u7075\u6d3b\u63a7\u5236\uff0c\u4e14\u5728\u4e0d\u9700\u72b6\u6001\u4fe1\u606f\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u6a21\u578b\u65e0\u5173\u5b66\u4e60\uff0c\u5e76\u5177\u5907\u7406\u8bba\u6536\u655b\u6027\u4e0e\u53ef\u7528\u4e8e\u4f18\u5316\u7684\u5b9e\u9645\u901a\u9053\u3002"}}
{"id": "2512.02386", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.02386", "abs": "https://arxiv.org/abs/2512.02386", "authors": ["Chuhan Xie"], "title": "Risk-Sensitive Q-Learning in Continuous Time with Application to Dynamic Portfolio Selection", "comment": null, "summary": "This paper studies the problem of risk-sensitive reinforcement learning (RSRL) in continuous time, where the environment is characterized by a controllable stochastic differential equation (SDE) and the objective is a potentially nonlinear functional of cumulative rewards. We prove that when the functional is an optimized certainty equivalent (OCE), the optimal policy is Markovian with respect to an augmented environment. We also propose \\textit{CT-RS-q}, a risk-sensitive q-learning algorithm based on a novel martingale characterization approach. Finally, we run a simulation study on a dynamic portfolio selection problem and illustrate the effectiveness of our algorithm.", "AI": {"tldr": "\u5728\u8fde\u7eed\u65f6\u95f4\u98ce\u9669\u654f\u611f\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u82e5\u76ee\u6807\u51fd\u6570\u4e3a\u4f18\u5316\u786e\u5b9a\u6027\u7b49\u4ef7\u7269\uff08OCE\uff09\uff0c\u6700\u4f18\u7b56\u7565\u5728\u589e\u5f3a\u73af\u5883\u4e0b\u5bf9\u72b6\u6001-\u52a8\u4f5c\u7684\u9a6c\u5c14\u53ef\u592b\u6027\u6210\u7acb\uff1b\u63d0\u51fa\u57fa\u4e8e\u9785\u8868\u5f81\u7684 CT-RS-q \u98ce\u9669\u654f\u611f Q \u5b66\u4e60\u7b97\u6cd5\uff1b\u901a\u8fc7\u52a8\u6001\u6295\u8d44\u7ec4\u5408\u4eff\u771f\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u3002", "motivation": "\u5c06\u98ce\u9669\u654f\u611f\u6027\u5f15\u5165\u8fde\u7eed\u65f6\u95f4\u5f3a\u5316\u5b66\u4e60\uff0c\u89e3\u51b3\u5bf9\u975e\u7ebf\u6027\u7d2f\u79ef\u5956\u52b1\u51fd\u6570\u7684\u6700\u4f18\u7b56\u7565\u5bfb\u4f18\uff0c\u7279\u522b\u662f\u5728\u7531\u53ef\u63a7\u7684\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u63cf\u8ff0\u7684\u73af\u5883\u4e2d\u3002", "method": "\u7406\u8bba\u4e0a\u8bc1\u660e\u5f53\u76ee\u6807\u51fd\u6570\u4e3a OCE \u65f6\uff0c\u6700\u4f18\u7b56\u7565\u53ef\u8868\u793a\u4e3a\u5bf9\u589e\u5f3a\u73af\u5883\u7684\u9a6c\u5c14\u53ef\u592b\u7b56\u7565\uff1b\u63d0\u51fa CT-RS-q \u7b97\u6cd5\uff0c\u57fa\u4e8e\u65b0\u7684 martingale \u8868\u5f81\u6765\u5b9e\u73b0\u98ce\u9669\u654f\u611f\u7684 Q \u5b66\u4e60\u3002", "result": "\u5728\u4eff\u771f\u5b9e\u9a8c\u7684\u52a8\u6001\u6295\u8d44\u7ec4\u5408\u95ee\u9898\u4e2d\uff0cCT-RS-q \u5c55\u73b0\u51fa\u6709\u6548\u6027\uff0c\u652f\u6301\u6240\u63d0\u51fa\u7406\u8bba\u548c\u7b97\u6cd5\u8bbe\u8ba1\u3002", "conclusion": "\u672c\u5de5\u4f5c\u63d0\u4f9b\u4e86\u5c06 OCE \u878d\u5165\u8fde\u7eed\u65f6\u95f4\u98ce\u9669\u654f\u611f\u5f3a\u5316\u5b66\u4e60\u7684\u7406\u8bba\u6846\u67b6\u4e0e\u53ef\u5b9e\u73b0\u7b97\u6cd5\uff0c\u5e76\u5728\u91d1\u878d\u573a\u666f\u5c55\u793a\u51fa\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.02403", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02403", "abs": "https://arxiv.org/abs/2512.02403", "authors": ["Hongxiang Liu", "Zhifang Deng", "Tong Pu", "Shengli Lu"], "title": "ESACT: An End-to-End Sparse Accelerator for Compute-Intensive Transformers via Local Similarity", "comment": null, "summary": "Transformers, composed of QKV generation, attention computation, and FFNs,\n  have become the dominant model across various domains due to their outstanding performance.\n  However, their high computational cost hinders efficient hardware deployment.\n  Sparsity offers a promising solution,\n  yet most existing accelerators exploit only intra-row sparsity in attention,\n  while few consider inter-row sparsity.\n  Approaches leveraging inter-row sparsity often rely on costly global similarity estimation,\n  which diminishes the acceleration benefits of sparsity,\n  and typically apply sparsity to only one or two transformer components.\n  Through careful analysis of the attention distribution and computation flow,\n  we observe that local similarity allows end-to-end sparse acceleration with lower computational overhead.\n  Motivated by this observation, we propose ESACT,\n  an end-to-end sparse accelerator for compute-intensive Transformers.\n  ESACT centers on the Sparsity Prediction with Local Similarity (SPLS) mechanism,\n  which leverages HLog quantization to accurately predict local attention sparsity prior to QK generation,\n  achieving efficient sparsity across all transformer components.\n  To support efficient hardware realization, we introduce three architectural innovations.\n  Experimental results on 26 benchmarks demonstrate that\n  SPLS reduces total computation by 52.03% with less than 1% accuracy loss.\n  ESACT achieves an end-to-end energy efficiency of 3.29 TOPS/W,\n  and improves attention-level energy efficiency by 2.95x and 2.26x over\n  SOTA attention accelerators SpAtten and Sanger, respectively.", "AI": {"tldr": "\u63d0\u51fa ESACT\uff0c\u7aef\u5230\u7aef\u7a00\u758f\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u5c40\u90e8\u76f8\u4f3c\u6027 SPLS \u9884\u6d4b\u6ce8\u610f\u529b\u7a00\u758f\u6027\uff0c\u5728\u4e0d\u663e\u8457\u635f\u5931\u7cbe\u5ea6\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u964d\u4f4e Transformer \u7684\u8ba1\u7b97\u91cf\uff0c\u4e14\u80fd\u63d0\u9ad8\u80fd\u6548\u3002", "motivation": "Transformer \u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u963b\u788d\u9ad8\u6548\u786c\u4ef6\u90e8\u7f72\u3002\u73b0\u6709\u52a0\u901f\u5668\u5927\u591a\u53ea\u5229\u7528\u6ce8\u610f\u529b\u7684\u884c\u5185\u7a00\u758f\uff0c\u5ffd\u7565\u884c\u95f4\u7a00\u758f\uff0c\u4e14\u5bf9\u5168\u5c40\u76f8\u4f3c\u5ea6\u7684\u4f30\u8ba1\u4ee3\u4ef7\u9ad8\uff0c\u901a\u5e38\u4ec5\u5bf9\u4e00\u4e2a\u6216\u4e24\u4e2a\u7ec4\u4ef6\u8fdb\u884c\u7a00\u758f\u5316\uff0c\u5bfc\u81f4\u53d7\u9650\u7684\u52a0\u901f\u6536\u76ca\u3002\u672c\u5de5\u4f5c\u901a\u8fc7\u5bf9\u6ce8\u610f\u529b\u5206\u5e03\u548c\u8ba1\u7b97\u6d41\u7a0b\u7684\u5206\u6790\uff0c\u53d1\u73b0\u5c40\u90e8\u76f8\u4f3c\u6027\u53ef\u4ee5\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u7a00\u758f\u52a0\u901f\uff0c\u5f00\u7bb1\u5373\u7528\u5730\u964d\u4f4e\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u7aef\u5230\u7aef\u7a00\u758f\u52a0\u901f\u5668 ESACT\uff0c\u6838\u5fc3\u662f SPLS\uff08Sparsity Prediction with Local Similarity\uff09\u673a\u5236\uff0c\u5229\u7528 HLog \u91cf\u5316\u5728 QK \u751f\u6210\u524d\u9884\u6d4b\u5c40\u90e8\u6ce8\u610f\u529b\u7a00\u758f\u6027\uff0c\u4ece\u800c\u5728\u6240\u6709 Transformer \u7ec4\u4ef6\u4e0a\u5b9e\u73b0\u9ad8\u6548\u7a00\u758f\u5316\u3002\u4e3a\u4fbf\u4e8e\u786c\u4ef6\u5b9e\u73b0\uff0c\u63d0\u51fa\u4e09\u9879\u4f53\u7cfb\u7ed3\u6784\u521b\u65b0\u3002", "result": "\u5728 26 \u4e2a\u57fa\u51c6\u4e0a\uff0cSPLS \u5c06\u603b\u4f53\u8ba1\u7b97\u91cf\u964d\u4f4e 52.03%\uff0c\u7cbe\u5ea6\u635f\u5931\u63a7\u5236\u5728 1% \u4ee5\u5185\u3002ESACT \u7684\u7aef\u5230\u7aef\u80fd\u6548\u8fbe\u5230 3.29 TOPS/W\uff0c\u5728\u6ce8\u610f\u529b\u5c42\u9762\u76f8\u5bf9 SOTA \u52a0\u901f\u5668 SpAtten \u4e0e Sanger\u7684\u80fd\u6548\u63d0\u5347\u5206\u522b\u4e3a 2.95x \u4e0e 2.26x\u3002", "conclusion": "ESA CT \u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7684 Transformer \u7a00\u758f\u5316\u52a0\u901f\uff0c\u8986\u76d6 QKV \u751f\u6210\u3001\u6ce8\u610f\u529b\u8ba1\u7b97\u4e0e FFN \u4e09\u5927\u7ec4\u4ef6\uff0c\u4e14\u901a\u8fc7 SPLS \u5728\u5c40\u90e8\u5c42\u9762\u5b9e\u73b0\u9ad8\u6548\u9884\u6d4b\uff0c\u7ed3\u5408\u786c\u4ef6\u521b\u65b0\u83b7\u5f97\u663e\u8457\u7684\u8ba1\u7b97\u548c\u80fd\u6548\u6536\u76ca\uff0c\u5c55\u793a\u4e86\u5229\u7528\u5c40\u90e8\u76f8\u4f3c\u6027\u8fdb\u884c\u5168\u94fe\u8def\u7a00\u758f\u52a0\u901f\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.02406", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02406", "abs": "https://arxiv.org/abs/2512.02406", "authors": ["Oshada Jayasinghe", "Farhana Choudhury", "Egemen Tanin", "Shanika Karunasekera"], "title": "Dynamic Configuration of On-Street Parking Spaces using Multi Agent Reinforcement Learning", "comment": null, "summary": "With increased travelling needs more than ever, traffic congestion has become a major concern in most urban areas. Allocating spaces for on-street parking, further hinders traffic flow, by limiting the effective road width available for driving. With the advancement of vehicle-to-infrastructure connectivity technologies, we explore how the impact of on-street parking on traffic congestion could be minimized, by dynamically configuring on-street parking spaces. Towards that end, we formulate dynamic on-street parking space configuration as an optimization problem, and we follow a data driven approach, considering the nature of our problem. Our proposed solution comprises a two-layer multi agent reinforcement learning based framework, which is inherently scalable to large road networks. The lane level agents are responsible for deciding the optimal parking space configuration for each lane, and we introduce a novel Deep Q-learning architecture which effectively utilizes long short term memory networks and graph attention networks to capture the spatio-temporal correlations evident in the given problem. The block level agents control the actions of the lane level agents and maintain a sufficient level of parking around the block. We conduct a set of comprehensive experiments using SUMO, on both synthetic data as well as real-world data from the city of Melbourne. Our experiments show that the proposed framework could reduce the average travel time loss of vehicles significantly, reaching upto 47%, with a negligible increase in the walking distance for parking.", "AI": {"tldr": "A scalable two-layer multi-agent reinforcement learning framework for dynamic on-street parking configuration using lane-level and block-level agents, leveraging Deep Q-learning with LSTM and Graph Attention Networks to model spatio-temporal dependencies; validated on SUMO with synthetic and Melbourne data, achieving up to 47% reduction in travel time loss with negligible walking distance increase.", "motivation": "Urban traffic congestion worsens as on-street parking consumes road width. Leveraging vehicle-to-infrastructure connectivity, dynamically configuring parking spaces can alleviate congestion. The goal is a scalable, data-driven optimization framework that can adapt to large road networks.", "method": "A two-layer multi-agent reinforcement learning framework where lane-level agents decide parking configurations per lane and block-level agents coordinate across blocks. The lane-level agents use a novel Deep Q-learning architecture that combines long short-term memory networks and graph attention networks to capture spatio-temporal correlations. Block-level agents regulate lane-level actions to ensure sufficient parking around blocks. Evaluation is conducted in SUMO on synthetic and Melbourne real-world data.", "result": "Experiments show the proposed framework can reduce average travel time loss by up to 47%, with only a negligible increase in walking distance for parking.", "conclusion": "Hierarchical, data-driven RL for dynamic on-street parking is effective and scalable, significantly mitigating travel time loss while preserving parking accessibility, and is suitable for large urban networks."}}
{"id": "2512.02435", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02435", "abs": "https://arxiv.org/abs/2512.02435", "authors": ["Zhongjian Qiao", "Rui Yang", "Jiafei Lyu", "Chenjia Bai", "Xiu Li", "Zhuoran Yang", "Siyang Gao", "Shuang Qiu"], "title": "Cross-Domain Offline Policy Adaptation with Dynamics- and Value-Aligned Data Filtering", "comment": null, "summary": "Cross-Domain Offline Reinforcement Learning aims to train an agent deployed in the target environment, leveraging both a limited target domain dataset and a source domain dataset with (possibly) sufficient data coverage. Due to the underlying dynamics misalignment between the source and target domain, simply merging the data from two datasets may incur inferior performance. Recent advances address this issue by selectively sharing source domain samples that exhibit dynamics alignment with the target domain. However, these approaches focus solely on dynamics alignment and overlook \\textit{value alignment}, i.e., selecting high-quality, high-value samples from the source domain. In this paper, we first demonstrate that both dynamics alignment and value alignment are essential for policy learning, by examining the limitations of the current theoretical framework for cross-domain RL and establishing a concrete sub-optimality gap of a policy trained on the source domain and evaluated on the target domain. Motivated by the theoretical insights, we propose to selectively share those source domain samples with both high dynamics and value alignment and present our \\textbf{\\underline{D}}ynamics- and \\textbf{\\underline{V}}alue-aligned \\textbf{\\underline{D}}ata \\textbf{\\underline{F}}iltering (DVDF) method. We design a range of dynamics shift settings, including kinematic and morphology shifts, and evaluate DVDF on various tasks and datasets, as well as in challenging extremely low-data settings where the target domain dataset contains only 5,000 transitions. Extensive experiments demonstrate that DVDF consistently outperforms prior strong baselines and delivers exceptional performance across multiple tasks and datasets.", "AI": {"tldr": "\u63d0\u51fa DVDF \u7684\u8de8\u57df\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6e90\u57df\u6570\u636e\u8fdb\u884c\u52a8\u6001\u5bf9\u9f50\u548c\u4ef7\u503c\u5bf9\u9f50\u7684\u7b5b\u9009\uff0c\u907f\u514d\u4ec5\u51ed\u52a8\u6001\u5bf9\u9f50\u5bfc\u81f4\u7684\u6b21\u4f18\uff0c\u5e76\u5728\u6781\u4f4e\u6570\u636e\u91cf\u76ee\u6807\u57df\u573a\u666f\u4e0b\u4e5f\u80fd\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u3002", "motivation": "\u8de8\u57df\u79bb\u7ebf RL \u9762\u4e34\u6e90\u57df\u548c\u76ee\u6807\u57df\u52a8\u529b\u5b66\u9519\u914d\uff0c\u5355\u7eaf\u5408\u5e76\u6570\u636e\u5f80\u5f80\u6027\u80fd\u4e0b\u964d\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u5173\u6ce8\u52a8\u529b\u5b66\u5bf9\u9f50\uff0c\u5ffd\u7565\u5728\u6e90\u57df\u4e2d\u7b5b\u9009\u9ad8\u4ef7\u503c\u6837\u672c\u3002\u9700\u8981\u540c\u65f6\u8003\u8651\u4ef7\u503c\u4fe1\u606f\u4ee5\u63d0\u5347\u7b56\u7565\u5b66\u4e60\u6548\u679c\uff1b\u7406\u8bba\u4e0a\u7ed9\u51fa\u5728\u4ec5\u7528\u6e90\u57df\u8bad\u7ec3\u5e76\u5728\u76ee\u6807\u57df\u8bc4\u4f30\u7684\u5b50\u6700\u4f18\u754c\uff0c\u4ee5\u53ca\u5f15\u51fa\u5bf9\u4e24\u7c7b\u5bf9\u9f50\u7684\u5fc5\u8981\u6027\u3002", "method": "\u63d0\u51fa DVDF\uff1a\u52a8\u6001\u4e0e\u4ef7\u503c\u5bf9\u9f50\u7684\u6570\u636e\u7b5b\u9009\u65b9\u6cd5\uff0c\u5728\u6e90\u57df\u6570\u636e\u4e2d\u7b5b\u9009\u51fa\u65e2\u4e0e\u76ee\u6807\u57df\u52a8\u529b\u5b66\u5bf9\u9f50\u3001\u53c8\u5177\u6709\u8f83\u9ad8\u56de\u62a5\u4ef7\u503c\u7684\u6837\u672c\uff0c\u8fdb\u884c\u5171\u4eab\u4e0e\u6df7\u5408\u3002\u8bbe\u8ba1\u8986\u76d6\u591a\u79cd\u52a8\u529b\u5b66\u504f\u79fb\u8bbe\u7f6e\uff08\u8fd0\u52a8\u5b66\u3001\u5f62\u6001\u5b66\u7b49\uff09\u7684\u5b9e\u9a8c\uff0c\u4e14\u5728\u76ee\u6807\u57df\u6570\u636e\u6781\u5c11\uff08\u4ec5 5,000 \u6761\u8f6c\u79fb\uff09\u65f6\u8bc4\u4f30\u5176\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e DVDF \u5728\u591a\u4efb\u52a1/\u6570\u636e\u96c6\u4e0a\u6301\u7eed\u8d85\u8d8a\u5f3a\u57fa\u7ebf\uff0c\u663e\u8457\u63d0\u5347\u8de8\u57df\u79bb\u7ebf RL \u7684\u6027\u80fd\u3002", "conclusion": "\u540c\u65f6\u8003\u8651\u52a8\u529b\u5b66\u5bf9\u9f50\u548c\u4ef7\u503c\u5bf9\u9f50\u662f\u8de8\u57df\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u5173\u952e\uff0cDVDF \u7684\u7b5b\u9009\u7b56\u7565\u80fd\u5728\u4e0d\u540c\u52a8\u529b\u5b66\u504f\u79fb\u548c\u6781\u4f4e\u6570\u636e\u6761\u4ef6\u4e0b\u5b9e\u73b0\u7a33\u5065\u63d0\u5347\u3002"}}
{"id": "2512.02465", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02465", "abs": "https://arxiv.org/abs/2512.02465", "authors": ["Xingwang Li", "Mengyun Chen", "Jiamou Liu", "Sijie Wang", "Shuanggen Jin", "Jafet C. M. Andersson", "Jonas Olsson", "Remco", "van de Beek", "Hai Victor Habi", "Congzheng Han"], "title": "TabGRU: An Enhanced Design for Urban Rainfall Intensity Estimation Using Commercial Microwave Links", "comment": null, "summary": "In the face of accelerating global urbanization and the increasing frequency of extreme weather events, highresolution urban rainfall monitoring is crucial for building resilient smart cities. Commercial Microwave Links (CMLs) are an emerging data source with great potential for this task.While traditional rainfall retrieval from CMLs relies on physicsbased models, these often struggle with real-world complexities like signal noise and nonlinear attenuation. To address these limitations, this paper proposes a novel hybrid deep learning architecture based on the Transformer and a Bidirectional Gated Recurrent Unit (BiGRU), which we name TabGRU. This design synergistically captures both long-term dependencies and local sequential features in the CML signal data. The model is further enhanced by a learnable positional embedding and an attention pooling mechanism to improve its dynamic feature extraction and generalization capabilities. The model was validated on a public benchmark dataset from Gothenburg, Sweden (June-September 2015). The evaluation used 12 sub-links from two rain gauges (Torp and Barl) over a test period (August 22-31) covering approximately 10 distinct rainfall events. The proposed TabGRU model demonstrated consistent advantages, outperforming deep learning baselines and achieving high coefficients of determination (R2) at both the Torp site (0.91) and the Barl site (0.96). Furthermore, compared to the physics-based approach, TabGRU maintained higher accuracy and was particularly effective in mitigating the significant overestimation problem observed in the PL model during peak rainfall events. This evaluation confirms that the TabGRU model can effectively overcome the limitations of traditional methods, providing a robust and accurate solution for CML-based urban rainfall monitoring under the tested conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a TabGRU \u7684\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u5c06 Transformer \u4e0e BiGRU \u7ed3\u5408\uff0c\u7528\u4e8e CML \u6570\u636e\u7684\u57ce\u5e02\u964d\u96e8\u76d1\u6d4b\u3002\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u5d4c\u5165\u548c\u6ce8\u610f\u529b\u6c60\u5316\u63d0\u5347\u7279\u5f81\u63d0\u53d6\u4e0e\u6cdb\u5316\uff0c\u5728\u54e5\u5fb7\u5821\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u4e8e\u57fa\u7ebf\u548c\u7269\u7406\u6a21\u578b\u7684\u8868\u73b0\uff0c\u9c81\u68d2\u6027\u8f83\u597d\uff0c\u80fd\u7f13\u89e3\u5cf0\u503c\u964d\u96e8\u65f6\u7684\u8fc7\u5ea6\u4f30\u8ba1\u3002", "motivation": "\u5728\u5168\u7403\u57ce\u5e02\u5316\u52a0\u901f\u548c\u6781\u7aef\u5929\u6c14\u589e\u591a\u7684\u80cc\u666f\u4e0b\uff0c\u9700\u8981\u9ad8\u5206\u8fa8\u7387\u7684\u57ce\u5e02\u964d\u96e8\u76d1\u6d4b\u3002\u5546\u4e1a\u5fae\u6ce2\u94fe\u8def\uff08CML\uff09\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u57fa\u4e8e\u7269\u7406\u6a21\u578b\u7684\u964d\u96e8\u63d0\u53d6\u5728\u5b9e\u9645\u566a\u58f0\u548c\u975e\u7ebf\u6027\u8870\u51cf\u4e0b\u8868\u73b0\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u540c\u65f6\u6355\u6349\u957f\u65f6\u4f9d\u8d56\u4e0e\u5c40\u90e8\u5e8f\u5217\u7279\u5f81\u7684\u5f3a\u5927\u6a21\u578b\u3002", "method": "\u63d0\u51fa TabGRU\uff0c\u878d\u5408 Transformer \u4e0e\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08BiGRU\uff09\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u5d4c\u5165\u548c\u6ce8\u610f\u529b\u6c47\u805a\u673a\u5236\u63d0\u5347\u52a8\u6001\u7279\u5f81\u63d0\u53d6\u4e0e\u6cdb\u5316\u3002\u57fa\u4e8e Gothenburg \u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\uff082015 \u5e74 6\u20139 \u6708\uff09\uff0c\u5728 12 \u6761\u5b50\u94fe\u8def\u3001\u6765\u81ea Torp \u4e0e Barl \u4e24\u4e2a\u96e8\u91cf\u8ba1\u7684\u6d4b\u8bd5\u533a\u95f4\uff088 \u6708 22\u201331 \u65e5\uff0c\u7ea6 10 \u6b21\u964d\u96e8\u4e8b\u4ef6\uff09\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u76f8\u8f83\u4e8e\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\uff0cTabGRU \u8868\u73b0\u7a33\u5b9a\uff0cR^2 \u5728 Torp \u4e3a 0.91\uff0c\u5728 Barl \u4e3a 0.96\uff1b\u6bd4\u7269\u7406\u6a21\u578b\uff08PL\uff09\u5728\u5cf0\u503c\u964d\u96e8\u65f6\u5bf9\u8fc7\u4f30\u8ba1\u95ee\u9898\u6709\u663e\u8457\u7f13\u89e3\uff0c\u603b\u4f53\u4fdd\u6301\u66f4\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "TabGRU \u80fd\u6709\u6548\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728 tested \u6761\u4ef6\u4e0b\u4e3a\u57fa\u4e8e CML \u7684\u57ce\u5e02\u964d\u96e8\u76d1\u6d4b\u63d0\u4f9b\u9c81\u68d2\u3001\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02486", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02486", "abs": "https://arxiv.org/abs/2512.02486", "authors": ["Zhongjian Qiao", "Rui Yang", "Jiafei Lyu", "Xiu Li", "Zhongxiang Dai", "Zhuoran Yang", "Siyang Gao", "Shuang Qiu"], "title": "Dual-Robust Cross-Domain Offline Reinforcement Learning Against Dynamics Shifts", "comment": null, "summary": "Single-domain offline reinforcement learning (RL) often suffers from limited data coverage, while cross-domain offline RL handles this issue by leveraging additional data from other domains with dynamics shifts. However, existing studies primarily focus on train-time robustness (handling dynamics shifts from training data), neglecting the test-time robustness against dynamics perturbations when deployed in practical scenarios. In this paper, we investigate dual (both train-time and test-time) robustness against dynamics shifts in cross-domain offline RL. We first empirically show that the policy trained with cross-domain offline RL exhibits fragility under dynamics perturbations during evaluation, particularly when target domain data is limited. To address this, we introduce a novel robust cross-domain Bellman (RCB) operator, which enhances test-time robustness against dynamics perturbations while staying conservative to the out-of-distribution dynamics transitions, thus guaranteeing the train-time robustness. To further counteract potential value overestimation or underestimation caused by the RCB operator, we introduce two techniques, the dynamic value penalty and the Huber loss, into our framework, resulting in the practical \\textbf{D}ual-\\textbf{RO}bust \\textbf{C}ross-domain \\textbf{O}ffline RL (DROCO) algorithm. Extensive empirical results across various dynamics shift scenarios show that DROCO outperforms strong baselines and exhibits enhanced robustness to dynamics perturbations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u8de8\u57df\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u63d0\u5347\u8bad\u7ec3\u65f6\u548c\u6d4b\u8bd5\u65f6\u5bf9\u52a8\u529b\u5b66\u504f\u79fb\u9c81\u68d2\u6027\u7684\u7b97\u6cd5DROCO\uff0c\u6838\u5fc3\u662f\u9c81\u68d2\u8de8\u57dfBellman\uff08RCB\uff09\u8fd0\u7b97\u7b26\uff0c\u5e76\u7ed3\u5408\u52a8\u6001\u503c\u60e9\u7f5a\u4e0eHuber\u635f\u5931\u4ee5\u7f13\u89e3\u503c\u51fd\u6570\u4f30\u8ba1\u504f\u5dee\u3002", "motivation": "\u89e3\u51b3\u5355\u57df\u79bb\u7ebfRL\u4e2d\u6570\u636e\u8986\u76d6\u4e0d\u8db3\u5bfc\u81f4\u7684\u6027\u80fd\u74f6\u9888\uff0c\u4ee5\u53ca\u8de8\u57df\u79bb\u7ebfRL\u5728\u8bad\u7ec3\u9636\u6bb5\u5f15\u5165\u52a8\u529b\u5b66\u504f\u79fb\u65f6\u7684\u9c81\u68d2\u6027\u4e0d\u8db3\u95ee\u9898\uff0c\u5e76\u5ef6\u4f38\u5230\u6d4b\u8bd5\u9636\u6bb5\u5bf9\u52a8\u529b\u5b66\u6270\u52a8\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u9c81\u68d2\u8de8\u57dfBellman\uff08RCB\uff09\u8fd0\u7b97\u7b26\uff0c\u4f7f\u8bad\u7ec3\u65f6\u5bf9\u672a\u77e5\u6216\u5206\u5e03\u5916\u7684\u52a8\u529b\u5b66\u8f6c\u79fb\u4fdd\u6301\u4fdd\u5b88\u6027\u4ee5\u786e\u4fdd\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u63d0\u9ad8\u5bf9\u6d4b\u8bd5\u65f6\u52a8\u529b\u5b66\u6270\u52a8\u7684\u9c81\u68d2\u6027\u3002\u4e3a\u907f\u514dRCB\u5f15\u8d77\u7684\u503c\u4f30\u8ba1\u504f\u5dee\uff0c\u7ed3\u5408\u52a8\u6001\u503c\u60e9\u7f5a\u4e0eHuber\u635f\u5931\uff0c\u5f62\u6210\u5b9e\u9645\u53ef\u7528\u7684DROCO\u6846\u67b6\u3002", "result": "\u5728\u591a\u79cd\u52a8\u529b\u5b66\u504f\u79fb\u573a\u666f\u4e0b\uff0cDROCO\u76f8\u5bf9\u4e8e\u5f3a\u57fa\u7ebf\u8868\u73b0\u66f4\u597d\uff0c\u5bf9\u52a8\u529b\u5b66\u6270\u52a8\u5177\u6709\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "DROCO\u80fd\u591f\u53cc\u91cd\u9c81\u68d2\u5316\u8de8\u57df\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u5347\u5728\u52a8\u6001\u53d8\u5316\u73af\u5883\u4e2d\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\uff0c\u5177\u5907\u8f83\u5f3a\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2512.02489", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02489", "abs": "https://arxiv.org/abs/2512.02489", "authors": ["Mithra D K"], "title": "Hybrid(Penalized Regression and MLP) Models for Outcome Prediction in HDLSS Health Data", "comment": null, "summary": "I present an application of established machine learning techniques to NHANES health survey data for predicting diabetes status. I compare baseline models (logistic regression, random forest, XGBoost) with a hybrid approach that uses an XGBoost feature encoder and a lightweight multilayer perceptron (MLP) head. Experiments show the hybrid model attains improved AUC and balanced accuracy compared to baselines on the processed NHANES subset. I release code and reproducible scripts to encourage replication.", "AI": {"tldr": "\u6df7\u5408\u6a21\u578b\u5bf9NHANES\u7cd6\u5c3f\u75c5\u9884\u6d4b\u6709\u6539\u8fdb\uff1a\u57fa\u7ebf\u6a21\u578b\u4e0e\u4ee5XGBoost\u7f16\u7801\u5668\u4e3a\u7279\u5f81\u7684MLP\u5934\u76f8\u7ed3\u5408\uff0c\u63d0\u5347AUC\u4e0e\u5e73\u8861\u51c6\u786e\u7387\uff0c\u4e14\u63d0\u4f9b\u4ee3\u7801\u4ee5\u4fbf\u590d\u73b0\u3002", "motivation": "\u5728NHANES\u5065\u5eb7\u8c03\u67e5\u6570\u636e\u4e0a\u5e94\u7528\u6210\u719f\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\u6765\u9884\u6d4b\u7cd6\u5c3f\u75c5\u72b6\u6001\uff0c\u5e76\u7cfb\u7edf\u6bd4\u8f83\u57fa\u7ebf\u6a21\u578b\u4e0e\u6df7\u5408\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5f3a\u8c03\u53ef\u590d\u73b0\u6027\u3002", "method": "\u6bd4\u8f83\u57fa\u7ebf\u6a21\u578b\uff1a\u903b\u8f91\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u3001XGBoost\uff1b\u63d0\u51fa\u6df7\u5408\u65b9\u6cd5\uff1a\u7528XGBoost\u4f5c\u4e3a\u7279\u5f81\u7f16\u7801\u5668\uff0c\u518d\u63a5\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u591a\u5c42\u611f\u77e5\u673a(MLP)\u5934\u3002\u5bf9\u7ecf\u8fc7\u5904\u7406\u7684NHANES\u5b50\u96c6\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u4ee5AUC\u548c\u5e73\u8861\u51c6\u786e\u7387\u8861\u91cf\u6027\u80fd\uff0c\u5e76\u53d1\u5e03\u53ef\u590d\u73b0\u7684\u4ee3\u7801\u4e0e\u811a\u672c\u3002", "result": "\u6df7\u5408\u6a21\u578b\u5728\u5904\u7406\u540e\u7684NHANES\u5b50\u96c6\u4e0a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u83b7\u5f97\u66f4\u9ad8\u7684AUC\u548c\u66f4\u597d\u7684\u5e73\u8861\u51c6\u786e\u7387\u3002", "conclusion": "\u5728\u7cd6\u5c3f\u75c5\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u91c7\u7528\u7f16\u7801\u5668+MLP\u5934\u7684\u6df7\u5408\u65b9\u6cd5\u53ef\u5e26\u6765\u6027\u80fd\u63d0\u5347\uff0c\u7814\u7a76\u8005\u540c\u65f6\u516c\u5f00\u4ee3\u7801\u4ee5\u4fc3\u8fdb\u7ed3\u679c\u590d\u73b0\u3002"}}
{"id": "2512.02494", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02494", "abs": "https://arxiv.org/abs/2512.02494", "authors": ["Zihao Zhao", "Kai-Chia Mo", "Shing-Hei Ho", "Brandon Amos", "Kai Wang"], "title": "A Fully First-Order Layer for Differentiable Optimization", "comment": null, "summary": "Differentiable optimization layers enable learning systems to make decisions by solving embedded optimization problems. However, computing gradients via implicit differentiation requires solving a linear system with Hessian terms, which is both compute- and memory-intensive. To address this challenge, we propose a novel algorithm that computes the gradient using only first-order information. The key insight is to rewrite the differentiable optimization as a bilevel optimization problem and leverage recent advances in bilevel methods. Specifically, we introduce an active-set Lagrangian hypergradient oracle that avoids Hessian evaluations and provides finite-time, non-asymptotic approximation guarantees. We show that an approximate hypergradient can be computed using only first-order information in $\\tilde{\\oo}(1)$ time, leading to an overall complexity of $\\tilde{\\oo}(\u03b4^{-1}\u03b5^{-3})$ for constrained bilevel optimization, which matches the best known rate for non-smooth non-convex optimization. Furthermore, we release an open-source Python library that can be easily adapted from existing solvers. Our code is available here: https://github.com/guaguakai/FFOLayer.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4ec5\u4f7f\u7528\u4e00\u9636\u4fe1\u606f\u7684\u5dee\u5206\u4f18\u5316\u5c42\u68af\u5ea6\u8ba1\u7b97\u65b9\u6cd5\uff1a\u5c06\u4f18\u5316\u95ee\u9898\u6539\u5199\u4e3a\u53cc\u5c42\u7ed3\u6784\uff0c\u5229\u7528\u6d3b\u8dc3\u96c6\u62c9\u683c\u6717\u65e5\u8d85\u68af\u5ea6\u5b50\u7a0b\u5e8f\u907f\u514d\u6d77\u68ee\u77e9\u9635\u8ba1\u7b97\uff0c\u7406\u8bba\u4e0a\u7ed9\u51fa\u975e\u6e10\u8fd1\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4fdd\u8bc1\uff0c\u5e76\u7ed9\u51fa\u5f00\u6e90\u5b9e\u73b0\u3002", "motivation": "\u4f20\u7edf\u7684\u9690\u5f0f\u6c42\u5bfc\u5728\u8ba1\u7b97\u68af\u5ea6\u65f6\u9700\u8981\u6c42\u89e3\u6d77\u68ee\u77e9\u9635\u76f8\u5173\u7684\u7ebf\u6027\u65b9\u7a0b\u7ec4\uff0c\u8ba1\u7b97\u91cf\u548c\u5185\u5b58\u5f00\u9500\u9ad8\u3002\u901a\u8fc7\u5c06\u5dee\u5206\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u53cc\u5c42\u4f18\u5316\u5e76\u91c7\u7528\u4e00\u9636\u4fe1\u606f\uff0c\u53ef\u663e\u8457\u964d\u4f4e\u6210\u672c\u5e76\u83b7\u5f97\u7406\u8bba\u4fdd\u8bc1\u3002", "method": "\u5c06\u5dee\u5206\u4f18\u5316\u89c6\u4e3a\u53cc\u5c42\u4f18\u5316\uff0c\u63d0\u51fa\u4e00\u4e2a\u6d3b\u8dc3\u96c6\u62c9\u683c\u6717\u65e5\u8d85\u68af\u5ea6\u54c8\u5e0coracle\uff0c\u907f\u514d\u6d77\u68ee\u77e9\u9635\u8ba1\u7b97\uff0c\u63d0\u4f9b\u6709\u9650\u65f6\u95f4\u3001\u975e\u6e10\u8fd1\u7684\u8fd1\u4f3c\u4fdd\u8bc1\u3002\u4ee5\u4ec5\u4f7f\u7528\u4e00\u9636\u4fe1\u606f\u5728 \u007f\u001c(1) \u65f6\u95f4\u5185\u8fd1\u4f3c\u8d85\u68af\u5ea6\uff0c\u5e76\u5f97\u5230\u5bf9\u7ea6\u675f\u53cc\u5c42\u4f18\u5316\u7684\u603b\u4f53\u590d\u6742\u5ea6\u4e3a \u007f\u001c(\u03b4^{-1}\u03b5^{-3})\uff0c\u4e0e\u975e\u5149\u6ed1\u975e\u51f8\u4f18\u5316\u7684\u6700\u4f73\u5df2\u77e5\u7387\u4e00\u81f4\u3002\u516c\u5f00\u5b9e\u73b0\u5e93\uff0c\u57fa\u4e8e\u73b0\u6709\u6c42\u89e3\u5668\u6539\u9020\u5373\u53ef\u4f7f\u7528\u3002", "result": "\u53ef\u5728\u4ec5\u4f7f\u7528\u4e00\u9636\u4fe1\u606f\u7684\u6761\u4ef6\u4e0b\uff0c\u8fd1\u4f3c\u8d85\u68af\u5ea6\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \u007f\u001c(1)\uff0c\u603b\u4f53\u590d\u6742\u5ea6\u4e3a \u007f\u001c(\u03b4^{-1}\u03b5^{-3})\uff0c\u4e0e\u73b0\u6709\u975e\u5149\u6ed1\u975e\u51f8\u4f18\u5316\u7684\u6700\u4f73\u901f\u7387\u76f8\u5339\u914d\u3002\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6613\u4e8e\u79fb\u690d\u7684\u5f00\u6e90Python\u5e93\u3002", "conclusion": "\u4e3a\u5dee\u5206\u4f18\u5316\u5c42\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u68af\u5ea6\u8ba1\u7b97\u65b9\u6848\uff0c\u907f\u514d\u6d77\u68ee\u77e9\u9635\u5e26\u6765\u7684\u8ba1\u7b97\u8d1f\u62c5\uff0c\u5e76\u4e14\u5177\u5907\u660e\u786e\u7684\u7406\u8bba\u6536\u655b/\u8fd1\u4f3c\u4fdd\u8bc1\u4e0e\u53ef\u590d\u73b0\u7684\u5b9e\u73b0\u3002"}}
{"id": "2512.02508", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02508", "abs": "https://arxiv.org/abs/2512.02508", "authors": ["Marco Cardia", "Stefano Chessa", "Alessio Micheli", "Antonella Giuliana Luminare", "Francesca Gambineri"], "title": "Water Quality Estimation Through Machine Learning Multivariate Analysis", "comment": "The paper has been accepted at Italian Workshop on Neural Networks (WIRN) 2024", "summary": "The quality of water is key for the quality of agrifood sector. Water is used in agriculture for fertigation, for animal husbandry, and in the agrifood processing industry. In the context of the progressive digitalization of this sector, the automatic assessment of the quality of water is thus becoming an important asset. In this work, we present the integration of Ultraviolet-Visible (UV-Vis) spectroscopy with Machine Learning in the context of water quality assessment aiming at ensuring water safety and the compliance of water regulation. Furthermore, we emphasize the importance of model interpretability by employing SHapley Additive exPlanations (SHAP) to understand the contribution of absorbance at different wavelengths to the predictions. Our approach demonstrates the potential for rapid, accurate, and interpretable assessment of key water quality parameters.", "AI": {"tldr": "UV-Vis spectroscopy combined with machine learning and SHAP enables rapid, interpretable water quality assessment for the agrifood sector.", "motivation": "\u6c34\u8d28\u5bf9\u4e8e\u519c\u4ea7\u54c1\u9886\u57df\u81f3\u5173\u91cd\u8981\uff0c\u6c34\u5728\u704c\u6e89\u3001\u755c\u79bd\u517b\u6b96\u548c\u52a0\u5de5\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u3002\u968f\u7740\u6570\u5b57\u5316\u63a8\u8fdb\uff0c\u9700\u5feb\u901f\u3001\u53ef\u89e3\u91ca\u7684\u6c34\u8d28\u8bc4\u4f30\u4ee5\u786e\u4fdd\u5b89\u5168\u548c\u5408\u89c4\u3002", "method": "\u5c06\u7d2b\u5916-\u53ef\u89c1\u5149\u8c31\u6570\u636e\u4e0e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7ed3\u5408\uff0c\u5e76\u4f7f\u7528 SHAP \u89e3\u91ca\u6a21\u578b\u5bf9\u4e0d\u540c\u6ce2\u957f\u5438\u6536\u5ea6\u7684\u8d21\u732e\uff0c\u4ece\u800c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u6c34\u8d28\u53c2\u6570\u9884\u6d4b\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5c55\u793a\u51fa\u5728\u5feb\u901f\u3001\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u5730\u8bc4\u4f30\u5173\u952e\u6c34\u8d28\u53c2\u6570\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4f46\u6458\u8981\u672a\u7ed9\u51fa\u5177\u4f53\u6570\u503c\u7ed3\u679c\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u4fdd\u969c\u6c34\u5b89\u5168\u4e0e\u6cd5\u89c4\u5408\u89c4\uff0c\u5e76\u80fd\u63a8\u52a8\u519c\u98df\u4f9b\u5e94\u94fe\u4e2d\u66f4\u5feb\u901f\u7684\u51b3\u7b56\u3002"}}
{"id": "2512.02551", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02551", "abs": "https://arxiv.org/abs/2512.02551", "authors": ["Songqiao Su", "Xiaofei Sun", "Xiaoya Li", "Albert Wang", "Jiwei Li", "Chris Shum"], "title": "CUDA-L2: Surpassing cuBLAS Performance for Matrix Multiplication through Reinforcement Learning", "comment": null, "summary": "In this paper, we propose CUDA-L2, a system that combines large language models (LLMs) and reinforcement learning (RL) to automatically optimize Half-precision General Matrix Multiply (HGEMM) CUDA kernels. Using CUDA execution speed as the RL reward, CUDA-L2 automatically optimizes HGEMM kernels across 1,000 configurations. CUDA-L2 systematically outperforms major matmul baselines to date, from the widely-used {\\it torch.matmul} to state-of-the-art Nvidia's closed-source libraries, i.e., {\\it cuBLAS}, {\\it cuBLASLt}. In offline mode, where kernels are executed consecutively without time intervals, CUDA-L2 yields +22.0\\% over {\\it torch.matmul} on average; +19.2\\% over {\\it cuBLAS} using the optimal layout configuration (normal-normal NN and transposed-normal TN); +16.8\\% over {\\it cuBLASLt-heuristic}, which queries {\\it cuBLASLt} library and selects the algorithm based on the heuristic's suggestion; and +11.4\\% over the most competitive {\\it cuBLASLt-AutoTuning} model, which selects the fastest algorithm from up to 100 candidates from {\\it cuBLASLt}'s suggestions. In server mode, where kernels are executed at random intervals simulating real-time inference, the speedups further increase to +28.7\\%, +26.0\\%, +22.4\\%, and +15.9\\% for {\\it torch.matmul}, {\\it cuBLAS}, {\\it cuBLASLt-heuristic}, and {\\it cuBLASLt-AutoTuning} respectively. CUDA-L2 shows that even the most performance-critical, heavily-optimized kernels like HGEMM can be improved through LLM-guided RL automation by systematically exploring configuration spaces at scales impractical for humans. Project and code can be found at github.com/deepreinforce-ai/CUDA-L2", "AI": {"tldr": "A system CUDA-L2 uses\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u4e0e\u5f3a\u5316\u5b66\u4e60(RL)\u7ed3\u5408\uff0c\u81ea\u52a8\u4f18\u5316HGEMM CUDA\u5185\u6838\u57281000\u79cd\u914d\u7f6e\u4e0a\u7684\u6027\u80fd\uff0c\u901a\u8fc7RL\u5956\u52b1\u4fe1\u53f7\u7684CUDA\u6267\u884c\u901f\u5ea6\u5b9e\u73b0\u81ea\u52a8\u5316\u8c03\u4f18\uff0c\u663e\u8457\u8d85\u8d8a\u4e3b\u6d41\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3HGEMM\u7b49\u9ad8\u6027\u80fd\u77e9\u9635\u4e58\u6cd5\u5728\u5e9e\u5927\u914d\u7f6e\u7a7a\u95f4\u4e2d\u7684\u4f18\u5316\u96be\u9898\uff1b\u73b0\u6709cuBLAS/ cuBLASLt\u7b49\u5e93\u7684\u7b97\u6cd5\u9009\u62e9\u548c\u5b9e\u73b0\u672a\u5fc5\u80fd\u5728\u7279\u5b9a\u8f93\u5165\u3001\u5e03\u5c40\u4e0e\u7cbe\u5ea6\u4e0b\u8fbe\u5230\u6700\u4f18\uff1b\u5229\u7528LLM\u4e0eRL\u5728\u5927\u89c4\u6a21\u914d\u7f6e\u641c\u7d22\u4e2d\u5f15\u5bfc\u4f18\u5316\uff0c\u63d0\u5347\u63a8\u7406/\u8bad\u7ec3\u4e2d\u7684\u5b9e\u9645\u6027\u80fd\u3002", "method": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u6784\u5efaCUDA-L2\u7cfb\u7edf\uff1b\u57281000\u79cd\u914d\u7f6e\u4e2d\u7cfb\u7edf\u5730\u63a2\u7d22\uff0c\u4ee5CUDA\u6267\u884c\u901f\u5ea6\u4f5c\u4e3a\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u4fe1\u53f7\uff1b\u79bb\u7ebf\u6a21\u5f0f\u4e0b\u8fde\u7eed\u6267\u884c\u5185\u6838\u5e76\u8bc4\u4f30\u6027\u80fd\uff1b\u670d\u52a1\u5668\u6a21\u5f0f\u6a21\u62df\u771f\u5b9e\u5728\u7ebf\u63a8\u7406\u573a\u666f\u3002\u4e0e\u57fa\u7ebf\u6bd4\u8f83\u5305\u62ectorch.matmul\u3001cuBLAS\u3001cuBLASLt\u7684\u542f\u53d1\u5f0f\u53caAutoTuning\u7b49\u7b56\u7565\u3002", "result": "\u79bb\u7ebf\u6a21\u5f0f\uff1a\u76f8\u6bd4torch.matmul\u63d0\u5347+22.0%\uff1b\u76f8\u5bf9cuBLAS\u63d0\u5347+19.2%\uff08\u6700\u4f18\u5e03\u5c40NN\u548cTN\uff09\uff1b\u76f8\u5bf9cuBLASLt-heuristic\u63d0\u5347+16.8%\uff1b\u76f8\u5bf9cuBLASLt-AutoTuning\u63d0\u5347+11.4%\u3002\u670d\u52a1\u5668\u6a21\u5f0f\uff1a\u76f8\u5bf9torch.matmul\u63d0\u5347+28.7%\uff1b\u76f8\u5bf9cuBLAS\u63d0\u5347+26.0%\uff1b\u76f8\u5bf9cuBLASLt-heuristic\u63d0\u5347+22.4%\uff1b\u76f8\u5bf9cuBLASLt-AutoTuning\u63d0\u5347+15.9%\u3002", "conclusion": "LLM-guided RL\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u5728\u5927\u5c3a\u5bf8\u7684\u914d\u7f6e\u7a7a\u95f4\u4e2d\u4f18\u5316\u6027\u80fd\u5173\u952e\u7684HGEMM\u5185\u6838\uff0c\u83b7\u5f97\u663e\u8457\u901f\u5ea6\u63d0\u5347\uff0c\u8bc1\u660e\u4e86LLM/ RL\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u4f18\u5316\u4e2d\u7684\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u5e76\u7ed9\u51fa\u53ef\u590d\u7528\u7684\u4ee3\u7801\u4e0e\u5b9e\u73b0\u3002"}}
{"id": "2512.02581", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02581", "abs": "https://arxiv.org/abs/2512.02581", "authors": ["Chubin Zhang", "Zhenglin Wan", "Feng Chen", "Xingrui Yu", "Ivor Tsang", "Bo An"], "title": "GoRL: An Algorithm-Agnostic Framework for Online Reinforcement Learning with Generative Policies", "comment": "27 pages", "summary": "Reinforcement learning (RL) faces a persistent tension: policies that are stable to optimize are often too simple to represent the multimodal action distributions needed for complex control. Gaussian policies provide tractable likelihoods and smooth gradients, but their unimodal form limits expressiveness. Conversely, generative policies based on diffusion or flow matching can model rich multimodal behaviors; however, in online RL, they are frequently unstable due to intractable likelihoods and noisy gradients propagating through deep sampling chains. We address this tension with a key structural principle: decoupling optimization from generation. Building on this insight, we introduce GoRL (Generative Online Reinforcement Learning), a framework that optimizes a tractable latent policy while utilizing a conditional generative decoder to synthesize actions. A two-timescale update schedule enables the latent policy to learn stably while the decoder steadily increases expressiveness, without requiring tractable action likelihoods. Across a range of continuous-control tasks, GoRL consistently outperforms both Gaussian policies and recent generative-policy baselines. Notably, on the HopperStand task, it reaches a normalized return above 870, more than 3 times that of the strongest baseline. These results demonstrate that separating optimization from generation provides a practical path to policies that are both stable and highly expressive.", "AI": {"tldr": "GoRL\u901a\u8fc7\u5c06\u4f18\u5316\u4e0e\u751f\u6210\u5206\u79bb\uff0c\u5b66\u4e60\u4e00\u4e2a\u53ef tractable \u7684\u6f5c\u5728\u7b56\u7565\u5e76\u5229\u7528\u6761\u4ef6\u751f\u6210\u89e3\u7801\u5668\u5408\u6210\u52a8\u4f5c\uff0c\u4ece\u800c\u5728\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u5b9e\u73b0\u7a33\u5b9a\u4e14\u8868\u8fbe\u529b\u5f3a\u7684\u7b56\u7565\uff0c\u8d85\u8d8a\u9ad8\u65af\u7b56\u7565\u4e0e\u8fd1\u671f\u751f\u6210\u7b56\u7565\u57fa\u7ebf\uff0c HopperStand \u8fbe\u5230 >870 \u7684\u5f52\u4e00\u5316\u56de\u62a5\uff08>3x \u6700\u5f3a\u57fa\u7ebf\uff09", "motivation": "\u5728 RL \u4e2d\uff0c\u7a33\u5b9a/\u7b80\u5355\u7684\u7b56\u7565\u6613\u4e8e\u4f18\u5316\u4f46\u96be\u4ee5\u8868\u793a\u591a\u6a21\u6001\u884c\u52a8\u5206\u5e03\uff1b\u800c\u57fa\u4e8e\u6269\u6563/\u6d41\u91cf\u5339\u914d\u7684\u751f\u6210\u7b56\u7565\u867d\u5177\u8868\u8fbe\u529b\uff0c\u4f46\u5728\u7ebf\u5b66\u4e60\u4e2d\u56e0\u96be\u4ee5\u5904\u7406\u7684\u4f3c\u7136\u6027\u548c\u6df1\u5c42\u91c7\u6837\u94fe\u5e26\u6765\u7684\u68af\u5ea6\u566a\u58f0\u800c\u4e0d\u7a33\u5b9a\u3002\u9700\u8981\u4e00\u79cd\u5728\u4f18\u5316\u4e0e\u751f\u6210\u4e4b\u95f4\u89e3\u8026\u7684\u7ed3\u6784\u539f\u5219\u3002", "method": "\u63d0\u51fa GoRL \u6846\u67b6\uff1a\u901a\u8fc7\u4e24\u65f6\u95f4\u5c3a\u5ea6\u66f4\u65b0\uff0c\u4f18\u5316\u4e00\u4e2a\u53ef tractable \u7684\u6f5c\u5728\u7b56\u7565\uff0c\u540c\u65f6\u4f7f\u7528\u6761\u4ef6\u751f\u6210\u89e3\u7801\u5668\u6765\u5408\u6210\u52a8\u4f5c\uff0c\u4f7f\u5f97\u6f5c\u5728\u7b56\u7565\u5b66\u4e60\u7a33\u5b9a\u800c\u89e3\u7801\u5668\u9010\u6b65\u63d0\u5347\u8868\u8fbe\u529b\uff1b\u65e0\u9700\u53ef tractable \u7684\u884c\u52a8\u4f3c\u7136\u3002", "result": "\u5728\u591a\u4efb\u52a1\u8fde\u7eed\u63a7\u5236\u4e0a\uff0cGoRL \u5728\u591a\u9879\u57fa\u7ebf\u4e0a\u53d6\u5f97\u66f4\u597d\u8868\u73b0\uff1b\u5728 HopperStand \u4efb\u52a1\u4e2d\u5f52\u4e00\u5316\u56de\u62a5\u8d85\u8fc7 870\uff0c\u662f\u6700\u5f3a\u57fa\u7ebf\u7684\u4e09\u500d\u4ee5\u4e0a\u3002", "conclusion": "\u5c06\u4f18\u5316\u4e0e\u751f\u6210\u5206\u79bb\u63d0\u4f9b\u4e00\u6761\u5b9e\u7528\u8def\u5f84\uff0c\u517c\u5177\u7a33\u5b9a\u6027\u548c\u9ad8\u5ea6\u8868\u8fbe\u529b\uff0c\u9002\u7528\u4e8e\u9700\u8981\u590d\u6742\u884c\u52a8\u5206\u5e03\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u573a\u666f\u3002"}}
{"id": "2512.02618", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.02618", "abs": "https://arxiv.org/abs/2512.02618", "authors": ["Wenhao Sha", "Tienchong Chang"], "title": "Modeling and Inverse Identification of Interfacial Heat Conduction in Finite Layer and Semi-Infinite Substrate Systems via a Physics-Guided Neural Framework", "comment": null, "summary": "Heat transfer in semiconductor devices is dominated by chip and substrate assemblies, where heat generated within a finite chip layer dissipates into a semi-infinite substrate with much higher thermophysical properties. This mismatch produces steep interfacial temperature gradients, making the transient thermal response highly sensitive to the interface. Conventional numerical solvers require excessive discretization to resolve these dynamics, while physics-informed neural networks (PINNs) often exhibit unstable convergence and loss of physical consistency near the material interface. To address these challenges, we introduce HeatTransFormer, a physics-guided Transformer architecture for interface-dominated diffusion problems. The framework integrates physically informed spatiotemporal sampling, a Laplace-based activation emulating analytical diffusion solutions, and a mask-free attention mechanism supporting bidirectional spatiotemporal coupling. These components enable the model to resolve steep gradients, maintain physical consistency, and remain stable where PINNs typically fail. HeatTransFormer produces coherent temperature fields across the interface when applied to a finite layer and semi-infinite substrate configuration. Coupled with a physics-constrained inverse strategy, it further enables reliable identification of three unknown thermal properties simultaneously using only external measurements. Overall, this work demonstrates that physics-guided Transformer architectures provide a unified framework for forward and inverse modeling in interface-dominated thermal systems.", "AI": {"tldr": "HeatTransFormer \u4ee5\u7269\u7406\u5f15\u5bfc\u7684 Transformer \u6846\u67b6\u89e3\u51b3\u82af\u7247-\u57fa\u677f\u754c\u9762\u7684\u6269\u6563\u95ee\u9898\uff0c\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u91c7\u6837\u3001\u62c9\u666e\u62c9\u65af\u6fc0\u6d3b\u548c\u65e0\u63a9\u819c\u6ce8\u610f\u529b\uff0c\u5b9e\u73b0\u524d\u540e\u5411\u5efa\u6a21\u4e0e\u4e09\u79cd\u5f85\u8bc6\u522b\u70ed\u53c2\u6570\u7684\u7a33\u5065\u9006\u63a8\u3002", "motivation": "\u82af\u7247\u5c42\u4e0e\u534a\u65e0\u9650\u57fa\u677f\u95f4\u7684\u5f3a\u70ed\u8026\u5408\u5bfc\u81f4\u754c\u9762\u5904\u7684\u9ad8\u68af\u5ea6\u548c\u5bf9\u754c\u9762\u7684\u654f\u611f\u6027\uff1b\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u9700\u5927\u91cf\u7f51\u683c\uff0cPINN \u5728\u754c\u9762\u533a\u57df\u6613\u5931\u7a33\u6216\u5931\u53bb\u7269\u7406\u4e00\u81f4\u6027\uff0c\u9700\u66f4\u7a33\u5065\u3001\u7edf\u4e00\u7684\u524d/\u540e\u5411\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa HeatTransFormer\uff1a\u5728\u65f6\u7a7a\u57df\u5f15\u5165\u7269\u7406\u4fe1\u606f\u91c7\u6837\u3001\u4f7f\u7528\u4eff\u771f\u6269\u6563\u89e3\u7684\u62c9\u666e\u62c9\u65af\u6fc0\u6d3b\u51fd\u6570\u3001\u4ee5\u53ca\u652f\u6301\u53cc\u5411\u65f6\u7a7a\u8026\u5408\u7684\u65e0\u63a9\u819c\u6ce8\u610f\u529b\u3002\u8be5\u6846\u67b6\u53ef\u89e3\u51b3\u754c\u9762\u5904\u7684\u68af\u5ea6\u95ee\u9898\uff0c\u4fdd\u6301\u7269\u7406\u4e00\u81f4\u6027\uff0c\u5e76\u5728 PINN \u5931\u6548\u533a\u95f4\u8868\u73b0\u7a33\u5b9a\u3002\u4e0e\u7269\u7406\u7ea6\u675f\u7684\u9006\u63a8\u7b56\u7565\u7ed3\u5408\uff0c\u80fd\u591f\u4ec5\u57fa\u4e8e\u5916\u90e8\u6d4b\u91cf\u8bc6\u522b\u4e09\u4e2a\u672a\u77e5\u70ed\u53c2\u6570\u3002", "result": "\u5728\u6709\u9650\u5c42\u4e0e\u534a\u65e0\u9650\u57fa\u5e95\u914d\u7f6e\u4e0b\uff0cHeatTransFormer \u4ea7\u751f\u8fde\u8d2f\u7684\u754c\u9762\u6e29\u5ea6\u573a\uff0c\u5177\u5907\u5bf9\u754c\u9762\u7684\u826f\u597d\u63cf\u8ff0\u80fd\u529b\uff1b\u524d\u5411\u6c42\u89e3\u5b9e\u73b0\u5bf9\u754c\u9762\u7684\u9ad8\u68af\u5ea6\u533a\u57df\u7684\u7a33\u5b9a\u91cd\u73b0\uff0c\u9006\u63a8\u9636\u6bb5\u53ef\u7a33\u5065\u8bc6\u522b\u4e09\u79cd\u672a\u77e5\u70ed\u53c2\u6570\u3002", "conclusion": "\u7269\u7406\u5f15\u5bfc\u7684 Transformer \u67b6\u6784\u4e3a\u754c\u9762\u652f\u914d\u578b\u70ed\u4f20\u5bfc\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u524d\u5411\u4e0e\u9006\u5411\u5efa\u6a21\u6846\u67b6\uff0c\u53ef\u5e94\u7528\u4e8e\u63a5\u53e3\u5f3a\u8026\u5408\u7684\u70ed\u7cfb\u7edf\u3002"}}
{"id": "2512.02653", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02653", "abs": "https://arxiv.org/abs/2512.02653", "authors": ["Farnaz Faramarzi Lighvan", "Mehrdad Asadi", "Lynn Houthuys"], "title": "Adaptive Weighted LSSVM for Multi-View Classification", "comment": null, "summary": "Multi-view learning integrates diverse representations of the same instances to improve performance. Most existing kernel-based multi-view learning methods use fusion techniques without enforcing an explicit collaboration type across views or co-regularization which limits global collaboration. We propose AW-LSSVM, an adaptive weighted LS-SVM that promotes complementary learning by an iterative global coupling to make each view focus on hard samples of others from previous iterations. Experiments demonstrate that AW-LSSVM outperforms existing kernel-based multi-view methods on most datasets, while keeping raw features isolated, making it also suitable for privacy-preserving scenarios.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u52a0\u6743\u7684 LS-SVM\uff08AW-LSSVM\uff09\u7528\u4e8e\u591a\u89c6\u56fe\u5b66\u4e60\uff0c\u901a\u8fc7\u8fed\u4ee3\u5168\u5c40\u8026\u5408\u4fc3\u4f7f\u5404\u89c6\u56fe\u5173\u6ce8\u5176\u4ed6\u89c6\u56fe\u7684\u96be\u6837\u672c\uff0c\u4ece\u800c\u5b9e\u73b0\u4e92\u8865\u5b66\u4e60\u5e76\u63d0\u5347\u6838\u65b9\u6cd5\u7684\u591a\u89c6\u56fe\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u59cb\u7279\u5f81\u72ec\u7acb\u4ee5\u5229\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6838\u7684\u591a\u89c6\u56fe\u65b9\u6cd5\u591a\u91c7\u7528\u7b80\u5355\u878d\u5408\u6216\u7f3a\u4e4f\u663e\u5f0f\u7684\u8de8\u89c6\u56fe\u534f\u4f5c/\u5171\u6b63\u5219\u5316\uff0c\u5bfc\u81f4\u5168\u5c40\u5c42\u9762\u7684\u534f\u4f5c\u53d7\u9650\u3002\u9700\u5f15\u5165\u673a\u5236\u4ee5\u5f3a\u5316\u89c6\u56fe\u4e4b\u95f4\u7684\u4e92\u8865\u4e0e\u5bf9\u56f0\u96be\u6837\u672c\u7684\u5173\u6ce8\u3002", "method": "\u63d0\u51fa AW-LSSVM\uff0c\u4e3a\u591a\u89c6\u56fe\u5b66\u4e60\u8bbe\u8ba1\u81ea\u9002\u5e94\u52a0\u6743\u7684 LS-SVM\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u7684\u5168\u5c40\u8026\u5408\u673a\u5236\uff0c\u4f7f\u6bcf\u4e2a\u89c6\u56fe\u5728\u6bcf\u8f6e\u8fed\u4ee3\u4e2d\u5173\u6ce8\u5176\u4ed6\u89c6\u56fe\u7684\u96be\u6837\u672c\uff0c\u4ece\u800c\u5b9e\u73b0\u4e92\u8865\u5b66\u4e60\uff1b\u5728\u4fdd\u6301\u539f\u59cb\u7279\u5f81\u72ec\u7acb\u7684\u540c\u65f6\u5b9e\u73b0\u8de8\u89c6\u56fe\u534f\u4f5c\uff0c\u5177\u5907\u9690\u79c1\u53cb\u597d\u7279\u6027\u3002", "result": "\u5728\u591a\u6570\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6838\u57fa\u591a\u89c6\u56fe\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u8de8\u89c6\u56fe\u5168\u5c40\u8026\u5408\u4e0e\u4e92\u8865\u5b66\u4e60\u7684\u6709\u6548\u6027\uff0c\u540c\u65f6\u7531\u4e8e\u7ef4\u6301\u539f\u59cb\u7279\u5f81\u72ec\u7acb\uff0c\u9002\u5408\u4f5c\u4e3a\u9690\u79c1\u4fdd\u62a4\u573a\u666f\u7684\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u5168\u5c40\u8026\u5408\u548c\u81ea\u9002\u5e94\u52a0\u6743\uff0cAW-LSSVM \u5b9e\u73b0\u4e86\u8de8\u89c6\u56fe\u7684\u4e92\u8865\u5b66\u4e60\u4e0e\u534f\u4f5c\u63d0\u5347\uff0c\u63d0\u5347\u4e86\u6838\u65b9\u6cd5\u7684\u591a\u89c6\u56fe\u6027\u80fd\u5e76\u4fdd\u6301\u6f5c\u5728\u7684\u9690\u79c1\u53cb\u597d\u6027\u3002"}}
{"id": "2512.02657", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02657", "abs": "https://arxiv.org/abs/2512.02657", "authors": ["Naveen George", "Naoki Murata", "Yuhta Takida", "Konda Reddy Mopuri", "Yuki Mitsufuji"], "title": "Distill, Forget, Repeat: A Framework for Continual Unlearning in Text-to-Image Diffusion Models", "comment": "Preprint", "summary": "The recent rapid growth of visual generative models trained on vast web-scale datasets has created significant tension with data privacy regulations and copyright laws, such as GDPR's ``Right to be Forgotten.'' This necessitates machine unlearning (MU) to remove specific concepts without the prohibitive cost of retraining. However, existing MU techniques are fundamentally ill-equipped for real-world scenarios where deletion requests arrive sequentially, a setting known as continual unlearning (CUL). Naively applying one-shot methods in a continual setting triggers a stability crisis, leading to a cascade of degradation characterized by retention collapse, compounding collateral damage to related concepts, and a sharp decline in generative quality. To address this critical challenge, we introduce a novel generative distillation based continual unlearning framework that ensures targeted and stable unlearning under sequences of deletion requests. By reframing each unlearning step as a multi-objective, teacher-student distillation process, the framework leverages principles from continual learning to maintain model integrity. Experiments on a 10-step sequential benchmark demonstrate that our method unlearns forget concepts with better fidelity and achieves this without significant interference to the performance on retain concepts or the overall image quality, substantially outperforming baselines. This framework provides a viable pathway for the responsible deployment and maintenance of large-scale generative models, enabling industries to comply with ongoing data removal requests in a practical and effective manner.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u6559\u5e08-\u5b66\u751f\u84b8\u998f\u7684\u6301\u7eed\u6027\u672a\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u8fde\u7eed\u5220\u9664\u8bf7\u6c42\u4e0b\u5b9e\u73b0\u76ee\u6807\u5316\u4e14\u7a33\u5b9a\u7684\u672a\u5b66\u4e60\uff0c\u9002\u7528\u4e8e\u5927\u578b\u751f\u6210\u6a21\u578b\uff0c\u4e14\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u968f\u7740\u89c6\u89c9\u751f\u6210\u6a21\u578b\u5728\u5927\u89c4\u6a21\u7f51\u9875\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u6570\u636e\u9690\u79c1\u4e0e\u7248\u6743\u6cd5\u89c4\uff08\u5982 GDPR \u7684\u201c\u88ab\u9057\u5fd8\u6743\u201d\uff09\u5bf9\u6a21\u578b\u63d0\u51fa\u6301\u7eed\u7684\u6570\u636e\u5220\u9664\u9700\u6c42\u3002\u73b0\u6709\u673a\u5668\u5fd8\u8bb0\uff08MU\uff09\u65b9\u6cd5\u591a\u4e3a\u4e00\u6b21\u6027\uff0c\u65e0\u6cd5\u5e94\u5bf9\u8fde\u7eed\u7684\u5220\u9664\u8bf7\u6c42\uff0c\u6613\u9677\u5165\u7a33\u5b9a\u6027\u5d29\u6e83\u3001\u5bf9\u4fdd\u7559\u6982\u5ff5\u7684\u5e72\u6270\u548c\u751f\u6210\u8d28\u91cf\u4e0b\u964d\u7b49\u95ee\u9898\u3002\u9700\u53d1\u5c55\u80fd\u5728\u8fde\u7eed\u5220\u9664\u60c5\u5883\u4e0b\u4fdd\u6301\u6a21\u578b\u6574\u4f53\u6027\u4e0e\u53ef\u7528\u6027\u7684\u6301\u7eed\u672a\u5b66\u4e60\uff08CUL\uff09\u65b9\u6cd5\u3002", "method": "\u628a\u6bcf\u4e00\u6b21\u672a\u5b66\u4e60\u6b65\u9aa4\u91cd\u65b0\u8868\u8ff0\u4e3a\u4e00\u4e2a\u591a\u76ee\u6807\u7684\u6559\u5e08-\u5b66\u751f\u84b8\u998f\u8fc7\u7a0b\uff0c\u7ed3\u5408\u6301\u7eed\u5b66\u4e60\u7684\u539f\u5219\uff0c\u901a\u8fc7\u751f\u6210\u84b8\u998f\u5b9e\u73b0\u5bf9\u76ee\u6807\u6982\u5ff5\u7684\u9057\u5fd8\u540c\u65f6\u6700\u5927\u7a0b\u5ea6\u4fdd\u7559\u4fdd\u7559\u6982\u5ff5\u53ca\u56fe\u50cf\u8d28\u91cf\uff0c\u4e14\u5728\u4e00\u4e2a10\u6b65\u7684\u8fde\u7eed\u57fa\u51c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728\u4e00\u4e2a10\u6b65\u7684\u8fde\u7eed\u57fa\u51c6\u4e0a\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u4ee5\u8f83\u9ad8\u4fdd\u771f\u5ea6\u5fd8\u8bb0\u76ee\u6807\u6982\u5ff5\uff0c\u540c\u65f6\u5bf9\u4fdd\u7559\u6982\u5ff5\u548c\u6574\u4f53\u56fe\u50cf\u8d28\u91cf\u5e72\u6270\u663e\u8457\u964d\u4f4e\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u7ed9\u51fa\u4e00\u79cd\u53ef\u843d\u5730\u7684\u6301\u7eed\u672a\u5b66\u4e60\u6846\u67b6\uff0c\u4e3a\u5927\u578b\u751f\u6210\u6a21\u578b\u5728\u73b0\u5b9e\u90e8\u7f72\u4e2d\u6ee1\u8db3\u6301\u7eed\u6570\u636e\u5220\u9664\u8bf7\u6c42\u63d0\u4f9b\u53ef\u884c\u4e14\u6709\u6548\u7684\u89e3\u51b3\u8def\u5f84\u3002"}}
{"id": "2512.02667", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02667", "abs": "https://arxiv.org/abs/2512.02667", "authors": ["Haozhuo Zheng", "Cheng Wang", "Yang Liu"], "title": "Graph VQ-Transformer (GVT): Fast and Accurate Molecular Generation via High-Fidelity Discrete Latents", "comment": null, "summary": "The de novo generation of molecules with desirable properties is a critical challenge, where diffusion models are computationally intensive and autoregressive models struggle with error propagation. In this work, we introduce the Graph VQ-Transformer (GVT), a two-stage generative framework that achieves both high accuracy and efficiency. The core of our approach is a novel Graph Vector Quantized Variational Autoencoder (VQ-VAE) that compresses molecular graphs into high-fidelity discrete latent sequences. By synergistically combining a Graph Transformer with canonical Reverse Cuthill-McKee (RCM) node ordering and Rotary Positional Embeddings (RoPE), our VQ-VAE achieves near-perfect reconstruction rates. An autoregressive Transformer is then trained on these discrete latents, effectively converting graph generation into a well-structured sequence modeling problem. Crucially, this mapping of complex graphs to high-fidelity discrete sequences bridges molecular design with the powerful paradigm of large-scale sequence modeling, unlocking potential synergies with Large Language Models (LLMs). Extensive experiments show that GVT achieves state-of-the-art or highly competitive performance across major benchmarks like ZINC250k, MOSES, and GuacaMol, and notably outperforms leading diffusion models on key distribution similarity metrics such as FCD and KL Divergence. With its superior performance, efficiency, and architectural novelty, GVT not only presents a compelling alternative to diffusion models but also establishes a strong new baseline for the field, paving the way for future research in discrete latent-space molecular generation.", "AI": {"tldr": "\u63d0\u51fa Graph VQ-Transformer (GVT)\uff0c\u901a\u8fc7\u56feVQ-VAE \u5c06\u5206\u5b50\u56fe\u538b\u7f29\u4e3a\u9ad8\u4fdd\u771f\u79bb\u6563\u6f5c\u5728\u5e8f\u5217\uff0c\u5e76\u4ee5\u81ea\u56de\u5f52 Transformer \u5728\u8be5\u79bb\u6563\u5e8f\u5217\u4e0a\u8fdb\u884c\u751f\u6210\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u6548\u4e14\u9ad8\u8d28\u91cf\u7684\u5206\u5b50\u751f\u6210\uff0c\u5728 ZINC250k\u3001MOSES\u3001GuacaMol \u7b49\u57fa\u51c6\u4e0a\u8fbe\u5230\u7ade\u4e89\u6027\u751a\u81f3\u9886\u5148\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3\u6269\u6563\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u3001 autoregressive \u6a21\u578b\u6613\u51fa\u73b0\u8bef\u5dee\u4f20\u64ad\u7684\u95ee\u9898\uff1b\u901a\u8fc7\u5c06\u5206\u5b50\u56fe\u6620\u5c04\u4e3a\u79bb\u6563\u6f5c\u5728\u5e8f\u5217\uff0c\u5c06\u5206\u5b50\u751f\u6210\u8f6c\u5316\u4e3a\u7ed3\u6784\u826f\u597d\u7684\u5e8f\u5217\u5efa\u6a21\u95ee\u9898\uff0c\u4ece\u800c\u5229\u7528\u5927\u89c4\u6a21\u5e8f\u5217\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u5e76\u4e3a\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u534f\u540c\u5960\u5b9a\u57fa\u7840\u3002", "method": "\u63d0\u51fa Graph VQ-VAE\uff1a\u7ed3\u5408 Graph Transformer\u3001canonical Reverse Cuthill-McKee (RCM) \u8282\u70b9\u6392\u5e8f\u4e0e Rotary Positional Embeddings (RoPE)\uff0c\u5728\u56fe\u4e0a\u5f97\u5230\u9ad8\u4fdd\u771f\u79bb\u6563\u6f5c\u5728\u7f16\u7801\u3002\u968f\u540e\u8bad\u7ec3\u81ea\u56de\u5f52 Transformer \u5728\u8fd9\u4e9b\u79bb\u6563\u6f5c\u5728\u5e8f\u5217\u4e0a\u8fdb\u884c\u5206\u5b50\u751f\u6210\uff0c\u5c06\u56fe\u751f\u6210\u95ee\u9898\u8f6c\u5316\u4e3a\u5e8f\u5217\u5efa\u6a21\u3002\u8fd8\u901a\u8fc7\u4e0e\u4e3b\u6d41\u57fa\u51c6\u7684\u5bf9\u6bd4\u9a8c\u8bc1\u6548\u7387\u4e0e\u8d28\u91cf\u3002", "result": "\u5728 ZINC250k\u3001MOSES\u3001GuacaMol \u7b49\u57fa\u51c6\u4e0a\u8fbe\u5230 state-of-the-art \u6216\u9ad8\u5ea6\u7ade\u4e89\u7684\u8868\u73b0\uff0c\u4e14\u5728\u5206\u5e03\u76f8\u4f3c\u6027\u5ea6\u91cf\u5982 FCD \u4e0e KL Divergence \u4e0a\u660e\u663e\u4f18\u4e8e\u9886\u5148\u6269\u6563\u6a21\u578b\u3002", "conclusion": "GVT \u63d0\u4f9b\u4e86\u4e00\u79cd\u5c06\u590d\u6742\u5206\u5b50\u56fe\u6620\u5c04\u5230\u9ad8\u4fdd\u771f\u79bb\u6563\u5e8f\u5217\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u56fe-\u5e8f\u5217\u6a21\u578b\u4e0e\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\uff0c\u6210\u4e3a\u6269\u6563\u6a21\u578b\u7684\u6709\u529b\u66ff\u4ee3\uff0c\u5e76\u4e3a\u672a\u6765\u5728\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\u7684\u5206\u5b50\u8bbe\u8ba1\u4e0e\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u878d\u5408\u5960\u5b9a\u65b0\u57fa\u7ebf\u3002"}}
{"id": "2512.02704", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02704", "abs": "https://arxiv.org/abs/2512.02704", "authors": ["Senrong Xu", "Tianyu Wang", "Zenan Li", "Yuan Yao", "Taolue Chen", "Feng Xu", "Xiaoxing Ma"], "title": "Conformal Correction for Efficiency May be at Odds with Entropy", "comment": null, "summary": "Conformal prediction (CP) provides a comprehensive framework to produce statistically rigorous uncertainty sets for black-box machine learning models. To further improve the efficiency of CP, conformal correction is proposed to fine-tune or wrap the base model with an extra module using a conformal-aware inefficiency loss. In this work, we empirically and theoretically identify a trade-off between the CP efficiency and the entropy of model prediction. We then propose an entropy-constrained conformal correction method, exploring a better Pareto optimum between efficiency and entropy. Extensive experimental results on both computer vision and graph datasets demonstrate the efficacy of the proposed method. For instance, it can significantly improve the efficiency of state-of-the-art CP methods by up to 34.4%, given an entropy threshold.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u71b5\u7ea6\u675f\u7684 conformal correction\uff0c\u4ee5\u5728 CP \u7684\u6548\u7387\u548c\u9884\u6d4b\u71b5\u4e4b\u95f4\u5b9e\u73b0 Pareto \u6700\u4f18\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u63d0\u9ad8 CP \u6548\u7387\uff0c\u53ef\u8fbe 34.4% \u7684\u63d0\u5347\u3002", "motivation": "\u5728\u9ed1\u76d2\u6a21\u578b\u7684 conformal prediction \u6846\u67b6\u4e2d\u9700\u63d0\u5347\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u8986\u76d6\u6027\u548c\u7edf\u8ba1\u53ef\u4fe1\u6027\uff1b\u73b0\u6709\u65b9\u6cd5\u5728\u6548\u7387\u4e0e\u9884\u6d4b\u71b5\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6743\u8861\u3002", "method": "\u5f15\u5165\u71b5\u7ea6\u675f\u7684 conformal correction \u6a21\u5757\uff0c\u8bbe\u5b9a\u71b5\u9608\u503c\u4ee5\u7ea6\u675f\u9884\u6d4b\u5206\u5e03\u7684\u71b5\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u8986\u76d6\u7387\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u6548\u7387\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u5206\u6790\u4e0e\u5927\u89c4\u6a21\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86 CP \u6548\u7387\u4e0e\u9884\u6d4b\u71b5\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff1b\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u56fe\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\u65b9\u6cd5\u53ef\u663e\u8457\u63d0\u5347\u6548\u7387\uff0c\u4e14\u5728\u7ed9\u5b9a\u71b5\u9608\u503c\u4e0b\u6700\u9ad8\u63d0\u5347\u53ef\u8fbe\u7ea6 34.4%\u3002", "conclusion": "\u63d0\u51fa\u7684\u71b5\u7ea6\u675f conformal correction \u63d0\u4f9b\u4e86\u66f4\u4f18\u7684 Pareto-optimal \u6027\u80fd\uff0c\u80fd\u591f\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6570\u636e\u96c6\u4e0a\u63d0\u5347 CP \u6548\u7387\u5e76\u63a7\u5236\u9884\u6d4b\u71b5\u3002"}}
{"id": "2512.02826", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02826", "abs": "https://arxiv.org/abs/2512.02826", "authors": ["Haoming Liu", "Jinnuo Liu", "Yanhao Li", "Liuyang Bai", "Yunkai Ji", "Yuanhe Guo", "Shenji Wan", "Hongyi Wen"], "title": "From Navigation to Refinement: Revealing the Two-Stage Nature of Flow-based Diffusion Models through Oracle Velocity", "comment": "Preprint version; 15 pages, 16 figures", "summary": "Flow-based diffusion models have emerged as a leading paradigm for training generative models across images and videos. However, their memorization-generalization behavior remains poorly understood. In this work, we revisit the flow matching (FM) objective and study its marginal velocity field, which admits a closed-form expression, allowing exact computation of the oracle FM target. Analyzing this oracle velocity field reveals that flow-based diffusion models inherently formulate a two-stage training target: an early stage guided by a mixture of data modes, and a later stage dominated by the nearest data sample. The two-stage objective leads to distinct learning behaviors: the early navigation stage generalizes across data modes to form global layouts, whereas the later refinement stage increasingly memorizes fine-grained details. Leveraging these insights, we explain the effectiveness of practical techniques such as timestep-shifted schedules, classifier-free guidance intervals, and latent space design choices. Our study deepens the understanding of diffusion model training dynamics and offers principles for guiding future architectural and algorithmic improvements.", "AI": {"tldr": "\u901a\u8fc7\u5bf9\u6d41\u57fa\u7840\u6269\u6563\u6a21\u578b\u7684\u8fb9\u9645\u901f\u5ea6\u573a\u8fdb\u884c\u89e3\u6790\uff0c\u63ed\u793aFM\u76ee\u6807\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u4fe1\u53f7\uff0c\u89e3\u91ca\u6cdb\u5316\u4e0e\u8bb0\u5fc6\u7684\u5206\u5e03\uff0c\u4ee5\u53ca\u5bf9\u8bad\u7ec3\u6280\u5de7\u7684\u6709\u6548\u6027\u63d0\u4f9b\u7406\u8bba\u89e3\u91ca\u4e0e\u8bbe\u8ba1\u539f\u5219\u3002", "motivation": "\u7406\u89e3\u6d41\u5f0f\uff08flow-based\uff09\u6269\u6563\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684 memorization\uff08\u8bb0\u5fc6\u5316\uff09\u4e0e generalization\uff08\u6cdb\u5316\uff09\u884c\u4e3a\uff0c\u4ee5\u53ca Flow Matching (FM) \u76ee\u6807\u7684\u51e0\u4f55/\u7269\u7406\u542b\u4e49\uff0c\u4ece\u800c\u4e3a\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u7b97\u6cd5\u6539\u8fdb\u63d0\u4f9b\u7406\u8bba\u57fa\u77f3\u3002", "method": "\u63a8\u5bfc FM \u76ee\u6807\u7684\u8fb9\u9645\u901f\u5ea6\u573a\uff08\u5b58\u5728\u95ed\u5f0f\u8868\u8fbe\uff09\uff0c\u5e76\u8ba1\u7b97\u51fa oracle FM \u76ee\u6807\uff1b\u636e\u6b64\u5206\u6790\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u5448\u73b0\u7684\u4e24\u9636\u6bb5\u4fe1\u53f7\uff1a\u65e9\u671f\u7531\u6570\u636e\u6a21\u6001\u6df7\u5408\u9a71\u52a8\u7684\u5bfc\u822a\u9636\u6bb5\uff0c\u665a\u671f\u7531\u6700\u8fd1\u6837\u672c\u9a71\u52a8\u7684\u7ec6\u5316\u9636\u6bb5\uff1b\u7ed3\u5408\u63a8\u5bfc\u7ed3\u679c\u89e3\u91ca\u5b9e\u8df5\u6280\u5de7\uff08\u5982\u65f6\u95f4\u6b65\u79fb\u4f4d\u3001\u65e0\u5206\u7c7b\u5668\u5f15\u5bfc\u3001\u6f5c\u5728\u7a7a\u95f4\u8bbe\u8ba1\u7b49\uff09\u7684\u4f5c\u7528\u3002", "result": "\u8bc1\u5b9e\u8fb9\u9645\u901f\u5ea6\u573a\u5bfc\u51fa\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u76ee\u6807\u5bfc\u81f4\u6a21\u578b\u5148\u5728\u5168\u5c40\u6570\u636e\u6a21\u6001\u4e0a\u5b9e\u73b0\u6cdb\u5316\u4ee5\u5f62\u6210\u5168\u5c40\u5e03\u5c40\uff0c\u968f\u540e\u9010\u6b65\u8bb0\u5fc6\u7ec6\u7c92\u5ea6\u7ec6\u8282\uff1b\u7ed9\u51fa\u5bf9\u5e38\u7528\u8bad\u7ec3\u6280\u5de7\u6709\u6548\u6027\u7684\u7edf\u4e00\u89e3\u91ca\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u6b64\u7406\u89e3\u7684\u672a\u6765\u67b6\u6784\u4e0e\u8bad\u7ec3\u7b97\u6cd5\u6539\u8fdb\u539f\u5219\u3002", "conclusion": "\u901a\u8fc7\u5bf9FM\u76ee\u6807\u53ca\u5176\u8fb9\u9645\u901f\u5ea6\u573a\u7684\u6df1\u5165\u5206\u6790\uff0c\u63ed\u793a\u6d41\u57fa\u6269\u6563\u6a21\u578b\u8bad\u7ec3\u52a8\u529b\u5b66\u7684\u672c\u8d28\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u5e2e\u52a9\u6307\u5bfc\u672a\u6765\u7684\u6a21\u578b\u5f00\u53d1\u4e0e\u4f18\u5316\u3002"}}
{"id": "2512.02833", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02833", "abs": "https://arxiv.org/abs/2512.02833", "authors": ["Ihab Ahmed", "Denis Krompa\u00df", "Cheng Feng", "Volker Tresp"], "title": "A Comparative Study on How Data Normalization Affects Zero-Shot Generalization in Time Series Foundation Models", "comment": null, "summary": "We investigate input normalization methods for Time-Series Foundation Models (TSFMs). While normalization is well-studied in dataset-specific time-series models, it remains overlooked in TSFMs where generalization is critical. Time-series data, unlike text or images, exhibits significant scale variation across domains and channels, coupled with non-stationarity, can undermine TSFM performance regardless of architectural complexity. Through systematic evaluation across four architecturally diverse TSFMs, we empirically establish REVIN as the most efficient approach, reducing zero-shot MASE by 89\\% relative to an un-normalized baseline and by 44\\% versus other normalization methods, while matching the best in-domain accuracy (0.84 MASE) without any dataset-level preprocessing -- yielding the highest accuracy-efficiency trade-off. Yet its effect utilization depends on architectural design choices and optimization objective, particularly with respect to training loss scale sensitivity and model type (probabilistic, point-forecast, or LLM-based models).", "AI": {"tldr": "\u5728\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u4e2d\uff0c\u8f93\u5165\u5f52\u4e00\u5316\u662f\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u7684\u5173\u952e\u624b\u6bb5\uff0cREVIN\u5728\u56db\u79cd\u4e0d\u540c\u67b6\u6784\u7684TSFM\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u663e\u8457\u63d0\u5347\u96f6-shot\u9c81\u68d2\u6027\u5e76\u5728\u4e0d\u9700\u6570\u636e\u7ea7\u9884\u5904\u7406\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6027\u4ef7\u6bd4\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5b58\u5728\u8de8\u9886\u57df\u548c\u901a\u9053\u7684\u5c3a\u5ea6\u53d8\u5316\u53ca\u975e\u5e73\u7a33\u6027\uff0c\u8fd9\u4e9b\u56e0\u7d20\u5728TSFM\u4e0a\u5bf9\u6cdb\u5316\u6027\u80fd\u7684\u5f71\u54cd\u5927\u4e8e\u6a21\u578b\u67b6\u6784\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5e76\u9009\u62e9\u6709\u6548\u7684\u5f52\u4e00\u5316\u65b9\u6cd5\u3002", "method": "\u5728\u56db\u79cd\u67b6\u6784\u5dee\u5f02\u663e\u8457\u7684TSFM\u4e0a\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u6bd4\u8f83\u4e0d\u540c\u5f52\u4e00\u5316\u7b56\u7565\uff08\u5305\u62ecREV IN\u7b49\uff09\uff0c\u4ee5\u96f6-shot\u548c\u5728-domain\u573a\u666f\u4e0b\u7684MASE\u8868\u73b0\uff0c\u4ee5\u53ca\u5bf9\u8bad\u7ec3\u635f\u5931\u5c3a\u5ea6\u654f\u611f\u6027\u548c\u6a21\u578b\u7c7b\u578b\u7684\u5f71\u54cd\u3002", "result": "\u8bc1\u660eREVIN\u662f\u6700\u5177\u6548\u7387\u7684\u5f52\u4e00\u5316\u65b9\u6cd5\uff0c\u96f6-shot MASE\u76f8\u8f83\u672a\u5f52\u4e00\u5316\u57fa\u7ebf\u4e0b\u964d\u7ea689%\uff0c\u76f8\u8f83\u5176\u4ed6\u5f52\u4e00\u5316\u65b9\u6cd5\u4e0b\u964d\u7ea644%\uff1b\u540c\u65f6\u5728\u4e0d\u8fdb\u884c\u6570\u636e\u96c6\u7ea7\u9884\u5904\u7406\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e0e\u6700\u4f73\u57df\u5185\u76f8\u540c\u76840.84 MASE\uff0c\u663e\u793a\u6700\u9ad8\u7684\u51c6\u786e\u5ea6-\u6548\u7387\u6743\u8861\u3002", "conclusion": "REV IN\u7684\u6548\u7528\u53d7\u6a21\u578b\u8bbe\u8ba1\uff08\u76ee\u6807\u51fd\u6570\u3001\u6982\u7387/\u70b9\u9884\u62a5/LLM\u7b49\uff09\u548c\u635f\u5931\u5c3a\u5ea6\u654f\u611f\u6027\u5f71\u54cd\uff0c\u9700\u7ed3\u5408\u5177\u4f53\u67b6\u6784\u9009\u62e9\u4f7f\u7528\u7b56\u7565\u3002"}}
{"id": "2512.02849", "categories": ["cs.LG", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.02849", "abs": "https://arxiv.org/abs/2512.02849", "authors": ["Miko\u0142aj Sacha", "Hammad Jafri", "Mattie Terzolo", "Ayan Sinha", "Andrew Rabinovich"], "title": "GraphMatch: Fusing Language and Graph Representations in a Dynamic Two-Sided Work Marketplace", "comment": null, "summary": "Recommending matches in a text-rich, dynamic two-sided marketplace presents unique challenges due to evolving content and interaction graphs. We introduce GraphMatch, a new large-scale recommendation framework that fuses pre-trained language models with graph neural networks to overcome these challenges. Unlike prior approaches centered on standalone models, GraphMatch is a comprehensive recipe built on powerful text encoders and GNNs working in tandem. It employs adversarial negative sampling alongside point-in-time subgraph training to learn representations that capture both the fine-grained semantics of evolving text and the time-sensitive structure of the graph. We evaluated extensively on interaction data from Upwork, a leading labor marketplace, at large scale, and discuss our approach towards low-latency inference suitable for real-time use. In our experiments, GraphMatch outperforms language-only and graph-only baselines on matching tasks while being efficient at runtime. These results demonstrate that unifying language and graph representations yields a highly effective solution to text-rich, dynamic two-sided recommendations, bridging the gap between powerful pretrained LMs and large-scale graphs in practice.", "AI": {"tldr": "GraphMatch integrates pretrained language models with graph neural networks to recommend matches in a dynamic, text-rich two-sided marketplace, achieving higher accuracy and lower latency than language-only or graph-only baselines.", "motivation": "Two-sided marketplaces with evolving content and interaction graphs require aligning textual semantics with graph structures; standalone models struggle to capture both fine-grained language meaning and time-sensitive graph dynamics.", "method": "Fuse powerful text encoders (LMs) with graph neural networks (GNNs); employ adversarial negative sampling and point-in-time subgraph training to learn representations that reflect evolving text semantics and time-sensitive graph topology; optimize for low-latency inference; large-scale evaluation on real data.", "result": "GraphMatch outperforms language-only and graph-only baselines on matching tasks at large scale while maintaining runtime efficiency.", "conclusion": "Unifying language and graph representations yields an effective, practical solution for text-rich, dynamic two-sided recommendations, bridging pretrained LMs and large-scale graphs for real-time marketplaces."}}
{"id": "2512.02852", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.02852", "abs": "https://arxiv.org/abs/2512.02852", "authors": ["Shuyuan Wu", "Feifei Wang", "Yuan Gao", "Hansheng Wang"], "title": "Adaptive Decentralized Federated Learning for Robust Optimization", "comment": null, "summary": "In decentralized federated learning (DFL), the presence of abnormal clients, often caused by noisy or poisoned data, can significantly disrupt the learning process and degrade the overall robustness of the model. Previous methods on this issue often require a sufficiently large number of normal neighboring clients or prior knowledge of reliable clients, which reduces the practical applicability of DFL. To address these limitations, we develop here a novel adaptive DFL (aDFL) approach for robust estimation. The key idea is to adaptively adjust the learning rates of clients. By assigning smaller rates to suspicious clients and larger rates to normal clients, aDFL mitigates the negative impact of abnormal clients on the global model in a fully adaptive way. Our theory does not put any stringent conditions on neighboring nodes and requires no prior knowledge. A rigorous convergence analysis is provided to guarantee the oracle property of aDFL. Extensive numerical experiments demonstrate the superior performance of the aDFL method.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\uff08aDFL\uff09\u6765\u9c81\u68d2\u4f30\u8ba1\uff0c\u4f9d\u636e\u5ba2\u6237\u7aef\u7684\u53ef\u7591\u7a0b\u5ea6\u81ea\u9002\u5e94\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u51cf\u5c11\u5f02\u5e38\u5ba2\u6237\u7aef\u5bf9\u5168\u5c40\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u4e14\u65e0\u9700\u5148\u9a8c\u4fe1\u606f\uff0c\u7ed9\u51fa\u6536\u655b\u6027\u5206\u6790\u548c\u4e30\u5bcc\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002", "motivation": "\u5728\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\uff08DFL\uff09\u4e2d\uff0c\u5f02\u5e38\u5ba2\u6237\u7aef\uff08\u566a\u58f0/\u4e2d\u6bd2\u6570\u636e\uff09\u4f1a\u663e\u8457\u6270\u52a8\u5b66\u4e60\u8fc7\u7a0b\uff0c\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u4f9d\u8d56\u5927\u91cf\u6b63\u5e38\u90bb\u5c45\u6216\u4e8b\u5148\u5df2\u77e5\u7684\u53ef\u9760\u5ba2\u6237\u7aef\uff0c\u8fd9\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5bf9\u6bcf\u4e2a\u5ba2\u6237\u7aef\u81ea\u9002\u5e94\u5206\u914d\u5b66\u4e60\u7387\uff1a\u5bf9\u53ef\u7591\u5ba2\u6237\u7aef\u964d\u4f4e\u5b66\u4e60\u7387\uff0c\u5bf9\u6b63\u5e38\u5ba2\u6237\u7aef\u63d0\u9ad8\u5b66\u4e60\u7387\uff0c\u4f7f\u9c81\u68d2\u6027\u4ee5\u5b8c\u5168\u81ea\u9002\u5e94\u7684\u65b9\u5f0f\u5b9e\u73b0\u3002\u8be5\u673a\u5236\u65e0\u9700\u5148\u9a8c\u77e5\u8bc6\uff0c\u7406\u8bba\u7ed9\u51fa\u6536\u655b\u6027\u5206\u6790\u5e76\u5177\u5907oracle\u6027\u8d28\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u663e\u793a\u6536\u655b\u4e14\u5177\u5907oracle\u5c5e\u6027\uff1b\u5927\u91cf\u6570\u503c\u5b9e\u9a8c\u8868\u660eaDFL\u5728\u9c81\u68d2\u6027\u548c\u7cbe\u5ea6\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "aDFL\u63d0\u4f9b\u4e00\u79cd\u65e0\u5148\u9a8c\u5047\u8bbe\u3001\u5bf9\u5f02\u5e38\u5ba2\u6237\u7aef\u9c81\u68d2\u7684\u81ea\u9002\u5e94\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u517c\u5177\u7406\u8bba\u4fdd\u969c\u4e0e\u5b9e\u9a8c\u8bc1\u636e\u3002"}}
{"id": "2512.02868", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02868", "abs": "https://arxiv.org/abs/2512.02868", "authors": ["Cristian J. Villatoro", "Gianluca Geraci", "Daniele E. Schiavazzi"], "title": "Assessing the performance of correlation-based multi-fidelity neural emulators", "comment": null, "summary": "Outer loop tasks such as optimization, uncertainty quantification or inference can easily become intractable when the underlying high-fidelity model is computationally expensive. Similarly, data-driven architectures typically require large datasets to perform predictive tasks with sufficient accuracy. A possible approach to mitigate these challenges is the development of multi-fidelity emulators, leveraging potentially biased, inexpensive low-fidelity information while correcting and refining predictions using scarce, accurate high-fidelity data. This study investigates the performance of multi-fidelity neural emulators, neural networks designed to learn the input-to-output mapping by integrating limited high-fidelity data with abundant low-fidelity model solutions. We investigate the performance of such emulators for low and high-dimensional functions, with oscillatory character, in the presence of discontinuities, for collections of models with equal and dissimilar parametrization, and for a possibly large number of potentially corrupted low-fidelity sources. In doing so, we consider a large number of architectural, hyperparameter, and dataset configurations including networks with a different amount of spectral bias (Multi-Layered Perceptron, Siren and Kolmogorov Arnold Network), various mechanisms for coordinate encoding, exact or learnable low-fidelity information, and for varying training dataset size. We further analyze the added value of the multi-fidelity approach by conducting equivalent single-fidelity tests for each case, quantifying the performance gains achieved through fusing multiple sources of information.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.02882", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.02882", "abs": "https://arxiv.org/abs/2512.02882", "authors": ["Youkang Wang", "Jian Wang", "Rubing Chen", "Tianyi Zeng", "Xiao-Yong Wei", "Qing Li"], "title": "OptPO: Optimal Rollout Allocation for Test-time Policy Optimization", "comment": "Work in Progress", "summary": "Test-time policy optimization enables large language models (LLMs) to adapt to distribution shifts by leveraging feedback from self-generated rollouts. However, existing methods rely on fixed-budget majority voting to estimate rewards, incurring substantial computational redundancy. We propose Optimal Rollout Allocation for Test-time Policy Optimization (OptPO), a principled framework that adaptively allocates inference budgets. By formulating the voting process as a Bayesian sequential probability ratio test, OptPO dynamically halts sampling once the posterior confidence in a consensus answer exceeds a specified threshold. Crucially, it utilizes the retained rollouts for on-policy updates, seamlessly integrating with algorithms like PPO or GRPO without requiring ground-truth labels. Across diverse reasoning benchmarks, OptPO significantly reduces rollout overhead compared to fixed-sample baselines while preserving or improving accuracy. By unifying statistically optimal stopping with test-time learning, OptPO offers a computationally efficient paradigm for test-time adaptation. The source code will be open upon acceptance at https://open-upon-acceptance.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.02925", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.02925", "abs": "https://arxiv.org/abs/2512.02925", "authors": ["Ahmadreza Chokhachian", "Matthias Katzfuss", "Yu Ding"], "title": "Fast Gaussian Process Approximations for Autocorrelated Data", "comment": "Accepted by the INFORMS Journal on Data Science", "summary": "This paper is concerned with the problem of how to speed up computation for Gaussian process models trained on autocorrelated data. The Gaussian process model is a powerful tool commonly used in nonlinear regression applications. Standard regression modeling assumes random samples and an independently, identically distributed noise. Various fast approximations that speed up Gaussian process regression work under this standard setting. But for autocorrelated data, failing to account for autocorrelation leads to a phenomenon known as temporal overfitting that deteriorates model performance on new test instances. To handle autocorrelated data, existing fast Gaussian process approximations have to be modified; one such approach is to segment the originally correlated data points into blocks in which the blocked data are de-correlated. This work explains how to make some of the existing Gaussian process approximations work with blocked data. Numerical experiments across diverse application datasets demonstrate that the proposed approaches can remarkably accelerate computation for Gaussian process regression on autocorrelated data without compromising model prediction performance.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u81ea\u76f8\u5173\u6570\u636e\u5206\u5757\u6765\u52a0\u901f\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\uff1b\u5728\u4fdd\u7559\u9884\u6d4b\u6027\u80fd\u7684\u524d\u63d0\u4e0b\uff0c\u6539\u9020\u73b0\u6709\u7684\u5feb\u901fGP\u8fd1\u4f3c\u65b9\u6cd5\u4ee5\u9002\u5e94\u5206\u5757\u6570\u636e\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347 autocorrelated \u6570\u636e\u7684\u8ba1\u7b97\u901f\u5ea6\u3002", "motivation": "\u81ea\u76f8\u5173\u6570\u636e\u5728\u4f7f\u7528\u6807\u51c6\u72ec\u7acb\u540c\u5206\u5e03\u566a\u58f0\u5047\u8bbe\u7684\u5feb\u901fGP\u8fd1\u4f3c\u65f6\u4f1a\u5bfc\u81f4\u65f6\u5e8f\u8fc7\u62df\u5408\uff0c\u964d\u4f4e\u5bf9\u65b0\u6837\u672c\u7684\u6cdb\u5316\u80fd\u529b\u3002\u56e0\u6b64\u9700\u8981\u5bf9\u5feb\u901f\u8fd1\u4f3c\u65b9\u6cd5\u8fdb\u884c\u4fee\u6539\uff0c\u4f7f\u4e4b\u80fd\u5904\u7406\u81ea\u76f8\u5173\u6027\u4ee5\u63d0\u9ad8\u6548\u7387\u4e0e\u9884\u6d4b\u7a33\u5b9a\u6027\u3002", "method": "\u5c06\u539f\u59cb\u76f8\u5173\u6570\u636e\u5206\u5272\u4e3a\u76f8\u5bf9\u72ec\u7acb\u7684\u5757\uff0c\u5728\u8fd9\u4e9b\u5757\u5185\u8fdb\u884c\u89e3\u76f8\u5173\u5316\u5904\u7406\u540e\uff0c\u4f7f\u7528\u6216\u6539\u9020\u73b0\u6709\u7684\u5feb\u901fGP\u8fd1\u4f3c\u7b97\u6cd5\u4ee5\u9002\u7528\u4e8e\u5206\u5757\u6570\u636e\u7ed3\u6784\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u81ea\u76f8\u5173\u6570\u636e\u7684\u9ad8\u6548GP\u56de\u5f52\u3002", "result": "\u5728\u591a\u79cd\u5e94\u7528\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u663e\u8457\u52a0\u901f\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u7684\u8ba1\u7b97\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5206\u5757\u81ea\u76f8\u5173\u6570\u636e\u7684\u5feb\u901fGP\u65b9\u6cd5\u4e3a\u5728\u81ea\u76f8\u5173\u6570\u636e\u573a\u666f\u4e2d\u7684GP\u56de\u5f52\u63d0\u4f9b\u4e86\u4e00\u79cd\u517c\u987e\u8ba1\u7b97\u6548\u7387\u4e0e\u9884\u6d4b\u6548\u679c\u7684\u6709\u6548\u9014\u5f84\u3002"}}
