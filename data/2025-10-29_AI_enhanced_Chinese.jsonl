{"id": "2510.23832", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23832", "abs": "https://arxiv.org/abs/2510.23832", "authors": ["Evan Allen", "Karim Said", "Robert Calderbank", "Lingjia Liu"], "title": "Communication in a Fractional World: MIMO MC-OTFS Precoder Prediction", "comment": null, "summary": "As 6G technologies advance, international bodies and regulatory agencies are\nintensifying efforts to extend seamless connectivity especially for\nhigh-mobility scenarios such as Mobile Ad-Hoc Networks (\\textit{MANETs}) types\nsuch as Vehicular Ad-Hoc Networks (\\textit{VANETs}) and Flying Ad-Hoc Networks\n(\\textit{FANETs}). For these environments to be considered for long term\nadoption and use they must support Multiple-Input-Multiple- (MIMO) technology,\nrapidly fluctuating channel conditions in these environments place a heavy\nburden on traditional time-frequency CSI feedback schemes required for MIMO\nprecoding. This motivates a shift toward delay-Doppler representations like\nthose employed by Orthogonal Time-Frequency Space(OTFS) modulation, which\noffers greater stability under mobility. We derive an expression for the\nvariation over time in the OTFS I/O relationship. We then use this to create a\nphysics informed complex exponential basis expansion model prediction framework\nthat maximizes the usefulness of outdated Channel State Information (CSI) in\nthe presence of integer and fractional delay-Doppler channels and facilitates\nhigh mobility MIMO communication.", "AI": {"tldr": "\u5728\u9ad8\u79fb\u52a8\u573a\u666f\u4e0b\uff0c\u63d0\u51fa\u7ed3\u5408OTFS\u548c\u7269\u7406\u4fe1\u606f\u9a71\u52a8\u7684\u57fa\u7ec4\u5c55\u5f00\u6a21\u578b\uff0c\u4ee5\u5229\u7528\u8fc7\u65f6CSI\u5b9e\u73b0\u9ad8\u673a\u52a8\u6027MIMO\u7684\u9884\u6d4b\u4e0e\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u65f6\u9891CSI\u53cd\u9988\u5728\u9ad8\u79fb\u52a8\u6027\u4e0b\u96be\u4ee5\u7a33\u5b9a\uff0c\u9700\u5229\u7528\u66f4\u7a33\u5065\u7684\u65f6-\u5ef6\u8fdf-\u591a\u666e\u52d2\u8868\u5f81\u3002OTFS\u63d0\u4f9b\u5ef6\u8fdf-\u591a\u666e\u52d2\u57df\u7a33\u5b9a\u6027\uff0c\u672c\u6587 aims \u5c06\u8fc7\u65f6CSI \u8f6c\u5316\u4e3a\u6709\u7528\u4fe1\u606f\u4ee5\u652f\u6491MIMO\u5728VANET/FANET\u7b49\u573a\u666f\u7684\u957f\u671f\u5e94\u7528\u3002", "method": "\u63a8\u5bfcOTFS\u8f93\u5165\u8f93\u51fa\u5173\u7cfb\u5728\u65f6\u95f4\u4e0a\u7684\u53d8\u5316\u8868\u8fbe\uff0c\u5e76\u57fa\u4e8e\u6b64\u5efa\u7acb\u4e00\u4e2a\u7269\u7406\u4fe1\u606f\u7ea6\u675f\u7684\u590d\u6742\u6307\u6570\u57fa\u7ec4\u5c55\u5f00\u6a21\u578b(BEM)\u9884\u6d4b\u6846\u67b6\uff0c\u4ee5\u5728\u6574\u6570\u548c\u5206\u6570\u5ef6\u8fdf-\u591a\u666e\u52d2\u901a\u9053\u4e2d\u6700\u5927\u5316\u8fc7\u65f6CSI\u7684\u6709\u7528\u6027\uff0c\u63d0\u5347\u9ad8\u673a\u52a8\u6027MIMO\u7684\u6027\u80fd\u3002", "result": "\u7ed9\u51faOTFS I/O\u5173\u7cfb\u65f6\u95f4\u53d8\u5316\u7684\u8868\u8fbe\u5f0f\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u5229\u7528\u8fc7\u65f6CSI\u7684\u9884\u6d4b\u6846\u67b6\uff08\u7269\u7406\u4fe1\u606f\u9a71\u52a8\u7684BEM\uff09\uff0c\u7406\u8bba\u4e0a\u9002\u7528\u4e8e\u5904\u7406\u6574\u6570\u548c\u5206\u6570D\u901a\u9053\u4ee5\u652f\u6301\u9ad8\u79fb\u52a8\u6027MIMO\u3002", "conclusion": "\u5c06OTFS\u4e0e\u7269\u7406\u4fe1\u606f\u9a71\u52a8\u7684BEM\u7ed3\u5408\uff0c\u53ef\u5728\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u4e2d\u66f4\u6709\u6548\u5730\u5229\u7528\u8fc7\u65f6CSI\uff0c\u4fc3\u8fdbMIMO\u5728VANETs/FANETs\u7b49\u5e94\u7528\u4e2d\u7684\u957f\u671f\u53ef\u7528\u6027\u3002"}}
{"id": "2510.23837", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23837", "abs": "https://arxiv.org/abs/2510.23837", "authors": ["Ali Amhaz", "Shreya Khisa", "Mohamed Elhattab", "Chadi Assi", "Sanaa Sharafeddine"], "title": "Coordinated Multipoint Transmission in Pinching Antenna Systems", "comment": null, "summary": "We study a coordinated multi-point (CoMP) transmission where two base\nstations (BSs), each supported by a pinching antenna system (PASS), are\ndeployed to jointly serve communication users under spatial division multiple\naccess (SDMA) technology. Pinching Antenna technology was introduced as a\npromising solution to overcome the large-scale fading that has been shown to be\nan impediment in multiple-input multiple-output (MIMO) systems. To realize the\nadvantages of this technology in CoMP systems, which suffer from an upperbound\nrate limitation when traditional uniform linear arrays (ULAs) are adopted, we\nformulate an optimization problem with the aim of maximizing the achievable sum\nrate by jointly determining the transmit beamforming vectors and pinching\nlocations on the waveguides while respecting the quality of service (QoS)\nrequirements of users. This problem is inherently non-convex due to the strong\ncoupling among its decision parameters, making it challenging to solve using\ntraditional optimization methods. Thus, we utilize a gradient-based\nmeta-learning (GML) strategy specifically designed for large-scale optimization\ntasks. Finally, numerical analysis demonstrates the effectiveness of the\nproposed GML approach, achieving 92 percent of the optimal solution, and the\nsuperiority of the solution presented compared to other benchmarks. In\naddition, it achieves a higher upper bound on the achievable rate compared to\nconventional CoMP systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u5143\u5b66\u4e60\uff08GML\uff09\u7684\u8054\u5408\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e24\u57fa\u7ad9CoMP\u7cfb\u7edf\u4e2d\uff0c\u5728PINCHING\u5929\u7ebf\u7cfb\u7edf\uff08PASS\uff09\u8f85\u52a9\u4e0b\uff0c\u8054\u5408\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u4e0e\u9488\u5939\u4f4d\u7f6e\u4ee5\u63d0\u5347\u7cfb\u7edf\u603b\u4f53\u901f\u7387\u3002\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u53ef\u8fbe\u5230\u8fd1\u4f3c\u6700\u4f18\u89e3\u768492%\uff0c\u5e76\u4f18\u4e8e\u57fa\u7ebf\uff0c\u4e14\u76f8\u6bd4\u4f20\u7edfCoMP\u83b7\u5f97\u66f4\u9ad8\u7684\u901f\u7387\u4e0a\u754c\u3002", "motivation": "\u5728CoMP\u573a\u666f\u4e2d\uff0c\u4f20\u7edf\u5747\u5300\u7ebf\u9635\uff08ULA\uff09\u5b58\u5728\u901f\u7387\u4e0a\u9650\u4e14\u5927\u5c3a\u5ea6\u8870\u843d\u5f71\u54cd\u663e\u8457\uff1bPASS\u88ab\u63d0\u51fa\u4ee5\u7f13\u89e3\u8870\u843d\u5e76\u63d0\u5347MIMO\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u9ad8\u6548\u7684\u975e\u51f8\u4f18\u5316\u7b56\u7565\u4ee5\u540c\u65f6\u4f18\u5316\u6ce2\u675f\u4e0e\u9488\u5939\u5e03\u7f6e\u3002", "method": "\u5c06\u76ee\u6807\u8bbe\u5b9a\u4e3a\u5728\u6ee1\u8db3QoS\u7ea6\u675f\u7684\u524d\u63d0\u4e0b\uff0c\u8054\u5408\u786e\u5b9a\u53d1\u9001\u6ce2\u675f\u5411\u91cf\u548c\u6ce2\u5bfc\u4e0a\u7684\u9488\u5939\u4f4d\u7f6e\u4ee5\u6700\u5927\u5316\u53ef\u5b9e\u73b0\u7684\u603b\u901f\u7387\u3002\u8be5\u4f18\u5316\u95ee\u9898\u9ad8\u5ea6\u975e\u51f8\u4e14\u53d8\u91cf\u8026\u5408\u5f3a\uff0c\u56e0\u6b64\u5f15\u5165\u9762\u5411\u5927\u89c4\u6a21\u4f18\u5316\u8bbe\u8ba1\u7684\u68af\u5ea6\u5143\u5b66\u4e60\uff08GML\uff09\u7b56\u7565\u6765\u6c42\u89e3\u3002", "result": "\u6570\u503c\u5206\u6790\u8868\u660e\uff0c\u6240\u63d0GML\u65b9\u6cd5\u53ef\u8fbe\u5230\u7ea692%\u7684\u6700\u4f18\u89e3\uff0c\u4e14\u76f8\u8f83\u5176\u4ed6\u57fa\u51c6\u5177\u6709\u4f18\u8d8a\u6027\uff1b\u6b64\u5916\uff0c\u4e0e\u4f20\u7edfCoMP\u7cfb\u7edf\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u65b9\u6cd5\u5728\u53ef\u5b9e\u73b0\u901f\u7387\u4e0a\u754c\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u5728\u8026\u5408\u4e14\u975e\u51f8\u7684CoMP\u4f18\u5316\u95ee\u9898\u4e2d\uff0cGML\u65b9\u6cd5\u5bf9PASS\u4e0eCoMP\u7684\u7ed3\u5408\u5177\u6709\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u6f5c\u529b\uff0c\u8bc1\u660e\u4e86PASS\u5728\u591a\u57fa\u7ad9\u534f\u540c\u4f20\u8f93\u4e2d\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.24190", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24190", "abs": "https://arxiv.org/abs/2510.24190", "authors": ["Hong Niu", "Jiancheng An", "Chau Yuen"], "title": "Flexible Intelligent Layered Metasurfaces for Downlink Multi-user MISO Communications", "comment": "13 pages", "summary": "Stacked intelligent metasurfaces (SIMs) have recently gained attention as a\nparadigm for wave-domain signal processing with reduced reliance on costly\nradio-frequency (RF) chains. However, conventional SIMs rely on uniform\ninter-layer spacing and require deep stacking to ensure processing capability,\nresulting in severe power attenuation in practice. To address this issue, we\npropose a flexible intelligent layered metasurface (FILM) architecture\nconsisting of two shape-controllable flexible metasurface layers. By replacing\nrigid metasurfaces with flexible ones in both layers, the transmission\ncoefficient matrix can be dynamically adjusted, significantly decreasing the\nnumber of required layers while maintaining signal processing performance.\nFirstly, we develop a two-layer FILM-assisted multi-user multiple-input\nsingle-output (MU-MISO) system, wherein we formulate a channel fitting problem\naimed at reducing the difference between the FILM-induced and target channels.\nThen, we solve this non-convex problem by employing an alternating optimization\n(AO) method, featuring closed-form phase shift updates and a gradient\ndescent-based shape optimization. Furthermore, we analyze the upper bound on\nsum-rate and the complexity of computation to provide insights into design\ntrade-offs. Finally, simulation results demonstrated that the proposed\ntransmissive FILM architecture achieves over 200\\% improvement in sum-rate and\nmore than 7 dB bit-error rate (BER) gain compared to the conventional\nseven-layer SIMs.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u5c42\u67d4\u6027\u53ef\u63a7\u900f\u955c\u5c42\u7684FILM\u7ed3\u6784\uff0c\u901a\u8fc7\u53ef\u53d8\u4f20\u8f93\u77e9\u9635\u5b9e\u73b0\u6bd4\u4e03\u5c42SIM\u66f4\u9ad8\u6548\u7684\u6ce2\u57df\u4fe1\u53f7\u5904\u7406\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u5bb9\u91cf\u548cBER\u6027\u80fd\uff0c\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u53ef\u63a7\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfSIM\u5bf9\u5c42\u95f4\u95f4\u8ddd\u56fa\u5b9a\u3001\u6df1\u5c42\u5806\u53e0\u5bfc\u81f4\u529f\u7387\u8870\u51cf\u548c\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5bfb\u6c42\u66f4\u5c11\u5c42\u6570\u4f46\u4fdd\u6301\u5904\u7406\u80fd\u529b\u7684\u7075\u6d3b\u7ed3\u6784\u3002", "method": "\u8bbe\u8ba1\u4e24\u5c42\u67d4\u6027\u900f\u955c\u9635\u5217\uff0c\u63d0\u51faFILM\u67b6\u6784\uff1b\u5c06\u5176\u5e94\u7528\u4e8eMU-MISO\u7cfb\u7edf\uff0c\u5efa\u7acbFILM\u8bf1\u5bfc\u4fe1\u9053\u4e0e\u76ee\u6807\u4fe1\u9053\u7684\u62df\u5408\u95ee\u9898\uff1b\u4f7f\u7528\u4ea4\u66ff\u4f18\u5316\u6cd5\u6c42\u89e3\uff0c\u5305\u62ec\u76f8\u4f4d\u504f\u79fb\u7684\u89e3\u6790\u66f4\u65b0\u548c\u5f62\u72b6\u4f18\u5316\u7684\u68af\u5ea6\u4e0b\u964d\u3002", "result": "\u901a\u8fc7\u4eff\u771f\uff0c\u4f20\u8f93FILM\u5728\u603b\u548c\u901f\u7387\u65b9\u9762\u6bd4\u4f20\u7edf\u4e03\u5c42SIM\u63d0\u5347\u8d85\u8fc7200%\uff0cBER\u63d0\u5347\u8d85\u8fc77 dB\uff1b\u5e76\u7ed9\u51fa\u5bf9\u603b\u548c\u901f\u7387\u7684\u4e0a\u754c\u5206\u6790\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u8ba8\u8bba\u3002", "conclusion": "\u67d4\u6027\u4e24\u5c42FILM\u5728\u51cf\u5c0f\u5c42\u6570\u7684\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u4fe1\u53f7\u5904\u7406\u6027\u80fd\uff0c\u4e3a\u4f4e\u6210\u672c\u9ad8\u6548\u6ce2\u57df\u4fe1\u53f7\u5904\u7406\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2510.24215", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24215", "abs": "https://arxiv.org/abs/2510.24215", "authors": ["Vishal Halder", "Alexandre Reiffers-Masson", "Abdeldjalil A\u00efssa-El-Bey", "Gugan Thoppe"], "title": "What Can Be Recovered Under Sparse Adversarial Corruption? Assumption-Free Theory for Linear Measurements", "comment": null, "summary": "Let \\(\\bm{A} \\in \\mathbb{R}^{m \\times n}\\) be an arbitrary, known matrix and\n\\(\\bm{e}\\) a \\(q\\)-sparse adversarial vector. Given \\(\\bm{y} = \\bm{A} x^* +\n\\bm{e}\\) and \\(q\\), we seek the smallest set containing \\(x^*\\)-hence the one\nconveying maximal information about \\(x^*\\)-that is uniformly recoverable from\n\\(\\bm{y}\\) without knowing \\(\\bm{e}\\). While exact recovery of \\(x^*\\) via\nstrong (and often impractical) structural assumptions on \\(\\bm{A}\\) or \\(x^*\\)\n(for example, restricted isometry, sparsity) is well studied, recoverability\nfor arbitrary \\(\\bm{A}\\) and \\(x^*\\) remains open. Our main result shows that\nthe best that one can hope to recover is \\(x^* + \\ker(\\bm{U})\\), where\n\\(\\bm{U}\\) is the unique projection matrix onto the intersection of rowspaces\nof all possible submatrices of \\(\\bm{A}\\) obtained by deleting \\(2q\\) rows.\nMoreover, we prove that every \\(x\\) that minimizes the \\(\\ell\\_0\\)-norm of\n\\(\\bm{y} - \\bm{A} x\\) lies in \\(x^* + \\ker(\\bm{U})\\), which then gives a\nconstructive approach to recover this set.", "AI": {"tldr": "\u5728\u4efb\u610f\u7684 A \u548c q-\u7a00\u758f\u5bf9\u6297\u6270\u52a8\u4e0b\uff0c\u80fd\u7edf\u4e00 recover \u7684\u6700\u5927\u4fe1\u606f\u7b49\u4ef7\u4e8e x* + ker(U)\uff0c\u5176\u4e2d U \u6295\u5f71\u5230\u5220\u9664\u4efb\u610f 2q \u884c\u540e\u7684 A \u7684\u5b50\u77e9\u9635\u884c\u7a7a\u95f4\u7684\u4ea4\u96c6\u3002\u5bf9 y \u4e0e A \u7684\u5bf9\u6bd4\u4e2d\uff0c\u6240\u6709\u4f7f \u21130 \u6700\u5c0f\u5316\u7684\u89e3\u90fd\u843d\u5728\u8be5\u7b49\u4ef7\u7c7b\u4e0a\uff0c\u7ed9\u51fa\u53ef\u6784\u9020\u7684\u6062\u590d\u8def\u5f84\u3002", "motivation": "\u5c3d\u7ba1\u5728\u6ee1\u8db3\u5982 RIP\u3001\u7a00\u758f\u6027\u7b49\u7ed3\u6784\u6027\u5047\u8bbe\u4e0b\u7684\u7cbe\u786e\u6062\u590d\u6709\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5728\u4efb\u610f A \u4e0e x* \u7684\u573a\u666f\u4e2d\uff0c\u7edf\u4e00\u53ef\u6062\u590d\u7684\u4fe1\u606f\u96c6\u5408\u4ecd\u4e0d\u6e05\u6670\u3002\u672c\u5de5\u4f5c\u65e8\u5728\u7ed9\u51fa\u5728\u5bf9\u6297\u6027\u7a00\u758f\u8bef\u5dee\u4e0b\u201c\u53ef uniformly \u6062\u590d\u201d\u7684\u6700\u5927\u5b50\u7a7a\u95f4\u7684\u51e0\u4f55\u523b\u753b\u3002", "method": "\u5efa\u7acb\u4ee5 y = Ax* + e\uff0c\u5176\u4e2d e \u4e3a q\u2013\u7a00\u758f\u5bf9\u6297\u6270\u52a8\u4e3a\u80cc\u666f\uff0c\u8003\u5bdf\u901a\u8fc7\u5220\u9664 A \u7684\u4efb\u610f 2q \u884c\u6240\u5f97\u5230\u5b50\u77e9\u9635\u7684\u884c\u7a7a\u95f4\u7684\u4ea4\u96c6\u3002\u4ee4 U \u4e3a\u8be5\u4ea4\u96c6\u7684\u552f\u4e00\u6295\u5f71\u77e9\u9635\uff0c\u7814\u7a76\u5728\u6240\u6709\u53ef\u80fd\u7684 x \u5411\u91cf\u4e2d\uff0c\u8c01\u80fd\u5728\u4e0d\u77e5\u9053 e \u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5bf9 y \u7684\u4e00\u81f4\u6062\u590d\u3002\u8bc1\u660e\u6700\u4f18\u7684\u53ef uniformly \u6062\u590d\u96c6\u5408\u4e3a x* + ker(U)\uff0c\u5e76\u4e14\u4efb\u4f55\u4f7f y \u4e0e Ax \u7684 \u21130 \u8ddd\u79bb\u6700\u5c0f\u5316\u7684 x \u90fd\u843d\u5728\u6b64\u96c6\u5408\u5185\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6784\u5efa\u6027\u7684\u6062\u590d\u65b9\u6848\u3002", "result": "\u7ed9\u51fa\u4e00\u4e2a\u51e0\u4f55-\u4ee3\u6570\u7684\u754c\u5b9a\uff1a\u5728\u5bf9\u6297\u6027 2q \u884c\u5220\u51cf\u4e0b\u7684\u884c\u7a7a\u95f4\u4ea4\u96c6\u7684\u6295\u5f71\u6838\u51b3\u5b9a\u4e86\u4e0d\u53ef\u907f\u514d\u7684\u4e0d\u786e\u5b9a\u6027\u8303\u56f4\uff0c\u5373\u53ef uniformly \u6062\u590d\u7684\u96c6\u5408\u4e3a x* \u7684\u4e00\u4e2a\u7b49\u4ef7\u7c7b\u3002", "conclusion": "\u672c\u6587\u7ed9\u51fa\u4e86\u5728\u4efb\u610f A \u4e0e x* \u60c5\u51b5\u4e0b\u7684\u6700\u5927\u53ef\u7edf\u4e00\u6062\u590d\u4fe1\u606f\u7684\u7cbe\u786e\u5b9a\u4e49\uff0c\u5e76\u57fa\u4e8e ker(U) \u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u64cd\u4f5c\u7684\u3001\u5bf9\u6297\u6027\u6270\u52a8\u4e0b\u7684\u6784\u9020\u6027\u6062\u590d\u8def\u5f84\u3002"}}
{"id": "2510.23619", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23619", "abs": "https://arxiv.org/abs/2510.23619", "authors": ["Yuyang Miao", "Huijun Xing", "Danilo P. Mandic", "Tony G. Constantinides"], "title": "Short Ticketing Detection Framework Analysis Report", "comment": null, "summary": "This report presents a comprehensive analysis of an unsupervised multi-expert\nmachine learning framework for detecting short ticketing fraud in railway\nsystems. The study introduces an A/B/C/D station classification system that\nsuccessfully identifies suspicious patterns across 30 high-risk stations. The\nframework employs four complementary algorithms: Isolation Forest, Local\nOutlier Factor, One-Class SVM, and Mahalanobis Distance. Key findings include\nthe identification of five distinct short ticketing patterns and potential for\nshort ticketing recovery in transportation systems.", "AI": {"tldr": "\u5728\u94c1\u8def\u7cfb\u7edf\u4e2d\uff0c\u63d0\u51fa\u4e00\u79cd\u65e0\u76d1\u7763\u7684\u591a\u4e13\u5bb6\u673a\u5668\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u68c0\u6d4b\u77ed\u7968\u6b3a\u8bc8\uff0c\u57fa\u4e8e\u56db\u79cd\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u5bf930\u4e2a\u9ad8\u98ce\u9669\u8f66\u7ad9\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u8bc6\u522b\u51fa\u4e94\u79cd\u77ed\u7968\u6a21\u5f0f\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\u4e14\u6b3a\u8bc8\u884c\u4e3a\u7a00\u5c11\uff0c\u9700\u65e0\u76d1\u7763\u65b9\u6cd5\u6765\u8bc6\u522b\u5f02\u5e38\u8d2d\u7968\u884c\u4e3a\uff1b\u591a\u4e13\u5bb6\u534f\u4f5c\u4ee5\u63d0\u5347\u68c0\u6d4b\u9c81\u68d2\u6027\u4e0e\u8986\u76d6\u9762\u3002", "method": "\u91c7\u7528\u56db\u79cd\u7b97\u6cd5\uff1aIsolation Forest\u3001Local Outlier Factor\u3001One-Class SVM\u3001Mahalanobis Distance\uff0c\u6784\u5efaA/B/C/D\u8f66\u7ad9\u5206\u7c7b\u4f53\u7cfb\uff0c\u572830\u4e2a\u9ad8\u98ce\u9669\u8f66\u7ad9\u4e0a\u8bc6\u522b\u53ef\u7591\u6a21\u5f0f\u5e76\u5bf9\u77ed\u7968\u6b3a\u8bc8\u8fdb\u884c\u5206\u6790\u3002", "result": "\u8bc6\u522b\u51fa\u4e94\u79cd\u4e0d\u540c\u7684\u77ed\u7968\u6a21\u5f0f\uff1b\u572830\u4e2a\u9ad8\u98ce\u9669\u8f66\u7ad9\u4e2d\u6210\u529f\u8bc6\u522b\u53ef\u7591\u6a21\u5f0f\uff0c\u5c55\u73b0\u6846\u67b6\u5bf9\u77ed\u7968\u6b3a\u8bc8\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u6307\u793a\u77ed\u7968\u52a1\u6062\u590d\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u65e0\u76d1\u7763\u591a\u4e13\u5bb6\u6846\u67b6\u5bf9\u94c1\u8def\u8d2d\u7968\u6b3a\u8bc8\u68c0\u6d4b\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u5c24\u5176\u5728\u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\u65f6\uff1b\u53ef\u4e3a\u7b56\u7565\u5236\u5b9a\u548c\u8fd0\u8f93\u7cfb\u7edf\u7684\u6062\u590d\u63d0\u4f9b\u4f9d\u636e\u3002\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u3001\u6269\u5c55\u6570\u636e\u8986\u76d6\u8303\u56f4\uff0c\u5e76\u8003\u8651\u90e8\u7f72\u4e0e\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.24242", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24242", "abs": "https://arxiv.org/abs/2510.24242", "authors": ["Zihan Li", "Jiahao Yang", "Yuxin Zhang", "Zhe Chen", "Yue Gao"], "title": "Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration of Large Vision-Language Models", "comment": "15 pages, 11 figures", "summary": "Large vision-language models (LVLMs) have recently demonstrated great\npotential in remote sensing (RS) tasks (e.g., disaster monitoring) conducted by\nlow Earth orbit (LEO) satellites. However, their deployment in real-world LEO\nsatellite systems remains largely unexplored, hindered by limited onboard\ncomputing resources and brief satellite-ground contacts. We propose Grace, a\nsatellite-ground collaborative system designed for near-realtime LVLM inference\nin RS tasks. Accordingly, we deploy compact LVLM on satellites for realtime\ninference, but larger ones on ground stations (GSs) to guarantee end-to-end\nperformance. Grace is comprised of two main phases that are asynchronous\nsatellite-GS Retrieval-Augmented Generation (RAG), and a task dispatch\nalgorithm. Firstly, we still the knowledge archive of GS RAG to satellite\narchive with tailored adaptive update algorithm during limited satellite-ground\ndata exchange period. Secondly, propose a confidence-based test algorithm that\neither processes the task onboard the satellite or offloads it to the GS.\nExtensive experiments based on real-world satellite orbital data show that\nGrace reduces the average latency by 76-95% compared to state-of-the-art\nmethods, without compromising inference accuracy.", "AI": {"tldr": "Grace \u63d0\u51fa\u536b\u661f-\u5730\u9762\u534f\u540c\u6846\u67b6\u4ee5\u5b9e\u73b0\u8fd1\u5b9e\u65f6 LVLM \u63a8\u7406\uff0c\u524d\u7aef\u5728\u536b\u661f\u90e8\u7f72\u7d27\u51d1\u6a21\u578b\uff0c\u540e\u7aef\u5728\u5730\u9762\u90e8\u7f72\u66f4\u5927\u6a21\u578b\uff0c\u901a\u8fc7\u5f02\u6b65 RAG \u548c\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u4efb\u52a1\u5206\u53d1\u5b9e\u73b0\u7aef\u5230\u7aef\u9ad8\u6548\u63a8\u7406\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u65f6\u5ef6\u4e14\u4fdd\u6301\u51c6\u786e\u5ea6\u3002", "motivation": "\u53d7\u9650\u7684\u536b\u661f\u7aef\u8ba1\u7b97\u8d44\u6e90\u4e0e\u77ed\u6682\u7684\u536b\u661f-ground \u8054\u7cfb\u9650\u5236\uff0c\u4f7f\u5f97\u5927\u89c4\u6a21\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u536b\u661f\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u90e8\u7f72\u4ecd\u5177\u6311\u6218\uff0c\u540c\u65f6\u5e0c\u671b\u5145\u5206\u6316\u6398 LVLM \u5728\u9065\u611f\u4efb\u52a1\uff08\u5982\u707e\u5bb3\u76d1\u6d4b\uff09\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa Grace \u7684\u4e24\u9636\u6bb5\u5f02\u6b65\u536b\u661f-GS Retrieval-Augmented Generation\uff08RAG\uff09\u6846\u67b6\u4e0e\u4efb\u52a1\u5206\u53d1\u7b97\u6cd5\uff1a1) \u5c06 GS \u7684\u77e5\u8bc6\u6863\u6848\u4ee5\u81ea\u9002\u5e94\u66f4\u65b0\u7b97\u6cd5\u5728\u6709\u9650\u7684\u6570\u636e\u4ea4\u6362\u671f\u5185\u66f4\u65b0\u5e76\u540c\u6b65\u5230\u536b\u661f\u6863\u6848\uff1b2) \u63d0\u51fa\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u4efb\u52a1\u5206\u53d1\u7b56\u7565\uff0c\u51b3\u5b9a\u4efb\u52a1\u5728\u536b\u661f\u7aef\u672c\u5730\u63a8\u7406\u8fd8\u662f\u4e0b\u653e\u5230 GS\uff1b\u536b\u661f\u7aef\u90e8\u7f72\u7d27\u51d1 LVLM\uff0cGS \u90e8\u7f72\u8f83\u5927 LVLM\uff0c\u786e\u4fdd\u7aef\u5230\u7aef\u6027\u80fd\u3002", "result": "\u57fa\u4e8e\u771f\u5b9e\u536b\u661f\u8f68\u9053\u6570\u636e\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cGrace \u76f8\u8f83\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u5728\u5e73\u5747\u65f6\u5ef6\u4e0a\u964d\u4f4e\u4e86 76-95%\uff0c\u4e14\u63a8\u7406\u7cbe\u5ea6\u672a\u53d7\u5f71\u54cd\u3002", "conclusion": "\u536b\u661f\u7aef\u4e0e\u5730\u9762\u7aef\u6a21\u578b\u534f\u540c\u7684\u5206\u5c42\u67b6\u6784\u80fd\u663e\u8457\u63d0\u5347\u4f4e\u8f68\u536b\u661f\u9065\u611f\u4efb\u52a1\u7684\u8fd1\u5b9e\u65f6 LVLM \u63a8\u7406\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u4e14\u9700\u5feb\u901f\u54cd\u5e94\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2510.23617", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23617", "abs": "https://arxiv.org/abs/2510.23617", "authors": ["Phuong Q. Dao", "Mark Roantree", "Vuong M. Ngo"], "title": "An Enhanced Dual Transformer Contrastive Network for Multimodal Sentiment Analysis", "comment": "The paper has been accepted for presentation at the MEDES 2025\n  conference", "summary": "Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by\njointly analyzing data from multiple modalities typically text and images\noffering a richer and more accurate interpretation than unimodal approaches. In\nthis paper, we first propose BERT-ViT-EF, a novel model that combines powerful\nTransformer-based encoders BERT for textual input and ViT for visual input\nthrough an early fusion strategy. This approach facilitates deeper cross-modal\ninteractions and more effective joint representation learning. To further\nenhance the model's capability, we propose an extension called the Dual\nTransformer Contrastive Network (DTCN), which builds upon BERT-ViT-EF. DTCN\nincorporates an additional Transformer encoder layer after BERT to refine\ntextual context (before fusion) and employs contrastive learning to align text\nand image representations, fostering robust multimodal feature learning.\nEmpirical results on two widely used MSA benchmarks MVSA-Single and TumEmo\ndemonstrate the effectiveness of our approach. DTCN achieves best accuracy\n(78.4%) and F1-score (78.3%) on TumEmo, and delivers competitive performance on\nMVSA-Single, with 76.6% accuracy and 75.9% F1-score. These improvements\nhighlight the benefits of early fusion and deeper contextual modeling in\nTransformer-based multimodal sentiment analysis.", "AI": {"tldr": "\u63d0\u51fa BERT-ViT-EF \u4e0e DTCN \u7684\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u65e9\u671f\u878d\u5408\u548c\u5bf9\u6bd4\u5b66\u4e60\u63d0\u5347\u6587\u672c-\u89c6\u89c9\u8de8\u6a21\u6001\u8868\u793a\uff0c\u5728 MVSA-Single \u4e0e TumEmo \u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u7ade\u4e89\u6027\u7ed3\u679c\u3002", "motivation": "\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u9700\u8981\u540c\u65f6\u4ece\u6587\u672c\u548c\u89c6\u89c9\u4fe1\u606f\u4e2d\u63d0\u53d6\u60c5\u611f\u7ebf\u7d22\uff0c\u5355\u6a21\u6001\u5f80\u5f80\u53d7\u9650\uff1b\u65e9\u671f\u8de8\u6a21\u6001\u878d\u5408\u53ef\u4fc3\u8fdb\u66f4\u6df1\u5c42\u6b21\u7684\u4ea4\u4e92\u4e0e\u8054\u5408\u8868\u5f81\uff1b\u5f15\u5165\u5bf9\u6bd4\u5b66\u4e60\u4ee5\u5bf9\u9f50\u4e0d\u540c\u6a21\u6001\u7684\u8bed\u4e49\u8868\u793a\u4ee5\u63d0\u5347\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa BERT-ViT-EF\uff1a\u91c7\u7528 BERT \u7f16\u7801\u6587\u672c\u3001ViT \u7f16\u7801\u56fe\u50cf\uff0c\u901a\u8fc7\u65e9\u671f\u878d\u5408\u5b9e\u73b0\u8de8\u6a21\u6001\u4ea4\u4e92\u4e0e\u8054\u5408\u8868\u793a\u5b66\u4e60\u3002\u57fa\u4e8e\u6b64\uff0c\u6269\u5c55\u51fa Dual Transformer Contrastive Network (DTCN)\uff1a\u5728 BERT \u4e4b\u540e\u518d\u52a0\u5165\u4e00\u4e2a Transformer \u7f16\u7801\u5c42\u4ee5\u8fdb\u4e00\u6b65 refine \u6587\u672c\u4e0a\u4e0b\u6587\uff0c\u5e76\u5f15\u5165\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u6587\u672c\u4e0e\u56fe\u50cf\u8868\u5f81\u3002", "result": "\u5728 TumEmo \u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u6700\u9ad8\u51c6\u786e\u7387 78.4% \u4e0e F1 78.3%\uff1b\u5728 MVSA-Single \u4e0a\u8fbe\u5230 76.6% \u7684\u51c6\u786e\u7387\u548c 75.9% \u7684 F1\uff1b\u7ed3\u679c\u8868\u660e\u65e9\u671f\u878d\u5408\u548c\u66f4\u6df1\u5c42\u7684\u4e0a\u4e0b\u6587\u5efa\u6a21\u5bf9\u63d0\u5347\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u6027\u80fd\u6709\u6548\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8868\u660e\u5c06\u65e9\u671f\u878d\u5408\u4e0e\u6df1\u5c42 Transformer \u5efa\u6a21\u7ed3\u5408\uff0c\u5e76\u8f85\u4ee5\u5bf9\u6bd4\u5b66\u4e60\uff0c\u80fd\u63d0\u5347\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u7684\u8868\u793a\u80fd\u529b\u4e0e\u9c81\u68d2\u6027\uff0c\u5728\u4e24\u4e2a\u4e3b\u6d41\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5c55\u73b0\u51fa\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002"}}
{"id": "2510.23892", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23892", "abs": "https://arxiv.org/abs/2510.23892", "authors": ["Kebin Contreras", "Emmanuel Martinez", "Brayan Monroy", "Sebastian Ardila", "Cristian Ramirez", "Mariana Caicedo", "Hans Garcia", "Tatiana Gelvez-Barrera", "Juan Poveda-Jaramillo", "Henry Arguello", "Jorge Bacca"], "title": "Learning-based Spectral Regression for Cocoa Bean Physicochemical Property Prediction", "comment": null, "summary": "Cocoa bean quality assessment is essential for ensuring compliance with\ncommercial standards, protecting consumer health, and increasing the market\nvalue of the cocoa product. The quality assessment estimates key\nphysicochemical properties, such as fermentation level, moisture content,\npolyphenol concentration, and cadmium content, among others. This assessment\nhas traditionally relied on the accurate estimation of these properties via\nvisual or sensory evaluation, jointly with laboratory-based physicochemical\nanalyses, which are often time-consuming, destructive, and difficult to scale.\nThis creates the need for rapid, reliable, and noninvasive alternatives.\nSpectroscopy, particularly in the visible and near-infrared ranges, offers a\nnon-invasive alternative by capturing the molecular signatures associated with\nthese properties. Therefore, this work introduces a scalable methodology for\nevaluating the quality of cocoa beans by predicting key physicochemical\nproperties from the spectral signatures of cocoa beans. This approach utilizes\na conveyor belt system integrated with a VIS-NIR spectrometer, coupled with\nlearning-based regression models. Furthermore, a dataset is built using cocoa\nbean batches from Santander, Colombia. Ground-truth reference values were\nobtained through standardized laboratory analyses and following commercial\ncocoa quality regulations. To further evaluate the proposed methodology's\ngeneralization, performance is tested on samples collected from other Colombian\nregions and from Cusco, Peru. Experimental results show that the proposed\nmodels achieved R2 scores exceeding 0.98 across all physicochemical properties,\nand reached 0.96 accuracy on geographically independent samples. This\nnon-destructive approach represents a suitable and scalable alternative to\nconventional laboratory methods for quality assessment across the cocoa\nproduction chain.", "AI": {"tldr": "\u4f7f\u7528VIS-NIR\u5149\u8c31\u4e0e\u5b66\u4e60\u56de\u5f52\u6a21\u578b\u5bf9\u53ef\u53ef\u8c46\u8fdb\u884c\u975e\u7834\u574f\u6027\u8d28\u91cf\u8bc4\u4f30\uff0c\u8fbe\u5230\u9ad8R2\u4e0e\u8de8\u533a\u57df\u6cdb\u5316\u7684\u6027\u80fd\u3002", "motivation": "\u9700\u8981\u5feb\u901f\u3001\u975e\u4fb5\u5165\u3001\u53ef\u6269\u5c55\u7684\u53ef\u53ef\u8c46\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\uff0c\u66ff\u4ee3\u8017\u65f6\u7684\u5b9e\u9a8c\u5ba4\u5206\u6790\uff0c\u51cf\u5c11\u7834\u574f\u4e0e\u6210\u672c\u3002", "method": "\u5728\u4f20\u9001\u5e26\u7cfb\u7edf\u4e0a\u96c6\u6210VIS-NIR\u5149\u8c31\u4eea\uff0c\u6536\u96c6\u53ef\u53ef\u8c46\u5149\u8c31\uff1b\u4ee5\u6807\u51c6\u5b9e\u9a8c\u5ba4\u5206\u6790\u4f5c\u4e3a\u5730\u9762\u5b9e\u51b5\uff1b\u5efa\u7acb\u56de\u5f52\u6a21\u578b\uff1b\u5728\u54e5\u4f26\u6bd4\u4e9a\u591a\u5730\u533a\u53ca\u79d8\u9c81Cusco\u8fdb\u884c\u5730\u7406\u72ec\u7acb\u8bc4\u4f30\u3002", "result": "\u5404\u7269\u7406\u5316\u5b66\u6027\u8d28\u7684R2\u5747\u8d85\u8fc70.98\uff1b\u5730\u7406\u72ec\u7acb\u6837\u672c\u51c6\u786e\u5ea6\u4e3a0.96\u3002", "conclusion": "\u975e\u7834\u574f\u6027\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u662f\u4f20\u7edf\u5b9e\u9a8c\u5ba4\u65b9\u6cd5\u7684\u53ef\u66ff\u4ee3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u53ef\u53ef\u751f\u4ea7\u94fe\u7684\u8d28\u91cf\u8bc4\u4f30\u3002"}}
{"id": "2510.23643", "categories": ["cs.CR", "cs.AI", "cs.LG", "I.2.6; D.4.6"], "pdf": "https://arxiv.org/pdf/2510.23643", "abs": "https://arxiv.org/abs/2510.23643", "authors": ["Zhixin Pan", "Ziyu Shu", "Linh Nguyen", "Amberbir Alemayoh"], "title": "SAND: A Self-supervised and Adaptive NAS-Driven Framework for Hardware Trojan Detection", "comment": null, "summary": "The globalized semiconductor supply chain has made Hardware Trojans (HT) a\nsignificant security threat to embedded systems, necessitating the design of\nefficient and adaptable detection mechanisms. Despite promising machine\nlearning-based HT detection techniques in the literature, they suffer from ad\nhoc feature selection and the lack of adaptivity, all of which hinder their\neffectiveness across diverse HT attacks. In this paper, we propose SAND, a\nselfsupervised and adaptive NAS-driven framework for efficient HT detection.\nSpecifically, this paper makes three key contributions. (1) We leverage\nself-supervised learning (SSL) to enable automated feature extraction,\neliminating the dependency on manually engineered features. (2) SAND integrates\nneural architecture search (NAS) to dynamically optimize the downstream\nclassifier, allowing for seamless adaptation to unseen benchmarks with minimal\nfine-tuning. (3) Experimental results show that SAND achieves a significant\nimprovement in detection accuracy (up to 18.3%) over state-of-the-art methods,\nexhibits high resilience against evasive Trojans, and demonstrates strong\ngeneralization.", "AI": {"tldr": "\u63d0\u51fa\u4e86 SAND \u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u81ea\u9002\u5e94 NAS \u5b9e\u73b0\u9ad8\u6548\u7684\u786c\u4ef6\u6728\u9a6c\u68c0\u6d4b\uff0c\u63d0\u5347\u5728\u591a\u6837\u5316\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\u4e0e\u6cdb\u5316\u6027\u3002", "motivation": "\u5168\u7403\u5316\u534a\u5bfc\u4f53\u4f9b\u5e94\u94fe\u5bfc\u81f4\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u7684\u786c\u4ef6\u6728\u9a6c\u6210\u4e3a\u663e\u8457\u5b89\u5168\u5a01\u80c1\uff0c\u73b0\u6709\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u7279\u5f81\u4f9d\u8d56\u6027\u5f3a\u3001\u7f3a\u4e4f\u81ea\u9002\u5e94\u6027\u7b49\u4e0d\u8db3\uff0c\u96be\u4ee5\u8de8\u4e0d\u540c\u653b\u51fb\u96c6\u6cdb\u5316\u3002", "method": "\u5f15\u5165 SAND\uff1a\u4f7f\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u5b9e\u73b0\u81ea\u52a8\u7279\u5f81\u63d0\u53d6\uff0c\u7ed3\u5408\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff08NAS\uff09\u52a8\u6001\u4f18\u5316\u4e0b\u6e38\u5206\u7c7b\u5668\uff0c\u5b9e\u73b0\u5bf9\u65b0\u57fa\u51c6\u7684\u5feb\u901f\u9002\u914d\u5e76\u6700\u5c0f\u5316\u5fae\u8c03\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0cSAND \u76f8\u8f83\u73b0\u6709\u65b9\u6cd5\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\u63d0\u5347\u6700\u9ad8\u53ef\u8fbe 18.3%\uff1b\u5bf9\u89c4\u907f\u6027\u6728\u9a6c\u5177\u6709\u8f83\u9ad8\u9c81\u68d2\u6027\uff0c\u5177\u5907\u8f83\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SAND \u63d0\u4f9b\u4e00\u79cd\u81ea\u76d1\u7763\u4e0e NAS \u9a71\u52a8\u7684\u81ea\u9002\u5e94 HT \u68c0\u6d4b\u6846\u67b6\uff0c\u80fd\u9ad8\u6548\u9002\u5e94\u4e0d\u540c\u57fa\u51c6\u5e76\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u4e0e\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.23819", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23819", "abs": "https://arxiv.org/abs/2510.23819", "authors": ["Avishka Herath", "Malith Jayalath", "Kumudu Kaushalya", "Sanjana Kapukotuwa", "Chathuni Wijegunawardena", "Pahan Mendis", "Kithmin Wickremasinghe", "Duminda Samarasinghe", "Wageesha N. Manamperi", "Chamira U. S. Edussooriya"], "title": "A Simultaneous ECG-PCG Acquisition System with Real-Time Burst-Adaptive Noise Cancellation", "comment": "Paper submitted to IEEE International Symposium on Circuits and\n  Systems (ISCAS) 2026", "summary": "Cardiac auscultation is an essential clinical skill, requiring excellent\nhearing to distinguish subtle differences in timing and pitch of heart sounds.\nHowever, diagnosing solely from these sounds is often challenging due to\ninterference from surrounding noise, and the information may be limited.\nExisting solutions that adaptively cancel external noise are either not\nreal-time or are computationally intensive, making them unsuitable for\nimplementation in a portable system. This work proposes an end-to-end system\nwith a real-time adaptive noise cancellation pipeline integrated into a device\nthat simultaneously acquires electrocardiogram (ECG) and phonocardiogram (PCG)\nsignals. The performance of the system is validated using real-world hospital\nnoise datasets and recordings captured with the dual-modality device. For PCG\nand ECG signals recorded from the device in noisy hospital settings, the\nproposed algorithms achieved signal-to-noise ratio improvements of 37.01 dB and\n30.32 dB, respectively. These results demonstrate the systems effectiveness in\nenabling reliable and accessible cardiac screening, including noisy hospital\nenvironments typical of resource-constrained settings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u5b9e\u65f6\u81ea\u9002\u5e94\u566a\u58f0\u6291\u5236\u7cfb\u7edf\uff0c\u96c6\u6210\u5728\u540c\u65f6\u91c7\u96c6ECG\u548cPCG\u7684\u8bbe\u5907\u4e2d\uff0c\u7528\u4e8e\u5728\u5608\u6742\u73af\u5883\u4e2d\u6539\u5584\u5fc3\u97f3\u4fe1\u53f7\u7684\u8d28\u91cf\u3002", "motivation": "\u5fc3\u97f3\u8bca\u65ad\u6613\u53d7\u73af\u5883\u566a\u58f0\u5e72\u6270\uff0c\u4e14\u4fbf\u643a\u7cfb\u7edf\u9700\u5177\u5907\u5b9e\u65f6\u6027\u4ee5\u7528\u4e8e\u8d44\u6e90\u6709\u9650\u7684\u8bbe\u7f6e\u3002", "method": "\u5f00\u53d1\u5b9e\u65f6\u81ea\u9002\u5e94\u566a\u58f0\u6291\u5236\u7ba1\u7ebf\u5e76\u96c6\u6210\u5230\u53cc\u6a21\u6001\u8bbe\u5907\uff0c\u5229\u7528\u533b\u9662\u566a\u58f0\u6570\u636e\u96c6\u4e0e\u8bbe\u5907\u5f55\u97f3\u8fdb\u884c\u9a8c\u8bc1\uff0c\u9488\u5bf9PCG\u548cECG\u4fe1\u53f7\u5206\u522b\u5b9e\u73b0\u566a\u58f0\u6291\u5236\u3002", "result": "\u5728\u5608\u6742\u7684\u533b\u9662\u73af\u5883\u4e2d\uff0cPCG\u4fe1\u53f7SNR\u63d0\u534737.01 dB\uff0cECG\u4fe1\u53f7\u63d0\u534730.32 dB\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u53ef\u63d0\u5347\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5fc3\u810f\u7b5b\u67e5\u7684\u53ef\u9760\u6027\u548c\u53ef\u53ca\u6027\uff0c\u4fbf\u643a\u4e14\u5177\u5907\u5b9e\u65f6\u6027\u3002"}}
{"id": "2510.24595", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.24595", "abs": "https://arxiv.org/abs/2510.24595", "authors": ["Azadeh Pourkabirian", "Kai Li", "Photios A. Stavrou", "Wei Ni"], "title": "A New Hybrid Precoding Approach for Multi-user Massive MIMO over Fading Channels", "comment": null, "summary": "Hybrid precoding is an indispensable technique to harness the full potential\nof a multi-user massive multiple-input, multiple-output (MU-MMIMO) system. In\nthis paper, we propose a new hybrid precoding approach that combines digital\nand analog precoding to optimize data transmission over multiple antennas. This\napproach steers signals in specific directions, leading to maximizing sum-rate\nand suppressing side-lobe interference. When dealing with complex signals,\nchanges in phase are naturally associated with changes in angle, and these\nvariations are inherently correlated. The correlation between the angle and\nphase is essential for accurately determining the channel characteristics. An\nimportant aspect of this approach is that we model the angle and phase as\ncorrelated variables following a bivariate Gaussian distribution, and for the\nfirst time, we define a joint angle and phase entropy to measure the\nuncertainty of angle and phase variations in wireless channels. This entropy is\ncrucial to adapt the proposed precoding method with variations. Simulation\nresult validate the accuracy of our analytical findings, demonstrating 18.31%\nincrease in sum-rate and an 11.47% improvement in robustness compared to other\nstate-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6570\u5b57\u4e0e\u6a21\u62df\u6df7\u5408\u9884\u7f16\u7801\u7684\u65b0\u65b9\u6cd5\uff0c\u8003\u8651\u89d2\u5ea6\u4e0e\u76f8\u4f4d\u7684\u76f8\u5173\u6027\u53ca\u5176\u8054\u5408\u71b5\uff0c\u7528\u4e8eMU-MIMO\u7684\u6df7\u5408\u9884\u7f16\u7801\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6df7\u5408\u9884\u7f16\u7801\u5e38\u5ffd\u7565\u89d2\u5ea6\u4e0e\u76f8\u4f4d\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002\u901a\u8fc7\u5c06\u89d2\u5ea6\u548c\u76f8\u4f4d\u5efa\u6a21\u4e3a\u76f8\u5173\u53d8\u91cf\u5e76\u5f15\u5165\u8054\u5408\u89d2-\u76f8\u4f4d\u71b5\uff0c\u53ef\u66f4\u51c6\u786e\u523b\u753b\u4fe1\u9053\u53d8\u5316\uff0c\u4ece\u800c\u5b9e\u73b0\u81ea\u9002\u5e94\u4e14\u9c81\u68d2\u7684\u9884\u7f16\u7801\u3002", "method": "\u5c06\u6570\u5b57\u4e0e\u6a21\u62df\u9884\u7f16\u7801\u76f8\u7ed3\u5408\uff0c\u5bf9\u4fe1\u53f7\u5728\u591a\u5929\u7ebf\u7cfb\u7edf\u4e2d\u6309\u7279\u5b9a\u65b9\u5411\u8fdb\u884c\u5b9a\u5411\uff0c\u540c\u65f6\u5c06\u89d2\u5ea6\u548c\u76f8\u4f4d\u5efa\u6a21\u4e3a\u76f8\u5173\u53d8\u91cf\uff0c\u5047\u8bbe\u670d\u4ece\u53cc\u53d8\u91cf\u9ad8\u65af\u5206\u5e03\uff0c\u5e76\u5b9a\u4e49\u8054\u5408\u89d2-\u76f8\u4f4d\u71b5\u4ee5\u8861\u91cf\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u636e\u6b64\u5f15\u5bfc\u9884\u7f16\u7801\u81ea\u9002\u5e94\u8c03\u6574\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u548c\u901a\u4fe1\u901f\u7387\u63d0\u5347\u7ea618.31%\uff0c\u9c81\u68d2\u6027\u63d0\u5347\u7ea611.47%\u3002", "conclusion": "\u5c06\u8054\u5408\u89d2-\u76f8\u4f4d\u71b5\u7528\u4e8e\u6df7\u5408\u9884\u7f16\u7801\uff0c\u53ef\u63d0\u5347MU\u2011MIMO\u7cfb\u7edf\u7684\u548c\u901f\u7387\u4e0e\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4e3a\u89d2\u76f8\u76f8\u5173\u4fe1\u9053\u5efa\u6a21\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2510.23621", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23621", "abs": "https://arxiv.org/abs/2510.23621", "authors": ["Alexandre Benoit"], "title": "Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields", "comment": "78 pages, 21 figures", "summary": "Machine-learning force fields can deliver accurate molecular dynamics (MD) at\nhigh computational cost. For SO(3)-equivariant models such as MACE, there is\nlittle systematic evidence on whether reduced-precision arithmetic and\nGPU-optimized kernels can cut this cost without harming physical fidelity. This\nthesis aims to make MACE cheaper and faster while preserving accuracy by\nidentifying computational bottlenecks and evaluating low-precision execution\npolicies. We profile MACE end-to-end and per block, compare the e3nn and NVIDIA\ncuEquivariance backends, and assess FP64/FP32/BF16/FP16 settings (with FP32\naccumulation) for inference, short NVT and long NPT water simulations, and toy\ntraining runs under reproducible, steady-state timing. cuEquivariance reduces\ninference latency by about $3\\times$. Casting only linear layers to BF16/FP16\nwithin an FP32 model yields roughly 4x additional speedups, while energies and\nthermodynamic observables in NVT/NPT MD remain within run-to-run variability.\nHalf-precision weights during training degrade force RMSE. Mixing e3nn and cuEq\nmodules without explicit adapters causes representation mismatches. Fused\nequivariant kernels and mixed-precision inference can substantially accelerate\nstate-of-the-art force fields with negligible impact on downstream MD. A\npractical policy is to use cuEquivariance with FP32 by default and enable\nBF16/FP16 for linear layers (keeping FP32 accumulations) for maximum\nthroughput, while training remains in FP32. Further gains are expected on\nAmpere/Hopper GPUs (TF32/BF16) and from kernel-level FP16/BF16 paths and\npipeline fusion.", "AI": {"tldr": "\u901a\u8fc7\u5bf9 MACE \u7684\u7aef\u5230\u7aef\u548c\u5206\u5757\u5206\u6790\uff0c\u4ee5\u53ca e3nn \u4e0e cuEquivariance \u4e24\u79cd\u540e\u7aef\u3001\u4e0d\u540c\u7cbe\u5ea6\u8bbe\u7f6e\uff08FP64/FP32/BF16/FP16\u3001FP32 \u7d2f\u52a0\uff09\u7684\u6bd4\u8f83\uff0c\u5bf9 SO(3) \u7b49\u53d8\u6a21\u578b\u7684\u63a8\u7406\u548c\u5206\u5b50\u52a8\u529b\u5b66\u6027\u80fd\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d1\u73b0\u4f7f\u7528 cuEquivariance \u53ef\u5c06\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e\u7ea6 3 \u500d\uff1b\u4ec5\u5c06\u7ebf\u6027\u5c42\u8f6c\u4e3a BF16/FP16\uff08\u5728 FP32 \u6a21\u578b\u5185\uff09\u53ef\u518d\u83b7\u5f97\u7ea6 4 \u500d\u7684\u901f\u5ea6\u63d0\u5347\uff1b\u5728\u4fdd\u6301\u70ed\u529b\u5b66 observables \u7684\u53ef\u53d8\u6027\u524d\u63d0\u4e0b\uff0c\u957f\u77ed\u671f MD \u7ed3\u679c\u672a\u663e\u8457\u504f\u79bb\u3002\u63d0\u51fa\u57fa\u4e8e\u6df7\u5408\u7cbe\u5ea6\u548c\u540e\u7aef\u9009\u62e9\u7684\u5b9e\u7528\u7b56\u7565\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e\u50cf MACE \u8fd9\u6837\u7684 SO(3) \u7b49\u53d8 ML \u529b\u573a\uff0c\u4f4e\u7cbe\u5ea6\u6267\u884c\u548c GPU \u5185\u6838\u4f18\u5316\u662f\u5426\u80fd\u5728\u4e0d\u635f\u5bb3\u7269\u7406\u4fdd\u771f\u5ea6\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u6210\u672c\uff0c\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u8bc1\u636e\u3002\u9700\u8981\u5bf9\u7aef\u5230\u7aef\u6027\u80fd\u3001\u5404\u6a21\u5757\u74f6\u9888\u53ca\u4e0d\u540c\u6570\u503c\u7b56\u7565\u8fdb\u884c Profiling \u4e0e\u5bf9\u6bd4\u3002", "method": "\u5bf9 MACE \u8fdb\u884c\u7aef\u5230\u7aef\u4e0e\u9010\u5757 Profiling\uff1b\u6bd4\u8f83 e3nn \u4e0e cuEquivariance \u540e\u7aef\uff1b\u5728\u63a8\u65ad\u4e0e\u77ed\u65f6 NVT\u3001\u957f\u65f6 NPT \u6c34\u7cfb\u7edf\u53ca\u7b80\u5355\u8bad\u7ec3\u7247\u6bb5\u4e0a\uff0c\u6bd4\u8f83 FP64/FP32/BF16/FP16\uff08FP32 \u7d2f\u52a0\uff09\u4e0b\u7684\u6027\u80fd\u4e0e\u6570\u503c\u7a33\u5b9a\u6027\uff1b\u5728\u91cd\u590d\u6027\u53ef\u63a7\u7684\u57fa\u51c6\u4e0b\u8fdb\u884c\u65f6\u95f4\u6d4b\u91cf\u3002", "result": "cuEquivariance \u5c06\u63a8\u7406\u5ef6\u8fdf\u7ea6\u964d\u4f4e 3\u00d7\uff1b\u4ec5\u5bf9\u7ebf\u6027\u5c42\u5728 FP32 \u6a21\u578b\u5185\u8f6c\u4e3a BF16/FP16 \u53ef\u518d\u63d0\u5347\u7ea6 4\u00d7 \u7684\u901f\u5ea6\uff1bNVT/NPT MD \u7684\u80fd\u91cf\u548c\u70ed\u529b\u5b66\u89c2\u6d4b\u503c\u5728 run-to-run \u7684\u53d8\u52a8\u8303\u56f4\u5185\uff1b\u8bad\u7ec3\u65f6\u4f7f\u7528\u534a\u7cbe\u5ea6\u6743\u91cd\u4f1a\u964d\u4f4e\u529b\u7684 RMSE\uff1b\u672a\u4f7f\u7528\u9002\u914d\u5668\u5c31\u6df7\u5408 e3nn \u4e0e cuEqmodules \u4f1a\u5bfc\u81f4\u8868\u793a\u4e0d\u5339\u914d\uff1b\u878d\u5408\u7684\u7b49\u53d8\u6838\u548c\u6df7\u5408\u7cbe\u5ea6\u63a8\u7406\u53ef\u5728\u4e0d\u663e\u8457\u5f71\u54cd MD \u7684\u60c5\u51b5\u4e0b\u663e\u8457\u52a0\u901f\u529b\u573a\u8ba1\u7b97\u3002", "conclusion": "\u5efa\u8bae\u7684\u5b9e\u7528\u7b56\u7565\u662f\u5728\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u4f7f\u7528 cuEquivariance + FP32\uff0c\u5e76\u5c06\u7ebf\u6027\u5c42\u5f00\u542f BF16/FP16\uff08\u4fdd\u7559 FP32 \u7d2f\u52a0\uff09\uff0c\u4ee5\u83b7\u5f97\u6700\u5927\u541e\u5410\uff0c\u540c\u65f6\u8bad\u7ec3\u4fdd\u6301 FP32\uff1b\u5728 Ampere/Hopper GPU\uff08TF32/BF16\uff09\u53ca\u5185\u6838\u5c42 FP16/BF16 \u8def\u5f84\u4e0e\u6d41\u6c34\u7ebf\u878d\u5408\u65b9\u9762\uff0c\u7406\u8bba\u4e0a\u5c06\u5e26\u6765\u8fdb\u4e00\u6b65\u6536\u76ca\u3002"}}
{"id": "2510.23900", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23900", "abs": "https://arxiv.org/abs/2510.23900", "authors": ["Kuan-Po Chiu", "Sumit Roy"], "title": "LEO Downlink Channel Model Revisited: Scattering Geometry-Inspired Derivation", "comment": "Accepted to Globecom 2025", "summary": "This paper presents a new derivation of LEO-to-ground receiver channel model\nto address a clear gap in the prior art: the lack of an appropriate geometry\naware characterization of non LOS (NLOS) link model represented by the power\nspectral density (PSD). Specifically, the main contribution is a coherent\nderivation of the PSD from 1st principles that is able to reproduce results in\nprior art and explain the causal relationship of main PSD features to the\npropagation geometry parameters.", "AI": {"tldr": "\u4ece\u7b2c\u4e00\u6027\u539f\u7406\u63a8\u5bfcLEO\u5230\u5730\u9762NLOS\u7684PSD\uff0c\u586b\u8865\u51e0\u4f55\u654f\u611fPSD\u8868\u5f81\u7a7a\u7f3a\uff0c\u5e76\u63ed\u793aPSD\u7279\u5f81\u4e0e\u4f20\u64ad\u51e0\u4f55\u7684\u56e0\u679c\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709PSD\u6a21\u578b\u7f3a\u4e4f\u51e0\u4f55\u611f\u77e5\u7684NLOS\u63cf\u8ff0\uff0c\u96be\u4ee5\u89e3\u91caPSD\u7279\u5f81\u4e0e\u8f68\u9053\u51e0\u4f55\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u3002", "method": "\u57fa\u4e8e\u7b2c\u4e00\u6027\u539f\u7406\uff0c\u7ed3\u5408LEO\u5730\u9762\u4f20\u64ad\u51e0\u4f55\uff0c\u63a8\u5bfcNLOSPSD\u7684\u8868\u8fbe\uff0c\u5e76\u4f7f\u4e4b\u80fd\u591f\u590d\u73b0\u5df2\u6709\u7ed3\u679c\u3001\u63ed\u793a\u51e0\u4f55\u53c2\u6570\u5bf9PSD\u7684\u51b3\u5b9a\u4f5c\u7528\u3002", "result": "\u5f97\u5230\u5177\u6709\u51e0\u4f55\u654f\u611f\u6027\u7684PSD\u63a8\u5bfc\u5f0f\uff0c\u80fd\u5728\u4e0d\u540c\u51e0\u4f55\u53c2\u6570\u4e0b\u4e0e\u5148\u524d\u5de5\u4f5c\u7ed3\u679c\u4fdd\u6301\u4e00\u81f4\uff0c\u5e76\u89e3\u91caPSD\u7279\u5f81\u7684\u6210\u56e0\u3002", "conclusion": "\u63d0\u4f9b\u4e00\u4e2a\u7269\u7406\u4e00\u81f4\u3001\u51e0\u4f55\u53ef\u89e3\u91ca\u7684LEO\u5230\u5730\u9762NLOS PSD\u5efa\u6a21\u6846\u67b6\uff0c\u7528\u4e8e\u6539\u8fdb\u4fe1\u9053\u5efa\u6a21\u4e0e\u7cfb\u7edf\u8bbe\u8ba1\u3002"}}
{"id": "2510.24480", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24480", "abs": "https://arxiv.org/abs/2510.24480", "authors": ["Qing Xue", "Yun Lan", "Jiajia Guo", "Qianbin Chen", "Shaodan Ma"], "title": "Joint Active and Passive Beamforming with Sensing-Assisted Discrete Phase Shifts for Dual-RIS ISAC Systems", "comment": null, "summary": "Targeting the requirements of 6G, this paper investigates a semi-passive\ndual-reconfigurable intelligent surface (RIS)-assisted integrated sensing and\ncommunication (ISAC) system, tackling the max-min user\nsignal-to-interference-plus-noise ratio (SINR) problem via joint active and\npassive beamforming to enhance system performance and ensure user fairness.\nAddressing this challenge, we first utilize dual RISs for user angle estimation\nto simplify the solution process of the formulated problem, an efficient\nalternating optimization algorithm is then developed. Specifically,\nsemi-definite relaxation and the bisection method are employed to solve the\ntransmit beamforming optimization subproblem. For the RIS discrete phase\nshifts, a sensing-assisted approach is adopted to constrain the optimization\nsearch space, with two distinct low-complexity search strategies introduced for\ndifferent RIS sizes. Numerical simulation results demonstrate that the proposed\nalgorithm achieves performance close to the ideal continuous phase shift\nbenchmark, outperforms conventional discrete phase shift optimization\nalgorithms, and exhibits a significant improvement over single-RIS systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u534a\u88ab\u52a8\u7684\u53ccRIS\u8f85\u52a9ISAC\u7cfb\u7edf\uff0c\u9488\u5bf9\u6700\u5927\u6700\u5c0fSINR\u95ee\u9898\uff0c\u901a\u8fc7\u8054\u52a8\u6709\u6e90\u4e0e\u88ab\u52a8\u6ce2\u675f\u6210\u5f62\u5e76\u5bf9RIS\u79bb\u6563\u76f8\u4f4d\u8fdb\u884c\u611f\u77e5\u8f85\u52a9\u7ea6\u675f\u641c\u7d22\uff0c\u5728\u590d\u6742\u5ea6\u53ef\u63a7\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u7406\u60f3\u8fde\u7eed\u76f8\u4f4d\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u5355RIS\u4e0e\u4f20\u7edf\u79bb\u6563\u641c\u7d22\u65b9\u6cd5\u3002", "motivation": "\u57286G\u573a\u666f\u4e0b\u9700\u63d0\u5347\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1(ISAC)\u6027\u80fd\u5e76\u517c\u987e\u7528\u6237\u516c\u5e73\u6027\uff0c\u540c\u65f6\u901a\u8fc7\u53ccRIS\u63d0\u5347\u89d2\u5ea6\u4f30\u8ba1\u548c\u8986\u76d6\u80fd\u529b\uff0c\u964d\u4f4e\u79bb\u6563\u76f8\u4f4d\u641c\u7d22\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u91c7\u7528\u53ccRIS\u8fdb\u884c\u7528\u6237\u89d2\u5ea6\u4f30\u8ba1\u4ee5\u7b80\u5316\u95ee\u9898\uff1b\u63d0\u51fa\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u6c42\u89e3\u8054\u5408\u6709\u6e90\u4e0e\u88ab\u52a8\u6ce2\u675f\u6210\u5f62\uff1b\u53d1\u5c04\u6ce2\u675f\u5f62\u6210\u5b50\u95ee\u9898\u91c7\u7528\u534a\u5b9a\u677e\u5f1b(SDR)\u7ed3\u5408\u4e8c\u5206\u6cd5\u6c42\u89e3\uff1b\u9488\u5bf9RIS\u79bb\u6563\u76f8\u4f4d\uff0c\u91c7\u7528\u611f\u77e5\u8f85\u52a9\u7ea6\u675f\u4ee5\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u5e76\u4e3a\u4e0d\u540cRIS\u89c4\u6a21\u63d0\u51fa\u4e24\u79cd\u4f4e\u590d\u6742\u5ea6\u641c\u7d22\u7b56\u7565\u3002", "result": "\u6570\u503c\u4eff\u771f\u8868\u660e\u6240\u63d0\u7b97\u6cd5\u7684\u6027\u80fd\u63a5\u8fd1\u7406\u60f3\u8fde\u7eed\u76f8\u4f4d\u57fa\u51c6\uff0c\u4f18\u4e8e\u4f20\u7edf\u79bb\u6563\u76f8\u4f4d\u4f18\u5316\u7b97\u6cd5\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u5355RIS\u7cfb\u7edf\u3002", "conclusion": "\u8bc1\u5b9e\u53ccRIS\u5728ISAC\u4e2d\u7684\u6f5c\u529b\uff0c\u63d0\u4f9b\u4e86\u9488\u5bf9\u79bb\u6563\u76f8\u4f4dRIS\u7684\u89c4\u6a21\u81ea\u9002\u5e94\u641c\u7d22\u7b56\u7565\uff0c\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u6298\u8877\u3002"}}
{"id": "2510.23820", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.23820", "abs": "https://arxiv.org/abs/2510.23820", "authors": ["Shahab Jahanbazi", "Mateen Ashraf", "Onel L. A. L\u00f3pez"], "title": "MDP-based Energy-aware Task Scheduling for Battery-less IoT", "comment": "13 pages, 11 figures", "summary": "Realizing high long-term task completion rates represents a fundamental\nchallenge in battery-less Internet of Things (IoT) devices powered by ambient\nenergy harvesting. This difficulty is primarily due to the stochastic and\ntime-varying characteristics of the available energy, which significantly\ncomplicate the design of optimal task scheduling policies. In this paper, we\nconsider a battery-less IoT device that must periodically report sensing\nmeasurements to a monitoring center. We adopt the Markov decision process (MDP)\nframework to handle energy variability while aiming to maximize the long-term\ntask completion rate. For this, we first identify its components and then\ndefine two appropriate reward functions. We demonstrate the inherent properties\nassociated with the MDP formulation and the related optimal policy.\nSubsequently, we solve the resulting optimization problem, leading to the\noptimal stationary threshold-based (OSTB) scheduling. Simulation results\ndemonstrate that OSTB outperforms the well-known ``as late as possible'' (ALAP)\nscheduling strategy. For instance, an $8.6\\%$ increase in the task completion\nrate, along with a $65\\%$ reduction in power failures and a $86.29\\%$ decrease\nin execution delays during task execution are registered assuming a $4.7$ mF\ncapacitor.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eMDP\u7684\u6700\u4f18\u7a33\u6001\u9608\u503c\u8c03\u5ea6\uff08OSTB\uff09\u4ee5\u63d0\u5347\u65e0\u7535\u6c60IoT\u5728\u73af\u5883\u80fd\u91cf\u4e0b\u7684\u957f\u671f\u4efb\u52a1\u5b8c\u6210\u7387\uff1b\u4e0eALAP\u76f8\u6bd4\uff0cOSTB\u5728\u4eff\u771f\u4e2d\u5b9e\u73b08.6%\u4efb\u52a1\u5b8c\u6210\u7387\u63d0\u5347\u3001\u529f\u7387\u5931\u8d25\u964d\u4f4e65%\u3001\u6267\u884c\u5ef6\u8fdf\u4e0b\u964d86.29%\uff0c\u57fa\u4e8e4.7 mF\u7535\u5bb9\u3002", "motivation": "\u5728\u4f9d\u8d56\u73af\u5883\u80fd\u91cf\u7684\u65e0\u7535\u6c60\u7269\u8054\u7f51\u8bbe\u5907\u4e2d\uff0c\u80fd\u6e90\u5230\u8fbe\u5177\u6709\u968f\u673a\u6027\u548c\u65f6\u53d8\u6027\uff0c\u7ed9\u4efb\u52a1\u8c03\u5ea6\u7684\u957f\u671f\u6027\u80fd\u5e26\u6765\u6311\u6218\uff0c\u9700\u8bbe\u8ba1\u80fd\u5728\u80fd\u91cf\u6ce2\u52a8\u4e2d\u5b9e\u73b0\u9ad8\u957f\u671f\u5b8c\u6210\u7387\u7684\u7b56\u7565\u3002", "method": "\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u5bf9\u80fd\u91cf\u6ce2\u52a8\u8fdb\u884c\u5efa\u6a21\uff0c\u8bc6\u522b\u7cfb\u7edf\u7ec4\u6210\u5e76\u5b9a\u4e49\u4e24\u79cd\u5956\u52b1\u51fd\u6570\uff0c\u5206\u6790MDP\u6027\u8d28\u5e76\u6c42\u89e3\u5f97\u5230\u6700\u4f18\u7684\u7a33\u5b9a\u6027\u9608\u503c\u8c03\u5ea6\u7b56\u7565\uff08OSTB\uff09\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u8bc1\u660eOSTB\u4f18\u4e8e\u5e7f\u4e3a\u4f7f\u7528\u7684\u201c\u5c3d\u91cf\u665a\u6267\u884c\u201d(ALAP)\u7b56\u7565\uff0c\u57284.7 mF\u7535\u5bb9\u6761\u4ef6\u4e0b\u5b9e\u73b08.6%\u4efb\u52a1\u5b8c\u6210\u7387\u63d0\u5347\u300165%\u529f\u7387\u5931\u8d25\u51cf\u5c11\u3001\u6267\u884c\u5ef6\u8fdf\u4e0b\u964d86.29%\u3002", "conclusion": "\u5728\u80fd\u6e90\u81ea\u7ed9\u7684\u65e0\u7535\u6c60IoT\u573a\u666f\u4e2d\uff0cOSTB\u63d0\u4f9b\u4e00\u6761\u53ef\u5b9e\u73b0\u7684\u7a33\u6001\u6700\u4f18\u8c03\u5ea6\u8def\u5f84\uff0c\u80fd\u663e\u8457\u63d0\u5347\u957f\u671f\u6027\u80fd\u5e76\u964d\u4f4e\u80fd\u91cf\u76f8\u5173\u98ce\u9669\u3002"}}
{"id": "2510.23622", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.23622", "abs": "https://arxiv.org/abs/2510.23622", "authors": ["Alyssa Gerhart", "Balaji Iyangar"], "title": "Adversarially-Aware Architecture Design for Robust Medical AI Systems", "comment": null, "summary": "Adversarial attacks pose a severe risk to AI systems used in healthcare,\ncapable of misleading models into dangerous misclassifications that can delay\ntreatments or cause misdiagnoses. These attacks, often imperceptible to human\nperception, threaten patient safety, particularly in underserved populations.\nOur study explores these vulnerabilities through empirical experimentation on a\ndermatological dataset, where adversarial methods significantly reduce\nclassification accuracy. Through detailed threat modeling, experimental\nbenchmarking, and model evaluation, we demonstrate both the severity of the\nthreat and the partial success of defenses like adversarial training and\ndistillation. Our results show that while defenses reduce attack success rates,\nthey must be balanced against model performance on clean data. We conclude with\na call for integrated technical, ethical, and policy-based approaches to build\nmore resilient, equitable AI in healthcare.", "AI": {"tldr": "\u8be5\u5de5\u4f5c\u6982\u8ff0\u4e86AI\u5728\u533b\u7597\u9886\u57df\u7684\u5bf9\u6297\u6027\u653b\u51fb\u98ce\u9669\uff0c\u901a\u8fc7\u76ae\u80a4\u79d1\u6570\u636e\u96c6\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\u653b\u51fb\u80fd\u663e\u8457\u964d\u4f4e\u5206\u7c7b\u51c6\u786e\u6027\uff1b\u9632\u5fa1\u65b9\u6cd5\uff08\u5bf9\u6297\u6027\u8bad\u7ec3\u3001\u84b8\u998f\uff09\u867d\u6709\u7f13\u89e3\uff0c\u4f46\u9700\u6743\u8861\u4e0e\u6e05\u6d01\u6570\u636e\u6027\u80fd\uff1b\u547c\u5401\u5728\u6280\u672f\u3001\u4f26\u7406\u4e0e\u653f\u7b56\u5c42\u9762\u5f00\u5c55\u7efc\u5408\u6cbb\u7406\u4ee5\u63d0\u5347\u97e7\u6027\u4e0e\u516c\u5e73\u6027\u3002", "motivation": "\u786e\u4fdd\u533b\u7597AI\u7684\u5b89\u5168\u6027\u4e0e\u516c\u5e73\u6027\uff0c\u907f\u514d\u5bf9\u5f31\u52bf\u4eba\u7fa4\u7684\u4e0d\u5229\u5f71\u54cd\uff1b\u5e94\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u5e26\u6765\u7684\u6f5c\u5728\u98ce\u9669\u3002", "method": "\u5728 dermatological \u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7ecf\u9a8c\u6027\u5b9e\u9a8c\uff0c\u8fdb\u884c\u5a01\u80c1\u5efa\u6a21\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u6a21\u578b\u8bc4\u4f30\uff0c\u8bc4\u4f30\u591a\u79cd\u9632\u5fa1\u7b56\u7565\uff08\u5bf9\u6297\u6027\u8bad\u7ec3\u3001\u84b8\u998f\u7b49\uff09\u3002", "result": "\u5bf9\u6297\u653b\u51fb\u663e\u8457\u964d\u4f4e\u5206\u7c7b\u51c6\u786e\u6027\uff1b\u9632\u5fa1\u663e\u8457\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff0c\u4f46\u53ef\u80fd\u964d\u4f4e\u5bf9\u6e05\u6d01\u6570\u636e\u7684\u6027\u80fd\uff0c\u4e14\u6548\u679c\u5e76\u975e\u5168\u9762\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u9700\u8981\u6280\u672f\u3001\u4f26\u7406\u4e0e\u653f\u7b56\u7684\u7efc\u5408\u8def\u5f84\uff0c\u4ee5\u6784\u5efa\u66f4\u9c81\u68d2\u4e14\u66f4\u516c\u5e73\u7684\u533b\u7597AI\u7cfb\u7edf\u3002"}}
{"id": "2510.24408", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.24408", "abs": "https://arxiv.org/abs/2510.24408", "authors": ["Yifan Wu", "Xuewei Feng", "Yuxiang Yang", "Ke Xu"], "title": "Uncovering Gaps Between RFC Updates and TCP/IP Implementations: LLM-Facilitated Differential Checks on Intermediate Representations", "comment": "15 pages, 7 figures", "summary": "As the core of the Internet infrastructure, the TCP/IP protocol stack\nundertakes the task of network data transmission. However, due to the\ncomplexity of the protocol and the uncertainty of cross-layer interaction,\nthere are often inconsistencies between the implementation of the protocol\nstack code and the RFC standard. This inconsistency may not only lead to\ndifferences in protocol functions but also cause serious security\nvulnerabilities. At present, with the continuous expansion of protocol stack\nfunctions and the rapid iteration of RFC documents, it is increasingly\nimportant to detect and fix these inconsistencies. With the rise of large\nlanguage models, researchers have begun to explore how to extract protocol\nspecifications from RFC documents through these models, including protocol\nstack modeling, state machine extraction, text ambiguity analysis, and other\nrelated content. However, existing methods rely on predefined patterns or\nrule-based approaches that fail to generalize across different protocol\nspecifications. Automated and scalable detection of these inconsistencies\nremains a significant challenge. In this study, we propose an automated\nanalysis framework based on LLM and differential models. By modeling the\niterative relationship of the protocol and based on the iterative update\nrelationship of the RFC standard, we perform incremental code function analysis\non different versions of kernel code implementations to automatically perform\ncode detection and vulnerability analysis. We conduct extensive evaluations to\nvalidate the effectiveness of our framework, demonstrating its effectiveness in\nidentifying potential vulnerabilities caused by RFC code inconsistencies.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5dee\u5206\u6a21\u578b\u7684\u81ea\u52a8\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4bRFC\u6807\u51c6\u4e0e\u5185\u6838TCP/IP\u5b9e\u73b0\u4e4b\u95f4\u5728\u4e0d\u540c\u7248\u672c\u4e0a\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u636e\u6b64\u8fdb\u884c\u6f0f\u6d1e\u5206\u6790\u4e0e\u4fee\u590d\u3002", "motivation": "\u534f\u8bae\u6808\u5b9e\u73b0\u7684\u590d\u6742\u6027\u4e0eRFC\u6807\u51c6\u7684\u6301\u7eed\u6f14\u53d8\u5bfc\u81f4\u5b9e\u73b0\u4e0e\u6807\u51c6\u4e4b\u95f4\u5b58\u5728\u4e0d\u4e00\u81f4\uff0c\u8fdb\u800c\u4ea7\u751f\u5b89\u5168\u6f0f\u6d1e\uff1b\u73b0\u6709\u57fa\u4e8e\u9884\u8bbe\u6a21\u5f0f\u7684\u68c0\u6d4b\u96be\u4ee5\u6cdb\u5316\uff0c\u9700\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5efa\u7acb\u534f\u8bae\u4e0eRFC\u66f4\u65b0\u5173\u7cfb\u7684\u8fed\u4ee3\u5efa\u6a21\uff1b\u5728\u4e0d\u540c\u5185\u6838\u7248\u672c\u4e0a\u5bf9\u4ee3\u7801\u51fd\u6570\u8fdb\u884c\u589e\u91cf\u5206\u6790\u4ee5\u81ea\u52a8\u6267\u884c\u4e00\u81f4\u6027\u68c0\u6d4b\u4e0e\u6f0f\u6d1e\u5206\u6790\uff1b\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u534f\u8bae\u89c4\u8303\u3001\u5229\u7528\u5dee\u5206\u6a21\u578b\u5bf9\u7248\u672c\u95f4\u5dee\u5f02\u8fdb\u884c\u5bf9\u6bd4\u4ee5\u53d1\u73b0\u4e0d\u4e00\u81f4\uff1b\u5bf9\u68c0\u6d4b\u6846\u67b6\u8fdb\u884c\u5927\u89c4\u6a21\u8bc4\u4f30\u4ee5\u9a8c\u8bc1\u5728\u8bc6\u522bRFC\u5f15\u53d1\u7684\u6f5c\u5728\u6f0f\u6d1e\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u8bc4\u4f30\uff0c\u8bc1\u660e\u8be5\u6846\u67b6\u5728\u8bc6\u522b\u7531RFC-\u4ee3\u7801\u4e0d\u4e00\u81f4\u5f15\u53d1\u7684\u6f5c\u5728\u6f0f\u6d1e\u65b9\u9762\u5177\u6709\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u81ea\u52a8\u5316\u6846\u67b6\u5177\u5907\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\uff0c\u80fd\u591f\u5e2e\u52a9\u68c0\u6d4b\u4e0e\u4fee\u590d\u534f\u8bae\u6808\u5b9e\u73b0\u4e2d\u7684RFC\u4e0d\u4e00\u81f4\uff0c\u5e76\u4e3a\u540e\u7eed\u5728\u66f4\u5e7f\u6cdb\u7684\u534f\u8bae\u96c6\u5408\u4e0a\u7684\u5e94\u7528\u63d0\u4f9b\u57fa\u7840\u4e0e\u65b9\u5411\u3002"}}
{"id": "2510.23624", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23624", "abs": "https://arxiv.org/abs/2510.23624", "authors": ["Tiago Mendon\u00e7a dos Santos", "Rafael Izbicki", "Lu\u00eds Gustavo Esteves"], "title": "DiNo and RanBu: Lightweight Predictions from Shallow Random Forests", "comment": null, "summary": "Random Forest ensembles are a strong baseline for tabular prediction tasks,\nbut their reliance on hundreds of deep trees often results in high inference\nlatency and memory demands, limiting deployment in latency-sensitive or\nresource-constrained environments. We introduce DiNo (Distance with Nodes) and\nRanBu (Random Bushes), two shallow-forest methods that convert a small set of\ndepth-limited trees into efficient, distance-weighted predictors. DiNo measures\ncophenetic distances via the most recent common ancestor of observation pairs,\nwhile RanBu applies kernel smoothing to Breiman's classical proximity measure.\nBoth approaches operate entirely after forest training: no additional trees are\ngrown, and tuning of the single bandwidth parameter $h$ requires only\nlightweight matrix-vector operations. Across three synthetic benchmarks and 25\npublic datasets, RanBu matches or exceeds the accuracy of full-depth random\nforests-particularly in high-noise settings-while reducing training plus\ninference time by up to 95\\%. DiNo achieves the best bias-variance trade-off in\nlow-noise regimes at a modest computational cost. Both methods extend directly\nto quantile regression, maintaining accuracy with substantial speed gains. The\nimplementation is available as an open-source R/C++ package at\nhttps://github.com/tiagomendonca/dirf. We focus on structured tabular random\nsamples (i.i.d.), leaving extensions to other modalities for future work.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u6d45\u68ee\u6797\u65b9\u6cd5DiNo\u548cRanBu\uff0c\u901a\u8fc7\u5728\u5df2\u6709\u68ee\u6797\u57fa\u7840\u4e0a\u4e0d\u589e\u6811\u6570\u91cf\u3001\u4ec5\u540e\u5904\u7406\u6765\u5b9e\u73b0\u9ad8\u6548\u8ddd\u79bb\u52a0\u6743\u9884\u6d4b\uff0c\u5728\u591a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e0e\u6df1\u5ea6\u968f\u673a\u68ee\u6797\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7cbe\u5ea6\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u51cf\u5c11\u6df1\u5ea6\u968f\u673a\u68ee\u6797\u5728\u63a8\u7406\u548c\u5185\u5b58\u4e0a\u7684\u5f00\u9500\uff0c\u63d0\u5347\u5728\u5ef6\u8fdf\u654f\u611f\u6216\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u53ef\u90e8\u7f72\u6027\uff0c\u540c\u65f6\u5728\u566a\u58f0\u73af\u5883\u4e0b\u4fdd\u6301\u6216\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "method": "DiNo\u901a\u8fc7\u89c2\u5bdf\u540e\u4ee3\u7956\u5148\u5f97\u5230\u7684\u5171\u751f\u8ddd\u79bb\uff08\u6700\u8fd1\u516c\u5171\u7956\u5148\u7684\u6d3e\u751f\u8ddd\u79bb\uff09\u6765\u5ea6\u91cf\u89c2\u6d4b\u5bf9\u7684\u8ddd\u79bb\uff1bRanBu\u4f7f\u7528\u5bf9Breiman\u7684\u90bb\u8fd1\u5ea6\u7684\u6838\u5e73\u6ed1\uff0c\u5c06\u6df1\u68ee\u6797\u8f6c\u5316\u4e3a\u8ddd\u79bb\u6743\u91cd\u7684\u6d45\u68ee\u6797\u9884\u6d4b\u3002\u4e24\u8005\u90fd\u5728\u68ee\u6797\u8bad\u7ec3\u5b8c\u6210\u540e\u8fdb\u884c\uff0c\u4e0d\u518d\u6210\u957f\u65b0\u6811\uff0c\u53ea\u9700\u8981\u5bf9\u5e26\u5bbd\u53c2\u6570h\u8fdb\u884c\u8f7b\u91cf\u77e9\u9635\u5411\u91cf\u8fd0\u7b97\u8c03\u53c2\u3002", "result": "\u5728\u4e09\u7ec4\u5408\u6210\u57fa\u51c6\u548c25\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0cRanBu\u8fbe\u5230\u6216\u8d85\u8fc7\u5168\u6df1\u5ea6\u968f\u673a\u68ee\u6797\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u9ad8\u566a\u58f0\u8bbe\u7f6e\u4e0b\uff0c\u5e76\u5c06\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4\u603b\u8ba1\u51cf\u5c11\u6700\u591a95%\uff1bDiNo\u5728\u4f4e\u566a\u58f0\u60c5\u51b5\u4e0b\u83b7\u5f97\u6700\u597d\u504f\u5dee-\u65b9\u5dee\u6743\u8861\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9002\u4e2d\uff1b\u4e24\u8005\u4e5f\u53ef\u6269\u5c55\u81f3\u5206\u4f4d\u6570\u56de\u5f52\uff0c\u4fdd\u6301\u7cbe\u5ea6\u540c\u65f6\u83b7\u5f97\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e24\u4e2a\u9ad8\u6548\u7684\u6d45\u68ee\u6797\u65b9\u6cd5\uff0c\u9002\u5408\u7528\u4e8e\u7ed3\u6784\u5316\u8868\u683c\u6570\u636e\uff0c\u4e14\u5f00\u6e90\u5b9e\u73b0\u53ef\u7528\u4e8e\u5b9e\u8df5\u90e8\u7f72\uff0c\u540c\u65f6\u4e3a\u4e0b\u4e00\u6b65\u5de5\u4f5c\u6269\u5c55\u81f3\u5176\u4ed6\u6a21\u6001\u548c\u5206\u4f4d\u56de\u5f52\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2510.23992", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23992", "abs": "https://arxiv.org/abs/2510.23992", "authors": ["Yuxiao Wen", "Yanjun Han", "Zhengyuan Zhou"], "title": "Optimal Arm Elimination Algorithms for Combinatorial Bandits", "comment": null, "summary": "Combinatorial bandits extend the classical bandit framework to settings where\nthe learner selects multiple arms in each round, motivated by applications such\nas online recommendation and assortment optimization. While extensions of upper\nconfidence bound (UCB) algorithms arise naturally in this context, adapting arm\nelimination methods has proved more challenging. We introduce a novel\nelimination scheme that partitions arms into three categories (confirmed,\nactive, and eliminated), and incorporates explicit exploration to update these\nsets. We demonstrate the efficacy of our algorithm in two settings: the\ncombinatorial multi-armed bandit with general graph feedback, and the\ncombinatorial linear contextual bandit. In both cases, our approach achieves\nnear-optimal regret, whereas UCB-based methods can provably fail due to\ninsufficient explicit exploration. Matching lower bounds are also provided.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4e09\u7c7b\u96c6\u5408\u6d88\u9664\u7684\u6846\u67b6\uff0c\u7528\u663e\u5f0f\u63a2\u7d22\u66f4\u65b0\u786e\u8ba4\u3001\u6d3b\u8dc3\u4e0e\u88ab\u6dd8\u6c70\u4e09\u7c7b\u81c2\uff0c\u5728\u4e24\u7c7b\u7ec4\u5408\u578b\u5e26\u53cd\u9988\u95ee\u9898\u4e2d\u5b9e\u73b0\u8fd1\u4f3c\u6700\u4f18\u7684\u540e\u6094\u754c\uff0c\u5e76\u7ed9\u51fa\u5339\u914d\u7684\u4e0b\u754c\uff0c\u5c55\u793a\u4e0e\u57fa\u4e8eUCB\u7684\u65b9\u6cd5\u5728\u663e\u5f0f\u63a2\u7d22\u65b9\u9762\u7684\u4e0d\u8db3\u5bf9\u6bd4\u3002", "motivation": "\u5c06\u5355\u81c2\u6d88\u9664\u7b56\u7565\u8fc1\u79fb\u81f3\u7ec4\u5408\u5f0f\u5e26\u53cd\u9988\u7684\u60c5\u5f62\u5177\u6709\u6311\u6218\u6027\uff1b\u9700\u8981\u8bbe\u8ba1\u6709\u6548\u7684\u63a2\u7d22\u673a\u5236\u4ee5\u907f\u514d\u8fc7\u65e9\u6dd8\u6c70\u5e76\u5728\u591a\u81c2\u3001\u56fe\u53cd\u9988\u4e0e\u4e0a\u4e0b\u6587\u8bbe\u7f6e\u4e0b\u83b7\u5f97\u7406\u8bba\u4fdd\u969c\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u4e09\u7c7b\u81c2\u96c6\u5408\u7684\u6d88\u9664\u65b9\u6848\uff0c\u52a0\u5165\u663e\u5f0f\u63a2\u7d22\u4ee5\u66f4\u65b0\u786e\u8ba4\u3001\u6d3b\u8dc3\u4e0e\u6dd8\u6c70\u96c6\u5408\uff1b\u5bf9\u4e24\u7c7b\u95ee\u9898\u8fdb\u884c\u5b9e\u73b0\u4e0e\u5206\u6790\uff1a\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\uff08CMAB\uff09 with\u4e00\u822c\u56fe\u53cd\u9988\uff0c\u4ee5\u53ca\u7ec4\u5408\u7ebf\u6027\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\uff08CLCB\uff09\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u7ed9\u51fa\u8fd1\u4f3c\u6700\u4f18\u7684\u540e\u6094\u754c\u5e76\u6bd4\u8f83\u4e0eUCB\u7b49\u65b9\u6cd5\u5728\u663e\u5f0f\u63a2\u7d22\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "result": "\u5728\u4e24\u79cd\u8bbe\u5b9a\u4e2d\u5b9e\u73b0\u8fd1\u4f3c\u6700\u4f18\u7684\u540e\u6094\u754c\uff0c\u8bc1\u660eUCB\u57fa\u65b9\u6cd5\u5728\u6ca1\u6709\u8db3\u591f\u663e\u5f0f\u63a2\u7d22\u7684\u60c5\u51b5\u4e0b\u53ef\u80fd\u5931\u6548\uff1b\u7ed9\u51fa\u5339\u914d\u7684\u4e0b\u754c\uff0c\u786e\u8ba4\u6240\u63d0\u6846\u67b6\u7684\u7406\u8bba\u4f18\u8d8a\u6027\u3002", "conclusion": "\u6240\u63d0\u4e09\u7c7b\u96c6\u5408\u6d88\u9664\u6846\u67b6\u89e3\u51b3\u4e86\u7ec4\u5408\u578bBandits\u4e2d\u6d88\u9664\u7b56\u7565\u7684\u96be\u9898\uff0c\u5177\u5907\u7406\u8bba\u4fdd\u8bc1\u5e76\u5728\u4e24\u7c7b\u91cd\u8981\u8bbe\u5b9a\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2510.23847", "categories": ["cs.CR", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23847", "abs": "https://arxiv.org/abs/2510.23847", "authors": ["Joel Poncha Lemayian", "Ghyslain Gagnon", "Kaiwen Zhang", "Pascal Giard"], "title": "EthVault: A Secure and Resource-Conscious FPGA-Based Ethereum Cold Wallet", "comment": "Under review for publication", "summary": "Cryptocurrency blockchain networks safeguard digital assets using\ncryptographic keys, with wallets playing a critical role in generating,\nstoring, and managing these keys. Wallets, typically categorized as hot and\ncold, offer varying degrees of security and convenience. However, they are\ngenerally software-based applications running on microcontrollers.\nConsequently, they are vulnerable to malware and side-channel attacks, allowing\nperpetrators to extract private keys by targeting critical algorithms, such as\nECC, which processes private keys to generate public keys and authorize\ntransactions. To address these issues, this work presents EthVault, the first\nhardware architecture for an Ethereum hierarchically deterministic cold wallet,\nfeaturing hardware implementations of key algorithms for secure key generation.\nAlso, an ECC architecture resilient to side-channel and timing attacks is\nproposed. Moreover, an architecture of the child key derivation function, a\nfundamental component of cryptocurrency wallets, is proposed. The design\nminimizes resource usage, meeting market demand for small, portable\ncryptocurrency wallets. FPGA implementation results validate the feasibility of\nthe proposed approach. The ECC architecture exhibits uniform execution behavior\nacross varying inputs, while the complete design utilizes only 27%, 7%, and 6%\nof LUTs, registers, and RAM blocks, respectively, on a Xilinx Zynq UltraScale+\nFPGA.", "AI": {"tldr": "\u63d0\u51fa EthVault \u53ca\u76f8\u5173\u786c\u4ef6\u67b6\u6784\uff0c\u5b9e\u73b0\u4ee5\u592a\u574a\u5206\u5c42\u786e\u5b9a\u6027\u51b7\u94b1\u5305\u7684\u6838\u5fc3\u7b97\u6cd5\u786c\u4ef6\u5316\uff0c\u5e76\u5728 FPGA \u4e0a\u8fdb\u884c\u53ef\u884c\u6027\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u94b1\u5305\u591a\u4e3a\u8f6f\u4ef6\u5b9e\u73b0\uff0c\u5bb9\u6613\u906d\u53d7\u6076\u610f\u8f6f\u4ef6\u4e0e\u4fa7\u4fe1\u9053\u653b\u51fb\uff0c\u79c1\u94a5\u5b58\u5728\u88ab\u63d0\u53d6\u7684\u98ce\u9669\uff1b\u9700\u8981\u4f4e\u8d44\u6e90\u3001\u4fbf\u643a\u4e14\u5b89\u5168\u7684\u786c\u4ef6\u5316\u89e3\u51b3\u65b9\u6848\u6765\u4fdd\u62a4\u5bc6\u94a5\u3002", "method": "\u63d0\u51fa\u4e09\u90e8\u5206\u786c\u4ef6\u8bbe\u8ba1\uff1a1) \u94a5\u94a5\u751f\u6210\u4e0e\u5bc6\u94a5\u7ba1\u7406\u7684\u786c\u4ef6\u5b9e\u73b0\u7528\u4e8e\u5b89\u5168\u7684\u5bc6\u94a5\u751f\u6210\uff1b2) \u9488\u5bf9\u692d\u5706\u66f2\u7ebf\u5bc6\u7801\u5b66\u7684\u6297\u4fa7\u4fe1\u9053\u4e0e\u65f6\u5e8f\u653b\u51fb\u7684 ECC \u67b6\u6784\uff1b3) \u5b50\u5bc6\u94a5\u6d3e\u751f\u51fd\u6570\uff08CKD\uff09\u7684\u786c\u4ef6\u67b6\u6784\u3002\u5e76\u5728 Xilinx Zynq UltraScale+ FPGA \u4e0a\u5b9e\u73b0\u4e0e\u8bc4\u4f30\uff0c\u5f3a\u8c03\u8d44\u6e90\u9ad8\u6548\u548c\u5b89\u5168\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u5b9e\u8bbe\u8ba1\u53ef\u884c\uff1bECC \u67b6\u6784\u5b9e\u73b0\u5bf9\u8f93\u5165\u5177\u6709\u7edf\u4e00\u6267\u884c\u884c\u4e3a\uff0c\u964d\u4f4e\u4fa7\u4fe1\u9053\u98ce\u9669\uff1b\u5b8c\u6574\u8bbe\u8ba1\u5728 FPGA \u4e0a\u7684\u8d44\u6e90\u5360\u7528\u4e3a LUTs 27%\u3001\u5bc4\u5b58\u5668 7%\u3001RAM 6%\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u9996\u4e2a\u9488\u5bf9\u4ee5\u592a\u574a\u5206\u5c42\u786e\u5b9a\u6027\u51b7\u94b1\u5305\u7684\u786c\u4ef6\u5b9e\u73b0\u65b9\u6848\uff0c\u63d0\u5347\u79c1\u94a5\u5b89\u5168\u6027\u4e0e\u4fbf\u643a\u6027\uff0c\u540c\u65f6\u5b9e\u73b0\u4f4e\u8d44\u6e90\u6d88\u8017\uff0c\u8bc1\u660e\u5728\u5546\u7528 FPGA \u4e0a\u7684\u5b9e\u73b0\u53ef\u884c\u3002"}}
{"id": "2510.23626", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23626", "abs": "https://arxiv.org/abs/2510.23626", "authors": ["Shuang Geng", "Wenli Zhang", "Jiaheng Xie", "Rui Wang", "Sudha Ram"], "title": "From Detection to Discovery: A Closed-Loop Approach for Simultaneous and Continuous Medical Knowledge Expansion and Depression Detection on Social Media", "comment": "Presented at SWAIB2025 and HICSS2026", "summary": "Social media user-generated content (UGC) provides real-time, self-reported\nindicators of mental health conditions such as depression, offering a valuable\nsource for predictive analytics. While prior studies integrate medical\nknowledge to improve prediction accuracy, they overlook the opportunity to\nsimultaneously expand such knowledge through predictive processes. We develop a\nClosed-Loop Large Language Model (LLM)-Knowledge Graph framework that\nintegrates prediction and knowledge expansion in an iterative learning cycle.\nIn the knowledge-aware depression detection phase, the LLM jointly performs\ndepression detection and entity extraction, while the knowledge graph\nrepresents and weights these entities to refine prediction performance. In the\nknowledge refinement and expansion phase, new entities, relationships, and\nentity types extracted by the LLM are incorporated into the knowledge graph\nunder expert supervision, enabling continual knowledge evolution. Using\nlarge-scale UGC, the framework enhances both predictive accuracy and medical\nunderstanding. Expert evaluations confirmed the discovery of clinically\nmeaningful symptoms, comorbidities, and social triggers complementary to\nexisting literature. We conceptualize and operationalize\nprediction-through-learning and learning-through-prediction as mutually\nreinforcing processes, advancing both methodological and theoretical\nunderstanding in predictive analytics. The framework demonstrates the\nco-evolution of computational models and domain knowledge, offering a\nfoundation for adaptive, data-driven knowledge systems applicable to other\ndynamic risk monitoring contexts.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u95ed\u73af\u7684\u5927\u8bed\u8a00\u6a21\u578b-\u77e5\u8bc6\u56fe\u8c31\u6846\u67b6\uff0c\u5c06\u9884\u6d4b\u4e0e\u77e5\u8bc6\u6269\u5c55\u5728\u8fed\u4ee3\u5b66\u4e60\u4e2d\u8026\u5408\uff0c\u7528\u4e8eUGC\u9a71\u52a8\u7684\u6291\u90c1\u9884\u6d4b\u5e76\u63d0\u5347\u533b\u5b66\u7406\u89e3\u3002", "motivation": "\u5728\u793e\u4ea4\u5a92\u4f53UGC\u7684\u5b9e\u65f6\u81ea\u62a5\u544a\u6307\u6807\u4e2d\uff0c\u4f20\u7edf\u65b9\u6cd5\u591a\u4ee5\u9759\u6001\u77e5\u8bc6\u4e3a\u57fa\u7840\uff0c\u96be\u4ee5\u5728\u9884\u6d4b\u8fc7\u7a0b\u4e2d\u6301\u7eed\u6269\u5c55\u9886\u57df\u77e5\u8bc6\u3002\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u81ea\u5b66\u4e60-\u81ea\u6211\u5b8c\u5584\u7684\u95ed\u73af\u6846\u67b6\uff0c\u5f25\u5408\u9884\u6d4b\u4e0e\u77e5\u8bc6\u66f4\u65b0\u4e4b\u95f4\u7684\u65ad\u5c42\u3002", "method": "\u5206\u4e24\u9636\u6bb5\u5faa\u73af\uff1a\u7b2c\u4e00\u9636\u6bb5\u5728\u77e5\u8bc6\u611f\u77e5\u7684\u6291\u90c1\u68c0\u6d4b\u4e2d\uff0cLLM\u540c\u65f6\u6267\u884c\u6291\u90c1\u68c0\u6d4b\u4e0e\u5b9e\u4f53\u62bd\u53d6\uff0c\u77e5\u8bc6\u56fe\u8c31\u5bf9\u5b9e\u4f53\u8fdb\u884c\u8868\u5f81\u548c\u52a0\u6743\u4ee5\u63d0\u5347\u9884\u6d4b\uff1b\u7b2c\u4e8c\u9636\u6bb5\u8fdb\u884c\u77e5\u8bc6 refinement and expansion\uff0c\u4eceLLM\u63d0\u53d6\u7684\u65b0\u5b9e\u4f53\u3001\u5173\u7cfb\u548c\u5b9e\u4f53\u7c7b\u578b\u5728\u4e13\u5bb6\u76d1\u7763\u4e0b\u52a0\u5165\u77e5\u8bc6\u56fe\u8c31\uff0c\u5b9e\u73b0\u6301\u7eed\u6f14\u5316\u3002\u4f7f\u7528\u5927\u89c4\u6a21UGC\u7528\u4e8e\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u4e0e\u533b\u5b66\u7406\u89e3\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\u663e\u8457\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u589e\u5f3a\u533b\u5b66\u7406\u89e3\uff1b\u4e13\u5bb6\u8bc4\u4f30\u8bc1\u5b9e\u53d1\u73b0\u4e86\u4e0e\u73b0\u6709\u6587\u732e\u4e92\u8865\u7684\u4e34\u5e8a\u76f8\u5173\u75c7\u72b6\u3001\u5171\u75c5\u548c\u793e\u4f1a\u89e6\u53d1\u56e0\u7d20\u3002\u63d0\u51fa\u201c\u901a\u8fc7\u9884\u6d4b\u5b66\u4e60\u201d\u548c\u201c\u4ee5\u5b66\u4fc3\u9884\u6d4b\u201d\u7684\u4e92\u8865\u5173\u7cfb\uff0c\u63a8\u52a8\u9884\u6d4b\u5206\u6790\u7684\u65b9\u6cd5\u8bba\u4e0e\u7406\u8bba\u7406\u89e3\u3002", "conclusion": "\u5c55\u793a\u8ba1\u7b97\u6a21\u578b\u4e0e\u9886\u57df\u77e5\u8bc6\u7684\u5171\u540c\u8fdb\u5316\uff0c\u4e3a\u53ef\u81ea\u9002\u5e94\u3001\u6570\u636e\u9a71\u52a8\u7684\u77e5\u8bc6\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840\uff0c\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u52a8\u6001\u98ce\u9669\u76d1\u6d4b\u573a\u666f\u3002"}}
{"id": "2510.24017", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24017", "abs": "https://arxiv.org/abs/2510.24017", "authors": ["Brian Skoglind", "Travis Roberts", "Sourabh Karmakar", "Cameron Turner", "Laine Mears"], "title": "Localized Acoustic-Event Measurement Probe: Connector Confirmation Utilizing Acoustic Signatures", "comment": null, "summary": "Modern consumer products are full of interconnected electrical and electronic\nmodules to fulfill direct and indirect needs. In an automated assembly line\nstill, most of these interconnections are required to be done manually due to\nthe large variety of connector types, connector positions, and the soft,\nflexible nature of their structures. The manual connection points are the\nsource of partial or completely loose connections. Sometimes connections are\nmissed due to the application of unequal mating forces and natural human\nfatigue. Subsequently, these defects can lead to unexpected downtime and\nexpensive rework. For successful connection detection, past approaches such as\nvision verification, Augmented Reality, or circuit parameter-based measurements\nhave shown limited ability to detect the correct connection state. Though most\nconnections emit a specific noise for successful mating, the acoustic-based\nverification system for electrical connection confirmation has not been\nextensively researched. The main discouraging reason for such research is the\ntypically low signal-to-noise ratio (SNR) between the sound of a pair of\nelectrical connector mating and the diverse soundscape of the plant. In this\nstudy, the authors investigated increasing the SNR between the electrical\nconnector mating sound and the plant soundscape to improve connection success\ndetection by employing a physical system for background noise mitigation and\nthe successful met noise signature amplification algorithm. The solution is\nover 75% effective at detecting and classifying connection state. The solution\nhas been constructed without any modification to the existing manual\ninterconnection process.", "AI": {"tldr": "\u57fa\u4e8e\u58f0\u5b66\u4fe1\u53f7\u7684\u7535\u8fde\u63a5\u63a5\u5408\u68c0\u6d4b\uff1a\u901a\u8fc7\u566a\u58f0\u6291\u5236\u4e0e\u4fe1\u53f7\u653e\u5927\u63d0\u5347SNR\uff0c\u5728\u73b0\u6709\u4eba\u5de5\u8fde\u63a5\u6d41\u7a0b\u4e0a\u5b9e\u73b0\u226575%\u68c0\u6d4b/\u5206\u7c7b\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u624b\u52a8\u8fde\u63a5\u4e2d\u7531\u4e8e\u8fde\u63a5\u4ef6\u591a\u6837\u3001\u4f4d\u7f6e\u53d8\u5316\u4e0e\u5de5\u4eba\u75b2\u52b3\u7b49\u539f\u56e0\u5bfc\u81f4\u7684\u677e\u52a8\u6216\u9519\u8fde\uff1b\u73b0\u6709\u7684\u89c6\u89c9/\u589e\u5f3a\u73b0\u5b9e\uff08AR\uff09\u6216\u7535\u8def\u53c2\u6570\u6d4b\u91cf\u65b9\u6cd5\u5728\u6b63\u786e\u8fde\u63a5\u72b6\u6001\u68c0\u6d4b\u65b9\u9762\u80fd\u529b\u6709\u9650\uff1b\u63a5\u5408\u58f0\u4fe1\u53f7\u7684\u4fe1\u566a\u6bd4\u901a\u5e38\u8f83\u4f4e\u4e14\u6613\u88ab\u5de5\u5382\u73af\u5883\u566a\u58f0\u6df9\u6ca1\u3002", "method": "\u6784\u5efa\u80cc\u666f\u566a\u58f0\u6291\u5236\u7684\u7269\u7406\u7cfb\u7edf\u5e76\u63d0\u51fa\u201c\u6210\u529f\u566a\u58f0\u7279\u5f81\u653e\u5927\u7b97\u6cd5\u201d\uff0c\u4ee5\u63d0\u5347\u7535\u8fde\u63a5\u63a5\u89e6\u914d\u5408\u58f0\u4e0e\u73af\u5883\u58f0\u666f\u4e4b\u95f4\u7684SNR\uff0c\u4ece\u800c\u63d0\u9ad8\u8fde\u63a5\u72b6\u6001\u68c0\u6d4b\u4e0e\u5224\u65ad\u7684\u9c81\u68d2\u6027\u3002", "result": "\u7cfb\u7edf\u5728\u68c0\u6d4b\u4e0e\u5206\u7c7b\u8fde\u63a5\u72b6\u6001\u65b9\u9762\u7684\u6548\u679c\u8d85\u8fc775%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u4fee\u6539\u73b0\u6709\u7684\u624b\u52a8\u4e92\u8fde\u6d41\u7a0b\u5373\u53ef\u5b9e\u73b0\u58f0\u5b66\u8fde\u63a5\u72b6\u6001\u68c0\u6d4b\uff0c\u5177\u5907\u5728\u81ea\u52a8\u5316\u751f\u4ea7\u7ebf\u4e2d\u843d\u5730\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.24088", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24088", "abs": "https://arxiv.org/abs/2510.24088", "authors": ["Moongyu Jeon", "Sangwoo Shin", "Dongjae Jeon", "Albert No"], "title": "Information-Theoretic Discrete Diffusion", "comment": "Accepted at NeurIPS 2025", "summary": "We present an information-theoretic framework for discrete diffusion models\nthat yields principled estimators of log-likelihood using score-matching\nlosses. Inspired by the I-MMSE identity for the Gaussian setup, we derive\nanalogous results for the discrete setting. Specifically, we introduce the\nInformation-Minimum Denoising Score Entropy (I-MDSE) relation, which links\nmutual information between data and its diffused version to the minimum\ndenoising score entropy (DSE) loss. We extend this theory to masked diffusion\nand establish the Information-Minimum Denoising Cross-Entropy (I-MDCE)\nrelation, connecting cross-entropy losses to mutual information in discrete\nmasked processes. These results provide a time-integral decomposition of the\nlog-likelihood of the data in terms of optimal score-based losses, showing that\ncommonly used losses such as DSE and DCE are not merely variational bounds but\ntight and principled estimators of log-likelihood. The I-MDCE decomposition\nfurther enables practical extensions, including time-free formula, conditional\nlikelihood estimation in prompt-response tasks, and coupled Monte Carlo\nestimation of likelihood ratios. Experiments on synthetic and real-world data\nconfirm the accuracy, variance stability, and utility of our estimators. The\ncode is publicly available at https://github.com/Dongjae0324/infodis.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u53bb\u566a\u5206\u6570\u71b5\u548c\u4ea4\u53c9\u71b5\u7684 I-MDSE / I-MDCE \u5173\u7cfb\uff0c\u5c06\u5bf9\u6570\u4f3c\u7136\u5206\u89e3\u4e3a\u4f20\u7edf\u5206\u6570\u635f\u5931\u7684\u65f6\u95f4\u79ef\u5206\uff0c\u8bc1\u660e DSE \u4e0e DCE \u662f\u5bf9\u6570\u4f3c\u7136\u7684\u7d27\u786e\u5b9a\u4f30\u8ba1\u5668\uff0c\u5e76\u7ed9\u51fa\u53ef\u6269\u5c55\u7684\u5e94\u7528\u5982\u65f6\u95f4\u65e0\u516c\u5f0f\u3001\u6761\u4ef6\u4f3c\u7136\u4f30\u8ba1\u4e0e\u9a6c\u53ef\u592b\u8499\u7279\u5361\u6d1b\u6bd4\u7387\u4f30\u8ba1\uff1b\u5e76\u5728\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u4e0a\u9a8c\u8bc1\u7a33\u5b9a\u6027\u4e0e\u51c6\u786e\u6027\uff0c\u4ee3\u7801\u516c\u5f00\u3002", "motivation": "\u5728\u79bb\u6563\u6269\u6563\u6a21\u578b\u4e2d\uff0c\u9700\u8981\u4e00\u4e2a\u4fe1\u606f\u8bba\u57fa\u7840\u6765\u5bf9\u5bf9\u6570\u4f3c\u7136\u8fdb\u884c principled \u7684\u4f30\u8ba1\u4e0e\u5206\u89e3\uff0c\u5f25\u5408\u9ad8\u65af\u60c5\u5f62\u7684 I-MMSE \u7406\u8bba\u4e0e\u79bb\u6563\u60c5\u5f62\u7684\u5e94\u7528\u3002\u901a\u8fc7 I-MDSE/ I-MDCE\uff0c\u5c06\u6570\u636e\u53ca\u5176\u6269\u6563\u7248\u672c\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u4e0e\u6700\u4f18\u53bb\u566a\u5206\u6570\u71b5/\u4ea4\u53c9\u71b5\u635f\u5931\u8054\u7cfb\u8d77\u6765\uff0c\u63d0\u4f9b\u7d27\u800c\u6709\u7528\u7684\u5bf9\u6570\u4f3c\u7136\u4f30\u8ba1\u6846\u67b6\u3002", "method": "\u5efa\u7acb I-MDSE \u5173\u7cfb\uff0c\u5c06\u6570\u636e\u4e0e\u6269\u6563\u7248\u672c\u95f4\u7684\u4e92\u4fe1\u606f\u4e0e\u6700\u5c0f\u53bb\u566a\u5206\u6570\u71b5\u635f\u5931\u8054\u7cfb\uff1b\u6269\u5c55\u5230\u63a9\u7801\u6269\u6563\uff0c\u5efa\u7acb I-MDCE \u5173\u7cfb\uff0c\u5c06\u4ea4\u53c9\u71b5\u635f\u5931\u4e0e\u79bb\u6563\u63a9\u7801\u8fc7\u7a0b\u7684\u4e92\u4fe1\u606f\u5173\u8054\uff1b\u7ed9\u51fa\u5bf9\u6570\u4f3c\u7136\u7684\u65f6\u95f4\u79ef\u5206\u5206\u89e3\uff0c\u8868\u660e DSE \u4e0e DCE \u4e0d\u662f\u53d8\u5206\u4e0b\u754c\uff0c\u800c\u662f\u5bf9\u6570\u4f3c\u7136\u7684\u7d27\u81f4\u4f30\u8ba1\u5668\uff1b\u63d0\u51fa\u65f6\u95f4\u65e0\u516c\u5f0f\u3001\u6761\u4ef6\u4f3c\u7136\u4f30\u8ba1\u4e0e\u8026\u5408\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u7b49\u53ef\u64cd\u4f5c\u6269\u5c55\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u4e92\u4fe1\u606f\u7b49\u4e8e\u4ee5\u6700\u4f18\u5206\u6570\u635f\u5931\u4e3a\u88ab\u79ef\u9879\u7684\u65f6\u95f4\u79ef\u5206\uff0c\u540c\u65f6\u8bc1\u660e DSE \u4e0e DCE \u662f\u5bf9\u6570\u4f3c\u7136\u7684\u7d27\u786e\u5b9a\u4f30\u8ba1\u5668\uff1b\u63d0\u51fa\u4e86\u5b9e\u7528\u6269\u5c55\u4e0e\u53ef\u91cd\u590d\u5b9e\u73b0\uff1b\u5728\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3001\u65b9\u5dee\u7a33\u5b9a\u6027\u548c\u5b9e\u7528\u6027\uff1b\u4ee3\u7801\u5df2\u516c\u5f00\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u5bf9\u6570\u4f3c\u7136\u4f30\u8ba1\u63d0\u4f9b\u4e00\u4e2a principled \u7684\u4fe1\u606f\u8bba\u57fa\u7840\uff0c\u7edf\u4e00\u5e76\u5de9\u56fa\u4e86 DSE/DCE \u7b49\u635f\u5931\u7684\u610f\u4e49\uff0c\u4fc3\u8fdb\u5728\u6761\u4ef6\u4f3c\u7136\u4f30\u8ba1\u548c\u6982\u7387\u6bd4\u4f30\u8ba1\u7b49\u5b9e\u9645\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u901a\u8fc7\u516c\u5f00\u4ee3\u7801\u4fbf\u4e8e\u590d\u73b0\u4e0e\u6269\u5c55\u3002"}}
{"id": "2510.23891", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23891", "abs": "https://arxiv.org/abs/2510.23891", "authors": ["Jiaqi Xue", "Yifei Zhao", "Mansour Al Ghanim", "Shangqian Gao", "Ruimin Sun", "Qian Lou", "Mengxin Zheng"], "title": "PRO: Enabling Precise and Robust Text Watermark for Open-Source LLMs", "comment": null, "summary": "Text watermarking for large language models (LLMs) enables model owners to\nverify text origin and protect intellectual property. While watermarking\nmethods for closed-source LLMs are relatively mature, extending them to\nopen-source models remains challenging, as developers cannot control the\ndecoding process. Consequently, owners of open-source LLMs lack practical means\nto verify whether text was generated by their models. A core difficulty lies in\nembedding watermarks directly into model weights without hurting detectability.\nA promising idea is to distill watermarks from a closed-source model into an\nopen one, but this suffers from (i) poor detectability due to mismatch between\nlearned and predefined patterns, and (ii) fragility to downstream modifications\nsuch as fine-tuning or model merging. To overcome these limitations, we propose\nPRO, a Precise and Robust text watermarking method for open-source LLMs. PRO\njointly trains a watermark policy model with the LLM, producing patterns that\nare easier for the model to learn and more consistent with detection criteria.\nA regularization term further simulates downstream perturbations and penalizes\ndegradation in watermark detectability, ensuring robustness under model edits.\nExperiments on open-source LLMs (e.g., LLaMA-3.2, LLaMA-3, Phi-2) show that PRO\nsubstantially improves both watermark detectability and resilience to model\nmodifications.", "AI": {"tldr": "PRO\u662f\u4e00\u4e2a\u7528\u4e8e\u5f00\u6e90LLM\u7684\u6c34\u5370\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e0e\u6a21\u578b\u8054\u5408\u8bad\u7ec3\u7684\u6c34\u5370\u7b56\u7565\u6765\u5b9e\u73b0\u66f4\u53ef\u68c0\u6d4b\u4e14\u6297\u5e72\u6270\u7684\u6c34\u5370\uff0c\u9002\u7528\u4e8e\u5982LLaMA-3.x\u3001Phi-2\u7b49\u6a21\u578b\u3002", "motivation": "\u5728\u6587\u672c\u6c34\u5370\u9886\u57df\uff0c\u5c01\u95ed\u6e90\u6a21\u578b\u7684\u6c34\u5370\u6280\u672f\u5df2\u8f83\u6210\u719f\uff0c\u4f46\u5c06\u5176\u5e94\u7528\u4e8e\u5f00\u6e90\u6a21\u578b\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u65e0\u6cd5\u63a7\u5236\u89e3\u7801\u8fc7\u7a0b\u5bfc\u81f4\u6c34\u5370\u5d4c\u5165\u56f0\u96be\uff0c\u4ee5\u53ca\u76f4\u63a5\u84b8\u998f\u95ed\u6e90\u6c34\u5370\u5728\u53ef\u68c0\u6d4b\u6027\u548c\u5bf9\u4e0b\u6e38\u4fee\u6539\u7684\u9c81\u68d2\u6027\u65b9\u9762\u5747\u8868\u73b0\u4e0d\u4f73\u3002\u9700\u8981\u4e00\u79cd\u80fd\u76f4\u63a5\u5bf9\u5f00\u6e90\u6a21\u578b\u505a\u51fa\u9c81\u68d2\u4e14\u6613\u68c0\u6d4b\u7684\u6c34\u5370\u65b9\u6848\u3002", "method": "PRO\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u4e00\u4e2a\u6c34\u5370\u7b56\u7565\u6a21\u578b\u4e0eLLM\uff0c\u4f7f\u751f\u6210\u7684\u6c34\u5370\u6a21\u5f0f\u66f4\u6613\u4e8e\u5b66\u4e60\u5e76\u4e0e\u68c0\u6d4b\u51c6\u5219\u66f4\u4e00\u81f4\u3002\u5f15\u5165\u6b63\u5219\u5316\u9879\u4ee5\u6a21\u62df\u4e0b\u6e38\u6270\u52a8\uff0c\u60e9\u7f5a\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u7684\u4e0b\u964d\uff0c\u4ece\u800c\u63d0\u5347\u5728\u6a21\u578b\u7f16\u8f91\u7b49\u4fee\u6539\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728\u5f00\u6e90LLM\uff08\u5982LLaMA-3.2\u3001LLaMA-3\u3001Phi-2\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPRO\u663e\u8457\u63d0\u5347\u6c34\u5370\u7684\u53ef\u68c0\u6d4b\u6027\uff0c\u5e76\u63d0\u9ad8\u5bf9\u6a21\u578b\u4fee\u6539\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "PRO\u4e3a\u5f00\u6e90LLM\u7684\u6587\u672c\u6c34\u5370\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cbe\u786e\u4e14\u9c81\u68d2\u7684\u89e3\u51b3\u601d\u8def\uff0c\u80fd\u591f\u5728\u4e0d\u727a\u7272\u53ef\u68c0\u6d4b\u6027\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u5bf9\u540e\u7eed\u4fee\u6539\u7684\u8010\u53d7\u6027\uff0c\u4fc3\u8fdb\u5f00\u6e90\u6a21\u578b\u5728\u7248\u6743\u4fdd\u62a4\u65b9\u9762\u7684\u5e94\u7528\u3002"}}
{"id": "2510.23877", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.23877", "abs": "https://arxiv.org/abs/2510.23877", "authors": ["Zhentong Shao", "Nanpeng Yu"], "title": "Carbon-Aware Optimal Power Flow with Data-Driven Carbon Emission Tracing", "comment": null, "summary": "Quantifying locational carbon emissions in power grids is crucial for\nimplementing effective carbon reduction strategies for customers relying on\nelectricity. This paper presents a carbon-aware optimal power flow (OPF)\nframework that incorporates data-driven carbon tracing, enabling rapid\nestimation of nodal carbon emissions from electric loads. By developing\ngenerator-to-load carbon emission distribution factors through data-driven\ntechnique, the analytical formulas for both average and marginal carbon\nemissions can be derived and integrated seamlessly into DC OPF models as linear\nconstraints. The proposed carbon-aware OPF model enables market operators to\noptimize energy dispatch while reducing greenhouse gas emissions. Simulations\non IEEE test systems confirm the accuracy and computational efficiency of the\nproposed approach, highlighting its applicability for real-time carbon-aware\nsystem operations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u78b3\u611f\u77e5\u7684\u6700\u4f18\u6f6e\u6d41\uff08OPF\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u78b3\u8ffd\u8e2a\u63a8\u5bfc\u53d1\u7535\u673a\u5230\u8d1f\u8377\u7684\u78b3\u6392\u653e\u5206\u5e03\u56e0\u5b50\uff0c\u5c06\u5e73\u5747\u4e0e\u8fb9\u9645\u78b3\u6392\u653e\u4ee5\u7ebf\u6027\u5f62\u5f0f\u5d4c\u5165\u76f4\u6d41OPF\uff0c\u652f\u6301\u5b9e\u65f6\u78b3\u4f18\u5316\u8c03\u5ea6\u3002", "motivation": "\u5728\u7535\u529b\u7cfb\u7edf\u8c03\u5ea6\u4e2d\u9700\u8981\u91cf\u5316\u8282\u70b9\u7ea7\u78b3\u6392\u653e\u4ee5\u652f\u6491\u78b3\u51cf\u6392\u7b56\u7565\u3001\u78b3\u4ea4\u6613\u548c\u5e02\u573a\u4f18\u5316\uff0c\u63d0\u5347\u7cfb\u7edf\u8fd0\u884c\u7684\u78b3\u6548\u7387\u4e0e\u7ecf\u6d4e\u6027\u3002", "method": "\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u78b3\u8ffd\u8e2a\u751f\u6210\u53d1\u7535\u673a\u2013\u8d1f\u8377\u78b3\u6392\u653e\u5206\u5e03\u56e0\u5b50\uff0c\u63a8\u5bfc\u51fa\u5e73\u5747\u4e0e\u8fb9\u9645\u78b3\u6392\u653e\u7684\u89e3\u6790\u516c\u5f0f\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u7ebf\u6027\u7ea6\u675f\u6574\u5408\u8fdbDC OPF\u6a21\u578b\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u8282\u70b9\u78b3\u6392\u653e\u7684\u5feb\u901f\u4f30\u7b97\u4e0e\u78b3\u7ea6\u675f\u7684\u7ebf\u6027\u5316\u5904\u7406\u3002", "result": "\u5728IEEE\u6d4b\u8bd5\u7cfb\u7edf\u4e0a\u8fdb\u884c\u4eff\u771f\uff0c\u9a8c\u8bc1\u4e86\u78b3\u6392\u653e\u4f30\u7b97\u7684\u51c6\u786e\u6027\u4e0e\u7b97\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u8bc1\u660e\u8be5\u78b3\u611f\u77e5OPF\u9002\u7528\u4e8e\u5b9e\u65f6\u7cfb\u7edf\u64cd\u4f5c\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u4f7f\u5e02\u573a\u8fd0\u8425\u8005\u5728\u4e0d\u663e\u8457\u727a\u7272\u7535\u529b\u7cfb\u7edf\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u78b3\u6392\u653e\u7684\u4f18\u5316\u8c03\u5ea6\uff0c\u5bf9\u5b9e\u73b0\u78b3\u51cf\u6392\u76ee\u6807\u5177\u6709\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.23629", "categories": ["cs.LG", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.23629", "abs": "https://arxiv.org/abs/2510.23629", "authors": ["Nuo Chen", "Zehua Li", "Keqin Bao", "Junyang Lin", "Dayiheng Liu"], "title": "Chain of Execution Supervision Promotes General Reasoning in Large Language Models", "comment": null, "summary": "Building robust and general reasoning ability is a central goal in the\ndevelopment of large language models (LLMs). Recent efforts increasingly turn\nto code as a rich training source, given its inherent logical structure and\ndiverse reasoning paradigms such as divide-and-conquer, topological ordering,\nand enumeration. However, reasoning in code is often expressed implicitly and\nentangled with syntactic or implementation noise, making direct training on raw\ncode suboptimal.To address this, we introduce TracePile, a large-scale corpus\nof 2.6 million samples that transforms code execution into explicit,\nstep-by-step chain-of-thought-style rationales, which we call Chain of\nExecution (CoE). The corpus spans domains including mathematics, classical\nalgorithms and algorithmic competition, and is enriched with variable-tracing\nquestions and code rewritings to enhance logical granularity and code\ndiversity. We evaluate TracePile using three training setups:\ncontinue-pretraining, instruction tuning after pretraining, and two-stage\nfinetuning. Experiments across four base models (LLaMA 3, LLaMA 3.1, Qwen-2.5,\nand Qwen-2.5 Coder) and 20 benchmarks covering math, code, logic, and\nalgorithms demonstrate consistent improvements. Notably, TracePile boosts\nLLaMA3.1-8B by 7.1\\% on average across nine math datasets and delivers clear\ngains on LiveCodeBench, CRUX, and MMLU under two-stage fine-tuning.", "AI": {"tldr": "TracePile introduces a large 2.6M-sample corpus that converts code execution into explicit, step-by-step chain-of-execution rationales (CoE) to improve robust reasoning in LLMs, showing consistent gains across math, code, logic, and algorithm domains with two-stage finetuning.", "motivation": "Code contains rich logical structure but reasoning signals are often implicit and polluted by noise; providing explicit CoE can guide models to generalize better across domains and tasks.", "method": "Construct a large-scale dataset (TracePile) with 2.6 million samples that turn code execution into CoE-style rationales. enrich with variable-tracing questions and code rewritings across domains (mathematics, classical algorithms, competitive programming). Evaluate via three training setups (continue-pretraining, instruction tuning after pretraining, two-stage finetuning) on four base models (LLaMA 3, LLaMA 3.1, Qwen-2.5, Qwen-2.5 Coder) over 20 benchmarks spanning math, code, logic, and algorithms.", "result": "Across four base models and 20 benchmarks, TracePile produces consistent improvements. Notably, LLaMA3.1-8B achieves an average +7.1% on nine math datasets; two-stage fine-tuning yields clear gains on LiveCodeBench, CRUX, and MMLU.", "conclusion": "Explicit CoE grounded in code execution can enhance general reasoning in LLMs, with two-stage finetuning amplifying benefits and wide-domain applicability demonstrated across math, code, and algorithmic tasks."}}
{"id": "2510.24058", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24058", "abs": "https://arxiv.org/abs/2510.24058", "authors": ["Zihan Zhao", "Masood Mortazavi", "Ning Yan"], "title": "PULSE: Privileged Knowledge Transfer from Electrodermal Activity to Low-Cost Sensors for Stress Monitoring", "comment": "Accepted as a finders paper at ML4H 2025", "summary": "Electrodermal activity (EDA), the primary signal for stress detection,\nrequires costly hardware often unavailable in real-world wearables. In this\npaper, we propose PULSE, a framework that utilizes EDA exclusively during\nself-supervised pretraining, while enabling inference without EDA but with more\nreadily available modalities such as ECG, BVP, ACC, and TEMP. Our approach\nseparates encoder outputs into shared and private embeddings. We align shared\nembeddings across modalities and fuse them into a modality-invariant\nrepresentation. The private embeddings carry modality-specific information to\nsupport the reconstruction objective. Pretraining is followed by knowledge\ntransfer where a frozen EDA teacher transfers sympathetic-arousal\nrepresentations into student encoders. On WESAD, our method achieves strong\nstress-detection performance, showing that representations of privileged EDA\ncan be transferred to low-cost sensors to improve accuracy while reducing\nhardware cost.", "AI": {"tldr": "PULSE\u5728\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u9636\u6bb5\u53ea\u4f7f\u7528EDA\uff0c\u5e76\u5728\u63a8\u65ad\u9636\u6bb5\u65e0\u9700EDA\uff0c\u5229\u7528ECG\u3001BVP\u3001ACC\u3001TEMP\u7b49\u6a21\u6001\u5b9e\u73b0\u538b\u529b\u68c0\u6d4b\uff1b\u901a\u8fc7\u5171\u4eab/\u79c1\u6709\u5d4c\u5165\u548c\u6559\u5e08\u84b8\u998f\uff0c\u5c06EDA\u7684\u8868\u793a\u4f20\u9012\u7ed9\u4f4e\u6210\u672c\u4f20\u611f\u5668\uff0c\u5728WESAD\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u826f\u597d\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u786c\u4ef6\u6210\u672c\u3002", "motivation": "\u89e3\u51b3\u9ad8\u6210\u672cEDA\u786c\u4ef6\u5728\u73b0\u5b9e\u7a7f\u6234\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\uff1b\u901a\u8fc7\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u4f7f\u7528\u591a\u6a21\u6001\u6570\u636e\u5e76\u4fdd\u7559EDA\u4f5c\u4e3a\u7279\u6743\u77e5\u8bc6\uff0c\u5b9e\u73b0\u8de8\u6a21\u6001\u5bf9\u9f50\u548c\u6a21\u6001\u4e0d\u53d8\u8868\u793a\uff0c\u5728\u84b8\u998f\u9636\u6bb5\u5c06EDA\u6559\u5e08\u7684\u7b26\u53f7\u6027\u5524\u9192\u8868\u793a\u8fc1\u79fb\u5230\u5b66\u751f\u7f16\u7801\u5668\u3002", "method": "\u5c06\u7f16\u7801\u5668\u8f93\u51fa\u5206\u4e3a\u5171\u4eab\u548c\u79c1\u6709\u5d4c\u5165\uff1b\u8de8\u6a21\u6001\u5bf9\u9f50\u5171\u4eab\u5d4c\u5165\u5e76\u878d\u5408\u6210\u6a21\u6001\u4e0d\u53d8\u8868\u793a\uff0c\u79c1\u6709\u5d4c\u5165\u627f\u8f7d\u6a21\u6001\u7279\u5b9a\u4fe1\u606f\u4ee5\u652f\u6491\u91cd\u6784\u76ee\u6807\u3002\u9884\u8bad\u7ec3\u540e\u8fdb\u884c\u77e5\u8bc6\u8fc1\u79fb\uff0c\u7531\u51bb\u7ed3\u7684EDA\u6559\u5e08\u5c06\u4ea4\u611f\u5524\u9192\u8868\u793a\u4f20\u9012\u7ed9\u5b66\u751f\u7f16\u7801\u5668\u3002", "result": "\u5728WESAD\u6570\u636e\u96c6\u4e0a\uff0c\u65b9\u6cd5\u5b9e\u73b0\u5f3a\u7684\u538b\u529b\u68c0\u6d4b\u6027\u80fd\uff0c\u8868\u660e\u7279\u6743EDA\u7684\u8868\u793a\u80fd\u591f\u4f20\u9012\u7ed9\u4f4e\u6210\u672c\u4f20\u611f\u5668\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u786c\u4ef6\u6210\u672c\u3002", "conclusion": "\u7279\u6743EDA\u8868\u793a\u53ef\u4ee5\u5728\u65e0\u9700\u989d\u5916\u6210\u672c\u7684\u524d\u63d0\u4e0b\u901a\u8fc7\u84b8\u998f\u4f20\u9012\u7ed9\u5e38\u89c4\u4f20\u611f\u5668\uff0c\u4ece\u800c\u63d0\u5347\u6548\u80fd\u5e76\u964d\u4f4e\u7cfb\u7edf\u6210\u672c\u3002"}}
{"id": "2510.23895", "categories": ["eess.SY", "cs.OS", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.23895", "abs": "https://arxiv.org/abs/2510.23895", "authors": ["Hoora Sobhani", "Hyoseung Kim"], "title": "Modeling and Scheduling of Fusion Patterns in Autonomous Driving Systems (Extended Version)", "comment": null, "summary": "In Autonomous Driving Systems (ADS), Directed Acyclic Graphs (DAGs) are\nwidely used to model complex data dependencies and inter-task communication.\nHowever, existing DAG scheduling approaches oversimplify data fusion tasks by\nassuming fixed triggering mechanisms, failing to capture the diverse fusion\npatterns found in real-world ADS software stacks. In this paper, we propose a\nsystematic framework for analyzing various fusion patterns and their\nperformance implications in ADS. Our framework models three distinct fusion\ntask types: timer-triggered, wait-for-all, and immediate fusion, which\ncomprehensively represent real-world fusion behaviors. Our Integer Linear\nProgramming (ILP)-based approach enables an optimization of multiple real-time\nperformance metrics, including reaction time, time disparity, age of\ninformation, and response time, while generating deterministic offline\nschedules directly applicable to real platforms. Evaluation using real-world\nADS case studies, Raspberry Pi implementation, and randomly generated DAGs\ndemonstrates that our framework handles diverse fusion patterns beyond the\nscope of existing work, and achieves substantial performance improvements in\ncomparable scenarios.", "AI": {"tldr": "\u9762\u5411\u81ea\u4e3b\u9a7e\u9a76\u7cfb\u7edf\u7684DAG\u878d\u5408\u6a21\u5f0f\u5206\u6790\u4e0eILP\u4f18\u5316\u6846\u67b6\u3002", "motivation": "\u73b0\u6709DAG\u8c03\u5ea6\u5bf9\u6570\u636e\u878d\u5408\u89e6\u53d1\u673a\u5236\u8fc7\u4e8e\u7b80\u5316\uff0c\u65e0\u6cd5\u8986\u76d6\u5b9e\u9645ADS\u4e2d\u7684\u591a\u6837\u5316\u878d\u5408\u6a21\u5f0f\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u5efa\u6a21\u591a\u79cd fusion \u6a21\u5f0f\u5e76\u5728\u79bb\u7ebf\u751f\u6210\u786e\u5b9a\u6027\u8c03\u5ea6\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e00\u4e2aILP\u57fa\u7840\u7684\u65b9\u6cd5\uff0c\u533a\u5206\u4e09\u79cd\u878d\u5408\u7c7b\u578b\uff1a\u5b9a\u65f6\u89e6\u53d1(timer-triggered)\u3001\u7b49\u5f85\u5168\u90e8(wait-for-all)\u3001\u5373\u65f6\u878d\u5408(immediate fusion)\uff0c\u4ee5\u4f18\u5316\u53cd\u5e94\u65f6\u95f4\u3001\u65f6\u5dee\u3001\u4fe1\u606f\u65b0\u9c9c\u5ea6\u548c\u54cd\u5e94\u65f6\u95f4\u7b49\u591a\u91cd\u5b9e\u65f6\u6027\u80fd\uff0c\u5e76\u76f4\u63a5\u751f\u6210\u9002\u7528\u4e8e\u771f\u5b9e\u5e73\u53f0\u7684\u79bb\u7ebf\u786e\u5b9a\u6027\u8c03\u5ea6\u3002", "result": "\u5728\u771f\u5b9eADS\u6848\u4f8b\u3001\u6811\u8393\u6d3e\u5b9e\u73b0\u4ee5\u53ca\u968f\u673aDAG\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u8986\u76d6\u6bd4\u73b0\u6709\u5de5\u4f5c\u66f4\u4e30\u5bcc\u7684\u878d\u5408\u6a21\u5f0f\uff0c\u5e76\u5728\u53ef\u6bd4\u60c5\u666f\u4e0b\u5b9e\u73b0\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u63d0\u4f9b\u4e00\u4e2a\u5168\u9762\u7684\u5206\u6790\u4e0e\u4f18\u5316\u6846\u67b6\u6765\u5904\u7406ADS DAG\u4e2d\u7684\u878d\u5408\u6a21\u5f0f\uff0c\u6539\u8fdb\u79bb\u7ebf\u8c03\u5ea6\u7684\u786e\u5b9a\u6027\u4e0e\u73b0\u5b9e\u5e73\u53f0\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.23630", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23630", "abs": "https://arxiv.org/abs/2510.23630", "authors": ["Ninghui Feng", "Yiyan Qi"], "title": "NUM2EVENT: Interpretable Event Reasoning from Numerical time-series", "comment": null, "summary": "Large language models (LLMs) have recently demonstrated impressive multimodal\nreasoning capabilities, yet their understanding of purely numerical time-series\nsignals remains limited. Existing approaches mainly focus on forecasting or\ntrend description, without uncovering the latent events that drive numerical\nchanges or explaining the reasoning process behind them. In this work, we\nintroduce the task of number-to-event reasoning and decoding, which aims to\ninfer interpretable structured events from numerical inputs, even when current\ntext is unavailable. To address the data scarcity and semantic alignment\nchallenges, we propose a reasoning-aware framework that integrates an\nagent-guided event extractor (AGE), a marked multivariate Hawkes-based\nsynthetic generator (EveDTS), and a two-stage fine-tuning pipeline combining a\ntime-series encoder with a structured decoder. Our model explicitly reasons\nover numerical changes, generates intermediate explanations, and outputs\nstructured event hypotheses. Experiments on multi-domain datasets show that our\nmethod substantially outperforms strong LLM baselines in event-level precision\nand recall. These results suggest a new direction for bridging quantitative\nreasoning and semantic understanding, enabling LLMs to explain and predict\nevents directly from numerical dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5c06\u6570\u503c\u65f6\u95f4\u5e8f\u5217\u6620\u5c04\u4e3a\u53ef\u89e3\u91ca\u4e8b\u4ef6\u7684\u63a8\u7406\u6846\u67b6\uff0c\u7ed3\u5408AGE\u3001EveDTS\u548c\u4e24\u9636\u6bb5\u5fae\u8c03\uff0c\u8f93\u51fa\u7ed3\u6784\u5316\u4e8b\u4ef6\u5047\u8bbe\u4e0e\u4e2d\u95f4\u89e3\u91ca\uff0c\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u51c6\u7684\u4e8b\u4ef6\u7ea7\u7cbe\u5ea6\u4e0e\u53ec\u56de\u3002", "motivation": "\u89e3\u51b3LLMs\u5728\u7eaf\u6570\u503c\u65f6\u95f4\u5e8f\u5217\u7406\u89e3\u4e0a\u7684\u5c40\u9650\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u805a\u7126\u4e8e\u9884\u6d4b\u548c\u8d8b\u52bf\u63cf\u8ff0\uff0c\u672a\u80fd\u63ed\u793a\u9a71\u52a8\u6570\u503c\u53d8\u5316\u7684\u6f5c\u5728\u4e8b\u4ef6\u6216\u7ed9\u51fa\u63a8\u7406\u8fc7\u7a0b\u3002\u6570\u636e\u7a00\u7f3a\u4e0e\u8bed\u4e49\u5bf9\u9f50\u4e5f\u662f\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51faager\u884c\u4e3a\u9a71\u52a8\u7684\u4e8b\u4ef6\u63d0\u53d6\u5668\uff08AGE\uff09\u3001\u5e26\u6807\u8bb0\u7684\u591a\u53d8\u91cf Hawkes \u5408\u6210\u751f\u6210\u5668\uff08EveDTS\uff09\uff0c\u4ee5\u53ca\u4e24\u9636\u6bb5\u5fae\u8c03\u6d41\u7a0b\uff0c\u5305\u542b\u65f6\u95f4\u5e8f\u5217\u7f16\u7801\u5668\u4e0e\u7ed3\u6784\u5316\u89e3\u7801\u5668\u3002\u6a21\u578b\u663e\u5f0f\u5bf9\u6570\u503c\u53d8\u5316\u8fdb\u884c\u63a8\u7406\uff0c\u751f\u6210\u4e2d\u95f4\u89e3\u91ca\u5e76\u7ed9\u51fa\u7ed3\u6784\u5316\u4e8b\u4ef6\u5047\u8bbe\u3002", "result": "\u5728\u591a\u9886\u57df\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u4e8b\u4ef6\u7ea7\u7cbe\u5ea6\u548c\u53ec\u56de\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u7684LLM\u3002", "conclusion": "\u4e3a\u91cf\u5316\u63a8\u7406\u4e0e\u8bed\u4e49\u7406\u89e3\u5efa\u7acb\u65b0\u65b9\u5411\uff0c\u4f7fLLMs\u80fd\u591f\u76f4\u63a5\u4ece\u6570\u503c\u52a8\u6001\u4e2d\u89e3\u91ca\u548c\u9884\u6d4b\u4e8b\u4ef6\u3002"}}
{"id": "2510.24185", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24185", "abs": "https://arxiv.org/abs/2510.24185", "authors": ["Kwadwo Mensah Obeng Afrane", "Yang Miao", "Andr\u00e9 B. J. Kokkeler"], "title": "Performance Analysis of Sub-band Full-duplex Cell-free Massive MIMO JCAS Systems", "comment": null, "summary": "In-band Full-duplex joint communication and sensing systems require self\ninterference cancellation as well as decoupling of the mutual interference\nbetween UL communication signals and radar echoes. We present sub-band\nfull-duplex as an alternative duplexing scheme to achieve simultaneous uplink\ncommunication and target parameter estimation in a cell-free massive MIMO\nsystem. Sub-band full-duplex allows uplink and downlink transmissions\nsimultaneously on non-overlapping frequency resources via explicitly defined\nuplink and downlink sub-bands in each timeslot. Thus, we propose a sub-band\nfull-duplex cell-free massive MIMO system with active downlink sensing on\ndownlink sub-bands and uplink communication on uplink sub-band. In the proposed\nsystem, the target illumination signal is transmitted on the downlink (radar)\nsub-band whereas uplink users transmit on the uplink (communication) sub-band.\nBy assuming efficient suppression of inter-sub-band interference between radar\nand communication sub-bands, uplink communication and radar signals can be\nefficiently processed without mutual interference. We show that each AP can\nestimate sensing parameters with high accuracy in SBFD cell-free massive MIMO\nJCAS systems.", "AI": {"tldr": "\u63d0\u51fa\u5728\u65e0\u4e2d\u5fc3\u5316\u7684\u5927\u89c4\u6a21MIMO JCAS\u7cfb\u7edf\u4e2d\uff0c\u91c7\u7528\u5b50\u5e26\u5168\u53cc\u5de5\uff08SBFD\uff09\u5b9e\u73b0\u4e0a\u884c\u901a\u4fe1\u4e0e\u4e0b\u884c\u96f7\u8fbe\u611f\u77e5\u7684\u540c\u65f6\u8fdb\u884c\uff0c\u901a\u8fc7\u975e\u91cd\u53e0\u7684\u4e0a\u884c/\u4e0b\u884c\u5b50\u5e26\u5206\u914d\u5b9e\u73b0\u4fe1\u53f7\u89e3\u8026\u5e76\u5047\u8bbe\u5b50\u5e26\u5e72\u6270\u53ef\u6291\u5236\uff0c\u4e14\u6bcf\u4e2aAP\u80fd\u5728SBFD\u7cfb\u7edf\u4e2d\u9ad8\u7cbe\u5ea6\u4f30\u8ba1\u611f\u77e5\u53c2\u6570\u3002", "motivation": "\u5728\u5e26\u5185\u5168\u53cc\u5de5\u7684JCAS\u4e2d\uff0c\u9700\u89e3\u51b3\u81ea\u5e72\u6270\u4ee5\u53ca\u4e0a\u884c\u901a\u4fe1\u4fe1\u53f7\u4e0e\u96f7\u8fbe\u56de\u6ce2\u4e4b\u95f4\u7684\u76f8\u4e92\u5e72\u6270\uff1b\u5b50\u5e26\u5168\u53cc\u5de5\u63d0\u4f9b\u4e00\u79cd\u964d\u4f4e\u5e72\u6270\u3001\u5b9e\u73b0\u540c\u65f6\u901a\u4fe1\u4e0e\u611f\u77e5\u7684\u65b0\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u7684\u3001\u9762\u5411\u5927\u89c4\u6a21MIMO\u7684\u573a\u666f\u3002", "method": "\u5728\u6bcf\u4e2a\u65f6\u9699\u5185\uff0c\u5c06\u4e0a\u884c\u4e0e\u4e0b\u884c\u5206\u914d\u5230\u975e\u91cd\u53e0\u7684\u5b50\u5e26\uff0c\u660e\u786e\u89c4\u5b9a\u4e0a\u884c\u5b50\u5e26\u7528\u4e8e\u4e0a\u884c\u901a\u4fe1\u3001\u4e0b\u884c\u5b50\u5e26\u7528\u4e8e\u96f7\u8fbe\u63a2\u6d4b\u4e0e\u611f\u77e5\u4fe1\u53f7\u7684\u4e0b\u884c\u4f20\u8f93\uff1b\u901a\u8fc7\u5bf9\u4e24\u5b50\u5e26\u95f4\u7684\u5e72\u6270\u8fdb\u884c\u6709\u6548\u6291\u5236\uff0c\u5b9e\u73b0\u5728\u4e0d\u76f8\u4e92\u5e72\u6270\u7684\u524d\u63d0\u4e0b\u5bf9\u96f7\u8fbe\u56de\u6ce2\u548c\u901a\u4fe1\u4fe1\u53f7\u8fdb\u884c\u5904\u7406\uff1b\u5047\u8bbe\u5404\u63a5\u5165\u70b9\uff08AP\uff09\u80fd\u591f\u5728\u5b50\u5e26\u9694\u79bb\u4e0b\u4f30\u8ba1\u76ee\u6807\u53c2\u6570\u3002", "result": "\u6307\u51fa\u5728SBFD\u7684\u65e0\u4e2d\u5fc3\u5316\u5927\u89c4\u6a21MIMO JCAS\u7cfb\u7edf\u4e2d\uff0c\u5404AP\u80fd\u591f\u5728\u9ad8\u7cbe\u5ea6\u4e0b\u4f30\u8ba1\u611f\u77e5\u53c2\u6570\u3002", "conclusion": "SBFD\u4e3a\u65e0\u4e2d\u5fc3\u5316\u7684\u5927\u89c4\u6a21MIMO JCAS\u573a\u666f\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u53cc\u5de5\u65b9\u6848\uff0c\u901a\u8fc7\u5b50\u5e26\u9694\u79bb\u5b9e\u73b0\u96f7\u8fbe\u4e0e\u901a\u4fe1\u7684\u89e3\u8026\u4e0e\u534f\u540c\uff0c\u4ece\u800c\u5b9e\u73b0\u51c6\u786e\u7684\u76ee\u6807\u53c2\u6570\u4f30\u8ba1\u3002"}}
{"id": "2510.23938", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23938", "abs": "https://arxiv.org/abs/2510.23938", "authors": ["Marcin Spoczynski", "Marcela S. Melara"], "title": "Scalable GPU-Based Integrity Verification for Large Machine Learning Models", "comment": null, "summary": "We present a security framework that strengthens distributed machine learning\nby standardizing integrity protections across CPU and GPU platforms and\nsignificantly reducing verification overheads. Our approach co-locates\nintegrity verification directly with large ML model execution on GPU\naccelerators, resolving the fundamental mismatch between how large ML workloads\ntypically run (primarily on GPUs) and how security verifications traditionally\noperate (on separate CPU-based processes), delivering both immediate\nperformance benefits and long-term architectural consistency. By performing\ncryptographic operations natively on GPUs using dedicated compute units (e.g.,\nIntel Arc's XMX units, NVIDIA's Tensor Cores), our solution eliminates the\npotential architectural bottlenecks that could plague traditional CPU-based\nverification systems when dealing with large models. This approach leverages\nthe same GPU-based high-memory bandwidth and parallel processing primitives\nthat power ML workloads ensuring integrity checks keep pace with model\nexecution even for massive models exceeding 100GB. This framework establishes a\ncommon integrity verification mechanism that works consistently across\ndifferent GPU vendors and hardware configurations. By anticipating future\ncapabilities for creating secure channels between trusted execution\nenvironments and GPU accelerators, we provide a hardware-agnostic foundation\nthat enterprise teams can deploy regardless of their underlying CPU and GPU\ninfrastructures.", "AI": {"tldr": "\u5728GPU\u4e0a\u5bf9\u5927\u89c4\u6a21ML\u5de5\u4f5c\u8d1f\u8f7d\u5b9e\u73b0\u5185\u7f6e\u7684\u5b8c\u6574\u6027\u9a8c\u8bc1\u6846\u67b6\uff0c\u964d\u4f4eCPU\u9a8c\u8bc1\u5f00\u9500\uff0c\u5e76\u5b9e\u73b0\u8de8GPU\u5382\u5546\u7684\u4e00\u81f4\u6027\u7ef4\u62a4\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21ML\u5de5\u4f5c\u8d1f\u8f7d\uff08\u901a\u5e38\u5728GPU\u4e0a\u8fd0\u884c\uff09\u4e0e\u4f20\u7edf\u57fa\u4e8eCPU\u7684\u5b89\u5168\u9a8c\u8bc1\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u964d\u4f4e\u9a8c\u8bc1\u5f00\u9500\uff0c\u540c\u65f6\u5b9e\u73b0\u8de8\u786c\u4ef6\u5e73\u53f0\u7684\u5b89\u5168\u4e00\u81f4\u6027\u3002", "method": "\u5c06\u5b8c\u6574\u6027\u9a8c\u8bc1\u76f4\u63a5\u4e0eGPU\u4e0a\u7684\u6a21\u578b\u6267\u884c\u5171\u5b9a\u4f4d\uff0c\u5229\u7528GPU\u539f\u751f\u7684\u8ba1\u7b97\u5355\u5143\u8fdb\u884c\u5bc6\u7801\u5b66\u8fd0\u7b97\uff08\u5982Intel Arc XMX\u3001NVIDIA Tensor Cores\uff09\uff0c\u5b9e\u73b0\u8de8\u5382\u5546\u7684\u4e00\u81f4\u6027\u9a8c\u8bc1\u673a\u5236\uff0c\u5e76\u8bbe\u60f3\u5728\u53ef\u4fe1\u6267\u884c\u73af\u5883\uff08TEE\uff09\u4e0eGPU\u4e4b\u95f4\u6784\u5efa\u5b89\u5168\u901a\u9053\u6765\u652f\u6491\u786c\u4ef6\u65e0\u5173\u7684\u90e8\u7f72\u3002", "result": "\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u4e0e\u67b6\u6784\u4e00\u81f4\u6027\uff1b\u80fd\u591f\u5bf9\u8d85\u5927\u6a21\u578b\uff08>100GB\uff09\u4fdd\u6301\u9a8c\u5168\u7684\u901f\u5ea6\u4e0e\u53ef\u6269\u5c55\u6027\uff0c\u964d\u4f4e\u5bf9CPU\u7aef\u9a8c\u8bc1\u7684\u4f9d\u8d56\u3002", "conclusion": "\u63d0\u51fa\u4e00\u79cd\u786c\u4ef6\u52a0\u901f\u3001\u8de8\u5382\u5546\u517c\u5bb9\u7684\u5206\u5e03\u5f0fML\u5b8c\u6574\u6027\u9a8c\u8bc1\u57fa\u7840\u8bbe\u65bd\uff0c\u53ef\u968f\u672a\u6765TEE-GPU\u5b89\u5168\u901a\u9053\u7684\u53d1\u5c55\u800c\u6269\u5c55\uff0c\u4fbf\u4e8e\u4f01\u4e1a\u5728\u4e0d\u540cCPU/GPU\u57fa\u7840\u8bbe\u65bd\u4e0a\u90e8\u7f72\u3002"}}
{"id": "2510.23910", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.23910", "abs": "https://arxiv.org/abs/2510.23910", "authors": ["Khadija Omar Said", "Yukta Pareek", "Satadru Dey", "Ashish Ranjan Kumar"], "title": "Dynamical Modeling of Temperature and Smoke Evolution in a Thermal-Runaway Event of a Large-Format Lithium-ion Battery in a Mine Tunnel", "comment": null, "summary": "Large-format lithium-ion batteries (LIBs) provide effective energy storage\nsolutions for high-power equipment used in underground mining operations. They\nhave high Columbic efficiency and minimal heat and emission footprints.\nHowever, improper use of LIBs, accidents, or other factors may increase the\nprobability of thermal runaway (TR), a rapid combustion reaction that\ndischarges toxic and flammable substances. Several such incidents have been\ndocumented in mines. Since repeatable TR experiments to uncover the\ntransient-state propagation of TR are expensive and hazardous, high-fidelity\nmodels are usually developed to mimic the impact of these events. They are\nresource-intensive and are impractical to develop for many scenarios that could\nbe observed in a mine. Therefore, dynamic models within a reduced-order\nframework were constructed to represent the transient-state combustion event.\nReduced order models (ROMs) reasonably replicate trends in temperature and\nsmoke, showing strong alignment with the ground-truth dataset.", "AI": {"tldr": "Reduced-order dynamic models for lithium-ion battery thermal runaway in underground mining; effectively capture temperature and smoke trends with data-driven validation.", "motivation": "To enable safe and scalable analysis of TR in large-format LIBs used in underground mining, given that high-fidelity models are expensive and dangerous to run for many scenarios.", "method": "Construct dynamic reduced-order models (ROMs) within a reduced-order framework to mimic the transient-state combustion event; validation shows ROMs reproduce temperature and smoke trends and align with ground-truth data.", "result": "ROMs reasonably replicate temperature and smoke trends with strong alignment to the ground-truth dataset, offering efficient and scalable simulations compared to high-fidelity models.", "conclusion": "Reduced-order models provide a practical, data-consistent approach for simulating TR events in mining LIBs, enabling rapid scenario analysis and risk assessment."}}
{"id": "2510.23631", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23631", "abs": "https://arxiv.org/abs/2510.23631", "authors": ["Yuxuan Tang", "Yifan Feng"], "title": "Beyond Pairwise: Empowering LLM Alignment With Ranked Choice Modeling", "comment": null, "summary": "Alignment of large language models (LLMs) has predominantly relied on\npairwise preference optimization, where annotators select the better of two\nresponses to a prompt. While simple, this approach overlooks the opportunity to\nlearn from richer forms of human feedback, such as multiwise comparisons and\ntop-$k$ rankings. We propose Ranked Choice Preference Optimization (RCPO), a\nunified framework that bridges preference optimization with (ranked) choice\nmodeling via maximum likelihood estimation. The framework is flexible,\nsupporting both utility-based and rank-based choice models. It subsumes several\nexisting pairwise methods (e.g., DPO, SimPO), while providing principled\ntraining objectives for richer feedback formats. We instantiate this framework\nwith two representative ranked choice models (Multinomial Logit and\nMallows-RMJ). Empirical studies on Llama-3-8B-Instruct and Gemma-2-9B-it across\nAlpacaEval 2 and Arena-Hard benchmarks show that RCPO consistently outperforms\ncompetitive baselines. RCPO shows how directly leveraging ranked preference\ndata, combined with the right choice models, yields more effective alignment.\nIt offers a versatile and extensible foundation for incorporating (ranked)\nchoice modeling into LLM training.", "AI": {"tldr": "\u63d0\u51fa Ranked Choice Preference Optimization (RCPO) \uff0c\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5c06\u6392\u5e8f\u9009\u62e9\uff08\u591a\u9009\u3001Top-k \u7b49\uff09\u4e0e\u504f\u597d\u4f18\u5316\u7ed3\u5408\u8d77\u6765\uff0c\u7528\u4e8e\u5bf9\u8bdd\u6a21\u578b\u7684\u5bf9\u9f50\u3002\u6bd4\u5bf9\u4e24\u4e24\u504f\u597d\u65b9\u6cd5\u5177\u6709\u66f4\u4e30\u5bcc\u53cd\u9988\uff0c\u4e14\u5728\u591a\u79cd\u6a21\u578b\u4e0e\u57fa\u51c6\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u9f50\u65b9\u6cd5\u5927\u591a\u57fa\u4e8e\u4e24\u4e24\u504f\u597d\uff0c\u5ffd\u7565\u4e86\u66f4\u4e30\u5bcc\u7684\u4eba\u7c7b\u53cd\u9988\u5f62\u5f0f\uff08\u591a\u9009\u3001Top-k \u6392\u5e8f\uff09\u3002\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u5145\u5206\u5229\u7528\u6392\u5e8f\u504f\u597d\u4fe1\u606f\uff0c\u4ee5\u63d0\u5347\u5bf9\u9f50\u6548\u679c\u3002", "method": "\u63d0\u51fa RCPO \u6846\u67b6\uff0c\u53ef\u7ed3\u5408\u6548\u7528-based \u4e0e\u6392\u5e8f-based \u7684\u9009\u62e9\u6a21\u578b\uff0c\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5bf9\u6392\u5e8f/\u591a\u9009\u6570\u636e\u8fdb\u884c\u5b66\u4e60\u3002\u8be5\u6846\u67b6\u53ef\u8986\u76d6\u73b0\u6709\u7684\u4e24\u4e24\u65b9\u6cd5\uff08\u5982 DPO\u3001SimPO\uff09\uff0c\u5e76\u63d0\u4f9b\u5bf9 richer \u53cd\u9988\u7684\u8bad\u7ec3\u76ee\u6807\u3002\u4ee5\u4e24\u79cd\u4ee3\u8868\u6027\u6392\u5e8f\u9009\u62e9\u6a21\u578b\uff08\u591a\u9879\u5f0f\u903b\u8f91\u56de\u5f52 MNL\u3001Mallows-RMJ\uff09\u4e3a\u4f8b\u5b9e\u73b0\uff0c\u5e76\u5728 Llama-3-8B-Instruct \u4e0e Gemma-2-9B-it \u4e0a\u7684 AlpacaEval 2 \u4e0e Arena-Hard \u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "RCPO \u5728\u5b9e\u9a8c\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\u3002\u76f4\u63a5\u5229\u7528\u6392\u5e8f\u504f\u597d\u6570\u636e\u5e76\u914d\u5408\u5408\u9002\u7684\u9009\u62e9\u6a21\u578b\uff0c\u80fd\u83b7\u5f97\u66f4\u6709\u6548\u7684\u6a21\u578b\u5bf9\u9f50\u3002", "conclusion": "RCPO \u4e3a\u5c06\u6392\u5e8f/\u6392\u540d\u504f\u597d\u5efa\u6a21\u5f15\u5165\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u53ef\u8fdb\u4e00\u6b65\u5728\u5bf9\u9f50\u4efb\u52a1\u4e2d\u5229\u7528\u66f4\u4e30\u5bcc\u7684\u53cd\u9988\u5f62\u5f0f\u3002"}}
{"id": "2510.24193", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24193", "abs": "https://arxiv.org/abs/2510.24193", "authors": ["Tailai Wen", "Da Ke", "Xiang Wang", "Zhitao Huang"], "title": "Dual-Domain Constraints: Designing Covert and Efficient Adversarial Examples for Secure Communication", "comment": null, "summary": "The advancements in Automatic Modulation Classification (AMC) have propelled\nthe development of signal sensing and identification technologies in\nnon-cooperative communication scenarios but also enable eavesdroppers to\neffectively intercept user signals in wireless communication environments. To\nprotect user privacy in communication links, we have optimized the adversarial\nexample generation model and introduced a novel framework for generating\nadversarial perturbations for transmitted signals. This framework implements\ndual-domain constraints in both the time and frequency domains, ensuring that\nthe adversarial perturbation cannot be filtered out. Comparative experiments\nconfirm the superiority of the proposed method and the concealment of the\nadversarial examples it generates.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u4f20\u8f93\u4fe1\u53f7\u7684\u5bf9\u6297\u6837\u672c\u751f\u6210\u6846\u67b6\uff0c\u5728\u65f6\u57df\u548c\u9891\u57df\u53cc\u57df\u7ea6\u675f\u4e0b\u5b9e\u73b0\u9690\u853d\u7684\u5bf9\u6297\u6270\u52a8\uff0c\u4ee5\u5e72\u6270AMC\u5206\u7c7b\u5e76\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3002", "motivation": "\u5728\u975e\u5408\u4f5c\u901a\u4fe1\u573a\u666f\u4e2d\uff0c\u5c3d\u7ba1\u81ea\u52a8\u8c03\u5236\u5206\u7c7b\uff08AMC\uff09\u6709\u52a9\u4e8e\u4fe1\u53f7\u611f\u77e5\u4e0e\u8bc6\u522b\uff0c\u4f46\u4e5f\u53ef\u80fd\u88ab\u7a83\u542c\u8005\u5229\u7528\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u4e14\u9690\u853d\u7684\u5bf9\u6297\u6270\u52a8\u6765\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3002", "method": "\u4f18\u5316\u5bf9\u6297\u6837\u672c\u751f\u6210\u6a21\u578b\uff0c\u63d0\u51fa\u5728\u65f6\u95f4\u57df\u548c\u9891\u57df\u540c\u65f6\u65bd\u52a0\u7ea6\u675f\u7684\u6270\u52a8\u6846\u67b6\uff0c\u786e\u4fdd\u6270\u52a8\u96be\u4ee5\u88ab\u8fc7\u6ee4\u4e14\u5177\u6709\u6301\u7eed\u6709\u6548\u6027\uff1b\u901a\u8fc7\u5bf9\u6bd4\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u4e0e\u5bf9\u6297\u6837\u672c\u7684\u9690\u853d\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u63d0\u5347\u5bf9\u6297\u6548\u679c\u7684\u540c\u65f6\uff0c\u6270\u52a8\u5177\u6709\u826f\u597d\u7684\u9690\u853d\u6027\uff0c\u8f83\u5bf9\u6bd4\u65b9\u6cd5\u66f4\u4e0d\u6613\u88ab\u68c0\u6d4b\u3002", "conclusion": "\u53cc\u57df\u7ea6\u675f\u7684\u5bf9\u6297\u6270\u52a8\u751f\u6210\u6846\u67b6\u53ef\u6709\u6548\u4fdd\u62a4\u901a\u4fe1\u94fe\u8def\u9690\u79c1\uff0c\u63d0\u5347\u5bf9\u6297\u6837\u672c\u7684\u9690\u853d\u6027\u4e0e\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.23632", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23632", "abs": "https://arxiv.org/abs/2510.23632", "authors": ["Guozhong Li", "Muhannad Alhumaidi", "Spiros Skiadopoulos", "Panos Kalnis"], "title": "LLMComp: A Language Modeling Paradigm for Error-Bounded Scientific Data Compression", "comment": null, "summary": "The rapid growth of high-resolution scientific simulations and observation\nsystems is generating massive spatiotemporal datasets, making efficient,\nerror-bounded compression increasingly important. Meanwhile, decoder-only large\nlanguage models (LLMs) have demonstrated remarkable capabilities in modeling\ncomplex sequential data. In this paper, we propose LLMCOMP, a novel lossy\ncompression paradigm that leverages decoder-only large LLMs to model scientific\ndata. LLMCOMP first quantizes 3D fields into discrete tokens, arranges them via\nZ-order curves to preserve locality, and applies coverage-guided sampling to\nenhance training efficiency. An autoregressive transformer is then trained with\nspatial-temporal embeddings to model token transitions. During compression, the\nmodel performs top-k prediction, storing only rank indices and fallback\ncorrections to ensure strict error bounds. Experiments on multiple reanalysis\ndatasets show that LLMCOMP consistently outperforms state-of-the-art\ncompressors, achieving up to 30% higher compression ratios under strict error\nbounds. These results highlight the potential of LLMs as general-purpose\ncompressors for high-fidelity scientific data.", "AI": {"tldr": "\u63d0\u51fa LLMCOMP\uff0c\u4e00\u79cd\u57fa\u4e8e\u89e3\u7801\u5668\u7684\u6709\u635f\u538b\u7f29\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u79d1\u5b66\u6570\u636e\u8fdb\u884c\u5e8f\u5217\u5efa\u6a21\uff0c\u901a\u8fc7\u79bb\u6563\u5316\u3001Z\u5e8f\u6392\u5217\u548c\u8986\u76d6\u5f15\u5bfc\u91c7\u6837\u7b49\u6280\u672f\u5bf9\u9ad8\u5206\u8fa8\u7387\u65f6\u7a7a\u6570\u636e\u8fdb\u884c\u9ad8\u6548\u3001\u5177\u4e25\u683c\u8bef\u5dee\u754c\u9650\u7684\u538b\u7f29\u3002", "motivation": "\u9762\u5bf9\u6d77\u91cf\u9ad8\u5206\u8fa8\u7387\u79d1\u5b66\u6570\u636e\u7684\u5b58\u50a8\u4e0e\u4f20\u8f93\u9700\u6c42\uff0c\u73b0\u6709\u9ad8\u6548\u538b\u7f29\u65b9\u6cd5\u5728\u4e25\u683c\u8bef\u5dee\u8fb9\u754c\u4e0b\u5f80\u5f80\u53d7\u9650\uff1b\u89e3\u7801\u5668\u4f18\u5148\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u590d\u6742\u5e8f\u5217\u6570\u636e\u5177\u6709\u5efa\u6a21\u6f5c\u529b\uff0c\u80fd\u591f\u4f5c\u4e3a\u901a\u7528\u538b\u7f29\u5668\u3002", "method": "\u5c063D\u573a\u91cf\u5316\u4e3a\u79bb\u6563\u6807\u8bb0\u5e76\u901a\u8fc7 Z-order \u66f2\u7ebf\u4fdd\u6301\u5c40\u90e8\u6027\uff0c\u91c7\u7528\u8986\u76d6\u5f15\u5bfc\u91c7\u6837\u63d0\u5347\u8bad\u7ec3\u6548\u7387\uff1b\u4f7f\u7528\u5177\u6709\u65f6\u7a7a\u5d4c\u5165\u7684\u81ea\u56de\u5f52\u53d8\u6362\u5668\u5bf9\u6807\u8bb0\u8f6c\u79fb\u8fdb\u884c\u5efa\u6a21\u3002\u5728\u538b\u7f29\u9636\u6bb5\uff0c\u6a21\u578b\u8fdb\u884c\u524dk\u9884\u6d4b\uff0c\u4ec5\u5b58\u50a8 rank \u7d22\u5f15\u548c\u56de\u9000\u4fee\u6b63\u4ee5\u786e\u4fdd\u4e25\u683c\u8bef\u5dee\u754c\u9650\u3002", "result": "\u5728\u591a\u7ec4\u518d\u5206\u6790\u6570\u636e\u96c6\u4e0a\uff0cLLMCOMP \u7684\u538b\u7f29\u6bd4\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u538b\u7f29\u5668\uff0c\u5728\u4e25\u683c\u8bef\u5dee\u8fb9\u754c\u4e0b\u5b9e\u73b0\u6700\u9ad8\u7ea6 30% \u7684\u63d0\u5347\u3002", "conclusion": "\u5c55\u793a\u4e86\u5c06\u89e3\u7801\u5668\u7aef\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u9ad8\u4fdd\u771f\u79d1\u5b66\u6570\u636e\u901a\u7528\u538b\u7f29\u5668\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.24223", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24223", "abs": "https://arxiv.org/abs/2510.24223", "authors": ["Mahmut Kemal Ercan", "Alireza Pourafzal", "Musa Furkan Keskin", "Sinan Gezici", "Henk Wymeersch"], "title": "Pilot Distortion Design for ToA Obfuscation in Uplink OFDM Communication", "comment": "The document consists of 6 pages and features 4 figures. Submitted to\n  IEEE WCNC 2026", "summary": "We study uplink orthogonal frequency-division multiplexing (OFDM) pilot\ndistortion to deliberately obfuscate time-of-arrival (ToA) estimation at a\nsingle base station while preserving communication performance. We design a\ncomplex per-subcarrier distortion vector that increases sidelobes of the\nmismatched ambiguity function (MAF) relative to its mainlobe, using two\nobjectives: the sidelobe-to-peak level ratio and the integrated sidelobe level.\nThe design is subject to a transmit-power budget and a proximity\n(dissimilarity) constraint around the communication-optimal pilot.\nCommunication impact is quantied by a capacity-motivated lower bound obtained\nfrom the linear minimum mean-squared error error covariance with a mismatched\nchannel estimate. The resulting generalized fractional program is solved with\nDinkelbach's transform and a difference-of-convex update that yields a\nclosed-form Karush-Kuhn-Tucker step. Simulations on a single-input\nsingle-output OFDM link show that the optimized distortions raise MAF sidelobes\nand degrade delay estimation, as validated by a mismatched maximum-likelihood\nToA estimator, while incurring only marginal capacity loss over a broad\nsignal-to-noise ratio range. The method requires no protocol changes or\nartificial path injection and provides a signal-level mechanism to control ToA\nobservability under communication constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cdOFDM\u4e0a\u884cpilot\u5931\u771f\u8bbe\u8ba1\uff0c\u7528\u4ee5\u5728\u4e0d\u663e\u8457\u635f\u5bb3\u901a\u4fe1\u6027\u80fd\u524d\u63d0\u4e0b\uff0c\u63d0\u5347ToA\u89c2\u6d4b\u7684\u96be\u5ea6\u3002\u901a\u8fc7\u5bf9\u6bcf\u4e2a\u5b50\u8f7d\u6ce2\u65bd\u52a0\u590d\u6570\u5931\u771f\u5411\u91cf\uff0c\u589e\u5927\u5339\u914d\u9519\u914d\u51fd\u6570(MAF)\u7684\u65c1\u74e3\u76f8\u5bf9\u4e8e\u4e3b\u74e3\u7684\u6bd4\u503c\u3002\u4ee5\u65c1\u74e3\u5cf0\u503c\u6bd4\u4e0e\u6574\u5408\u65c1\u74e3\u80fd\u91cf\u4e3a\u591a\u76ee\u6807\uff0c\u5728\u529f\u7387\u9884\u7b97\u548c\u4e0e\u901a\u4fe1\u6700\u4f18pilot\u7684\u76f8\u4f3c\u6027\u7ea6\u675f\u4e0b\uff0c\u5229\u7528Dinkelbach\u53d8\u6362\u4e0e\u5dee\u5206\u51f8\u4f18\u5316\u5f97\u5230\u95ed\u5f0fKKT\u6b65\u3002\u4eff\u771f\u8868\u660e\u5355\u8f93\u5165\u5355\u8f93\u51faOFDM\u94fe\u8def\u4e2d\uff0c\u4f18\u5316\u5931\u771f\u63d0\u5347MAF\u65c1\u74e3\u5e76\u964d\u4f4e\u5ef6\u8fdf\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u540c\u65f6\u5728\u8f83\u5bbd\u7684SNR\u533a\u95f4\u5185\u5bb9\u91cf\u635f\u5931\u5f88\u5c0f\u3002", "motivation": "\u7814\u7a76\u5728\u4e0d\u635f\u5bb3\u901a\u4fe1\u6027\u80fd\u7684\u524d\u63d0\u4e0b\uff0c\u5bf9\u4e0a\u884cOFDM pilot\u7684ToA\u4f30\u8ba1\u8fdb\u884c\u5e72\u6270/\u6df7\u6dc6\uff0c\u4ee5\u63d0\u5347ToA\u7684\u4e0d\u53ef\u89c2\u6d4b\u6027\u4e0e\u4f4d\u7f6e\u9690\u79c1\u3002", "method": "\u8bbe\u8ba1\u6bcf\u5b50\u8f7d\u6ce2\u7684\u590d\u6570\u5931\u771f\u5411\u91cf\uff0c\u4f18\u5316\u4e24\u9879\u6307\u6807\uff1a\u65c1\u74e3\u5bf9\u5cf0\u503c\u6bd4(\u65c1\u74e3/\u4e3b\u74e3)\u4e0e\u6574\u5408\u65c1\u74e3\u80fd\u91cf(ISL)\uff1b\u53d7\u9650\u4e8e\u53d1\u5c04\u529f\u7387\u9884\u7b97\u548c\u4e0e\u901a\u4fe1\u6700\u4f18pilot\u7684\u8fd1\u4f3c\u7ea6\u675f\u3002\u57fa\u4e8e\u5e26\u9519\u4f30\u8ba1\u7684\u7ebf\u6027\u6700\u5c0f\u5747\u65b9\u8bef\u5dee\u534f\u65b9\u5dee\u63a8\u5bfc\u51fa\u9762\u5411\u5bb9\u91cf\u7684\u4e0b\u754c\uff1b\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u5e7f\u4e49\u5206\u5f0f\u89c4\u5212\uff0c\u91c7\u7528Dinkelbach\u53d8\u6362\u548c\u5dee\u5206\u51f8\u66f4\u65b0\uff0c\u7ed9\u51fa\u95ed\u5f0f\u7684KKT\u6b65\u3002", "result": "\u4eff\u771f\uff08SISO-OFDM\uff09\u8868\u660e\u4f18\u5316\u5931\u771f\u63d0\u5347MAF\u65c1\u74e3\u5e76\u964d\u4f4e\u5ef6\u8fdf\u4f30\u8ba1\u7cbe\u5ea6\uff08\u901a\u8fc7\u9519\u914d\u6700\u5927\u4f3c\u7136ToA\u4f30\u8ba1\u5668\u9a8c\u8bc1\uff09\uff0c\u540c\u65f6\u5728\u5e7f\u6cdb\u7684SNR\u533a\u95f4\u5185\u5bb9\u91cf\u635f\u5931\u4ec5\u4e3a\u8fb9\u9645\u91cf\u3002", "conclusion": "\u63d0\u4f9b\u4e00\u79cd\u4fe1\u53f7\u7ea7\u522b\u7684\u63a7\u5236ToA\u53ef\u89c2\u6d4b\u6027\u7684\u624b\u6bb5\uff0c\u5728\u6ee1\u8db3\u901a\u4fe1\u7ea6\u675f\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0ToA\u7684\u53ef\u89c2\u6d4b\u6027\u8c03\u63a7\uff1b\u65e0\u9700\u534f\u8bae\u4fee\u6539\u6216\u4eba\u4e3a\u8def\u5f84\u6ce8\u5165\u3002"}}
{"id": "2510.24101", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.24101", "abs": "https://arxiv.org/abs/2510.24101", "authors": ["Nam Tran", "Khoa Nguyen", "Dongxi Liu", "Josef Pieprzyk", "Willy Susilo"], "title": "Traceable Signatures from Lattices", "comment": "45 pages", "summary": "Traceable signatures (Kiayas et al., EUROCRYPT 2004) is an anonymous digital\nsignature system that extends the tracing power of the opening authority in\ngroup signatures. There are many known constructions of traceable signatures,\nbut all are based on number-theoretic/pairing assumptions. For such reason,\nthey may not be secure in the presence of quantum computers. This work revisits\nthe notion of traceable signatures and presents a lattice-based construction\nprovably secure in the quantum random oracle model (QROM).", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u683c\u7684\u53ef\u8ffd\u8e2a\u7b7e\u540d\uff0c\u5728\u91cf\u5b50\u5b89\u5168\u7684QROM\u4e2d\u5177\u6709\u53ef\u8bc1\u660e\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8ddf\u8e2a\u7b7e\u540d\u591a\u57fa\u4e8e\u6570\u8bba\u6216\u914d\u5bf9\uff0c\u9762\u5bf9\u91cf\u5b50\u5bf9\u624b\u65f6\u53ef\u80fd\u5931\u6548\uff0c\u56e0\u6b64\u9700\u8981\u91cf\u5b50\u5b89\u5168\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u6784\u9020\u4e00\u4e2a\u683c\u57fa\u7684\u53ef\u8ffd\u8e2a\u7b7e\u540d\u65b9\u6848\uff0c\u5e76\u5728\u91cf\u5b50\u968f\u673a Oracle \u6a21\u578b\uff08QROM\uff09\u4e0b\u7ed9\u51fa\u5b89\u5168\u6027\u8bc1\u660e\u3002", "result": "\u7ed9\u51fa\u5728QROM\u4e2d\u7684\u5b89\u5168\u6027\u8bc1\u660e\uff0c\u5229\u7528\u683c\u95ee\u9898\uff08\u5982 SVP/SIVP \u7b49\uff09\u7684\u56f0\u96be\u6027\u5b9e\u73b0\u7406\u8bba\u5b89\u5168\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u8ffd\u8e2a\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8bc1\u660e\u4e86\u683c\u57fa\u65b9\u6cd5\u5728\u53ef\u8ffd\u8e2a\u7b7e\u540d\u9886\u57df\u7684\u53ef\u884c\u6027\uff0c\u63d0\u4f9b\u5bf9\u91cf\u5b50\u653b\u51fb\u7684\u62b5\u6297\u80fd\u529b\uff1b\u540e\u7eed\u5de5\u4f5c\u53ef\u805a\u7126\u6548\u7387\u3001\u5b9e\u73b0\u4e0e\u5b9e\u9645\u5e94\u7528\u8bc4\u4f30\uff0c\u4ee5\u53ca\u5bf9\u5176\u4ed6\u5b89\u5168\u5c5e\u6027\u7684\u6269\u5c55\u3002"}}
{"id": "2510.24191", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24191", "abs": "https://arxiv.org/abs/2510.24191", "authors": ["Isabelle Krauss", "Victor G. Lopez", "Matthias A. M\u00fcller"], "title": "Sample-based Moving Horizon Estimation", "comment": null, "summary": "In this paper, we propose a sample-based moving horizon estimation (MHE)\nscheme for general nonlinear systems to estimate the current system state using\nirregularly and/or infrequently available measurements. The cost function of\nthe MHE optimization problem is suitably designed to accommodate these\nirregular output sequences. We also establish that, under a suitable\nsample-based detectability condition known as sample-based incremental\ninput/output-to-state stability (i-IOSS), the proposed sample-based MHE\nachieves robust global exponential stability (RGES). Additionally, for the case\nof linear systems, we draw connections between sample-based observability and\nsample-based i-IOSS. This demonstrates that previously established conditions\nfor linear systems to be sample-based observable can be utilized to verify or\ndesign sampling strategies that satisfy the conditions to guarantee RGES of the\nsample-based MHE. Finally, the effectiveness of the proposed sample-based MHE\nis illustrated through a simulation example.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6837\u672c\u7684\u79fb\u52a8\u8fb9\u754c\u4f30\u8ba1\uff08MHE\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u6d4b\u91cf\u4e0d\u89c4\u5219\u6216\u4f4e\u9891\u91c7\u6837\u65f6\u5bf9\u4e00\u822c\u975e\u7ebf\u6027\u7cfb\u7edf\u8fdb\u884c\u72b6\u6001\u4f30\u8ba1\uff1b\u901a\u8fc7\u8bbe\u8ba1\u9002\u5408\u4e0d\u89c4\u5219\u8f93\u51fa\u5e8f\u5217\u7684\u4ee3\u4ef7\u51fd\u6570\u5e76\u5f15\u5165\u6837\u672c\u57fa\u7684\u589e\u91cf\u8f93\u5165/\u8f93\u51fa\u5230\u72b6\u6001\u7a33\u5b9a\u6027(i-IOSS)\u6765\u5b9e\u73b0\u9c81\u68d2\u5168\u5c40\u6307\u6570\u7a33\u5b9a\uff08RGES\uff09\u3002\u5bf9\u7ebf\u6027\u7cfb\u7edf\u7ed9\u51fa\u6837\u672c\u57fa\u53ef\u89c2\u6d4b\u6027\u4e0e\u6837\u672c\u57faIOSS\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u5e76\u5229\u7528\u5df2\u6709\u7684\u7ebf\u6027\u7cfb\u7edf\u53ef\u89c2\u6d4b\u6027\u6761\u4ef6\u6765\u9a8c\u8bc1\u6216\u8bbe\u8ba1\u91c7\u6837\u7b56\u7565\u4ee5\u4fdd\u8bc1RGES\u3002\u6700\u540e\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u6240\u63d0\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5728\u4e0d\u89c4\u5219/\u4f4e\u9891\u91c7\u6837\u4e0b\u7684\u7cfb\u7edf\u72b6\u6001\u4f30\u8ba1\u95ee\u9898\uff0c\u5e76\u4e3a\u57fa\u4e8eMHE\u7684\u4f30\u8ba1\u63d0\u4f9b\u9c81\u68d2\u5168\u5c40\u6307\u6570\u7a33\u5b9a\u6027\u4fdd\u969c\uff0c\u6b64\u5916\u5efa\u7acb\u6837\u672c\u5c42\u9762\u7684\u53ef\u89c2\u6d4b\u6027\u4e0ei-IOSS\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u4f7f\u7ebf\u6027\u7cfb\u7edf\u7684\u91c7\u6837\u7b56\u7565\u8bbe\u8ba1\u5177\u6709\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u4e3a\u4e0d\u89c4\u5219\u8f93\u51fa\u5e8f\u5217\u8bbe\u8ba1MHE\u7684\u4ee3\u4ef7\u51fd\u6570\u5e76\u7ed9\u51fa\u6837\u672c\u57fa\u7684i-IOSS\u5224\u636e\uff0c\u7ed9\u51fa\u5728\u8be5\u5224\u636e\u4e0b\u7684RGES\u8bc1\u660e\uff1b\u5728\u7ebf\u6027\u7cfb\u7edf\u4e2d\uff0c\u5c06\u6837\u672c\u57fa\u53ef\u89c2\u6d4b\u6027\u4e0e\u6837\u672c\u57fai-IOSS\u5efa\u7acb\u8054\u7cfb\uff0c\u5e76\u5229\u7528\u7ebf\u6027\u7cfb\u7edf\u5df2\u6709\u7684\u53ef\u89c2\u6d4b\u6027\u6761\u4ef6\u6765\u8bbe\u8ba1/\u9a8c\u8bc1\u91c7\u6837\u65b9\u6848\u4ee5\u6ee1\u8db3RGES\uff1b\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u6548\u679c\u3002", "result": "\u5728\u5047\u8bbe\u6ee1\u8db3\u6837\u672c\u57faIOSS\u6761\u4ef6\u4e0b\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u6837\u672c\u57faMHE\u5177\u6709\u9c81\u68d2\u5168\u5c40\u6307\u6570\u7a33\u5b9a\u6027\uff1b\u5bf9\u7ebf\u6027\u7cfb\u7edf\uff0c\u7ed9\u51fa\u5c06\u6837\u672c\u57fa\u53ef\u89c2\u6d4b\u6027\u63a8\u5bfc\u81f3\u91c7\u6837\u7b56\u7565\u8bbe\u8ba1\u4ee5\u786e\u4fddRGES\u7684\u9014\u5f84\uff1b\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u4e0e\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c06\u4e0d\u89c4\u5219\u91c7\u6837\u4e0b\u7684MHE\u7a33\u5b9a\u6027\u95ee\u9898\u7cfb\u7edf\u5316\uff0c\u63d0\u4f9b\u4e86\u5728\u6837\u672c\u5c42\u9762\u7684\u53ef\u89c2\u6d4b\u6027\u4e0eIOSS\u6846\u67b6\u4e0b\u7684\u7406\u8bba\u4fdd\u969c\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u793a\u4f8b\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.23633", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.23633", "abs": "https://arxiv.org/abs/2510.23633", "authors": ["Xun Su", "Hiroyuki Kasai"], "title": "Noise is All You Need: Solving Linear Inverse Problems by Noise Combination Sampling with Diffusion Models", "comment": "9 pages", "summary": "Pretrained diffusion models have demonstrated strong capabilities in\nzero-shot inverse problem solving by incorporating observation information into\nthe generation process of the diffusion models. However, this presents an\ninherent dilemma: excessive integration can disrupt the generative process,\nwhile insufficient integration fails to emphasize the constraints imposed by\nthe inverse problem. To address this, we propose \\emph{Noise Combination\nSampling}, a novel method that synthesizes an optimal noise vector from a noise\nsubspace to approximate the measurement score, replacing the noise term in the\nstandard Denoising Diffusion Probabilistic Models process. This enables\nconditional information to be naturally embedded into the generation process\nwithout reliance on step-wise hyperparameter tuning. Our method can be applied\nto a wide range of inverse problem solvers, including image compression, and,\nparticularly when the number of generation steps $T$ is small, achieves\nsuperior performance with negligible computational overhead, significantly\nimproving robustness and stability.", "AI": {"tldr": "Noise Combination Sampling\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u566a\u58f0\u5b50\u7a7a\u95f4\u5408\u6210\u6700\u4f73\u566a\u58f0\u5411\u91cf\u4ee5\u8fd1\u4f3c\u6d4b\u91cf\u5206\u6570\uff0c\u4ece\u800c\u5728\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u8fc7\u7a0b\u4e2d\u81ea\u7136\u5d4c\u5165\u9006\u95ee\u9898\u7ea6\u675f\uff0c\u907f\u514d\u9010\u6b65\u8d85\u53c2\u8c03\u4f18\uff0c\u63d0\u5347\u5c0f\u6b65\u957f\u65f6\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u9006\u95ee\u9898\u5982\u56fe\u50cf\u538b\u7f29\u3002", "motivation": "\u73b0\u6709\u7684\u96f6-shot \u9006\u95ee\u9898\u6c42\u89e3\u4e2d\u5bf9\u89c2\u6d4b\u4fe1\u606f\u7684\u5d4c\u5165\u5b58\u5728\u6743\u8861\uff1a\u8fc7\u5ea6\u6574\u5408\u53ef\u80fd\u5e72\u6270\u751f\u6210\uff0c\u4e0d\u8db3\u6574\u5408\u96be\u4ee5\u6ee1\u8db3\u7ea6\u675f\u3002", "method": "\u63d0\u51faNoise Combination Sampling\uff0c\u901a\u8fc7\u4ece\u566a\u58f0\u5b50\u7a7a\u95f4\u5408\u6210\u4e00\u4e2a\u6700\u4f73\u566a\u58f0\u5411\u91cf\u6765\u66ff\u4ee3\u6269\u6563\u8fc7\u7a0b\u4e2d\u7684\u566a\u58f0\u9879\u4ee5\u8fd1\u4f3c\u6d4b\u91cf\u5206\u6570\uff0c\u505a\u5230\u4e0d\u9700\u8981\u9010\u6b65\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u540c\u65f6\u5c06\u6761\u4ef6\u4fe1\u606f\u81ea\u7136\u5d4c\u5165\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5728\u5305\u62ec\u56fe\u50cf\u538b\u7f29\u7b49\u591a\u79cd\u9006\u95ee\u9898\u4e2d\u6709\u6548\uff0c\u4e14\u5728\u751f\u6210\u6b65\u6570T\u8f83\u5c0f\u65f6\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\uff0c\u8ba1\u7b97\u5f00\u9500\u51e0\u4e4e\u4e3a\u96f6\uff0c\u663e\u8457\u63d0\u5347\u9c81\u68d2\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u9006\u95ee\u9898\u6c42\u89e3\uff0c\u63d0\u4f9b\u66f4\u9c81\u68d2\u3001\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u6761\u4ef6\u5316\u6269\u6563\u6a21\u578b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24243", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24243", "abs": "https://arxiv.org/abs/2510.24243", "authors": ["Duc Nguyen Dao", "Haibin Zhang", "Andre B. J. Kokkeler", "Yang Miao"], "title": "Joint Beamforming for Multi-user Multi-target FD ISAC System: A Hybrid GRQ-GA Approach", "comment": "6 pages, 4 figures", "summary": "In this paper, we consider a full-duplex (FD) Integrated Sensing and\nCommunication (ISAC) system, in which the base station (BS) performs downlink\nand uplink communications with multiple users while simultaneously sensing\nmultiple targets. In the scope of this work, we assume a narrowband and static\nscenario, aiming to focus on the beamforming and power allocation strategies.\nWe propose a joint beamforming strategy for designing transmit and receive\nbeamformer vectors at the BS. The optimization problem aims to maximize the\ncommunication sum-rate, which is critical for ensuring high-quality service to\nusers, while also maintaining accurate sensing performance for detection tasks\nand adhering to maximum power constraints for efficient resource usage. The\noptimal receive beamformers are first derived using a closed-form Generalized\nRayleigh Quotient (GRQ) solution, reducing the variables to be optimized. Then,\nthe remaining problem is solved using floating-point Genetic Algorithms (GA).\nThe numerical results show that the proposed GA-based solution demonstrates up\nto a 98% enhancement in sum-rate compared to a baseline half-duplex ISAC system\nand provides better performance than a benchmark algorithm from the literature.\nAdditionally, it offers insights into sensing performance effects on beam\npatterns as well as communicationsensing trade-offs in multi-target scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u5168\u53cc\u5de5\uff08FD\uff09ISAC\u7cfb\u7edf\u7684\u8054\u5408\u6ce2\u675f\u8d4b\u5f62\u4e0e\u529f\u7387\u5206\u914d\u7b56\u7565\uff0c\u5728\u786e\u4fdd\u611f\u77e5\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u6700\u5927\u5316\u901a\u4fe1\u603b\u548c\u9891\u7387\u5e76\u53d7\u9650\u4e8e\u529f\u7387\u7ea6\u675f\u3002\u4f7f\u7528\u5e7f\u4e49Rayleigh\u5546\uff08GRQ\uff09\u5f97\u5230\u63a5\u6536\u6ce2\u675f\u5f62\u6210\u7684\u95ed\u5f0f\u89e3\uff0c\u968f\u540e\u901a\u8fc7\u6d6e\u70b9\u9057\u4f20\u7b97\u6cd5\uff08GA\uff09\u4f18\u5316\u53d1\u9001\u6ce2\u675f\u548c\u529f\u7387\u5206\u914d\u3002\u7ed3\u679c\u663e\u793a\u76f8\u6bd4\u534a\u53cc\u5de5ISAC\u7cfb\u7edf\uff0cGA\u89e3\u5728\u603b\u548c\u901f\u7387\u65b9\u9762\u63d0\u5347\u53ef\u8fbe\u7ea698%\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u7b97\u6cd5\uff0c\u540c\u65f6\u7ed9\u51fa\u5bf9\u611f\u77e5\u6027\u80fd\u5bf9\u6ce2\u675f\u5f62\u72b6\u548c\u591a\u76ee\u6807\u573a\u666f\u4e0b\u901a\u4fe1-\u611f\u77e5\u6743\u8861\u7684\u6d1e\u5bdf\u3002", "motivation": "\u5728\u540c\u65f6\u8fdb\u884c\u9ad8\u6548\u901a\u4fe1\u4e0e\u76ee\u6807\u611f\u77e5\u7684ISAC\u7cfb\u7edf\u4e2d\uff0c\u9700\u8981\u5728\u6709\u9650\u8d44\u6e90\u4e0b\u5b9e\u73b0\u9ad8\u8d28\u91cf\u670d\u52a1\u548c\u7cbe\u51c6\u611f\u77e5\u3002FD ISAC\u7cfb\u7edf\u9762\u4e34\u81ea\u5e72\u6270\u548c\u590d\u6742\u7684\u591a\u76ee\u6807/\u591a\u7528\u6237\u6ce2\u675f\u4f18\u5316\u95ee\u9898\u3002\u901a\u8fc7\u5c06\u63a5\u6536\u6ce2\u675f\u5f62\u6210\u7684\u6c42\u89e3\u8f6c\u5316\u4e3a\u95ed\u5f0fGRQ\uff0c\u5e76\u7528GA\u89e3\u51b3\u53d1\u9001\u7aef\u7684\u975e\u7ebf\u6027\u4f18\u5316\uff0c\u4ece\u800c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u5efa\u7acb\u4e00\u4e2aFD ISAC\u7cfb\u7edf\u6a21\u578b\uff0c\u9488\u5bf9\u4e0b\u884c/\u4e0a\u884c\u591a\u7528\u6237\u4e0e\u591a\u76ee\u6807\u573a\u666f\u3002\u63a5\u6536\u7aef\u6ce2\u675f\u5f62\u6210\u901a\u8fc7\u5e7f\u4e49Rayleigh\u5546\u5f97\u5230\u95ed\u5f0f\u89e3\uff0c\u7b80\u5316\u4f18\u5316\u53d8\u91cf\u3002\u53d1\u9001\u7aef\u901a\u8fc7\u6d6e\u70b9\u9057\u4f20\u7b97\u6cd5\u5728\u529f\u7387\u548c\u6ce2\u675f\u5411\u91cf\u4e4b\u95f4\u641c\u7d22\u6700\u4f18\u89e3\uff0c\u4ee5\u6700\u5927\u5316\u901a\u4fe1\u603b\u548c\u901f\u7387\u5e76\u6ee1\u8db3\u529f\u7387\u9650\u5236\uff0c\u540c\u65f6\u517c\u987e\u611f\u77e5\u6027\u80fd\u6307\u6807\u3002", "result": "\u6240\u63d0\u51fa\u7684GA-based\u6c42\u89e3\u7b56\u7565\u5728\u6570\u503c\u5b9e\u9a8c\u4e2d\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u534a\u53cc\u5de5ISAC\u7cfb\u7edf\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u603b\u548c\u901f\u7387\u63d0\u5347\uff08\u9ad8\u8fbe\u7ea698%\uff09\uff0c\u4ea6\u4f18\u4e8e\u6587\u732e\u4e2d\u7684\u57fa\u51c6\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u7ed3\u679c\u63ed\u793a\u611f\u77e5\u6027\u80fd\u5bf9\u6ce2\u675f\u6a21\u5f0f\u548c\u591a\u76ee\u6807\u573a\u666f\u4e0b\u7684\u901a\u4fe1-\u611f\u77e5\u6743\u8861\u3002", "conclusion": "\u901a\u8fc7\u5c06\u95ed\u5f0f\u63a5\u6536\u6ce2\u675f\u5f62\u6210\u4e0e\u5168\u5c40\u641c\u7d22\u7684GA\u4f18\u5316\u76f8\u7ed3\u5408\uff0c\u672c\u6587\u5b9e\u73b0\u4e86FD ISAC\u7cfb\u7edf\u5728\u591a\u7528\u6237\u591a\u76ee\u6807\u573a\u666f\u4e0b\u7684\u9ad8\u6548\u6ce2\u675f\u8bbe\u8ba1\u4e0e\u529f\u7387\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u901a\u4fe1\u6027\u80fd\u5e76\u63d0\u4f9b\u611f\u77e5-\u901a\u4fe1\u4e4b\u95f4\u7684\u6743\u8861\u6d1e\u5bdf\u3002"}}
{"id": "2510.24141", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.24141", "abs": "https://arxiv.org/abs/2510.24141", "authors": ["Miao Zhang", "Shenao Wang", "Guilin Zheng", "Yanjie Zhao", "Haoyu Wang"], "title": "Demystifying Cookie Sharing Risks in WebView-based Mobile App-in-app Ecosystems", "comment": "To appear in the 40th IEEE/ACM International Conference on Automated\n  Software Engineering (ASE'25)", "summary": "Mini-programs, an emerging mobile application paradigm within super-apps,\noffer a seamless and installation-free experience. However, the adoption of the\nweb-view component has disrupted their isolation mechanisms, exposing new\nattack surfaces and vulnerabilities. In this paper, we introduce a novel\nvulnerability called Cross Mini-program Cookie Sharing (CMCS), which arises\nfrom the shared web-view environment across mini-programs. This vulnerability\nallows unauthorized data exchange across mini-programs by enabling one\nmini-program to access cookies set by another within the same web-view context,\nviolating isolation principles. As a preliminary step, we analyzed the web-view\nmechanisms of four major platforms, including WeChat, AliPay, TikTok, and\nBaidu, and found that all of them are affected by CMCS vulnerabilities.\nFurthermore, we demonstrate the collusion attack enabled by CMCS, where\nprivileged mini-programs exfiltrate sensitive user data via cookies accessible\nto unprivileged mini-programs. To measure the impact of collusion attacks\nenabled by CMCS vulnerabilities in the wild, we developed MiCoScan, a static\nanalysis tool that detects mini-programs affected by CMCS vulnerabilities.\nMiCoScan employs web-view context modeling to identify clusters of\nmini-programs sharing the same web-view domain and cross-webview data flow\nanalysis to detect sensitive data transmissions to/from web-views. Using\nMiCoScan, we conducted a large-scale analysis of 351,483 mini-programs,\nidentifying 45,448 clusters sharing web-view domains, 7,965 instances of\nprivileged data transmission, and 9,877 mini-programs vulnerable to collusion\nattacks. Our findings highlight the widespread prevalence and significant\nsecurity risks posed by CMCS vulnerabilities, underscoring the urgent need for\nimproved isolation mechanisms in mini-program ecosystems.", "AI": {"tldr": "CMCS \u8de8\u5c0f\u7a0b\u5e8f Cookie \u5171\u4eab\u6f0f\u6d1e\u63ed\u793a web-view \u5171\u4eab\u5bfc\u81f4\u7684\u9694\u79bb\u7834\u574f\uff0c\u5f71\u54cd\u591a\u5e73\u53f0\uff1b\u63d0\u51fa MiCoScan \u9759\u6001\u5206\u6790\u5de5\u5177\uff0c\u5b8c\u6210\u5927\u89c4\u6a21\u6d4b\u91cf\u3002", "motivation": "mini-program \u5728\u8d85\u5e94\u7528\u4e2d\u5e7f\u6cdb\u5e94\u7528\u4e14\u65e0\u9700\u5b89\u88c5\uff0c\u4f46 web-view \u5171\u4eab\u73af\u5883\u5f15\u5165\u8de8\u57df cookies \u8bbf\u95ee\u98ce\u9669\uff0c\u5a01\u80c1\u7528\u6237\u9690\u79c1\u548c\u5c0f\u7a0b\u5e8f\u751f\u6001\u5b89\u5168\u3002", "method": "\u5bf9\u5fae\u4fe1\u3001\u652f\u4ed8\u5b9d\u3001\u6296\u97f3\u3001\u767e\u5ea6\u56db\u5927\u5e73\u53f0\u7684 web-view \u673a\u5236\u8fdb\u884c\u5206\u6790\uff1b\u5b9a\u4e49 CMCS \u6f0f\u6d1e\uff1b\u5b9e\u73b0 MiCoScan\uff0c\u57fa\u4e8e web-view \u4e0a\u4e0b\u6587\u5efa\u6a21\u4e0e\u8de8-webview \u6570\u636e\u6d41\u5206\u6790\uff1b\u5bf9 351,483 \u4e2a\u5c0f\u7a0b\u5e8f\u8fdb\u884c\u9759\u6001\u5206\u6790\u3002", "result": "\u56db\u4e2a\u5e73\u53f0\u5747\u5b58\u5728 CMCS; \u53d1\u73b0 45,448 \u4e2a\u5171\u4eab web-view \u57df\u7684\u96c6\u7fa4\uff0c7,965 \u4e2a\u5177\u5907\u7279\u6743\u6570\u636e\u4f20\u8f93\u7684\u5b9e\u4f8b\uff0c9,877 \u4e2a\u6613\u53d7 collusion \u653b\u51fb\u7684\u5c0f\u7a0b\u5e8f\u3002", "conclusion": "CMCS \u6f5c\u5728\u5e7f\u6cdb\u4e14\u98ce\u9669\u663e\u8457\uff0c\u8feb\u5207\u9700\u8981\u5728\u5c0f\u7a0b\u5e8f\u751f\u6001\u5c42\u9762\u6539\u8fdb\u9694\u79bb\u673a\u5236\u548c\u6570\u636e\u8bbf\u95ee\u63a7\u5236\u3002"}}
{"id": "2510.23634", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23634", "abs": "https://arxiv.org/abs/2510.23634", "authors": ["Soutrik Sarangi", "Yonatan Sverdlov", "Nadav Dym", "Abir De"], "title": "Monotone and Separable Set Functions: Characterizations and Neural Models", "comment": null, "summary": "Motivated by applications for set containment problems, we consider the\nfollowing fundamental problem: can we design set-to-vector functions so that\nthe natural partial order on sets is preserved, namely $S\\subseteq T \\text{ if\nand only if } F(S)\\leq F(T) $. We call functions satisfying this property\nMonotone and Separating (MAS) set functions. % We establish lower and upper\nbounds for the vector dimension necessary to obtain MAS functions, as a\nfunction of the cardinality of the multisets and the underlying ground set. In\nthe important case of an infinite ground set, we show that MAS functions do not\nexist, but provide a model called our which provably enjoys a relaxed MAS\nproperty we name \"weakly MAS\" and is stable in the sense of Holder continuity.\nWe also show that MAS functions can be used to construct universal models that\nare monotone by construction and can approximate all monotone set functions.\nExperimentally, we consider a variety of set containment tasks. The experiments\nshow the benefit of using our our model, in comparison with standard set models\nwhich do not incorporate set containment as an inductive bias. Our code is\navailable in https://github.com/yonatansverdlov/Monotone-Embedding.", "AI": {"tldr": "\u7814\u7a76\u5982\u4f55\u8bbe\u8ba1\u96c6\u5408\u5230\u5411\u91cf\u7684\u6620\u5c04\uff0c\u4f7f\u96c6\u5408\u5305\u542b\u5173\u7cfb\u5728\u5411\u91cf\u7a7a\u95f4\u4e2d\u5f97\u5230\u7b49\u4ef7\u8868\u8fbe\uff08S \u2286 T \u5f53\u4e14\u4ec5\u5f53 F(S) \u2264 F(T)\uff09\uff0c\u79f0\u4e3a\u5355\u8c03\u4e14\u53ef\u5206\u79bb\uff08MAS\uff09\u7684\u96c6\u5408\u51fd\u6570\u3002\u4f5c\u8005\u7ed9\u51fa\u5173\u4e8e\u5b9e\u73b0MAS\u7684\u5411\u91cf\u7ef4\u5ea6\u4e0a\u4e0b\u754c\uff0c\u8bc1\u660e\u5728\u65e0\u7a77\u5e95\u96c6\u65f6\u4e0d\u5b58\u5728MAS\u51fd\u6570\uff0c\u4f46\u7ed9\u51fa\u4e00\u79cd\u677e\u5f1b\u6a21\u578b\u201cweakly MAS\u201d\u7684\u5b9e\u73b0\uff0c\u5e76\u5177\u6709Holder\u8fde\u7eed\u6027\u7684\u7a33\u5b9a\u6027\u3002\u8fd8\u63d0\u51fa\u5229\u7528MAS\u6784\u5efa\u7684\u901a\u7528\u6a21\u578b\uff0c\u5e76\u80fd\u8fd1\u4f3c\u6240\u6709\u5355\u8c03\u7684\u96c6\u5408\u51fd\u6570\u3002\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5728\u96c6\u5408\u5305\u542b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4e0d\u5e26\u6b64\u504f\u7f6e\u7684\u6807\u51c6\u96c6\u5408\u6a21\u578b\uff0c\u4e14\u7ed9\u51fa\u4e86\u5f00\u6e90\u5b9e\u73b0\u3002", "motivation": "\u52a8\u673a\u662f\u5728\u96c6\u5408\u5305\u542b\u95ee\u9898\u7684\u5e94\u7528\u80cc\u666f\u4e0b\uff0c\u5bfb\u627e\u80fd\u591f\u4fdd\u6301\u96c6\u5408\u4e4b\u95f4\u90e8\u5206\u5e8f\u5173\u7cfb\u7684\u96c6\u5408\u5230\u5411\u91cf\u6620\u5c04\uff0c\u4ee5\u4fbf\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4f7f\u7528\u8fde\u7eed\u4f18\u5316\u6216\u5b66\u4e60\u6a21\u578b\u3002", "method": "\u7ed9\u51fa\u96c6\u5408\u7ef4\u5ea6\u4e0e\u591a\u91cd\u96c6\u5408\u57fa\u6570\u7684\u4e0a\u4e0b\u754c\uff1b\u8bc1\u660e\u5728\u65e0\u9650\u5e95\u96c6\u60c5\u51b5\u4e0b\u4e0d\u5b58\u5728\u4e25\u683c\u7684MAS\u51fd\u6570\uff1b\u63d0\u51fa\u4e00\u4e2a\u540d\u4e3a\u201cour model\u201d\u7684\u677e\u5f1b\u6a21\u578b\uff0c\u5b9e\u73b0\u5f31MAS\u5e76\u5177Holder\u8fde\u8d2f\u6027\uff1b\u6784\u9020\u53ef\u4ee5\u5355\u8c03\u5730\u6784\u9020\u5e76\u8fd1\u4f3c\u4efb\u610f\u5355\u8c03\u96c6\u5408\u51fd\u6570\u7684\u901a\u7528\u6a21\u578b\uff1b\u8fdb\u884c\u591a\u4efb\u52a1\u5b9e\u9a8c\u6bd4\u8f83\uff0c\u63d0\u4f9b\u5b9e\u73b0\u4ee3\u7801\u3002", "result": "\u7ed9\u51faMAS\u7ef4\u5ea6\u754c\u3001\u65e0\u7a77\u5e95\u96c6\u4e0b\u7684\u4e0d\u53ef\u884c\u6027\u3001\u5f31MAS\u6a21\u578b\u53ca\u5176\u7a33\u5b9a\u6027\u3001\u53ef\u7528\u4e8e\u8fd1\u4f3c\u6240\u6709\u5355\u8c03\u96c6\u5408\u51fd\u6570\u7684\u901a\u7528\u6a21\u578b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u504f\u7f6e\u6709\u76ca\uff0c\u4ee3\u7801\u516c\u5f00\u3002", "conclusion": "\u5728\u65e0\u7a77\u5e95\u96c6\u60c5\u5f62\u4e0b\u4e25\u683c\u7684MAS\u4e0d\u53ef\u884c\uff0c\u4f46\u901a\u8fc7\u5f31MAS\u7b49\u677e\u5f1b\u5b9a\u4e49\u53ef\u83b7\u5f97\u5b9e\u7528\u6027\u5f3a\u7684\u6a21\u578b\uff0c\u4e14\u53ef\u7528\u4e8e\u903c\u8fd1\u4e0e\u4fdd\u6301\u96c6\u5408\u5305\u542b\u5173\u7cfb\u7684\u4efb\u52a1\uff1b\u672a\u6765\u5de5\u4f5c\u53ef\u80fd\u96c6\u4e2d\u5728\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684\u96c6\u5408\u64cd\u4f5c\u4e0e\u5206\u6790\u6536\u655b\u6027\u3002"}}
{"id": "2510.24255", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24255", "abs": "https://arxiv.org/abs/2510.24255", "authors": ["Jihao Luo", "Zesong Fei", "Xinyi Wang", "Le Zhao", "Yuanhao Cui", "Guangxu Zhu", "Dusit Niyato"], "title": "Trajectory Design for UAV-Based Low-Altitude Wireless Networks in Unknown Environments: A Digital Twin-Assisted TD3 Approach", "comment": "13 pages, 11 figures", "summary": "Unmanned aerial vehicles (UAVs) are emerging as key enablers for low-altitude\nwireless network (LAWN), particularly when terrestrial networks are\nunavailable. In such scenarios, the environmental topology is typically\nunknown; hence, designing efficient and safe UAV trajectories is essential yet\nchallenging. To address this, we propose a digital twin (DT)-assisted training\nand deployment framework. In this framework, the UAV transmits integrated\nsensing and communication signals to provide communication services to ground\nusers, while simultaneously collecting echoes that are uploaded to the DT\nserver to progressively construct virtual environments (VEs). These VEs\naccelerate model training and are continuously updated with real-time UAV\nsensing data during deployment, supporting decision-making and enhancing flight\nsafety. Based on this framework, we further develop a trajectory design scheme\nthat integrates simulated annealing for efficient user scheduling with the\ntwin-delayed deep deterministic policy gradient algorithm for continuous\ntrajectory design, aiming to minimize mission completion time while ensuring\nobstacle avoidance. Simulation results demonstrate that the proposed approach\nachieves faster convergence, higher flight safety, and shorter mission\ncompletion time compared with baseline methods, providing a robust and\nefficient solution for LAWN deployment in unknown environments.", "AI": {"tldr": "A digital twin (DT)-assisted framework enables UAVs to operate in unknown low-altitude wireless networks by building virtual environments from sensed echoes and using them for training and deployment; it combines simulated annealing-based user scheduling with twin-delayed DDPG for continuous trajectory optimization to minimize mission time while avoiding obstacles.", "motivation": "In unknown topologies, reliable UAV trajectory design for LAWN is difficult due to lack of environmental knowledge. A DT approach can progressively construct virtual environments from UAV sensing data, accelerating learning, enhancing decision-making, and improving flight safety.", "method": "UAVs transmit integrated sensing and communication signals to serve ground users while collecting echoes that are uploaded to a DT server to progressively construct virtual environments. These VEs are updated in real time with new sensing data to support decision-making and safety. The trajectory design uses simulated annealing for user scheduling and twin-delayed deep deterministic policy gradient (TD3) for continuous trajectory control, aiming to minimize mission completion time with obstacle avoidance.", "result": "Simulation results show faster convergence, improved flight safety, and shorter mission completion time compared with baseline methods, indicating a robust and efficient solution for LAWN deployment in unknown environments.", "conclusion": "A DT-assisted training and deployment framework can effectively enable safe, efficient, and rapid UAV operations for LAWN in unknown environments by leveraging real-time sensing, VE construction, and hybrid optimization for trajectory planning."}}
{"id": "2510.24272", "categories": ["eess.SY", "cs.AI", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24272", "abs": "https://arxiv.org/abs/2510.24272", "authors": ["Maximilian Bloor", "Max Mowbray", "Ehecatl Antonio Del Rio Chanona", "Calvin Tsay"], "title": "Survey and Tutorial of Reinforcement Learning Methods in Process Systems Engineering", "comment": null, "summary": "Sequential decision making under uncertainty is central to many Process\nSystems Engineering (PSE) challenges, where traditional methods often face\nlimitations related to controlling and optimizing complex and stochastic\nsystems. Reinforcement Learning (RL) offers a data-driven approach to derive\ncontrol policies for such challenges. This paper presents a survey and tutorial\non RL methods, tailored for the PSE community. We deliver a tutorial on RL,\ncovering fundamental concepts and key algorithmic families including\nvalue-based, policy-based and actor-critic methods. Subsequently, we survey\nexisting applications of these RL techniques across various PSE domains, such\nas in fed-batch and continuous process control, process optimization, and\nsupply chains. We conclude with PSE focused discussion of specialized\ntechniques and emerging directions. By synthesizing the current state of RL\nalgorithm development and implications for PSE this work identifies successes,\nchallenges, trends, and outlines avenues for future research at the interface\nof these fields.", "AI": {"tldr": "\u5bf9\u5f3a\u5316\u5b66\u4e60\u5728\u8fc7\u7a0b\u7cfb\u7edf\u5de5\u7a0b\uff08PSE\uff09\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u7cfb\u7edf\u6027\u7efc\u8ff0\u4e0e\u6559\u7a0b\uff0c\u5305\u62ec\u57fa\u7840\u6982\u5ff5\u3001\u4e3b\u6d41\u7b97\u6cd5\u65cf\u53ca\u5728\u53d1\u9175\u6279\u6b21/\u8fde\u7eed\u8fc7\u7a0b\u63a7\u5236\u3001\u8fc7\u7a0b\u4f18\u5316\u4e0e\u4f9b\u5e94\u94fe\u7b49\u9886\u57df\u7684\u5e94\u7528\uff0c\u5e76\u5bf9\u672a\u6765\u7814\u7a76\u65b9\u5411\u8fdb\u884c\u68b3\u7406\u3002", "motivation": "\u5728\u9ad8\u4e0d\u786e\u5b9a\u6027\u548c\u590d\u6742\u6027\u7684\u8fc7\u7a0b\u7cfb\u7edf\u4e2d\uff0c\u4f20\u7edf\u65b9\u6cd5\u5f80\u5f80\u96be\u4ee5\u6709\u6548\u63a7\u5236\u4e0e\u4f18\u5316\uff1bRL\u63d0\u4f9b\u6570\u636e\u9a71\u52a8\u7684\u7b56\u7565\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff1b\u9700\u8981\u9762\u5411PSE\u793e\u533a\u7cfb\u7edf\u6574\u5408\u73b0\u6709RL\u8fdb\u5c55\u3002", "method": "\u901a\u8fc7\u8bb2\u89e3\u57fa\u7840\u6982\u5ff5\u3001\u6309\u4ef7\u503c\u57fa\u7840\u3001\u7b56\u7565\u57fa\u7840\u3001\u4ee5\u53caactor-critic\u7b49\u7b97\u6cd5\u65cf\u7ec4\u7ec7\u6559\u7a0b\uff1b\u7cfb\u7edf\u6027\u7efc\u8ff0\u5df2\u6709\u5728PSE\u9886\u57df\u7684\u5e94\u7528\uff1b\u8ba8\u8bba\u4e13\u95e8\u6280\u672f\u4e0e\u65b0\u5174\u65b9\u5411\u3002", "result": "\u63d0\u4f9b\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u77e5\u8bc6\u68b3\u7406\uff0c\u7efc\u5408\u6210\u529f\u7ecf\u9a8c\u3001\u6311\u6218\u3001\u8d8b\u52bf\uff0c\u5e76\u63d0\u51fa\u9762\u5411PSE\u7684\u672a\u6765\u7814\u7a76\u8def\u7ebf\u4e0e\u5b9e\u8df5\u5efa\u8bae\u3002", "conclusion": "RL\u5177\u5907\u5728PSE\u4e2d\u5f00\u53d1\u6570\u636e\u9a71\u52a8\u63a7\u5236\u7b56\u7565\u7684\u6f5c\u529b\uff0c\u9700\u8fdb\u4e00\u6b65\u5bf9\u63a5PSE\u5177\u4f53\u573a\u666f\uff0c\u8bc6\u522b\u5e76\u586b\u8865\u7814\u7a76\u7a7a\u767d\uff0c\u63a8\u52a8\u4e24\u9886\u57df\u7684\u6df1\u5ea6\u878d\u5408\u3002"}}
{"id": "2510.23635", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23635", "abs": "https://arxiv.org/abs/2510.23635", "authors": ["Andrea Bontempelli", "Matteo Busso", "Leonardo Javier Malcotti", "Fausto Giunchiglia"], "title": "Help the machine to help you: an evaluation in the wild of egocentric data cleaning via skeptical learning", "comment": null, "summary": "Any digital personal assistant, whether used to support task performance,\nanswer questions, or manage work and daily life, including fitness schedules,\nrequires high-quality annotations to function properly. However, user\nannotations, whether actively produced or inferred from context (e.g., data\nfrom smartphone sensors), are often subject to errors and noise. Previous\nresearch on Skeptical Learning (SKEL) addressed the issue of noisy labels by\ncomparing offline active annotations with passive data, allowing for an\nevaluation of annotation accuracy. However, this evaluation did not include\nconfirmation from end-users, the best judges of their own context. In this\nstudy, we evaluate SKEL's performance in real-world conditions with actual\nusers who can refine the input labels based on their current perspectives and\nneeds. The study involves university students using the iLog mobile application\non their devices over a period of four weeks. The results highlight the\nchallenges of finding the right balance between user effort and data quality,\nas well as the potential benefits of using SKEL, which include reduced\nannotation effort and improved quality of collected data.", "AI": {"tldr": "\u5728\u771f\u5b9e\u7528\u6237\u6761\u4ef6\u4e0b\u8bc4\u4f30 Skeptical Learning (SKEL) \u5bf9\u566a\u58f0\u6807\u6ce8\u7684\u9c81\u68d2\u6027\uff0c\u7ed3\u679c\u8868\u660e\u5728\u5e73\u8861\u7528\u6237\u52aa\u529b\u4e0e\u6570\u636e\u8d28\u91cf\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u4f46 SKEL \u5177\u6709\u964d\u4f4e\u6807\u6ce8\u5de5\u4f5c\u91cf\u5e76\u63d0\u5347\u6570\u636e\u8d28\u91cf\u7684\u6f5c\u529b\u3002", "motivation": "\u6570\u5b57\u4e2a\u4eba\u52a9\u7406\u9700\u8981\u9ad8\u8d28\u91cf\u6807\u6ce8\u6765\u652f\u6301\u4efb\u52a1\u6267\u884c\u3001\u95ee\u7b54\u4e0e\u65e5\u5e38\u751f\u6d3b\u7ba1\u7406\u3002\u7528\u6237\u6807\u6ce8\u5bb9\u6613\u5e26\u5165\u566a\u58f0\u4e0e\u9519\u8bef\uff0c\u4e14\u4ee5\u5f80\u5bf9\u566a\u58f0\u6807\u7b7e\u7684\u7814\u7a76\uff08SKEL\uff09\u57fa\u4e8e\u79bb\u7ebf\u5bf9\u6bd4\uff0c\u7f3a\u4e4f\u7528\u6237\u7aef\u7684\u786e\u8ba4\u3002\u672c\u6587\u65e8\u5728\u5728\u771f\u5b9e\u4e16\u754c\u60c5\u5883\u4e2d\uff0c\u9080\u8bf7\u6700\u7ec8\u7528\u6237\u5bf9\u6807\u7b7e\u8fdb\u884c\u786e\u8ba4\u4e0e refinement\uff0c\u4ee5\u8bc4\u4f30 SKEL \u7684\u5b9e\u9645\u6548\u679c\u3002", "method": "\u5728\u56db\u5468\u7684\u65f6\u95f4\u91cc\uff0c\u8ba9\u5927\u5b66\u751f\u4f7f\u7528 iLog \u79fb\u52a8\u5e94\u7528\uff0c\u4e0e\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u4ea4\u4e92\uff0c\u5e76\u8ba9\u7528\u6237\u5728\u8f93\u5165\u6807\u7b7e\u65f6\u5bf9\u4fe1\u606f\u8fdb\u884c\u786e\u8ba4\u548c refinement\uff0c\u4ee5\u8bc4\u4f30 SKEL \u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u8868\u73b0\u53ca\u5bf9\u6807\u6ce8\u52aa\u529b\u4e0e\u6570\u636e\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u63ed\u793a\u5728\u7528\u6237\u6295\u5165\uff08\u52aa\u529b\uff09\u4e0e\u6570\u636e\u8d28\u91cf\u4e4b\u95f4\u9700\u8981\u627e\u5230\u5e73\u8861\u70b9\uff0c\u540c\u65f6\u4f7f\u7528 SKEL \u53ef\u80fd\u964d\u4f4e\u6807\u6ce8\u7684\u5de5\u4f5c\u91cf\u5e76\u63d0\u5347\u6240\u6536\u96c6\u6570\u636e\u7684\u8d28\u91cf\u3002", "conclusion": "\u5728\u5305\u542b\u6700\u7ec8\u7528\u6237\u786e\u8ba4\u7684\u771f\u5b9e\u6761\u4ef6\u4e0b\u8bc4\u4f30 SKEL \u7684\u53ef\u884c\u6027\u548c\u6548\u76ca\u3002\u7ed3\u679c\u8868\u660e SKEL \u5728\u51cf\u5c11\u6807\u6ce8\u8d1f\u62c5\u7684\u540c\u65f6\u53ef\u6539\u5584\u6570\u636e\u8d28\u91cf\uff0c\u4f46\u9700\u6743\u8861\u7528\u6237\u53c2\u4e0e\u6210\u672c\u4e0e\u7cfb\u7edf\u51c6\u786e\u6027\u3002"}}
{"id": "2510.24287", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24287", "abs": "https://arxiv.org/abs/2510.24287", "authors": ["Richard Koebe", "Noah Saibel", "Juan Miguel Lopez Alcaraz", "Simon Sch\u00e4fer", "Nils Strodthoff"], "title": "Towards actionable hypotension prediction- predicting catecholamine therapy initiation in the intensive care unit", "comment": "27 pages, 8 figures, source code under\n  https://github.com/AI4HealthUOL/actionable-hypotension", "summary": "Hypotension in critically ill ICU patients is common and life-threatening.\nEscalation to catecholamine therapy marks a key management step, with both\nundertreatment and overtreatment posing risks. Most machine learning (ML)\nmodels predict hypotension using fixed MAP thresholds or MAP forecasting,\noverlooking the clinical decision behind treatment escalation. Predicting\ncatecholamine initiation, the start of vasoactive or inotropic agent\nadministration offers a more clinically actionable target reflecting real\ndecision-making. Using the MIMIC-III database, we modeled catecholamine\ninitiation as a binary event within a 15-minute prediction window. Input\nfeatures included statistical descriptors from a two-hour sliding MAP context\nwindow, along with demographics, biometrics, comorbidities, and ongoing\ntreatments. An Extreme Gradient Boosting (XGBoost) model was trained and\ninterpreted via SHapley Additive exPlanations (SHAP). The model achieved an\nAUROC of 0.822 (0.813-0.830), outperforming the hypotension baseline (MAP < 65,\nAUROC 0.686 [0.675-0.699]). SHAP analysis highlighted recent MAP values, MAP\ntrends, and ongoing treatments (e.g., sedatives, electrolytes) as dominant\npredictors. Subgroup analysis showed higher performance in males, younger\npatients (<53 years), those with higher BMI (>32), and patients without\ncomorbidities or concurrent medications. Predicting catecholamine initiation\nbased on MAP dynamics, treatment context, and patient characteristics supports\nthe critical decision of when to escalate therapy, shifting focus from\nthreshold-based alarms to actionable decision support. This approach is\nfeasible across a broad ICU cohort under natural event imbalance. Future work\nshould enrich temporal and physiological context, extend label definitions to\ninclude therapy escalation, and benchmark against existing hypotension\nprediction systems.", "AI": {"tldr": "\u5c06\u660f\u8ff7\u3001\u4f4e\u704c\u6ce8\u7b49\u5371\u53ca\u751f\u547d\u7684\u4f4e\u8840\u538b\u95ee\u9898\u4ece\u4f20\u7edf\u7684\u9608\u503c\u9884\u6d4b\u8f6c\u5411\u5bf9\u5347\u538b\u836f\u7269\u542f\u52a8\u7684\u5373\u65f6\u53ef\u884c\u51b3\u7b56\u9884\u6d4b\uff1b\u5229\u7528MIMIC-III\u6570\u636e\u572815\u5206\u949f\u9884\u6d4b\u7a97\u53e3\u5185\uff0c\u5c06\u50ac\u7720\u836f\u7269/\u5347\u538b\u836f\u7269\u542f\u52a8\u4f5c\u4e3a\u4e8c\u5206\u7c7b\u4e8b\u4ef6\u8fdb\u884c\u5efa\u6a21\uff0c\u4f53\u73b0\u4ee5\u6cbb\u7597\u51b3\u7b56\u4e3a\u5bfc\u5411\u7684\u9884\u6d4b\u76ee\u6807\u3002", "motivation": "\u5f53\u524dICU\u4f4e\u8840\u538b\u9884\u6d4b\u591a\u4f9d\u8d56\u56fa\u5b9a\u7684\u5e73\u5747\u52a8\u8109\u538b(MAP)\u9608\u503c\u6216MAP\u9884\u6d4b\uff0c\u672a\u76f4\u63a5\u5bf9\u4e34\u5e8a\u6cbb\u7597 escalations \u8fdb\u884c\u5efa\u6a21\u3002\u56e0\u800c\u5b58\u5728 undertreatment \u4e0e overtreatment \u7684\u98ce\u9669\u3002\u4ee5\u50ac\u5316\u836f\u7269\uff08vasoactive/inotropic\uff09\u542f\u52a8\u4e3a\u76ee\u6807\uff0c\u53ef\u4ee5\u66f4\u8d34\u5408\u4e34\u5e8a\u51b3\u7b56\uff0c\u63d0\u9ad8\u5e72\u9884\u65f6\u673a\u7684\u53ef\u64cd\u4f5c\u6027\u3002", "method": "\u4f7f\u7528\u4e24\u5c0f\u65f6MAP\u4e0a\u4e0b\u6587\u7684\u7edf\u8ba1\u63cf\u8ff0\u7b26\u3001\u4eba\u53e3\u7edf\u8ba1\u3001\u751f\u547d\u4f53\u5f81\u3001\u5171\u75c5\u3001\u6b63\u5728\u8fdb\u884c\u7684\u6cbb\u7597\u7b49\u7279\u5f81\uff1b\u5c06\u50ac\u5316\u836f\u7269\u542f\u52a8\u5b9a\u4e49\u4e3a15\u5206\u949f\u9884\u6d4b\u7a97\u53e3\u5185\u7684\u4e8c\u5206\u7c7b\u4e8b\u4ef6\uff1b\u5728MIMIC-III\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3XGBoost\u6a21\u578b\uff0c\u5e76\u901a\u8fc7SHAP\u8fdb\u884c\u89e3\u91ca\uff1b\u5bf9\u7ed3\u679c\u8fdb\u884c\u5b50\u7ec4\u5206\u6790\u3002", "result": "\u6a21\u578b\u5728AUROC\u4e0a\u8fbe\u52300.822\uff080.813-0.830\uff09\uff0c\u660e\u663e\u4f18\u4e8e\u4ec5\u57fa\u4e8eMAP<65\u7684\u4f4e\u8840\u538b\u57fa\u7ebf\u6a21\u578b\uff08AUROC 0.686 [0.675-0.699]\uff09\u3002SHAP\u663e\u793a\u8fd1\u671fMAP\u6570\u503c\u3001MAP\u8d8b\u52bf\u53ca\u6b63\u5728\u8fdb\u884c\u7684\u6cbb\u7597\uff08\u9547\u9759\u5242\u3001\u7535\u89e3\u8d28\u7b49\uff09\u4e3a\u4e3b\u8981\u9884\u6d4b\u56e0\u7d20\u3002\u7537\u6027\u3001\u5e74\u9f84<53\u5c81\u3001BMI>32\u53ca\u65e0\u5408\u5e76\u75c7/\u65e0\u5e76\u53d1\u836f\u7269\u8005\u5b50\u7ec4\u6027\u80fd\u66f4\u597d\u3002", "conclusion": "\u4ee5MAP\u52a8\u529b\u5b66\u3001\u6cbb\u7597\u80cc\u666f\u4e0e\u60a3\u8005\u7279\u5f81\u6765\u9884\u6d4b\u50ac\u5316\u836f\u7269\u542f\u52a8\uff0c\u80fd\u591f\u63d0\u4f9b\u5bf9\u6cbb\u7597\u5347\u7ea7\u7684\u4e34\u5e8a\u53ef\u64cd\u4f5c\u51b3\u7b56\uff0c\u8d85\u8d8a\u5355\u7eaf\u7684\u9608\u503c\u8b66\u62a5\u3002\u8be5\u65b9\u6cd5\u5728\u81ea\u7136\u4e8b\u4ef6\u4e0d\u5e73\u8861\u7684\u5e7f\u6cdbICU\u961f\u5217\u4e2d\u53ef\u884c\u3002\u672a\u6765\u5de5\u4f5c\u5e94\u4e30\u5bcc\u65f6\u95f4\u4e0e\u751f\u7406\u4e0a\u4e0b\u6587\u3001\u5c06\u6807\u7b7e\u6269\u5c55\u4e3a\u6cbb\u7597\u5347\u7ea7\uff0c\u5e76\u4e0e\u73b0\u6709\u4f4e\u8840\u538b\u9884\u6d4b\u7cfb\u7edf\u8fdb\u884c\u57fa\u51c6\u5bf9\u6bd4\u3002"}}
{"id": "2510.24393", "categories": ["cs.CR", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.24393", "abs": "https://arxiv.org/abs/2510.24393", "authors": ["Yan Meng", "Jiachun Li", "Matthew Pillari", "Arjun Deopujari", "Liam Brennan", "Hafsah Shamsie", "Haojin Zhu", "Yuan Tian"], "title": "Your Microphone Array Retains Your Identity: A Robust Voice Liveness Detection System for Smart Speakers", "comment": "This is a paper accepted by USENIX Security 2022. See:\n  https://www.usenix.org/conference/usenixsecurity22/presentation/meng", "summary": "Though playing an essential role in smart home systems, smart speakers are\nvulnerable to voice spoofing attacks. Passive liveness detection, which\nutilizes only the collected audio rather than the deployed sensors to\ndistinguish between live-human and replayed voices, has drawn increasing\nattention. However, it faces the challenge of performance degradation under the\ndifferent environmental factors as well as the strict requirement of the fixed\nuser gestures.\n  In this study, we propose a novel liveness feature, array fingerprint, which\nutilizes the microphone array inherently adopted by the smart speaker to\ndetermine the identity of collected audios. Our theoretical analysis\ndemonstrates that by leveraging the circular layout of microphones, compared\nwith existing schemes, array fingerprint achieves a more robust performance\nunder the environmental change and user's movement. Then, to leverage such a\nfingerprint, we propose ARRAYID, a lightweight passive detection scheme, and\nelaborate a series of features working together with array fingerprint. Our\nevaluation on the dataset containing 32,780 audio samples and 14 spoofing\ndevices shows that ARRAYID achieves an accuracy of 99.84%, which is superior to\nexisting passive liveness detection schemes.", "AI": {"tldr": "\u5229\u7528\u9ea6\u9635\u5217\u6307\u7eb9\u5b9e\u73b0\u88ab\u52a8\u6d3b\u4f53\u68c0\u6d4b\uff0c\u63d0\u51fa ARRAYID\uff0c\u9c81\u68d2\u6027\u5f3a\u4e14\u51c6\u786e\u7387\u9ad8\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u667a\u80fd\u97f3\u7bb1\u4e2d\uff0c\u58f0\u97f3\u6b3a\u9a97\u653b\u51fb\u666e\u904d\uff0c\u73b0\u6709\u88ab\u52a8\u6d3b\u4f53\u68c0\u6d4b\u53d7\u73af\u5883\u548c\u7528\u6237\u52a8\u4f5c\u5f71\u54cd\u8f83\u5927\uff0c\u9700\u8981\u65e0\u9700\u989d\u5916\u4f20\u611f\u5668\u7684\u9c81\u68d2\u65b9\u6848\u3002", "method": "\u63d0\u51fa array fingerprint \u57fa\u4e8e\u5706\u5f62\u9ea6\u9635\u5217\u7684\u7279\u5f81\uff0c\u5e76\u8bbe\u8ba1 ARRAYID \u7cfb\u7edf\u4ee5\u7ed3\u5408\u591a\u79cd\u7279\u5f81\u5b9e\u73b0\u8f7b\u91cf\u88ab\u52a8\u68c0\u6d4b\u3002", "result": "\u5728\u5305\u542b 32780 \u6761\u6837\u672c\u300114 \u79cd spoofing \u8bbe\u5907\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u51c6\u786e\u7387\u8fbe\u5230 99.84%\uff0c\u4f18\u4e8e\u73b0\u6709\u88ab\u52a8\u68c0\u6d4b\u65b9\u6848\u3002", "conclusion": "\u9ea6\u9635\u5217\u6307\u7eb9\u63d0\u4f9b\u7a33\u5065\u7684\u73af\u5883\u548c\u7528\u6237\u79fb\u52a8\u9c81\u68d2\u6027\uff0c\u663e\u793a\u51fa\u5b9e\u9645\u53ef\u843d\u5730\u7684\u88ab\u52a8\u6d3b\u4f53\u68c0\u6d4b\u6f5c\u529b\uff1b\u672a\u6765\u5de5\u4f5c\u53ef\u5173\u6ce8\u66f4\u5e7f\u6cdb\u8bbe\u5907\u548c\u573a\u666f\u7684\u6cdb\u5316\u3002"}}
{"id": "2510.23636", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23636", "abs": "https://arxiv.org/abs/2510.23636", "authors": ["Thaweerath Phisannupawong", "Joshua Julian Damanik", "Han-Lim Choi"], "title": "Flight Delay Prediction via Cross-Modality Adaptation of Large Language Models and Aircraft Trajectory Representation", "comment": "Preprint submitted to Aerospace Science and Technology (Elsevier) for\n  possible publication", "summary": "Flight delay prediction has become a key focus in air traffic management, as\ndelays highlight inefficiencies that impact overall network performance. This\npaper presents a lightweight large language model-based multimodal flight delay\nprediction, formulated from the perspective of air traffic controllers\nmonitoring aircraft delay after entering the terminal area. The approach\nintegrates trajectory representations with textual aeronautical information,\nincluding flight information, weather reports, and aerodrome notices, by\nadapting trajectory data into the language modality to capture airspace\nconditions. Experimental results show that the model consistently achieves\nsub-minute prediction error by effectively leveraging contextual information\nrelated to the sources of delay. The framework demonstrates that linguistic\nunderstanding, when combined with cross-modality adaptation of trajectory\ninformation, enhances delay prediction. Moreover, the approach shows\npracticality and scalability for real-world operations, supporting real-time\nupdates that refine predictions upon receiving new operational information.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6a21\u6001\u822a\u73ed\u5ef6\u8bef\u9884\u6d4b\u6846\u67b6\uff0c\u5c06\u8f68\u8ff9\u6570\u636e\u8f6c\u5316\u4e3a\u8bed\u8a00\u6a21\u6001\u5e76\u4e0e\u6587\u672c\u822a\u884c\u60c5\u62a5\u3001\u5929\u6c14\u548c\u673a\u573a\u516c\u544a\u878d\u5408\uff0c\u5b9e\u73b0\u4e9a\u5206\u949f\u7ea7\u8bef\u5dee\u5e76\u5177\u5907\u5b9e\u65f6\u66f4\u65b0\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u822a\u8def\u7ba1\u7406\u4e2d\u7684\u5ef6\u8bef\u5e26\u6765\u7684\u6548\u7387\u635f\u5931\uff1b\u9700\u8981\u5728\u5854\u53f0\u533a\u57df\u5185\u5bf9\u8fdb\u5165\u4fe1\u606f\u7684\u65f6\u5e8f\u4e0e\u73af\u5883\u4fe1\u606f\u4f5c\u51fa\u5b9e\u65f6\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u9884\u6d4b\u3002", "method": "\u5c06\u8f68\u8ff9\u6570\u636e\u8f6c\u5316\u4e3a\u8bed\u8a00\u6a21\u6001\uff0c\u4e0e\u98de\u884c\u4fe1\u606f\u3001\u5929\u6c14\uff08METAR/TAF\uff09\u548cNOTAM\u7b49\u6587\u672c\u4fe1\u606f\u8fdb\u884c\u8de8\u6a21\u6001\u878d\u5408\uff1b\u5bf9\u8f68\u8ff9-\u8bed\u8a00\u7684\u8de8\u6a21\u6001\u9002\u914d\uff1b\u91c7\u7528\u8f7b\u91cf\u7ea7LLM\u5b9e\u73b0\u5b9e\u65f6\u63a8\u7406\u5e76\u652f\u6301\u65b0\u4fe1\u606f\u7684\u589e\u91cf\u66f4\u65b0\uff1b\u5728\u4eff\u771f/\u5b9e\u9645\u6570\u636e\u4e0a\u8bc4\u4f30\u3002", "result": "\u5728\u591a\u6a21\u6001\u878d\u5408\u4e0b\u5b9e\u73b0\u7a33\u5065\u7684\u4e9a\u5206\u949f\u7ea7\u9884\u6d4b\u8bef\u5dee\uff0c\u5145\u5206\u5229\u7528\u5ef6\u8fdf\u6765\u6e90\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u663e\u793a\u51fa\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u65f6\u66f4\u65b0\u80fd\u529b\u3002", "conclusion": "\u8bed\u8a00\u7406\u89e3\u4e0e\u8f68\u8ff9\u4fe1\u606f\u7684\u8de8\u6a21\u6001\u9002\u914d\u76f8\u7ed3\u5408\u80fd\u63d0\u5347\u5ef6\u8bef\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u64cd\u4f5c\u6027\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u6f5c\u529b\u3002"}}
{"id": "2510.24350", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24350", "abs": "https://arxiv.org/abs/2510.24350", "authors": ["Yiming Zhu", "Zhuhong Zhu", "Xiaodong Xu", "Hongwei Hou", "Wenjin Wang", "Rui Ding"], "title": "Achieving Constant-Envelope Waveform in CP-OFDMA Framework", "comment": "This work will be submitted to the IEEE for possible publication", "summary": "OFDM is widely adopted in modern wireless communication systems, but its\npower efficiency is limited by high envelope fluctuations. Although various\nhigh power-efficiency waveforms have been proposed, most are incompatible with\nthe CP-OFDMA framework and remain ineffective in multi-user downlink\ntransmissions. To address this issue, we propose a constant-envelope (CE)\nwaveform design, which enables low-complexity transceiver architectures while\nmaintaining full compatibility with the prevailing CP-OFDMA framework.\nSpecifically, we start from a general CE FDMA signal model and develop a\nCP-OFDMA-compatible waveform implementation structure, followed by the design\nof an optimized CE-constrained pulse-shaping filter to suppress out-of-band\nemissions. To tackle channel estimation challenge under non-flat\nfrequency-domain pilots induced by CE modulation, we optimize the time-domain\nbinary pilot sequence to achieve frequency-domain CE properties, and then\npropose a multi-stage method combining delay-domain denoising with power delay\nprofile estimation to facilitate reduced-dimension LMMSE estimation.\nSubsequently, we design a low-complexity maximum ratio combining-aided LMMSE\nequalizer by exploiting the periodicity and conjugate symmetry of the CE\nreceived signals. To mitigate the downlink peak-to-average power ratio increase\ncaused by FDMA, we further develop a multi-user downlink CE transmission scheme\nincluding multiple access mechanism, downlink control information design, and\ncorresponding system-level implementation, which ensures compatibility with the\nNew Radio standard. Numerical results demonstrate that the proposed scheme\nachieves bit error rate performance close to the ideal case while significantly\nreducing transceiver complexity compared to existing CE waveform solutions.", "AI": {"tldr": "\u63d0\u51fa\u4e0eCP-OFDMA\u517c\u5bb9\u7684\u6052\u5305\u7edcCE\u6ce2\u5f62\uff0c\u63d0\u5347\u529f\u7387\u6548\u7387\u5e76\u964d\u4f4e\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u8986\u76d6\u591a\u7528\u6237\u4e0b\u884c\u573a\u666f\u3002", "motivation": "OFDM\u6613\u4ea7\u751f\u9ad8\u5305\u7edc\u5cf0\u503c\uff0c\u964d\u4f4e\u529f\u7387\u653e\u5927\u5668\u6548\u7387\uff1b\u73b0\u6709\u9ad8\u6548\u6ce2\u5f62\u591a\u4e0eCP-OFDMA\u4e0d\u517c\u5bb9\uff0c\u9700\u4e00\u79cd\u5728\u4fdd\u6301CP-OFDMA\u6846\u67b6\u4e0b\u7684CE\u6ce2\u5f62\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u591a\u7528\u6237\u4e0b\u884c\u548cNR\u6807\u51c6\u3002", "method": "\u5efa\u7acb\u4e00\u822cCE FDMA\u4fe1\u53f7\u6a21\u578b\uff0c\u7ed9\u51faCP-OFDMA\u517c\u5bb9\u7684\u5b9e\u73b0\u7ed3\u6784\uff1b\u8bbe\u8ba1CE\u7ea6\u675f\u8109\u51b2\u6574\u5f62\u6ee4\u6ce2\u5668\u4ee5\u6291\u5236\u5e26\u5916\u53d1\u5c04\uff1b\u901a\u8fc7\u4f18\u5316\u65f6\u57df\u4e8c\u503c Pilot \u5e8f\u5217\u5b9e\u73b0\u9891\u57df CE \u7279\u6027\uff1b\u63d0\u51fa\u5ef6\u8fdf\u57df\u53bb\u566a\u4e0e\u529f\u7387\u5ef6\u8fdf\u8f6e\u5ed3\u4f30\u8ba1\u7684\u591a\u9636\u6bb5\u964d\u7ef4LMMSE\u4f30\u8ba1\uff1b\u8bbe\u8ba1\u57fa\u4e8e\u6700\u5927\u6bd4\u7ec4\u5408\u7684\u4f4e\u590d\u6742\u5ea6CE\u63a5\u6536\u7aefLMMSE\u7b49\u5316\u5668\uff1b\u63d0\u51fa\u591a\u7528\u6237\u4e0b\u884cCE\u4f20\u8f93\u65b9\u6848\u53caNR\u517c\u5bb9\u7684\u7cfb\u7edf\u5b9e\u73b0\u3002", "result": "\u6570\u503c\u7ed3\u679c\u663e\u793a\u6240\u63d0\u65b9\u6848\u5728\u8bef\u6bd4\u7279\u7387\u65b9\u9762\u63a5\u8fd1\u7406\u60f3\u60c5\u51b5\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u76f8\u8f83\u4e8e\u73b0\u6709CE\u6ce2\u5f62\u7684\u6536\u53d1\u673a\u590d\u6742\u5ea6\u3002", "conclusion": "CE\u6ce2\u5f62\u7efc\u5408\u8003\u8651\u517c\u5bb9CP-OFDMA\u4e0e\u591a\u7528\u6237\u4e0b\u884c\uff0c\u80fd\u663e\u8457\u63d0\u5347\u529f\u7387\u6548\u7387\u5e76\u964d\u4f4e\u5b9e\u73b0\u590d\u6742\u5ea6\uff0c\u5177\u5907\u843d\u5730NR\u573a\u666f\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.24389", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24389", "abs": "https://arxiv.org/abs/2510.24389", "authors": ["Lamine Chalal", "Ahmed Rachid"], "title": "Development of a Digital Twin for an Electric Vehicle Emulator Modeling, Control, and Experimental Validation", "comment": "6 pages, Accepted at CODIT 2025 (Conference on Decision and Control\n  in Intelligent Technology)", "summary": "This paper presents the development and validation of a digital twin for a\nscaled-down electric vehicle (EV) emulator, designed to replicate longitudinal\nvehicle dynamics under diverse operating conditions. The emulator integrates a\nseparately excited DC motor (SEDCM), a four-quadrant DC-DC converter, a battery\nemulator, and a mechanical load emulator. The system models tractive effort,\naerodynamic drag, and gradient resistance using Newton's second law. In\ncontrast to conventional graphical modeling tools (e.g., block diagrams and\nbond graphs), the adopted Energetic Macroscopic Representation (EMR) framework\noffers clear advantages by explicitly representing energy interactions and\nfacilitating the systematic derivation of control structures. A control\nstrategy developed within this framework governs energy flow across the\npowertrain, enabling accurate speed control via armature voltage regulation.\nExperimental tests conducted on a Lucas-Nulle test bench show strong\ncorrelation with simulation results. The study also introduces a methodology to\ncompute the maximum admissible vehicle mass - determined to be 13.5 kg for a\n180 W motor operating at 1900 rpm - based on acceleration and slope\nconstraints. Furthermore, a switching algorithm for the bidirectional converter\nensures reliable four quadrant operation. Overall, the proposed framework\nprovides a scalable and effective approach for EV emulation, control design,\nand energy management validation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u80fd\u91cf\u5b8f\u89c2\u8868\u793a\u6cd5\uff08EMR\uff09\u7684\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u7528\u4e8e\u7f29\u653eEV\u4eff\u771f\u5668\u7684\u7eb5\u5411\u52a8\u529b\u5b66\u5efa\u6a21\u4e0e\u63a7\u5236\uff1b\u5728\u5b9e\u9a8c\u53f0\u4e0a\u9a8c\u8bc1\uff0c\u5e76\u7ed9\u51fa\u6700\u5927\u53ef\u5bb9\u7eb3\u8d28\u91cf\u4e0e\u56db\u8c61\u9650\u5de5\u4f5c\u5207\u6362\u7b56\u7565\u3002", "motivation": "\u5728EV\u52a8\u529b\u4f20\u52a8\u7cfb\u7edf\u7684\u80fd\u91cf\u6d41\u4e0e\u529f\u7387\u7ba1\u7406\u4e2d\uff0c\u73b0\u6709\u56fe\u5f62\u5efa\u6a21\u5de5\u5177\u96be\u4ee5\u6e05\u6670\u5730\u8868\u793a\u80fd\u91cf\u4ea4\u4e92\u53ca\u63a8\u5bfc\u63a7\u5236\u7ed3\u6784\uff0c\u9700\u4e00\u79cd\u66f4\u76f4\u89c2\u4e14\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u80fd\u91cf\u7ba1\u7406\u9a8c\u8bc1\u4e0e\u63a7\u5236\u8bbe\u8ba1\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u5305\u542b\u5206\u52b1\u76f4\u6d41\u7535\u673a\u3001\u56db\u8c61\u9650DC-DC\u53d8\u6362\u5668\u3001\u84c4\u7535\u6c60\u4eff\u771f\u5668\u548c\u673a\u68b0\u8d1f\u8f7d\u4eff\u771f\u5668\u7684\u6570\u5b57\u5b6a\u751f\uff0c\u901a\u8fc7\u725b\u987f\u7b2c\u4e8c\u5b9a\u5f8b\u5efa\u6a21\u7275\u5f15\u529b\u3001\u7a7a\u6c14\u963b\u529b\u548c\u5761\u9053\u963b\u529b\u7b49\u52a8\u529b\u5b66\uff1b\u91c7\u7528EMR\u6846\u67b6\u6e05\u6670\u8868\u793a\u80fd\u91cf\u4ea4\u4e92\u5e76\u5bfc\u51fa\u63a7\u5236\u7ed3\u6784\uff0c\u8bbe\u8ba1\u57fa\u4e8eEMR\u7684\u80fd\u91cf\u6d41\u63a7\u5236\u7b56\u7565\u4ee5\u901a\u8fc7\u7535\u67a2\u7535\u538b\u5b9e\u73b0\u901f\u5ea6\u63a7\u5236\uff1b\u5728Lucas-Nulle\u6d4b\u8bd5\u53f0\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u4e14\u63d0\u51fa\u6700\u5927\u53ef\u5bb9\u7eb3\u8d28\u91cf\u7684\u8ba1\u7b97\u65b9\u6cd5\uff08\u5bf9180 W\u30011900 rpm\u7684\u7535\u673a\u4e3a13.5 kg\uff09\uff0c\u5e76\u5b9e\u73b0\u53cc\u5411\u53d8\u6362\u5668\u5207\u6362\u7b97\u6cd5\u4ee5\u786e\u4fdd\u56db\u8c61\u9650\u53ef\u9760\u8fd0\u884c\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u4e0e\u5b9e\u9a8c\u7ed3\u679c\u9ad8\u5ea6\u76f8\u5173\uff0c\u9a8c\u8bc1\u4e86EMR\u6570\u5b57\u5b6a\u751f\u5728EV\u4eff\u771f\u3001\u63a7\u5236\u8bbe\u8ba1\u4e0e\u80fd\u91cf\u7ba1\u7406\u9a8c\u8bc1\u4e2d\u7684\u6709\u6548\u6027\uff1b\u7ed9\u51fa\u5177\u4f53\u7684\u5de5\u4f5c\u8fb9\u754c\uff08\u6700\u5927\u8d28\u91cf13.5 kg\uff09\u548c\u7535\u673a\u4e0e\u8f6c\u901f\u7ea6\u675f\u4e0b\u7684\u53ef\u9760\u6027\u5b9e\u73b0\uff1b\u63d0\u51fa\u7684\u5207\u6362\u7b97\u6cd5\u5b9e\u73b0\u4e86\u56db\u8c61\u9650\u7a33\u5b9a\u64cd\u4f5c\u3002", "conclusion": "\u57fa\u4e8eEMR\u7684\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u4e3aEV\u4eff\u771f\u3001\u80fd\u91cf\u7ba1\u7406\u9a8c\u8bc1\u4ee5\u53ca\u63a7\u5236\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u6e05\u6670\u7684\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u652f\u6491\u591a\u7269\u7406\u91cf\u8026\u5408\u7684\u80fd\u91cf\u6d41\u52a8\u5efa\u6a21\u4e0e\u63a7\u5236\u5b9e\u73b0\u3002"}}
{"id": "2510.24422", "categories": ["cs.CR", "cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24422", "abs": "https://arxiv.org/abs/2510.24422", "authors": ["Bijeet Basak", "Nupur Patil", "Kurian Polachan", "Srinivas Vivek"], "title": "Attack on a PUF-based Secure Binary Neural Network", "comment": "Accepted at VLSID 2026. To be published in IEEE Xplore", "summary": "Binarized Neural Networks (BNNs) deployed on memristive crossbar arrays\nprovide energy-efficient solutions for edge computing but are susceptible to\nphysical attacks due to memristor nonvolatility. Recently, Rajendran et al.\n(IEEE Embedded Systems Letter 2025) proposed a Physical Unclonable Function\n(PUF)-based scheme to secure BNNs against theft attacks. Specifically, the\nweight and bias matrices of the BNN layers were secured by swapping columns\nbased on device's PUF key bits.\n  In this paper, we demonstrate that this scheme to secure BNNs is vulnerable\nto PUF-key recovery attack. As a consequence of our attack, we recover the\nsecret weight and bias matrices of the BNN. Our approach is motivated by\ndifferential cryptanalysis and reconstructs the PUF key bit-by-bit by observing\nthe change in model accuracy, and eventually recovering the BNN model\nparameters. Evaluated on a BNN trained on the MNIST dataset, our attack could\nrecover 85% of the PUF key, and recover the BNN model up to 93% classification\naccuracy compared to the original model's 96% accuracy. Our attack is very\nefficient and it takes a couple of minutes to recovery the PUF key and the\nmodel parameters.", "AI": {"tldr": "\u5bf9\u57fa\u4e8ePUF\u7684\u5bf9\u79f0\u5217\u4ea4\u6362\u4fdd\u62a4\u7684BNN\u5728\u5fc6\u963b\u4ea4\u53c9\u9635\u5217\u4e0a\u7684\u65b9\u6848\u8fdb\u884c\u653b\u51fb\u5206\u6790\uff0c\u53d1\u73b0\u5b58\u5728\u5bc6\u94a5\u6062\u590d\u653b\u51fb\u6f0f\u6d1e\u3002\u653b\u51fb\u8005\u53ef\u9010\u4f4d\u6062\u590dPUF\u5bc6\u94a5\u5e76\u91cd\u6784\u6a21\u578b\u53c2\u6570\uff0c\u5b9e\u9a8c\u5728 MNIST \u4e0a\u53ef\u6062\u590d\u7ea685%\u7684PUF\u5bc6\u94a5\uff0cBNN\u5206\u7c7b\u51c6\u786e\u7387\u964d\u81f3\u7ea693%\uff08\u539f\u59cb96%\uff09\uff0c\u8017\u65f6\u6570\u5206\u949f\u3002", "motivation": "\u8bc4\u4f30\u5728\u8fb9\u7f18\u8ba1\u7b97\u573a\u666f\u4e2d\uff0c\u5e26\u975e\u6613\u5931\u5fc6\u963b\u5668\u7684BNN\u82e5\u91c7\u7528PUF\u4f5c\u4e3a\u5b89\u5168\u652f\u6491\u7684\u9c81\u68d2\u6027\u4e0e\u8106\u5f31\u6027\u3002\u539f\u65b9\u6848\uff08Rajendran\u7b49\uff0cIEEE Embedded Systems Letters 2025\uff09\u901a\u8fc7\u57fa\u4e8e\u5217\u4ea4\u6362\u7684\u5bc6\u94a5\u63a7\u5236\u6765\u4fdd\u62a4\u6743\u91cd\u548c\u504f\u7f6e\u77e9\u9635\uff0c\u9700\u68c0\u9a8c\u5176\u5bf9\u5bc6\u94a5\u6cc4\u9732\u4e0e\u6a21\u578b\u7a83\u53d6\u7b49\u653b\u51fb\u7684\u8010\u53d7\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u7c7b\u53d7\u5dee\u5206\u5bc6\u7801\u5206\u6790\u542f\u53d1\u7684\u653b\u51fb\uff0c\u9010\u4f4d\u63a8\u5bfcPUF\u5bc6\u94a5\u6bd4\u7279\uff0c\u89c2\u5bdf\u6a21\u578b\u51c6\u786e\u7387\u7684\u53d8\u5316\u4ee5\u6062\u590dPUF\u5bc6\u94a5\uff0c\u8fdb\u800c\u8fd8\u539fBNN\u7684\u6743\u91cd\u548c\u504f\u7f6e\u77e9\u9635\u3002\u8bc4\u4f30\u5728\u5bf9MNIST\u6570\u636e\u96c6\u8bad\u7ec3\u7684BNN\u4e0a\uff0c\u80fd\u5728\u51e0\u5206\u949f\u5185\u6062\u590d\u7ea685%\u7684PUF\u5bc6\u94a5\uff0c\u5e76\u4f7f\u6a21\u578b\u51c6\u786e\u7387\u964d\u81f3\u7ea693%\uff08\u76f8\u6bd4\u539f\u6a21\u578b\u768496%\uff09\uff0c\u653b\u51fb\u8fc7\u7a0b\u9ad8\u6548\u3002", "result": "\u653b\u51fb\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9PUF\u5bc6\u94a5\u548cBNN\u53c2\u6570\u7684\u9ad8\u6548\u6062\u590d\uff0c\u4e14\u5728\u5b9e\u9a8c\u4e2d\u8fbe\u5230\u663e\u8457\u7684\u5b9e\u7528\u6027\uff0c\u8868\u660e\u73b0\u6709\u7684PUF\u57fa\u4fdd\u62a4\u5e76\u4e0d\u80fd\u6709\u6548\u9632\u6b62\u5bc6\u94a5\u548c\u6a21\u578b\u53c2\u6570\u7684\u6cc4\u6f0f\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u57fa\u4e8ePUF\u7684BNN\u4fdd\u62a4\u5b58\u5728\u660e\u663e\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u5bf9\u4fdd\u62a4\u673a\u5236\u8fdb\u884c\u52a0\u5f3a\uff08\u5982\u6539\u8fdbPUF\u5bc6\u94a5\u4f7f\u7528\u3001\u589e\u52a0\u9632\u7a83\u53d6\u7684\u5197\u4f59\u6216\u5bf9\u6743\u91cd\u91cd\u6784\u7684\u6297\u653b\u51fb\u8bbe\u8ba1\uff09\uff0c\u4ee5\u63d0\u5347\u5728\u8fb9\u7f18\u573a\u666f\u4e0b\u5bf9BNN\u7684\u5168\u9762\u5b89\u5168\u6027\u3002"}}
{"id": "2510.23639", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.23639", "abs": "https://arxiv.org/abs/2510.23639", "authors": ["Jonathan Amar", "Edward Liu", "Alessandra Breschi", "Liangliang Zhang", "Pouya Kheradpour", "Sylvia Li", "Lisa Soleymani Lehmann", "Alessandro Giulianelli", "Matt Edwards", "Yugang Jia", "David Nola", "Raghav Mani", "Pankaj Vats", "Jesse Tetreault", "T. J. Chen", "Cory Y. McLean"], "title": "Integrating Genomics into Multimodal EHR Foundation Models", "comment": null, "summary": "This paper introduces an innovative Electronic Health Record (EHR) foundation\nmodel that integrates Polygenic Risk Scores (PRS) as a foundational data\nmodality, moving beyond traditional EHR-only approaches to build more holistic\nhealth profiles. Leveraging the extensive and diverse data from the All of Us\n(AoU) Research Program, this multimodal framework aims to learn complex\nrelationships between clinical data and genetic predispositions. The\nmethodology extends advancements in generative AI to the EHR foundation model\nspace, enhancing predictive capabilities and interpretability. Evaluation on\nAoU data demonstrates the model's predictive value for the onset of various\nconditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay\nbetween PRS and EHR data. The work also explores transfer learning for custom\nclassification tasks, showcasing the architecture's versatility and efficiency.\nThis approach is pivotal for unlocking new insights into disease prediction,\nproactive health management, risk stratification, and personalized treatment\nstrategies, laying the groundwork for more personalized, equitable, and\nactionable real-world evidence generation in healthcare.", "AI": {"tldr": "\u5c06EHR\u57fa\u7840\u6a21\u578b\u4e0e\u591a\u57fa\u56e0\u98ce\u9669\u8bc4\u5206\uff08PRS\uff09\u6574\u5408\uff0c\u5229\u7528All of Us\u6570\u636e\u6784\u5efa\u591a\u6a21\u6001\u3001\u53ef\u6269\u5c55\u7684\u5065\u5eb7\u98ce\u9669\u8868\u5f81\uff0c\u63d0\u5347\u75be\u75c5\u9884\u6d4b\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u5c24\u5176\u57282\u578b\u7cd6\u5c3f\u75c5\uff08T2D\uff09\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "\u901a\u8fc7\u628a\u9057\u4f20\u4fe1\u606f\u5d4c\u5165EHR\u6846\u67b6\uff0c\u8d85\u8d8a\u53ea\u4f9d\u8d56\u4e34\u5e8a\u8bb0\u5f55\u7684\u4f20\u7edf\u65b9\u6cd5\uff0c\u5f62\u6210\u66f4\u5168\u9762\u7684\u5065\u5eb7\u753b\u50cf\uff0c\u4ece\u800c\u63d0\u5347\u9884\u6d4b\u80fd\u529b\u3001\u4e2a\u6027\u5316\u5e72\u9884\u4e0e\u5065\u5eb7\u516c\u5e73\u6027\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u591a\u6a21\u6001\u7684EHR\u57fa\u7840\u6a21\u578b\uff0c\u878d\u5165PRS\u7b49\u9057\u4f20\u6570\u636e\uff0c\u57fa\u4e8eAll of Us\u7814\u7a76\u8ba1\u5212\u4e2d\u7684\u5927\u89c4\u6a21\u5f02\u8d28\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff1b\u5728\u751f\u6210\u5f0fAI\u6846\u67b6\u4e0b\u6269\u5c55EHR\u57fa\u7840\u6a21\u578b\uff0c\u63a2\u7a76\u9057\u4f20\u4e0e\u4e34\u5e8a\u4fe1\u53f7\u7684\u4ea4\u4e92\uff1b\u5e76\u7814\u7a76\u5728\u81ea\u5b9a\u4e49\u4efb\u52a1\u4e0a\u7684\u8fc1\u79fb\u5b66\u4e60\u4ee5\u63d0\u5347\u67b6\u6784\u7684\u901a\u7528\u6027\u4e0e\u6548\u7387\u3002", "result": "\u5728All of Us\u6570\u636e\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u6a21\u578b\u5bf9\u591a\u79cd\u75be\u75c5\u7684\u53d1\u751f\u9884\u6d4b\u5177\u6709\u4ef7\u503c\uff0c\u5c24\u5176\u662fT2D\uff1b\u63ed\u793aPRS\u4e0eEHR\u6570\u636e\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u5bf9\u9884\u6d4b\u7684\u8d21\u732e\uff0c\u5c55\u793a\u4e86\u8de8\u6a21\u6001\u4fe1\u606f\u6574\u5408\u7684\u6f5c\u529b\u4e0e\u53ef\u89e3\u91ca\u6027\u63d0\u5347\u3002", "conclusion": "\u4e3a\u75be\u75c5\u9884\u6d4b\u3001\u4e3b\u52a8\u5065\u5eb7\u7ba1\u7406\u3001\u98ce\u9669\u5206\u5c42\u548c\u4e2a\u6027\u5316\u6cbb\u7597\u7b56\u7565\u63d0\u4f9b\u65b0\u7684\u8bc1\u636e\u4e0e\u5de5\u5177\uff0c\u5960\u5b9a\u5c06\u4e2a\u6027\u5316\u3001\u53ef\u53ca\u4e14\u5177\u73b0\u5b9e\u4e16\u754c\u8bc1\u636e\u4ef7\u503c\u7684\u5065\u5eb7\u5e72\u9884\u843d\u5730\u7684\u57fa\u7840\u3002"}}
{"id": "2510.24495", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24495", "abs": "https://arxiv.org/abs/2510.24495", "authors": ["Yuzhi Yang", "Sen Yan", "Weijie Zhou", "Brahim Mefgouda", "Ridong Li", "Zhaoyang Zhang", "M\u00e9rouane Debbah"], "title": "Diffusion Models for Wireless Transceivers: From Pilot-Efficient Channel Estimation to AI-Native 6G Receivers", "comment": "Submitted for potential publication in IEEE Wireless Communications", "summary": "With the development of artificial intelligence (AI) techniques, implementing\nAI-based techniques to improve wireless transceivers becomes an emerging\nresearch topic. Within this context, AI-based channel characterization and\nestimation become the focus since these methods have not been solved by\ntraditional methods very well and have become the bottleneck of transceiver\nefficiency in large-scale orthogonal frequency division multiplexing (OFDM)\nsystems. Specifically, by formulating channel estimation as a generative AI\nproblem, generative AI methods such as diffusion models (DMs) can efficiently\ndeal with rough initial estimations and have great potential to cooperate with\ntraditional signal processing methods. This paper focuses on the transceiver\ndesign of OFDM systems based on DMs, provides an illustration of the potential\nof DMs in wireless transceivers, and points out the related research directions\nbrought by DMs. We also provide a proof-of-concept case study of further\nadapting DMs for better wireless receiver performance.", "AI": {"tldr": "\u5c06\u6269\u6563\u6a21\u578b\u7528\u4e8eOFDM\u7cfb\u7edf\u7684AI\u9a71\u52a8\u901a\u9053\u4f30\u8ba1\u4e0e\u6536\u53d1\u673a\u8bbe\u8ba1\uff0c\u5c55\u793a\u5176\u6f5c\u529b\u5e76\u7ed9\u51fa\u521d\u6b65\u9a8c\u8bc1\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u5927\u89c4\u6a21OFDM\u7cfb\u7edf\u4e2d\u7684\u901a\u9053\u4f30\u8ba1\u74f6\u9888\uff1bAI\u65b9\u6cd5\u53ef\u63d0\u5347\u4f30\u8ba1\u7cbe\u5ea6\u4e0e\u6548\u7387\uff0c\u6269\u6563\u6a21\u578b\u5177\u5907\u4ece\u7c97\u7cd9\u521d\u59cb\u4f30\u8ba1\u4e2d\u6539\u8fdb\u7684\u80fd\u529b\u3002", "method": "\u5c06\u901a\u9053\u4f30\u8ba1\u89c6\u4e3a\u751f\u6210\u95ee\u9898\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u8fdb\u884c\u53bb\u566a/\u751f\u6210\uff0c\u5e76\u4e0e\u4f20\u7edf\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\u7ed3\u5408\uff0c\u4ee5\u8bbe\u8ba1OFDM\u63a5\u6536\u7aef\u7684AI\u5faa\u73af\u3002\u63d0\u4f9b\u4e00\u4e2a\u6982\u5ff5\u6027\u5b9e\u73b0\u4e0e\u9a8c\u8bc1\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u6269\u6563\u6a21\u578b\u5728\u65e0\u7ebf\u901a\u9053\u4f30\u8ba1\u4e2d\u7684\u6f5c\u5728\u6548\u7528\uff0c\u7ed9\u51fa\u4e00\u4e2aproof-of-concept\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793aDMs\u5bf9\u6539\u8fdb\u63a5\u6536\u7aef\u6027\u80fd\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u6269\u6563\u6a21\u578b\u5728OFDM\u901a\u9053\u4f30\u8ba1\u4e0e\u65e0\u7ebf\u6536\u53d1\u673a\u8bbe\u8ba1\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u6f5c\u529b\uff0c\u672a\u6765\u65b9\u5411\u5305\u62ec\u4e0e\u4f20\u7edf\u65b9\u6cd5\u8fdb\u4e00\u6b65\u534f\u4f5c\u3001\u63d0\u5347\u5bf9\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u53ca\u5728\u5b9e\u9645\u65e0\u7ebf\u573a\u666f\u4e2d\u7684\u90e8\u7f72\u4e0e\u4f18\u5316\u3002"}}
{"id": "2510.24498", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24498", "abs": "https://arxiv.org/abs/2510.24498", "authors": ["Tejaswini Bollikonda"], "title": "Design and Optimization of Cloud Native Homomorphic Encryption Workflows for Privacy-Preserving ML Inference", "comment": "6 pages 2 figures, 2 tABLES", "summary": "As machine learning (ML) models become increasingly deployed through cloud\ninfrastructures, the confidentiality of user data during inference poses a\nsignificant security challenge. Homomorphic Encryption (HE) has emerged as a\ncompelling cryptographic technique that enables computation on encrypted data,\nallowing predictions to be generated without decrypting sensitive inputs.\nHowever, the integration of HE within large scale cloud native pipelines\nremains constrained by high computational overhead, orchestration complexity,\nand model compatibility issues.\n  This paper presents a systematic framework for the design and optimization of\ncloud native homomorphic encryption workflows that support privacy-preserving\nML inference. The proposed architecture integrates containerized HE modules\nwith Kubernetes-based orchestration, enabling elastic scaling and parallel\nencrypted computation across distributed environments. Furthermore,\noptimization strategies including ciphertext packing, polynomial modulus\nadjustment, and operator fusion are employed to minimize latency and resource\nconsumption while preserving cryptographic integrity. Experimental results\ndemonstrate that the proposed system achieves up to 3.2times inference\nacceleration and 40% reduction in memory utilization compared to conventional\nHE pipelines. These findings illustrate a practical pathway for deploying\nsecure ML-as-a-Service (MLaaS) systems that guarantee data confidentiality\nunder zero-trust cloud conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4e91\u539f\u751f\u540c\u6001\u52a0\u5bc6\u5de5\u4f5c\u6d41\u6846\u67b6\uff0c\u901a\u8fc7\u5bb9\u5668\u5316HE\u6a21\u5757\u4e0eKubernetes\u7f16\u6392\u5b9e\u73b0\u5f39\u6027\u6269\u5c55\u7684\u9690\u79c1\u63a8\u7406\uff0c\u52a0\u901f\u5e76\u964d\u4f4e\u5185\u5b58\u5360\u7528\u3002", "motivation": "\u968f\u7740 ML \u6a21\u578b\u5728\u4e91\u7aef\u90e8\u7f72\uff0c\u63a8\u7406\u9636\u6bb5\u7684\u6570\u636e\u9690\u79c1\u6210\u4e3a\u5173\u952e\u6311\u6218\uff1b\u540c\u6001\u52a0\u5bc6\u63d0\u4f9b\u5728\u52a0\u5bc6\u6570\u636e\u4e0a\u8ba1\u7b97\u7684\u80fd\u529b\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u4e91\u7ba1\u9053\u4e2d\u7684\u5f00\u9500\u3001\u7f16\u6392\u590d\u6742\u5ea6\u548c\u6a21\u578b\u517c\u5bb9\u6027\u963b\u788d\u5b9e\u9645\u843d\u5730\uff0c\u9700\u8981\u4e91\u539f\u751f\u7ed3\u6784\u4e0e\u4f18\u5316\u7b56\u7565\u6765\u964d\u4f4e\u6210\u672c\u3002", "method": "\u8bbe\u8ba1\u4e00\u4e2a\u5c06\u5bb9\u5668\u5316HE\u6a21\u5757\u4e0eKubernetes\u7f16\u6392\u7ed3\u5408\u7684\u67b6\u6784\uff0c\u652f\u6301\u5206\u5e03\u5f0f\u52a0\u5bc6\u8ba1\u7b97\u7684\u5f39\u6027\u6269\u5c55\u4e0e\u5e76\u884c\u6027\uff1b\u5e76\u901a\u8fc7 ciphertext packing\u3001\u591a\u9879\u5f0f\u6a21\u6570\u8c03\u6574\u3001\u7b97\u5b50\u878d\u5408\u7b49\u4f18\u5316\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u548c\u8d44\u6e90\u8282\u7ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u4f20\u7edfHE\u7ba1\u7ebf\u76f8\u6bd4\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u81f3 3.2\u00d7\uff0c\u5185\u5b58\u5229\u7528\u7387\u4e0b\u964d\u7ea640%\u3002", "conclusion": "\u4e3a\u5728\u96f6\u4fe1\u4efb\u4e91\u73af\u5883\u4e2d\u90e8\u7f72\u5b89\u5168\u7684 MLaaS \u63d0\u4f9b\u4e86\u5207\u5b9e\u53ef\u884c\u7684\u8def\u5f84\uff0c\u63a8\u52a8\u9690\u79c1\u4fdd\u62a4\u7684\u4e91\u7aef ML \u63a8\u7406\u843d\u5730\u3002"}}
{"id": "2510.24416", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24416", "abs": "https://arxiv.org/abs/2510.24416", "authors": ["Nikhat Khan", "E. M. H. E. B. Ekanayake", "Nicolas Casilli", "Cristian Cassella", "Luke Theogarajan", "Nikhil Shukla"], "title": "Analyzing Parametric Oscillator Ising Machines through the Kuramoto Lens", "comment": null, "summary": "Networks of coupled nonlinear oscillators are emerging as powerful physical\nplatforms for implementing Ising machines. Yet the relationship between\nparametric-oscillator implementations and traditional oscillator-based Ising\nmachines remains underexplored. In this work, we develop a Kuramoto-style,\ncanonical phase description of parametric oscillator Ising machines by starting\nfrom the Stuart-Landau oscillator model- the canonical normal form near a Hopf\nbifurcation, and a natural reduced description for many parametric oscillator\nimplementations such as the degenerate optical parametric oscillator (DOPO)\namong others. The resulting phase dynamics combine the usual phase-difference\ncoupling observed in the standard Kuramoto model along with an intrinsic phase\nsum term that is generated when conjugate coupling is considered. Moreover, our\nformulation helps explain why explicit second-harmonic driving is unnecessary\nin parametric oscillators and also reveals how quasi-steady amplitude\nheterogeneity scales the original strength of the spin interaction with\npotentially adverse impacts on the solution quality. Our work helps develop a\nunifying view of the oscillator-based approach to designing Ising machines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u65af\u56fe\u7279-\u5170\u9053\u65b9\u7a0b\u7684\u540c\u9707\u8026\u5408\u53c2\u6570\u632f\u8361\u5668Ising\u673a\u7684\u89c4\u8303\u76f8\u4f4d\u63cf\u8ff0\uff0c\u7ed3\u5408\u5361\u62c9\u83ab\u6258\u76f8\u4f4d\u8026\u5408\u4e0e\u5185\u5728\u76f8\u4f4d\u548c\u9879\uff0c\u89e3\u91ca\u4e3a\u4f55\u65e0\u9700\u663e\u5f0f\u4e8c\u6b21\u8c10\u6ce2\u9a71\u52a8\uff0c\u5e76\u5206\u6790\u5e45\u5ea6\u5f02\u8d28\u6027\u5bf9\u81ea\u65cb\u76f8\u4e92\u4f5c\u7528\u5f3a\u5ea6\u53ca\u89e3\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u8bbe\u8ba1\u89c6\u89d2\u3002", "motivation": "\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u3001\u53ef\u63a8\u5e7f\u7684\u76f8\u4f4d\u63cf\u8ff0\u6846\u67b6\uff0c\u4ee5\u8fde\u63a5\u4f20\u7edf\u7684\u57fa\u4e8e\u632f\u8361\u5668\u7684Ising\u673a\u5b9e\u73b0\uff08\u5982DOPO\u7b49\uff09\u548cKuramoto\u578b\u8026\u5408\u6a21\u578b\uff0c\u4fbf\u4e8e\u6bd4\u8f83\u4e0d\u540c\u5b9e\u73b0\u7684\u5171\u6027\u4e0e\u5dee\u5f02\u3002", "method": "\u4ee5Stuart\u2013Landau\u632f\u5b50\u4f5c\u4e3aHopf\u5206\u5c94\u6b63\u5219\u5f62\u5f0f\u7684canonical\u6a21\u578b\uff0c\u63a8\u5bfc\u51fa\u5305\u542b\u76f8\u4f4d\u5dee\u8026\u5408\u548c\u5171\u8f6d\u8026\u5408\u6240\u4ea7\u751f\u7684\u76f8\u4f4d\u548c\u9879\u7684\u8026\u5408\u52a8\u529b\u5b66\uff1b\u89e3\u91ca\u4e3a\u4f55\u5728\u53c2\u6570\u632f\u8361\u5668\u4e2d\u65e0\u9700\u663e\u5f0f\u7684\u4e8c\u6b21\u8c10\u6ce2\u9a71\u52a8\uff0c\u5e76\u5206\u6790\u5e45\u5ea6\u5206\u5e03\u4e0d\u5747\uff08quasi-steady amplitude heterogeneity\uff09\u5bf9\u8026\u5408\u5f3a\u5ea6\u7684\u7b49\u6548\u524a\u5f31\uff0c\u4ee5\u53ca\u5bf9\u89e3\u8d28\u91cf\u7684\u6f5c\u5728\u8d1f\u9762\u5f71\u54cd\u3002", "result": "\u7ed9\u51fa\u4e00\u4e2aKuramoto\u98ce\u683c\u7684\u7edf\u4e00\u76f8\u4f4d\u63cf\u8ff0\uff0c\u63ed\u793a\u6807\u51c6\u76f8\u5dee\u8026\u5408\u4e0e\u989d\u5916\u7684\u76f8\u4f4d\u548c\u9879\u5728parametric-oscillator Ising\u673a\u4e2d\u7684\u4f5c\u7528\uff1b\u6f84\u6e05\u5b9e\u73b0\u5dee\u5f02\u7684\u7269\u7406\u6765\u6e90\uff0c\u63d0\u4f9b\u5bf9\u8bbe\u8ba1\u548c\u4f18\u5316\u7684\u5b9a\u91cf/\u5b9a\u6027\u89c1\u89e3\u3002", "conclusion": "\u5efa\u7acb oscillator-based Ising machines \u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u65b9\u4fbf\u5bf9\u6bd4\u4e0d\u540c\u5b9e\u73b0\u3001\u6307\u5bfc\u7cfb\u7edf\u8bbe\u8ba1\u3001\u63d0\u5347\u89e3\u8d28\u91cf\u5e76\u4fc3\u8fdb\u65b0\u5b9e\u73b0\u7684\u5f00\u53d1\u3002"}}
{"id": "2510.24512", "categories": ["eess.SP", "physics.geo-ph", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.24512", "abs": "https://arxiv.org/abs/2510.24512", "authors": ["Magnus Heimpel", "Irena Hajnsek", "Othmar Frey"], "title": "Quality Coefficients for Interferometric Phase Linking", "comment": null, "summary": "In multi-temporal InSAR, phase linking refers to the estimation of a\nsingle-reference interferometric phase history from the information contained\nin the coherence matrix of a distributed scatterer. Since the phase information\nin the coherence matrix is typically inconsistent, the extent to which the\nestimated phase history captures it must be assessed to exclude unreliable\npixels from further processing. We introduce three quality criteria in the form\nof coefficients, for threshold-based pixel selection: a coefficient based on\nclosure phase that quantifies the internal consistency of the phase information\nin the coherence matrix; a goodness-of-fit coefficient that quantifies how well\na resulting phase history estimate approximates the phase information according\nto the characteristic optimization model of a given phase linking method; and\nan ambiguity coefficient that compares the goodness of fit of the original\nestimate with that of an orthogonal alternative. We formulate the phase linking\nmethods and these criteria within a unified mathematical framework and discuss\ncomputational and algorithmic aspects. Unlike existing goodness-of-fit\nindicators, the proposed coefficients are normalized to the unit interval with\nexplicit noise-floor correction, improving interpretability across stacks of\ndifferent size. Experiments on TerraSAR-X data over Visp, Switzerland, indicate\nthat the closure phase coefficient effectively pre-screens stable areas, the\ngoodness-of-fit coefficient aligns with and systematically generalizes\nestablished quality indicators, and the ambiguity coefficient flags solutions\nthat fit well but are unstable. Together, the coefficients enable systematic\npixel selection and quality control in the interferometric processing of\ndistributed scatterers.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u4e2a\u8d28\u91cf\u6307\u6807\u7528\u4e8e\u591a\u65f6\u76f8InSAR\u7684\u76f8\u4f4d\u8fde\u63a5\uff1a\u95ed\u5305\u76f8\u4f4d\u7cfb\u6570\u3001\u62df\u5408\u4f18\u5ea6\u7cfb\u6570\u548c\u6b67\u4e49\u7cfb\u6570\uff0c\u5e76\u5c06\u5b83\u4eec\u5728\u7edf\u4e00\u6846\u67b6\u5185\u89c4\u8303\u5316\u3001\u5e26\u566a\u58f0\u57fa\u7ebf\u6821\u6b63\uff0c\u7528\u4e8e\u50cf\u5143\u7b5b\u9009\u548c\u8d28\u91cf\u63a7\u5236\u3002\u5b9e\u9a8c\u8bc1\u660e\u95ed\u5305\u76f8\u4f4d\u7cfb\u6570\u80fd\u6709\u6548\u7b5b\u9009\u7a33\u5b9a\u533a\u57df\u3001\u62df\u5408\u4f18\u5ea6\u4e0e\u65e2\u6709\u6307\u6807\u76f8\u5173\u5e76\u63a8\u5e7f\u3001\u6b67\u4e49\u7cfb\u6570\u80fd\u6807\u8bb0\u867d\u62df\u5408\u826f\u4f46\u4e0d\u7a33\u5b9a\u7684\u89e3\u3002", "motivation": "\u5728\u591a\u65f6\u76f8InSAR\u4e2d\uff0c\u76f8\u4f4d\u4fe1\u606f\u5e38\u6765\u81ea\u5206\u5e03\u6563\u5c04\u4f53\u7684\u76f8\u5e72\u77e9\u9635\uff0c\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\u3002\u9700\u8981\u53ef\u89e3\u91ca\u4e14\u7edf\u4e00\u7684\u8d28\u91cf\u8bc4\u4f30\u6307\u6807\u6765\u7b5b\u9009\u548c\u63a7\u5236\u50cf\u5143\uff0c\u4ee5\u63d0\u9ad8\u76f8\u4f4d\u8fde\u7ed3\u7684\u53ef\u9760\u6027\u548c\u540e\u7eed\u5904\u7406\u7684\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4e09\u9879\u57fa\u4e8e\u76f8\u5e72\u77e9\u9635\u548c\u76f8\u4f4d\u8fde\u7ed3\u6a21\u578b\u7684\u8d28\u91cf\u7cfb\u6570\uff1a\u95ed\u5305\u76f8\u4f4d\u7cfb\u6570\u7528\u4e8e\u6d4b\u91cf\u76f8\u4f4d\u4fe1\u606f\u5185\u90e8\u4e00\u81f4\u6027\uff1b\u62df\u5408\u4f18\u5ea6\u7cfb\u6570\u91cf\u5316\u7ed9\u5b9a\u76f8\u4f4d\u8fde\u7ed3\u65b9\u6cd5\u7684\u76ee\u6807\u6a21\u578b\u5bf9\u89c2\u6d4b\u76f8\u4f4d\u4fe1\u606f\u7684\u62df\u5408\u7a0b\u5ea6\uff1b\u6b67\u4e49\u7cfb\u6570\u6bd4\u8f83\u539f\u59cb\u62df\u5408\u4e0e\u6b63\u4ea4\u5907\u9009\u89e3\u7684\u62df\u5408\u4f18\u5ea6\u3002\u628a\u76f8\u4f4d\u8fde\u7ed3\u65b9\u6cd5\u53ca\u8fd9\u4e09\u7c7b\u6307\u6807\u653e\u5728\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\u4e2d\uff0c\u7ed9\u51fa\u5f52\u4e00\u5316\u5230\u5355\u4f4d\u533a\u95f4\u4e14\u5e26\u566a\u58f0\u57fa\u7ebf\u4fee\u6b63\u7684\u8ba1\u7b97\u516c\u5f0f\uff0c\u5e76\u8003\u8651\u8ba1\u7b97\u4e0e\u7b97\u6cd5\u65b9\u9762\u7684\u5b9e\u73b0\u3002", "result": "\u5b9e\u9a8c\u5728TerraSAR-X\u6570\u636e\uff08Visp, \u745e\u58eb\uff09\u4e0a\u8868\u660e\uff1a\u95ed\u5305\u76f8\u4f4d\u7cfb\u6570\u53ef\u6709\u6548\u521d\u7b5b\u7a33\u5b9a\u533a\u57df\uff1b\u62df\u5408\u4f18\u5ea6\u7cfb\u6570\u4e0e\u73b0\u6709\u8d28\u91cf\u6307\u793a\u5668\u4e00\u81f4\u5e76\u53ef\u5728\u66f4\u5e7f\u6cdb\u60c5\u5f62\u4e0b\u63a8\u5e7f\uff1b\u6b67\u4e49\u7cfb\u6570\u80fd\u53d1\u73b0\u62df\u5408\u826f\u4f46\u89e3\u4e0d\u7a33\u5b9a\u7684\u60c5\u51b5\u3002\u4e09\u8005\u5171\u540c\u5b9e\u73b0\u5bf9\u5206\u5e03\u6563\u5c04\u4f53\u7684\u50cf\u5143\u7b5b\u9009\u4e0e\u8d28\u91cf\u63a7\u5236\u3002", "conclusion": "\u8fd9\u7ec4\u53ef\u5f52\u4e00\u5316\u3001\u5e26\u566a\u58f0\u4fee\u6b63\u7684\u8d28\u91cf\u6307\u6807\u4e3a\u5206\u5e03\u6563\u5c04\u4f53\u7684\u5e72\u6d89\u5904\u7406\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u50cf\u5143\u7b5b\u9009\u4e0e\u8d28\u91cf\u63a7\u5236\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u591a\u65f6\u76f8InSAR\u4e2d\u76f8\u4f4d\u8fde\u7ed3\u7684\u9c81\u68d2\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.16620", "categories": ["cs.IT", "cs.AI", "cs.CR", "cs.LG", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.16620", "abs": "https://arxiv.org/abs/2510.16620", "authors": ["Yingyao Zhou", "Natasha Devroye", "Onur G\u00fcnl\u00fc"], "title": "Feedback Lunch: Deep Feedback Codes for Wiretap Channels", "comment": null, "summary": "We consider reversely-degraded wiretap channels, for which the secrecy\ncapacity is zero if there is no channel feedback. This work focuses on a seeded\nmodular code design for the Gaussian wiretap channel with channel output\nfeedback, combining universal hash functions for security and learned\nfeedback-based codes for reliability to achieve positive secrecy rates. We\nstudy the trade-off between communication reliability and information leakage,\nillustrating that feedback enables agreeing on a secret key shared between\nlegitimate parties, overcoming the security advantage of the wiretapper. Our\nfindings also motivate code designs for sensing-assisted secure communication,\nto be used in next-generation integrated sensing and communication methods.", "AI": {"tldr": "\u5728\u9ad8\u65af\u7ebf\u9053\uff08Gaussian wiretap channel\uff09\u4e2d\uff0c\u5229\u7528\u901a\u9053\u8f93\u51fa\u53cd\u9988\uff0c\u53ef\u4ee5\u901a\u8fc7\u79cd\u5b50\u5f0f\u6a21\u5757\u5316\u7f16\u7801\u3001\u901a\u7528\u54c8\u5e0c\u548c\u5b66\u4e60\u9a71\u52a8\u7684\u53ef\u9760\u6027\u7f16\u7801\u5b9e\u73b0\u6b63\u7684\u4fdd\u5bc6\u901f\u7387\uff0c\u5e76\u53ef\u5728\u53cc\u65b9\u5171\u4eab\u5bc6\u94a5\u7684\u5e2e\u52a9\u4e0b\u514b\u670d\u7a83\u542c\u8005\u7684\u4f18\u52bf\u3002", "motivation": "\u7814\u7a76\u5728\u53cd\u9000\u5316\uff08reversely-degraded\uff09wiretap\u4fe1\u9053\u4e0b\uff0c\u5f53\u65e0\u53cd\u9988\u65f6\u4fdd\u5bc6\u5bb9\u91cf\u4e3a\u96f6\u7684\u60c5\u5f62\uff0c\u63a2\u7d22\u662f\u5426\u901a\u8fc7\u53cd\u9988\u5b9e\u73b0\u6b63\u7684\u4fdd\u5bc6\u4f20\u8f93\uff0c\u5e76\u63a8\u52a8\u5bf9\u611f\u77e5\u534f\u540c\u5b89\u5168\u901a\u4fe1\u7684\u7f16\u7801\u8bbe\u8ba1\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5e26\u79cd\u5b50\u7684\u6a21\u5757\u5316\u7f16\u7801\u8bbe\u8ba1\uff0c\u7ed3\u5408\u901a\u7528\u54c8\u5e0c\u51fd\u6570\u7528\u4e8e\u4fe1\u606f\u5b89\u5168\u6027\uff0c\u4ee5\u53ca\u57fa\u4e8e\u5b66\u4e60\u7684\u53cd\u9988\u7f16\u7801\u7528\u4e8e\u63d0\u9ad8\u53ef\u9760\u6027\uff1b\u5206\u6790\u53ef\u9760\u6027\u548c\u4fe1\u606f\u6cc4\u9732\u4e4b\u95f4\u7684\u6743\u8861\uff1b\u5c55\u793a\u901a\u8fc7\u53cd\u9988\u53ef\u5728\u5408\u6cd5\u65b9\u4e4b\u95f4\u5efa\u7acb\u79d8\u5bc6\u5bc6\u94a5\u7684\u53ef\u884c\u6027\u3002", "result": "\u8bc1\u5b9e\u53cd\u9988\u4f7f\u5f97\u5728\u9ad8\u65afwiretap\u4fe1\u9053\u4e0a\u83b7\u5f97\u6b63\u7684\u4fdd\u5bc6\u901f\u7387\u6210\u4e3a\u53ef\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u901a\u8fc7\u5bc6\u94a5\u534f\u5546\u6291\u5236\u7a83\u542c\u8005\u7684\u4f18\u52bf\uff1b\u63d0\u4f9b\u5bf9\u611f\u77e5\u8f85\u52a9\u5b89\u5168\u901a\u4fe1\u7684\u4ee3\u7801\u8bbe\u8ba1\u542f\u793a\u3002", "conclusion": "\u8fd9\u7c7b\u8bbe\u8ba1\u4e3a\u4e0b\u4e00\u4ee3\u7efc\u5408\u611f\u77e5\u4e0e\u901a\u4fe1\u7684\u5b89\u5168\u7f16\u7801\u63d0\u4f9b\u4e86\u601d\u8def\uff0c\u5f3a\u8c03\u5728\u53cd\u9988\u53ef\u7528\u7684\u573a\u666f\u4e0b\uff0c\u7ed3\u5408\u54c8\u5e0c\u548c\u5b66\u4e60\u9a71\u52a8\u7684\u7f16\u7801\u6709\u671b\u63d0\u5347\u4fdd\u5bc6\u6027\u4e0e\u53ef\u9760\u6027\u3002"}}
{"id": "2510.24674", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.24674", "abs": "https://arxiv.org/abs/2510.24674", "authors": ["Bram De Cooman", "Johan Suykens"], "title": "Learning to Drive Safely with Hybrid Options", "comment": null, "summary": "Out of the many deep reinforcement learning approaches for autonomous\ndriving, only few make use of the options (or skills) framework. That is\nsurprising, as this framework is naturally suited for hierarchical control\napplications in general, and autonomous driving tasks in specific. Therefore,\nin this work the options framework is applied and tailored to autonomous\ndriving tasks on highways. More specifically, we define dedicated options for\nlongitudinal and lateral manoeuvres with embedded safety and comfort\nconstraints. This way, prior domain knowledge can be incorporated into the\nlearning process and the learned driving behaviour can be constrained more\neasily. We propose several setups for hierarchical control with options and\nderive practical algorithms following state-of-the-art reinforcement learning\ntechniques. By separately selecting actions for longitudinal and lateral\ncontrol, the introduced policies over combined and hybrid options obtain the\nsame expressiveness and flexibility that human drivers have, while being easier\nto interpret than classical policies over continuous actions. Of all the\ninvestigated approaches, these flexible policies over hybrid options perform\nthe best under varying traffic conditions, outperforming the baseline policies\nover actions.", "AI": {"tldr": "\u5c06\u9009\u9879\u6846\u67b6\u5e94\u7528\u4e8e\u9ad8\u901f\u516c\u8def\u81ea\u4e3b\u9a7e\u9a76\uff0c\u6784\u5efa\u7eb5\u5411\u4e0e\u6a2a\u5411\u4e13\u7528\u9009\u9879\uff0c\u5d4c\u5165\u5b89\u5168\u4e0e\u8212\u9002\u7ea6\u675f\uff0c\u5f97\u5230\u53ef\u89e3\u91ca\u7684\u5206\u5c42\u63a7\u5236\u7b56\u7565\uff0c\u6df7\u5408\u9009\u9879\u5728\u591a\u53d8\u4ea4\u901a\u6761\u4ef6\u4e0b\u4f18\u4e8e\u57fa\u7ebf\u52a8\u4f5c\u7b56\u7565\u3002", "motivation": "\u5f25\u8865\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u81ea\u4e3b\u9a7e\u9a76\u4e2d\u5bf9\u9009\u9879\u6846\u67b6\u5e94\u7528\u7684\u6b20\u7f3a\uff0c\u901a\u8fc7\u5206\u5c42\u63a7\u5236\u4e0e\u9886\u57df\u77e5\u8bc6\u7684\u6ce8\u5165\uff0c\u63d0\u9ad8\u5b89\u5168\u3001\u8212\u9002\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u8bbe\u8ba1\u7eb5\u5411\u548c\u6a2a\u5411\u9a7e\u63a7\u7684\u4e13\u7528\u9009\u9879\uff0c\u5d4c\u5165\u5b89\u5168\u4e0e\u8212\u9002\u7ea6\u675f\uff0c\u63d0\u51fa\u591a\u79cd\u5e26\u9009\u9879\u7684\u5206\u5c42\u63a7\u5236\u8bbe\u7f6e\uff0c\u7ed3\u5408\u6700\u524d\u6cbf\u7684\u5f3a\u5316\u5b66\u4e60\u6280\u672f\uff0c\u5206\u522b\u5bf9\u7eb5\u5411\u548c\u6a2a\u5411\u63a7\u5236\u505a\u52a8\u4f5c\u9009\u62e9\uff0c\u5f62\u6210\u5bf9\u7ec4\u5408\u4e0e\u6df7\u5408\u9009\u9879\u7684\u7b56\u7565\u3002", "result": "\u5728\u7814\u7a76\u7684\u65b9\u6cd5\u4e2d\uff0c\u6df7\u5408\u9009\u9879\u7684\u7b56\u7565\u8868\u73b0\u6700\u4f73\uff0c\u5728\u53d8\u52a8\u4ea4\u901a\u6761\u4ef6\u4e0b\u4f18\u4e8e\u57fa\u7ebf\u7684\u76f4\u63a5\u52a8\u4f5c\u7b56\u7565\u3002", "conclusion": "\u9009\u9879\u6846\u67b6\u4e0b\u7684\u5206\u5c42\u3001\u6df7\u5408\u9009\u9879\u7b56\u7565\u5177\u6709\u826f\u597d\u8868\u8fbe\u80fd\u529b\u3001\u53ef\u89e3\u91ca\u6027\u5e76\u4fbf\u4e8e\u6574\u5408\u9886\u57df\u77e5\u8bc6\uff0c\u9002\u5408\u5b9e\u73b0\u63a5\u8fd1\u4eba\u7c7b\u9a7e\u9a76\u7684\u7075\u6d3b\u6027\u4e0e\u5b89\u5168\u6027\u3002"}}
{"id": "2510.23641", "categories": ["cs.LG", "cs.AI", "hep-ex", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2510.23641", "abs": "https://arxiv.org/abs/2510.23641", "authors": ["Aaron Wang", "Zihan Zhao", "Subash Katel", "Vivekanand Gyanchand Sahu", "Elham E Khoda", "Abhijith Gandrakota", "Jennifer Ngadiuba", "Richard Cavanaugh", "Javier Duarte"], "title": "Spatially Aware Linear Transformer (SAL-T) for Particle Jet Tagging", "comment": null, "summary": "Transformers are very effective in capturing both global and local\ncorrelations within high-energy particle collisions, but they present\ndeployment challenges in high-data-throughput environments, such as the CERN\nLHC. The quadratic complexity of transformer models demands substantial\nresources and increases latency during inference. In order to address these\nissues, we introduce the Spatially Aware Linear Transformer (SAL-T), a\nphysics-inspired enhancement of the linformer architecture that maintains\nlinear attention. Our method incorporates spatially aware partitioning of\nparticles based on kinematic features, thereby computing attention between\nregions of physical significance. Additionally, we employ convolutional layers\nto capture local correlations, informed by insights from jet physics. In\naddition to outperforming the standard linformer in jet classification tasks,\nSAL-T also achieves classification results comparable to full-attention\ntransformers, while using considerably fewer resources with lower latency\nduring inference. Experiments on a generic point cloud classification dataset\n(ModelNet10) further confirm this trend. Our code is available at\nhttps://github.com/aaronw5/SAL-T4HEP.", "AI": {"tldr": "SAL-T\u662f\u4e00\u79cd\u5bf9\u7ebf\u6027\u6ce8\u610f\u529b\u8fdb\u884c\u7269\u7406\u4fe1\u606f\u589e\u5f3a\u7684\u53d8\u4f53\uff0c\u7528\u4e8e\u9ad8\u80fd\u7c92\u5b50\u78b0\u649e\u6570\u636e\u5206\u6790\uff0c\u4fdd\u6301\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u901a\u8fc7\u57fa\u4e8e\u52a8\u91cf-\u89d2\u5ea6\u7b49\u7269\u7406\u7279\u5f81\u7684\u533a\u57df\u5212\u5206\u548c\u5377\u79ef\u5c42\u6355\u6349\u5c40\u90e8\u76f8\u5173\u6027\uff0c\u5728Jet\u5206\u7c7b\u7b49\u4efb\u52a1\u4e0a\u8fbe\u5230\u63a5\u8fd1\u5168\u6ce8\u610f\u529b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e14\u8d44\u6e90\u6d88\u8017\u548c\u5ef6\u8fdf\u663e\u8457\u964d\u4f4e\u3002", "motivation": "\u89e3\u51b3\u9ad8\u80fd\u7269\u7406\u573a\u666f\u4e2dTransformer\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\u5728\u9ad8\u541e\u5410\u91cf\u73af\u5883\uff08\u5982CERN LHC\uff09\u5e26\u6765\u7684\u8d44\u6e90\u4e0e\u5ef6\u8fdf\u6311\u6218\uff1b\u901a\u8fc7\u7269\u7406\u542f\u53d1\u7684\u533a\u57df\u5212\u5206\u548c\u5c40\u90e8\u5377\u79ef\u6765\u4fdd\u7559\u91cd\u8981\u5168\u5c40\u4e0e\u5c40\u90e8\u76f8\u5173\u4fe1\u606f\uff0c\u540c\u65f6\u4fdd\u6301\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "method": "\u5728linformer\u7684\u57fa\u7840\u4e0a\u63d0\u51faSAL-T\uff0c\u5229\u7528\u57fa\u4e8e\u52a8\u91cf\u548c\u51e0\u4f55\u7279\u5f81\u7684\u7a7a\u95f4\u5206\u533a\u5bf9\u7c92\u5b50\u8fdb\u884c\u805a\u7c7b\uff0c\u5e76\u5728\u533a\u57df\u4e4b\u95f4\u8ba1\u7b97\u6ce8\u610f\u529b\u4ee5\u805a\u7126\u7269\u7406\u663e\u8457\u7684\u533a\u57df\uff1b\u5f15\u5165\u5377\u79ef\u5c42\u4ee5\u6355\u6349\u5c40\u90e8\u76f8\u5173\u6027\uff0c\u7ed3\u5408\u7269\u7406\u5b66\u6d1e\u5bdf\u8fdb\u884c\u6a21\u578b\u8bbe\u8ba1\uff1b\u5728Jet\u5206\u7c7b\u548cModelNet10\u7b49\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u5e76\u4e0e\u6807\u51c6linformer\u548c\u5168\u6ce8\u610f\u529b\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cSAL-T\u5728Jet\u5206\u7c7b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u6807\u51c6linformer\uff0c\u5e76\u5728\u5206\u7c7b\u51c6\u786e\u7387\u4e0a\u4e0e\u5168\u6ce8\u610f\u529b\u53d8\u6362\u5668\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8d44\u6e90\u5360\u7528\u548c\u63a8\u7406\u5ef6\u8fdf\uff1bModelNet10\u4e0a\u7684\u5b9e\u9a8c\u4e5f\u652f\u6301\u8fd9\u4e00\u8d8b\u52bf\uff1b\u5e76\u63d0\u4f9b\u4ee3\u7801\u5b9e\u73b0\u3002", "conclusion": "\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u9a71\u52a8\u7684\u533a\u57df\u5316\u6ce8\u610f\u529b\u4e0e\u5c40\u90e8\u5377\u79ef\uff0cSAL-T\u5b9e\u73b0\u4e86\u9ad8\u541e\u5410\u573a\u666f\u4e0b\u7684\u9ad8\u6548\u4e14\u5177\u6709\u7ade\u4e89\u529b\u7684Transformer\u53d8\u4f53\uff0c\u4e3aLHC\u7ea7\u522b\u7684\u6570\u636e\u5206\u6790\u4efb\u52a1\u63d0\u4f9b\u53ef\u90e8\u7f72\u7684\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2510.24597", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24597", "abs": "https://arxiv.org/abs/2510.24597", "authors": ["Longpan Wang", "Zhuoran Zhang", "Zhenyuan Li", "Xuetao Gan", "Xudong Bai", "Wen Chen", "Qingqing Wu"], "title": "Multifunctional Wideband Digital Metasurface for Secure Electromagnetic Manipulation in S-Band", "comment": null, "summary": "Digital metasurfaces have attracted significant attention in recent years due\nto their ability to manipulate electromagnetic (EM) waves for secure sensing\nand communication. However, most reported metasurfaces operate at relatively\nhigh frequencies, primarily due to the constraints imposed by the physical\nscale of the dielectric substrate, thus limiting their full-wave system\napplications. In this work, a wideband digital reflective metasurface is\npresented for capable of dynamically controlling EM waves, with multifunctional\napplications in the lower-frequency S-band. The metasurface is composed of\nelectronically reconfigurable meta-atoms with wideband characteristics, and\ndesigned by using trapezoidal and M-shaped patches connected by a pin diode.\nSimulation results show that the proposed digital metasurface could achieve\nwideband 1-bit phase quantization with a stable phase difference within 180\ndegree +/- 25 degree and small reflection loss below 0.6 dB from 2.72 to 3.25\nGHz. To validate the proposed design, a 20x20-unit metasurface array was\ndesigned, simulated and fabricated. By dynamically adjusting the coding\nsequence, the metasurface could enable multi-mode orbital angular momentum\n(OAM) beam generation, dynamic beam scanning, and precise direction finding.\nThese capabilities support secure sensing and secure communications through\nhigh-resolution target detection and anti-jamming beam steering, as well as\nphysical-layer security. The proposed wideband metasurface may serve as an\neffective candidate for enhancing spectral efficiency and security performance\nin radar and wireless systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5de5\u4f5c\u5728S\u9891\u6bb5\u7684\u5bbd\u5e26\u6570\u5b57\u53cd\u5c04\u5143\u8868\u9762\uff0c\u91c7\u7528\u68af\u5f62\u548cM\u5f62\u8d34\u7247+\u9488\u5f0f\u4e8c\u6781\u7ba1\u5b9e\u73b01\u4f4d\u76f8\u91cf\u5316\uff0c2.72\u20133.25 GHz\u53cd\u5c04\u635f\u8017<0.6 dB\u3002\u901a\u8fc720\u00d720\u9635\u5217\u6f14\u793a\u53ef\u5b9e\u73b0\u591a\u6a21OAM\u6ce2\u3001\u6ce2\u675f\u626b\u63cf\u548c\u5b9a\u5411\u63a2\u6d4b\uff0c\u63d0\u5347\u5b89\u5168\u611f\u77e5\u4e0e\u901a\u4fe1\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5143\u8868\u9762\u5bf9\u9ad8\u9891\u6bb5\u7684\u4f9d\u8d56\u5bfc\u81f4\u5c3a\u5bf8\u548c\u635f\u8017\u95ee\u9898\uff0c\u96be\u4ee5\u5728\u8f83\u4f4e\u9891\u6bb5\u5b9e\u73b0\u5bbd\u5e26\u3001\u4f4e\u6210\u672c\u7684\u5927\u5c3a\u5ea6\u3001\u6570\u5b57\u5316\u3001\u53ef\u91cd\u6784\u7684\u7cfb\u7edf\u3002\u9700\u8981\u5728S\u6ce2\u6bb5\u7b49\u66f4\u4f4e\u9891\u6bb5\u5b9e\u73b0\u5bbd\u5e26\u6570\u5b57\u5316\u4e0e\u5b89\u5168\u529f\u80fd\u7684\u5143\u8868\u9762\u3002", "method": "\u8bbe\u8ba1\u4e86\u7531\u68af\u5f62\u548cM\u5f62\u8d34\u7247\u6784\u6210\u7684\u53ef\u7535\u5b50\u91cd\u6784\u5bbd\u5e26\u5355\u6bd4\u7279\u5143\u5355\u5143\uff0c\u91c7\u7528\u9488\u4e8c\u6781\u7ba1\u5b9e\u73b0\u76f8\u4f4d\u53ef\u63a7\u76841-bit\u91cf\u5316\uff1b\u901a\u8fc7\u6570\u5b57\u7f16\u7801\u5e8f\u5217\u5b9e\u73b0\u591a\u6a21OAM\u3001\u52a8\u6001\u6ce2\u675f\u626b\u63cf\u548c\u5b9a\u5411\u63a2\u6d4b\u3002\u5b8c\u6210\u4e8620\u00d720\u5355\u5143\u9635\u5217\u7684\u8bbe\u8ba1\u3001\u4eff\u771f\u4e0e\u5236\u9020\u9a8c\u8bc1\u3002", "result": "\u57282.72\u20133.25 GHz\u8303\u56f4\u5185\u5b9e\u73b0\u5bbd\u5e26\u76841-bit\u76f8\u4f4d\u91cf\u5316\uff0c\u76f8\u4f4d\u5dee\u7a33\u5b9a\u5728180\u00b0\u00b125\u00b0\uff0c\u53cd\u5c04\u635f\u8017<0.6 dB\uff1b20\u00d720\u9635\u5217\u7684\u4eff\u771f\u4e0e\u5b9e\u7269\u9a8c\u8bc1\u663e\u793a\u53ef\u901a\u8fc7\u7f16\u7801\u5b9e\u73b0OAM\u6ce2\u751f\u6210\u3001\u6ce2\u675f\u626b\u63cf\u4e0e\u7cbe\u786e\u5b9a\u5411\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5bbd\u5e26\u6570\u5b57\u53cd\u5c04\u5143\u8868\u9762\u53ef\u63d0\u5347\u96f7\u8fbe\u4e0e\u65e0\u7ebf\u7cfb\u7edf\u7684\u9891\u8c31\u6548\u7387\u4e0e\u5b89\u5168\u6027\uff0c\u4f5c\u4e3a\u9ad8\u5206\u8fa8\u7387\u63a2\u6d4b\u3001\u6297\u5e72\u6270\u6ce2\u675f\u6307\u5411\u548c\u7269\u7406\u5c42\u5b89\u5168\u7684\u6709\u6548\u5019\u9009\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.23931", "categories": ["cs.LG", "cs.CR", "cs.DC", "68T07 (Primary) 68M14, 68P27, 68Q32, 94A16, 62H35 (Secondary)", "I.2.11; I.2.6; C.2.4; D.4.6; K.4.1"], "pdf": "https://arxiv.org/pdf/2510.23931", "abs": "https://arxiv.org/abs/2510.23931", "authors": ["Miguel Fernandez-de-Retana", "Unai Zulaika", "Rub\u00e9n S\u00e1nchez-Corcuera", "Aitor Almeida"], "title": "Differential Privacy: Gradient Leakage Attacks in Federated Learning Environments", "comment": "17 pages, 12 figures", "summary": "Federated Learning (FL) allows for the training of Machine Learning models in\na collaborative manner without the need to share sensitive data. However, it\nremains vulnerable to Gradient Leakage Attacks (GLAs), which can reveal private\ninformation from the shared model updates. In this work, we investigate the\neffectiveness of Differential Privacy (DP) mechanisms - specifically, DP-SGD\nand a variant based on explicit regularization (PDP-SGD) - as defenses against\nGLAs. To this end, we evaluate the performance of several computer vision\nmodels trained under varying privacy levels on a simple classification task,\nand then analyze the quality of private data reconstructions obtained from the\nintercepted gradients in a simulated FL environment. Our results demonstrate\nthat DP-SGD significantly mitigates the risk of gradient leakage attacks,\nalbeit with a moderate trade-off in model utility. In contrast, PDP-SGD\nmaintains strong classification performance but proves ineffective as a\npractical defense against reconstruction attacks. These findings highlight the\nimportance of empirically evaluating privacy mechanisms beyond their\ntheoretical guarantees, particularly in distributed learning scenarios where\ninformation leakage may represent an unassumable critical threat to data\nsecurity and privacy.", "AI": {"tldr": "DP-SGD reduces gradient leakage risk with moderate utility loss; PDP-SGD preserves accuracy but fails to defend against reconstruction", "motivation": "Evaluate DP mechanisms against gradient leakage in federated learning", "method": "Train CV models under varying privacy levels in a simulated FL setup; analyze reconstructed data from gradients; compare DP-SGD vs PDP-SGD", "result": "DP-SGD mitigates gradient leakage; moderate utility loss; PDP-SGD preserves accuracy but ineffective against reconstruction attacks", "conclusion": "Beyond theoretical privacy guarantees, empirical evaluation is crucial for distributed learning leakage risks; choose defenses accordingly"}}
{"id": "2510.23650", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23650", "abs": "https://arxiv.org/abs/2510.23650", "authors": ["Wei Xia"], "title": "Beyond Hidden-Layer Manipulation: Semantically-Aware Logit Interventions for Debiasing LLMs", "comment": null, "summary": "We proposed Static and Dynamic -- two zero-shot logits-layer debiasing\nmethods. Dynamic reduces bias by up to 70% with minimal fluency loss. Logits\nintervention outperforms hidden-layer approaches. We show semantic-aware logits\nintervention is stable and effective for debiasing aligned LLMs.", "AI": {"tldr": "\u63d0\u51fa\u9759\u6001\u4e0e\u52a8\u6001\u4e24\u79cd\u96f6-shot logits \u5c42\u53bb\u504f\u65b9\u6cd5\u3002\u52a8\u6001\u65b9\u6cd5\u5728\u6700\u5c0f\u6d41\u7545\u5ea6\u635f\u5931\u4e0b\u5c06\u504f\u5dee\u964d\u4f4e\u6700\u591a 70%\uff1blogits \u5e72\u9884\u4f18\u4e8e\u9690\u85cf\u5c42\u65b9\u6cd5\uff1b\u8bed\u4e49\u611f\u77e5\u7684 logits \u5e72\u9884\u5728\u5bf9\u9f50\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7a33\u5b9a\u4e14\u6709\u6548\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u96f6-shot \u60c5\u51b5\u4e0b\u7684\u504f\u89c1\u95ee\u9898\uff0c\u907f\u514d\u9891\u7e41\u7684\u5fae\u8c03\u6216\u9690\u85cf\u5c42\u6539\u52a8\uff0c\u6bd4\u8f83 logits \u5c42\u53bb\u504f\u4e0e\u9690\u85cf\u5c42\u53bb\u504f\u7684\u6548\u679c\u4e0e\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa Static \u4e0e Dynamic \u4e24\u79cd\u96f6-shot logits \u5c42\u53bb\u504f\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165 logits \u5e72\u9884\u53ca\u5176\u8bed\u4e49\u611f\u77e5\u53d8\u4f53\uff0c\u4f5c\u4e3a\u5bf9\u9f50 LLM \u7684\u53bb\u504f\u7b56\u7565\uff0c\u8bc4\u4f30\u5728\u96f6-shot \u573a\u666f\u4e2d\u7684\u504f\u5dee\u51cf\u5c11\u4e0e\u6d41\u7545\u5ea6\u4fdd\u6301\u3002", "result": "Dynamic \u65b9\u6cd5\u5728\u5bf9\u504f\u5dee\u7684\u51cf\u5c11\u4e0a\u53ef\u8fbe 70% \u7ea7\u522b\uff0c\u4e14\u5bf9\u8bed\u8a00\u6d41\u7545\u5ea6\u635f\u5931\u6781\u5c0f\uff1blogits \u5e72\u9884\u4f18\u4e8e\u9690\u85cf\u5c42\u65b9\u6cd5\uff1b\u8bed\u4e49\u611f\u77e5\u7684 logits \u5e72\u9884\u5728\u5bf9\u9f50 LLMs \u4e0a\u8868\u73b0\u7a33\u5b9a\u4e14\u6709\u6548\u3002", "conclusion": "\u96f6-shot logits \u5c42\u53bb\u504f\u662f\u4e00\u79cd\u6709\u6548\u4e14\u9c81\u68d2\u7684\u7b56\u7565\uff0c\u5c24\u5176\u662f\u8bed\u4e49\u611f\u77e5\u7684 logits \u5e72\u9884\u5728\u5bf9\u9f50\u6a21\u578b\u4e2d\u5177\u6709\u8f83\u5f3a\u7684\u7a33\u5b9a\u6027\u4e0e\u6548\u679c\u3002"}}
{"id": "2510.24200", "categories": ["cs.LG", "cs.CR", "cs.DC", "I.2.11"], "pdf": "https://arxiv.org/pdf/2510.24200", "abs": "https://arxiv.org/abs/2510.24200", "authors": ["Alexander Bakarsky", "Dimitar I. Dimitrov", "Maximilian Baader", "Martin Vechev"], "title": "SPEAR++: Scaling Gradient Inversion via Sparsely-Used Dictionary Learning", "comment": "Published at the Workshop on Regulatable ML at the 39th Conference on\n  Neural Information Processing Systems (NeurIPS 2025)", "summary": "Federated Learning has seen an increased deployment in real-world scenarios\nrecently, as it enables the distributed training of machine learning models\nwithout explicit data sharing between individual clients. Yet, the introduction\nof the so-called gradient inversion attacks has fundamentally challenged its\nprivacy-preserving properties. Unfortunately, as these attacks mostly rely on\ndirect data optimization without any formal guarantees, the vulnerability of\nreal-world systems remains in dispute and requires tedious testing for each new\nfederated deployment. To overcome these issues, recently the SPEAR attack was\nintroduced, which is based on a theoretical analysis of the gradients of linear\nlayers with ReLU activations. While SPEAR is an important theoretical\nbreakthrough, the attack's practicality was severely limited by its exponential\nruntime in the batch size b. In this work, we fill this gap by applying\nState-of-the-Art techniques from Sparsely-Used Dictionary Learning to make the\nproblem of gradient inversion on linear layers with ReLU activations tractable.\nOur experiments demonstrate that our new attack, SPEAR++, retains all desirable\nproperties of SPEAR, such as robustness to DP noise and FedAvg aggregation,\nwhile being applicable to 10x bigger batch sizes.", "AI": {"tldr": "\u63d0\u51faSPEAR++\uff0c\u901a\u8fc7\u7a00\u758f\u5b57\u5178\u5b66\u4e60\u63d0\u5347\u68af\u5ea6\u53cd\u6f14\u5728\u7ebf\u6027\u5c42+ReLU\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4f7f\u6279\u5927\u5c0f\u63d0\u534710x\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9DP\u566a\u58f0\u4e0eFedAvg\u805a\u5408\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u5b9e\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e2d\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u7684\u53ef\u884c\u6027\u95ee\u9898\uff1a\u539fSPEAR\u5728\u6279\u91cf\u5927\u5c0f\u589e\u957f\u65f6\u8ba1\u7b97\u590d\u6742\u5ea6\u6307\u6570\u7ea7\uff0c\u96be\u4ee5\u7528\u4e8e\u5b9e\u9645\u6d4b\u8bd5\u4e0e\u8bc4\u4f30\u3002\u5e0c\u671b\u7ed9\u51fa\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u9c81\u68d2\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u4ee5\u8bc4\u4f30\u771f\u5b9e\u7cfb\u7edf\u7684\u9690\u79c1\u98ce\u9669\u3002", "method": "\u5728SPEAR\u7684\u57fa\u7840\u4e0a\u5f15\u5165\u7a00\u758f\u4f7f\u7528\u5b57\u5178\u5b66\u4e60\uff08Sparsely-Used Dictionary Learning\uff09\u6280\u672f\uff0c\u9488\u5bf9\u5e26ReLU\u7684\u7ebf\u6027\u5c42\u68af\u5ea6\uff0c\u91c7\u7528\u5b57\u5178\u5b66\u4e60\u548c\u7a00\u758f\u8868\u793a\u6765\u9ad8\u6548\u91cd\u5efa\u8f93\u5165\uff0c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u63d0\u5347\u5bf9\u5927\u6279\u91cf\u7684\u9002\u5e94\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9DP\u566a\u58f0\u4e0eFedAvg\u805a\u5408\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSPEAR++\u5728\u4fdd\u6301SPEAR\u7684\u6838\u5fc3\u5c5e\u6027\uff08\u5bf9DP\u566a\u58f0\u4e0eFedAvg\u805a\u5408\u7684\u9c81\u68d2\u6027\uff09\u7684\u540c\u65f6\uff0c\u80fd\u591f\u5904\u7406\u5927\u7ea610\u500d\u7684\u6279\u5927\u5c0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "SPEAR++\u4f7f\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u5728\u73b0\u5b9e\u7684\u8054\u90a6\u5b66\u4e60\u90e8\u7f72\u4e2d\u66f4\u52a0\u53ef\u884c\uff0c\u4fbf\u4e8e\u8fdb\u884c\u9690\u79c1\u98ce\u9669\u8bc4\u4f30\u548c\u7cfb\u7edf\u9c81\u68d2\u6027\u6d4b\u8bd5\uff1b\u4f46\u4e5f\u63d0\u793a\u9700\u8981\u52a0\u5f3a\u9632\u62a4\u4ee5\u62b5\u5fa1\u6b64\u7c7b\u66f4\u9ad8\u6548\u7684\u653b\u51fb\u3002"}}
{"id": "2510.23652", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23652", "abs": "https://arxiv.org/abs/2510.23652", "authors": ["Yao Lu", "Yuqi Li", "Wenbin Xie", "Shanqing Yu", "Qi Xuan", "Zhaowei Zhu", "Shiping Wen"], "title": "The Structural Scalpel: Automated Contiguous Layer Pruning for Large Language Models", "comment": null, "summary": "Although large language models (LLMs) have achieved revolutionary\nbreakthroughs in many fields, their large model size and high computational\ncost pose significant challenges for practical deployment on\nresource-constrained edge devices. To this end, layer pruning has been proposed\nto reduce the computational overhead by directly removing redundant layers.\nHowever, existing layer pruning methods typically rely on hand-crafted metrics\nto evaluate and remove individual layers, while ignoring the dependencies\nbetween layers. This can disrupt the model's information flow and severely\ndegrade performance. To address these issues, we propose CLP, a novel\ncontinuous layer pruning framework that introduces two key innovations: a\ndifferentiable concave gate algorithm that automatically identifies the best\ncontinuous layer segments for pruning via gradient-based optimization; and a\ncutoff endpoint tuning strategy that effectively restores model performance by\nfine-tuning only the layers adjacent to the pruned segments. Extensive\nexperiments across multiple model architectures (including LLaMA2, LLaMA3 and\nQwen) and sizes (from $7$B to $70$B parameters) show that CLP significantly\noutperforms existing state-of-the-art baselines. For example, at a pruning rate\nof $20\\%$, CLP achieves an average performance retention of $95.34\\%$ on\nLLaMA3-70B, outperforming baselines by $4.29\\%$-$30.52\\%$. Furthermore, CLP can\nbe seamlessly combined with quantization to further compress the model with\nonly a slight performance loss.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8fde\u7eed\u5c42\u526a\u679d\u6846\u67b6 CLP\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u51f9\u95e8\u63a7\u548c\u7aef\u70b9\u8c03\u4f18\u6765\u667a\u80fd\u88c1\u526a\u8fde\u7eed\u5c42\u6bb5\uff0c\u4ee5\u6700\u5927\u5316\u526a\u679d\u540e\u7684\u4fe1\u606f\u6d41\u4fdd\u7559\u5e76\u517c\u5bb9\u91cf\u5316\u3002", "motivation": "LLMs\u4f53\u91cf\u5de8\u5927\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u3002\u73b0\u6709\u5c42\u526a\u679d\u591a\u4f9d\u8d56\u624b\u5de5\u5ea6\u91cf\u4e14\u5ffd\u7565\u5c42\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bb9\u6613\u7834\u574f\u4fe1\u606f\u6d41\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u8003\u8651\u5c42\u95f4\u5173\u7cfb\u7684\u81ea\u9002\u5e94\u526a\u679d\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa CLP\uff1a\u5305\u542b\u53ef\u5fae\u5206\u7684\u51f9\u95e8\u63a7\u7b97\u6cd5\uff0c\u7528\u68af\u5ea6\u4f18\u5316\u81ea\u52a8\u8bc6\u522b\u6700\u4f73\u8fde\u7eed\u5f85\u526a\u679d\u5c42\u6bb5\uff1b\u4ee5\u53ca\u7aef\u70b9\u8c03\u4f18\u7b56\u7565\uff0c\u901a\u8fc7\u5fae\u8c03\u88ab\u526a\u6bb5\u90bb\u8fd1\u7684\u5c42\u6765\u6062\u590d\u6027\u80fd\u3002\u5bf9 LLaMA2\u3001LLaMA3\u3001Qwen \u7b49\u6a21\u578b\uff0c\u89c4\u6a21\u4ece 7B \u5230 70B \u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u5e76\u53ef\u4e0e\u91cf\u5316\u7ed3\u5408\u3002", "result": "\u5728 20% \u526a\u679d\u7387\u4e0b\uff0cLLaMA3-70B \u7684\u5e73\u5747\u6027\u80fd\u4fdd\u7559\u7387\u4e3a 95.34%\uff0c\u76f8\u8f83\u57fa\u7ebf\u63d0\u9ad8\u7ea6 4.29%\u201330.52% \u7684\u6027\u80fd\u4fdd\u7559\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u6a21\u578b\u548c\u89c4\u6a21\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5e76\u53ef\u4e0e\u91cf\u5316\u534f\u540c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u4e14\u6027\u80fd\u635f\u5931\u6781\u5c0f\u3002", "conclusion": "CLP \u63d0\u4f9b\u4e86\u4e00\u79cd\u5bf9\u4fe1\u606f\u6d41\u53cb\u597d\u7684\u8fde\u7eed\u5c42\u526a\u679d\u6846\u67b6\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u53ef\u4e0e\u91cf\u5316\u7ed3\u5408\u8fdb\u4e00\u6b65\u538b\u7f29\u6a21\u578b\u3002"}}
{"id": "2510.23657", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23657", "abs": "https://arxiv.org/abs/2510.23657", "authors": ["Saklain Niam", "Tashfiqur Rahman", "Md. Amjad Patwary", "Mukarram Hossain"], "title": "A machine learning framework integrating seed traits and plasma parameters for predicting germination uplift in crops", "comment": null, "summary": "Cold plasma (CP) is an eco-friendly method to enhance seed germination, yet\noutcomes remain difficult to predict due to complex seed--plasma--environment\ninteractions. This study introduces the first machine learning framework to\nforecast germination uplift in soybean, barley, sunflower, radish, and tomato\nunder dielectric barrier discharge (DBD) plasma. Among the models tested (GB,\nXGB, ET, and hybrids), Extra Trees (ET) performed best (R\\textsuperscript{2} =\n0.919; RMSE = 3.21; MAE = 2.62), improving to R\\textsuperscript{2} = 0.925\nafter feature reduction. Engineering analysis revealed a hormetic response:\nnegligible effects at $<$7 kV or $<$200 s, maximum germination at 7--15 kV for\n200--500 s, and reduced germination beyond 20 kV or prolonged exposures.\nDischarge power was also a dominant factor, with germination rate maximizing at\n$\\geq$100 W with low exposure time. Species and cultivar-level predictions\nshowed radish (MAE = 1.46) and soybean (MAE = 2.05) were modeled with high\nconsistency, while sunflower remained slightly higher variable (MAE = 3.80).\nAmong cultivars, Williams (MAE = 1.23) and Sari (1.33) were well predicted,\nwhile Arian (2.86) and Ny\\'{\\i}rs\\'{e}gi fekete (3.74) were comparatively\npoorly captured. This framework was also embedded into MLflow, providing a\ndecision-support tool for optimizing CP seed germination in precision\nagriculture.", "AI": {"tldr": "\u9996\u6b21\u6784\u5efa\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u51b7\u7b49\u79bb\u5b50\u4f53\uff08DBD\uff09\u5904\u7406\u4e0b\u7684\u79cd\u5b50\u53d1\u82bd\u63d0\u5347\uff0cET \u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u7279\u5f81\u964d\u7ef4\u540e\u8fdb\u4e00\u6b65\u63d0\u9ad8\uff1b\u63ed\u793a hormetic \u54cd\u5e94\u4e0e\u653e\u7535\u53c2\u6570\u7684\u5173\u952e\u5f71\u54cd\uff0c\u5e76\u63d0\u4f9b\u9762\u5411\u7cbe\u51c6\u519c\u4e1a\u7684\u51b3\u7b56\u5de5\u5177\uff08MLflow \u96c6\u6210\uff09\u3002", "motivation": "\u7eff\u8272\u751f\u6001\u7684\u4f4e\u6e29\u7b49\u79bb\u5b50\u4f53\u5904\u7406\u53ef\u63d0\u5347\u79cd\u5b50\u53d1\u82bd\uff0c\u4f46\u53d7\u79cd-\u7b49\u79bb\u5b50\u4f53-\u73af\u5883\u590d\u6742\u76f8\u4e92\u4f5c\u7528\u5f71\u54cd\uff0c\u96be\u4ee5\u9884\u6d4b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u53ef\u6cdb\u5316\u7684\u9884\u6d4b\u6846\u67b6\u6765\u4f18\u5316\u5904\u7406\u6761\u4ef6\u3002", "method": "\u5728\u5927\u8c46\u3001\u71d5\u9ea6\u3001\u5411\u65e5\u8475\u3001\u841d\u535c\u548c\u756a\u8304\u7b49\u7269\u79cd\u4e0b\uff0c\u4f7f\u7528 Dielectric Barrier Discharge\uff08DBD\uff09\u7b49\u79bb\u5b50\u4f53\uff0c\u6bd4\u8f83 GB\u3001XGB\u3001ET \u53ca\u6df7\u5408\u6a21\u578b\uff0c\u7279\u5f81\u964d\u7ef4\u540e ET \u8868\u73b0\u6700\u4f73\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u9884\u6d4b\u53d1\u82bd\u63d0\u5347\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u5c06\u5176\u5d4c\u5165 MLflow\uff1b\u5e76\u5bf9\u653e\u7535\u529f\u7387\u3001\u66b4\u9732\u65f6\u95f4\u3001\u5242\u91cf\u7b49\u53d8\u91cf\u8fdb\u884c\u5206\u6790\u3002", "result": "ET \u7684 R^2 0.919\u3001RMSE 3.21\u3001MAE 2.62\uff0c\u964d\u7ef4\u540e R^2 0.925\uff1b\u51fa\u73b0 hormetic \u54cd\u5e94\uff1a<7 kV \u6216 <200 s \u65e0\u660e\u663e\u63d0\u5347\uff0c7\u201315 kV\u3001200\u2013500 s \u65f6\u8fbe\u5230\u6700\u5927\u53d1\u82bd\uff0c>20 kV \u6216\u8fc7\u957f\u66b4\u9732\u65f6\u6291\u5236\u53d1\u82bd\uff1b\u653e\u7535\u529f\u7387\u2265100 W\u3001\u77ed\u66b4\u9732\u65f6\u95f4\u5bf9\u53d1\u82bd\u7387\u6700\u4f18\uff1b\u7269\u79cd\u5c42\u9762\uff1a\u841d\u535c MAE 1.46\u3001\u8c46\u7c7b MAE 2.05\u3001\u5411\u65e5\u8475 MAE 3.80\uff1b\u54c1\u79cd\u5c42\u9762\uff1aWilliams MAE 1.23\u3001Sari 1.33\u3001Arian 2.86\u3001Ny\u00edrs\u00e9g fekete 3.74\uff1b\u5e76\u5c06\u6846\u67b6\u5d4c\u5165 MLflow \u63d0\u4f9b\u519c\u4e1a\u7cbe\u51c6\u51b3\u7b56\u652f\u6301\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\u53ef\u5bf9 CP \u53d1\u82bd\u63d0\u5347\u8fdb\u884c\u9ad8\u51c6\u786e\u5ea6\u9884\u6d4b\uff0c\u5e76\u63ed\u793a\u5173\u952e\u7269\u7406\u53c2\u6570\u7684\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u4e3a\u5728\u7cbe\u51c6\u519c\u4e1a\u4e2d\u5229\u7528 CP \u8fdb\u884c\u79cd\u5b50\u5904\u7406\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u4f18\u5316\u7b56\u7565\u4e0e\u51b3\u7b56\u5de5\u5177\u3002"}}
{"id": "2510.24614", "categories": ["cs.LG", "cs.CE", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24614", "abs": "https://arxiv.org/abs/2510.24614", "authors": ["James Josep Perry", "Pablo Garcia-Conde Ortiz", "George Konstantinou", "Cornelie Vergouwen", "Edlyn Santha Kumaran", "Morteza Moradi"], "title": "Semi-supervised and unsupervised learning for health indicator extraction from guided waves in aerospace composite structures", "comment": null, "summary": "Health indicators (HIs) are central to diagnosing and prognosing the\ncondition of aerospace composite structures, enabling efficient maintenance and\noperational safety. However, extracting reliable HIs remains challenging due to\nvariability in material properties, stochastic damage evolution, and diverse\ndamage modes. Manufacturing defects (e.g., disbonds) and in-service incidents\n(e.g., bird strikes) further complicate this process. This study presents a\ncomprehensive data-driven framework that learns HIs via two learning approaches\nintegrated with multi-domain signal processing. Because ground-truth HIs are\nunavailable, a semi-supervised and an unsupervised approach are proposed: (i) a\ndiversity deep semi-supervised anomaly detection (Diversity-DeepSAD) approach\naugmented with continuous auxiliary labels used as hypothetical damage proxies,\nwhich overcomes the limitation of prior binary labels that only distinguish\nhealthy and failed states while neglecting intermediate degradation, and (ii) a\ndegradation-trend-constrained variational autoencoder (DTC-VAE), in which the\nmonotonicity criterion is embedded via an explicit trend constraint. Guided\nwaves with multiple excitation frequencies are used to monitor single-stiffener\ncomposite structures under fatigue loading. Time, frequency, and time-frequency\nrepresentations are explored, and per-frequency HIs are fused via unsupervised\nensemble learning to mitigate frequency dependence and reduce variance. Using\nfast Fourier transform features, the augmented Diversity-DeepSAD model achieved\n81.6% performance, while DTC-VAE delivered the most consistent HIs with 92.3%\nperformance, outperforming existing baselines.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23659", "categories": ["cs.LG", "cs.CV", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.23659", "abs": "https://arxiv.org/abs/2510.23659", "authors": ["Md. Farhan Shahriyar", "Gazi Tanbhir", "Abdullah Md Raihan Chy"], "title": "Quantum Machine Learning for Image Classification: A Hybrid Model of Residual Network with Quantum Support Vector Machine", "comment": null, "summary": "Recently, there has been growing attention on combining quantum machine\nlearning (QML) with classical deep learning approaches, as computational\ntechniques are key to improving the performance of image classification tasks.\nThis study presents a hybrid approach that uses ResNet-50 (Residual Network)\nfor feature extraction and Quantum Support Vector Machines (QSVM) for\nclassification in the context of potato disease detection. Classical machine\nlearning as well as deep learning models often struggle with high-dimensional\nand complex datasets, necessitating advanced techniques like quantum computing\nto improve classification efficiency. In our research, we use ResNet-50 to\nextract deep feature representations from RGB images of potato diseases. These\nfeatures are then subjected to dimensionality reduction using Principal\nComponent Analysis (PCA). The resulting features are processed through QSVM\nmodels which apply various quantum feature maps such as ZZ, Z, and Pauli-X to\ntransform classical data into quantum states. To assess the model performance,\nwe compared it with classical machine learning algorithms such as Support\nVector Machine (SVM) and Random Forest (RF) using five-fold stratified\ncross-validation for comprehensive evaluation. The experimental results\ndemonstrate that the Z-feature map-based QSVM outperforms classical models,\nachieving an accuracy of 99.23 percent, surpassing both SVM and RF models. This\nresearch highlights the advantages of integrating quantum computing into image\nclassification and provides a potential disease detection solution through\nhybrid quantum-classical modeling.", "AI": {"tldr": "A hybrid quantum-classical framework using ResNet-50 for feature extraction, PCA for dimensionality reduction, and QSVM with Z/ZZ/Pauli-X quantum feature maps for potato disease image classification. The Z-feature map QSVM achieves 99.23% accuracy, outperforming classical SVM and RF in five-fold cross-validation.", "motivation": "Explores the synergy between quantum machine learning and classical deep learning to tackle high-dimensional image data and potentially improve classification accuracy in plant disease detection.", "method": "Extract deep features from RGB potato disease images using ResNet-50, reduce dimensionality with PCA, then classify with QSVM using multiple quantum feature maps (ZZ, Z, Pauli-X); compare against classical SVM and RF using five-fold stratified cross-validation.", "result": "QSVM with the Z-feature map achieved 99.23% accuracy, outperforming both SVM and RF baselines.", "conclusion": "Hybrid quantum-classical modeling can enhance image classification performance in plant disease detection, demonstrating the potential of integrating quantum computing into practical computer vision tasks."}}
{"id": "2510.23663", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23663", "abs": "https://arxiv.org/abs/2510.23663", "authors": ["Padmanabhan Jagannathan Prajesh", "Kaliaperumal Ragunath", "Miriam Gordon", "Bruce Rathgeber", "Suresh Neethirajan"], "title": "AI-Driven Carbon Monitoring: Transformer-Based Reconstruction of Atmospheric CO2 in Canadian Poultry Regions", "comment": null, "summary": "Accurate mapping of column-averaged CO2 (XCO2) over agricultural landscapes\nis essential for guiding emission mitigation strategies. We present a\nSpatiotemporal Vision Transformer with Wavelets (ST-ViWT) framework that\nreconstructs continuous, uncertainty-quantified XCO2 fields from OCO-2 across\nsouthern Canada, emphasizing poultry-intensive regions. The model fuses wavelet\ntime-frequency representations with transformer attention over meteorology,\nvegetation indices, topography, and land cover. On 2024 OCO-2 data, ST-ViWT\nattains R2 = 0.984 and RMSE = 0.468 ppm; 92.3 percent of gap-filled predictions\nlie within +/-1 ppm. Independent validation with TCCON shows robust\ngeneralization (bias = -0.14 ppm; r = 0.928), including faithful reproduction\nof the late-summer drawdown. Spatial analysis across 14 poultry regions reveals\na moderate positive association between facility density and XCO2 (r = 0.43);\nhigh-density areas exhibit larger seasonal amplitudes (9.57 ppm) and enhanced\nsummer variability. Compared with conventional interpolation and standard\nmachine-learning baselines, ST-ViWT yields seamless 0.25 degree CO2 surfaces\nwith explicit uncertainties, enabling year-round coverage despite sparse\nobservations. The approach supports integration of satellite constraints with\nnational inventories and precision livestock platforms to benchmark emissions,\nrefine region-specific factors, and verify interventions. Importantly,\ntransformer-based Earth observation enables scalable, transparent, spatially\nexplicit carbon accounting, hotspot prioritization, and policy-relevant\nmitigation assessment.", "AI": {"tldr": "ST-ViWT: a Spatiotemporal Vision Transformer with Wavelets that reconstructs continuous, uncertainty-quantified XCO2 fields from OCO-2 data, outperforming baselines and enabling policy-relevant CO2 mapping over agricultural regions.", "motivation": "Need accurate, gap-filled, spatially explicit XCO2 maps with quantified uncertainty to support inventories, mitigation strategies, and verification in agricultural landscapes where data are sparse and heterogeneity is high.", "method": "A Spatiotemporal Vision Transformer that fuses wavelet-based time-frequency representations with transformer attention across meteorology, vegetation indices, topography, and land cover. Trains on 2024 OCO-2 data; validated against TCCON; outputs 0.25-degree XCO2 surfaces with explicit uncertainties and gap-filling in sparse regions.", "result": "On 2024 OCO-2 data, R2 = 0.984, RMSE = 0.468 ppm; 92.3% of gap-filled predictions within \u00b11 ppm. Independent TCCON validation shows bias = -0.14 ppm; r = 0.928. Captures late-summer drawdown. Across 14 poultry regions, XCO2 correlates with facility density (r = 0.43); high-density areas have larger seasonal amplitudes (9.57 ppm) and enhanced summer variability. Outperforms conventional interpolation and standard ML baselines, yielding seamless 0.25-degree CO2 surfaces with uncertainties, enabling year-round coverage.", "conclusion": "Transformer-based Earth observation enables scalable, transparent, spatially explicit carbon accounting, hotspot prioritization, and policy-relevant mitigation assessment. The approach supports integration with inventories and precision livestock platforms to benchmark emissions and verify interventions."}}
{"id": "2510.23665", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23665", "abs": "https://arxiv.org/abs/2510.23665", "authors": ["Juan C. Leon Alcazar", "Mattia Soldan", "Mohammad Saatialsoruji", "Alejandro Pardo", "Hani Itani", "Juan Camilo Perez", "Bernard Ghanem"], "title": "Transformers from Compressed Representations", "comment": null, "summary": "Compressed file formats are the corner stone of efficient data storage and\ntransmission, yet their potential for representation learning remains largely\nunderexplored. We introduce TEMPEST (TransformErs froM comPressed\nrEpreSenTations), a method that exploits the inherent byte-stream structure of\ncompressed files to design an effective tokenization and encoding strategy. By\nleveraging this compact encoding, a standard transformer can directly learn\nsemantic representations from compressed data streams, bypassing the need for\nraw byte-level processing or full media decoding. Our proposal substantially\nreduces the number of tokens required for semantic classification, thereby\nlowering both computational complexity and memory usage. Through extensive\nexperiments across diverse datasets, coding schemes, and modalities, we show\nthat TEMPEST achieves accuracy competitive wit the state-of-the-art while\ndelivering efficiency gains in memory and compute.", "AI": {"tldr": "TEMPEST \u901a\u8fc7\u5229\u7528\u538b\u7f29\u6587\u4ef6\u7684\u5b57\u8282\u6d41\u7ed3\u6784\u6765\u8bbe\u8ba1 tokenizer/\u7f16\u7801\u7b56\u7565\uff0c\u4f7f transformer \u53ef\u4ee5\u76f4\u63a5\u4ece\u538b\u7f29\u6570\u636e\u6d41\u4e2d\u5b66\u4e60\u8bed\u4e49\u8868\u793a\uff0c\u663e\u8457\u51cf\u5c11\u9700\u8981\u7684 token \u6570\u91cf\u5e76\u964d\u4f4e\u5185\u5b58\u4e0e\u8ba1\u7b97\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6700\u5148\u8fdb\u6a21\u578b\u76f8\u7ade\u4e89\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u6709\u6548\u6570\u636e\u5b58\u50a8\u548c\u4f20\u8f93\u7684\u524d\u63d0\u4e0b\uff0c\u6316\u6398\u538b\u7f29\u683c\u5f0f\u4e2d\u7684\u8868\u5f81\u5b66\u4e60\u6f5c\u529b\uff0c\u907f\u514d\u5bf9\u539f\u59cb\u5b57\u8282\u8fdb\u884c\u9010\u5b57\u5904\u7406\u6216\u5b8c\u6574\u89e3\u7801\uff0c\u63d0\u5347\u6548\u7387\u3002", "method": "\u5229\u7528\u538b\u7f29\u6587\u4ef6\u7684\u5b57\u8282\u6d41\u7ed3\u6784\u6765\u8bbe\u8ba1 tokenization \u4e0e\u7f16\u7801\u7b56\u7565\uff0c\u4f7f\u6807\u51c6 transformer \u76f4\u63a5\u5904\u7406\u538b\u7f29\u6570\u636e\u6d41\uff0c\u8df3\u8fc7\u89e3\u7801\u6b65\u9aa4\uff0c\u51cf\u5c11 token \u6570\u91cf\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u6548\u7684\u8bed\u4e49\u8868\u793a\u5b66\u4e60\u3002", "result": "\u5728\u591a\u79cd\u6570\u636e\u96c6\u3001\u7f16\u7801\u65b9\u6848\u548c\u6a21\u6001\u4e0b\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0cTEMPEST \u7684\u51c6\u786e\u6027\u8fbe\u5230\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\uff0c\u540c\u65f6\u5728\u5185\u5b58\u548c\u8ba1\u7b97\u4e0a\u5b9e\u73b0\u6548\u7387\u63d0\u5347\uff0c\u663e\u8457\u964d\u4f4e token \u6570\u91cf\u3002", "conclusion": "\u8bc1\u660e\u4e86\u4ece\u538b\u7f29\u8868\u793a\u4e2d\u8fdb\u884c\u8bed\u4e49\u5b66\u4e60\u7684\u53ef\u884c\u6027\u4e0e\u9ad8\u6548\u6027\uff0c\u4e3a\u538b\u7f29\u57df\u7684\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u8def\u5f84\uff0cTEMPEST \u53ef\u4f5c\u4e3a\u9ad8\u6548\u7684\u8868\u793a\u5b66\u4e60\u6846\u67b6\u5728\u76f8\u5173\u4efb\u52a1\u4e2d\u5f97\u5230\u5e94\u7528\u3002"}}
{"id": "2510.23667", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.23667", "abs": "https://arxiv.org/abs/2510.23667", "authors": ["Amin Heyrani Nobari", "Lyle Regenwetter", "Cyril Picard", "Ligong Han", "Faez Ahmed"], "title": "Optimize Any Topology: A Foundation Model for Shape- and Resolution-Free Structural Topology Optimization", "comment": null, "summary": "Structural topology optimization (TO) is central to engineering design but\nremains computationally intensive due to complex physics and hard constraints.\nExisting deep-learning methods are limited to fixed square grids, a few\nhand-coded boundary conditions, and post-hoc optimization, preventing general\ndeployment. We introduce Optimize Any Topology (OAT), a foundation-model\nframework that directly predicts minimum-compliance layouts for arbitrary\naspect ratios, resolutions, volume fractions, loads, and fixtures. OAT combines\na resolution- and shape-agnostic autoencoder with an implicit neural-field\ndecoder and a conditional latent-diffusion model trained on OpenTO, a new\ncorpus of 2.2 million optimized structures covering 2 million unique\nboundary-condition configurations. On four public benchmarks and two\nchallenging unseen tests, OAT lowers mean compliance up to 90% relative to the\nbest prior models and delivers sub-1 second inference on a single GPU across\nresolutions from 64 x 64 to 256 x 256 and aspect ratios as high as 10:1. These\nresults establish OAT as a general, fast, and resolution-free framework for\nphysics-aware topology optimization and provide a large-scale dataset to spur\nfurther research in generative modeling for inverse design. Code & data can be\nfound at https://github.com/ahnobari/OptimizeAnyTopology.", "AI": {"tldr": "OAT is a foundation-model framework for topology optimization that predicts minimum-compliance layouts for arbitrary aspect ratios, resolutions, volume fractions, loads, and fixtures. It uses a resolution- and shape-agnostic autoencoder, an implicit neural-field decoder, and a conditional latent-diffusion model trained on a large OpenTO dataset, enabling fast, resolution-free inference across diverse conditions.", "motivation": "TO is computationally intensive due to complex physics and rigid constraints; existing DL methods are limited to fixed grids and boundary conditions, hindering general deployment.", "method": "A resolution- and shape-agnostic autoencoder feeds into an implicit neural-field decoder; a conditional latent-diffusion model generates designs conditioned on problem parameters. Trained on OpenTO, a dataset with 2.2M optimized structures across 2M boundary-condition configurations.", "result": "On four public benchmarks and two unseen tests, OAT achieves up to 90% relative improvement in mean compliance over the best prior models and delivers sub-1-second inference on a single GPU across resolutions from 64x64 to 256x256 and aspect ratios up to 10:1.", "conclusion": "OAT is a general, fast, and resolution-free framework for physics-aware topology optimization and provides a large-scale dataset to spur further research in generative modeling for inverse design; code and data are publicly available."}}
{"id": "2510.23668", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23668", "abs": "https://arxiv.org/abs/2510.23668", "authors": ["Fujiang Yuan", "Yangrui Fan", "Xiaohuan Bing", "Zhen Tian", "Chunhong Yuan", "Yankang Li"], "title": "Traffic flow forecasting, STL decomposition, Hybrid model, LSTM, ARIMA, XGBoost, Intelligent transportation systems", "comment": null, "summary": "Accurate traffic flow forecasting is essential for intelligent transportation\nsystems and urban traffic management. However, single model approaches often\nfail to capture the complex, nonlinear, and multi scale temporal patterns in\ntraffic flow data. This study proposes a decomposition driven hybrid framework\nthat integrates Seasonal Trend decomposition using Loess (STL) with three\ncomplementary predictive models. STL first decomposes the original time series\ninto trend, seasonal, and residual components. Then, a Long Short Term Memory\n(LSTM) network models long term trends, an Autoregressive Integrated Moving\nAverage (ARIMA) model captures seasonal periodicity, and an Extreme Gradient\nBoosting (XGBoost) algorithm predicts nonlinear residual fluctuations. The\nfinal forecast is obtained through multiplicative integration of the sub model\npredictions. Using 998 traffic flow records from a New York City intersection\nbetween November and December 2015, results show that the LSTM ARIMA XGBoost\nhybrid model significantly outperforms standalone models including LSTM, ARIMA,\nand XGBoost across MAE, RMSE, and R squared metrics. The decomposition strategy\neffectively isolates temporal characteristics, allowing each model to\nspecialize, thereby improving prediction accuracy, interpretability, and\nrobustness.", "AI": {"tldr": "\u57fa\u4e8e STL \u5206\u89e3\u7684\u6df7\u5408\u9884\u6d4b\u6846\u67b6\uff1a\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u8d8b\u52bf\u3001\u5b63\u8282\u548c\u6b8b\u5dee\u540e\uff0c\u5206\u522b\u7528 LSTM\u3001ARIMA\u3001XGBoost \u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u91c7\u7528\u4e58\u6cd5\u878d\u5408\u5b9e\u73b0\u6700\u7ec8\u9884\u6d4b\uff0c\u5728 NYC \u4ea4\u901a\u6d41\u6570\u636e\u4e0a\u663e\u8457\u4f18\u4e8e\u5355\u6a21\u578b\u3002", "motivation": "\u5355\u4e00\u6a21\u578b\u5f80\u5f80\u96be\u4ee5\u540c\u65f6\u6355\u6349\u4ea4\u901a\u6d41\u6570\u636e\u7684\u975e\u7ebf\u6027\u548c\u591a\u5c3a\u5ea6\u65f6\u95f4\u7279\u5f81\uff0c\u9700\u901a\u8fc7\u5206\u89e3\u6765\u9694\u79bb\u4e0d\u540c\u6210\u5206\u5e76\u8ba9\u4e13\u95e8\u6a21\u578b\u5404\u81ea\u64c5\u957f\uff0c\u4ece\u800c\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u6027\u4e0e\u9c81\u68d2\u6027\u3002", "method": "\u5bf9\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u4f7f\u7528 STL \u8fdb\u884c\u8d8b\u52bf\u3001\u5b63\u8282\u548c\u6b8b\u5dee\u5206\u89e3\uff1b\u7528 LSTM \u5efa\u6a21\u957f\u671f\u8d8b\u52bf\uff0c\u7528 ARIMA \u6355\u6349\u5b63\u8282\u6027\u5468\u671f\u6027\uff0c\u7528 XGBoost \u9884\u6d4b\u975e\u7ebf\u6027\u6b8b\u5dee\u6ce2\u52a8\uff1b\u6700\u7ec8\u901a\u8fc7\u4e58\u6cd5\u96c6\u6210\u5404\u5b50\u6a21\u578b\u7684\u9884\u6d4b\u3002\u6570\u636e\u96c6\u4e3a 2015 \u5e74 11 \u6708\u81f3 12 \u6708\u7ebd\u7ea6\u5e02\u67d0\u8def\u53e3\u7684 998 \u6761\u4ea4\u901a\u6d41\u8bb0\u5f55\u3002", "result": "\u6df7\u5408\u6a21\u578b\u5728 MAE\u3001RMSE\u3001R^2 \u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5355\u72ec\u7684 LSTM\u3001ARIMA \u548c XGBoost\u3002\u5206\u89e3\u7b56\u7565\u6709\u6548\u9694\u79bb\u65f6\u95f4\u7279\u5f81\uff0c\u4f7f\u5404\u6a21\u578b\u4e13\u4e1a\u5316\uff0c\u4ece\u800c\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u5206\u89e3-\u534f\u540c\u5efa\u6a21\u7684\u7b56\u7565\u80fd\u6709\u6548\u63d0\u53d6\u65f6\u95f4\u5e8f\u5217\u7684\u4e0d\u540c\u6210\u5206\uff0c\u63d0\u5347\u4ea4\u901a\u6d41\u9884\u6d4b\u7684\u6027\u80fd\u4e0e\u7a33\u5065\u6027\uff0c\u4e14\u6709\u52a9\u4e8e\u5bf9\u5404\u7ec4\u4ef6\u7684\u89e3\u91ca\u4e0e\u5206\u6790\u3002"}}
{"id": "2510.23672", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23672", "abs": "https://arxiv.org/abs/2510.23672", "authors": ["Xiangfei Qiu", "Xingjian Wu", "Hanyin Cheng", "Xvyuan Liu", "Chenjuan Guo", "Jilin Hu", "Bin Yang"], "title": "DBLoss: Decomposition-based Loss Function for Time Series Forecasting", "comment": "Accepted by NeurIPS 2025", "summary": "Time series forecasting holds significant value in various domains such as\neconomics, traffic, energy, and AIOps, as accurate predictions facilitate\ninformed decision-making. However, the existing Mean Squared Error (MSE) loss\nfunction sometimes fails to accurately capture the seasonality or trend within\nthe forecasting horizon, even when decomposition modules are used in the\nforward propagation to model the trend and seasonality separately. To address\nthese challenges, we propose a simple yet effective Decomposition-Based Loss\nfunction called DBLoss. This method uses exponential moving averages to\ndecompose the time series into seasonal and trend components within the\nforecasting horizon, and then calculates the loss for each of these components\nseparately, followed by weighting them. As a general loss function, DBLoss can\nbe combined with any deep learning forecasting model. Extensive experiments\ndemonstrate that DBLoss significantly improves the performance of\nstate-of-the-art models across diverse real-world datasets and provides a new\nperspective on the design of time series loss functions.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23681", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23681", "abs": "https://arxiv.org/abs/2510.23681", "authors": ["Carl Hvarfner", "David Eriksson", "Eytan Bakshy", "Max Balandat"], "title": "Informed Initialization for Bayesian Optimization and Active Learning", "comment": "28 pages", "summary": "Bayesian Optimization is a widely used method for optimizing expensive\nblack-box functions, relying on probabilistic surrogate models such as Gaussian\nProcesses. The quality of the surrogate model is crucial for good optimization\nperformance, especially in the few-shot setting where only a small number of\nbatches of points can be evaluated. In this setting, the initialization plays a\ncritical role in shaping the surrogate's predictive quality and guiding\nsubsequent optimization. Despite this, practitioners typically rely on\n(quasi-)random designs to cover the input space. However, such approaches\nneglect two key factors: (a) space-filling designs may not be desirable to\nreduce predictive uncertainty, and (b) efficient hyperparameter learning during\ninitialization is essential for high-quality prediction, which may conflict\nwith space-filling designs. To address these limitations, we propose\nHyperparameter-Informed Predictive Exploration (HIPE), a novel acquisition\nstrategy that balances predictive uncertainty reduction with hyperparameter\nlearning using information-theoretic principles. We derive a closed-form\nexpression for HIPE in the Gaussian Process setting and demonstrate its\neffectiveness through extensive experiments in active learning and few-shot BO.\nOur results show that HIPE outperforms standard initialization strategies in\nterms of predictive accuracy, hyperparameter identification, and subsequent\noptimization performance, particularly in large-batch, few-shot settings\nrelevant to many real-world Bayesian Optimization applications.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23685", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23685", "abs": "https://arxiv.org/abs/2510.23685", "authors": ["Junwen Ma", "Mingyu Ge", "Yisen Wang", "Yong Zhang", "Weicheng Fu"], "title": "Parallel BiLSTM-Transformer networks for forecasting chaotic dynamics", "comment": "9 pages,7 figures", "summary": "The nonlinear nature of chaotic systems results in extreme sensitivity to\ninitial conditions and highly intricate dynamical behaviors, posing fundamental\nchallenges for accurately predicting their evolution. To overcome the\nlimitation that conventional approaches fail to capture both local features and\nglobal dependencies in chaotic time series simultaneously, this study proposes\na parallel predictive framework integrating Transformer and Bidirectional Long\nShort-Term Memory (BiLSTM) networks. The hybrid model employs a dual-branch\narchitecture, where the Transformer branch mainly captures long-range\ndependencies while the BiLSTM branch focuses on extracting local temporal\nfeatures. The complementary representations from the two branches are fused in\na dedicated feature-fusion layer to enhance predictive accuracy. As\nillustrating examples, the model's performance is systematically evaluated on\ntwo representative tasks in the Lorenz system. The first is autonomous\nevolution prediction, in which the model recursively extrapolates system\ntrajectories from the time-delay embeddings of the state vector to evaluate\nlong-term tracking accuracy and stability. The second is inference of\nunmeasured variable, where the model reconstructs the unobserved states from\nthe time-delay embeddings of partial observations to assess its\nstate-completion capability. The results consistently indicate that the\nproposed hybrid framework outperforms both single-branch architectures across\ntasks, demonstrating its robustness and effectiveness in chaotic system\nprediction.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cdTransformer\u4e0eBiLSTM\u5e76\u884c\u6df7\u5408\u6846\u67b6\u7528\u4e8e\u6df7\u6c8c\u7cfb\u7edf\u9884\u6d4b\uff0c\u901a\u8fc7\u53cc\u5206\u652f\u6355\u83b7\u5168\u5c40\u4f9d\u8d56\u548c\u5c40\u90e8\u65f6\u5e8f\u7279\u5f81\uff0c\u5e76\u5728Lorenz\u7cfb\u7edf\u7684\u81ea\u4e3b\u6f14\u5316\u9884\u6d4b\u4e0e\u672a\u89c2\u6d4b\u53d8\u91cf\u63a8\u65ad\u4e24\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5355\u5206\u652f\u6a21\u578b\u3002", "motivation": "\u6df7\u6c8c\u65f6\u95f4\u5e8f\u5217\u5bf9\u521d\u59cb\u6761\u4ef6\u6781\u5ea6\u654f\u611f\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u6355\u6349\u5c40\u90e8\u7279\u5f81\u548c\u5168\u5c40\u4f9d\u8d56\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u6574\u5408\u4e24\u8005\u7684\u9884\u6d4b\u6846\u67b6\u3002", "method": "\u53cc\u5206\u652f\u67b6\u6784\uff0cTransformer\u5206\u652f\u63d0\u53d6\u957f\u7a0b\u4f9d\u8d56\uff0cBiLSTM\u5206\u652f\u63d0\u53d6\u5c40\u90e8\u65f6\u5e8f\u7279\u5f81\uff0c\u5728\u7279\u5f81\u878d\u5408\u5c42\u8fdb\u884c\u878d\u5408\u3002\u4f7f\u7528\u72b6\u6001\u5411\u91cf\u7684\u65f6\u6ede\u5d4c\u5165\uff0c\u8fdb\u884c\u81ea\u56de\u5f52\u5916\u63a8\u548c\u5bf9\u90e8\u5206\u89c2\u6d4b\u7684\u672a\u89c2\u6d4b\u53d8\u91cf\u91cd\u5efa\u3002\u4e24\u4e2a\u4efb\u52a1\uff1a\u81ea\u6cbb\u6f14\u5316\u9884\u6d4b\u548c\u672a\u89c2\u6d4b\u53d8\u91cf\u63a8\u65ad\u3002", "result": "\u5b9e\u9a8c\u5728Lorenz\u7cfb\u7edf\u4e0a\u8868\u660e\u8be5\u6df7\u5408\u6846\u67b6\u5728\u4e24\u4e2a\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u5355\u5206\u652f\u6a21\u578b\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u957f\u671f\u8ddf\u8e2a\u7cbe\u5ea6\u4e0e\u7a33\u5b9a\u6027\uff0c\u4ee5\u53ca\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5c06Transformer\u4e0eBiLSTM\u7684\u4e92\u8865\u8868\u793a\u878d\u5408\u7684\u6df7\u5408\u6846\u67b6\u5bf9\u6df7\u6c8c\u7cfb\u7edf\u9884\u6d4b\u5177\u6709\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u5c06\u5168\u5c40\u548c\u5c40\u90e8\u7279\u5f81\u7ed3\u5408\u7684\u7b56\u7565\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.23693", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.23693", "abs": "https://arxiv.org/abs/2510.23693", "authors": ["Joachim Baumann"], "title": "On the Societal Impact of Machine Learning", "comment": "PhD thesis", "summary": "This PhD thesis investigates the societal impact of machine learning (ML). ML\nincreasingly informs consequential decisions and recommendations, significantly\naffecting many aspects of our lives. As these data-driven systems are often\ndeveloped without explicit fairness considerations, they carry the risk of\ndiscriminatory effects. The contributions in this thesis enable more\nappropriate measurement of fairness in ML systems, systematic decomposition of\nML systems to anticipate bias dynamics, and effective interventions that reduce\nalgorithmic discrimination while maintaining system utility. I conclude by\ndiscussing ongoing challenges and future research directions as ML systems,\nincluding generative artificial intelligence, become increasingly integrated\ninto society. This work offers a foundation for ensuring that ML's societal\nimpact aligns with broader social values.", "AI": {"tldr": "\u672c\u8bba\u6587\uff08\u535a\u58eb\u8bba\u6587\uff09\u5173\u6ce8\u673a\u5668\u5b66\u4e60\u7684\u793e\u4f1a\u5f71\u54cd\uff0c\u805a\u7126\u516c\u5e73\u6027\u6d4b\u91cf\u3001\u504f\u89c1\u52a8\u6001\u7684\u7cfb\u7edf\u6027\u5206\u89e3\uff0c\u4ee5\u53ca\u5728\u4fdd\u6301\u7cfb\u7edf\u6548\u7528\u7684\u524d\u63d0\u4e0b\u51cf\u5c11\u7b97\u6cd5\u6b67\u89c6\u7684\u5e72\u9884\u7b56\u7565\uff1b\u6700\u540e\u8ba8\u8bba\u6311\u6218\u4e0e\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u7279\u522b\u662f\u5728\u751f\u6210\u5f0fAI\u65e5\u76ca\u878d\u5165\u793e\u4f1a\u7684\u80cc\u666f\u4e0b\u7684\u5408\u4ef7\u503c\u53d6\u5411\u3002", "motivation": "ML\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u53c2\u4e0e\u5173\u4e4e\u540e\u679c\u7684\u51b3\u7b56\uff0c\u82e5\u7f3a\u4e4f\u660e\u786e\u7684\u516c\u5e73\u6027\u8003\u91cf\uff0c\u53ef\u80fd\u4ea7\u751f\u6b67\u89c6\u6027\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u5408\u9002\u7684\u516c\u5e73\u6027\u6d4b\u91cf\u3001\u5bf9\u7cfb\u7edf\u504f\u89c1\u7684\u9884\u6d4b\u4e0e\u7406\u89e3\uff0c\u4ee5\u53ca\u6709\u6548\u7684\u5e72\u9884\u624b\u6bb5\u3002", "method": "\u63d0\u51fa\u7528\u4e8e\u66f4\u6070\u5f53\u5730\u6d4b\u91cf\u516c\u5e73\u6027\u7684\u6846\u67b6\u3001\u5bf9ML\u7cfb\u7edf\u8fdb\u884c\u7cfb\u7edf\u6027\u5206\u89e3\u4ee5\u9884\u5224\u504f\u89c1\u52a8\u6001\u3001\u4ee5\u53ca\u8bbe\u8ba1\u5728\u4fdd\u6301\u7cfb\u7edf\u6548\u7528\u7684\u540c\u65f6\u51cf\u5c11\u7b97\u6cd5\u6b67\u89c6\u7684\u5e72\u9884\u7b56\u7565\uff1b\u5e76\u5728\u672a\u6765\u5de5\u4f5c\u4e2d\u8ba8\u8bba\u5c06\u8fd9\u4e9b\u65b9\u6cd5\u5e94\u7528\u4e8e\u5305\u62ec\u751f\u6210\u5f0fAI\u7684\u573a\u666f\u3002", "result": "\u4e3aML\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u63d0\u4f9b\u57fa\u7840\u6027\u65b9\u6cd5\u3001\u63d0\u4f9b\u5bf9\u504f\u89c1\u4ea7\u751f\u673a\u5236\u7684\u7cfb\u7edf\u6027\u5206\u89e3\uff0c\u4ee5\u53ca\u5b9e\u73b0\u51cf\u5c11\u6b67\u89c6\u7684\u5e72\u9884\u624b\u6bb5\uff0c\u540c\u65f6\u517c\u987e\u7cfb\u7edf\u6548\u7528\u3002", "conclusion": "\u6307\u51fa\u5f53\u524d\u4ecd\u5b58\u5728\u6311\u6218\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5f3a\u8c03\u968f\u7740\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7b49\u6280\u672f\u878d\u5165\u793e\u4f1a\uff0c\u9700\u8fdb\u4e00\u6b65\u786e\u4fddML\u7684\u793e\u4f1a\u5f71\u54cd\u4e0e\u66f4\u5e7f\u6cdb\u7684\u793e\u4f1a\u4ef7\u503c\u76f8\u4e00\u81f4\u3002"}}
{"id": "2510.23727", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23727", "abs": "https://arxiv.org/abs/2510.23727", "authors": ["Anisha Saha", "Varsha Suresh", "Timothy Hospedales", "Vera Demberg"], "title": "MUStReason: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs for Multimodal Sarcasm Detection", "comment": null, "summary": "Sarcasm is a specific type of irony which involves discerning what is said\nfrom what is meant. Detecting sarcasm depends not only on the literal content\nof an utterance but also on non-verbal cues such as speaker's tonality, facial\nexpressions and conversational context. However, current multimodal models\nstruggle with complex tasks like sarcasm detection, which require identifying\nrelevant cues across modalities and pragmatically reasoning over them to infer\nthe speaker's intention. To explore these limitations in VideoLMs, we introduce\nMUStReason, a diagnostic benchmark enriched with annotations of\nmodality-specific relevant cues and underlying reasoning steps to identify\nsarcastic intent. In addition to benchmarking sarcasm classification\nperformance in VideoLMs, using MUStReason we quantitatively and qualitatively\nevaluate the generated reasoning by disentangling the problem into perception\nand reasoning, we propose PragCoT, a framework that steers VideoLMs to focus on\nimplied intentions over literal meaning, a property core to detecting sarcasm.", "AI": {"tldr": "\u63d0\u51fa MUStReason \u8bca\u65ad\u57fa\u51c6\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u5728\u8bbd\u523a\u68c0\u6d4b\u4e2d\u7684\u611f\u77e5\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u63d0\u51fa PragCoT \u6846\u67b6\u4ee5\u5f15\u5bfc\u6a21\u578b\u805a\u7126\u9690\u542b\u610f\u56fe\u800c\u975e\u5b57\u9762\u610f\u4e49\u3002", "motivation": "\u8bbd\u523a\u68c0\u6d4b\u9700\u8981\u8de8\u6a21\u6001\u7ebf\u7d22\u548c\u8bed\u7528\u63a8\u7406\uff0c\u4f46\u73b0\u6709\u591a\u6a21\u6001\u6a21\u578b\u5728\u8bc6\u522b\u76f8\u5173\u7ebf\u7d22\u4e0e\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002", "method": "\u6784\u5efa\u5e26\u6709\u6a21\u6001\u7279\u5b9a\u7ebf\u7d22\u4e0e\u63a8\u7406\u6b65\u9aa4\u6ce8\u91ca\u7684\u8bca\u65ad\u57fa\u51c6 MUStReason\uff1b\u5bf9 VideoLMs \u5728\u8bbd\u523a\u5206\u7c7b\u4e0a\u7684\u6027\u80fd\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u5e76\u5bf9\u751f\u6210\u63a8\u7406\u8fdb\u884c\u5b9a\u91cf\u4e0e\u5b9a\u6027\u8bc4\u4f30\uff0c\u8fdb\u4e00\u6b65\u63d0\u51fa PragCoT \u7528\u4e8e\u5f15\u5bfc\u63a8\u7406\u3002", "result": "\u901a\u8fc7\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u611f\u77e5\u4e0e\u63a8\u7406\uff0c\u63ed\u793a\u6a21\u578b\u5728\u63a8\u7406\u5c42\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u7ed9\u51fa\u5b9a\u6027\u5206\u6790\uff1bPragCoT \u80fd\u63d0\u5347\u6a21\u578b\u5c06\u6ce8\u610f\u529b\u805a\u7126\u4e8e\u9690\u542b\u610f\u56fe\u7684\u80fd\u529b\u3002", "conclusion": "MUStReason \u4e0e PragCoT \u63d0\u4f9b\u4e86\u4e00\u6761\u8bc4\u4f30\u4e0e\u63d0\u5347\u591a\u6a21\u6001\u8bbd\u523a\u63a8\u7406\u80fd\u529b\u7684\u8def\u5f84\uff0c\u5f3a\u8c03\u5bf9\u9690\u542b\u610f\u56fe\u7684\u5173\u6ce8\u3002"}}
{"id": "2510.23794", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23794", "abs": "https://arxiv.org/abs/2510.23794", "authors": ["Jun Liu", "Tao Zhou", "Jiarui Li", "Xiaohui Zhong", "Peng Zhang", "Jie Feng", "Lei Chen", "Hao Li"], "title": "Revealing the Potential of Learnable Perturbation Ensemble Forecast Model for Tropical Cyclone Prediction", "comment": "30 pages, 21 figures, 1 table", "summary": "Tropical cyclones (TCs) are highly destructive and inherently uncertain\nweather systems. Ensemble forecasting helps quantify these uncertainties, yet\ntraditional systems are constrained by high computational costs and limited\ncapability to fully represent atmospheric nonlinearity. FuXi-ENS introduces a\nlearnable perturbation scheme for ensemble generation, representing a novel\nAI-based forecasting paradigm. Here, we systematically compare FuXi-ENS with\nECMWF-ENS using all 90 global TCs in 2018, examining their performance in\nTC-related physical variables, track and intensity forecasts, and the\nassociated dynamical and thermodynamical fields. FuXi-ENS demonstrates clear\nadvantages in predicting TC-related physical variables, and achieves more\naccurate track forecasts with reduced ensemble spread, though it still\nunderestimates intensity relative to observations. Further dynamical and\nthermodynamical analyses reveal that FuXi-ENS better captures large-scale\ncirculation, with moisture turbulent energy more tightly concentrated around\nthe TC warm core, whereas ECMWF-ENS exhibits a more dispersed distribution.\nThese findings highlight the potential of learnable perturbations to improve TC\nforecasting skill and provide valuable insights for advancing AI-based ensemble\nprediction of extreme weather events that have significant societal impacts.", "AI": {"tldr": " FuXi-ENS\u4ee5\u53ef\u5b66\u4e60\u6270\u52a8\u6765\u751f\u6210\u96c6\u5408\u9884\u6d4b\uff0c\u4e0eECMWF-ENS\u57282018\u5e74\u5168\u740390\u4e2a\u70ed\u5e26\u6c14\u65cb\u7684\u5bf9\u6bd4\u4e2d\uff0c\u5728TC\u76f8\u5173\u53d8\u91cf\u3001\u8f68\u8ff9\u548c\u5f3a\u5ea6\u9884\u6d4b\u4ee5\u53ca\u52a8\u529b\u70ed\u573a\u65b9\u9762\u8868\u73b0\u51fa\u660e\u663e\u4f18\u52bf\uff0c\u4e14\u96c6\u5408\u65b9\u5dee\u66f4\u7d27\u51d1\u3002", "motivation": " \u89e3\u51b3\u4f20\u7edf\u96c6\u5408\u9884\u62a5\u5728\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u65e0\u6cd5\u5145\u5206\u8868\u8fbe\u5927\u6c14\u975e\u7ebf\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u57fa\u4e8eAI\u7684\u53ef\u5b66\u4e60\u6270\u52a8\u6765\u6539\u8fdb\u70ed\u5e26\u6c14\u65cb\u96c6\u5408\u9884\u6d4b\u7684\u6f5c\u529b\u3002", "method": " \u4f7f\u75282018\u5e74\u5168\u740390\u4e2a\u70ed\u5e26\u6c14\u65cb\u7684\u5168\u6837\u672c\u6570\u636e\uff0c\u7cfb\u7edf\u6027\u6bd4\u8f83FuXi-ENS\u4e0eECMWF-ENS\u5728TC\u76f8\u5173\u7269\u7406\u53d8\u91cf\u3001\u8f68\u8ff9\u4e0e\u5f3a\u5ea6\u9884\u6d4b\u53ca\u5176\u76f8\u5173\u7684\u52a8\u529b\u4e0e\u70ed\u529b\u573a\u8868\u73b0\u3002\u8bc4\u4f30\u96c6\u5408\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u3001\u5f3a\u5ea6\u504f\u5dee\u53ca\u5927\u5c3a\u5ea6\u73af\u6d41\u53ca\u6e7f\u5ea6\u80fd\u91cf\u5206\u5e03\u7279\u5f81\u3002", "result": " FuXi-ENS\u5728TC\u76f8\u5173\u7269\u7406\u53d8\u91cf\u9884\u6d4b\u3001\u8f68\u8ff9\u9884\u6d4b\u51c6\u786e\u6027\u53ca\u96c6\u5408\u6563\u5ea6\uff08\u66f4\u5c0f\u7684\u96c6\u5408\u6269\u5c55\uff09\u65b9\u9762\u4f18\u4e8eECMWF-ENS\uff1b\u4f46\u5bf9\u5f3a\u5ea6\u7684\u9884\u6d4b\u4ecd\u663e\u8457\u4f4e\u4e8e\u89c2\u6d4b\u503c\u3002\u52a8\u6001\u4e0e\u70ed\u529b\u5206\u6790\u663e\u793aFuXi-ENS\u66f4\u597d\u5730\u6355\u6349\u5927\u5c3a\u5ea6\u73af\u6d41\uff0c\u6e7f\u6da6\u6e4d\u53d8\u80fd\u5728\u70ed\u5e26\u6c14\u65cb\u6696\u6838\u5468\u56f4\u5206\u5e03\u66f4\u96c6\u4e2d\uff0c\u800cECMWF-ENS\u5448\u73b0\u66f4\u5206\u6563\u7684\u5206\u5e03\u3002", "conclusion": " \u4f7f\u7528\u53ef\u5b66\u4e60\u6270\u52a8\u7684AI\u96c6\u5408\u9884\u6d4b\u65b9\u6cd5\u6709\u671b\u63d0\u5347\u70ed\u5e26\u6c14\u65cb\u9884\u62a5\u6280\u80fd\uff0c\u5e76\u4e3a\u57fa\u4e8eAI\u7684\u6781\u7aef\u5929\u6c14\u96c6\u5408\u9884\u6d4b\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u4e0e\u5b9e\u8df5\u8def\u5f84\u3002"}}
{"id": "2510.23802", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23802", "abs": "https://arxiv.org/abs/2510.23802", "authors": ["Nathan Paek", "Yongyi Zang", "Qihui Yang", "Randal Leistikow"], "title": "Learning Interpretable Features in Audio Latent Spaces via Sparse Autoencoders", "comment": "Accepted to NeurIPS 2025 Mechanistic Interpretability Workshop", "summary": "While sparse autoencoders (SAEs) successfully extract interpretable features\nfrom language models, applying them to audio generation faces unique\nchallenges: audio's dense nature requires compression that obscures semantic\nmeaning, and automatic feature characterization remains limited. We propose a\nframework for interpreting audio generative models by mapping their latent\nrepresentations to human-interpretable acoustic concepts. We train SAEs on\naudio autoencoder latents, then learn linear mappings from SAE features to\ndiscretized acoustic properties (pitch, amplitude, and timbre). This enables\nboth controllable manipulation and analysis of the AI music generation process,\nrevealing how acoustic properties emerge during synthesis. We validate our\napproach on continuous (DiffRhythm-VAE) and discrete (EnCodec, WavTokenizer)\naudio latent spaces, and analyze DiffRhythm, a state-of-the-art text-to-music\nmodel, to demonstrate how pitch, timbre, and loudness evolve throughout\ngeneration. While our work is only done on audio modality, our framework can be\nextended to interpretable analysis of visual latent space generation models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5c06\u7a00\u758f\u81ea\u7f16\u7801\u5668\u4e0e\u97f3\u9891\u751f\u6210\u6a21\u578b\u76f8\u7ed3\u5408\u7684\u89e3\u91ca\u6846\u67b6\uff1a\u5728\u97f3\u9891\u81ea\u7f16\u7801\u5668\u6f5c\u5728\u8868\u5f81\u4e0a\u8bad\u7ec3\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff0c\u5e76\u4eceSAE\u7279\u5f81\u6620\u5c04\u5230\u79bb\u6563\u5316\u7684\u58f0\u5b66\u5c5e\u6027\uff08\u97f3\u9ad8\u3001\u5e45\u5ea6\u3001\u97f3\u8272\uff09\uff0c\u5b9e\u73b0\u5bf9\u6f5c\u5728\u751f\u6210\u8fc7\u7a0b\u7684\u53ef\u63a7\u64cd\u4f5c\u4e0e\u5206\u6790\u3002\u5bf9\u8fde\u7eed\u4e0e\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\u5747\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5e76\u5206\u6790DiffRhythm\u7b49\u6a21\u578b\u4ee5\u63ed\u793a\u5728\u5408\u6210\u8fc7\u7a0b\u4e2d\u7684\u58f0\u5b66\u5c5e\u6027\u6f14\u5316\u3002\u8be5\u6846\u67b6\u867d\u4ec5\u5728\u97f3\u9891\u6a21\u6001\u4e0a\u5f00\u5c55\uff0c\u4f46\u5177\u5907\u6269\u5c55\u5230\u89c6\u89c9\u6f5c\u5728\u7a7a\u95f4\u5206\u6790\u7684\u6f5c\u529b\u3002", "motivation": "\u97f3\u9891\u7684\u9ad8\u5bc6\u5ea6\u6027\u8d28\u4f7f\u5f97\u538b\u7f29\u53ef\u80fd\u6a21\u7cca\u8bed\u4e49\uff0c\u4e14\u81ea\u52a8\u7279\u5f81\u8868\u5f81\u4ecd\u7136\u53d7\u9650\uff0c\u5bfc\u81f4\u5bf9\u97f3\u9891\u751f\u6210\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u3002\u9700\u8981\u5c06\u6a21\u578b\u6f5c\u5728\u8868\u5f81\u6620\u5c04\u5230\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u58f0\u5b66\u6982\u5ff5\uff0c\u4ee5\u5b9e\u73b0\u5bf9AI\u97f3\u4e50\u751f\u6210\u8fc7\u7a0b\u7684\u53ef\u63a7\u6027\u4e0e\u5206\u6790\u3002", "method": "\u5728\u97f3\u9891\u81ea\u7f16\u7801\u5668\u6f5c\u5728\u8868\u793a\u4e0a\u8bad\u7ec3\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\uff0c\u518d\u5b66\u4e60\u4eceSAE\u7279\u5f81\u5230\u79bb\u6563\u5316\u58f0\u5b66\u5c5e\u6027\uff08\u97f3\u9ad8\u3001\u5e45\u5ea6\u3001\u97f3\u8272\uff09\u7684\u7ebf\u6027\u6620\u5c04\u3002\u5bf9\u8fde\u7eed\uff08DiffRhythm-VAE\uff09\u548c\u79bb\u6563\uff08EnCodec\u3001WavTokenizer\uff09\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5e76\u5206\u6790DiffRhythm\u4e2d\u97f3\u9ad8\u3001\u97f3\u8272\u3001\u54cd\u5ea6\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u6f14\u53d8\u3002", "result": "\u5b9e\u73b0\u5bf9AI\u97f3\u4e50\u751f\u6210\u8fc7\u7a0b\u7684\u53ef\u63a7\u64cd\u63a7\u4e0e\u5206\u6790\uff0c\u63ed\u793a\u5728\u5408\u6210\u8fc7\u7a0b\u4e2d\u58f0\u5b66\u5c5e\u6027\u7684\u51fa\u73b0\u4e0e\u6f14\u5316\u3002\u9a8c\u8bc1\u5bf9\u8c61\u6db5\u76d6\u8fde\u7eed\u4e0e\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\u7684\u4e3b\u6d41\u6a21\u578b\uff0c\u4e14\u4ee5DiffRhythm\u7b49\u6587\u672c\u5230\u97f3\u4e50\u6a21\u578b\u4e3a\u5206\u6790\u5bf9\u8c61\uff0c\u5c55\u793a\u4e0d\u540c\u58f0\u5b66\u5c5e\u6027\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u53d8\u5316\u8d8b\u52bf\u3002", "conclusion": "\u7ed9\u51fa\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u97f3\u9891\u6a21\u6001\u89e3\u91ca\u6846\u67b6\uff0c\u672a\u6765\u53ef\u62d3\u5c55\u81f3\u53ef\u89c6\u5316\u6f5c\u5728\u7a7a\u95f4\u7684\u5206\u6790\uff0c\u5e2e\u52a9\u7406\u89e3\u5176\u4ed6\u89c6\u89c9\u6216\u8de8\u6a21\u6001\u7684\u6f5c\u5728\u751f\u6210\u6a21\u578b\u7684\u58f0\u5b66/\u8bed\u4e49\u5173\u7cfb\u3002"}}
{"id": "2510.23804", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23804", "abs": "https://arxiv.org/abs/2510.23804", "authors": ["Adela DePavia", "Vasileios Charisopoulos", "Rebecca Willett"], "title": "How do simple rotations affect the implicit bias of Adam?", "comment": null, "summary": "Adaptive gradient methods such as Adam and Adagrad are widely used in machine\nlearning, yet their effect on the generalization of learned models -- relative\nto methods like gradient descent -- remains poorly understood. Prior work on\nbinary classification suggests that Adam exhibits a ``richness bias,'' which\ncan help it learn nonlinear decision boundaries closer to the Bayes-optimal\ndecision boundary relative to gradient descent. However, the coordinate-wise\npreconditioning scheme employed by Adam renders the overall method sensitive to\northogonal transformations of feature space. We show that this sensitivity can\nmanifest as a reversal of Adam's competitive advantage: even small rotations of\nthe underlying data distribution can make Adam forfeit its richness bias and\nconverge to a linear decision boundary that is farther from the Bayes-optimal\ndecision boundary than the one learned by gradient descent. To alleviate this\nissue, we show that a recently proposed reparameterization method -- which\napplies an orthogonal transformation to the optimization objective -- endows\nany first-order method with equivariance to data rotations, and we empirically\ndemonstrate its ability to restore Adam's bias towards rich decision\nboundaries.", "AI": {"tldr": "\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u6cd5\uff08\u5982 Adam\u3001Adagrad\uff09\u7684\u6cdb\u5316\u6548\u5e94\u4f9d\u8d56\u4e8e\u6570\u636e\u8868\u5f81\uff1b\u5728\u4e8c\u5143\u5206\u7c7b\u4e2d\u5b58\u5728\u201c\u4e30\u5bcc\u6027\u504f\u7f6e\u201d\uff0c\u4f46\u5bf9\u5750\u6807\u9884\u5904\u7406\u654f\u611f\uff0c\u6570\u636e\u7684\u6b63\u4ea4\u65cb\u8f6c\u53ef\u80fd\u6d88\u9664\u8be5\u504f\u7f6e\u5e76\u4f7f Adam \u7684\u8fb9\u754c\u6bd4\u68af\u5ea6\u4e0b\u964d\u66f4\u5dee\uff1b\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u6b63\u4ea4\u53d8\u6362\u7684\u518d\u53c2\u6570\u5316\u53ef\u4f7f\u4f18\u5316\u76ee\u6807\u5bf9\u6570\u636e\u65cb\u8f6c\u7b49\u53d8\uff0c\u4ece\u800c\u6062\u590d Adam \u7684\u4e30\u5bcc\u6027\u504f\u7f6e\u3002", "motivation": "\u7406\u89e3\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u6cd5\u5bf9\u6cdb\u5316\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u8868\u5f81\uff08\u65cb\u8f6c\u7b49\u6b63\u4ea4\u53d8\u6362\uff09\u4e0b\uff1b\u63ed\u793a Adam \u7684\u4e30\u5bcc\u6027\u504f\u7f6e\u4e3a\u4f55\u4f1a\u56e0\u4e3a\u5750\u6807\u7cfb\u53d8\u6362\u800c\u6d88\u5931\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u91cd\u53c2\u6570\u5316\u5b9e\u73b0\u7b49\u53d8\u6027\u3002", "method": "\u5bf9 Adam\u3001Adagrad \u5728\u4e8c\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u8fdb\u884c\u7406\u8bba\u5206\u6790\u4e0e\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u7814\u7a76\u5176\u5750\u6807\u9884\u6761\u4ef6\u5316\u7684\u5f71\u54cd\uff1b\u63d0\u51fa\u5bf9\u4f18\u5316\u76ee\u6807\u8fdb\u884c\u6b63\u4ea4\u53d8\u6362\u7684\u518d\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u4f7f\u7b2c\u4e00\u9636\u65b9\u6cd5\u5bf9\u6570\u636e\u65cb\u8f6c\u4fdd\u6301\u7b49\u53d8\uff1b\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u8be5\u518d\u53c2\u6570\u5316\u53ef\u4ee5\u6062\u590d Adam \u7684\u4e30\u5bcc\u6027\u504f\u7f6e\u3002", "result": "\u53d1\u73b0\u5373\u4f7f\u662f\u5f88\u5c0f\u7684\u65cb\u8f6c\u4e5f\u80fd\u4f7f Adam \u5931\u53bb\u76f8\u5bf9\u4e8e\u68af\u5ea6\u4e0b\u964d\u7684\u4f18\u52bf\uff0c\u8d8b\u5411\u5b66\u4e60\u51fa\u8ddd\u79bb Bayes \u5224\u51b3\u8fb9\u754c\u66f4\u8fdc\u7684\u7ebf\u6027\u8fb9\u754c\uff1b\u6240\u63d0\u51fa\u7684\u518d\u53c2\u6570\u5316\u65b9\u6cd5\u8ba9\u4efb\u4f55\u4e00\u9636\u65b9\u6cd5\u5177\u6709\u5bf9\u6570\u636e\u65cb\u8f6c\u7684\u7b49\u53d8\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8bc1\u5b9e\u5176\u80fd\u6062\u590d Adam \u7684\u4e30\u5bcc\u6027\u504f\u7f6e\u3002", "conclusion": "\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u6cd5\u7684\u5bf9\u6570\u636e\u8868\u5f81\u654f\u611f\u6027\u662f\u4e00\u4e2a\u73b0\u5b9e\u95ee\u9898\uff1b\u901a\u8fc7\u7b80\u5355\u7684\u6b63\u4ea4\u53d8\u6362\u518d\u53c2\u6570\u5316\u53ef\u4ee5\u63d0\u9ad8\u4e00\u9636\u4f18\u5316\u5668\u5bf9\u65cb\u8f6c\u7684\u9c81\u68d2\u6027\u5e76\u6062\u590d\u66f4\u63a5\u8fd1 Bayes \u8fb9\u754c\u7684\u51b3\u7b56\u8fb9\u754c\uff0c\u5f3a\u8c03\u5728\u8bbe\u8ba1\u4f18\u5316\u7b97\u6cd5\u65f6\u9700\u8981\u8003\u8651\u6570\u636e\u8868\u793a\u7684\u5f71\u54cd\u3002"}}
{"id": "2510.23810", "categories": ["cs.LG", "math.AP", "physics.comp-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23810", "abs": "https://arxiv.org/abs/2510.23810", "authors": ["Sumanta Roy", "Bahador Bahmani", "Ioannis G. Kevrekidis", "Michael D. Shields"], "title": "A Physics-informed Multi-resolution Neural Operator", "comment": "26 pages, 14 figures, 4 tables", "summary": "The predictive accuracy of operator learning frameworks depends on the\nquality and quantity of available training data (input-output function pairs),\noften requiring substantial amounts of high-fidelity data, which can be\nchallenging to obtain in some real-world engineering applications. These\ndatasets may be unevenly discretized from one realization to another, with the\ngrid resolution varying across samples. In this study, we introduce a\nphysics-informed operator learning approach by extending the Resolution\nIndependent Neural Operator (RINO) framework to a fully data-free setup,\naddressing both challenges simultaneously. Here, the arbitrarily (but\nsufficiently finely) discretized input functions are projected onto a latent\nembedding space (i.e., a vector space of finite dimensions), using pre-trained\nbasis functions. The operator associated with the underlying partial\ndifferential equations (PDEs) is then approximated by a simple multi-layer\nperceptron (MLP), which takes as input a latent code along with spatiotemporal\ncoordinates to produce the solution in the physical space. The PDEs are\nenforced via a finite difference solver in the physical space. The validation\nand performance of the proposed method are benchmarked on several numerical\nexamples with multi-resolution data, where input functions are sampled at\nvarying resolutions, including both coarse and fine discretizations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u6570\u636e\u65e0\u5173\u3001\u5206\u8fa8\u7387\u65e0\u5173\u7684\u7269\u7406\u4fe1\u606f\u7b97\u5b50\u5b66\u4e60\u6846\u67b6\uff1a\u5c06\u8f93\u5165\u573a\u6295\u5f71\u5230\u6f5c\u5728\u5d4c\u5165\u7a7a\u95f4\uff0c\u7531MLP\u8fd1\u4f3c\u7b97\u5b50\uff0c\u5e76\u901a\u8fc7\u7269\u7406\u7a7a\u95f4\u7684\u6709\u9650\u5dee\u5206\u6c42\u89e3\u5668\u5f3a\u5236 PDE\uff0c\u9002\u7528\u4e8e\u591a\u5206\u8fa8\u7387\u6570\u636e\u7684\u6570\u503c\u9a8c\u8bc1\u3002", "motivation": "\u89e3\u51b3\u9ad8\u4fdd\u771f\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u4e0e\u4e0d\u540c\u6837\u672c\u7f51\u683c\u5206\u8fa8\u7387\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u4f7f\u7b97\u5b50\u5b66\u4e60\u5728\u7f3a\u4e4f\u5927\u91cf\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u6cdb\u5316\uff0c\u5e76\u4e14\u8de8\u4e0d\u540c\u79bb\u6563\u5316\u5c3a\u5ea6\u8fdb\u884c\u63a8\u7406\u3002", "method": "\u5728RINO\u6846\u67b6\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e00\u4e2a\u5b8c\u5168\u6570\u636e\u65e0\u5173\u7684\u65b9\u6848\uff1a\u5c06\u4efb\u610f\u5206\u8fa8\u7387\u7684\u8f93\u5165\u51fd\u6570\u6295\u5f71\u5230\u6709\u9650\u7ef4\u5411\u91cf\u7a7a\u95f4\u7684\u6f5c\u5728\u7f16\u7801\uff0c\u5229\u7528MLP\u8fd1\u4f3c\u7b97\u5b50\uff0c\u8f93\u5165\u4e3a\u6f5c\u5728\u7f16\u7801\u548c\u65f6\u7a7a\u5750\u6807\uff0c\u8f93\u51fa\u7269\u7406\u7a7a\u95f4\u89e3\uff1b\u5728\u7269\u7406\u7a7a\u95f4\u901a\u8fc7\u6709\u9650\u5dee\u5206\u6c42\u89e3\u5668\u5f3a\u5236 PDE\u3002", "result": "\u5728\u591a\u5c3a\u5ea6\u6570\u636e\u7684\u6570\u503c\u793a\u4f8b\u4e2d\u9a8c\u8bc1\uff0c\u8f93\u5165\u5728\u4e0d\u540c\u5206\u8fa8\u7387\u4e0b\u91c7\u6837\uff08\u4ece\u7c97\u5230\u7cbe\uff09\uff0c\u65b9\u6cd5\u4ecd\u80fd\u6709\u6548\u5de5\u4f5c\u5e76\u7ed9\u51fa\u89e3\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u65e0\u5173\u3001\u5206\u8fa8\u7387\u65e0\u5173\u7684\u7269\u7406\u4fe1\u606f\u7b97\u5b50\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6f5c\u5728\u7f16\u7801\u4e0eMLP\u8fd1\u4f3c\u7b97\u5b50\u7ed3\u5408\u3001\u5e76\u5728\u7269\u7406\u7a7a\u95f4\u4ee5FD\u6c42\u89e3\u5668\u5f3a\u5236 PDE\uff0c\u53ef\u5bf9\u591a\u5206\u8fa8\u7387\u6570\u636e\u8fdb\u884c\u9c81\u68d2\u7684\u7b97\u5b50\u5b66\u4e60\u4e0e\u63a8\u7406\u3002"}}
{"id": "2510.23817", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.23817", "abs": "https://arxiv.org/abs/2510.23817", "authors": ["Pedro Cortes dos Santos", "Matheus Becali Rocha", "Renato A Krohling"], "title": "Combining SHAP and Causal Analysis for Interpretable Fault Detection in Industrial Processes", "comment": null, "summary": "Industrial processes generate complex data that challenge fault detection\nsystems, often yielding opaque or underwhelming results despite advanced\nmachine learning techniques. This study tackles such difficulties using the\nTennessee Eastman Process, a well-established benchmark known for its intricate\ndynamics, to develop an innovative fault detection framework. Initial attempts\nwith standard models revealed limitations in both performance and\ninterpretability, prompting a shift toward a more tractable approach. By\nemploying SHAP (SHapley Additive exPlanations), we transform the problem into a\nmore manageable and transparent form, pinpointing the most critical process\nfeatures driving fault predictions. This reduction in complexity unlocks the\nability to apply causal analysis through Directed Acyclic Graphs, generated by\nmultiple algorithms, to uncover the underlying mechanisms of fault propagation.\nThe resulting causal structures align strikingly with SHAP findings,\nconsistently highlighting key process elements-like cooling and separation\nsystems-as pivotal to fault development. Together, these methods not only\nenhance detection accuracy but also provide operators with clear, actionable\ninsights into fault origins, a synergy that, to our knowledge, has not been\npreviously explored in this context. This dual approach bridges predictive\npower with causal understanding, offering a robust tool for monitoring complex\nmanufacturing environments and paving the way for smarter, more interpretable\nfault detection in industrial systems.", "AI": {"tldr": "\u901a\u8fc7SHAP\u4e0e\u56e0\u679cDAG\u7684\u7ed3\u5408\uff0c\u5728Tennessee Eastman\u5de5\u827a\u4e2d\u63d0\u5347\u6545\u969c\u68c0\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u51c6\u786e\u6027\uff0c\u5e76\u63ed\u793a\u5173\u952e\u5de5\u827a\u8981\u7d20\uff08\u5982\u51b7\u5374\u4e0e\u5206\u79bb\u7cfb\u7edf\uff09\u5bf9\u6545\u969c\u7684\u4f5c\u7528\u3002", "motivation": "\u89e3\u51b3\u590d\u6742\u5de5\u4e1a\u8fc7\u7a0b\u4e2d\u7684\u6545\u969c\u68c0\u6d4b\u5728\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\u4e0a\u7684\u74f6\u9888\uff1b\u901a\u8fc7\u5c06\u53ef\u89e3\u91ca\u6027\u5206\u6790\uff08SHAP\uff09\u4e0e\u56e0\u679c\u63a8\u65ad\uff08DAG\uff09\u7ed3\u5408\uff0c\u5f62\u6210\u66f4\u900f\u660e\u4e14\u5177\u64cd\u4f5c\u6027\u7684\u76d1\u63a7\u6846\u67b6\u3002", "method": "1) \u4f7f\u7528\u6807\u51c6\u6a21\u578b\u8fdb\u884c\u521d\u6b65\u6545\u969c\u68c0\u6d4b\uff0c\u53d1\u73b0\u6027\u80fd\u4e0e\u89e3\u91ca\u6027\u4e0d\u8db3\uff1b2) \u4f7f\u7528SHAP\u786e\u5b9a\u5173\u952e\u7279\u5f81\uff0c\u8f6c\u5316\u95ee\u9898\u4e3a\u66f4\u6613\u7ba1\u7406\u7684\u5f62\u5f0f\uff1b3) \u57fa\u4e8eSHAP\u7ed3\u679c\uff0c\u5e94\u7528\u591a\u7b97\u6cd5\u751f\u6210\u7684\u6709\u5411\u65e0\u73af\u56fe\u8fdb\u884c\u56e0\u679c\u5206\u6790\uff0c\u63ed\u793a\u6545\u969c\u4f20\u64ad\u673a\u5236\u5e76\u9a8c\u8bc1\u4e0eSHAP\u7684\u4e00\u81f4\u6027\u3002", "result": "SHAP\u4e0eDAG\u6240\u5f97\u7ed3\u679c\u4e00\u81f4\uff0c\u663e\u8457\u6307\u51fa\u5982\u51b7\u5374\u4e0e\u5206\u79bb\u7cfb\u7edf\u7b49\u5173\u952e\u5de5\u827a\u8981\u7d20\u5728\u6545\u969c\u53d1\u5c55\u4e2d\u7684\u4f5c\u7528\uff0c\u63d0\u5347\u68c0\u6d4b\u51c6\u786e\u6027\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6545\u969c\u6e90\u6d1e\u5bdf\u3002", "conclusion": "\u63d0\u51fa\u5c06\u9884\u6d4b\u6027\u80fd\u529b\u4e0e\u56e0\u679c\u7406\u89e3\u76f8\u7ed3\u5408\u7684\u9c81\u68d2\u6545\u969c\u68c0\u6d4b\u6846\u67b6\uff0c\u4e3a\u590d\u6742\u5236\u9020\u73af\u5883\u7684\u76d1\u63a7\u63d0\u4f9b\u66f4\u6e05\u6670\u3001\u53ef\u64cd\u4f5c\u7684\u89e3\u91ca\uff0c\u5e76\u63a8\u52a8\u5de5\u4e1a\u7cfb\u7edf\u66f4\u667a\u80fd\u3001\u53ef\u89e3\u91ca\u7684\u6545\u969c\u68c0\u6d4b\u5b9e\u8df5\u3002"}}
{"id": "2510.23818", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23818", "abs": "https://arxiv.org/abs/2510.23818", "authors": ["Yilang Zhang", "Xiaodong Yang", "Yiwei Cai", "Georgios B. Giannakis"], "title": "ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank Fine-Tuning", "comment": null, "summary": "As large language models (LLMs) continue to scale in size, the computational\noverhead has become a major bottleneck for task-specific fine-tuning. While\nlow-rank adaptation (LoRA) effectively curtails this cost by confining the\nweight updates to a low-dimensional subspace, such a restriction can hinder\neffectiveness and slow convergence. This contribution deals with these\nlimitations by accumulating progressively a high-rank weight update from\nconsecutive low-rank increments. Specifically, the per update optimal low-rank\nmatrix is identified to minimize the loss function and closely approximate full\nfine-tuning. To endow efficient and seamless optimization without restarting,\nthis optimal choice is formed by appropriately scaling the columns of the\noriginal low-rank matrix. Rigorous performance guarantees reveal that the\noptimal scaling can be found analytically. Extensive numerical tests with\npopular LLMs scaling up to 12 billion parameters demonstrate a consistent\nperformance gain and fast convergence relative to state-of-the-art LoRA\nvariants on diverse tasks including natural language understanding, commonsense\nreasoning, and mathematical problem solving.", "AI": {"tldr": "\u901a\u8fc7\u5c06LoRA\u589e\u91cf\u9ad8\u79e9\u7d2f\u79ef\u5e76\u5bf9\u539f\u4f4e\u79e9\u77e9\u9635\u7684\u5217\u8fdb\u884c\u7ebf\u6027\u7f29\u653e\uff0c\u5f97\u5230\u53ef\u89e3\u6790\u7684\u6700\u4f18\u9ad8\u79e9\u8fd1\u4f3c\u4ee5\u66ff\u4ee3\u9010\u6b65\u5168\u5fae\u8c03\uff0c\u4ece\u800c\u63d0\u5347\u5927\u6a21\u578b\u7684\u5fae\u8c03\u6548\u679c\u4e0e\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u5728\u5927\u6a21\u578b\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u4e2d\uff0cLoRA\u5c06\u66f4\u65b0\u9650\u5236\u5728\u4f4e\u79e9\u5b50\u7a7a\u95f4\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0e\u6536\u655b\u53d7\u9650\uff1b\u63d0\u51fa\u4e00\u79cd\u9ad8\u79e9\u589e\u91cf\u7d2f\u79ef\u7b56\u7565\uff0c\u517c\u987e\u6548\u7387\u4e0e\u6548\u679c\u3002", "method": "\u6bcf\u6b21\u66f4\u65b0\u4e2d\u8bc6\u522b\u80fd\u6700\u5c0f\u5316\u635f\u5931\u7684\u6700\u4f18\u4f4e\u79e9\u77e9\u9635\uff0c\u5e76\u901a\u8fc7\u5bf9\u539f\u59cb\u4f4e\u79e9\u77e9\u9635\u7684\u5217\u8fdb\u884c\u7f29\u653e\u6765\u6784\u9020\u9ad8\u79e9\u66f4\u65b0\uff1b\u8bc1\u660e\u7f29\u653e\u7cfb\u6570\u53ef\u89e3\u6790\u6c42\u89e3\u4e14\u65e0\u91cd\u542f\u5730\u8fdb\u884c\u4f18\u5316\uff1b\u5728\u591a\u8fbe12B\u53c2\u6570\u7684\u6a21\u578b\u4e0a\u5bf9\u6bd4LoRA\u53d8\u4f53\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\u3002", "result": "\u5728\u591a\u4efb\u52a1\u9886\u57df\uff08\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3001\u5e38\u8bc6\u63a8\u7406\u3001\u6570\u5b66\u95ee\u9898\u6c42\u89e3\uff09\u4ee5\u53ca\u89c4\u6a21\u9ad8\u8fbe12B\u7684\u6a21\u578b\u4e0a\uff0c\u65b9\u6cd5\u6bd4\u73b0\u6709LoRA\u53d8\u4f53\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u4e0e\u66f4\u5feb\u7684\u6536\u655b\u3002", "conclusion": "\u9ad8\u79e9\u66f4\u65b0\u7d2f\u79ef\u7ed3\u5408\u7ebf\u6027\u5217\u7f29\u653e\u63d0\u4f9b\u4e86\u4e00\u79cd\u7406\u8bba\u4e0a\u53ef\u89e3\u6790\u7684\u9ad8\u6548\u5fae\u8c03\u9014\u5f84\uff0c\u53ef\u5728\u4e0d\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u7684\u524d\u63d0\u4e0b\u63d0\u5347LoRA\u7684\u6548\u679c\u4e0e\u6536\u655b\u901f\u5ea6\u3002"}}
{"id": "2510.23866", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23866", "abs": "https://arxiv.org/abs/2510.23866", "authors": ["Paul Rosu", "Muchang Bahng", "Erick Jiang", "Rico Zhu", "Vahid Tarokh"], "title": "A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling", "comment": null, "summary": "This work presents a physics-conditioned latent diffusion model tailored for\ndynamical downscaling of atmospheric data, with a focus on reconstructing\nhigh-resolution 2-m temperature fields. Building upon a pre-existing diffusion\narchitecture and employing a residual formulation against a reference UNet, we\nintegrate a partial differential equation (PDE) loss term into the model's\ntraining objective. The PDE loss is computed in the full resolution (pixel)\nspace by decoding the latent representation and is designed to enforce physical\nconsistency through a finite-difference approximation of an effective\nadvection-diffusion balance. Empirical observations indicate that conventional\ndiffusion training already yields low PDE residuals, and we investigate how\nfine-tuning with this additional loss further regularizes the model and\nenhances the physical plausibility of the generated fields. The entirety of our\ncodebase is available on Github, for future reference and development.", "AI": {"tldr": "\u5c06\u7269\u7406\u6761\u4ef6\u5f15\u5165\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff0c\u7528\u4e8e\u5927\u6c14\u6570\u636e\u7684\u52a8\u6001\u5c3a\u5ea6\u4e0b\u653e\uff0c\u76ee\u6807\u91cd\u5efa\u9ad8\u5206\u8fa8\u7387\u76842\u7c73\u6e29\u5ea6\u573a\u3002\u901a\u8fc7\u6b8b\u5dee\u8fde\u63a5\u5230\u73b0\u6709UNet\uff0c\u5e76\u5728\u8bad\u7ec3\u76ee\u6807\u4e2d\u52a0\u5165PDE\u635f\u5931\uff0cPDE\u5728\u50cf\u7d20\u7a7a\u95f4\u89e3\u7801\u6f5c\u5728\u8868\u5f81\u540e\u8ba1\u7b97\uff0c\u5229\u7528\u6709\u9650\u5dee\u5206\u8fd1\u4f3c\u7684\u6709\u6548\u5e73\u8861\u4ee5\u7ea6\u675f\u5bf9\u6d41-\u6269\u6563\u7269\u7406\u5173\u7cfb\u3002", "motivation": "\u89e3\u51b3\u9ad8\u5206\u8fa8\u7387\u5927\u6c14\u573a\u666f\u4e0b\u7684\u7269\u7406\u4e00\u81f4\u6027\u95ee\u9898\u4e0e\u6570\u636e\u9a71\u52a8\u4e0b\u653e\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u5229\u7528PDE\u7ea6\u675f\u63d0\u9ad8\u751f\u6210\u573a\u7684\u7269\u7406\u53ef\u4fe1\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u6269\u6563\u6a21\u578b\u7684\u5efa\u6a21\u80fd\u529b\u3002", "method": "\u5728\u73b0\u6709\u6269\u6563\u67b6\u6784\u57fa\u7840\u4e0a\u5f15\u5165\u5bf9\u53c2\u8003UNet\u7684\u6b8b\u5dee\u5f62\u5f0f\uff1b\u8bad\u7ec3\u76ee\u6807\u4e2d\u52a0\u5165PDE\u635f\u5931\uff0c\u8be5\u635f\u5931\u5728\u5168\u5206\u8fa8\u7387\u50cf\u7d20\u7a7a\u95f4\u89e3\u7801\u6f5c\u5728\u8868\u5f81\u540e\u8ba1\u7b97\uff0c\u901a\u8fc7\u6709\u9650\u5dee\u5206\u8fd1\u4f3c\u5bf9\u5bf9\u6d41-\u6269\u6563\u5e73\u8861\u8fdb\u884c\u7ea6\u675f\uff1b\u5e76\u5728\u8bad\u7ec3\u4e2d\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u4ee5\u589e\u5f3a\u7269\u7406\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u89c2\u6d4b\u8868\u660e\uff0c\u5e38\u89c4\u6269\u6563\u8bad\u7ec3\u5df2\u80fd\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u5b9e\u73b0\u8f83\u4f4e\u7684PDE\u6b8b\u5dee\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u52a0\u5165PDE\u635f\u5931\u53ef\u8fdb\u4e00\u6b65\u6b63\u5219\u5316\u6a21\u578b\u5e76\u63d0\u5347\u751f\u6210\u573a\u7684\u7269\u7406\u76f8\u5bb9\u6027\uff1b\u4ee3\u7801\u5e93\u516c\u5f00\u5728Github\u4ee5\u4f9b\u590d\u73b0\u4e0e\u8fdb\u4e00\u6b65\u5f00\u53d1\u3002", "conclusion": "\u5c06PDE\u5c42\u9762\u7684\u7269\u7406\u7ea6\u675f\u6574\u5408\u5230\u6761\u4ef6\u6269\u6563\u6a21\u578b\u4e2d\uff0c\u53ef\u63d0\u5347\u4e0b\u653e\u5f97\u5230\u7684\u9ad8\u5206\u8fa8\u7387\u5927\u6c14\u573a\u7684\u7269\u7406\u4e00\u81f4\u6027\uff0c\u4e14\u63d0\u4f9b\u53ef\u590d\u73b0\u7684\u5f00\u6e90\u5b9e\u73b0\u3002"}}
{"id": "2510.23868", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23868", "abs": "https://arxiv.org/abs/2510.23868", "authors": ["Zhichao Wang"], "title": "GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA", "comment": null, "summary": "I propose \\textbf{G}roup-relative \\textbf{I}mplicit \\textbf{F}ine\n\\textbf{T}uning (GIFT), a novel reinforcement learning framework for aligning\nLLMs. Instead of directly maximizing cumulative rewards like PPO or GRPO, GIFT\nminimizes the discrepancy between implicit and explicit reward models. It\ncombines three key ideas: (1) the online multi-response generation and\nnormalization of GRPO, (2) the implicit reward formulation of DPO, and (3) the\nimplicit-explicit reward alignment principle of UNA. By jointly normalizing the\nimplicit and explicit rewards, GIFT eliminates an otherwise intractable term\nthat prevents effective use of implicit rewards. This normalization transforms\nthe complex reward maximization objective into a simple mean squared error\n(MSE) loss between the normalized reward functions, converting a non-convex\noptimization problem into a convex, stable, and analytically differentiable\nformulation. Unlike offline methods such as DPO and UNA, GIFT remains on-policy\nand thus retains exploration capability. Compared to GRPO, it requires fewer\nhyperparameters, converges faster, and generalizes better with significantly\nreduced training overfitting. Empirically, GIFT achieves superior reasoning and\nalignment performance on mathematical benchmarks while remaining\ncomputationally efficient.", "AI": {"tldr": "GIFT\u63d0\u51fa\u4e00\u79cd\u7ec4\u76f8\u5173\u9690\u5f0f\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u9690\u5f0f\u5956\u52b1\u4e0e\u663e\u5f0f\u5956\u52b1\u5f52\u4e00\u5316\u5e76\u6700\u5c0f\u5316\u5b83\u4eec\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u8f6c\u5316\u4e3aMSE\u76ee\u6807\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u6548\u3001\u7a33\u5065\u4e14\u5177\u6709\u63a2\u7d22\u6027\u7684\u5bf9\u9f50\u4f18\u5316\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709RLHF/\u9690\u5f0f\u5956\u52b1\u65b9\u6cd5\u5728\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e2d\u7684\u6311\u6218\uff1a\u975e\u51f8\u4f18\u5316\u3001\u9690\u5f0f\u5956\u52b1\u4e2d\u7684\u4e0d\u53ef\u63a7\u9879\u3001\u79bb\u7ebf\u65b9\u6cd5\u7f3a\u4e4f\u63a2\u7d22\u3001\u4ee5\u53ca\u9700\u8981\u66f4\u5c11\u8d85\u53c2\u6570\u548c\u66f4\u597d\u6cdb\u5316\u3002", "method": "\u7ed3\u5408GRPO\u7684\u5728\u7ebf\u591a\u91cd\u54cd\u5e94\u751f\u6210\u4e0e\u5f52\u4e00\u5316\u3001DPO\u7684\u9690\u5f0f\u5956\u52b1\u8868\u8ff0\u3001\u4ee5\u53caUNA\u7684\u9690\u5f0f-\u663e\u5f0f\u5956\u52b1\u5bf9\u9f50\u4e09\u8005\uff0c\u63d0\u51faGIFT\u3002\u901a\u8fc7\u5f52\u4e00\u5316\u6d88\u9664\u4e0d\u53ef\u79ef\u9879\uff0c\u5c06\u76ee\u6807\u8f6c\u5316\u4e3a\u5bf9\u5f52\u4e00\u5316\u540e\u7684\u5956\u52b1\u51fd\u6570\u7684\u5747\u5e73\u65b9\u8bef\u5dee\uff08MSE\uff09\uff0c\u5b9e\u73b0\u5173\u4e8e\u7b56\u7565\u7684\u5bf9\u9f50\u4f18\u5316\u3002\u4fdd\u6301\u5728\u7b56\u7565\u7684\u63a2\u7d22\u6027\u3002\u4e0eGRPO\u76f8\u6bd4\uff0c\u8d85\u53c2\u6570\u66f4\u5c11\u3001\u6536\u655b\u66f4\u5feb\u3001\u6cdb\u5316\u66f4\u597d\u3001\u8bad\u7ec3\u8fc7\u62df\u5408\u663e\u8457\u51cf\u5c11\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7b49\u57fa\u51c6\u4e0a\uff0cGIFT\u5728\u63a8\u7406\u548c\u5bf9\u9f50\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u8bad\u7ec3\u7a33\u5b9a\u3002", "conclusion": "GIFT\u5c06\u5bf9\u9f50\u4f18\u5316\u4ece\u975e\u51f8\u95ee\u9898\u8f6c\u5316\u4e3a\u7b80\u5355\u7684MSE\u6700\u5c0f\u5316\uff0c\u63d0\u4f9b\u4e00\u4e2a\u5728\u7b56\u7565\u5728\u7ebf\u3001\u6709\u6548\u63a2\u7d22\u4e0e\u9690\u5f0f\u663e\u5f0f\u5956\u52b1\u5bf9\u9f50\u4e4b\u95f4\u7684\u6298\u4e2d\u65b9\u6848\uff0c\u589e\u5f3a\u4e86\u5bf9LLM\u5bf9\u9f50\u7684\u53ef\u884c\u6027\u4e0e\u6cdb\u5316\u6027\uff0c\u540c\u65f6\u5bf9\u51cf\u5c11\u8d85\u53c2\u6570\u5177\u6709\u6f5c\u5728\u610f\u4e49\u3002"}}
{"id": "2510.23901", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23901", "abs": "https://arxiv.org/abs/2510.23901", "authors": ["Cristobal Heredia", "Pedro Chumpitaz-Flores", "Kaixun Hua"], "title": "RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal Regression Trees", "comment": "20 pages, 1 figure, uses ICLR 2026 LaTeX style. Submitted to arXiv as\n  a preprint version", "summary": "Mixed-integer programming (MIP) has emerged as a powerful framework for\nlearning optimal decision trees. Yet, existing MIP approaches for regression\ntasks are either limited to purely binary features or become computationally\nintractable when continuous, large-scale data are involved. Naively binarizing\ncontinuous features sacrifices global optimality and often yields needlessly\ndeep trees. We recast the optimal regression-tree training as a two-stage\noptimization problem and propose Reduced-Space Optimal Regression Trees\n(RS-ORT) - a specialized branch-and-bound (BB) algorithm that branches\nexclusively on tree-structural variables. This design guarantees the\nalgorithm's convergence and its independence from the number of training\nsamples. Leveraging the model's structure, we introduce several bound\ntightening techniques - closed-form leaf prediction, empirical threshold\ndiscretization, and exact depth-1 subtree parsing - that combine with\ndecomposable upper and lower bounding strategies to accelerate the training.\nThe BB node-wise decomposition enables trivial parallel execution, further\nalleviating the computational intractability even for million-size datasets.\nBased on the empirical studies on several regression benchmarks containing both\nbinary and continuous features, RS-ORT also delivers superior training and\ntesting performance than state-of-the-art methods. Notably, on datasets with up\nto 2,000,000 samples with continuous features, RS-ORT can obtain guaranteed\ntraining performance with a simpler tree structure and a better generalization\nability in four hours.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a RS-ORT \u7684Reduced-Space Optimal Regression Trees \u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e13\u95e8\u7684\u5206\u652f\u5b9a\u754c\uff08BB\uff09\u7b97\u6cd5\u5728\u51cf\u5c11\u7684\u7a7a\u95f4\u4e2d\u5bf9\u56de\u5f52\u6811\u8fdb\u884c\u6700\u4f18\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u5927\u5c3a\u5ea6\u6570\u636e\u4e0a\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MIP\uff09\u7684\u56de\u5f52\u6811\u5b66\u4e60\u5728\u8fde\u7eed\u7279\u5f81\u548c\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u8981\u4e48\u53d7\u9650\u4e8e\u4e8c\u503c\u5316\u8981\u4e48\u8ba1\u7b97\u4e0d\u53ef\u884c\u3002\u9700\u8981\u4e00\u79cd\u5728\u4fdd\u8bc1\u5168\u5c40\u6700\u4f18\u6027\u7684\u540c\u65f6\uff0c\u80fd\u5904\u7406\u767e\u4e07\u7ea7\u6570\u636e\u7684\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u5c06\u6700\u4f18\u56de\u5f52\u6811\u8bad\u7ec3\u95ee\u9898\u5efa\u6a21\u4e3a\u4e24\u9636\u6bb5\u4f18\u5316\uff0c\u91c7\u7528\u4ec5\u5bf9\u6811\u7ed3\u6784\u53d8\u91cf\u8fdb\u884c\u5206\u652f\u7684 BB \u601d\u8def\uff1b\u5229\u7528\u7ed3\u6784\u7279\u6027\u5b9e\u73b0\u591a\u79cd\u754c Tightening\uff08\u95ed\u5f0f\u53f6\u9884\u6d4b\u3001\u7ecf\u9a8c\u9608\u503c\u79bb\u6563\u5316\u3001\u6df1\u5ea6-1 \u5b50\u6811\u89e3\u6790\uff09\uff0c\u5e76\u8f85\u4ee5\u53ef\u5206\u89e3\u7684\u4e0a\u754c/\u4e0b\u754c\u4e0e\u8282\u70b9\u7ea7\u5e76\u884c\uff0c\u6784\u5efa\u51cf\u5c11\u5c3a\u5ea6\u7684\u5bb9\u9519\u7cfb\u7edf\uff0c\u8bad\u7ec3\u4e0e\u63a8\u7406\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e0e\u6837\u672c\u91cf\u6b63\u76f8\u5173\u6027\u51cf\u5f31\u3002", "result": "\u5728\u6df7\u5408\u7279\u5f81\uff08\u5305\u542b\u4e8c\u503c\u548c\u8fde\u7eed\u7279\u5f81\uff09\u7684\u591a\u79cd\u56de\u5f52\u57fa\u51c6\u4e0a\uff0cRS-ORT \u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1b\u5728\u9ad8\u8fbe200\u4e07\u6837\u672c\u3001\u5305\u542b\u8fde\u7eed\u7279\u5f81\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u80fd\u591f\u5728\u56db\u5c0f\u65f6\u5185\u83b7\u5f97\u5e26\u6709\u7b80\u5355\u6811\u5f62\u7ed3\u6784\u7684\u4fdd\u8bc1\u6027\u8bad\u7ec3\u6027\u80fd\u5e76\u5177\u5907\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "RS-ORT \u4e3a\u5927\u89c4\u6a21\u3001\u8fde\u7eed\u7279\u5f81\u7684\u56de\u5f52\u6811\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u4fdd\u8bc1\u7684\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u5206\u652f\u7b56\u7565\u4e0e\u591a\u79cd\u754c\u4ef7\u6539\u8fdb\uff0c\u5b9e\u73b0\u9ad8\u6548\u5e76\u884c\u548c\u4f18\u826f\u6cdb\u5316\u3002"}}
{"id": "2510.23912", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23912", "abs": "https://arxiv.org/abs/2510.23912", "authors": ["Marko Karbevski", "Antonij Mijoski"], "title": "Key and Value Weights Are Probably All You Need: On the Necessity of the Query, Key, Value weight Triplet in Decoder-Only Transformers", "comment": null, "summary": "The Query, Key, Value weight triplet is a building block of current attention\nmechanisms in state-of-the-art LLMs. We theoretically investigate whether this\ntriplet can be reduced, proving under simplifying assumptions that the Query\nweights are redundant, thereby reducing the number of non-embedding/lm-head\nparameters by over 8%. We validate the theory on full-complexity GPT-3 small\narchitectures (with layer normalization, skip connections, and weight decay)\ntrained from scratch, demonstrating that the reduced model achieves comparable\nvalidation loss to standard baselines. These findings motivate the\ninvestigation of the Query weight redundancy at scale.", "AI": {"tldr": "\u5728\u6ce8\u610f\u529b\u7684 Query-Key-Value \u4e09\u5143\u7ec4\u4e2d\uff0cQuery \u6743\u91cd\u53ef\u5197\u4f59\uff0c\u964d\u4f4e\u975e\u5d4c\u5165/LM\u5934\u53c2\u6570\u22658%\uff0c\u5728\u4ece\u5934\u8bad\u7ec3\u7684 GPT-3 \u5c0f\u578b\u67b6\u6784\u4e0a\u4ecd\u4fdd\u6301\u4e0e\u6807\u51c6\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u7406\u89e3 Query \u6743\u91cd\u7684\u5197\u4f59\u6027\uff0c\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u6ce8\u610f\u529b\u8868\u793a\u53ca\u5176\u5728\u5927\u89c4\u6a21\u6a21\u578b\u4e2d\u7684\u6f5c\u5728\u6269\u5c55\u6027\u3002", "method": "\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff08\u5728\u7b80\u5316\u5047\u8bbe\u4e0b\uff09\uff0c\u5e76\u5728\u5305\u542b\u5c42\u5f52\u4e00\u5316\u3001\u8df3\u8dc3\u8fde\u63a5\u3001\u6743\u8870\u51cf\u7b49\u6761\u4ef6\u7684\u5b8c\u6574\u590d\u6742\u5ea6 GPT-3 \u5c0f\u578b\u67b6\u6784\u4e0a\u4ece\u5934\u8bad\u7ec3\u8fdb\u884c\u9a8c\u8bc1\uff0c\u6bd4\u8f83\u7b80\u5316\u6a21\u578b\u4e0e\u57fa\u7ebf\u7684\u8868\u73b0\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e Query \u6743\u91cd\u5197\u4f59\uff1b\u5b9e\u8bc1\u4e0a\u7b80\u5316\u6a21\u578b\u5728\u9a8c\u8bc1\u635f\u5931\u4e0a\u4e0e\u6807\u51c6\u57fa\u7ebf\u76f8\u5f53\u3002", "conclusion": "\u8be5\u7ed3\u679c\u63a8\u52a8\u5728\u5927\u89c4\u6a21\u6a21\u578b\u4e2d\u5bf9 Query \u6743\u91cd\u5197\u4f59\u6027\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u4fc3\u8fdb\u53c2\u6570\u9ad8\u6548\u7684\u6ce8\u610f\u529b\u8bbe\u8ba1\u4e0e\u6269\u5c55\u3002"}}
{"id": "2510.23914", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23914", "abs": "https://arxiv.org/abs/2510.23914", "authors": ["Arsenii Mustafin", "Xinyi Sheng", "Dominik Baumann"], "title": "Geometry-Inspired Unified Framework for Discounted and Average Reward MDPs", "comment": "12 pages, 1 figure", "summary": "The theoretical analysis of Markov Decision Processes (MDPs) is commonly\nsplit into two cases - the average-reward case and the discounted-reward case -\nwhich, while sharing similarities, are typically analyzed separately. In this\nwork, we extend a recently introduced geometric interpretation of MDPs for the\ndiscounted-reward case to the average-reward case, thereby unifying both. This\nallows us to extend a major result known for the discounted-reward case to the\naverage-reward case: under a unique and ergodic optimal policy, the Value\nIteration algorithm achieves a geometric convergence rate.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u6298\u6263\u4e0e\u5e73\u5747\u5956\u52b1MDP\u7684\u51e0\u4f55\u89e3\u91ca\u6846\u67b6\uff0c\u5e76\u5728\u552f\u4e00\u4e14\u904d\u5386\u7684\u6700\u4f18\u7b56\u7565\u4e0b\u8bc1\u660e\u5e73\u5747\u5956\u52b1\u95ee\u9898\u4e2d\u7684\u503c\u8fed\u4ee3\u5177\u6709\u51e0\u4f55\u6536\u655b\u901f\u7387\u3002", "motivation": "\u901a\u8fc7\u5c06\u6298\u6263\u5956\u52b1\u60c5\u5f62\u7684\u51e0\u4f55\u89e3\u91ca\u6269\u5c55\u5230\u5e73\u5747\u5956\u52b1\u60c5\u5f62\uff0c\u7edf\u4e00\u4e24\u7c7bMDP\u7684\u5206\u6790\uff0c\u5e76\u63d0\u5347\u5bf9\u503c\u8fed\u4ee3\u6536\u655b\u6027\u7684\u7406\u89e3\u3002", "method": "\u6269\u5c55\u6298\u6263\u60c5\u5f62\u7684\u51e0\u4f55\u89e3\u91ca\u5230\u5e73\u5747\u5956\u52b1\u60c5\u5f62\uff0c\u5efa\u7acb\u7edf\u4e00\u5206\u6790\u6846\u67b6\uff1b\u5728\u552f\u4e00\u4e14\u904d\u5386\u7684\u6700\u4f18\u7b56\u7565\u6761\u4ef6\u4e0b\uff0c\u63a8\u5bfc\u503c\u8fed\u4ee3\u7684\u51e0\u4f55\u6536\u655b\u7387\u3002", "result": "\u5728\u4e0a\u8ff0\u6761\u4ef6\u4e0b\uff0c\u5e73\u5747\u5956\u52b1MDP\u7684\u503c\u8fed\u4ee3\u5b9e\u73b0\u51e0\u4f55\u6536\u655b\uff0c\u7c7b\u4f3c\u4e8e\u6298\u6263\u60c5\u5f62\u7684\u7ed3\u679c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5b9e\u73b0\u5e73\u5747\u5956\u52b1\u4e0e\u6298\u6263\u5956\u52b1\u5206\u6790\u7684\u7edf\u4e00\uff0c\u5c55\u793a\u4e86\u6240\u63d0\u51fa\u51e0\u4f55\u6846\u67b6\u7684\u9002\u7528\u6027\uff0c\u5e76\u5c06\u6298\u6263\u60c5\u5f62\u7684\u91cd\u8981\u6027\u8d28\u63a8\u5e7f\u5230\u5e73\u5747\u5956\u52b1\u60c5\u5f62\u3002"}}
{"id": "2510.23948", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23948", "abs": "https://arxiv.org/abs/2510.23948", "authors": ["Qianfeng Wen", "Zhenwei Tang", "Ashton Anderson"], "title": "ChessQA: Evaluating Large Language Models for Chess Understanding", "comment": "33 pages,8 figures", "summary": "Chess provides an ideal testbed for evaluating the reasoning, modeling, and\nabstraction capabilities of large language models (LLMs), as it has\nwell-defined structure and objective ground truth while admitting a wide\nspectrum of skill levels. However, existing evaluations of LLM ability in chess\nare ad hoc and narrow in scope, making it difficult to accurately measure LLM\nchess understanding and how it varies with scale, post-training methodologies,\nor architecture choices. We present ChessQA, a comprehensive benchmark that\nassesses LLM chess understanding across five task categories (Structural,\nMotifs, Short Tactics, Position Judgment, and Semantic), which approximately\ncorrespond to the ascending abstractions that players master as they accumulate\nchess knowledge, from understanding basic rules and learning tactical motifs to\ncorrectly calculating tactics, evaluating positions, and semantically\ndescribing high-level concepts. In this way, ChessQA captures a more\ncomprehensive picture of chess ability and understanding, going significantly\nbeyond the simple move quality evaluations done previously, and offers a\ncontrolled, consistent setting for diagnosis and comparison. Furthermore,\nChessQA is inherently dynamic, with prompts, answer keys, and construction\nscripts that can evolve as models improve. Evaluating a range of contemporary\nLLMs, we find persistent weaknesses across all five categories and provide\nresults and error analyses by category. We will release the code, periodically\nrefreshed datasets, and a public leaderboard to support further research.", "AI": {"tldr": "ChessQA \u662f\u4e00\u4e2a\u5168\u9762\u4e14\u52a8\u6001\u7684\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u68cb\u827a\u7406\u89e3\u4e2d\u7684\u4e94\u7c7b\u4efb\u52a1\uff08\u7ed3\u6784\u3001\u6280\u5de7\u3001\u77ed\u6218\u672f\u3001\u4f4d\u7f6e\u5224\u65ad\u3001\u8bed\u4e49\uff09\uff0c\u8d85\u8d8a\u7b80\u5355\u7684\u8d70\u68cb\u8d28\u91cf\u8bc4\u4ef7\uff0c\u80fd\u591f\u8bca\u65ad\u4e0d\u540c\u89c4\u6a21\u3001\u8bad\u7ec3\u540e\u65b9\u6cd5\u548c\u67b6\u6784\u5bf9\u68cb\u7406\u89e3\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u4f9b\u4ee3\u7801\u3001\u6570\u636e\u96c6\u548c\u6392\u884c\u699c\u4ee5\u652f\u6301\u6301\u7eed\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u5bf9\u68cb\u7c7b\u80fd\u529b\u7684\u8bc4\u4f30\u591a\u4e3a\u96f6\u6563\u4e14\u9886\u57df\u5c40\u9650\uff0c\u96be\u4ee5\u51c6\u786e\u8861\u91cf\u6a21\u578b\u5728\u68cb\u7406\u63a8\u7406\u3001\u5efa\u6a21\u4e0e\u62bd\u8c61\u4e0a\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u968f\u6a21\u578b\u89c4\u6a21\u3001\u540e\u8bad\u7ec3\u65b9\u6cd5\u6216\u67b6\u6784\u53d8\u5316\u7684\u5dee\u5f02\u3002\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u8986\u76d6\u68cb\u77e5\u8bc6\u6f14\u8fdb\u9636\u6bb5\u7684\u7efc\u5408\u6027\u57fa\u51c6\uff0c\u4ee5\u4fbf\u5728\u53ef\u63a7\u3001\u53ef\u6bd4\u8f83\u7684\u5b9e\u9a8c\u73af\u5883\u4e2d\u8bca\u65ad\u548c\u6bd4\u8f83\u6a21\u578b\u8868\u73b0\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e94\u5927\u4efb\u52a1\u7c7b\u522b\u7684\u57fa\u51c6 ChessQA\uff1a\u7ed3\u6784\uff08Structural\uff09\u3001\u4e3b\u9898/\u6280\u5de7\u6a21\u5f0f\uff08Motifs\uff09\u3001\u77ed\u671f\u6218\u672f\uff08Short Tactics\uff09\u3001\u4f4d\u7f6e\u5224\u65ad\uff08Position Judgment\uff09\u548c\u8bed\u4e49\u7406\u89e3\uff08Semantic\uff09\u3002\u4efb\u52a1\u8bbe\u8ba1\u5927\u81f4\u5bf9\u5e94\u68cb\u624b\u4ece\u7406\u89e3\u57fa\u672c\u89c4\u5219\u3001\u5b66\u4e60\u6218\u672f\u6a21\u5f0f\uff0c\u5230\u6b63\u786e\u8ba1\u7b97\u6218\u672f\u3001\u8bc4\u4f30\u68cb\u5c40\u4ee5\u53ca\u8bed\u4e49\u63cf\u8ff0\u9ad8\u5c42\u6982\u5ff5\u7684\u9010\u6b65\u62bd\u8c61\u8fc7\u7a0b\u3002\u57fa\u51c6\u5177\u5907\u52a8\u6001\u7279\u6027\uff0c\u63d0\u793a\u3001\u7b54\u6848\u952e\u548c\u6784\u5efa\u811a\u672c\u53ef\u968f\u6a21\u578b\u8fdb\u6b65\u800c\u6f14\u5316\u3002\u5bf9\u4e00\u7cfb\u5217\u5f53\u4ee3 LLMs \u8fdb\u884c\u8bc4\u6d4b\uff0c\u63d0\u4f9b\u6309\u7c7b\u522b\u7684\u9519\u8bef\u5206\u6790\u548c\u7ed3\u679c\u3002\u7814\u7a76\u65b9\u8fd8\u5c06\u53d1\u5e03\u4ee3\u7801\u3001\u5b9a\u671f\u5237\u65b0\u6570\u636e\u96c6\u4ee5\u53ca\u516c\u5f00\u6392\u884c\u699c\u3002", "result": "\u5728\u6240\u6709\u4e94\u7c7b\u4efb\u52a1\u4e2d\uff0c\u5f53\u524d\u7684\u5404\u5927\u6a21\u578b\u5747\u8868\u73b0\u51fa\u6301\u7eed\u7684\u5f31\u70b9\uff0c\u5b58\u5728\u666e\u904d\u6027\u4e0d\u8db3\uff0c\u5e76\u7ed9\u51fa\u6309\u7c7b\u522b\u7684\u9519\u8bef\u5206\u6790\u4e0e\u7ed3\u679c\u3002\u57fa\u51c6\u7684\u8bc4\u6d4b\u8986\u76d6\u4e94\u7c7b\u62bd\u8c61\u5c42\u7ea7\uff0c\u80fd\u591f\u63ed\u793a\u6a21\u578b\u5728\u4e0d\u540c\u68cb\u7c7b\u7406\u89e3\u7ef4\u5ea6\u7684\u74f6\u9888\u3002\u7814\u7a76\u8fd8\u5c55\u793a\u4e86\u52a8\u6001\u3001\u53ef\u6f14\u5316\u7684\u8bc4\u6d4b\u751f\u6001\uff0c\u4fbf\u4e8e\u968f\u6a21\u578b\u6539\u8fdb\u6301\u7eed\u5bf9\u6bd4\u3002", "conclusion": "ChessQA \u63d0\u4f9b\u4e00\u4e2a\u66f4\u5168\u9762\u7684\u8bca\u65ad\u6027\u5de5\u5177\uff0c\u4fbf\u4e8e\u5bf9\u4e0d\u540c\u6a21\u578b\u3001\u57f9\u8bad\u65b9\u6cd5\u548c\u67b6\u6784\u5728\u68cb\u7406\u89e3\u4e0a\u7684\u5dee\u5f02\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\u4e0e\u8bca\u65ad\u3002\u7531\u4e8e\u5176\u52a8\u6001\u7279\u6027\uff0c\u8be5\u57fa\u51c6\u80fd\u591f\u968f\u6a21\u578b\u8fdb\u6b65\u6301\u7eed\u6f14\u5316\uff0c\u4fc3\u8fdb\u5bf9\u68cb\u7406\u7406\u89e3\u7684\u6df1\u5165\u7814\u7a76\u4e0e\u6539\u8fdb\u3002"}}
{"id": "2510.23966", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.23966", "abs": "https://arxiv.org/abs/2510.23966", "authors": ["Scott Emmons", "Roland S. Zimmermann", "David K. Elson", "Rohin Shah"], "title": "A Pragmatic Way to Measure Chain-of-Thought Monitorability", "comment": "The first two authors contributed equally", "summary": "While Chain-of-Thought (CoT) monitoring offers a unique opportunity for AI\nsafety, this opportunity could be lost through shifts in training practices or\nmodel architecture. To help preserve monitorability, we propose a pragmatic way\nto measure two components of it: legibility (whether the reasoning can be\nfollowed by a human) and coverage (whether the CoT contains all the reasoning\nneeded for a human to also produce the final output). We implement these\nmetrics with an autorater prompt that enables any capable LLM to compute the\nlegibility and coverage of existing CoTs. After sanity-checking our prompted\nautorater with synthetic CoT degradations, we apply it to several frontier\nmodels on challenging benchmarks, finding that they exhibit high\nmonitorability. We present these metrics, including our complete autorater\nprompt, as a tool for developers to track how design decisions impact\nmonitorability. While the exact prompt we share is still a preliminary version\nunder ongoing development, we are sharing it now in the hopes that others in\nthe community will find it useful. Our method helps measure the default\nmonitorability of CoT - it should be seen as a complement, not a replacement,\nfor the adversarial stress-testing needed to test robustness against\ndeliberately evasive models.", "AI": {"tldr": "\u63d0\u51fa\u901a\u8fc7 autorater \u63d0\u793a\u6765\u91cf\u5316 Chain-of-Thought \u7684 legibility\uff08\u53ef\u88ab\u4eba\u7406\u89e3\u7684\u7a0b\u5ea6\uff09\u4e0e coverage\uff08\u662f\u5426\u8986\u76d6\u5fc5\u8981\u63a8\u7406\uff09\uff0c\u5e76\u7528\u5bf9\u73b0\u6709 CoT \u7684\u8bc4\u4f30\u6765\u76d1\u63a7\u6a21\u578b\u7684 monitorability\u3002\u5b9e\u73b0\u5305\u542b\u4e00\u4e2a autorater LLM\u3001\u5bf9\u5408\u6210\u964d\u7ea7\u7684\u81ea\u68c0\u3001\u5728\u524d\u6cbf\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u4ecd\u5177\u9ad8 monitorability\uff1b\u5e76\u516c\u5f00\u5b8c\u6574 prompt \u4f9b\u5f00\u53d1\u8005\u8ffd\u8e2a\u8bbe\u8ba1\u9009\u62e9\u5bf9 monitorability \u7684\u5f71\u54cd\uff0c\u5f3a\u8c03\u8be5\u65b9\u6cd5\u662f\u5bf9\u6297\u6027\u538b\u529b\u6d4b\u8bd5\u7684\u8865\u5145\u3002", "motivation": "\u5728\u8bad\u7ec3\u5b9e\u8df5\u6216\u6a21\u578b\u67b6\u6784\u53d8\u5316\u540e\uff0c\u4ecd\u80fd\u4fdd\u7559 CoT \u7684\u53ef\u76d1\u63a7\u6027\u3002\u9700\u8981\u53ef\u64cd\u4f5c\u3001\u53ef\u590d\u73b0\u7684\u6307\u6807\u6765\u8861\u91cf\u63a8\u7406\u8fc7\u7a0b\u7684\u53ef\u8bfb\u6027\u4e0e\u8986\u76d6\u5ea6\uff0c\u4ee5\u4fbf\u8bbe\u8ba1\u8005\u8bc4\u4f30\u4e0d\u540c\u8bbe\u8ba1\u5bf9 monitorability \u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a autorater prompt\uff0c\u4f7f\u4efb\u4f55\u5177\u5907\u80fd\u529b\u7684\u5927\u6a21\u578b\u90fd\u80fd\u8bc4\u4f30\u73b0\u6709 CoT \u7684 legibility \u4e0e coverage\u3002\u5bf9\u8be5 prompt \u8fdb\u884c\u5408\u6210\u964d\u7ea7\u7684\u81ea\u68c0\u9a8c\u8bc1\u540e\uff0c\u5c06\u5176\u5e94\u7528\u4e8e\u591a\u5bb6\u524d\u6cbf\u6a21\u578b\u5728\u6311\u6218\u6027\u57fa\u51c6\u4e0a\u7684\u8bc4\u4f30\uff0c\u7edf\u8ba1 monitorability \u6307\u6807\uff0c\u5e76\u516c\u5f00\u5b8c\u6574 autorater prompt \u4ee5\u4f9b\u5f00\u53d1\u8005\u4f7f\u7528\u3002", "result": "\u5728\u591a\u5bb6 frontier \u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0c\u89c2\u5bdf\u5230\u5b83\u4eec\u5448\u73b0\u51fa\u8f83\u9ad8\u7684 monitorability\u3002\u7814\u7a76\u8005\u5c06\u4e24\u9879\u6307\u6807\u53ca\u5b8c\u6574 prompt \u4f5c\u4e3a\u5de5\u5177\u63d0\u4f9b\u7ed9\u5f00\u53d1\u8005\uff0c\u7528\u4ee5\u8ddf\u8e2a\u8bbe\u8ba1\u51b3\u7b56\u5bf9 monitorability \u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5e94\u88ab\u89c6\u4e3a\u5bf9\u6297\u6027\u538b\u529b\u6d4b\u8bd5\u7684\u8865\u5145\uff0c\u800c\u975e\u66ff\u4ee3\uff0c\u5728\u63d0\u793a\u5c42\u9762\u5206\u4eab\u7684 prompt \u4ecd\u5904\u4e8e\u521d\u6b65\u7248\u672c\uff0c\u6b22\u8fce\u793e\u533a\u4f7f\u7528\u5e76\u8fdb\u4e00\u6b65\u5b8c\u5584\u3002\u5b83\u6709\u52a9\u4e8e\u8861\u91cf CoT \u7684\u9ed8\u8ba4 monitorability\uff0c\u4e3a\u4e86\u89e3\u8bbe\u8ba1\u6539\u52a8\u5bf9\u76d1\u63a7\u6027\u7684\u5f71\u54cd\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2510.23972", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23972", "abs": "https://arxiv.org/abs/2510.23972", "authors": ["Andra\u017e Jelin\u010di\u010d", "Owen Lockwood", "Akhil Garlapati", "Guillaume Verdon", "Trevor McCourt"], "title": "An efficient probabilistic hardware architecture for diffusion-like models", "comment": "9 pages, 6 figures", "summary": "The proliferation of probabilistic AI has promoted proposals for specialized\nstochastic computers. Despite promising efficiency gains, these proposals have\nfailed to gain traction because they rely on fundamentally limited modeling\ntechniques and exotic, unscalable hardware. In this work, we address these\nshortcomings by proposing an all-transistor probabilistic computer that\nimplements powerful denoising models at the hardware level. A system-level\nanalysis indicates that devices based on our architecture could achieve\nperformance parity with GPUs on a simple image benchmark using approximately\n10,000 times less energy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5168\u6676\u4f53\u7ba1\u6982\u7387\u8ba1\u7b97\u673a\uff0c\u5728\u786c\u4ef6\u5c42\u9762\u5b9e\u73b0\u5f3a\u5927\u7684\u53bb\u566a\u6a21\u578b\uff0c\u7406\u8bba\u4e0a\u53ef\u4e0eGPU\u5728\u7b80\u5355\u56fe\u50cf\u57fa\u51c6\u4e0a\u6027\u80fd\u76f8\u5f53\uff0c\u4f46\u80fd\u8017\u7ea6\u964d\u4f4e10000\u500d\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6982\u7387AI\u7684\u4e13\u7528\u968f\u673a\u8ba1\u7b97\u673a\u5e38\u56e0\u5efa\u6a21\u65b9\u6cd5\u6709\u9650\u3001\u786c\u4ef6\u4e0d\u53ef\u6269\u5c55\u800c\u96be\u4ee5\u843d\u5730\uff0c\u9700\u8981\u4e00\u4e2a\u5728\u786c\u4ef6\u5c42\u9762\u5c31\u80fd\u9ad8\u6548\u5b9e\u73b0\u53bb\u566a\u4e0e\u63a8\u7406\u7684\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5168\u6676\u4f53\u7ba1(all-transistor)\u6982\u7387\u8ba1\u7b97\u673a\uff0c\u5728\u786c\u4ef6\u7ea7\u522b\u5b9e\u73b0\u5f3a\u5927\u7684\u53bb\u566a\u6a21\u578b\uff1b\u8fdb\u884c\u4e86\u7cfb\u7edf\u7ea7\u5206\u6790\u4ee5\u8bc4\u4f30\u4e0eGPU\u7684\u6027\u80fd\u5bf9\u6bd4\u548c\u80fd\u8017\u6f5c\u529b\u3002", "result": "\u7cfb\u7edf\u7ea7\u5206\u6790\u8868\u660e\uff0c\u8be5\u67b6\u6784\u7684\u8bbe\u5907\u5728\u4e00\u4e2a\u7b80\u5355\u7684\u56fe\u50cf\u57fa\u51c6\u4e0a\u6709\u671b\u8fbe\u5230\u4e0eGPU\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u80fd\u8017\u6bd4GPU\u4f4e\u7ea61\u4e07\u500d\u3002", "conclusion": "\u5c55\u793a\u4e86\u5728\u786c\u4ef6\u5c42\u9762\u5b9e\u73b0\u9ad8\u6548\u6982\u7387\u63a8\u7406\u4e0e\u53bb\u566a\u80fd\u529b\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u6982\u7387AI\u786c\u4ef6\u7684\u80fd\u6548\u63d0\u5347\u63d0\u4f9b\u6f5c\u5728\u8def\u5f84\u3002"}}
{"id": "2510.23974", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23974", "abs": "https://arxiv.org/abs/2510.23974", "authors": ["Byeonghu Na", "Minsang Park", "Gyuwon Sim", "Donghyeok Shin", "HeeSun Bae", "Mina Kang", "Se Jung Kwon", "Wanmo Kang", "Il-Chul Moon"], "title": "Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models", "comment": "Accepted at NeurIPS 2025", "summary": "Text-to-image diffusion models rely on text embeddings from a pre-trained\ntext encoder, but these embeddings remain fixed across all diffusion timesteps,\nlimiting their adaptability to the generative process. We propose Diffusion\nAdaptive Text Embedding (DATE), which dynamically updates text embeddings at\neach diffusion timestep based on intermediate perturbed data. We formulate an\noptimization problem and derive an update rule that refines the text embeddings\nat each sampling step to improve alignment and preference between the mean\npredicted image and the text. This allows DATE to dynamically adapts the text\nconditions to the reverse-diffused images throughout diffusion sampling without\nrequiring additional model training. Through theoretical analysis and empirical\nresults, we show that DATE maintains the generative capability of the model\nwhile providing superior text-image alignment over fixed text embeddings across\nvarious tasks, including multi-concept generation and text-guided image\nediting. Our code is available at https://github.com/aailab-kaist/DATE.", "AI": {"tldr": "DATE\u5728\u6269\u6563\u91c7\u6837\u7684\u6bcf\u4e00\u6b65\u52a8\u6001\u66f4\u65b0\u6587\u672c\u5d4c\u5165\u4ee5\u63d0\u9ad8\u6587\u672c-\u56fe\u50cf\u5bf9\u9f50\uff0c\u4e14\u4e0d\u9700\u989d\u5916\u8bad\u7ec3\u3002", "motivation": "\u56fa\u5b9a\u7684\u6587\u672c\u5d4c\u5165\u5728\u6574\u4e2a\u6269\u6563\u8fc7\u7a0b\u4e2d\u4e0d\u53ef\u53d8\uff0c\u9650\u5236\u4e86\u5bf9\u751f\u6210\u8fc7\u7a0b\u7684\u9002\u5e94\u6027\u4e0e\u5bf9\u9f50\u6027\u3002", "method": "\u5c06\u66f4\u65b0\u89c4\u5219\u4f5c\u4e3a\u5728\u6bcf\u4e00\u6b65\u91c7\u6837\u65f6\u5bf9\u6587\u672c\u5d4c\u5165\u7684\u4f18\u5316\u95ee\u9898\uff0c\u57fa\u4e8e\u4e2d\u95f4\u6270\u52a8\u6570\u636e\u8fdb\u884c\u8fed\u4ee3\u66f4\u65b0\uff0c\u4ee5\u63d0\u5347\u5d4c\u5165\u4e0e\u5747\u503c\u9884\u6d4b\u56fe\u50cf\u4e4b\u95f4\u7684\u5bf9\u9f50\u3002", "result": "\u5728\u4fdd\u6301\u6a21\u578b\u539f\u6709\u751f\u6210\u80fd\u529b\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86\u6587\u672c\u4e0e\u56fe\u50cf\u7684\u5bf9\u9f50\uff0c\u5728\u591a\u6982\u5ff5\u751f\u6210\u4e0e\u6587\u672c\u5f15\u5bfc\u7684\u56fe\u50cf\u7f16\u8f91\u7b49\u4efb\u52a1\u4e0a\u4f18\u4e8e\u56fa\u5b9a\u5d4c\u5165\uff0c\u4e14\u4ee3\u7801\u516c\u5f00\u3002", "conclusion": "DATE\u80fd\u591f\u5728\u4e0d\u989d\u5916\u8bad\u7ec3\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u52a8\u6001\u9002\u5e94\u6587\u672c\u6761\u4ef6\uff0c\u63d0\u5347\u6587\u672c-\u56fe\u50cf\u5bf9\u9f50\u80fd\u529b\uff0c\u4e14\u5177\u5907\u826f\u597d\u7684\u4e00\u822c\u6027\u3002"}}
{"id": "2510.23977", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23977", "abs": "https://arxiv.org/abs/2510.23977", "authors": ["Yohan Abeysinghe", "Muhammad Akhtar Munir", "Sanoojan Baliah", "Ron Sarafian", "Fahad Shahbaz Khan", "Yinon Rudich", "Salman Khan"], "title": "Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling", "comment": null, "summary": "Air pollution remains a leading global health and environmental risk,\nparticularly in regions vulnerable to episodic air pollution spikes due to\nwildfires, urban haze and dust storms. Accurate forecasting of particulate\nmatter (PM) concentrations is essential to enable timely public health warnings\nand interventions, yet existing models often underestimate rare but hazardous\npollution events. Here, we present SynCast, a high-resolution neural\nforecasting model that integrates meteorological and air composition data to\nimprove predictions of both average and extreme pollution levels. Built on a\nregionally adapted transformer backbone and enhanced with a diffusion-based\nstochastic refinement module, SynCast captures the nonlinear dynamics driving\nPM spikes more accurately than existing approaches. Leveraging on harmonized\nERA5 and CAMS datasets, our model shows substantial gains in forecasting\nfidelity across multiple PM variables (PM$_1$, PM$_{2.5}$, PM$_{10}$),\nespecially under extreme conditions. We demonstrate that conventional loss\nfunctions underrepresent distributional tails (rare pollution events) and show\nthat SynCast, guided by domain-aware objectives and extreme value theory,\nsignificantly enhances performance in highly impacted regions without\ncompromising global accuracy. This approach provides a scalable foundation for\nnext-generation air quality early warning systems and supports climate-health\nrisk mitigation in vulnerable regions.", "AI": {"tldr": "SynCast \u5728\u9ad8\u5206\u8fa8\u7387\u4e0b\u4f7f\u7528\u533a\u57df\u9002\u914d\u7684 Transformer \u4e3b\u5e72 + \u6269\u6563\u5f0f\u968f\u673a Refinement \u6a21\u5757\uff0c\u6574\u5408 ERA5 \u4e0e CAMS \u6570\u636e\uff0c\u663e\u8457\u63d0\u5347 PM1\u3001PM2.5\u3001PM10 \u7684\u5e73\u5747\u4e0e\u6781\u7aef\u6c61\u67d3\u9884\u6d4b\uff0c\u6539\u5584\u5c3e\u90e8\u5206\u5e03\u5e76\u5728\u9ad8\u6c61\u67d3\u533a\u57df\u663e\u8457\u63d0\u5347\u8b66\u62a5\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5bf9\u7f55\u89c1\u4f46\u5371\u9669\u7684\u6781\u7aef\u6c61\u67d3\u4e8b\u4ef6\u5f80\u5f80\u4f4e\u4f30\uff0c\u4e14\u5c3e\u90e8\u5206\u5e03\u63cf\u8ff0\u4e0d\u8db3\uff0c\u4e9f\u9700\u7ed3\u5408\u6c14\u8c61\u4e0e\u5927\u6c14\u6210\u5206\u6570\u636e\u7684\u9ad8\u5206\u8fa8\u7387\u3001\u5bf9\u6781\u7aef\u4e8b\u4ef6\u654f\u611f\u7684\u9884\u6d4b\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u516c\u5171\u536b\u751f\u9884\u8b66\u6548\u679c\u3002", "method": "\u91c7\u7528\u533a\u57df\u9002\u914d\u7684 Transformer \u4e3b\u5e72\uff0c\u8f85\u4ee5\u6269\u6563\u5f0f\u968f\u673a\u98ce\u683c\u5316\uff08diffusion-based stochastic refinement\uff09\u6a21\u5757\uff1b\u5c06\u6c14\u8c61\u6570\u636e\u4e0e\u5927\u6c14\u7ec4\u5206\u6570\u636e\u8fdb\u884c\u6df1\u5ea6\u878d\u5408\uff1b\u57fa\u4e8e harmonized ERA5 \u4e0e CAMS \u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff1b\u5f15\u5165\u9886\u57df\u611f\u77e5\u76ee\u6807\u4e0e\u6781\u503c\u7406\u8bba\uff08EVT\uff09\u4ee5\u63d0\u5347\u5c3e\u90e8\u9884\u6d4b\u80fd\u529b\u3002", "result": "\u5728 PM1\u3001PM2.5\u3001PM10 \u7684\u9884\u6d4b\u4e0a\u83b7\u5f97\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u5728\u6781\u7aef\u6761\u4ef6\u4e0b\u5bf9\u5206\u5e03\u5c3e\u90e8\u7684\u62df\u5408\u6539\u5584\u660e\u663e\uff1b\u5168\u7403\u7cbe\u5ea6\u4fdd\u6301\u826f\u597d\uff0c\u540c\u65f6\u5728\u9ad8\u6c61\u67d3\u5730\u533a\u7684\u9884\u6d4b\u80fd\u529b\u6709\u663e\u8457\u589e\u5f3a\uff0c\u9002\u5408\u7528\u4e8e\u533a\u57df\u6027\u65e9\u671f\u8b66\u62a5\u3002", "conclusion": "\u4e3a\u4e0b\u4e00\u4ee3\u7a7a\u6c14\u8d28\u91cf\u9884\u8b66\u7cfb\u7edf\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u9ad8\u5206\u8fa8\u7387\u9884\u6d4b\u6846\u67b6\uff0c\u652f\u6301\u53d7\u5f71\u54cd\u5730\u533a\u7684\u6c14\u5019-\u5065\u5eb7\u98ce\u9669\u7f13\u89e3\u3002"}}
{"id": "2510.23980", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.23980", "abs": "https://arxiv.org/abs/2510.23980", "authors": ["Guojing Cong", "Tom Potok", "Hamed Poursiami", "Maryam Parsa"], "title": "HyperGraphX: Graph Transductive Learning with Hyperdimensional Computing and Message Passing", "comment": null, "summary": "We present a novel algorithm, \\hdgc, that marries graph convolution with\nbinding and bundling operations in hyperdimensional computing for transductive\ngraph learning. For prediction accuracy \\hdgc outperforms major and popular\ngraph neural network implementations as well as state-of-the-art\nhyperdimensional computing implementations for a collection of homophilic\ngraphs and heterophilic graphs. Compared with the most accurate learning\nmethodologies we have tested, on the same target GPU platform, \\hdgc is on\naverage 9561.0 and 144.5 times faster than \\gcnii, a graph neural network\nimplementation and HDGL, a hyperdimensional computing implementation,\nrespectively. As the majority of the learning operates on binary vectors, we\nexpect outstanding energy performance of \\hdgc on neuromorphic and emerging\nprocess-in-memory devices.", "AI": {"tldr": "\u5c06\u56fe\u5377\u79ef\u4e0e\u8d85\u7ef4\u8ba1\u7b97\u4e2d\u7684\u7ed1\u5b9a/\u6346\u7ed1\u64cd\u4f5c\u76f8\u7ed3\u5408\u7684 hdgc\uff0c\u5728\u4f20\u5bfc\u5b66\u4e60\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u5ea6\u548c\u663e\u8457\u7684\u8ba1\u7b97\u52a0\u901f\uff0c\u4e14\u5bf9\u540c\u6784/\u5f02\u6784\u56fe\u5747\u6709\u826f\u597d\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3\u4f20\u5bfc\u56fe\u5b66\u4e60\u4e2d\u5728\u51c6\u786e\u6027\u4e0e\u80fd\u8017\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5229\u7528\u8d85\u7ef4\u8ba1\u7b97\u7684\u7ed1\u5b9a/\u6346\u7ed1\u64cd\u4f5c\u589e\u5f3a\u56fe\u7279\u5f81\u7684\u8868\u8fbe\uff0c\u540c\u65f6\u5728\u540c\u4e00GPU\u5e73\u53f0\u4e0b\u4e0e\u73b0\u6709GNN\u548cHD\u5b9e\u73b0\u8fdb\u884c\u5f3a\u5bf9\u6bd4\u3002", "method": "\u63d0\u51fa hdgc \u7b97\u6cd5\uff0c\u5c06\u56fe\u5377\u79ef\u4e0e\u7ed1\u5b9a/\u6346\u7ed1\u64cd\u4f5c\u8026\u5408\u5230\u8d85\u7ef4\u8ba1\u7b97\u6846\u67b6\u4e2d\uff0c\u9762\u5411\u4e8c\u503c\u5411\u91cf\u5b66\u4e60\uff0c\u9002\u7528\u4e8e\u540c\u8d28/\u5f02\u8d28\u56fe\uff0c\u8fdb\u884c\u4f20\u5bfc\u5b66\u4e60\uff0c\u5e76\u5728\u76f8\u540cGPU\u5e73\u53f0\u4e0a\u4e0e gcnii\uff08GNN\u5b9e\u73b0\uff09\u548c HDGL\uff08HD\u5b9e\u73b0\uff09\u7b49\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728\u4e00\u7ec4\u540c\u8d28/\u5f02\u8d28\u56fe\u4e0a\uff0chdgc \u5728\u9884\u6d4b\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u4e3b\u8981GNN\u4e0e\u5148\u8fdbHD\u5b9e\u73b0\uff1b\u5728\u76f8\u540c\u76ee\u6807GPU\u5e73\u53f0\u4e0a\uff0c\u5e73\u5747\u5206\u522b\u6bd4 gcnii \u5feb 9561.0 \u500d\u3001\u6bd4 HDGL \u5feb 144.5 \u500d\u3002\u5e76\u4e14\u591a\u6570\u5b66\u4e60\u5728\u4e8c\u503c\u5411\u91cf\u4e0a\uff0c\u9884\u671f\u5728\u7c7b\u8111\u795e\u7ecf\u5f62\u6001\u548c\u5185\u5b58\u8ba1\u7b97\u8bbe\u5907\u4e0a\u5177\u5907\u51fa\u8272\u7684\u80fd\u6e90\u6027\u80fd\u3002", "conclusion": "hdgc \u4e3a\u4f20\u5bfc\u56fe\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u65b0\u8def\u5f84\uff0c\u663e\u8457\u63d0\u5347\u901f\u5ea6\u4e14\u5177\u5907\u6f5c\u5728\u7684\u80fd\u6e90\u4f18\u52bf\uff0c\u9002\u5408\u5728\u672a\u6765\u7684\u795e\u7ecf\u5f62\u6001\u548c\u8fc7\u7a0b\u5185\u5b58\u8bbe\u5907\u4e0a\u5b9e\u73b0\u3002"}}
{"id": "2510.23986", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.23986", "abs": "https://arxiv.org/abs/2510.23986", "authors": ["Hong Wang", "Jiang Yixuan", "Jie Wang", "Xinyi Li", "Jian Luo", "Huanshuo Dong"], "title": "STNet: Spectral Transformation Network for Solving Operator Eigenvalue Problem", "comment": null, "summary": "Operator eigenvalue problems play a critical role in various scientific\nfields and engineering applications, yet numerical methods are hindered by the\ncurse of dimensionality. Recent deep learning methods provide an efficient\napproach to address this challenge by iteratively updating neural networks.\nThese methods' performance relies heavily on the spectral distribution of the\ngiven operator: larger gaps between the operator's eigenvalues will improve\nprecision, thus tailored spectral transformations that leverage the spectral\ndistribution can enhance their performance. Based on this observation, we\npropose the Spectral Transformation Network (STNet). During each iteration,\nSTNet uses approximate eigenvalues and eigenfunctions to perform spectral\ntransformations on the original operator, turning it into an equivalent but\neasier problem. Specifically, we employ deflation projection to exclude the\nsubspace corresponding to already solved eigenfunctions, thereby reducing the\nsearch space and avoiding converging to existing eigenfunctions. Additionally,\nour filter transform magnifies eigenvalues in the desired region and suppresses\nthose outside, further improving performance. Extensive experiments demonstrate\nthat STNet consistently outperforms existing learning-based methods, achieving\nstate-of-the-art performance in accuracy.", "AI": {"tldr": "\u63d0\u51fa Spectral Transformation Network (STNet)\uff0c\u901a\u8fc7\u8c31\u53d8\u6362\u4e0e\u6d88\u53bb\u6295\u5f71\u63d0\u5347\u6df1\u5ea6\u5b66\u4e60\u6c42\u89e3\u7b97\u5b50\u7279\u5f81\u503c\u95ee\u9898\u7684\u7cbe\u5ea6\u4e0e\u6548\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u9ad8\u7ef4\u7b97\u5b50\u7279\u5f81\u503c\u95ee\u9898\u53d7\u7ef4\u5ea6\u707e\u96be\u5f71\u54cd\uff0c\u7279\u5f81\u503c\u5206\u5e03\u5bf9\u5b66\u4e60\u65b9\u6cd5\u7684\u6536\u655b\u4e0e\u51c6\u786e\u6027\u5f71\u54cd\u663e\u8457\uff0c\u56e0\u6b64\u9700\u8981\u5229\u7528\u8c31\u4fe1\u606f\u7684\u53d8\u6362\u6765\u7b80\u5316\u95ee\u9898\u3002", "method": "\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\uff0cSTNet \u4f7f\u7528\u8fd1\u4f3c\u7684\u7279\u5f81\u503c\u4e0e\u7279\u5f81\u5411\u91cf\u5bf9\u7b97\u5b50\u8fdb\u884c\u8c31\u53d8\u6362\uff0c\u5c06\u539f\u95ee\u9898\u8f6c\u5316\u4e3a\u7b49\u4ef7\u7684\u3001\u6c42\u89e3\u66f4\u6613\u7684\u5f62\u5f0f\u3002\u5177\u4f53\u5305\u62ec\uff1a1\uff09deflation \u6295\u5f71\u53bb\u9664\u5df2\u6c42\u89e3\u7279\u5f81\u5b50\u7a7a\u95f4\uff0c\u51cf\u5c11\u641c\u7d22\u7a7a\u95f4\u5e76\u907f\u514d\u6536\u655b\u5230\u5df2\u77e5\u7279\u5f81\u5411\u91cf\uff1b2\uff09\u6ee4\u6ce2\u53d8\u6362\u653e\u5927\u76ee\u6807\u533a\u57df\u7684\u7279\u5f81\u503c\u3001\u6291\u5236\u5176\u4ed6\u533a\u57df\uff0c\u4ee5\u63d0\u5347\u6c42\u89e3\u6027\u80fd\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e STNet \u5728\u51c6\u786e\u6027\u65b9\u9762\u6301\u7eed\u8d85\u8d8a\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\uff0c\u8fbe\u5230\u5f53\u524d\u7684\u72b6\u6001-\u827a\u672f\u6c34\u5e73\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408 deflation \u6295\u5f71\u4e0e\u8c31\u53d8\u6362\u6ee4\u6ce2\uff0cSTNet \u6709\u6548\u7f13\u89e3\u7ef4\u5ea6\u707e\u96be\uff0c\u63d0\u5347\u7b97\u5b50\u7279\u5f81\u503c\u95ee\u9898\u7684\u6c42\u89e3\u6027\u80fd\uff0c\u6210\u4e3a\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e2d\u6c42\u89e3\u6b64\u7c7b\u95ee\u9898\u7684\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2510.23994", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23994", "abs": "https://arxiv.org/abs/2510.23994", "authors": ["Geoffery Agorku", "Sarah Hernandez", "Hayley Hames", "Cade Wagner"], "title": "Predicting Barge Tow Size on Inland Waterways Using Vessel Trajectory Derived Features: Proof of Concept", "comment": null, "summary": "Accurate, real-time estimation of barge quantity on inland waterways remains\na critical challenge due to the non-self-propelled nature of barges and the\nlimitations of existing monitoring systems. This study introduces a novel\nmethod to use Automatic Identification System (AIS) vessel tracking data to\npredict the number of barges in tow using Machine Learning (ML). To train and\ntest the model, barge instances were manually annotated from satellite scenes\nacross the Lower Mississippi River. Labeled images were matched to AIS vessel\ntracks using a spatiotemporal matching procedure. A comprehensive set of 30\nAIS-derived features capturing vessel geometry, dynamic movement, and\ntrajectory patterns were created and evaluated using Recursive Feature\nElimination (RFE) to identify the most predictive variables. Six regression\nmodels, including ensemble, kernel-based, and generalized linear approaches,\nwere trained and evaluated. The Poisson Regressor model yielded the best\nperformance, achieving a Mean Absolute Error (MAE) of 1.92 barges using 12 of\nthe 30 features. The feature importance analysis revealed that metrics\ncapturing vessel maneuverability such as course entropy, speed variability and\ntrip length were most predictive of barge count. The proposed approach provides\na scalable, readily implementable method for enhancing Maritime Domain\nAwareness (MDA), with strong potential applications in lock scheduling, port\nmanagement, and freight planning. Future work will expand the proof of concept\npresented here to explore model transferability to other inland rivers with\ndiffering operational and environmental conditions.", "AI": {"tldr": "\u901a\u8fc7 AIS \u822a\u8ff9\u6570\u636e\u9884\u6d4b\u5185\u9646\u6c34\u9053\u62d6\u5e26\u6570\u91cf\u7684\u65b0\u65b9\u6cd5\uff1a\u4ee5 30 \u4e2a AIS \u7279\u5f81\u4e3a\u8f93\u5165\uff0c\u4f7f\u7528\u7279\u5f81\u9009\u62e9\u548c\u591a\u79cd\u56de\u5f52\u6a21\u578b\uff0cPoisson \u56de\u5f52\u5668\u4ee5 MAE=1.92 \u7684\u6700\u4f73\u8868\u73b0\uff1b\u5728\u4e0b\u5bc6\u897f\u897f\u6bd4\u6cb3\u8fdb\u884c\u6807\u6ce8\u6570\u636e\u7684\u65f6\u7a7a\u5339\u914d\u8bad\u7ec3\u4e0e\u8bc4\u4f30\uff0c\u7ed3\u679c\u5bf9\u6e2f\u53e3\u7ba1\u7406\u4e0e\u6c34\u8def\u4ea4\u901a\u76d1\u63a7\u5177\u6709\u6f5c\u5728\u5e94\u7528\uff0c\u5e76\u8ba1\u5212\u6269\u5c55\u5230\u5176\u4ed6\u6cb3\u9053\u3002", "motivation": "\u89e3\u51b3\u5185\u9646\u6c34\u9053\u62d6\u5e26\u6570\u91cf\u7684\u5b9e\u65f6\u4f30\u7b97\u96be\u9898\u3002\u62d6\u8239\u975e\u81ea\u63a8\u8fdb\u6027\u4ee5\u53ca\u73b0\u6709\u76d1\u6d4b\u7cfb\u7edf\u7684\u5c40\u9650\u6027\u5bfc\u81f4\u96be\u4ee5\u51c6\u786e\u5feb\u901f\u5730\u4f30\u8ba1\u62d6\u5e26\u6570\u91cf\uff0c\u4ece\u800c\u5f71\u54cd\u822a\u9053\u7ba1\u7406\u4e0e\u7269\u6d41\u4f18\u5316\u3002", "method": "\u57fa\u4e8e AIS \u8f66\u8f86\u8ddf\u8e2a\u6570\u636e\uff0c\u901a\u8fc7\u65f6\u7a7a\u5339\u914d\u5c06\u536b\u661f\u573a\u666f\u4e2d\u7684\u4eba\u5de5\u6807\u6ce8\u62d6\u5e26\u5b9e\u4f8b\u4e0e AIS \u822a\u8ff9\u5339\u914d\uff0c\u6784\u5efa 30 \u4e2a AIS \u6d3e\u751f\u7279\u5f81\uff08\u8986\u76d6 Vessel \u51e0\u4f55\u3001\u52a8\u529b\u5b66\u4e0e\u8f68\u8ff9\u6a21\u5f0f\uff09\u3002\u4f7f\u7528\u9012\u63a8\u7279\u5f81\u6d88\u9664 (RFE) \u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u7b5b\u9009\u51fa\u6700\u5177\u9884\u6d4b\u529b\u7684 12 \u9879\u7279\u5f81\u3002\u8bad\u7ec3\u5e76\u8bc4\u4f30\u516d\u79cd\u56de\u5f52\u6a21\u578b\uff08\u5305\u62ec\u96c6\u6210\u3001\u6838\u65b9\u6cd5\u548c\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\uff09\uff0c\u5e76\u6bd4\u8f83\u5176\u6027\u80fd\u3002", "result": "Poisson \u56de\u5f52\u5668\u5728\u6d4b\u8bd5\u96c6\u4e0a\u83b7\u5f97\u6700\u4f73\u6027\u80fd\uff0cMAE=1.92 \u67b6\u62d6\u5e26\uff0c\u4f7f\u7528 12 \u9879\u7279\u5f81\u3002\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u663e\u793a\u822a\u5411\u71b5\u3001\u901f\u5ea6\u53d8\u5f02\u6027\u4e0e\u822a\u6bb5\u957f\u5ea6\u7b49\u4e0e\u62d6\u5e26\u6570\u91cf\u9ad8\u5ea6\u76f8\u5173\u3002\u8be5\u65b9\u6cd5\u5177\u5907\u53ef\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u6d77\u4e8b\u9886\u57df\u6001\u52bf\u611f\u77e5\uff0c\u4e14\u5177\u6709\u5728\u9501\u8c03\u5ea6\u3001\u6e2f\u53e3\u7ba1\u7406\u4e0e\u8d27\u8fd0\u89c4\u5212\u7b49\u573a\u666f\u7684\u6f5c\u5728\u5e94\u7528\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u53ef\u843d\u5730\u7684\u57fa\u4e8e AIS \u6570\u636e\u7684\u62d6\u5e26\u6570\u91cf\u4f30\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u4e0e\u591a\u6a21\u578b\u6bd4\u8f83\u5b9e\u73b0\u9884\u6d4b\u51c6\u786e\u6027\u63d0\u5347\uff1b\u672a\u6765\u5de5\u4f5c\u62df\u5c06\u6982\u5ff5\u9a8c\u8bc1\u62d3\u5c55\u81f3\u4e0d\u540c\u6c34\u8def\u73af\u5883\uff0c\u4ee5\u8bc4\u4f30\u6a21\u578b\u7684\u8fc1\u79fb\u80fd\u529b\u4e0e\u5728\u4e0d\u540c\u64cd\u4f5c\u4e0e\u73af\u5883\u6761\u4ef6\u4e0b\u7684\u6cdb\u5316\u6027\u3002"}}
{"id": "2510.24012", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24012", "abs": "https://arxiv.org/abs/2510.24012", "authors": ["Byeonghu Na", "Mina Kang", "Jiseok Kwak", "Minsang Park", "Jiwoo Shin", "SeJoon Jun", "Gayoung Lee", "Jin-Hwa Kim", "Il-Chul Moon"], "title": "Training-Free Safe Text Embedding Guidance for Text-to-Image Diffusion Models", "comment": "Accepted at NeurIPS 2025", "summary": "Text-to-image models have recently made significant advances in generating\nrealistic and semantically coherent images, driven by advanced diffusion models\nand large-scale web-crawled datasets. However, these datasets often contain\ninappropriate or biased content, raising concerns about the generation of\nharmful outputs when provided with malicious text prompts. We propose Safe Text\nembedding Guidance (STG), a training-free approach to improve the safety of\ndiffusion models by guiding the text embeddings during sampling. STG adjusts\nthe text embeddings based on a safety function evaluated on the expected final\ndenoised image, allowing the model to generate safer outputs without additional\ntraining. Theoretically, we show that STG aligns the underlying model\ndistribution with safety constraints, thereby achieving safer outputs while\nminimally affecting generation quality. Experiments on various safety\nscenarios, including nudity, violence, and artist-style removal, show that STG\nconsistently outperforms both training-based and training-free baselines in\nremoving unsafe content while preserving the core semantic intent of input\nprompts. Our code is available at https://github.com/aailab-kaist/STG.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8bad\u7ec3\u65e0\u5173\u7684\u5b89\u5168\u5f15\u5bfc\u65b9\u6cd5 STG\uff0c\u5728\u6269\u6563\u6a21\u578b\u91c7\u6837\u9636\u6bb5\u8c03\u6574\u6587\u672c\u5d4c\u5165\u4ee5\u9075\u5faa\u5b89\u5168\u7ea6\u675f\uff0c\u4ece\u800c\u53bb\u9664\u4e0d\u5b89\u5168\u5185\u5bb9\u5e76\u5c3d\u91cf\u4fdd\u7559\u539f\u59cb\u8bed\u4e49\u3002", "motivation": "\u5927\u89c4\u6a21\u7f51\u9875\u6293\u53d6\u7684\u6570\u636e\u5f80\u5f80\u5305\u542b\u4e0d\u5f53\u3001\u504f\u89c1\u6216\u6709\u5bb3\u5185\u5bb9\uff0c\u5728\u9762\u5bf9\u6076\u610f\u6587\u672c\u63d0\u793a\u65f6\uff0c\u73b0\u6709\u6a21\u578b\u53ef\u80fd\u8f93\u51fa\u6709\u5bb3\u5185\u5bb9\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u989d\u5916\u8bad\u7ec3\u7684\u5b89\u5168\u63d0\u5347\u65b9\u6cd5\u3002", "method": "\u5728\u91c7\u6837\u8fc7\u7a0b\u4e2d\u57fa\u4e8e\u4e00\u4e2a\u5bf9\u6700\u7ec8\u53bb\u566a\u56fe\u50cf\u7684\u5b89\u5168\u8bc4\u4f30\u51fd\u6570\uff0c\u52a8\u6001\u8c03\u6574\u6587\u672c\u5d4c\u5165\u4ee5\u5f15\u5bfc\u6a21\u578b\u6ee1\u8db3\u5b89\u5168\u7ea6\u675f\uff1b\u8be5\u8bad\u7ec3\u8fc7\u7a0b\u53ef\u4ee5\u89c6\u4e3a\u5bf9\u6a21\u578b\u5206\u5e03\u7684\u5b89\u5168\u7ea6\u675f\u5bf9\u9f50\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "result": "\u5728\u88f8\u4f53\u3001\u66b4\u529b\u3001\u827a\u672f\u98ce\u683c\u5220\u9664\u7b49\u591a\u79cd\u5b89\u5168\u573a\u666f\u4e2d\uff0cSTG\u6301\u7eed\u4f18\u4e8e\u8bad\u7ec3\u578b\u548c\u8bad\u7ec3-free\u57fa\u7ebf\uff0c\u80fd\u591f\u53bb\u9664\u4e0d\u5b89\u5168\u5185\u5bb9\u540c\u65f6\u5c3d\u91cf\u4fdd\u7559\u8f93\u5165\u7684\u8bed\u4e49\u610f\u56fe\u3002", "conclusion": "STG\u901a\u8fc7\u8bad\u7ec3\u65e0\u5173\u7684\u5d4c\u5165\u5f15\u5bfc\u5b9e\u73b0\u5b89\u5168\u6027\u63d0\u5347\uff0c\u7406\u8bba\u4e0a\u4e0e\u5b89\u5168\u7ea6\u675f\u7684\u5206\u5e03\u5bf9\u9f50\uff0c\u4e14\u5bf9\u751f\u6210\u8d28\u91cf\u5f71\u54cd\u6700\u5c0f\uff0c\u5177\u5907\u63d0\u5347\u5927\u89c4\u6a21\u6587\u672c-\u56fe\u50cf\u751f\u6210\u7cfb\u7edf\u5b89\u5168\u6027\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.24027", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24027", "abs": "https://arxiv.org/abs/2510.24027", "authors": ["Zibo Liu", "Zhe Jiang", "Zelin Xu", "Tingsong Xiao", "Yupu Zhang", "Zhengkun Xiao", "Haibo Wang", "Shigang Chen"], "title": "Spatio-temporal Multivariate Time Series Forecast with Chosen Variables", "comment": "In submission", "summary": "Spatio-Temporal Multivariate time series Forecast (STMF) uses the time series\nof $n$ spatially distributed variables in a period of recent past to forecast\ntheir values in a period of near future. It has important applications in\nspatio-temporal sensing forecast such as road traffic prediction and air\npollution prediction. Recent papers have addressed a practical problem of\nmissing variables in the model input, which arises in the sensing applications\nwhere the number $m$ of sensors is far less than the number $n$ of locations to\nbe monitored, due to budget constraints. We observe that the state of the art\nassumes that the $m$ variables (i.e., locations with sensors) in the model\ninput are pre-determined and the important problem of how to choose the $m$\nvariables in the input has never been studied. This paper fills the gap by\nstudying a new problem of STMF with chosen variables, which optimally selects\n$m$-out-of-$n$ variables for the model input in order to maximize the forecast\naccuracy. We propose a unified framework that jointly performs variable\nselection and model optimization for both forecast accuracy and model\nefficiency. It consists of three novel technical components: (1) masked\nvariable-parameter pruning, which progressively prunes less informative\nvariables and attention parameters through quantile-based masking; (2)\nprioritized variable-parameter replay, which replays low-loss past samples to\npreserve learned knowledge for model stability; (3) dynamic extrapolation\nmechanism, which propagates information from variables selected for the input\nto all other variables via learnable spatial embeddings and adjacency\ninformation. Experiments on five real-world datasets show that our work\nsignificantly outperforms the state-of-the-art baselines in both accuracy and\nefficiency, demonstrating the effectiveness of joint variable selection and\nmodel optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5728\u65f6\u7a7a\u591a\u53d8\u91cf\u9884\u6d4b\uff08STMF\uff09\u4e2d\u8fdb\u884cm-out-of-n\u53d8\u91cf\u9009\u62e9\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u63a9\u853d\u526a\u679d\u3001\u4f18\u5148\u7ea7\u56de\u653e\u548c\u52a8\u6001\u5916\u63a8\u5b9e\u73b0\u9884\u6d4b\u51c6\u786e\u6027\u4e0e\u6548\u7387\u7684\u517c\u987e\uff0c\u5728\u4e94\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u5b9e\u4f20\u611f\u573a\u666f\u4e2d\u53ef\u7528\u4f20\u611f\u5668\u6570\u91cf\u6709\u9650\uff0c\u9700\u8981\u4ecen\u4e2a\u89c2\u6d4b\u4f4d\u7f6e\u4e2d\u9009\u53d6m\u4e2a\u4f5c\u4e3a\u8f93\u5165\u53d8\u91cf\u4ee5\u6700\u5927\u5316\u9884\u6d4b\u51c6\u786e\u6027\uff1b\u73b0\u6709\u5de5\u4f5c\u5047\u8bbe\u8f93\u5165\u53d8\u91cf\u5df2\u5b9a\uff0c\u7f3a\u4e4f\u5bf9\u5982\u4f55\u9009\u62e9\u8f93\u5165\u53d8\u91cf\u7684\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e09\u5927\u6280\u672f\u7ec4\u4ef6\u5e76\u884c/\u534f\u540c\u5b9e\u73b0\uff1a1) \u63a9\u853d\u53d8\u91cf-\u53c2\u6570\u526a\u679d\uff0c\u901a\u8fc7\u57fa\u4e8e\u5206\u4f4d\u6570\u7684\u63a9\u853d\u9010\u6b65\u88c1\u526a\u4e0d\u4fe1\u606f\u53d8\u91cf\u4e0e\u6ce8\u610f\u529b\u53c2\u6570\uff1b2) \u4f18\u5148\u7ea7\u53d8\u91cf-\u53c2\u6570\u56de\u653e\uff0c\u56de\u653e\u4f4e\u635f\u5931\u7684\u5386\u53f2\u6837\u672c\u4ee5\u7ef4\u6301\u8bad\u7ec3\u7a33\u5b9a\u6027\u5e76\u4fdd\u7559\u77e5\u8bc6\uff1b3) \u52a8\u6001\u5916\u63a8\u673a\u5236\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u7a7a\u95f4\u5d4c\u5165\u4e0e\u90bb\u63a5\u4fe1\u606f\u5c06\u9009\u62e9\u8f93\u5165\u53d8\u91cf\u7684\u4fe1\u606f\u4f20\u64ad\u7ed9\u6240\u6709\u53d8\u91cf\uff0c\u5f62\u6210\u5168\u5c40\u4fe1\u606f\u4f20\u64ad\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u6a21\u578b\u6548\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u8bc1\u660e\u4e86\u53d8\u91cf\u9009\u62e9\u4e0e\u6a21\u578b\u4f18\u5316\u7684\u8054\u5408\u6709\u6548\u6027\u3002", "conclusion": "\u8054\u5408\u53d8\u91cf\u9009\u62e9\u4e0e\u6a21\u578b\u4f18\u5316\u53ef\u4ee5\u63d0\u5347STMF\u5728\u73b0\u5b9e\u4f20\u611f\u5e94\u7528\u4e2d\u7684\u9884\u6d4b\u6027\u80fd\u4e0e\u8d44\u6e90\u5229\u7528\u7387\u3002\u8be5\u6846\u67b6\u4e3a\u5904\u7406\u4f20\u611f\u6570\u636e\u7f3a\u5931\u4e0e\u9884\u7b97\u7ea6\u675f\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u8def\u5f84\uff0c\u672a\u6765\u5de5\u4f5c\u53ef\u6269\u5c55\u5230\u66f4\u5927\u89c4\u6a21\u573a\u666f\u3001\u5206\u6790\u9c81\u68d2\u6027\u4e0e\u81ea\u9002\u5e94\u6027\u7b49\u3002"}}
{"id": "2510.24035", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24035", "abs": "https://arxiv.org/abs/2510.24035", "authors": ["Xinqi Li", "Yiqun Liu", "Shan Jiang", "Enrong Zheng", "Huaijin Zheng", "Wenhao Dai", "Haodong Deng", "Dianhai Yu", "Yanjun Ma"], "title": "GraphNet: A Large-Scale Computational Graph Dataset for Tensor Compiler Research", "comment": null, "summary": "We introduce GraphNet, a dataset of 2.7K real-world deep learning\ncomputational graphs with rich metadata, spanning six major task categories\nacross multiple deep learning frameworks. To evaluate tensor compiler\nperformance on these samples, we propose the benchmark metric Speedup Score\nS(t), which jointly considers runtime speedup and execution correctness under\ntunable tolerance levels, offering a reliable measure of general optimization\ncapability. Furthermore, we extend S(t) to the Error-aware Speedup Score ES(t),\nwhich incorporates error information and helps compiler developers identify key\nperformance bottlenecks. In this report, we benchmark the default tensor\ncompilers, CINN for PaddlePaddle and TorchInductor for PyTorch, on computer\nvision (CV) and natural language processing (NLP) samples to demonstrate the\npracticality of GraphNet. The full construction pipeline with graph extraction\nand compiler evaluation tools is available at\nhttps://github.com/PaddlePaddle/GraphNet .", "AI": {"tldr": "GraphNet \u662f\u4e00\u4e2a\u5305\u542b 2700 \u4f59\u4e2a\u73b0\u5b9e\u4e16\u754c\u6df1\u5ea6\u5b66\u4e60\u8ba1\u7b97\u56fe\u53ca\u4e30\u5bcc\u5143\u6570\u636e\u7684\u6570\u636e\u96c6\uff0c\u8986\u76d6\u516d\u5927\u4efb\u52a1\u7c7b\u522b\u548c\u591a\u79cd\u6846\u67b6\u3002\u63d0\u51fa\u4e86\u57fa\u51c6\u5ea6\u91cf Speedup Score S(t)\uff0c\u7ed3\u5408\u8fd0\u884c\u65f6\u52a0\u901f\u4e0e\u5bb9\u9519\u6027\uff08\u53ef\u8c03\u5bb9\u5fcd\u5ea6\uff09\u6765\u8bc4\u4f30\u5f20\u91cf\u7f16\u8bd1\u5668\u6027\u80fd\uff0c\u5e76\u6269\u5c55\u51fa\u8003\u8651\u9519\u8bef\u4fe1\u606f\u7684 ES(t) \u4ee5\u5e2e\u52a9\u5b9a\u4f4d\u74f6\u9888\u3002\u57fa\u4e8e CV \u4e0e NLP \u4efb\u52a1\u5bf9\u9ed8\u8ba4\u7f16\u8bd1\u5668 CINN\uff08PaddlePaddle\uff09\u4e0e TorchInductor\uff08PyTorch\uff09\u8fdb\u884c\u5b9e\u8bc1\uff0c\u8bc1\u660e GraphNet \u7684\u5b9e\u7528\u6027\u3002\u5b8c\u6574\u6784\u5efa\u548c\u8bc4\u4f30\u7ba1\u7ebf\u53ef\u5728 GitHub \u83b7\u53d6\u3002", "motivation": "\u5728\u4e0d\u540c\u5f20\u91cf\u7f16\u8bd1\u5668\u4f18\u5316\u4e4b\u95f4\u7f3a\u4e4f\u4e00\u4e2a\u7edf\u4e00\u3001\u53ef\u9760\u7684\u6bd4\u8f83\u6807\u51c6\uff0c\u9700\u540c\u65f6\u8003\u8651\u8fd0\u884c\u65f6\u901f\u5ea6\u4e0e\u6267\u884c\u6b63\u786e\u6027\uff0c\u5e76\u80fd\u5728\u4e0d\u540c\u5bb9\u5fcd\u5ea6\u4e0b\u8bc6\u522b\u6f5c\u5728\u74f6\u9888\uff1b\u540c\u65f6\u9700\u8981\u4e00\u4e2a\u8986\u76d6\u771f\u5b9e\u4e16\u754c\u8ba1\u7b97\u56fe\u7684\u57fa\u51c6\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u8de8\u6846\u67b6\u7684\u5e7f\u6cdb\u6027\u3002", "method": "\u6784\u5efa GraphNet \u6570\u636e\u96c6\uff08\u7ea6 2.7K \u4e2a\u771f\u5b9e\u4e16\u754c\u6df1\u5ea6\u5b66\u4e60\u8ba1\u7b97\u56fe\uff0c\u8986\u76d6\u516d\u5927\u4efb\u52a1\u7c7b\u522b\uff0c\u8de8\u591a\u4e2a\u6846\u67b6\uff09\uff0c\u63d0\u51fa\u5e76\u5b9a\u4e49\u57fa\u51c6\u5ea6\u91cf Speedup Score S(t)\uff0c\u5c06\u8fd0\u884c\u65f6\u901f\u5ea6\u4e0e\u6b63\u786e\u6027\u5728\u53ef\u8c03\u5bb9\u5fcd\u5ea6\u4e0b\u8026\u5408\uff1b\u6269\u5c55\u51fa\u9519\u8bef\u611f\u77e5\u7684 ES(t) \u503c\u4ee5\u6355\u6349\u9519\u8bef\u4fe1\u606f\u5e76\u8f85\u52a9\u5b9a\u4f4d\u74f6\u9888\u3002\u5bf9\u9ed8\u8ba4\u7f16\u8bd1\u5668 CINN\uff08PaddlePaddle\uff09\u4e0e TorchInductor\uff08PyTorch\uff09\u5728 CV \u4e0e NLP \u6837\u672c\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u9a8c\u8bc1\u8be5\u6570\u636e\u96c6\u548c\u8bc4\u4ef7\u6307\u6807\u7684\u53ef\u884c\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e S(t) \u4e0e ES(t) \u80fd\u5728\u4e0d\u540c\u5bb9\u5fcd\u5ea6\u8bbe\u7f6e\u4e0b\u7a33\u5b9a\u53cd\u6620\u7f16\u8bd1\u5668\u7684\u6027\u80fd\u6539\u8fdb\u4e0e\u6f5c\u5728\u74f6\u9888\uff1b\u5bf9 CV \u4e0e NLP \u4efb\u52a1\u7684\u6837\u672c\u7ed9\u51fa\u4e86\u4e00\u7ec4\u53ef\u6bd4\u7684\u57fa\u7ebf\u8868\u73b0\uff0c\u8bc1\u660e GraphNet \u5728\u5b9e\u9645\u4f18\u5316\u573a\u666f\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u533a\u5206\u529b\u3002", "conclusion": "GraphNet \u63d0\u4f9b\u4e86\u4e00\u4e2a\u8986\u76d6\u5e7f\u6cdb\u3001\u53ef\u91cd\u590d\u7684\u73b0\u5b9e\u4e16\u754c deep learning \u8ba1\u7b97\u56fe\u57fa\u51c6\u53ca\u91cf\u5316\u6846\u67b6\uff0c\u7ed3\u5408 S(t) \u4e0e ES(t) \u80fd\u5e2e\u52a9\u7f16\u8bd1\u5668\u5f00\u53d1\u8005\u66f4\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e0e\u5b9a\u4f4d\u6027\u80fd\u74f6\u9888\uff0c\u5e76\u4fc3\u8fdb\u5728\u8de8\u6846\u67b6\u3001\u8de8\u4efb\u52a1\u7684\u6bd4\u8f83\u7814\u7a76\u3002\u5b8c\u6574\u7684\u6784\u5efa\u4e0e\u8bc4\u6d4b\u5de5\u5177\u94fe\u5bf9\u5916\u53ef\u83b7\u53d6\u3002"}}
{"id": "2510.24039", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24039", "abs": "https://arxiv.org/abs/2510.24039", "authors": ["Nikolaos Karalias", "Akbar Rafiey", "Yifei Xu", "Zhishang Luo", "Behrooz Tahmasebi", "Connie Jiang", "Stefanie Jegelka"], "title": "Geometric Algorithms for Neural Combinatorial Optimization with Constraints", "comment": null, "summary": "Self-Supervised Learning (SSL) for Combinatorial Optimization (CO) is an\nemerging paradigm for solving combinatorial problems using neural networks. In\nthis paper, we address a central challenge of SSL for CO: solving problems with\ndiscrete constraints. We design an end-to-end differentiable framework that\nenables us to solve discrete constrained optimization problems with neural\nnetworks. Concretely, we leverage algorithmic techniques from the literature on\nconvex geometry and Carath\\'eodory's theorem to decompose neural network\noutputs into convex combinations of polytope corners that correspond to\nfeasible sets. This decomposition-based approach enables self-supervised\ntraining but also ensures efficient quality-preserving rounding of the neural\nnet output into feasible solutions. Extensive experiments in\ncardinality-constrained optimization show that our approach can consistently\noutperform neural baselines. We further provide worked-out examples of how our\nmethod can be applied beyond cardinality-constrained problems to a diverse set\nof combinatorial optimization tasks, including finding independent sets in\ngraphs, and solving matroid-constrained problems.", "AI": {"tldr": "A differentiable self-supervised framework for solving discrete-constrained combinatorial optimization (CO) problems by decomposing neural outputs into convex combinations of polytope corners that represent feasible solutions, enabling efficient rounding and strong empirical performance.", "motivation": "SSL for CO struggles with discrete constraints; a method that integrates discrete feasibility into end-to-end differentiable learning is needed to leverage neural networks for CO tasks.", "method": "Use convex geometry and Carath\u00e9odory's theorem to decompose neural network outputs into convex combinations of a small set of polytope corners (feasible corners). This yields a differentiable training signal via self-supervision and guarantees a quality-preserving rounding to feasible discrete solutions.", "result": "On cardinality-constrained optimization, the approach consistently outperforms neural baselines. The paper also demonstrates applicability beyond cardinality constraints, to problems such as finding independent sets in graphs and matroid-constrained optimization.", "conclusion": "The framework provides a general, end-to-end differentiable method to handle discrete constraints in CO tasks by embedding feasibility via convex decompositions, enabling effective self-supervised learning and robust rounding across a range of combinatorial problems."}}
{"id": "2510.24043", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24043", "abs": "https://arxiv.org/abs/2510.24043", "authors": ["Akira Tamamori"], "title": "Localized Kernel Projection Outlyingness: A Two-Stage Approach for Multi-Modal Outlier Detection", "comment": "10 pages, 4 figures; submitted to The IEICE Transactions on\n  Information and Systems", "summary": "This paper presents Two-Stage LKPLO, a novel multi-stage outlier detection\nframework that overcomes the coexisting limitations of conventional\nprojection-based methods: their reliance on a fixed statistical metric and\ntheir assumption of a single data structure. Our framework uniquely synthesizes\nthree key concepts: (1) a generalized loss-based outlyingness measure (PLO)\nthat replaces the fixed metric with flexible, adaptive loss functions like our\nproposed SVM-like loss; (2) a global kernel PCA stage to linearize non-linear\ndata structures; and (3) a subsequent local clustering stage to handle\nmulti-modal distributions. Comprehensive 5-fold cross-validation experiments on\n10 benchmark datasets, with automated hyperparameter optimization, demonstrate\nthat Two-Stage LKPLO achieves state-of-the-art performance. It significantly\noutperforms strong baselines on datasets with challenging structures where\nexisting methods fail, most notably on multi-cluster data (Optdigits) and\ncomplex, high-dimensional data (Arrhythmia). Furthermore, an ablation study\nempirically confirms that the synergistic combination of both the kernelization\nand localization stages is indispensable for its superior performance. This\nwork contributes a powerful new tool for a significant class of outlier\ndetection problems and underscores the importance of hybrid, multi-stage\narchitectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u7684 LKPLO \u6846\u67b6\uff0c\u7528\u4e8e\u591a\u9636\u6bb5\u5f02\u5e38\u68c0\u6d4b\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u635f\u5931\u3001\u5168\u5c40\u6838 PCA \u4ee5\u53ca\u5c40\u90e8\u805a\u7c7b\uff0c\u8fbe\u5230\u5728\u591a\u7c07\u548c\u9ad8\u7ef4\u6570\u636e\u4e0a\u7684 SOTA \u6027\u80fd\u3002", "motivation": "\u514b\u670d\u4f20\u7edf\u6295\u5f71\u6cd5\u5bf9\u56fa\u5b9a\u5ea6\u91cf\u548c\u5355\u4e00\u6570\u636e\u7ed3\u6784\u7684\u4f9d\u8d56\uff0c\u9700\u5f15\u5165\u7075\u6d3b\u7684\u635f\u5931\u3001\u975e\u7ebf\u6027\u5316\u548c\u591a\u6a21\u6001\u7ed3\u6784\u5904\u7406\u3002", "method": "\u5f15\u5165 PLO \u4f5c\u4e3a\u53ef\u81ea\u9002\u5e94\u7684\u5f02\u5e38\u6027\u5ea6\u91cf\uff1b\u901a\u8fc7\u5168\u5c40\u6838 PCA \u5b9e\u73b0\u6570\u636e\u7ed3\u6784\u7684\u7ebf\u6027\u5316\uff1b\u968f\u540e\u8fdb\u884c\u5c40\u90e8\u805a\u7c7b\u4ee5\u5904\u7406\u591a\u5cf0\u5206\u5e03\u3002\u91c7\u7528 5 \u6298\u4ea4\u53c9\u9a8c\u8bc1\u548c\u81ea\u52a8\u8d85\u53c2\u4f18\u5316\u3002", "result": "\u5728 10 \u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0 SOTA\uff0c\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5c24\u5176\u5728 Optdigits\uff08\u591a\u7c07\u6570\u636e\uff09\u548c Arrhythmia\uff08\u9ad8\u7ef4\u6570\u636e\uff09\u3002\u6d88\u878d\u5206\u6790\u8bc1\u5b9e\u6838\u5316\u4e0e\u5c40\u90e8\u5316\u7684\u534f\u540c\u662f\u5fc5\u9700\u7684\u3002", "conclusion": "\u591a\u9636\u6bb5\u6df7\u5408\u67b6\u6784\u5bf9\u5f02\u5e38\u68c0\u6d4b\u5177\u6709\u5f3a\u5927\u6548\u80fd\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u65b0\u5de5\u5177\uff0c\u5f3a\u8c03\u6df7\u5408\u591a\u9636\u6bb5\u8bbe\u8ba1\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.24044", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24044", "abs": "https://arxiv.org/abs/2510.24044", "authors": ["Hui Sun", "Zheng Xie", "Hao-Yuan He", "Ming Li"], "title": "Mitigating Negative Transfer via Reducing Environmental Disagreement", "comment": "13 pages, 5 figures", "summary": "Unsupervised Domain Adaptation~(UDA) focuses on transferring knowledge from a\nlabeled source domain to an unlabeled target domain, addressing the challenge\nof \\emph{domain shift}. Significant domain shifts hinder effective knowledge\ntransfer, leading to \\emph{negative transfer} and deteriorating model\nperformance. Therefore, mitigating negative transfer is essential. This study\nrevisits negative transfer through the lens of causally disentangled learning,\nemphasizing cross-domain discriminative disagreement on non-causal\nenvironmental features as a critical factor. Our theoretical analysis reveals\nthat overreliance on non-causal environmental features as the environment\nevolves can cause discriminative disagreements~(termed \\emph{environmental\ndisagreement}), thereby resulting in negative transfer. To address this, we\npropose Reducing Environmental Disagreement~(RED), which disentangles each\nsample into domain-invariant causal features and domain-specific non-causal\nenvironmental features via adversarially training domain-specific environmental\nfeature extractors in the opposite domains. Subsequently, RED estimates and\nreduces environmental disagreement based on domain-specific non-causal\nenvironmental features. Experimental results confirm that RED effectively\nmitigates negative transfer and achieves state-of-the-art performance.", "AI": {"tldr": "\u63d0\u51faRED\uff0c\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u89e3\u8026\u7684\u65e0\u76d1\u7763\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6e90/\u76ee\u6807\u57df\u7684\u975e\u56e0\u679c\u73af\u5883\u7279\u5f81\u8fdb\u884c\u5bf9\u6297\u6027\u63d0\u53d6\u548c\u57df\u7279\u5f02\u6027\u5206\u6790\uff0c\u51cf\u5c11\u73af\u5883\u5206\u6b67\u4ee5\u7f13\u89e3\u8d1f\u8fc1\u79fb\uff0c\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u57df\u95f4\u5206\u5e03\u504f\u79fb\u5f15\u53d1\u7684\u8d1f\u8fc1\u79fb\u4e00\u76f4\u662fUDA\u4e2d\u7684\u6838\u5fc3\u6311\u6218\u3002\u5355\u7eaf\u4f9d\u8d56\u76f8\u5173\u7279\u5f81\u5bb9\u6613\u5728\u73af\u5883\u6f14\u5316\u65f6\u5931\u6548\uff0c\u56e0\u6b64\u9700\u8981\u901a\u8fc7\u56e0\u679c\u89e3\u8026\u63d0\u5347\u8de8\u57df\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faRED\uff1a\u5bf9\u6837\u672c\u8fdb\u884c\u56e0\u679c\u4e0d\u53d8\u91cf\u4e0e\u975e\u56e0\u679c\u73af\u5883\u7279\u5f81\u7684\u89e3\u8026\uff0c\u5c06\u57df\u7279\u5f02\u7684\u975e\u56e0\u679c\u73af\u5883\u7279\u5f81\u5728\u5bf9\u7acb\u57df\u8fdb\u884c\u5bf9\u6297\u6027\u63d0\u53d6\uff1b\u57fa\u4e8e\u57df\u7279\u5f02\u7684\u975e\u56e0\u679c\u73af\u5883\u7279\u5f81\u4f30\u8ba1\u5e76\u51cf\u5c11\u73af\u5883\u5206\u6b67\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRED\u663e\u8457\u7f13\u89e3\u8d1f\u8fc1\u79fb\u5e76\u8fbe\u5230\u6216\u63a5\u8fd1SOTA\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u73af\u5883\u5206\u6b67\u7684\u91cf\u5316\u4e0e\u63a7\u5236\uff0c\u57fa\u4e8e\u56e0\u679c\u89e3\u8026\u7684UDA\u5728\u73af\u5883\u6f14\u5316\u65f6\u66f4\u5177\u9c81\u68d2\u6027\uff0c\u80fd\u6709\u6548\u964d\u4f4e\u8d1f\u8fc1\u79fb\u3002"}}
{"id": "2510.24046", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24046", "abs": "https://arxiv.org/abs/2510.24046", "authors": ["Tu Anh Hoang Nguyen", "Dang Nguyen", "Tri-Nhan Vo", "Thuc Duy Le", "Sunil Gupta"], "title": "Causal-Aware Generative Adversarial Networks with Reinforcement Learning", "comment": null, "summary": "The utility of tabular data for tasks ranging from model training to\nlarge-scale data analysis is often constrained by privacy concerns or\nregulatory hurdles. While existing data generation methods, particularly those\nbased on Generative Adversarial Networks (GANs), have shown promise, they\nfrequently struggle with capturing complex causal relationship, maintaining\ndata utility, and providing provable privacy guarantees suitable for enterprise\ndeployment. We introduce CA-GAN, a novel generative framework specifically\nengineered to address these challenges for real-world tabular datasets. CA-GAN\nutilizes a two-step approach: causal graph extraction to learn a robust,\ncomprehensive causal relationship in the data's manifold, followed by a custom\nConditional WGAN-GP (Wasserstein GAN with Gradient Penalty) that operates\nexclusively as per the structure of nodes in the causal graph. More\nimportantly, the generator is trained with a new Reinforcement Learning-based\nobjective that aligns the causal graphs constructed from real and fake data,\nensuring the causal awareness in both training and sampling phases. We\ndemonstrate CA-GAN superiority over six SOTA methods across 14 tabular\ndatasets. Our evaluations, focused on core data engineering metrics: causal\npreservation, utility preservation, and privacy preservation. Our method offers\na practical, high-performance solution for data engineers seeking to create\nhigh-quality, privacy-compliant synthetic datasets to benchmark database\nsystems, accelerate software development, and facilitate secure data-driven\nresearch.", "AI": {"tldr": "CA-GAN \u662f\u4e00\u79cd\u9488\u5bf9\u8868\u683c\u6570\u636e\u7684\u56e0\u679c\u611f\u77e5\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u56fe\u63d0\u53d6\u7ed3\u5408\u6761\u4ef6WGAN-GP\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u76ee\u6807\u4ee5\u5bf9\u9f50\u771f\u5b9e\u4e0e\u4f2a\u9020\u6570\u636e\u7684\u56e0\u679c\u7ed3\u6784\uff0c\u572814\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e6\u79cdSOTA\u65b9\u6cd5\uff0c\u805a\u7126\u56e0\u679c\u4fdd\u771f\u3001\u6570\u636e\u5b9e\u7528\u6027\u548c\u9690\u79c1\u4fdd\u62a4\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u573a\u666f\u4e0b\u7684\u79c1\u6709\u4e14\u9ad8\u6548\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u3002", "motivation": "\u9690\u79c1\u4e0e\u5408\u89c4\u9650\u5236\u5f80\u5f80\u963b\u788d\u5bf9\u8868\u683c\u6570\u636e\u7684\u4f7f\u7528\uff1b\u73b0\u6709\u57fa\u4e8eGAN\u7684\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5728\u6355\u6349\u590d\u6742\u56e0\u679c\u5173\u7cfb\u3001\u7ef4\u6301\u6570\u636e\u5b9e\u7528\u6027\u4ee5\u53ca\u63d0\u4f9b\u53ef\u843d\u5730\u7684\u9690\u79c1\u4fdd\u8bc1\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u96be\u4ee5\u7528\u4e8e\u4f01\u4e1a\u90e8\u7f72\u3002", "method": "CA-GAN \u91c7\u7528\u4e24\u6b65\u7b56\u7565\uff1a\u7b2c\u4e00\u6b65\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u56e0\u679c\u56fe\uff0c\u5b66\u4e60\u6570\u636e\u6d41\u5f62\u4e2d\u7684\u7a33\u5065\u548c\u5168\u9762\u7684\u56e0\u679c\u5173\u7cfb\uff1b\u7b2c\u4e8c\u6b65\u5728\u56e0\u679c\u56fe\u8282\u70b9\u7ed3\u6784\u7ea6\u675f\u4e0b\u4f7f\u7528\u5b9a\u5236\u7684\u6761\u4ef6WGAN-GP\u8fdb\u884c\u751f\u6210\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u76ee\u6807\u51fd\u6570\u6765\u5bf9\u9f50\u771f\u5b9e\u4e0e\u4f2a\u6570\u636e\u6240\u6784\u5efa\u7684\u56e0\u679c\u56fe\uff0c\u786e\u4fdd\u5728\u8bad\u7ec3\u4e0e\u91c7\u6837\u9636\u6bb5\u5177\u5907\u56e0\u679c\u611f\u77e5\u3002", "result": "\u572814\u4e2a\u8868\u683c\u6570\u636e\u96c6\u4e0a\uff0cCA-GAN \u76f8\u5bf9\u4e8e\u516d\u79cdSOTA\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\uff0c\u8bc4\u4f30\u805a\u7126\u6838\u5fc3\u6570\u636e\u5de5\u7a0b\u6307\u6807\uff1a\u56e0\u679c\u4fdd\u771f\u3001\u5b9e\u7528\u6027\u4fdd\u771f\u548c\u9690\u79c1\u4fdd\u771f\u3002", "conclusion": "CA-GAN \u4e3a\u6570\u636e\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e00\u4e2a\u5b9e\u7528\u4e14\u9ad8\u6027\u80fd\u7684\u79c1\u6709\u5316\u5408\u6210\u6570\u636e\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u7528\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u6570\u636e\u5e93\u7cfb\u7edf\u3001\u52a0\u901f\u8f6f\u4ef6\u5f00\u53d1\u4e0e\u63a8\u52a8\u5b89\u5168\u7684\u6570\u636e\u9a71\u52a8\u7814\u7a76\u3002"}}
{"id": "2510.24053", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.24053", "abs": "https://arxiv.org/abs/2510.24053", "authors": ["Jacob B. Roberts", "Catherine R. Ji", "Isaac Donnell", "Thomas D. Young", "Allison N. Pearson", "Graham A. Hudson", "Leah S. Keiser", "Mia Wesselkamper", "Peter H. Winegar", "Janik Ludwig", "Sarah H. Klass", "Isha V. Sheth", "Ezechinyere C. Ukabiala", "Maria C. T. Astolfi", "Benjamin Eysenbach", "Jay D. Keasling"], "title": "Low-N Protein Activity Optimization with FolDE", "comment": "18 pages, 4 figures. Preprint. Open-source software available at\n  https://github.com/JBEI/foldy", "summary": "Proteins are traditionally optimized through the costly construction and\nmeasurement of many mutants. Active Learning-assisted Directed Evolution (ALDE)\nalleviates that cost by predicting the best improvements and iteratively\ntesting mutants to inform predictions. However, existing ALDE methods face a\ncritical limitation: selecting the highest-predicted mutants in each round\nyields homogeneous training data insufficient for accurate prediction models in\nsubsequent rounds. Here we present FolDE, an ALDE method designed to maximize\nend-of-campaign success. In simulations across 20 protein targets, FolDE\ndiscovers 23% more top 10% mutants than the best baseline ALDE method (p=0.005)\nand is 55% more likely to find top 1% mutants. FolDE achieves this primarily\nthrough naturalness-based warm-starting, which augments limited activity\nmeasurements with protein language model outputs to improve activity\nprediction. We also introduce a constant-liar batch selector, which improves\nbatch diversity; this is important in multi-mutation campaigns but had limited\neffect in our benchmarks. The complete workflow is freely available as\nopen-source software, making efficient protein optimization accessible to any\nlaboratory.", "AI": {"tldr": "FolDE\uff1a\u4e00\u79cd ALDE \u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u7136\u6027\u6696\u542f\u52a8\u548c\u5e38\u91cf\u8c0e\u8a00\u6279\u91cf\u9009\u62e9\u5b9e\u73b0\u5bf9\u86cb\u767d\u8d28\u4f18\u5316\u7684\u7aef\u5230\u7aef\u6539\u8fdb\uff0c\u572820\u4e2a\u86cb\u767d\u76ee\u6807\u4e0a\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u663e\u8457\uff0c\u4e14\u5f00\u53d1\u4e3a\u5f00\u6e90\u8f6f\u4ef6\u3002", "motivation": "\u964d\u4f4e\u86cb\u767d\u8d28\u4f18\u5316\u6210\u672c\uff0c\u89e3\u51b3\u73b0\u6709 ALDE \u5728\u6bcf\u8f6e\u9009\u53d6\u6700\u9ad8\u9884\u6d4b\u503c\u65f6\u5bfc\u81f4\u8bad\u7ec3\u6570\u636e\u540c\u8d28\u5316\u7684\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u9884\u6d4b\u6a21\u578b\u5728\u540e\u7eed\u8f6e\u6b21\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa FolDE\uff0c\u5f15\u5165\u81ea\u7136\u6027\u57fa\u4e8e\u7684\u6696\u542f\u52a8\uff0c\u5c06\u6709\u9650\u7684\u6d3b\u6027\u6d4b\u91cf\u4e0e\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7ed3\u5408\u4ee5\u63d0\u5347\u6d3b\u6027\u9884\u6d4b\uff1b\u5f15\u5165\u5e38\u91cf\u8c0e\u8a00\uff08constant-liar\uff09\u6279\u91cf\u9009\u62e9\u5668\u4ee5\u589e\u52a0\u6279\u91cf\u591a\u6837\u6027\uff0c\u5f00\u653e\u6e90\u4ee3\u7801\u5de5\u4f5c\u6d41\u3002", "result": "\u5728\u5bf920\u4e2a\u86cb\u767d\u76ee\u6807\u7684\u4eff\u771f\u4e2d\uff0cFolDE \u6bd4\u6700\u4f73\u57fa\u7ebf ALDE \u591a\u53d1\u73b023%\u7684\u524d10%\u7a81\u53d8\u4f53\uff08p=0.005\uff09\uff0c\u627e\u51fa\u524d1%\u7a81\u53d8\u4f53\u7684\u6982\u7387\u63d0\u5347\u4e8655%\uff1b\u5e38\u91cf\u8c0e\u8a00\u9009\u62e9\u5668\u5bf9\u591a\u7a81\u53d8\u8ba1\u5212\u7684\u6279\u91cf\u591a\u6837\u6027\u6709\u5e2e\u52a9\uff0c\u4f46\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u4f5c\u7528\u6709\u9650\u3002", "conclusion": "FolDE \u80fd\u901a\u8fc7\u6539\u8fdb\u8bad\u7ec3\u6570\u636e\u591a\u6837\u6027\u548c\u5f15\u5bfc\u9884\u6d4b\u6a21\u578b\u63d0\u5347\u7aef\u5230\u7aef\u6210\u529f\u7387\uff0c\u4e14\u5b8c\u6574\u5de5\u4f5c\u6d41\u53ef\u81ea\u7531\u83b7\u53d6\u7684\u5f00\u6e90\u8f6f\u4ef6\uff0c\u4f7f\u9ad8\u6548\u86cb\u767d\u8d28\u4f18\u5316\u66f4\u6613\u4e8e\u5b9e\u9a8c\u5ba4\u4f7f\u7528\u3002"}}
{"id": "2510.24095", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24095", "abs": "https://arxiv.org/abs/2510.24095", "authors": ["Vedant Gupta", "Haotian Fu", "Calvin Luo", "Yiding Jiang", "George Konidaris"], "title": "Learning Parameterized Skills from Demonstrations", "comment": "Neurips 2025", "summary": "We present DEPS, an end-to-end algorithm for discovering parameterized skills\nfrom expert demonstrations. Our method learns parameterized skill policies\njointly with a meta-policy that selects the appropriate discrete skill and\ncontinuous parameters at each timestep. Using a combination of temporal\nvariational inference and information-theoretic regularization methods, we\naddress the challenge of degeneracy common in latent variable models, ensuring\nthat the learned skills are temporally extended, semantically meaningful, and\nadaptable. We empirically show that learning parameterized skills from\nmultitask expert demonstrations significantly improves generalization to unseen\ntasks. Our method outperforms multitask as well as skill learning baselines on\nboth LIBERO and MetaWorld benchmarks. We also demonstrate that DEPS discovers\ninterpretable parameterized skills, such as an object grasping skill whose\ncontinuous arguments define the grasp location.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7aef\u5230\u7aef\u7684DEPS\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u53d1\u73b0\u53c2\u6570\u5316\u6280\u80fd\uff0c\u8054\u5408\u5b66\u4e60\u53c2\u6570\u5316\u6280\u80fd\u7b56\u7565\u548c\u5143\u7b56\u7565\uff0c\u5229\u7528\u65f6\u95f4\u53d8\u5206\u63a8\u65ad\u4e0e\u4fe1\u606f\u8bba\u6b63\u5219\u5316\u89e3\u51b3\u6f5c\u53d8\u91cf\u6a21\u578b\u7684\u9000\u5316\u95ee\u9898\uff0c\u4ece\u800c\u5b66\u5f97 temporally extended\u3001\u8bed\u4e49\u660e\u786e\u4e14\u53ef\u9002\u5e94\u7684\u6280\u80fd\uff0c\u4e14\u5728LIBERO\u4e0eMetaWorld\u57fa\u7ebf\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u591a\u4efb\u52a1\u4e0e\u6280\u80fd\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u591f\u53d1\u73b0\u53ef\u89e3\u91ca\u7684\u53c2\u6570\u5316\u6280\u80fd\uff08\u5982\u628a\u63e1\u4f4d\u7f6e\u7531\u8fde\u7eed\u53c2\u6570\u5b9a\u4e49\uff09\u3002", "motivation": "\u5728\u673a\u5668\u4eba\u5b66\u4e60\u4e2d\uff0c\u671f\u671b\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u590d\u7528\u6027\u9ad8\u3001\u53ef\u89e3\u91ca\u7684\u53c2\u6570\u5316\u6280\u80fd\uff0c\u5e76\u80fd\u591f\u5bf9\u672a\u77e5\u4efb\u52a1\u8fdb\u884c\u6cdb\u5316\u3002\u73b0\u6709\u65b9\u6cd5\u5e38\u9677\u5165\u6f5c\u53d8\u91cf\u9000\u5316\u3001\u6280\u80fd\u4e0d\u7a33\u5b9a\u6216\u96be\u4ee5\u89e3\u91ca\u7684\u95ee\u9898\uff0c\u96be\u4ee5\u5728\u591a\u4efb\u52a1\u573a\u666f\u4e2d\u5b66\u4e60\u5230\u53ef\u8f6c\u79fb\u7684\u53c2\u6570\u5316\u63a7\u5236\u3002", "method": "\u63d0\u51fa\u7aef\u5230\u7aef\u7684DEPS\u6846\u67b6\uff0c\u8054\u5408\u5b66\u4e60\u53c2\u6570\u5316\u6280\u80fd\u7b56\u7565\u4ee5\u53ca\u7528\u4e8e\u79bb\u6563\u6280\u80fd\u4e0e\u8fde\u7eed\u53c2\u6570\u9009\u62e9\u7684\u5143\u7b56\u7565\u3002\u901a\u8fc7\u65f6\u95f4\u53d8\u5206\u63a8\u65ad\u5bf9\u6f5c\u53d8\u91cf\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u7ed3\u5408\u4fe1\u606f\u7406\u8bba\u6b63\u5219\u5316\u4ee5\u7f13\u89e3\u6f5c\u53d8\u91cf\u9000\u5316\uff0c\u4fc3\u4f7f\u5b66\u4e60\u5230\u7684\u6280\u80fd\u5728\u65f6\u95f4\u4e0a\u4fdd\u6301\u6269\u5c55\u6027\u3001\u8bed\u4e49\u4e0a\u660e\u786e\u4e14\u53ef\u9002\u5e94\u3002\u8bad\u7ec3\u8fc7\u7a0b\u5229\u7528\u591a\u4efb\u52a1\u4e13\u5bb6\u6f14\u793a\u6570\u636e\uff0c\u76ee\u6807\u662f\u63d0\u5347\u5bf9\u672a\u89c1\u4efb\u52a1\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4ece\u591a\u4efb\u52a1\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u53c2\u6570\u5316\u6280\u80fd\u663e\u8457\u63d0\u5347\u5bf9\u672a\u89c1\u4efb\u52a1\u7684\u6cdb\u5316\uff0c\u4e14\u5728LIBERO\u4e0eMetaWorld\u57fa\u51c6\u4e0a\u4f18\u4e8e\u591a\u4efb\u52a1\u57fa\u7ebf\u548c\u6280\u80fd\u5b66\u4e60\u57fa\u7ebf\u3002\u6b64\u5916\uff0cDEPS\u80fd\u53d1\u73b0\u53ef\u89e3\u91ca\u7684\u53c2\u6570\u5316\u6280\u80fd\uff0c\u4f8b\u5982\u4e00\u4e2a\u5c06\u8fde\u7eed\u53c2\u6570\u7528\u4e8e\u5b9a\u4e49\u6293\u53d6\u4f4d\u7f6e\u7684\u6293\u53d6\u6280\u80fd\u3002", "conclusion": "DEPS\u80fd\u591f\u5728\u7aef\u5230\u7aef\u5b66\u4e60\u4e2d\u540c\u65f6\u83b7\u53d6\u53c2\u6570\u5316\u6280\u80fd\u548c\u5143\u7b56\u7565\uff0c\u4ea7\u751f temporally extended\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u6cdb\u5316\u7684\u6280\u80fd\u96c6\u5408\uff1b\u901a\u8fc7\u65f6\u95f4\u53d8\u5206\u63a8\u65ad\u4e0e\u4fe1\u606f\u8bba\u6b63\u5219\u5316\u6709\u6548\u7f13\u89e3\u6f5c\u53d8\u91cf\u9000\u5316\u95ee\u9898\uff0c\u793a\u8303\u4e86\u4ece\u591a\u4efb\u52a1\u6f14\u793a\u4e2d\u5b66\u4e60\u53c2\u6570\u5316\u6280\u80fd\u7684\u53ef\u884c\u6027\u4e0e\u4f18\u52bf\u3002"}}
{"id": "2510.24120", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24120", "abs": "https://arxiv.org/abs/2510.24120", "authors": ["Ziyu Liu", "Yijing Liu", "Jianfei Yuan", "Minzhi Yan", "Le Yue", "Honghui Xiong", "Yi Yang"], "title": "Graph-Guided Concept Selection for Efficient Retrieval-Augmented Generation", "comment": null, "summary": "Graph-based RAG constructs a knowledge graph (KG) from text chunks to enhance\nretrieval in Large Language Model (LLM)-based question answering. It is\nespecially beneficial in domains such as biomedicine, law, and political\nscience, where effective retrieval often involves multi-hop reasoning over\nproprietary documents. However, these methods demand numerous LLM calls to\nextract entities and relations from text chunks, incurring prohibitive costs at\nscale. Through a carefully designed ablation study, we observe that certain\nwords (termed concepts) and their associated documents are more important.\nBased on this insight, we propose Graph-Guided Concept Selection (G2ConS). Its\ncore comprises a chunk selection method and an LLM-independent concept graph.\nThe former selects salient document chunks to reduce KG construction costs; the\nlatter closes knowledge gaps introduced by chunk selection at zero cost.\nEvaluations on multiple real-world datasets show that G2ConS outperforms all\nbaselines in construction cost, retrieval effectiveness, and answering quality.", "AI": {"tldr": "\u63d0\u51faG2ConS\uff0c\u901a\u8fc7 chunk \u9009\u62e9\u548c\u65e0\u989d\u5916\u6210\u672c\u7684\u6982\u5ff5\u56fe\u964d\u4f4e\u57fa\u4e8e\u56fe\u7684RAG\u5728LLM\u95ee\u7b54\u4e2d\u7684\u6784\u5efa\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u68c0\u7d22\u4e0e\u56de\u7b54\u8d28\u91cf\u3002", "motivation": "\u7f13\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6587\u6863\u68c0\u7d22\u4e2d\u5bf9\u6587\u672cChunk\u8fdb\u884c\u5b9e\u4f53\u4e0e\u5173\u7cfb\u62bd\u53d6\u9020\u6210\u7684\u9ad8\u6602\u6210\u672c\uff1b\u5229\u7528\u53d1\u73b0\u67d0\u4e9b\u6982\u5ff5\u8bcd\u53ca\u5176\u76f8\u5173\u6587\u6863\u5bf9\u4efb\u52a1\u66f4\u5177\u5f71\u54cd\u529b\uff0c\u964d\u4f4e\u6574\u4f53\u6210\u672c\u3002", "method": "\u63d0\u51faGraph-Guided Concept Selection (G2ConS)\uff0c\u5305\u62ec\u4e00\u4e2aLLM\u65e0\u5173\u7684chunk\u9009\u62e9\u65b9\u6cd5\u7528\u4e8e\u7b5b\u9009\u91cd\u8981\u6587\u6863\u7247\u6bb5\uff0c\u4ece\u800c\u964d\u4f4eKG\u6784\u5efa\u6210\u672c\uff0c\u4ee5\u53ca\u4e00\u4e2aLLM\u65e0\u6210\u672c\u7684\u6982\u5ff5\u56fe\uff0c\u7528\u4ee5\u5f25\u8865\u56e0chunk\u9009\u62e9\u5e26\u6765\u7684\u77e5\u8bc6\u7a7a\u7f3a\u3002\u901a\u8fc7\u7cfb\u7edf\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u5173\u952e\u6982\u5ff5\u4e0e\u6587\u6863\u7684\u91cd\u8981\u6027\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cG2ConS\u5728\u6784\u5efa\u6210\u672c\u3001\u68c0\u7d22\u6709\u6548\u6027\u548c\u56de\u7b54\u8d28\u91cf\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u6982\u5ff5\u7ea7\u9009\u62e9\u4e0e\u96f6\u6210\u672c\u7684\u6982\u5ff5\u56fe\uff0cG2ConS\u5b9e\u73b0\u4e86\u6210\u672c\u8282\u7701\u4e0e\u6027\u80fd\u63d0\u5347\uff0c\u662f\u4e00\u79cd\u6709\u6548\u7684\u56fe\u68c0\u7d22\u589e\u5f3a\u7b56\u7565\uff0c\u9002\u7528\u4e8e\u9700\u8981\u591a\u8df3\u63a8\u7406\u7684\u9886\u57df\u3002"}}
{"id": "2510.24173", "categories": ["cs.LG", "cs.NA", "math.DS", "math.NA", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.24173", "abs": "https://arxiv.org/abs/2510.24173", "authors": ["Yiheng Du", "Aditi S. Krishnapriyan"], "title": "EddyFormer: Accelerated Neural Simulations of Three-Dimensional Turbulence at Scale", "comment": "NeurIPS 2025", "summary": "Computationally resolving turbulence remains a central challenge in fluid\ndynamics due to its multi-scale interactions. Fully resolving large-scale\nturbulence through direct numerical simulation (DNS) is computationally\nprohibitive, motivating data-driven machine learning alternatives. In this\nwork, we propose EddyFormer, a Transformer-based spectral-element (SEM)\narchitecture for large-scale turbulence simulation that combines the accuracy\nof spectral methods with the scalability of the attention mechanism. We\nintroduce an SEM tokenization that decomposes the flow into grid-scale and\nsubgrid-scale components, enabling capture of both local and global features.\nWe create a new three-dimensional isotropic turbulence dataset and train\nEddyFormer to achieves DNS-level accuracy at 256^3 resolution, providing a 30x\nspeedup over DNS. When applied to unseen domains up to 4x larger than in\ntraining, EddyFormer preserves accuracy on physics-invariant metrics-energy\nspectra, correlation functions, and structure functions-showing domain\ngeneralization. On The Well benchmark suite of diverse turbulent flows,\nEddyFormer resolves cases where prior ML models fail to converge, accurately\nreproducing complex dynamics across a wide range of physical conditions.", "AI": {"tldr": "EddyFormer uses a Transformer-based SEM to simulate large-scale turbulence with DNS-level accuracy at 256^3, achieving 30x speedup and strong domain generalization across larger domains and diverse flows.", "motivation": "Tackle the computational infeasibility of direct numerical simulation for turbulence and the limitations of existing data-driven models in capturing multi-scale interactions and cross-domain generalization.", "method": "Introduce EddyFormer, an SEM-based Transformer architecture with SEM tokenization that splits flow into grid-scale and subgrid-scale components; train on a 3D isotropic-turbulence dataset to DNS-level accuracy; evaluate on unseen domains up to 4x larger and on the The Well benchmark to test generalization and robustness.", "result": "Attains DNS-level accuracy at 256^3 with ~30x speedup over DNS; preserves energy spectra, correlation/structure functions on larger unseen domains; demonstrates domain generalization and successful convergence on The Well benchmark where previous ML models fail.", "conclusion": "A Transformer-based SEM framework can fuse spectral-method accuracy with the scalability of attention, enabling accurate, scalable turbulence simulations with strong cross-domain generalization."}}
{"id": "2510.24180", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24180", "abs": "https://arxiv.org/abs/2510.24180", "authors": ["Arpita Kundu", "Joyita Chakraborty", "Anindita Desarkar", "Aritra Sen", "Srushti Anil Patil", "Vishwanathan Raman"], "title": "V-SAT: Video Subtitle Annotation Tool", "comment": null, "summary": "The surge of audiovisual content on streaming platforms and social media has\nheightened the demand for accurate and accessible subtitles. However, existing\nsubtitle generation methods primarily speech-based transcription or OCR-based\nextraction suffer from several shortcomings, including poor synchronization,\nincorrect or harmful text, inconsistent formatting, inappropriate reading\nspeeds, and the inability to adapt to dynamic audio-visual contexts. Current\napproaches often address isolated issues, leaving post-editing as a\nlabor-intensive and time-consuming process. In this paper, we introduce V-SAT\n(Video Subtitle Annotation Tool), a unified framework that automatically\ndetects and corrects a wide range of subtitle quality issues. By combining\nLarge Language Models(LLMs), Vision-Language Models (VLMs), Image Processing,\nand Automatic Speech Recognition (ASR), V-SAT leverages contextual cues from\nboth audio and video. Subtitle quality improved, with the SUBER score reduced\nfrom 9.6 to 3.54 after resolving all language mode issues and F1-scores of\n~0.80 for image mode issues. Human-in-the-loop validation ensures high-quality\nresults, providing the first comprehensive solution for robust subtitle\nannotation.", "AI": {"tldr": "\u63d0\u51faV-SAT\uff08\u89c6\u9891\u5b57\u5e55\u6807\u6ce8\u5de5\u5177\uff09\uff0c\u901a\u8fc7\u6574\u5408\u5927\u6a21\u578b\u548c\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u81ea\u52a8\u68c0\u6d4b\u5e76\u4fee\u6b63\u591a\u79cd\u5b57\u5e55\u8d28\u91cf\u95ee\u9898\uff0c\u63d0\u5347\u5b57\u5e55\u8d28\u91cf\u5e76\u5b9e\u73b0\u4eba\u673a\u534f\u540c\u7684\u9ad8\u8d28\u91cf\u5b57\u5e55\u6807\u6ce8\u3002", "motivation": "\u968f\u7740\u6d41\u5a92\u4f53\u548c\u793e\u4ea4\u5e73\u53f0\u7684\u89c6\u9891\u5185\u5bb9\u6fc0\u589e\uff0c\u5bf9\u51c6\u786e\u3001\u53ef\u8bfb\u4e14\u9002\u914d\u52a8\u6001\u573a\u666f\u7684\u5b57\u5e55\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff1b\u73b0\u6709\u5b57\u5e55\u751f\u6210\u65b9\u6cd5\u591a\u805a\u7126\u5355\u4e00\u6e90\uff08\u8bed\u97f3\u6216OCR\uff09\uff0c\u5728\u540c\u6b65\u6027\u3001\u6587\u672c\u5408\u89c4\u3001\u683c\u5f0f\u7edf\u4e00\u3001\u9605\u8bfb\u901f\u5ea6\u7b49\u65b9\u9762\u5b58\u5728\u7f3a\u9677\uff0c\u5bfc\u81f4\u540e\u671f\u4eba\u5de5\u4fee\u6b63\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u878d\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3001\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u3001\u56fe\u50cf\u5904\u7406\u548c\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\uff0c\u5229\u7528\u97f3\u89c6\u9891\u4e0a\u4e0b\u6587\u5bf9\u5b57\u5e55\u8fdb\u884c\u5168\u9762\u68c0\u6d4b\u4e0e\u7ea0\u9519\uff0c\u5e76\u901a\u8fc7\u4eba\u673a\u5728\u73af\u9a8c\u8bc1\u63d0\u5347\u7ed3\u679c\u8d28\u91cf\u3002", "result": "\u5b57\u5e55\u8d28\u91cf\u663e\u8457\u63d0\u5347\uff1a\u5c06SUBER\u5206\u6570\u4ece9.6\u964d\u81f33.54\uff08\u89e3\u51b3\u8bed\u8a00\u6a21\u5f0f\u95ee\u9898\u540e\uff09\uff0c\u56fe\u50cf\u6a21\u5f0f\u95ee\u9898\u7684F1-score\u7ea6\u4e3a0.80\uff1b\u5e76\u901a\u8fc7\u4eba\u673a\u534f\u540c\u9a8c\u8bc1\u786e\u4fdd\u9ad8\u8d28\u91cf\u7ed3\u679c\uff0c\u63d0\u4f9b\u9996\u4e2a\u7efc\u5408\u89e3\u51b3\u65b9\u6848\u7528\u4e8e\u9c81\u68d2\u5b57\u5e55\u6807\u6ce8\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u7aef\u5230\u7aef\u3001\u53ef\u6269\u5c55\u7684\u5b57\u5e55\u8d28\u91cf\u4fee\u6b63\u4e0e\u6807\u6ce8\u65b9\u6848\uff0c\u80fd\u5728\u52a8\u6001\u591a\u6a21\u6001\u573a\u666f\u4e2d\u5b9e\u73b0\u66f4\u7a33\u5065\u7684\u5b57\u5e55\u751f\u6210\u4e0e\u540e\u671f\u6da6\u8272\u3002"}}
{"id": "2510.24216", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24216", "abs": "https://arxiv.org/abs/2510.24216", "authors": ["Fan Xu", "Hao Wu", "Kun Wang", "Nan Wang", "Qingsong Wen", "Xian Wu", "Wei Gong", "Xibin Zhao"], "title": "Unlocking Out-of-Distribution Generalization in Dynamics through Physics-Guided Augmentation", "comment": null, "summary": "In dynamical system modeling, traditional numerical methods are limited by\nhigh computational costs, while modern data-driven approaches struggle with\ndata scarcity and distribution shifts. To address these fundamental\nlimitations, we first propose SPARK, a physics-guided quantitative augmentation\nplugin. Specifically, SPARK utilizes a reconstruction autoencoder to integrate\nphysical parameters into a physics-rich discrete state dictionary. This state\ndictionary then acts as a structured dictionary of physical states, enabling\nthe creation of new, physically-plausible training samples via principled\ninterpolation in the latent space. Further, for downstream prediction, these\naugmented representations are seamlessly integrated with a Fourier-enhanced\nGraph ODE, a combination designed to robustly model the enriched data\ndistribution while capturing long-term temporal dependencies. Extensive\nexperiments on diverse benchmarks demonstrate that SPARK significantly\noutperforms state-of-the-art baselines, particularly in challenging\nout-of-distribution scenarios and data-scarce regimes, proving the efficacy of\nour physics-guided augmentation paradigm.", "AI": {"tldr": "SPARK \u5c06\u7269\u7406\u53c2\u6570\u6574\u5408\u5230\u79bb\u6563\u72b6\u6001\u5b57\u5178\uff0c\u501f\u52a9\u91cd\u6784\u81ea\u7f16\u7801\u5668\u8fdb\u884c\u7269\u7406\u5f15\u5bfc\u7684\u589e\u5e7f\uff0c\u5e76\u901a\u8fc7\u5728\u6f5c\u7a7a\u95f4\u5185\u8fdb\u884c principled \u63d2\u503c\u6765\u751f\u6210\u65b0\u7684\u8bad\u7ec3\u6837\u672c\uff1b\u5bf9\u4e0b\u6e38\u9884\u6d4b\u4f7f\u7528 Fourier \u589e\u5f3a\u7684 Graph ODE\uff0c\u65e8\u5728\u63d0\u5347\u5728\u5206\u5e03\u5916\u548c\u6570\u636e\u7a00\u7f3a\u60c5\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u4e0e\u957f\u671f\u4f9d\u8d56\u5efa\u6a21\u80fd\u529b\u3002", "motivation": "\u5728\u52a8\u529b\u7cfb\u7edf\u5efa\u6a21\u4e2d\uff0c\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u6210\u672c\u9ad8\uff0c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728\u6570\u636e\u7a00\u7f3a\u548c\u8fc1\u79fb\u5206\u5e03\u65f6\u8868\u73b0\u4e0d\u4f73\u3002\u63d0\u51fa\u4e00\u79cd\u7269\u7406\u5f15\u5bfc\u7684\u589e\u5e7f\u6846\u67b6\uff0c\u4ee5\u7f13\u89e3\u8fd9\u4e24\u5927\u6311\u6218\u3002", "method": "SPARK \u4f7f\u7528\u91cd\u6784\u81ea\u7f16\u7801\u5668\u5c06\u7269\u7406\u53c2\u6570\u5d4c\u5165\u4e00\u4e2a\u7269\u7406\u4e30\u5bcc\u7684\u79bb\u6563\u72b6\u6001\u5b57\u5178\uff1b\u8fd9\u4e2a\u5b57\u5178\u4f5c\u4e3a\u7269\u7406\u72b6\u6001\u7684\u7ed3\u6784\u5316\u8868\u793a\uff0c\u5141\u8bb8\u901a\u8fc7\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u6709\u539f\u5219\u7684\u63d2\u503c\u6765\u751f\u6210\u65b0\u7684\u3001\u7269\u7406\u4e0a\u5408\u7406\u7684\u8bad\u7ec3\u6837\u672c\u3002\u4e0b\u6e38\u9884\u6d4b\u9636\u6bb5\u5c06\u589e\u5f3a\u7684\u8868\u793a\u4e0e Fourier \u589e\u5f3a\u7684 Graph ODE \u7ed3\u5408\uff0c\u4ee5\u7a33\u5065\u5730\u5efa\u6a21\u6269\u5c55\u7684\u6570\u636e\u5206\u5e03\u5e76\u6355\u6349\u957f\u671f\u65f6\u5e8f\u4f9d\u8d56\u3002", "result": "\u5728\u591a\u6837\u5316\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cSPARK \u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\uff0c\u5c24\u5176\u662f\u5728\u5206\u5e03\u5916\u548c\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\uff0c\u9a8c\u8bc1\u4e86\u7269\u7406\u5f15\u5bfc\u589e\u5e7f\u8303\u5f0f\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u7269\u7406\u5f15\u5bfc\u7684\u589e\u5e7f\u8303\u5f0f\uff0cSPARK \u80fd\u5728\u6570\u636e\u7a00\u7f3a\u4e0e\u5206\u5e03\u8fc1\u79fb\u573a\u666f\u4e2d\u63d0\u5347\u52a8\u529b\u7cfb\u7edf\u5efa\u6a21\u7684\u9c81\u68d2\u6027\u4e0e\u9884\u6d4b\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u5c06\u7269\u7406\u5148\u9a8c\u878d\u5165\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.24217", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24217", "abs": "https://arxiv.org/abs/2510.24217", "authors": ["Alisher Turubayev", "Anna Shopova", "Fabian Lange", "Mahmut Kamalak", "Paul Mattes", "Victoria Ayvasky", "Bert Arnrich", "Bjarne Pfitzner", "Robin P. van de Water"], "title": "Closing Gaps: An Imputation Analysis of ICU Vital Signs", "comment": "Preprint", "summary": "As more Intensive Care Unit (ICU) data becomes available, the interest in\ndeveloping clinical prediction models to improve healthcare protocols\nincreases. However, the lack of data quality still hinders clinical prediction\nusing Machine Learning (ML). Many vital sign measurements, such as heart rate,\ncontain sizeable missing segments, leaving gaps in the data that could\nnegatively impact prediction performance. Previous works have introduced\nnumerous time-series imputation techniques. Nevertheless, more comprehensive\nwork is needed to compare a representative set of methods for imputing ICU\nvital signs and determine the best practice. In reality, ad-hoc imputation\ntechniques that could decrease prediction accuracy, like zero imputation, are\nstill used. In this work, we compare established imputation techniques to guide\nresearchers in improving the performance of clinical prediction models by\nselecting the most accurate imputation technique. We introduce an extensible\nand reusable benchmark with currently 15 imputation and 4 amputation methods,\ncreated for benchmarking on major ICU datasets. We hope to provide a\ncomparative basis and facilitate further ML development to bring more models\ninto clinical practice.", "AI": {"tldr": "A reusable benchmark compares 15 imputation methods and 4 amputation methods on ICU vital signs to guide ML-based clinical prediction.", "motivation": "Data missingness in ICU vital sign time series degrades predictive performance; there is a need for a systematic, comprehensive comparison of imputation techniques beyond ad-hoc approaches.", "method": "They establish an extensible and reusable benchmark framework, aggregating 15 imputation methods and 4 amputation methods, and evaluate them on major ICU datasets to assess impact on clinical prediction models.", "result": "The benchmark provides a comparative basis for selecting imputation techniques and highlights the importance of systematic evaluation to improve prediction performance.", "conclusion": "A standardized benchmark will facilitate the development and clinical adoption of better ML models by promoting rigorous comparison of imputation strategies on ICU data."}}
{"id": "2510.24233", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24233", "abs": "https://arxiv.org/abs/2510.24233", "authors": ["Antoine Szatkownik", "Aur\u00e9lien Decelle", "Beatriz Seoane", "Nicolas Bereux", "L\u00e9o Planche", "Guillaume Charpiat", "Burak Yelmen", "Flora Jay", "Cyril Furtlehner"], "title": "PRIVET: Privacy Metric Based on Extreme Value Theory", "comment": null, "summary": "Deep generative models are often trained on sensitive data, such as genetic\nsequences, health data, or more broadly, any copyrighted, licensed or protected\ncontent. This raises critical concerns around privacy-preserving synthetic\ndata, and more specifically around privacy leakage, an issue closely tied to\noverfitting. Existing methods almost exclusively rely on global criteria to\nestimate the risk of privacy failure associated to a model, offering only\nquantitative non interpretable insights. The absence of rigorous evaluation\nmethods for data privacy at the sample-level may hinder the practical\ndeployment of synthetic data in real-world applications. Using extreme value\nstatistics on nearest-neighbor distances, we propose PRIVET, a generic\nsample-based, modality-agnostic algorithm that assigns an individual privacy\nleak score to each synthetic sample. We empirically demonstrate that PRIVET\nreliably detects instances of memorization and privacy leakage across diverse\ndata modalities, including settings with very high dimensionality, limited\nsample sizes such as genetic data and even under underfitting regimes. We\ncompare our method to existing approaches under controlled settings and show\nits advantage in providing both dataset level and sample level assessments\nthrough qualitative and quantitative outputs. Additionally, our analysis\nreveals limitations in existing computer vision embeddings to yield\nperceptually meaningful distances when identifying near-duplicate samples.", "AI": {"tldr": "\u63d0\u51fa PRIVET\uff0c\u4e00\u79cd\u57fa\u4e8e\u6837\u672c\u7684\u3001\u4efb\u610f\u6a21\u6001\u7684\u9690\u79c1\u6cc4\u9732\u8bc4\u4f30\u7b97\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6700\u8fd1\u90bb\u8ddd\u79bb\u7684\u6781\u503c\u7edf\u8ba1\u6765\u7ed9\u6bcf\u4e2a\u5408\u6210\u6837\u672c\u5206\u914d\u9690\u79c1\u6cc4\u9732\u5206\u6570\uff0c\u4fbf\u4e8e\u6837\u672c\u7ea7\u522b\u7684\u9690\u79c1\u68c0\u6d4b\u3002", "motivation": "\u5728\u5408\u6210\u6570\u636e\u7684\u9690\u79c1\u4fdd\u62a4\u7814\u7a76\u4e2d\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u4f7f\u7528\u5168\u5c40\u6027\u3001\u4e0d\u53ef\u89e3\u91ca\u7684\u98ce\u9669\u8bc4\u4f30\uff0c\u7f3a\u4e4f\u5bf9\u5355\u6837\u672c\u7684\u53ef\u89e3\u91ca\u3001\u53ef\u64cd\u4f5c\u7684\u8bc4\u4f30\u624b\u6bb5\uff0c\u53ef\u80fd\u963b\u788d\u5b9e\u9645\u90e8\u7f72\u3002\u9700\u8981\u4e00\u79cd\u6837\u672c\u7ea7\u3001\u6a21\u6001\u65e0\u5173\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u68c0\u6d4b memorization \u4e0e\u9690\u79c1\u6cc4\u9732\u3002", "method": "\u63d0\u51fa PRIVET\uff1a\u57fa\u4e8e\u6700\u8fd1\u90bb\u8ddd\u79bb\u7684\u6781\u503c\u7edf\u8ba1\uff0c\u5229\u7528\u6781\u503c\u7406\u8bba\u5bf9\u6bcf\u4e2a\u5408\u6210\u6837\u672c\u5206\u914d\u9690\u79c1\u6cc4\u9732\u5206\u6570\uff0c\u65b9\u6cd5\u5bf9\u6570\u636e\u6a21\u6001\u65e0\u5173\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u3001\u5927\u6837\u672c\u91cf\u53ca\u6837\u672c\u7a00\u7f3a\uff08\u5982\u57fa\u56e0\u6570\u636e\uff09\u7684\u573a\u666f\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e PRIVET \u80fd\u53ef\u9760\u68c0\u6d4b memorization \u4e0e\u9690\u79c1\u6cc4\u9732\uff0c\u5728\u591a\u79cd\u6570\u636e\u6a21\u6001\u4e0b\u6709\u6548\uff0c\u5305\u62ec\u9ad8\u7ef4\u3001\u6781\u5c11\u6837\u672c\uff08\u57fa\u56e0\u6570\u636e\uff09\u4ee5\u53ca\u6b20\u62df\u5408\u60c5\u5f62\uff1b\u4e0e\u73b0\u6709\u65b9\u6cd5\u5728\u6570\u636e\u96c6\u7ea7\u522b\u548c\u6837\u672c\u7ea7\u522b\u8f93\u51fa\u65b9\u9762\u7684\u6bd4\u8f83\u663e\u793a\u5176\u4f18\u52bf\uff0c\u5e76\u7ed9\u51fa\u5b9a\u6027\u4e0e\u5b9a\u91cf\u8f93\u51fa\u3002\u5206\u6790\u8fd8\u63ed\u793a\u4e86\u73b0\u6709\u8ba1\u7b97\u673a\u89c6\u89c9\u5d4c\u5165\u5728\u5f97\u5230\u8fd1\u4f3c\u91cd\u590d\u6837\u672c\u65f6\u7684\u8ddd\u79bb\u611f\u77e5\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6570\u636e\u9690\u79c1\u7684\u6837\u672c\u7ea7\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u3001\u901a\u7528\u7684\u5ea6\u91cf\u624b\u6bb5\uff0c\u4f18\u4e8e\u73b0\u6709\u5168\u5c40\u6027\u8bc4\u4f30\uff0c\u5e76\u5bf9\u5b9e\u9645\u90e8\u7f72\u5408\u6210\u6570\u636e\u7684\u9690\u79c1\u4fdd\u62a4\u5177\u6709\u6f5c\u5728\u4ef7\u503c\uff0c\u540c\u65f6\u4e5f\u66b4\u9732\u4e86\u5d4c\u5165\u8868\u793a\u5728\u8fd1\u4f3c\u91cd\u590d\u6837\u672c\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.24234", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24234", "abs": "https://arxiv.org/abs/2510.24234", "authors": ["Ludovic Schwartz", "Hamish Flynn", "Gergely Neu"], "title": "Sparse Optimistic Information Directed Sampling", "comment": null, "summary": "Many high-dimensional online decision-making problems can be modeled as\nstochastic sparse linear bandits. Most existing algorithms are designed to\nachieve optimal worst-case regret in either the data-rich regime, where\npolynomial depen- dence on the ambient dimension is unavoidable, or the\ndata-poor regime, where dimension-independence is possible at the cost of worse\ndependence on the num- ber of rounds. In contrast, the sparse Information\nDirected Sampling (IDS) algo- rithm satisfies a Bayesian regret bound that has\nthe optimal rate in both regimes simultaneously. In this work, we explore the\nuse of Sparse Optimistic Informa- tion Directed Sampling (SOIDS) to achieve the\nsame adaptivity in the worst-case setting, without Bayesian assumptions.\nThrough a novel analysis that enables the use of a time-dependent learning\nrate, we show that SOIDS can optimally balance information and regret. Our\nresults extend the theoretical guarantees of IDS, pro- viding the first\nalgorithm that simultaneously achieves optimal worst-case regret in both the\ndata-rich and data-poor regimes. We empirically demonstrate the good\nperformance of SOIDS.", "AI": {"tldr": "SOIDS\u4e3a\u7a00\u758f\u968f\u673a\u7ebf\u6027\u5e26\u5bbd\u95ee\u9898\u63d0\u4f9b\u4e86\u5728\u6570\u636e\u4e30\u5bcc\u548c\u6570\u636e\u7a00\u7f3a\u4e24\u79cd\u60c5\u5f62\u4e0b\u7684\u6700\u4f18\u6700\u574f\u60c5\u5883 regrets \u7684\u81ea\u9002\u5e94\u89e3\uff0c\u4e14\u4e0d\u4f9d\u8d56\u8d1d\u53f6\u65af\u5047\u8bbe\u3002", "motivation": "\u73b0\u6709\u7b97\u6cd5\u5728\u6570\u636e\u4e30\u5bcc\u6216\u6570\u636e\u7a00\u7f3a\u4e24\u7aef\u53ea\u80fd\u5728\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u8fbe\u5230\u6700\u4f18\u7684\u6700\u574f\u60c5\u5883\u8868\u73b0\uff0c\u7f3a\u4e4f\u5728\u4e24\u7aef\u540c\u65f6\u6700\u4f18\u7684\u81ea\u9002\u5e94\u6027\u3002\u4e4b\u524d\u7684\u7a00\u758fIDS\u5728\u8d1d\u53f6\u65af\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u4e24\u7aef\u7684\u6700\u4f18\u7387\uff0c\u4f46\u5728\u4e25\u683c\u7684\u6700\u574f\u60c5\u5883\u4e0b\u65e0\u76f8\u5e94\u65b9\u6cd5\u3002\u9700\u8981\u4e00\u4e2a\u7eaf\u7cb9\u6700\u574f\u60c5\u5883\u4e0b\u4e5f\u80fd\u5728\u4e24\u79cd regime \u540c\u65f6\u8fbe\u5230\u6700\u4f18\u7684\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u7a00\u758f\u4e50\u89c2\u4fe1\u606f\u5bfc\u5411\u91c7\u6837\uff08SOIDS\uff09\uff0c\u901a\u8fc7\u5f15\u5165\u65f6\u95f4\u76f8\u5173\u7684\u5b66\u4e60\u7387\u6765\u5b9e\u73b0\u4fe1\u606f\u4e0e\u540e\u6094\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u6269\u5c55\u4e86IDS\u7684\u5206\u6790\u4ee5\u9002\u5e94\u6700\u574f\u60c5\u5883\u7684\u8981\u6c42\uff0c\u4e14\u9488\u5bf9\u7a00\u758f\u7ebf\u6027\u5e26\u6765\u5e26\u6765\u4e86\u81ea\u9002\u5e94\u7684\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u7406\u8bba\u4e0a\u7ed9\u51faSOIDS\u5728\u6570\u636e\u4e30\u5bcc\u4e0e\u6570\u636e\u7a00\u7f3a\u4e24\u79cd\u60c5\u5f62\u4e0b\u90fd\u8fbe\u5230\u6700\u4f18\u7684\u6700\u574f\u60c5\u5883\u540e\u6094\u754c\uff1b\u5728\u5b9e\u8df5\u4e2d\u5bf9SOIDS\u8fdb\u884c\u4e86\u7ecf\u9a8c\u6027\u9a8c\u8bc1\uff0c\u663e\u793a\u826f\u597d\u6027\u80fd\u3002", "conclusion": "SOIDS\u5b9e\u73b0\u4e86\u5728\u6700\u574f\u60c5\u5883\u4e0b\u7684\u81ea\u9002\u5e94\u6027\u6700\u4f18\u754c\u9650\uff0c\u6269\u5c55\u4e86IDS\u7684\u7406\u8bba\u4fdd\u969c\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u7a00\u758f\u5728\u7ebf\u51b3\u7b56\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b2c\u4e00\u7684\u7eaf\u6700\u574f\u60c5\u5883\u4e0b\u7684\u6700\u4f18\u89e3\u3002"}}
{"id": "2510.24235", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24235", "abs": "https://arxiv.org/abs/2510.24235", "authors": ["Ai Jian", "Jingqing Ruan", "Xing Ma", "Dailin Li", "QianLin Zhou", "Ke Zeng", "Xunliang Cai"], "title": "PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling", "comment": null, "summary": "Reward models (RMs) are central to reinforcement learning from human feedback\n(RLHF), providing the critical supervision signals that align large language\nmodels (LLMs) with human preferences. While generative reward models (GRMs)\noffer greater interpretability than traditional scalar RMs, current training\nparadigms remain limited. Pair-wise methods rely on binary good-versus-bad\nlabels, which cause mismatches for point-wise inference and necessitate complex\npairing strategies for effective application in RLHF. On the other hand,\npoint-wise methods require more elaborate absolute labeling with rubric-driven\ncriteria, resulting in poor adaptability and high annotation costs. In this\nwork, we propose the Preference-Aware Task-Adaptive Reward Model (PaTaRM), a\nunified framework that integrates a preference-aware reward (PAR) mechanism\nwith dynamic rubric adaptation. PaTaRM leverages relative preference\ninformation from pairwise data to construct robust point-wise training signals,\neliminating the need for explicit point-wise labels. Simultaneously, it employs\na task-adaptive rubric system that flexibly generates evaluation criteria for\nboth global task consistency and instance-specific fine-grained reasoning. This\ndesign enables efficient, generalizable, and interpretable reward modeling for\nRLHF. Extensive experiments show that PaTaRM achieves an average relative\nimprovement of 4.7% on RewardBench and RMBench across Qwen3-8B and Qwen3-14B\nmodels. Furthermore, PaTaRM boosts downstream RLHF performance, with an average\nimprovement of 13.6% across IFEval and InFoBench benchmarks, confirming its\neffectiveness and robustness. Our code is available at\nhttps://github.com/JaneEyre0530/PaTaRM.", "AI": {"tldr": "PaTaRM\u5c06\u504f\u597d\u611f\u77e5\u7684\u4efb\u52a1\u81ea\u9002\u5e94\u5956\u52b1\u6a21\u578b\u7528\u4e8eRLHF\uff1a\u901a\u8fc7PAR\u5c06\u6210\u5bf9\u504f\u597d\u8f6c\u5316\u4e3a\u70b9\u7ea7\u4fe1\u53f7\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u8bc4\u91cf\u6807\u5c3a\u5b9e\u73b0\u5168\u5c40\u4efb\u52a1\u4e00\u81f4\u6027\u4e0e\u5b9e\u4f8b\u7ea7\u63a8\u7406\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u9ad8\u6548\u3001\u53ef\u6cdb\u5316\u4e14\u53ef\u89e3\u91ca\u7684\u5956\u52b1\u5efa\u6a21\uff0c\u63d0\u5347RLHF\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5956\u52b1\u6a21\u578b\u5206\u4e3a\u6210\u5bf9\uff08pairwise\uff09\u548c\u70b9\u5bf9\uff08point-wise\uff09\u4e24\u7c7b\uff0c\u5404\u81ea\u5b58\u5728\u6807\u6ce8\u548c\u5bf9\u9f50\u95ee\u9898\uff0c\u96be\u4ee5\u5728RLHF\u4e2d\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u5730\u5e94\u7528\u3002\u9700\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u540c\u65f6\u5229\u7528\u5bf9\u504f\u597d\u4fe1\u606f\u5e76\u63d0\u4f9b\u53ef\u8c03\u6574\u7684\u8bc4\u4f30\u51c6\u5219\u6765\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u5e76\u63d0\u5347\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faPaTaRM\u6846\u67b6\uff1a\u5305\u542b\u504f\u597d\u611f\u77e5\u5956\u52b1\uff08PAR\uff09\u673a\u5236\uff0c\u7528\u6210\u5bf9\u6570\u636e\u4e2d\u7684\u76f8\u5bf9\u504f\u597d\u6765\u6784\u5efa\u7a33\u5065\u7684\u70b9\u7ea7\u8bad\u7ec3\u4fe1\u53f7\uff1b\u4ee5\u53ca\u4efb\u52a1\u81ea\u9002\u5e94\u8bc4\u5c3a\u7cfb\u7edf\uff0c\u80fd\u591f\u4e3a\u5168\u5c40\u4efb\u52a1\u4e00\u81f4\u6027\u548c\u5b9e\u4f8b\u7ea7\u7ec6\u7c92\u5ea6\u63a8\u7406\u751f\u6210\u8bc4\u4f30\u6807\u51c6\u3002\u4e24\u8005\u7ed3\u5408\u5f62\u6210\u7edf\u4e00\u7684GRM\u4ee5\u7528\u4e8eRLHF\u8bad\u7ec3\u3002", "result": "\u5728RewardBench\u4e0eRMBench\u4e0a\uff0c\u5bf9Qwen3-8B\u4e0eQwen3-14B\u6a21\u578b\u7684\u76f8\u5bf9\u6539\u8fdb\u5e73\u5747\u4e3a4.7%\uff1b\u5728IFEval\u4e0eInFoBench\u7684\u4e0b\u6e38RLHF\u4efb\u52a1\u4e2d\u5e73\u5747\u63d0\u534713.6%\u3002\u4ee3\u7801\u5f00\u6e90\u3002", "conclusion": "PaTaRM\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u53ef\u6cdb\u5316\u4e14\u53ef\u89e3\u91ca\u7684RLHF\u5956\u52b1\u5efa\u6a21\uff0c\u80fd\u591f\u5728\u4e0d\u540c\u6a21\u578b\u4e0e\u57fa\u51c6\u4e0a\u8868\u73b0\u7a33\u5065\uff0c\u964d\u4f4e\u5bf9\u663e\u5f0f\u70b9\u7ea7\u6807\u7b7e\u7684\u4f9d\u8d56\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30Rubric\u3002"}}
{"id": "2510.24240", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24240", "abs": "https://arxiv.org/abs/2510.24240", "authors": ["Edward Markai", "Sina Molavipour"], "title": "Temporal Knowledge Graph Hyperedge Forecasting: Exploring Entity-to-Category Link Prediction", "comment": null, "summary": "Temporal Knowledge Graphs have emerged as a powerful way of not only modeling\nstatic relationships between entities but also the dynamics of how relations\nevolve over time. As these informational structures can be used to store\ninformation from a real-world setting, such as a news flow, predicting future\ngraph components to a certain extent equates predicting real-world events. Most\nof the research in this field focuses on embedding-based methods, often\nleveraging convolutional neural net architectures. These solutions act as black\nboxes, limiting insight. In this paper, we explore an extension to an\nestablished rule-based framework, TLogic, that yields a high accuracy in\ncombination with explainable predictions. This offers transparency and allows\nthe end-user to critically evaluate the rules applied at the end of the\nprediction stage. The new rule format incorporates entity category as a key\ncomponent with the purpose of limiting rule application only to relevant\nentities. When categories are unknown for building the graph, we propose a\ndata-driven method to generate them with an LLM-based approach. Additionally,\nwe investigate the choice of aggregation method for scores of retrieved\nentities when performing category prediction.", "AI": {"tldr": "\u5c06\u5b9e\u4f53\u7c7b\u522b\u5f15\u5165 TLogic \u7684\u89c4\u5219\u6269\u5c55\u4ee5\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u548c\u51c6\u786e\u6027\uff1b\u5728\u7c7b\u522b\u672a\u77e5\u65f6\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff08LLM\uff09\u751f\u6210\u7c7b\u522b\uff0c\u5e76\u8bc4\u4f30\u68c0\u7d22\u5206\u6570\u7684\u805a\u5408\u65b9\u6cd5\u5bf9\u7c7b\u522b\u9884\u6d4b\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u591a\u4fa7\u91cd\u5d4c\u5165\u5f0f\u65b9\u6cd5\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002\u5f15\u5165\u89c4\u5219\u5316\u6846\u67b6\u5e76\u4ee5\u7c7b\u522b\u7ea6\u675f\u89c4\u5219\u5e94\u7528\uff0c\u53ef\u63d0\u5347\u900f\u660e\u5ea6\u4e0e\u53ef\u8bc4\u4f30\u6027\uff1b\u5728\u7c7b\u522b\u672a\u77e5\u573a\u666f\u63d0\u4f9b\u6570\u636e\u9a71\u52a8\u7684\u7c7b\u522b\u751f\u6210\u4ee5\u6269\u5c55\u9002\u7528\u6027\u3002", "method": "\u5728 TLogic \u4e2d\u65b0\u589e\u4ee5\u5b9e\u4f53\u7c7b\u522b\u4e3a\u5173\u952e\u53c2\u6570\u7684\u89c4\u5219\u683c\u5f0f\uff0c\u9650\u5b9a\u89c4\u5219\u4ec5\u5bf9\u76f8\u5173\u5b9e\u4f53\u751f\u6548\uff1b\u82e5\u7c7b\u522b\u672a\u77e5\uff0c\u901a\u8fc7\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u751f\u6210\u7c7b\u522b\uff1b\u7814\u7a76\u5e76\u6bd4\u8f83\u7528\u4e8e\u6c47\u805a\u68c0\u7d22\u5230\u7684\u5b9e\u4f53\u5206\u6570\u7684\u4e0d\u540c\u805a\u5408\u7b56\u7565\u5bf9\u7c7b\u522b\u9884\u6d4b\u7684\u5f71\u54cd\u3002", "result": "\u7406\u8bba\u4e0a\u5b9e\u73b0\u9ad8\u51c6\u786e\u6027\u4e0e\u53ef\u89e3\u91ca\u7684\u9884\u6d4b\uff0c\u63d0\u5347\u89c4\u5219\u900f\u660e\u5ea6\uff0c\u6700\u7ec8\u7528\u6237\u80fd\u591f\u5728\u9884\u6d4b\u9636\u6bb5\u8bc4\u4f30\u6240\u5e94\u7528\u7684\u89c4\u5219\uff1b\u5728\u7c7b\u522b\u9a71\u52a8\u4e0b\u89c4\u5219\u5e94\u7528\u66f4\u805a\u7126\u76f8\u5173\u5b9e\u4f53\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7c7b\u522b\u6574\u5408\u5230 TLogic \u7684\u6269\u5c55\u63d0\u5347\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u6027\u80fd\uff0cLLM \u9a71\u52a8\u7684\u7c7b\u522b\u751f\u6210\u4ee5\u53ca\u805a\u5408\u7b56\u7565\u7684\u63a2\u7d22\u4e3a\u53ef\u89e3\u91ca\u7684\u77e5\u8bc6\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u65b9\u5411\u3002"}}
{"id": "2510.24273", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24273", "abs": "https://arxiv.org/abs/2510.24273", "authors": ["Junlin Mu", "Hantao Huang", "Jihang Zhang", "Minghui Yu", "Tao Wang", "Yidong Li"], "title": "SALS: Sparse Attention in Latent Space for KV cache Compression", "comment": null, "summary": "Large Language Models capable of handling extended contexts are in high\ndemand, yet their inference remains challenging due to substantial Key-Value\ncache size and high memory bandwidth requirements. Previous research has\ndemonstrated that KV cache exhibits low-rank characteristics within the hidden\ndimension, suggesting the potential for effective compression. However, due to\nthe widely adopted Rotary Position Embedding mechanism in modern LLMs, naive\nlow-rank compression suffers severe accuracy degradation or creates a new speed\nbottleneck, as the low-rank cache must first be reconstructed in order to apply\nRoPE. In this paper, we introduce two key insights: first, the application of\nRoPE to the key vectors increases their variance, which in turn results in a\nhigher rank; second, after the key vectors are transformed into the latent\nspace, they largely maintain their representation across most layers. Based on\nthese insights, we propose the Sparse Attention in Latent Space framework. SALS\nprojects the KV cache into a compact latent space via low-rank projection, and\nperforms sparse token selection using RoPE-free query-key interactions in this\nspace. By reconstructing only a small subset of important tokens, it avoids the\noverhead of full KV cache reconstruction. We comprehensively evaluate SALS on\nvarious tasks using two large-scale models: LLaMA2-7b-chat and Mistral-7b, and\nadditionally verify its scalability on the RULER-128k benchmark with\nLLaMA3.1-8B-Instruct. Experimental results demonstrate that SALS achieves SOTA\nperformance by maintaining competitive accuracy. Under different settings, SALS\nachieves 6.4-fold KV cache compression and 5.7-fold speed-up in the attention\noperator compared to FlashAttention2 on the 4K sequence. For the end-to-end\nthroughput performance, we achieves 1.4-fold and 4.5-fold improvement compared\nto GPT-fast on 4k and 32K sequences, respectively.", "AI": {"tldr": "SALS introduces sparse attention in latent space to compress KV cache and accelerate attention without full cache reconstruction, achieving substantial compression and speedups while maintaining accuracy.", "motivation": "Long-context LLMs demand large KV caches, but their inference is bottlenecked by memory and bandwidth. RoPE-based low-rank compression fails due to increased variance and the need to reconstruct for RoPE. A latent-space sparse approach can reduce KV footprint without RoPE overhead.", "method": "Two key insights: (1) RoPE increases variance and rank of key vectors; (2) transformed key vectors preserve representations across many layers in latent space. SALS projects KV cache into a compact latent space via low-rank projection, and performs sparse token selection using RoPE-free query-key interactions in this space. Only a subset of important tokens are reconstructed, avoiding full KV cache reconstruction. ", "result": "Empirical evaluation on LLaMA2-7b-chat and Mistral-7b; scalable to RULER-128k with LLaMA3.1-8B-Instruct. SALS achieves state-of-the-art performance with competitive accuracy, 6.4x KV cache compression, 5.7x speed-up in attention vs FlashAttention2 on 4K sequences, and end-to-end throughput improvements of 1.4x and 4.5x vs GPT-fast on 4K and 32K sequences respectively.", "conclusion": "SALS effectively reduces KV cache size and speeds up attention with minimal accuracy loss, and scales to very long contexts, offering practical benefits for deploying long-context LLMs."}}
{"id": "2510.24310", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24310", "abs": "https://arxiv.org/abs/2510.24310", "authors": ["Guus Toussaint", "Arno Knobbe"], "title": "EDC: Equation Discovery for Classification", "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in Lecture Notes in Computer Science, and is available online at\n  https://doi.org/10.1007/978-3-032-05461-6_9", "summary": "Equation Discovery techniques have shown considerable success in regression\ntasks, where they are used to discover concise and interpretable models\n(\\textit{Symbolic Regression}). In this paper, we propose a new ED-based binary\nclassification framework. Our proposed method EDC finds analytical functions of\nmanageable size that specify the location and shape of the decision boundary.\nIn extensive experiments on artificial and real-life data, we demonstrate how\nEDC is able to discover both the structure of the target equation as well as\nthe value of its parameters, outperforming the current state-of-the-art\nED-based classification methods in binary classification and achieving\nperformance comparable to the state of the art in binary classification. We\nsuggest a grammar of modest complexity that appears to work well on the tested\ndatasets but argue that the exact grammar -- and thus the complexity of the\nmodels -- is configurable, and especially domain-specific expressions can be\nincluded in the pattern language, where that is required. The presented grammar\nconsists of a series of summands (additive terms) that include linear,\nquadratic and exponential terms, as well as products of two features (producing\nhyperbolic curves ideal for capturing XOR-like dependencies). The experiments\ndemonstrate that this grammar allows fairly flexible decision boundaries while\nnot so rich to cause overfitting.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u65b9\u7a0b\u53d1\u73b0\uff08Equation Discovery\uff09\u7684\u4e8c\u5206\u7c7b\u6846\u67b6 EDC\uff0c\u901a\u8fc7\u53d1\u73b0\u53ef\u7ba1\u7406\u89c4\u6a21\u7684\u89e3\u6790\u51fd\u6570\u6765\u754c\u5b9a\u51b3\u7b56\u8fb9\u754c\u7684\u5f62\u72b6\u4e0e\u4f4d\u7f6e\u3002\u5b9e\u9a8c\u8bc1\u660e EDC \u5728\u4e8c\u5206\u7c7b\u7684 ED \u57fa\u65b9\u6cd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u6027\u80fd\u76f8\u5f53\uff1b\u6240\u7ed9\u8bed\u6cd5\u5141\u8bb8\u7075\u6d3b\u4f46\u4e0d\u8fc7\u62df\u5408\u7684\u8fb9\u754c\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u7b26\u53f7\u56de\u5f52\u6846\u67b6\u6765\u5b66\u4e60\u4e8c\u5206\u7c7b\u8fb9\u754c\uff0c\u65e2\u80fd\u81ea\u52a8\u53d1\u73b0\u76ee\u6807\u65b9\u7a0b\u7684\u7ed3\u6784\uff0c\u53c8\u80fd\u4f30\u8ba1\u5176\u53c2\u6570\uff0c\u4ece\u800c\u5f97\u5230\u53ef\u89e3\u91ca\u4e14\u5177\u6709\u63a7\u5236\u590d\u6742\u5ea6\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51fa EDC \u65b9\u6cd5\uff0c\u5229\u7528\u4e00\u4e2a modest complexity \u7684\u6587\u6cd5\u6765\u751f\u6210\u51b3\u7b56\u8fb9\u754c\u7684\u89e3\u6790\u51fd\u6570\uff0c\u8be5\u6587\u6cd5\u5305\u542b\u7ebf\u6027\u3001\u4e8c\u6b21\u3001\u6307\u6570\u9879\u4ee5\u53ca\u4e24\u4e2a\u7279\u5f81\u7684\u4e58\u79ef\uff08\u53ef\u6355\u6349 XOR \u4e4b\u7c7b\u7684\u4f9d\u8d56\uff09\uff0c\u4ee5\u83b7\u5f97\u53ef\u7ba1\u7406\u5927\u5c0f\u7684\u8fb9\u754c\u3002\u6a21\u578b\u540c\u65f6\u5b66\u4e60\u8fb9\u754c\u7684\u7ed3\u6784\u4e0e\u53c2\u6570\u3002", "result": "\u5728\u4eba\u5de5\u4e0e\u771f\u5b9e\u6570\u636e\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cEDC \u80fd\u540c\u65f6\u53d1\u73b0\u76ee\u6807\u65b9\u7a0b\u7684\u7ed3\u6784\u4e0e\u53c2\u6570\uff1b\u76f8\u8f83\u4e8e\u5f53\u524d\u7684\u57fa\u4e8e ED \u7684\u5206\u7c7b\u65b9\u6cd5\uff0cEDC \u5728\u4e8c\u5206\u7c7b\u4efb\u52a1\u4e0a\u5b9e\u73b0\u66f4\u597d\u7684\u8868\u73b0\uff0c\u5e76\u5728\u603b\u4f53\u4e0a\u8fbe\u5230\u4e0e\u6700\u5148\u8fdb\u4e8c\u5206\u7c7b\u65b9\u6cd5\u7684\u6027\u80fd\u63a5\u8fd1\u7684\u6c34\u5e73\uff1b\u6587\u6cd5\u8bbe\u8ba1\u4f7f\u8fb9\u754c\u5177\u6709\u8f83\u9ad8\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u540c\u65f6\u4e0d\u8fc7\u62df\u5408\u3002", "conclusion": "\u7ed9\u5b9a\u7684\u4e2d\u7b49\u590d\u6742\u5ea6\u6587\u6cd5\u5728\u5b9e\u73b0\u53ef\u89e3\u91ca\u4e14\u7075\u6d3b\u7684\u8fb9\u754c\u65b9\u9762\u6709\u6548\uff0c\u4e14\u5141\u8bb8\u5f15\u5165\u9886\u57df\u7279\u5b9a\u8868\u8fbe\u4ee5\u9002\u5e94\u7279\u5b9a\u4efb\u52a1\uff1b\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5728\u53ef\u63a7\u590d\u6742\u5ea6\u4e0b\u901a\u8fc7\u7b26\u53f7\u56de\u5f52\u5b9e\u73b0\u53ef\u89e3\u91ca\u4e8c\u5206\u7c7b\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.24318", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24318", "abs": "https://arxiv.org/abs/2510.24318", "authors": ["Prajit Bhaskaran", "Tom Viering"], "title": "Transformers can do Bayesian Clustering", "comment": null, "summary": "Bayesian clustering accounts for uncertainty but is computationally demanding\nat scale. Furthermore, real-world datasets often contain missing values, and\nsimple imputation ignores the associated uncertainty, resulting in suboptimal\nresults. We present Cluster-PFN, a Transformer-based model that extends\nPrior-Data Fitted Networks (PFNs) to unsupervised Bayesian clustering. Trained\nentirely on synthetic datasets generated from a finite Gaussian Mixture Model\n(GMM) prior, Cluster-PFN learns to estimate the posterior distribution over\nboth the number of clusters and the cluster assignments. Our method estimates\nthe number of clusters more accurately than handcrafted model selection\nprocedures such as AIC, BIC and Variational Inference (VI), and achieves\nclustering quality competitive with VI while being orders of magnitude faster.\nCluster-PFN can be trained on complex priors that include missing data,\noutperforming imputation-based baselines on real-world genomic datasets, at\nhigh missingness. These results show that the Cluster-PFN can provide scalable\nand flexible Bayesian clustering.", "AI": {"tldr": "\u63d0\u51fa\u4e86 Cluster-PFN\uff0c\u4e00\u79cd\u57fa\u4e8e Transformer \u7684\u65e0\u76d1\u7763\u8d1d\u53f6\u65af\u805a\u7c7b\u6a21\u578b\uff0c\u6269\u5c55\u4e86 PFN \u6846\u67b6\u4ee5\u8fdb\u884c\u8d1d\u53f6\u65af\u805a\u7c7b\u3002\u901a\u8fc7\u5bf9\u6765\u81ea\u6709\u9650\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u5148\u9a8c\u7684\u5408\u6210\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u80fd\u591f\u4f30\u8ba1\u805a\u7c7b\u6570\u548c\u7c07\u5206\u914d\u7684\u540e\u9a8c\u3002\u76f8\u6bd4 AIC\u3001BIC\u3001\u53d8\u5206\u63a8\u65ad\uff08VI\uff09\u7b49\u624b\u5de5\u6a21\u578b\u9009\u62e9\uff0c\u805a\u7c7b\u6570\u4f30\u8ba1\u66f4\u51c6\u786e\uff0c\u805a\u7c7b\u8d28\u91cf\u4e0e VI \u76f8\u5f53\uff0c\u4f46\u901f\u5ea6\u5feb\u51fa\u82e5\u5e72\u6570\u91cf\u7ea7\uff1b\u5728\u9ad8\u7f3a\u5931\u6570\u636e\u7684\u73b0\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u5148\u9a8c\u5e76\u4f18\u4e8e\u57fa\u4e8e imputation \u7684\u65b9\u6cd5\u3002", "motivation": "\u8d1d\u53f6\u65af\u805a\u7c7b\u867d\u7136\u80fd\u5f88\u597d\u5730\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u8ba1\u7b97\u6210\u672c\u9ad8\uff1b\u73b0\u5b9e\u6570\u636e\u5e38\u6709\u7f3a\u5931\u503c\uff0c\u7b80\u5355\u586b\u5145\u5ffd\u7565\u4e0d\u786e\u5b9a\u6027\uff0c\u5bfc\u81f4 suboptimal \u7ed3\u679c\u3002\u9700\u8981\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u7075\u6d3b\u7684\u8d1d\u53f6\u65af\u805a\u7c7b\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u7f3a\u5931\u6570\u636e\u53ca\u5176\u4e0d\u786e\u5b9a\u6027\u3002", "method": "Cluster-PFN \u5c06 Prior-Data Fitted Networks\uff08PFN\uff09\u6269\u5c55\u5230\u65e0\u76d1\u7763\u8d1d\u53f6\u65af\u805a\u7c7b\u3002\u6a21\u578b\u5728\u6765\u81ea\u6709\u9650\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u5148\u9a8c\u7684\u5408\u6210\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5b66\u4e60\u76ee\u6807\u662f\u540e\u9a8c\u5206\u5e03\uff1a\u7c07\u7684\u6570\u91cf\u4ee5\u53ca\u6bcf\u4e2a\u6837\u672c\u7684\u7c07\u5206\u914d\u3002", "result": "\u5728\u805a\u7c7b\u6570\u4f30\u8ba1\u65b9\u9762\u4f18\u4e8e AIC\u3001BIC\u3001VI \u7b49\u624b\u5de5\u6a21\u578b\u9009\u62e9\uff1b\u805a\u7c7b\u8d28\u91cf\u4e0e VI \u76f8\u5f53\uff0c\u540c\u65f6\u5728\u901f\u5ea6\u4e0a\u5feb\u51fa\u82e5\u5e72\u6570\u91cf\u7ea7\uff1b\u5728\u542b\u7f3a\u5931\u6570\u636e\u7684\u590d\u6742\u5148\u9a8c\u4e0b\uff0c\u80fd\u8d85\u8d8a\u57fa\u4e8e imputation \u7684\u57fa\u7ebf\uff0c\u4e14\u5728\u771f\u5b9e\u57fa\u56e0\u7ec4\u6570\u636e\u96c6\u4e0a\u5f62\u6210\u9ad8\u7f3a\u5931\u7387\u573a\u666f\u7684\u4f18\u52bf\u3002", "conclusion": "Cluster-PFN \u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u7075\u6d3b\u7684\u8d1d\u53f6\u65af\u805a\u7c7b\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u5148\u9a8c\uff08\u5305\u62ec\u7f3a\u5931\u6570\u636e\uff09\uff0c\u5728\u65e0\u76d1\u7763\u8d1d\u53f6\u65af\u805a\u7c7b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u6027\u80fd\u3002"}}
{"id": "2510.24331", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24331", "abs": "https://arxiv.org/abs/2510.24331", "authors": ["Gabriel O. dos Santos", "Esther Colombini", "Sandra Avila"], "title": "What do vision-language models see in the context? Investigating multimodal in-context learning", "comment": null, "summary": "In-context learning (ICL) enables Large Language Models (LLMs) to learn tasks\nfrom demonstration examples without parameter updates. Although it has been\nextensively studied in LLMs, its effectiveness in Vision-Language Models (VLMs)\nremains underexplored. In this work, we present a systematic study of ICL in\nVLMs, evaluating seven models spanning four architectures on three image\ncaptioning benchmarks. We analyze how prompt design, architectural choices, and\ntraining strategies influence multimodal ICL. To our knowledge, we are the\nfirst to analyze how attention patterns in VLMs vary with an increasing number\nof in-context demonstrations. Our results reveal that training on imag-text\ninterleaved data enhances ICL performance but does not imply effective\nintegration of visual and textual information from demonstration examples. In\ncontrast, instruction tuning improves instruction-following but can reduce\nreliance on in-context demonstrations, suggesting a trade-off between\ninstruction alignment and in-context adaptation. Attention analyses further\nshow that current VLMs primarily focus on textual cues and fail to leverage\nvisual information, suggesting a limited capacity for multimodal integration.\nThese findings highlight key limitations in the ICL abilities of current VLMs\nand provide insights for enhancing their ability to learn from multimodal\nin-context examples.", "AI": {"tldr": "\u5728\u591a\u6a21\u6001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u7684\u4e0a\u4e0b\u6587\u4e2d\u5b66\u4e60\uff08ICL\uff09\u80fd\u529b\u6709\u9650\u4e14\u6613\u53d7\u8bad\u7ec3\u6570\u636e\u3001\u63d0\u793a\u8bbe\u8ba1\u3001\u67b6\u6784\u4e0e\u8bad\u7ec3\u7b56\u7565\u5f71\u54cd\u3002\u5f53\u524dVLM\u5bf9\u89c6\u89c9\u4fe1\u606f\u7684\u5229\u7528\u4e0d\u8db3\uff0c\u66f4\u591a\u4f9d\u8d56\u6587\u672c\u7ebf\u7d22\uff1b\u9700\u6539\u8fdb\u5bf9\u89c6\u89c9-\u6587\u672c\u7684\u8026\u5408\u4ee5\u63d0\u5347\u4ece\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u80fd\u529b\u3002", "motivation": "\u63a2\u7d22\u5728Vision-Language Models\u4e2d\u662f\u5426\u5b58\u5728\u7c7b\u4f3c\u4e8eLLMs\u7684\u5c31\u5730\u5b66\u4e60\u80fd\u529b\uff08ICL\uff09\uff0c\u4ee5\u53ca\u54ea\u4e9b\u56e0\u7d20\u5f71\u54cd\u5176\u6709\u6548\u6027\uff0c\u4ece\u800c\u5f25\u8865\u5bf9VLM ICL\u7684\u7814\u7a76\u7a7a\u7f3a\u3002", "method": "\u5bf9\u4e03\u4e2a\u6a21\u578b\u3001\u56db\u79cd\u67b6\u6784\u3001\u4e09\u4e2a\u56fe\u50cf\u5b57\u5e55\u57fa\u51c6\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff1b\u5206\u6790\u63d0\u793a\u8bbe\u8ba1\u3001\u67b6\u6784\u9009\u62e9\u548c\u8bad\u7ec3\u7b56\u7565\u5bf9\u591a\u6a21\u6001ICL\u7684\u5f71\u54cd\uff1b\u9996\u6b21\u5206\u6790\u968f\u7740\u6f14\u793a\u793a\u4f8b\u589e\u52a0\uff0cVLM\u4e2d\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\uff1b\u6bd4\u8f83\u4f7f\u7528imag-text interleaved\u6570\u636e\u7684\u8bad\u7ec3\u548cinstruction tuning\u5bf9ICL\u80fd\u529b\u7684\u5f71\u54cd\u3002", "result": "\u8bad\u7ec3\u5728imag-text\u4ea4\u9519\u6570\u636e\u4e0a\u7684\u6a21\u578b\u63d0\u5347\u4e86ICL\u6027\u80fd\uff0c\u4f46\u672a\u6709\u6548\u5b9e\u73b0\u6f14\u793a\u793a\u4f8b\u4e2d\u7684\u89c6\u89c9\u4fe1\u606f\u4e0e\u6587\u672c\u4fe1\u606f\u7684\u878d\u5408\uff1binstruction tuning\u63d0\u5347\u4e86\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u4f46\u964d\u4f4e\u4e86\u5bf9\u4e0a\u4e0b\u6587\u6f14\u793a\u7684\u4f9d\u8d56\uff0c\u8868\u660e\u6307\u4ee4\u5bf9\u9f50\u4e0e\u5728-context\u81ea\u9002\u5e94\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff1b\u6ce8\u610f\u529b\u5206\u6790\u663e\u793a\u5f53\u524dVLM\u4e3b\u8981\u5173\u6ce8\u6587\u672c\u7ebf\u7d22\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u89c6\u89c9\u4fe1\u606f\uff0c\u663e\u793a\u73b0\u6709VLM\u7684\u591a\u6a21\u6001\u6574\u5408\u80fd\u529b\u6709\u9650\u3002", "conclusion": "\u63ed\u793a\u4e86\u5f53\u524dVLM\u5728ICL\u4e2d\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u6539\u8fdb\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u65b9\u5411\uff0c\u5982\u52a0\u5f3a\u89c6\u89c9\u4e0e\u6587\u672c\u4fe1\u606f\u7684\u8026\u5408\u3001\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u591a\u6a21\u6001\u63d0\u793a\uff0c\u4ee5\u53ca\u5728\u6307\u4ee4\u5bf9\u9f50\u4e0eICL\u81ea\u9002\u5e94\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002"}}
{"id": "2510.24356", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.24356", "abs": "https://arxiv.org/abs/2510.24356", "authors": ["Suman Sanyal"], "title": "Perception Learning: A Formal Separation of Sensory Representation Learning from Decision Learning", "comment": null, "summary": "We introduce Perception Learning (PeL), a paradigm that optimizes an agent's\nsensory interface $f_\\phi:\\mathcal{X}\\to\\mathcal{Z}$ using task-agnostic\nsignals, decoupled from downstream decision learning\n$g_\\theta:\\mathcal{Z}\\to\\mathcal{Y}$. PeL directly targets label-free\nperceptual properties, such as stability to nuisances, informativeness without\ncollapse, and controlled geometry, assessed via objective\nrepresentation-invariant metrics. We formalize the separation of perception and\ndecision, define perceptual properties independent of objectives or\nreparameterizations, and prove that PeL updates preserving sufficient\ninvariants are orthogonal to Bayes task-risk gradients. Additionally, we\nprovide a suite of task-agnostic evaluation metrics to certify perceptual\nquality.", "AI": {"tldr": "PeL\u901a\u8fc7\u4e0e\u4efb\u52a1\u65e0\u5173\u7684\u611f\u77e5\u4fe1\u53f7\u6765\u4f18\u5316\u611f\u77e5\u63a5\u53e3\uff0c\u5b9e\u73b0\u5728\u51b3\u7b56\u4e0e\u611f\u77e5\u89e3\u8026\uff0c\u5f3a\u8c03\u7a33\u5b9a\u6027\u3001\u4fe1\u606f\u6027\u4e0e\u51e0\u4f55\u53d7\u63a7\u7684\u65e0\u6807\u7b7e\u611f\u77e5\u5c5e\u6027\uff0c\u5e76\u63d0\u4f9b\u4e00\u5957\u4efb\u52a1\u65e0\u5173\u7684\u8bc4\u4ef7\u6307\u6807\u3002", "motivation": "\u5f53\u524d\u5b66\u4e60\u7cfb\u7edf\u5f80\u5f80\u5c06\u611f\u77e5\u548c\u51b3\u7b56\u7ed1\u5b9a\u5728\u4e00\u8d77\uff0c\u4f9d\u8d56\u5e26\u6807\u7b7e\u7684\u4e0b\u6e38\u4efb\u52a1\u3002\u63d0\u51fa\u5206\u79bb\u611f\u77e5\u4e0e\u51b3\u7b56\uff0c\u4e13\u6ce8\u4e8e\u53ef\u9a8c\u8bc1\u7684\u611f\u77e5\u6027\u8d28\uff0c\u4ee5\u63d0\u9ad8\u9c81\u68d2\u6027\u3001\u53ef\u79fb\u690d\u6027\u548c\u6cdb\u5316\u6027\uff1b\u5e0c\u671b\u901a\u8fc7\u4e0d\u6539\u53d8\u4efb\u52a1\u76ee\u6807\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u611f\u77e5\u8d28\u91cf\u3002", "method": "\u4f18\u5316\u611f\u77e5\u63a5\u53e3f_phi(X)->Z\uff0c\u4f7f\u7528\u4efb\u52a1\u65e0\u5173\u4fe1\u53f7\u8fdb\u884c\u66f4\u65b0\uff0c\u4e0e\u4e0b\u6e38\u51b3\u7b56g_theta(Z)->Y\u89e3\u8026\u3002\u5b9a\u4e49\u5e76\u8ffd\u8e2a\u611f\u77e5\u5c5e\u6027\uff08\u5bf9\u5e72\u6270\u7684\u7a33\u5b9a\u6027\u3001\u4fe1\u606f\u542b\u91cf\u3001\u53d7\u63a7\u51e0\u4f55\u6027\uff09\uff0c\u901a\u8fc7\u76ee\u6807\u8868\u793a\u4e0d\u53d8\u6027\u5ea6\u91cf\u6765\u8bc4\u4f30\u3002 formalize separation; \u8bc1\u660e\u4fdd\u7559\u5145\u5206\u4e0d\u53d8\u91cf\u7684\u66f4\u65b0\u4e0e\u8d1d\u53f6\u65af\u4efb\u52a1\u98ce\u9669\u68af\u5ea6\u6b63\u4ea4\uff1b\u63d0\u4f9b\u4e00\u7ec4\u4efb\u52a1\u65e0\u5173\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u7406\u8bba\u5c42\u9762\u7ed9\u51fa\u5206\u79bb\u6846\u67b6\u4e0e\u4e0d\u53d8\u91cf\u66f4\u65b0\u7684\u6b63\u4ea4\u6027\u8bc1\u660e\uff0c\u4ee5\u53ca\u4e00\u5957\u7528\u4e8e\u8bc1\u660e\u611f\u77e5\u8d28\u91cf\u7684\u4efb\u52a1\u65e0\u5173\u8bc4\u4f30\u6307\u6807\u3002\u7ed3\u679c\u66f4\u504f\u7406\u8bba\u4e0e\u65b9\u6cd5\u8bba\uff0c\u5c1a\u5f85\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "conclusion": "PeL\u63d0\u4f9b\u4e00\u4e2a\u660e\u786e\u7684\u611f\u77e5-\u51b3\u7b56\u5206\u79bb\u6846\u67b6\uff0c\u5f3a\u8c03\u4ee5\u65e0\u6807\u7b7e\u611f\u77e5\u5c5e\u6027\u6765\u63d0\u5347\u611f\u77e5\u8d28\u91cf\u53ca downstream \u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u7ed9\u51fa\u53ef\u7528\u4e8e\u9a8c\u8bc1\u611f\u77e5\u8d28\u91cf\u7684\u5b9e\u9645\u5de5\u5177\u96c6\uff0c\u5177\u6709\u9c81\u68d2\u6027\u548c\u53ef\u79fb\u690d\u6027\u6f5c\u529b\u3002"}}
{"id": "2510.24368", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24368", "abs": "https://arxiv.org/abs/2510.24368", "authors": ["Maria Gabriela Valeriano", "David Kohan Marzag\u00e3o", "Alfredo Montelongo", "Carlos Roberto Veiga Kiffer", "Natan Katz", "Ana Carolina Lorena"], "title": "Filtering instances and rejecting predictions to obtain reliable models in healthcare", "comment": "This paper is under review at Machine Learning (Springer)", "summary": "Machine Learning (ML) models are widely used in high-stakes domains such as\nhealthcare, where the reliability of predictions is critical. However, these\nmodels often fail to account for uncertainty, providing predictions even with\nlow confidence. This work proposes a novel two-step data-centric approach to\nenhance the performance of ML models by improving data quality and filtering\nlow-confidence predictions. The first step involves leveraging Instance\nHardness (IH) to filter problematic instances during training, thereby refining\nthe dataset. The second step introduces a confidence-based rejection mechanism\nduring inference, ensuring that only reliable predictions are retained. We\nevaluate our approach using three real-world healthcare datasets, demonstrating\nits effectiveness at improving model reliability while balancing predictive\nperformance and rejection rate. Additionally, we use alternative criteria -\ninfluence values for filtering and uncertainty for rejection - as baselines to\nevaluate the efficiency of the proposed method. The results demonstrate that\nintegrating IH filtering with confidence-based rejection effectively enhances\nmodel performance while preserving a large proportion of instances. This\napproach provides a practical method for deploying ML systems in\nsafety-critical applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4e24\u6b65\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff1a\u5728\u8bad\u7ec3\u9636\u6bb5\u5229\u7528\u5b9e\u4f8b\u96be\u5ea6(IH)\u7b5b\u9009\u5e76\u51c0\u5316\u6570\u636e\uff0c\u5728\u63a8\u65ad\u9636\u6bb5\u901a\u8fc7\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u62d2\u7edd\u673a\u5236\u53ea\u4fdd\u7559\u9ad8\u7f6e\u4fe1\u9884\u6d4b\u3002\u7ed3\u5408\u4e09\u7ec4\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u7684\u8bc4\u4f30\uff0c\u5c55\u793a\u5728\u63d0\u5347\u6a21\u578b\u53ef\u9760\u6027\u7684\u540c\u65f6\u5c3d\u91cf\u4fdd\u7559\u5927\u91cf\u6837\u672c\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u9886\u57df\u7684ML\u5e94\u7528\u4e2d\uff0c\u6a21\u578b\u5f80\u5f80\u672a\u80fd\u5145\u5206\u8003\u8651\u4e0d\u786e\u5b9a\u6027\uff0c\u5bb9\u6613\u5728\u4f4e\u7f6e\u4fe1\u5ea6\u65f6\u4ecd\u7ed9\u51fa\u9884\u6d4b\u3002\u9700\u8981\u901a\u8fc7\u6570\u636e\u8d28\u91cf\u63d0\u5347\u548c\u63a8\u65ad\u9636\u6bb5\u7684\u62d2\u7edd\u7b56\u7565\u6765\u63d0\u9ad8\u6574\u4f53\u53ef\u9760\u6027\u3002", "method": "\u7b2c\u4e00\u6b65\u5728\u8bad\u7ec3\u9636\u6bb5\u57fa\u4e8e\u5b9e\u4f8b\u96be\u5ea6(IH)\u7b5b\u9009\u5e76\u6ee4\u9664\u96be\u4ee5\u5b66\u4e60\u7684\u6837\u672c\uff0c\u4ece\u800c\u63d0\u5347\u6570\u636e\u96c6\u8d28\u91cf\uff1b\u7b2c\u4e8c\u6b65\u5728\u63a8\u65ad\u9636\u6bb5\u5f15\u5165\u4e00\u4e2a\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u62d2\u7edd\u673a\u5236\uff0c\u53ea\u6709\u8fbe\u5230\u53ef\u9760\u9608\u503c\u7684\u9884\u6d4b\u624d\u88ab\u8f93\u51fa\u3002\u4f5c\u4e3a\u5bf9\u6bd4\uff0c\u8fd8\u4f7f\u7528\u5f71\u54cd\u503c\u548c\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u57fa\u7ebf\u8bc4\u4f30\u8fc7\u6ee4\u548c\u62d2\u7edd\u7684\u6709\u6548\u6027\u3002", "result": "\u5728\u4e09\u7ec4\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u4e0a\uff0cIH\u8fc7\u6ee4\u7ed3\u5408\u7f6e\u4fe1\u5ea6\u62d2\u7edd\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u53ef\u9760\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u6837\u672c\u4fdd\u7559\u7387\uff0c\u4e0e\u57fa\u7ebf\u76f8\u6bd4\u5728\u9884\u6d4b\u6027\u80fd\u4e0e\u62d2\u7edd\u7387\u4e4b\u95f4\u53d6\u5f97\u66f4\u4f18\u7684\u5e73\u8861\u3002", "conclusion": "\u8be5\u6570\u636e\u9a71\u52a8\u7684\u4e24\u6b65\u65b9\u6cd5\u4e3a\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u90e8\u7f72ML\u7cfb\u7edf\u63d0\u4f9b\u4e00\u79cd\u53ef\u884c\u8def\u5f84\uff0c\u517c\u987e\u9884\u6d4b\u6027\u80fd\u4e0e\u98ce\u9669\u63a7\u5236\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5bf9\u4e0d\u786e\u5b9a\u6027\u654f\u611f\u7684\u9886\u57df\u3002"}}
{"id": "2510.24473", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24473", "abs": "https://arxiv.org/abs/2510.24473", "authors": ["Lucas Buk Cardoso", "Simone Aldrey Angelo", "Yasmin Pacheco Gil Bonilha", "Fernando Maia", "Adeylson Guimar\u00e3es Ribeiro", "Maria Paula Curado", "Gisele Aparecida Fernandes", "Vanderlei Cunha Parro", "Fl\u00e1vio Almeida de Magalh\u00e3es Cipparrone", "Alexandre Dias Porto Chiavegatto Filho", "Tatiana Natasha Toporcov"], "title": "Methodology for Comparing Machine Learning Algorithms for Survival Analysis", "comment": null, "summary": "This study presents a comparative methodological analysis of six machine\nlearning models for survival analysis (MLSA). Using data from nearly 45,000\ncolorectal cancer patients in the Hospital-Based Cancer Registries of S\\~ao\nPaulo, we evaluated Random Survival Forest (RSF), Gradient Boosting for\nSurvival Analysis (GBSA), Survival SVM (SSVM), XGBoost-Cox (XGB-Cox),\nXGBoost-AFT (XGB-AFT), and LightGBM (LGBM), capable of predicting survival\nconsidering censored data. Hyperparameter optimization was performed with\ndifferent samplers, and model performance was assessed using the Concordance\nIndex (C-Index), C-Index IPCW, time-dependent AUC, and Integrated Brier Score\n(IBS). Survival curves produced by the models were compared with predictions\nfrom classification algorithms, and predictor interpretation was conducted\nusing SHAP and permutation importance. XGB-AFT achieved the best performance\n(C-Index = 0.7618; IPCW = 0.7532), followed by GBSA and RSF. The results\nhighlight the potential and applicability of MLSA to improve survival\nprediction and support decision making.", "AI": {"tldr": "\u6bd4\u8f83\u516d\u79cd MLSA \u5728\u7ed3\u76f4\u80a0\u764c\u60a3\u8005\u751f\u5b58\u5206\u6790\u4e2d\u7684\u6027\u80fd\uff1bXGB-AFT \u8868\u73b0\u6700\u4f73\uff0cGBSA \u4e0e RSF \u7d27\u968f\u5176\u540e\u3002", "motivation": "\u5728\u542b\u5220\u5931\u6570\u636e\u7684\u4e34\u5e8a\u751f\u5b58\u5206\u6790\u4e2d\uff0c\u7cfb\u7edf\u6bd4\u8f83\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\u53ca\u53ef\u89e3\u91ca\u6027\uff0c\u4ee5\u63d0\u5347\u751f\u5b58\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u51b3\u7b56\u652f\u6301\u3002", "method": "\u4f7f\u7528\u7ea64.5\u4e07\u4f8b\u6765\u81ea\u5723\u4fdd\u7f57\u5e02\u764c\u75c7\u767b\u8bb0\u7684\u6570\u636e\uff1b\u6bd4\u8f83 Random Survival Forest\u3001Gradient Boosting for Survival Analysis\u3001Survival SVM\u3001XGBoost-Cox\u3001XGBoost-AFT\u3001LightGBM\uff1b\u8d85\u53c2\u6570\u4f18\u5316\u91c7\u7528\u4e0d\u540c\u91c7\u6837\u7b56\u7565\uff1b\u8bc4\u4f30\u6307\u6807\u5305\u62ec C-Index\u3001IPCW-C\u3001\u65f6\u95f4\u4f9d\u8d56 AUC\u3001\u96c6\u6210 Brier \u8bef\u5dee IBS\uff1b\u7528 SHAP \u4e0e\u7f6e\u6362\u91cd\u8981\u6027\u8fdb\u884c\u7279\u5f81\u89e3\u91ca\u3002", "result": "XGB-AFT \u6700\u4f18\uff08C-Index 0.7618\uff1bIPCW 0.7532\uff09\uff0cGBSA \u4e0e RSF \u6b21\u4e4b\uff1b\u6a21\u578b\u751f\u6210\u7684\u751f\u5b58\u66f2\u7ebf\u4e0e\u5206\u7c7b\u6a21\u578b\u9884\u6d4b\u6709\u6bd4\u8f83\uff1bMLSAs \u5c55\u73b0\u6f5c\u529b\u4e0e\u9002\u7528\u6027\u4ee5\u6539\u8fdb\u751f\u5b58\u9884\u6d4b\u5e76\u652f\u6301\u51b3\u7b56\u3002", "conclusion": "MLSAs \u5bf9\u751f\u5b58\u9884\u6d4b\u5177\u6709\u6f5c\u529b\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u5c24\u5176\u5728\u5904\u7406\u5220\u5931\u6570\u636e\u65b9\u9762\uff1b\u9700\u8981\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u5e76\u63a2\u7d22\u89e3\u91ca\u6027\u4e0e\u5916\u90e8\u63a8\u5e7f\u6027\u3002"}}
{"id": "2510.24500", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24500", "abs": "https://arxiv.org/abs/2510.24500", "authors": ["Yong Huang", "Zhongqi Yang", "Amir Rahmani"], "title": "MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU", "comment": null, "summary": "Sepsis is a leading cause of mortality in intensive care units (ICUs), yet\nexisting research often relies on outdated datasets, non-reproducible\npreprocessing pipelines, and limited coverage of clinical interventions. We\nintroduce MIMIC-Sepsis, a curated cohort and benchmark framework derived from\nthe MIMIC-IV database, designed to support reproducible modeling of sepsis\ntrajectories. Our cohort includes 35,239 ICU patients with time-aligned\nclinical variables and standardized treatment data, including vasopressors,\nfluids, mechanical ventilation and antibiotics. We describe a transparent\npreprocessing pipeline-based on Sepsis-3 criteria, structured imputation\nstrategies, and treatment inclusion-and release it alongside benchmark tasks\nfocused on early mortality prediction, length-of-stay estimation, and shock\nonset classification. Empirical results demonstrate that incorporating\ntreatment variables substantially improves model performance, particularly for\nTransformer-based architectures. MIMIC-Sepsis serves as a robust platform for\nevaluating predictive and sequential models in critical care research.", "AI": {"tldr": "\u63d0\u51fa MIMIC-Sepsis\uff1a\u57fa\u4e8e MIMIC-IV \u7684\u6807\u51c6\u5316\u961f\u5217\u4e0e\u57fa\u51c6\u6846\u67b6\uff0c\u7528\u4e8e\u53ef\u91cd\u590d\u7684\u8d25\u8840\u75c7\u8f68\u8ff9\u5efa\u6a21\uff0c\u5305\u542b\u65f6\u95f4\u5bf9\u9f50\u7684\u4e34\u5e8a\u53d8\u91cf\u4e0e\u6cbb\u7597\u6570\u636e\uff0c\u63d0\u4f9b\u4ece Sepsis-3 \u51fa\u53d1\u7684\u9884\u5904\u7406\u7ba1\u7ebf\u3001\u7f3a\u5931\u503c\u586b\u5145\u7b56\u7565\u4e0e\u6cbb\u7597\u7eb3\u5165\u7b56\u7565\uff0c\u5e76\u8bbe\u5b9a\u65e9\u671f\u6b7b\u4ea1\u9884\u6d4b\u3001\u4f4f\u9662\u65f6\u957f\u4f30\u8ba1\u548c\u4f11\u514b\u53d1\u4f5c\u5206\u7c7b\u7b49\u57fa\u51c6\u4efb\u52a1\u3002\u7ed3\u679c\u663e\u793a\u7eb3\u5165\u6cbb\u7597\u53d8\u91cf\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0cTransformer \u67b6\u6784\u5c24\u4e3a\u663e\u8457\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e\u8d25\u8840\u75c7\u7684\u7814\u7a76\u5e38\u4f7f\u7528\u8fc7\u65f6\u6570\u636e\u96c6\u3001\u7f3a\u4e4f\u53ef\u91cd\u590d\u7684\u9884\u5904\u7406\u6d41\u7a0b\u3001\u5bf9\u4e34\u5e8a\u5e72\u9884\u7684\u8986\u76d6\u6709\u9650\uff0c\u4e9f\u9700\u4e00\u4e2a\u53ef\u91cd\u590d\u3001\u8986\u76d6\u6cbb\u7597\u5e72\u9884\u4e14\u53ef\u6bd4\u8f83\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0e\u8bc4\u4f30\u4efb\u52a1\u6765\u63a8\u52a8\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u7684\u53d1\u5c55\u3002", "method": "\u4ece MIMIC-IV \u4e2d\u6784\u5efa 35,239 \u540d ICU \u60a3\u8005\u7684\u961f\u5217\uff0c\u63d0\u4f9b\u65f6\u95f4\u5bf9\u9f50\u7684\u4e34\u5e8a\u53d8\u91cf\u4e0e\u6807\u51c6\u5316\u6cbb\u7597\u6570\u636e\uff08\u8840\u7ba1\u6d3b\u6027\u836f\u3001\u6db2\u4f53\u3001\u673a\u68b0\u901a\u6c14\u3001\u6297\u751f\u7d20\uff09\u3002\u57fa\u4e8e Sepsis-3 \u8bbe\u5b9a\u7684\u900f\u660e\u9884\u5904\u7406\u7ba1\u7ebf\uff0c\u7ed3\u6784\u5316\u7684\u7f3a\u5931\u503c\u586b\u5145\u7b56\u7565\uff0c\u4ee5\u53ca\u6cbb\u7597\u56e0\u7d20\u7684\u7eb3\u5165\u4e0e\u91ca\u653e\u3002\u8bbe\u5b9a\u65e9\u671f\u6b7b\u4ea1\u9884\u6d4b\u3001\u4f4f\u9662\u65f6\u957f\u4f30\u8ba1\u3001\u4f11\u514b\u53d1\u4f5c\u5206\u7c7b\u7b49\u57fa\u51c6\u4efb\u52a1\u3002", "result": "\u5c06\u6cbb\u7597\u53d8\u91cf\u7eb3\u5165\u6a21\u578b\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e14 Transformer \u7b49\u590d\u6742\u6a21\u578b\u5bf9\u6cbb\u7597\u4fe1\u606f\u7684\u5229\u7528\u5c24\u4e3a\u6709\u6548\u3002\u4f5c\u4e3a\u4e00\u4e2a\u7a33\u5065\u7684\u5e73\u53f0\uff0cMIMIC-Sepsis \u53ef\u7528\u4e8e\u8bc4\u4f30\u5173\u952e\u62a4\u7406\u9884\u6d4b\u4e0e\u5e8f\u5217\u6a21\u578b\u3002", "conclusion": "MIMIC-Sepsis \u4e3a\u5728\u91cd\u75c7\u76d1\u62a4\u7814\u7a76\u4e2d\u8bc4\u4f30\u9884\u6d4b\u4e0e\u5e8f\u5217\u6a21\u578b\u63d0\u4f9b\u53ef\u91cd\u590d\u3001\u8986\u76d6\u6cbb\u7597\u5e72\u9884\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u4e34\u5e8a\u9884\u6d4b\u65b9\u6cd5\u7684\u6bd4\u8f83\u4e0e\u6539\u8fdb\u3002"}}
{"id": "2510.24503", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.24503", "abs": "https://arxiv.org/abs/2510.24503", "authors": ["Mortesa Hussaini", "Jan Thei\u00df", "Anthony Stein"], "title": "Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments", "comment": null, "summary": "In the context of Federated Learning with heterogeneous data environments,\nlocal models tend to converge to their own local model optima during local\ntraining steps, deviating from the overall data distributions. Aggregation of\nthese local updates, e.g., with FedAvg, often does not align with the global\nmodel optimum (client drift), resulting in an update that is suboptimal for\nmost clients. Personalized Federated Learning approaches address this challenge\nby exclusively focusing on the average local performances of clients' models on\ntheir own data distribution. Generalization to out-of-distribution samples,\nwhich is a substantial benefit of FedAvg and represents a significant component\nof robustness, appears to be inadequately incorporated into the assessment and\nevaluation processes. This study involves a thorough evaluation of Federated\nLearning approaches, encompassing both their local performance and their\ngeneralization capabilities. Therefore, we examine different stages within a\nsingle communication round to enable a more nuanced understanding of the\nconsidered metrics. Furthermore, we propose and incorporate a modified approach\nof FedAvg, designated as Federated Learning with Individualized Updates (FLIU),\nextending the algorithm by a straightforward individualization step with an\nadaptive personalization factor. We evaluate and compare the approaches\nempirically using MNIST and CIFAR-10 under various distributional conditions,\nincluding benchmark IID and pathological non-IID, as well as additional novel\ntest environments with Dirichlet distribution specifically developed to stress\nthe algorithms on complex data heterogeneity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684FedAvg\u65b9\u6cd5FLIU\uff08Federated Learning with Individualized Updates\uff09\uff0c\u901a\u8fc7\u4e00\u4e2a\u7b80\u5355\u7684\u4e2a\u6027\u5316\u66f4\u65b0\u6b65\u9aa4\u4e0e\u81ea\u9002\u5e94\u4e2a\u6027\u5316\u56e0\u5b50\uff0c\u5728\u6570\u636e\u5206\u5e03\u5f02\u8d28\u7684\u8054\u90a6\u5b66\u4e60\u4e2d\u5728\u5c40\u90e8\u6027\u80fd\u4e0e\u5bf9\u5206\u5e03\u5916\u6837\u672c\u7684\u6cdb\u5316\u6027\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u7684\u6298\u4e2d\uff1b\u5728MNIST\u4e0eCIFAR-10\u7684IID\u548c\u975eIID Dirichlet\u5206\u5e03\u4e0b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u663e\u793a\u76f8\u8f83\u4e8e\u4f20\u7edfFedAvg\u5177\u6709\u66f4\u597d\u7684\u5c40\u90e8\u51c6\u786e\u6027\u548c\u6cdb\u5316\u6027\u3002", "motivation": "\u5728\u5206\u5e03\u5f02\u8d28\u7684\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e2d\uff0c\u5c40\u90e8\u6a21\u578b\u5728\u672c\u5730\u8bad\u7ec3\u4e2d\u6613\u6536\u655b\u4e8e\u5404\u81ea\u5c40\u90e8\u6700\u4f18\uff0c\u5bfc\u81f4\u5168\u5c40\u805a\u5408\u504f\u79bb\u5168\u5c40\u6700\u4f18\uff0c\u51fa\u73b0\u5ba2\u6237\u7aef\u6f02\u79fb\u3002\u73b0\u6709\u7684\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u4fa7\u91cd\u63d0\u5347\u5c40\u90e8\u8868\u73b0\uff0c\u5f80\u5f80\u5ffd\u7565\u5bf9\u5206\u5e03\u5916\uff08OOD\uff09\u6837\u672c\u7684\u9c81\u68d2\u6027\u4e0e\u6cdb\u5316\u8bc4\u4f30\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u5173\u6ce8\u5c40\u90e8\u8868\u73b0\u548c\u8de8\u5206\u5e03\u6cdb\u5316\u7684\u8bc4\u4f30\u4e0e\u65b9\u6cd5\u3002", "method": "\u5728FedAvg\u6846\u67b6\u4e0a\u5f15\u5165FLIU\uff0c\u5373\u5728\u5168\u5c40\u805a\u5408\u540e\u589e\u52a0\u4e00\u4e2a\u7b80\u5355\u7684\u4e2a\u6027\u5316\u66f4\u65b0\u6b65\u9aa4\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u4e2a\u6027\u5316\u56e0\u5b50\u5bf9\u6bcf\u4e2a\u5ba2\u6237\u7aef\u8fdb\u884c\u4e2a\u6027\u5316\u8c03\u6574\u3002\u901a\u8fc7\u5728MNIST\u548cCIFAR-10\u4e0a\uff0c\u7ed3\u5408IID\u548cDirichlet\u6784\u9020\u7684\u975eIID\u5206\u5e03\u4ee5\u53ca\u66f4\u5177\u6311\u6218\u6027\u7684\u5206\u5e03\u60c5\u51b5\uff0c\u8fdb\u884c\u591a\u9636\u6bb5\u3001\u5355\u901a\u4fe1\u8f6e\u5185\u7684\u9636\u6bb5\u6027\u6307\u6807\u8bc4\u4f30\uff0c\u5168\u9762\u6bd4\u8f83\u5c40\u90e8\u8868\u73b0\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFLIU\u5728\u591a\u79cd\u6570\u636e\u5206\u5e03\u4e0b\u5728\u5c40\u90e8\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u76f8\u8f83\u4e8eFedAvg\u53ca\u5176\u4ed6\u57fa\u7ebf\u5747\u8868\u73b0\u51fa\u663e\u8457\u6539\u5584\uff1b\u901a\u8fc7\u5bf9\u5355\u8f6e\u5185\u4e0d\u540c\u9636\u6bb5\u7684\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5c40\u90e8\u66f4\u65b0\u4e0e\u5168\u5c40\u805a\u5408\u4e4b\u95f4\u7684\u534f\u540c\u6548\u679c\u4e0e\u65f6\u5e8f\u52a8\u6001\u3002", "conclusion": "FLIU\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u6d01\u4e14\u6709\u6548\u7684\u8054\u90a6\u5b66\u4e60\u4e2a\u6027\u5316\u7b56\u7565\uff0c\u80fd\u591f\u5728\u6570\u636e\u5f02\u8d28\u6027\u73af\u5883\u4e2d\u66f4\u597d\u5730\u517c\u987e\u5c40\u90e8\u6700\u4f18\u4e0e\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002\u8be5\u7814\u7a76\u5f3a\u8c03\u5728\u8bc4\u4f30\u4e2d\u7eb3\u5165\u9636\u6bb5\u6027\u3001\u5c40\u90e8\u53ca\u5168\u5c40\u7ef4\u5ea6\u7684\u7efc\u5408\u6307\u6807\uff0c\u4ee5\u63a8\u52a8\u9c81\u68d2\u6027\u66f4\u5f3a\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.24561", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24561", "abs": "https://arxiv.org/abs/2510.24561", "authors": ["Qingyue Zhang", "Chang Chu", "Tianren Peng", "Qi Li", "Xiangyang Luo", "Zhihao Jiang", "Shao-Lun Huang"], "title": "LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via Asymptotic Analysis", "comment": null, "summary": "With the widespread adoption of LLMs, LoRA has become a dominant method for\nPEFT, and its initialization methods have attracted increasing attention.\nHowever, existing methods have notable limitations: many methods do not\nincorporate target-domain data, while gradient-based methods exploit data only\nat a shallow level by relying on one-step gradient decomposition, which remains\nunsatisfactory due to the weak empirical performance of the one-step\nfine-tuning model that serves as their basis, as well as the fact that these\nmethods either lack a rigorous theoretical foundation or depend heavily on\nrestrictive isotropic assumptions. In this paper, we establish a theoretical\nframework for data-aware LoRA initialization based on asymptotic analysis.\nStarting from a general optimization objective that minimizes the expectation\nof the parameter discrepancy between the fine-tuned and target models, we\nderive an optimization problem with two components: a bias term, which is\nrelated to the parameter distance between the fine-tuned and target models, and\nis approximated using a Fisher-gradient formulation to preserve anisotropy; and\na variance term, which accounts for the uncertainty introduced by sampling\nstochasticity through the Fisher information. By solving this problem, we\nobtain an optimal initialization strategy for LoRA. Building on this\ntheoretical framework, we develop an efficient algorithm, LoRA-DA, which\nestimates the terms in the optimization problem from a small set of target\ndomain samples and obtains the optimal LoRA initialization. Empirical results\nacross multiple benchmarks demonstrate that LoRA-DA consistently improves final\naccuracy over existing initialization methods. Additional studies show faster,\nmore stable convergence, robustness across ranks, and only a small\ninitialization overhead for LoRA-DA. The source code will be released upon\npublication.", "AI": {"tldr": "\u63d0\u51fa\u9762\u5411\u76ee\u6807\u57df\u6570\u636e\u7684\u6570\u636e\u611f\u77e5LoRA\u521d\u59cb\u5316\u6846\u67b6LoRA-DA\uff0c\u57fa\u4e8e\u6e10\u8fd1\u5206\u6790\uff0c\u5c06\u521d\u59cb\u5316\u95ee\u9898\u5206\u89e3\u4e3a\u504f\u5dee\u548c\u65b9\u5dee\u4e24\u9879\uff0c\u901a\u8fc7Fisher-gradient\u8868\u793a\u504f\u5dee\uff0c\u8003\u8651Fisher\u4fe1\u606f\u7684\u65b9\u5dee\uff0c\u7ed9\u51fa\u6700\u4f18\u521d\u59cb\u5316\u5e76\u5b9e\u73b0LoRA-DA\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u591a\u9879\u57fa\u51c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u6536\u655b\u66f4\u5feb\u3001\u9c81\u68d2\u6027\u597d\u3001\u5f00\u9500\u5c0f\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709LoRA\u521d\u59cb\u5316\u5728\u672a\u5145\u5206\u5229\u7528\u76ee\u6807\u57df\u6570\u636e\u3001\u68af\u5ea6\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u4e00\u9636\u68af\u5ea6\u5206\u89e3\u4e14\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u4e2a\u6570\u636e\u611f\u77e5\u4e14\u6709\u7406\u8bba\u652f\u6491\u7684\u521d\u59cb\u5316\u6846\u67b6\u3002", "method": "\u4ece\u6700\u5c0f\u5316\u5fae\u8c03\u6a21\u578b\u4e0e\u76ee\u6807\u6a21\u578b\u53c2\u6570\u5dee\u5f02\u7684\u671f\u671b\u51fa\u53d1\uff0c\u5f97\u5230\u5305\u542b\u4e00\u4e2a\u504f\u5dee\u9879\uff08\u7528Fisher-gradient\u8fd1\u4f3c\u4ee5\u4fdd\u7559\u5404\u5411\u5f02\u6027\uff09\u548c\u4e00\u4e2a\u65b9\u5dee\u9879\uff08\u7531\u91c7\u6837\u4e0d\u786e\u5b9a\u6027\u901a\u8fc7Fisher\u4fe1\u606f\u523b\u753b\uff09\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u6c42\u89e3\u5f97\u5230\u6700\u4f18\u521d\u59cb\u5316\uff1b\u5b9e\u73b0LoRA-DA\u7b97\u6cd5\uff0c\u4ece\u5c11\u91cf\u76ee\u6807\u57df\u6837\u672c\u4e2d\u4f30\u8ba1\u4e24\u9879\u5e76\u7ed9\u51faLoRA\u521d\u59cb\u5316\u3002", "result": "\u5728\u591a\u9879\u57fa\u51c6\u4e0a\uff0cLoRA-DA\u5728\u6700\u7ec8\u51c6\u786e\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u521d\u59cb\u5316\u65b9\u6cd5\uff1b\u6536\u655b\u66f4\u5feb\u3001\u66f4\u7a33\u5b9a\uff0c\u5bf9\u79e9\u9c81\u68d2\uff0c\u521d\u59cb\u5316\u5f00\u9500\u5c0f\u3002", "conclusion": "\u7ed9\u51fa\u4e00\u4e2a\u5177\u6709\u7406\u8bba\u57fa\u7840\u7684\u6570\u636e\u611f\u77e5LoRA\u521d\u59cb\u5316\u6846\u67b6\u53ca\u9ad8\u6548\u7b97\u6cd5\uff0cLoRA-DA\u5728\u5b9e\u8df5\u4e2d\u5177\u6709\u663e\u8457\u7684\u6027\u80fd\u4e0e\u6548\u7387\u63d0\u5347\uff0c\u4ee3\u7801\u5c06\u516c\u5f00\u3002"}}
{"id": "2510.24574", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24574", "abs": "https://arxiv.org/abs/2510.24574", "authors": ["Hao Wang", "Licheng Pan", "Yuan Lu", "Zhixuan Chu", "Xiaoxi Li", "Shuting He", "Zhichao Chen", "Haoxuan Li", "Qingsong Wen", "Zhouchen Lin"], "title": "DistDF: Time-Series Forecasting Needs Joint-Distribution Wasserstein Alignment", "comment": null, "summary": "Training time-series forecast models requires aligning the conditional\ndistribution of model forecasts with that of the label sequence. The standard\ndirect forecast (DF) approach resorts to minimize the conditional negative\nlog-likelihood of the label sequence, typically estimated using the mean\nsquared error. However, this estimation proves to be biased in the presence of\nlabel autocorrelation. In this paper, we propose DistDF, which achieves\nalignment by alternatively minimizing a discrepancy between the conditional\nforecast and label distributions. Because conditional discrepancies are\ndifficult to estimate from finite time-series observations, we introduce a\nnewly proposed joint-distribution Wasserstein discrepancy for time-series\nforecasting, which provably upper bounds the conditional discrepancy of\ninterest. This discrepancy admits tractable, differentiable estimation from\nempirical samples and integrates seamlessly with gradient-based training.\nExtensive experiments show that DistDF improves the performance diverse\nforecast models and achieves the state-of-the-art forecasting performance. Code\nis available at https://anonymous.4open.science/r/DistDF-F66B.", "AI": {"tldr": "DistDF introduces a joint-distribution Wasserstein discrepancy to align conditional forecast distributions with the label distribution in time-series forecasting, addressing bias from label autocorrelation and enabling differentiable, tractable optimization that improves performance across diverse models.", "motivation": "Standard direct forecast minimizes conditional negative log-likelihood often estimated by MSE, which is biased when label autocorrelation exists. There's a need for an objective that aligns the conditional forecast distribution with the true label distribution, accounting for dependencies over time.", "method": "Propose DistDF which minimizes a discrepancy between the conditional forecast distribution and the label distribution using a joint-distribution Wasserstein metric for time-series. This discrepancy upper-bounds the targeted conditional discrepancy, is differentiable and estimable from empirical samples, and integrates with gradient-based training.", "result": "Extensive experiments demonstrate that DistDF improves forecasting performance across diverse models and achieves state-of-the-art results.", "conclusion": "DistDF provides a principled, tractable approach to time-series forecasting by aligning conditional and label distributions via a joint-Wasserstein discrepancy, with empirical gains and publicly available code."}}
{"id": "2510.24577", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24577", "abs": "https://arxiv.org/abs/2510.24577", "authors": ["He Yang", "Fei Ren", "Hai-Sui Yu", "Xiaohui Chen", "Pei-Zhi Zhuang"], "title": "Physics-Informed Extreme Learning Machine (PIELM): Opportunities and Challenges", "comment": null, "summary": "We are very delighted to see the fast development of physics-informed extreme\nlearning machine (PIELM) in recent years for higher computation efficiency and\naccuracy in physics-informed machine learning. As a summary or review on PIELM\nis currently not available, we would like to take this opportunity to show our\nperspective and experience for this promising research direction. We can see\nmany efforts are made to solve PDEs with sharp gradients, nonlinearities,\nhigh-frequency behavior, hard constraints, uncertainty, multiphysics coupling.\nDespite the success, many urgent challenges remain to be tackled, which also\nprovides us opportunities to develop more robust, interpretable, and\ngeneralizable PIELM frameworks with applications in science and engineering.", "AI": {"tldr": "PIELM\u9886\u57df\u53d1\u5c55\u8fc5\u901f\uff0c\u4f5c\u8005\u63d0\u51fa\u4ee5\u7efc\u8ff0/\u5c55\u671b\u7684\u5f62\u5f0f\u68b3\u7406\u73b0\u72b6\u3001\u6311\u6218\u4e0e\u673a\u4f1a\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u7a33\u5065\u3001\u53ef\u89e3\u91ca\u3001\u6cdb\u5316\u7684\u6846\u67b6\u3002", "motivation": "\u5f53\u524d\u5c1a\u65e0\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u4e9f\u9700\u5bf9PIELM\u5728\u6c42\u89e3\u5177\u6709\u5c16\u9510\u68af\u5ea6\u3001\u975e\u7ebf\u6027\u3001\u9ad8\u9891\u884c\u4e3a\u3001\u7ea6\u675f\u6761\u4ef6\u3001\u4ee5\u53ca\u591a\u7269\u7406\u8026\u5408\u7b49\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u4e0e\u6311\u6218\u8fdb\u884c\u6574\u7406\u3001\u603b\u7ed3\u4e0e\u5c55\u671b\u3002", "method": "\u4ee5\u89c2\u70b9/\u7ecf\u9a8c\u7684\u5f62\u5f0f\u5bf9\u73b0\u6709PIELM\u7814\u7a76\u8fdb\u884c\u7efc\u5408\u8bc4\u8ff0\uff0c\u5206\u6790\u5728PDE\u6c42\u89e3\u4e2d\u7684\u56f0\u96be\u4e0e\u8d8b\u52bf\uff0c\u8ba8\u8bba\u672a\u6765\u7814\u7a76\u65b9\u5411\u4e0e\u53ef\u80fd\u7684\u6539\u8fdb\u8def\u5f84\u3002", "result": "\u5bf9PIELM\u9886\u57df\u7684\u8fdb\u5c55\u8fdb\u884c\u68b3\u7406\uff0c\u660e\u786e\u5173\u952e\u6311\u6218\u4e0e\u7814\u7a76\u673a\u4f1a\uff0c\u63d0\u51fa\u6784\u5efa\u66f4\u7a33\u5065\u3001\u53ef\u89e3\u91ca\u3001\u901a\u7528\u7684PIELM\u6846\u67b6\u7684\u65b9\u5411\u3002", "conclusion": "\u5c3d\u7ba1\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4ecd\u5b58\u5728\u82e5\u5e72\u8feb\u5207\u6311\u6218\uff0c\u672a\u6765\u9700\u5728\u9c81\u68d2\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u6cdb\u5316\u80fd\u529b\u53ca\u5de5\u7a0b/\u79d1\u5b66\u5e94\u7528\u7684\u843d\u5730\u65b9\u9762\u6df1\u5316\u7814\u7a76\u3002"}}
{"id": "2510.24633", "categories": ["cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.24633", "abs": "https://arxiv.org/abs/2510.24633", "authors": ["Mingyue Liu", "Andrew Cropper"], "title": "Symbolic Snapshot Ensembles", "comment": null, "summary": "Inductive logic programming (ILP) is a form of logical machine learning. Most\nILP algorithms learn a single hypothesis from a single training run. Ensemble\nmethods train an ILP algorithm multiple times to learn multiple hypotheses. In\nthis paper, we train an ILP algorithm only once and save intermediate\nhypotheses. We then combine the hypotheses using a minimum description length\nweighting scheme. Our experiments on multiple benchmarks, including game\nplaying and visual reasoning, show that our approach improves predictive\naccuracy by 4% with less than 1% computational overhead.", "AI": {"tldr": "\u5355\u6b21\u8fd0\u884c\u7684 ILP \u52a0\u8f7d\u5e76\u4fdd\u5b58\u4e2d\u95f4\u4ea7\u751f\u7684\u5047\u8bbe\uff0c\u57fa\u4e8e MDL \u6743\u91cd\u5bf9\u5b83\u4eec\u8fdb\u884c\u878d\u5408\uff0c\u4ece\u800c\u5728\u591a\u9879\u57fa\u51c6\u4e0a\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u7ea6 4%\uff0c\u4e14\u989d\u5916\u5f00\u9500\u5c0f\u4e8e 1%\u3002", "motivation": "\u4f20\u7edf ILP \u901a\u5e38\u901a\u8fc7\u591a\u6b21\u8bad\u7ec3\u4ea7\u751f\u4e00\u4e2a\u96c6\u6210\uff0c\u5176\u4e2d\u6bcf\u6b21\u8bad\u7ec3\u4ea7\u751f\u4e00\u4e2a\u5047\u8bbe\u3002\u672c\u6587\u63d0\u51fa\u5728\u4e00\u6b21\u8bad\u7ec3\u4e2d\u4fdd\u5b58\u4e2d\u95f4\u5047\u8bbe\uff0c\u5e76\u4f7f\u7528\u6700\u5c0f\u63cf\u8ff0\u957f\u5ea6\uff08MDL\uff09\u52a0\u6743\u878d\u5408\u8fd9\u4e9b\u5047\u8bbe\uff0c\u4ee5\u83b7\u5f97\u6027\u80fd\u63d0\u5347\u4e14\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u5728\u4e00\u6b21 ILP \u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u5b58\u591a\u4e2a\u4e2d\u95f4\u4ea7\u751f\u7684\u5047\u8bbe\uff1b\u5229\u7528\u6700\u5c0f\u63cf\u8ff0\u957f\u5ea6\u539f\u7406\u5bf9\u8fd9\u4e9b\u5047\u8bbe\u8fdb\u884c\u52a0\u6743\uff0c\u5f62\u6210\u4e00\u4e2a\u96c6\u5408\u9884\u6d4b\u7684\u6743\u91cd\u6a21\u578b\uff0c\u5e76\u5728\u6e38\u620f\u548c\u89c6\u89c9\u63a8\u7406\u7b49\u57fa\u51c6\u4e0a\u8bc4\u4f30\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6cd5\u76f8\u6bd4\u5355\u4e00\u5047\u8bbe\u63d0\u5347\u7ea6 4% \u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u603b\u8ba1\u7b97\u5f00\u9500\u4f4e\u4e8e 1%\u3002", "conclusion": "\u5355\u6b21\u8bad\u7ec3\u5e76\u7ed3\u5408\u4e2d\u95f4\u5047\u8bbe\u7684 MDL \u52a0\u6743\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u5b9e\u73b0\u5bf9 ILP \u96c6\u6210\u7684\u6709\u6548\u63d0\u5347\uff0c\u5177\u6709\u6f5c\u5728\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u4e0e\u6269\u5c55\u7a7a\u95f4\u3002"}}
{"id": "2510.24670", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.24670", "abs": "https://arxiv.org/abs/2510.24670", "authors": ["Genesis Research Team", "Alejandro Dobles", "Nina Jovic", "Kenneth Leidal", "Pranav Murugan", "David C. Williams", "Drausin Wulsin", "Nate Gruver", "Christina X. Ji", "Korrawat Pruegsanusak", "Gianluca Scarpellini", "Ansh Sharma", "Wojciech Swiderski", "Andrea Bootsma", "Richard Strong Bowen", "Charlotte Chen", "Jamin Chen", "Marc Andr\u00e9 D\u00e4mgen", "Roy Tal Dew", "Benjamin DiFrancesco", "J. D. Fishman", "Alla Ivanova", "Zach Kagin", "David Li-Bland", "Zuli Liu", "Igor Morozov", "Jeffrey Ouyang-Zhang", "Frank C. Pickard IV", "Kushal S. Shah", "Ben Shor", "Gabriel Monteiro da Silva", "Maxx Tessmer", "Carl Tilbury", "Cyr Vetcher", "Daniel Zeng", "Maruan Al-Shedivat", "Aleksandra Faust", "Evan N. Feinberg", "Michael V. LeVine", "Matteus Pan"], "title": "Pearl: A Foundation Model for Placing Every Atom in the Right Location", "comment": null, "summary": "Accurately predicting the three-dimensional structures of protein-ligand\ncomplexes remains a fundamental challenge in computational drug discovery that\nlimits the pace and success of therapeutic design. Deep learning methods have\nrecently shown strong potential as structural prediction tools, achieving\npromising accuracy across diverse biomolecular systems. However, their\nperformance and utility are constrained by scarce experimental data,\ninefficient architectures, physically invalid poses, and the limited ability to\nexploit auxiliary information available at inference. To address these issues,\nwe introduce Pearl (Placing Every Atom in the Right Location), a foundation\nmodel for protein-ligand cofolding at scale. Pearl addresses these challenges\nwith three key innovations: (1) training recipes that include large-scale\nsynthetic data to overcome data scarcity; (2) architectures that incorporate an\nSO(3)-equivariant diffusion module to inherently respect 3D rotational\nsymmetries, improving generalization and sample efficiency, and (3)\ncontrollable inference, including a generalized multi-chain templating system\nsupporting both protein and non-polymeric components as well as dual\nunconditional/conditional modes. Pearl establishes a new state-of-the-art\nperformance in protein-ligand cofolding. On the key metric of generating\naccurate (RMSD < 2 \\r{A}) and physically valid poses, Pearl surpasses AlphaFold\n3 and other open source baselines on the public Runs N' Poses and PoseBusters\nbenchmarks, delivering 14.5% and 14.2% improvements, respectively, over the\nnext best model. In the pocket-conditional cofolding regime, Pearl delivers\n$3.6\\times$ improvement on a proprietary set of challenging, real-world drug\ntargets at the more rigorous RMSD < 1 \\r{A} threshold. Finally, we demonstrate\nthat model performance correlates directly with synthetic dataset size used in\ntraining.", "AI": {"tldr": "Pearl\u662f\u4e00\u4e2a\u7528\u4e8e\u86cb\u767d-\u914d\u4f53\u534ffolding\u7684\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u5408\u6210\u6570\u636e\u3001SO(3)\u7b49\u53d8\u6269\u6563\u6a21\u5757\u548c\u53ef\u63a7\u63a8\u65ad\u5b9e\u73b0\u66f4\u9ad8\u7684\u7cbe\u5ea6\u4e0e\u7269\u7406\u6709\u6548\u6027\uff0c\u5728Runs N' Poses\u4e0ePoseBusters\u57fa\u51c6\u4e0a\u8d85\u8d8aAlphaFold 3\u7b49 baselines\uff0c\u4e14\u5728\u53e3\u888b\u6761\u4ef6\u4e0b\u5b9e\u73b03.6x\u63d0\u5347\uff0c\u6570\u636e\u89c4\u6a21\u4e0e\u6027\u80fd\u5448\u6b63\u76f8\u5173\u3002", "motivation": "\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u3001\u67b6\u6784\u4f4e\u6548\u3001\u59ff\u6001\u7269\u7406\u65e0\u6548\u53ca\u5728\u63a8\u65ad\u9636\u6bb5\u65e0\u6cd5\u5145\u5206\u5229\u7528\u8f85\u52a9\u4fe1\u606f\u7684\u95ee\u9898\uff1b\u901a\u8fc7\u5927\u89c4\u6a21\u6570\u636e\u3001\u51e0\u4f55\u5bf9\u79f0\u6027\u5c0a\u91cd\u7684\u6a21\u578b\u548c\u53ef\u63a7\u6a21\u677f\u63a8\u65ad\u63d0\u9ad8\u9884\u6d4b\u8d28\u91cf\u548c\u6cdb\u5316\u3002", "method": "\u63d0\u51faPearl\uff0c\u5305\u542b\uff1a1) \u5927\u89c4\u6a21\u5408\u6210\u6570\u636e\u8bad\u7ec3\u4ee5\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\uff1b2) \u5f15\u5165SO(3)-\u7b49\u53d8\u6269\u6563\u6a21\u5757\u4ee5\u672c\u8d28\u4e0a\u9075\u5faa3D\u65cb\u8f6c\u5bf9\u79f0\u6027\uff0c\u63d0\u9ad8\u6cdb\u5316\u548c\u6837\u672c\u6548\u7387\uff1b3) \u53ef\u63a7\u63a8\u65ad\uff0c\u652f\u6301\u591a\u94fe\u6a21\u677f\u7cfb\u7edf\uff0c\u9002\u7528\u4e8e\u86cb\u767d\u548c\u975e\u805a\u5408\u7ec4\u4ef6\uff0c\u4e14\u5177\u5907\u53cc\u5411\u65e0\u6761\u4ef6/\u6709\u6761\u4ef6\u6a21\u5f0f\u3002", "result": "\u5728\u5173\u952e\u6307\u6807RMSD<2\u00c5\u7684\u51c6\u786e\u6027\u548c\u7269\u7406\u6709\u6548\u6027\u65b9\u9762\u8d85\u8d8aAlphaFold 3\u53ca\u5176\u4ed6\u5f00\u6e90\u57fa\u7ebf\uff0c\u5206\u522b\u5728Runs N' Poses\u548cPoseBusters\u57fa\u51c6\u4e0a\u5b9e\u73b014.5%\u548c14.2%\u7684\u63d0\u5347\uff1b\u5728\u53e3\u888b\u6761\u4ef6\u7684\u771f\u5b9e\u836f\u7269\u9776\u70b9\u96c6\u4e0a\u5b9e\u73b03.6x\u63d0\u5347\uff08RMSD<1\u00c5\uff09\uff1b\u6a21\u578b\u6027\u80fd\u4e0e\u8bad\u7ec3\u6570\u636e\u89c4\u6a21\u6b63\u76f8\u5173\u3002", "conclusion": "\u901a\u8fc7\u6570\u636e\u89c4\u6a21\u4e0e\u51e0\u4f55\u5bf9\u79f0\u6027\u53cb\u597d\u7684\u6269\u6563\u67b6\u6784\uff0cPearl\u5b9e\u73b0\u4e86\u86cb\u767d-\u914d\u4f53\u534f\u6298\u53e0\u7684\u65b0\u5173\u7cfb\uff0c\u786e\u7acb\u65b0\u57fa\u51c6\uff0c\u4e14\u6570\u636e\u89c4\u6a21\u8d8a\u5927\uff0c\u6027\u80fd\u8d8a\u597d\u3002"}}
{"id": "2510.24672", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.24672", "abs": "https://arxiv.org/abs/2510.24672", "authors": ["Burak Var\u0131c\u0131", "Che-Ping Tsai", "Ritabrata Ray", "Nicholas M. Boffi", "Pradeep Ravikumar"], "title": "Eigenfunction Extraction for Ordered Representation Learning", "comment": null, "summary": "Recent advances in representation learning reveal that widely used\nobjectives, such as contrastive and non-contrastive, implicitly perform\nspectral decomposition of a contextual kernel, induced by the relationship\nbetween inputs and their contexts. Yet, these methods recover only the linear\nspan of top eigenfunctions of the kernel, whereas exact spectral decomposition\nis essential for understanding feature ordering and importance. In this work,\nwe propose a general framework to extract ordered and identifiable\neigenfunctions, based on modular building blocks designed to satisfy key\ndesiderata, including compatibility with the contextual kernel and scalability\nto modern settings. We then show how two main methodological paradigms,\nlow-rank approximation and Rayleigh quotient optimization, align with this\nframework for eigenfunction extraction. Finally, we validate our approach on\nsynthetic kernels and demonstrate on real-world image datasets that the\nrecovered eigenvalues act as effective importance scores for feature selection,\nenabling principled efficiency-accuracy tradeoffs via adaptive-dimensional\nrepresentations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u901a\u7528\u6a21\u5757\u5316\u6846\u67b6\uff0c\u7528\u4ee5\u4ece\u4e0a\u4e0b\u6587\u5185\u6838\u4e2d\u63d0\u53d6\u6709\u5e8f\u3001\u53ef\u8bc6\u522b\u7684\u7279\u5f81\u51fd\u6570\uff08\u7279\u5f81\u503c/\u7279\u5f81\u5411\u91cf\uff09\uff0c\u8d85\u8d8a\u4ec5\u6062\u590d\u7ebf\u6027\u524d\u51e0\u4e2a\u7279\u5f81\u7684\u8868\u793a\uff0c\u7ed3\u5408\u4f4e\u79e9\u8fd1\u4f3c\u548c Rayleigh\u5546\u4f18\u5316\u4e24\u5927\u8303\u5f0f\uff0c\u5e76\u5728\u5408\u6210\u6838\u548c\u771f\u5b9e\u56fe\u50cf\u6570\u636e\u4e0a\u9a8c\u8bc1\uff0c\u7279\u5f81\u503c\u4f5c\u4e3a\u91cd\u8981\u6027\u8bc4\u5206\u7528\u4e8e\u7279\u5f81\u9009\u62e9\uff0c\u652f\u6491\u81ea\u9002\u5e94\u7ef4\u5ea6\u8868\u793a\u7684\u6548\u7387-\u51c6\u786e\u6027\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u975e\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\u9690\u5f0f\u5730\u5bf9\u8f93\u5165\u53ca\u5176\u4e0a\u4e0b\u6587\u5173\u7cfb\u7684\u6838\u8fdb\u884c\u8c31\u5206\u89e3\uff0c\u4f46\u5f80\u5f80\u53ea\u6062\u590d\u6838\u7684\u524d\u82e5\u5e72\u7ebf\u6027\u7279\u5f81\u7684\u7ebf\u6027\u5f20\u91cf\uff0c\u65e0\u6cd5\u83b7\u5f97\u5b8c\u6574\u8c31\u53ca\u7279\u5f81\u6392\u5e8f\u548c\u91cd\u8981\u6027\u3002\u9700\u8981\u4e00\u4e2a\u53ef\u8fa8\u8bc6\u3001\u53ef\u6392\u5e8f\u7684\u7279\u5f81\u51fd\u6570\u96c6\u5408\u6765\u63ed\u793a\u7279\u5f81\u7684\u91cd\u8981\u6027\u4e0e\u7ec4\u7ec7\u7ed3\u6784\u3002", "method": "\u7ed9\u51fa\u4e00\u4e2a\u53ef\u6a21\u5757\u5316\u7684\u6846\u67b6\uff0c\u8bbe\u8ba1\u82e5\u5e72\u6784\u5efa\u5757\u4ee5\u786e\u4fdd\u4e0e\u4e0a\u4e0b\u6587\u5185\u6838\u7684\u517c\u5bb9\u6027\u5e76\u5177\u5907\u5904\u7406\u73b0\u4ee3\u6570\u636e\u89c4\u6a21\u7684\u80fd\u529b\uff1b\u5e76\u5c06\u4f4e\u79e9\u8fd1\u4f3c\u4e0e Rayleigh\u5546\u4f18\u5316\u8fd9\u4e24\u5927\u4e3b\u6d41\u65b9\u6cd5\u8bba\u6620\u5c04\u5230\u8be5\u6846\u67b6\uff0c\u534f\u540c\u5b9e\u73b0\u5bf9\u7279\u5f81\u51fd\u6570\u7684\u63d0\u53d6\u4e0e\u6392\u5e8f\u3002", "result": "\u5728\u5408\u6210\u6838\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u80fd\u591f\u63d0\u53d6\u6709\u5e8f\u4e14\u53ef\u8fa8\u8bc6\u7684\u7279\u5f81\u51fd\u6570\uff1b\u5728\u771f\u5b9e\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\uff0c\u6062\u590d\u7684\u7279\u5f81\u503c\u53ef\u4f5c\u4e3a\u6709\u6548\u7684\u7279\u5f81\u91cd\u8981\u6027\u5206\u6570\u7528\u4e8e\u7279\u5f81\u9009\u62e9\uff0c\u4ece\u800c\u5b9e\u73b0\u81ea\u9002\u5e94\u7ef4\u5ea6\u8868\u793a\u4e0b\u7684\u6548\u7387-\u51c6\u786e\u6027\u6743\u8861\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u3001\u53ef\u6269\u5c55\u7684\u6846\u67b6\u6765\u63d0\u53d6\u6709\u5e8f\u3001\u53ef\u8fa8\u8bc6\u7684\u7279\u5f81\u51fd\u6570\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5c55\u793a\u5176\u5728\u7406\u89e3\u7279\u5f81\u6392\u5e8f\u4e0e\u63d0\u9ad8\u8868\u793a\u5b66\u4e60\u6548\u7387\u65b9\u9762\u7684\u6f5c\u5728\u4ef7\u503c\u3002"}}
