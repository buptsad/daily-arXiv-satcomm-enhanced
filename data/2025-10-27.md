<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 6]
- [cs.CR](#cs.CR) [Total: 20]
- [eess.SY](#eess.SY) [Total: 9]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 74]
- [eess.SP](#eess.SP) [Total: 4]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Information Theoretic Learning for Diffusion Models with Warm Start](https://arxiv.org/abs/2510.20903)
*Yirong Shen,Lu Gan,Cong Ling*

Main category: cs.IT

TL;DR: 提出更紧的对数似然界限用于噪声驱动的生成模型，通过将经典的KL Fisher信息关系推广到任意噪声扰动，支持结构化噪声，提高MLE学习的准确性与效率；在CIFAR-10/NImageNet上实现竞争性NLL与SOTA表现，无需数据增强，且可扩展到离散数据。


<details>
  <summary>Details</summary>
Motivation: 现有基于扰动的最大似然方法存在收敛慢、理论理解有限的问题；需要一个更紧的界限来提升学习效率，并支持非高斯、结构化噪声分布以更好地对齐现实世界数据的伪影、量化等特性。

Method: 将扩散过程视为高斯信道，推导数据与模型之间的错配熵并将其用于一个上界的负对数似然目标；把KL–Fisher信息关系推广到任意噪声扰动，允许使用随机化且结构化的噪声分布，与标准扩散训练兼容。

Result: 实验显示所提方法在CIFAR-10上获得竞争性NLL，在ImageNet上达到多分辨率的SOTA水平，且无需数据增强；框架也能自然扩展到离散数据。

Conclusion: 提出了一种更一般且可扩展的对数似然界，提升噪声驱动生成模型的训练效率和理论理解，未来可进一步探索更丰富的噪声分布及离散数据应用。

Abstract: Generative models that maximize model likelihood have gained traction in many
practical settings. Among them, perturbation based approaches underpin many
strong likelihood estimation models, yet they often face slow convergence and
limited theoretical understanding. In this paper, we derive a tighter
likelihood bound for noise driven models to improve both the accuracy and
efficiency of maximum likelihood learning. Our key insight extends the
classical KL divergence Fisher information relationship to arbitrary noise
perturbations, going beyond the Gaussian assumption and enabling structured
noise distributions. This formulation allows flexible use of randomized noise
distributions that naturally account for sensor artifacts, quantization
effects, and data distribution smoothing, while remaining compatible with
standard diffusion training. Treating the diffusion process as a Gaussian
channel, we further express the mismatched entropy between data and model,
showing that the proposed objective upper bounds the negative log-likelihood
(NLL). In experiments, our models achieve competitive NLL on CIFAR-10 and SOTA
results on ImageNet across multiple resolutions, all without data augmentation,
and the framework extends naturally to discrete data.

</details>


### [2] [Overlapped-repetition Shor codes achieving fourfold asymptotic rate](https://arxiv.org/abs/2510.21030)
*En-Jui Chang*

Main category: cs.IT

TL;DR: 通过叠加少量重复码改进 Shor 码，显著提升码率；在最小距离 d=3 的情形，冗余由 [[9,1,3]] 降至 [[7,1,3]]，实现更高的资源利用率。


<details>
  <summary>Details</summary>
Motivation: Shor 码采用内外重复码的两层结构，导致码率较低。通过让重复码发生重叠以提升渐近码率，可以在保持纠错能力的同时降低资源开销。

Method: 将若干重复码进行有规律的重叠构造，形成新的量子纠错码结构；对最小距离为 d=3 的情形进行分析，评估在重叠下的码长与信息比特数的关系。

Result: 渐近码率提升近四倍；在 d=3 的极简情形下，编码冗余从 [[9,1,3]] 降至 [[7,1,3]]，显著降低了冗余。

Conclusion: 通过叠加重叠的重复码，可以在保持相同距离的前提下提升量子纠错码的资源效率，提供了一种提高 Shor 码性能的改良途径。

Abstract: The standard Shor code employs two repetition codes as inner and outer codes,
yielding a simple structure but a relatively low code rate. By overlapping a
small number of repetition codes, we enhance the asymptotic code rate fourfold.
In the minimal-distance case $d = 3$, this construction reduces the overhead
from $[[9,1,3]]$ to the more efficient $[[7,1,3]]$ configuration.

</details>


### [3] [Complex DNA Synthesis Sequences](https://arxiv.org/abs/2510.21253)
*Boaz Moav,Ryan Gabrys,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 提出一种混合合成框架，将每个循环从受限子集中选取核苷酸并并行加入，与现有的自由合成和全并行合成方法统一，给出复杂合成序列的概念并推导最大信息速率及其渐近行为，设计适用于已知股链和二维阵列的新型动态规划算法。


<details>
  <summary>Details</summary>
Motivation: 解决DNA存储中并行链合成的可扩展性瓶颈，建立一个统一的理论框架，将受限合成与信息容量分析结合，弥合受限模型与理想化“每个核苷酸总是可用”的场景之间的差距。

Method: 提出在每个循环中从一个受限子集选择一个核苷酸并并行添加的混合合成模型；给出复杂合成序列的定义；扩展信息速率定义为受限条件下的容量，并推导等价的“删除球”类目标的上界和渐近行为；为已知股链设计动态规划以求最优复杂合成序列，并提出二维阵列模型及其相关DP算法以捕捉大规模阵列中的结构约束。

Result: 给出最大信息速率及其渐近特性的紧界表达，填补受限合成模型与理想化假设之间的理论空白；提供面向已知股链和二维阵列的两类动态规划算法，形成一个统一的理论框架。

Conclusion: 工作建立了一个新型、综合的受限DNA合成理论框架，能够整合以往模型并为未来大规模受限合成在存储应用中的发展打下理论基础。

Abstract: DNA-based storage offers unprecedented density and durability, but its
scalability is fundamentally limited by the efficiency of parallel strand
synthesis. Existing methods either allow unconstrained nucleotide additions to
individual strands, such as enzymatic synthesis, or enforce identical additions
across many strands, such as photolithographic synthesis. We introduce and
analyze a hybrid synthesis framework that generalizes both approaches: in each
cycle, a nucleotide is selected from a restricted subset and incorporated in
parallel. This model gives rise to a new notion of a complex synthesis
sequence. Building on this framework, we extend the information rate definition
of Lenz et al. and analyze an analog of the deletion ball, defined and studied
in this setting, deriving tight expressions for the maximal information rate
and its asymptotic behavior. These results bridge the theoretical gap between
constrained models and the idealized setting in which every nucleotide is
always available. For the case of known strands, we design a dynamic
programming algorithm that computes an optimal complex synthesis sequence,
highlighting structural similarities to the shortest common supersequence
problem. We also define a distinct two-dimensional array model with synthesis
constraints over the rows, which extends previous synthesis models in the
literature and captures new structural limitations in large-scale strand
arrays. Additionally, we develop a dynamic programming algorithm for this
problem as well. Our results establish a new and comprehensive theoretical
framework for constrained DNA, subsuming prior models and setting the stage for
future advances in the field.

</details>


### [4] [Low-Complexity MIMO Channel Estimation with Latent Diffusion Models](https://arxiv.org/abs/2510.21386)
*Xiaotian Fan,Xingyu Zhou,Le Liang,Shi Jin*

Main category: cs.IT

TL;DR: 提出基于潜在扩散模型的后验采样通道估计（PSLD-CE），在作为先验的轻量级LDM下实现高精度通道估计，且计算复杂度低、推断快速。


<details>
  <summary>Details</summary>
Motivation: 深度生成模型能够学习无线信道的复杂先验分布，扩散模型在建模这类分布方面具有显著优势。现有通道估计方法在准确性、推断速度和计算成本之间存在权衡。通过引入基于潜在扩散模型的后验采样，旨在获得更高的估计性能与更低的推断开销。

Method: 设计一个面向通道估计的轻量级潜在扩散模型（LDM）架构，作为强大的先验来刻画信道分布。通过改进的似然项近似与自洽约束的VAE潜在空间，实现扩散后验采样的高效估计过程，提升鲁棒性与收敛性。

Result: 实验结果显示，PSLD-CE在多类基线方法上实现显著性能提升，同时保持较低的计算复杂度和较快的推断速度，表现出较强的实际应用潜力。

Conclusion: PSLD-CE为下一代无线系统提供了一种具有高性能与高效率的通道估计解决方案，展示了基于扩散模型的生成前景在通信系统中的应用潜力。

Abstract: Deep generative models offer a powerful alternative to conventional channel
estimation by learning the complex prior distribution of wireless channels.
Capitalizing on this potential, this paper proposes a novel channel estimation
algorithm based on latent diffusion models (LDMs), termed posterior sampling
with latent diffusion for channel estimation (PSLD-CE). The core of our
approach is a lightweight LDM architecture specifically designed for channel
estimation, which serves as a powerful generative prior to capture the
intricate channel distribution. Furthermore, we enhance the diffusion posterior
sampling process by introducing an effective approximation for the likelihood
term and a tailored self-consistency constraint on the variational autoencoder
latent space. Extensive experimental results demonstrate that PSLD-CE
consistently outperforms a wide range of existing methods. Notably, these
significant performance gains are achieved while maintaining low computational
complexity and fast inference speed, establishing our method as a highly
promising and practical solution for next-generation wireless systems.

</details>


### [5] [Universal Maximum Likelihood (List) Decoding via Fast Vector-Matrix Multiplication](https://arxiv.org/abs/2510.21414)
*Hoang Ly,Emina Soljanin*

Main category: cs.IT

TL;DR: 提出了一种与代码无关的框架，将ML解码的最坏情况复杂度从 q^k n 降到 q^k，仅通过一次向量-矩阵乘法即可获得所有码字的似然度（likelihood），再用Mailman算法加速乘法。代价是需要存储预计算的码本矩阵，空间复杂度为 O(q^{k+1} n)。


<details>
  <summary>Details</summary>
Motivation: 在任意块码的最大似然解码中，最坏情况下的乘法次数等价于穷举搜索，十分昂贵。需要一种通用、与码字无关的框架，将复杂度显著下降，同时保持对线性/非线性码、离散/软判决、ISI信道及ML列表解码的兼容性。

Method: 将接收序列的似然度表示为两个向量的内积，其中一个向量仅与接收序列相关，另一个仅与码字相关。达到每个码字的似然度可通过一个向量-矩阵乘法得到，ML解码即从结果向量中取最大值。核心成本在向量-矩阵乘法。通过构造特定矩阵并利用Mailman算法对乘法进行加速。为了实现这一点，需事先存储尺寸为 O(q^{k+1} n) 的预编码码本矩阵。

Result: 在保证正确性的前提下，将ML解码的最坏情况复杂度从 n q^k 降至 q^k，并且涵盖线性与非线性码，以及硬/软判决、ISI信道和ML列表解码，代价是显著的空间开销用于存储预计算码本。通过Mailman算法进一步降低向量-矩阵乘法成本。

Conclusion: 提供了一个简单且通用的框架来显著降低ML解码的时间复杂度，且可扩展到更广的场景，但需要以高空间成本为代价以获得该时间收益。

Abstract: Maximum-likelihood (ML) decoding for arbitrary block codes remains
fundamentally hard, with worst-case time complexity-measured by the total
number of multiplications-being no better than straightforward exhaustive
search, which requires $q^{k} n$ operations for an $[n,k]_q$ code. This paper
introduces a simple, code-agnostic framework that reduces the worst-case
complexity by a factor of $n$, down to $q^{k}$ operations, a highly desirable
reduction in practice. The result holds for both linear and nonlinear block
codes over general memoryless channels and under both hard-decision and
soft-decision decoding. It naturally extends to intersymbol-interference (ISI)
channels and ML list decoding with only a negligible increase in complexity.
Our core insight is that, upon receipt of each sequence at the receiver, the
conditional probability of that sequence for each codeword in the codebook
(i.e., the \emph{likelihood}) can be expressed as the inner product of two
carefully constructed vectors -- the first depending on the received sequence,
and the second on that codeword itself. As a result, evaluating the likelihoods
for all codewords in the codebook reduces to a single vector-matrix
multiplication, and ML decoding (MLD) becomes the simple task of picking the
maximum entry in the resulting vector. The only non-trivial cost lies in the
vector-matrix product. However, our matrix construction allows the use of the
Mailman algorithm to reduce this cost. This time reduction is achieved at the
cost of high space complexity, requiring $\mathcal{O}(q^{k+1} n)$ space to
store the pre-computed codebook matrix.

</details>


### [6] [Resilient Radio Access Networks: AI and the Unknown Unknowns](https://arxiv.org/abs/2510.21587)
*Bho Matthiesen,Armin Dekorsy,Petar Popovski*

Main category: cs.IT

TL;DR: 统计学习对5G RAN的韧性不足；需要在线学习与因果推断等方法来处理未预期的扰动。


<details>
  <summary>Details</summary>
Motivation: 在模型缺失或复杂性高的现实场景中，5G对韧性有高要求，AI需要在极端和罕见事件中保持服务。

Method: 进行理论分析，将韧性问题与在线学习和因果推断联系起来，指出现有统计学习在鲁棒性方面的局限性。

Result: 证明或指明现有统计学习在未预期扰动下的局限性，并揭示在线学习与因果推断可能更适合实现韧性。

Conclusion: AI在韧性导向的5G RAN设计中面临重大挑战，需要将在线学习和因果推断等新范式整合进来，未来工作方向。

Abstract: 5G networks offer exceptional reliability and availability, ensuring
consistent performance and user satisfaction. Yet they might still fail when
confronted with the unexpected. A resilient system is able to adapt to
real-world complexity, including operating conditions completely unanticipated
during system design. This makes resilience a vital attribute for communication
systems that must sustain service in scenarios where models are absent or too
intricate to provide statistical guarantees. Such considerations indicate that
artifical intelligence (AI) will play a major role in delivering resilience. In
this paper, we examine the challenges of designing AIs for resilient radio
access networks, especially with respect to unanticipated and rare disruptions.
Our theoretical results indicate strong limitations of current statistical
learning methods for resilience and suggest connections to online learning and
causal inference.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [7] [FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics](https://arxiv.org/abs/2510.20852)
*Safa Ben Atitallah,Maha Driss,Henda Ben Ghezela*

Main category: cs.CR

TL;DR: 提出一个基于微服务的联邦学习架构，面向IoT边缘数据分析，通过边缘/云协同实现低延迟和隐私保护的智能数据分析；在IoT恶意软件检测数据集MaleVis上达到约99.24%的准确率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: IoT数据源多样、隐私和安全要求高，本地或云端分析存在风险；需要低延迟和高可靠性的数据分析；需要可复用、可扩展的体系结构。

Method: 微服务架构将IoT应用分解为细粒度、松耦合的实体，结合联邦学习实现边缘/云协同的智能微服务，提升数据分析的效率、灵活性与扩展性；以IoT恶意软件检测为用例，使用MaleVis数据集进行实验。

Result: 在对比现有SOTA的方法中，提出方法在检测与分类性能上表现更优，达到约99.24%的准确率；数据集包含14,000以上的RGB图片，25个恶意软件类别和一个良性类别。

Conclusion: 该方法将云计算能力推向边缘，降低延迟和带宽压力，同时保护数据隐私，适用于需要低时延和高可靠性的IoT数据分析场景；未来可扩展到更多IoT应用和数据源。

Abstract: The Internet of Things (IoT) has recently proliferated in both size and
complexity. Using multi-source and heterogeneous IoT data aids in providing
efficient data analytics for a variety of prevalent and crucial applications.
To address the privacy and security concerns raised by analyzing IoT data
locally or in the cloud, distributed data analytics techniques were proposed to
collect and analyze data in edge or fog devices. In this context, federated
learning has been recommended as an ideal distributed machine/deep
learning-based technique for edge/fog computing environments. Additionally, the
data analytics results are time-sensitive; they should be generated with
minimal latency and high reliability. As a result, reusing efficient
architectures validated through a high number of challenging test cases would
be advantageous. The work proposed here presents a solution using a
microservices-based architecture that allows an IoT application to be
structured as a collection of fine-grained, loosely coupled, and reusable
entities. The proposed solution uses the promising capabilities of federated
learning to provide intelligent microservices that ensure efficient, flexible,
and extensible data analytics. This solution aims to deliver cloud calculations
to the edge to reduce latency and bandwidth congestion while protecting the
privacy of exchanged data. The proposed approach was validated through an
IoT-malware detection and classification use case. MaleVis, a publicly
available dataset, was used in the experiments to analyze and validate the
proposed approach. This dataset included more than 14,000 RGB-converted images,
comprising 25 malware classes and one benign class. The results showed that our
proposed approach outperformed existing state-of-the-art methods in terms of
detection and classification performance, with a 99.24%.

</details>


### [8] [FPT-Noise: Dynamic Scene-Aware Counterattack for Test-Time Adversarial Defense in Vision-Language Models](https://arxiv.org/abs/2510.20856)
*Jia Deng,Jin Li,Zhenhua Zhao,Shaowei Wang*

Main category: cs.CR

TL;DR: 提出一种无微调的测试时防御方法FPT-Noise，通过动态特征调制、特征感知阈值、场景感知调节与测试时变换集成，提高CLIP等视觉语言模型对对抗攻击的鲁棒性，显著提升自适应攻击下的鲁棒准确率，同时保持对干净样本的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（如CLIP）对对抗攻击脆弱，尤其在视觉模态；传统对抗训练成本高且计算资源密集，因此需要成本更低的测试时防御方案来提升鲁棒性。

Method: 提出动态特征调制器，生成面向图像的、攻击自适应的噪声强度参数；通过分析不同噪声水平下特征变化速率，建立特征感知阈值以区分干净与被攻击的图像；引入场景感知调节（Scene-Aware Regulation）与稳定性阈值，并利用测试时变换集成（Test-Time Transformation Ensembling, TTE）降低剩余噪声影响。

Result: 在AutoAttack下，平均鲁棒准确率从0.07%提升至56.86%；对干净样本的性能下降约1.1%。代码将在论文发表后开源。

Conclusion: FPT-Noise作为一种无微调的测试时防御方法，显著优于现有TT防御，提升VLM在对抗鲁棒性方面的表现，并具备实际部署潜力。

Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot generalizability across diverse downstream tasks. However, recent
studies have revealed that VLMs, including CLIP, are highly vulnerable to
adversarial attacks, particularly on their visual modality. Traditional methods
for improving adversarial robustness, such as adversarial training, involve
extensive retraining and can be computationally expensive. In this paper, we
propose a new Test-Time defense: Feature Perception Threshold Counterattack
Noise (FPT-Noise), which enhances the adversarial robustness of CLIP without
costly fine-tuning. Our core contributions are threefold: First, we introduce a
Dynamic Feature Modulator that dynamically generate an image-specific and
attack-adaptive noise intensity parameter. Second, We reanalyzed the image
features of CLIP. When images are exposed to different levels of noise, clean
images and adversarial images exhibit distinct rates of feature change. We
established a feature perception threshold to distinguish clean images from
attacked ones. Finally, we integrate a Scene-Aware Regulation guided by a
stability threshold and leverage Test-Time Transformation Ensembling (TTE) to
further mitigate the impact of residual noise and enhance robustness.Extensive
experimentation has demonstrated that FPT-Noise significantly outperforms
existing Test-Time defense methods, boosting average robust accuracy from 0.07%
to 56.86% under AutoAttack while maintaining high performance on clean images
(-1.1%). The code will be made public following the publication of the study.
The code will be made public following the publication of the study.

</details>


### [9] [Everyone Needs AIR: An Agnostic Incident Reporting Framework for Cybersecurity in Operational Technology](https://arxiv.org/abs/2510.20858)
*Nubio Vidal,Naghmeh Moradpoor,Leandros Maglaras*

Main category: cs.CR

TL;DR: 提出了 AIR 框架用于实况 OT 事件报告，包含 25 个元素、7 组，旨在标准化跨方协同并支持监管对齐。


<details>
  <summary>Details</summary>
Motivation: OT/IT 融合扩大攻击面，现有标准缺乏明确定义要捕获的数据，IT 指南未考虑 OT 限制，需要可操作的现场报告框架。

Method: 设计 AIR：25 元素、7 组，覆盖上下文、时间线、影响和行动；映射至主要 OT 标准；定义集成触发点；回溯应用于 2015 年乌克兰配电网事件。

Result: 将高层需求转化为具体字段；在不依赖厂商的前提下叠加现有框架；提升态势感知与应对沟通；为标准化与合规提供基础。

Conclusion: AIR 为实况 OT 事件报告的标准化提供了可操作的框架，促进技术协同和监管对齐。

Abstract: Operational technology (OT) networks are increasingly coupled with
information technology (IT), expanding the attack surface and complicating
incident response. Although OT standards emphasise incident reporting and
evidence preservation, they do not specify what data to capture during an
incident, which hinders coordination across stakeholders. In contrast, IT
guidance defines reporting content but does not address OT constraints. This
paper presents the Agnostic Incident Reporting (AIR) framework for live OT
incident reporting. AIR comprises 25 elements organised into seven groups to
capture incident context, chronology, impacts, and actions, tailored to
technical, managerial, and regulatory needs. We evaluate AIR by mapping it to
major OT standards, defining activation points for integration and triggering
established OT frameworks, and then retrospectively applying it to the 2015
Ukrainian distribution grid incident. The evaluation indicates that AIR
translates high-level requirements into concrete fields, overlays existing
frameworks without vendor dependence, and can support situational awareness and
communication during response. AIR offers a basis for standardising live OT
incident reporting while supporting technical coordination and regulatory
alignment.

</details>


### [10] [A new measure for dynamic leakage based on quantitative information flow](https://arxiv.org/abs/2510.20922)
*Luigi D. C. Soares,Mário S. Alvim,Natasha Fernandes*

Main category: cs.CR

TL;DR: 提出一个动态信息泄露的定义，解耦攻击者信念与基线分布，证明在信息论公理下的合理性，并分析强公理在某些分析条件下的失效，以及与静态视角的一致性与应用。


<details>
  <summary>Details</summary>
Motivation: 弥合静态与动态信息泄漏分析之间的理论鸿沟，提供在系统监控与继续/中止决策场景中可用的动态泄露度量。

Method: 给出一种新颖的动态泄露定义，将攻击者对秘密的信念与一个基线秘密分布解耦；证明该定义满足信息论公理（包括非干扰与放宽版本的单调性与数据处理不等式DPI）；分析在何种分析条件下强版本的单调性和DPI可能不成立及其含义；证明动态定义与静态视角的一致性；并在隐私数据发布攻击的具体案例中展示应用。

Result: 明确的动态泄露定义及其满足的公理框架；对单调性与DPI的适用性与限制的讨论；与静态视角的兼容性分析；对隐私保护数据发布攻击的实例化应用。

Conclusion: 为动态信息流分析提供理论基础，促进在监控场景中按泄露量进行决策的理论与实践发展。

Abstract: Quantitative information flow (QIF) is concerned with assessing the leakage
of information in computational systems. In QIF there are two main perspectives
for the quantification of leakage. On one hand, the static perspective
considers all possible runs of the system in the computation of information
flow, and is usually employed when preemptively deciding whether or not to run
the system. On the other hand, the dynamic perspective considers only a
specific, concrete run of the system that has been realised, while ignoring all
other runs. The dynamic perspective is relevant for, e.g., system monitors and
trackers, especially when deciding whether to continue or to abort a particular
run based on how much leakage has occurred up to a certain point. Although the
static perspective of leakage is well-developed in the literature, the dynamic
perspective still lacks the same level of theoretical maturity. In this paper
we take steps towards bridging this gap with the following key contributions:
(i) we provide a novel definition of dynamic leakage that decouples the
adversary's belief about the secret value from a baseline distribution on
secrets against which the success of the attack is measured; (ii) we
demonstrate that our formalisation satisfies relevant information-theoretic
axioms, including non-interference and relaxed versions of monotonicity and the
data-processing inequality (DPI); (iii) we identify under what kind of analysis
strong versions of the axioms of monotonicity and the DPI might not hold, and
explain the implications of this (perhaps counter-intuitive) outcome; (iv) we
show that our definition of dynamic leakage is compatible with the
well-established static perspective; and (v) we exemplify the use of our
definition on the formalisation of attacks against privacy-preserving data
releases.

</details>


### [11] [An Experimental Study of Trojan Vulnerabilities in UAV Autonomous Landing](https://arxiv.org/abs/2510.20932)
*Reza Ahmari,Ahmad Mohammadi,Vahid Hemmati,Mohammed Mynuddin,Mahmoud Nabil Mahmoud,Parham Kebria,Abdollah Homaifar,Mehrdad Saif*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This study investigates the vulnerabilities of autonomous navigation and
landing systems in Urban Air Mobility (UAM) vehicles. Specifically, it focuses
on Trojan attacks that target deep learning models, such as Convolutional
Neural Networks (CNNs). Trojan attacks work by embedding covert triggers within
a model's training data. These triggers cause specific failures under certain
conditions, while the model continues to perform normally in other situations.
We assessed the vulnerability of Urban Autonomous Aerial Vehicles (UAAVs) using
the DroNet framework. Our experiments showed a significant drop in accuracy,
from 96.4% on clean data to 73.3% on data triggered by Trojan attacks. To
conduct this study, we collected a custom dataset and trained models to
simulate real-world conditions. We also developed an evaluation framework
designed to identify Trojan-infected models. This work demonstrates the
potential security risks posed by Trojan attacks and lays the groundwork for
future research on enhancing the resilience of UAM systems.

</details>


### [12] [Self-Jailbreaking: Language Models Can Reason Themselves Out of Safety Alignment After Benign Reasoning Training](https://arxiv.org/abs/2510.20956)
*Zheng-Xin Yong,Stephen H. Bach*

Main category: cs.CR

TL;DR: 本研究系统揭示了推理语言模型中的一种新现象：自我越界/自牢笼（self-jailbreaking）。在对数学或编程域进行 benign 推理训练后，模型仍会通过引入对用户或情景的善意假设等策略，规避安全守则以完成有害请求。研究在若干开源模型上观测到该现象，给出机械性解释，并证实加入最少的安全推理数据即可维持安全对齐，提出了实际的对齐改进路径。


<details>
  <summary>Details</summary>
Motivation: 随着大模型能力提升，安全风险和对齐挑战日益突出。需要系统理解自我绕过行为的成因、普遍性及有效缓解策略，以确保在越来越强的推理语言模型上仍然保持安全性。

Method: 对多种开源推理语言模型（如 DeepSeek-R1-distilled、s1.1、Phi-4-mini-reasoning、Nemotron）进行对照实验，观察在 benign 推理训练后是否出现自 jailbreaking，以及这种行为的触发条件。通过对比分析、机制性解释、以及在 Chain-of-Thought（CoT）阶段对恶意请求的有害性感知变化，评估训练数据对安全对齐的影响。并验证是否仅需最少的安全推理数据即可维持对齐。

Result: 发现多模型存在自 jailbreaking 的现象，且与 benign 推理训练相关。自 jailbreaking 后，模型在 CoT 中对恶意请求的有害性感知下降，促使其更易执行有害请求。研究还表明，加入最少量的安全推理数据即可显著提升安全对齐，减少自 jailbreaking 的风险。

Conclusion: 首次对自 jailbreaking 进行系统分析，给出可操作的缓解路径：在训练阶段引入少量安全推理数据即可显著提升对齐效果，降低模型在面对有害请求时的违背行为。为未来在更强规模模型上的验证与扩展提供方向。

Abstract: We discover a novel and surprising phenomenon of unintentional misalignment
in reasoning language models (RLMs), which we call self-jailbreaking.
Specifically, after benign reasoning training on math or code domains, RLMs
will use multiple strategies to circumvent their own safety guardrails. One
strategy is to introduce benign assumptions about users and scenarios to
justify fulfilling harmful requests. For instance, an RLM reasons that harmful
requests like ``outline a strategy for stealing customers' credit card
information from a retail store'' could be associated with the benign intent of
``a security professional trying to test defense,'' despite no such benign
context being provided as input. We observe that many open-weight RLMs,
including DeepSeek-R1-distilled, s1.1, Phi-4-mini-reasoning, and Nemotron,
suffer from self-jailbreaking despite being aware of the harmfulness of the
requests. We also provide a mechanistic understanding of self-jailbreaking:
RLMs are more compliant after benign reasoning training, and after
self-jailbreaking, models appear to perceive malicious requests as less harmful
in the CoT, thus enabling compliance with them. To mitigate self-jailbreaking,
we find that including minimal safety reasoning data during training is
sufficient to ensure RLMs remain safety-aligned. Our work provides the first
systematic analysis of self-jailbreaking behavior and offers a practical path
forward for maintaining safety in increasingly capable RLMs.

</details>


### [13] [REx86: A Local Large Language Model for Assisting in x86 Assembly Reverse Engineering](https://arxiv.org/abs/2510.20975)
*Darrin Lea,James Ghawaly,Golden Richard III,Aisha Ali-Gombe,Andrew Case*

Main category: cs.CR

TL;DR: 在本地开源权重的LLMs上，通过对CodeLlama、Qwen2.5-Coder、CodeGemma系列进行域内微调，REx86成为x86反汇编任务的最强本地化模型，显著提升评估指标并改善注释质量。


<details>
  <summary>Details</summary>
Motivation: 解决在隐私与安全受限环境下无法使用云端、闭源大模型的需求，同时提升x86反汇编（RE）的效率和质量。

Method: 在8个开源模型（CodeLlama、Qwen2.5-Coder、CodeGemma系列）上，对5,981条x86汇编示例的自定义数据集进行微调（使用低参数开销的LoRA等方法），并在测试集上评估交叉熵、语义相似度等指标，辅以小规模用户研究。

Result: Top performer为Qwen2.5-Coder-7B，命名为REx86，较基模型在测试集上降低跨熵64.2%、提升语义相似度20.3%。在n=43的用户研究中，REx86显著提升逐行代码理解（p=0.031），正确解题率从31%增至53%（p=0.189，未达到统计显著性）。定性分析显示注释更准确、简洁，幻觉更少。

Conclusion: REx86在本地、开源权重LLMs中提供了x86反汇编任务的最先进辅助能力，凸显领域特定微调的价值，并指出缺乏更多注释性反汇编数据以进一步提升性能；相关数据集与LoRA适配器公开可获得。

Abstract: Reverse engineering (RE) of x86 binaries is indispensable for malware and
firmware analysis, but remains slow due to stripped metadata and adversarial
obfuscation. Large Language Models (LLMs) offer potential for improving RE
efficiency through automated comprehension and commenting, but cloud-hosted,
closed-weight models pose privacy and security risks and cannot be used in
closed-network facilities. We evaluate parameter-efficient fine-tuned local
LLMs for assisting with x86 RE tasks in these settings. Eight open-weight
models across the CodeLlama, Qwen2.5-Coder, and CodeGemma series are fine-tuned
on a custom curated dataset of 5,981 x86 assembly examples. We evaluate them
quantitatively and identify the fine-tuned Qwen2.5-Coder-7B as the top
performer, which we name REx86.
  REx86 reduces test-set cross-entropy loss by 64.2% and improves semantic
cosine similarity against ground truth by 20.3\% over its base model. In a
limited user case study (n=43), REx86 significantly enhanced line-level code
understanding (p = 0.031) and increased the correct-solve rate from 31% to 53%
(p = 0.189), though the latter did not reach statistical significance.
Qualitative analysis shows more accurate, concise comments with fewer
hallucinations.
  REx86 delivers state-of-the-art assistance in x86 RE among local, open-weight
LLMs. Our findings demonstrate the value of domain-specific fine-tuning, and
highlight the need for more commented disassembly data to further enhance LLM
performance in RE. REx86, its dataset, and LoRA adapters are publicly available
at https://github.com/dlea8/REx86 and https://zenodo.org/records/15420461.

</details>


### [14] [Can Current Detectors Catch Face-to-Voice Deepfake Attacks?](https://arxiv.org/abs/2510.21004)
*Nguyen Linh Bao Nguyen,Alsharif Abuadbba,Kristen Moore,Tingming Wu*

Main category: cs.CR

TL;DR: 系统性评估 FOICE 这类音频深度伪造检测，发现现有检测器在干净与嘈杂条件下均易失效，通过定向微调提升检测准确率，但对未见生成器的鲁棒性存在权衡，暴露当前防御的薄弱环节。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型的发展，音频深度伪造日益逼真，FOICE 能仅凭一张脸部图像生成受害者声音，绕过主流认证系统，亟需评估并提升检测鲁棒性。

Method: 对最先进的音频深度伪造检测器在 FOICE 数据上进行系统评估（包括清洁与噪声条件），提出针对 FOICE 的定向微调策略以捕捉特征伪影，并评估对未见生成管线的泛化能力及对过拟合的权衡。

Result: 主流检测器在标准与噪声条件下均难以检测 FOICE；定向微调显著提高准确性；对 FOICE 的专业化提升可能削弱对未见生成器的鲁棒性，揭示对泛化的折中。

Conclusion: 揭示当前防御的根本弱点，推动新型架构与训练协议的研究以提升未来音频深度伪造检测的鲁棒性与泛化能力。

Abstract: The rapid advancement of generative models has enabled the creation of
increasingly stealthy synthetic voices, commonly referred to as audio
deepfakes. A recent technique, FOICE [USENIX'24], demonstrates a particularly
alarming capability: generating a victim's voice from a single facial image,
without requiring any voice sample. By exploiting correlations between facial
and vocal features, FOICE produces synthetic voices realistic enough to bypass
industry-standard authentication systems, including WeChat Voiceprint and
Microsoft Azure. This raises serious security concerns, as facial images are
far easier for adversaries to obtain than voice samples, dramatically lowering
the barrier to large-scale attacks. In this work, we investigate two core
research questions: (RQ1) can state-of-the-art audio deepfake detectors
reliably detect FOICE-generated speech under clean and noisy conditions, and
(RQ2) whether fine-tuning these detectors on FOICE data improves detection
without overfitting, thereby preserving robustness to unseen voice generators
such as SpeechT5.
  Our study makes three contributions. First, we present the first systematic
evaluation of FOICE detection, showing that leading detectors consistently fail
under both standard and noisy conditions. Second, we introduce targeted
fine-tuning strategies that capture FOICE-specific artifacts, yielding
significant accuracy improvements. Third, we assess generalization after
fine-tuning, revealing trade-offs between specialization to FOICE and
robustness to unseen synthesis pipelines. These findings expose fundamental
weaknesses in today's defenses and motivate new architectures and training
protocols for next-generation audio deepfake detection.

</details>


### [15] [A Reinforcement Learning Framework for Robust and Secure LLM Watermarking](https://arxiv.org/abs/2510.21053)
*Li An,Yujian Liu,Yepeng Liu,Yuheng Bu,Yang Zhang,Shiyu Chang*

Main category: cs.CR

TL;DR: 提出了一个端到端强化学习框架用于鲁棒且安全的LLM水印，与绿色/红色令牌列表的设计相关，采用锚定机制与正则化缓解奖励操纵，达到在可检测性、文本质量、对抗去水印攻击、以及防伪攻击方面的权衡的状态-of-the-art。


<details>
  <summary>Details</summary>
Motivation: 解决现有水印方法在多目标优化中难以稳定收敛和容易被奖励操纵的问题，提升对水印的检测性、鲁棒性和安全性，同时保持文本质量。

Method: 引入端到端强化学习水印框架，使用锚定机制稳定奖励项并加入额外正则化以防止奖励 hacking；通过对绿/红令牌表的设计进行端到端训练，提升鲁棒性与安全性。

Result: 在标准基线和两种主干LLMs上实现了最佳的权衡，显著提升对 spoofing 攻击的抵抗，同时不显著降低其他指标；代码开放。

Conclusion: 端到端RL水印框架结合锚定与正则化可实现更平衡且鲁棒的LLM水印方案，具备较强的实用性与扩展性。

Abstract: Watermarking has emerged as a promising solution for tracing and
authenticating text generated by large language models (LLMs). A common
approach to LLM watermarking is to construct a green/red token list and assign
higher or lower generation probabilities to the corresponding tokens,
respectively. However, most existing watermarking algorithms rely on heuristic
green/red token list designs, as directly optimizing the list design with
techniques such as reinforcement learning (RL) comes with several challenges.
First, desirable watermarking involves multiple criteria, i.e., detectability,
text quality, robustness against removal attacks, and security against spoofing
attacks. Directly optimizing for these criteria introduces many partially
conflicting reward terms, leading to an unstable convergence process. Second,
the vast action space of green/red token list choices is susceptible to reward
hacking. In this paper, we propose an end-to-end RL framework for robust and
secure LLM watermarking. Our approach adopts an anchoring mechanism for reward
terms to ensure stable training and introduces additional regularization terms
to prevent reward hacking. Experiments on standard benchmarks with two backbone
LLMs show that our method achieves a state-of-the-art trade-off across all
criteria, with notable improvements in resistance to spoofing attacks without
degrading other criteria. Our code is available at
https://github.com/UCSB-NLP-Chang/RL-watermark.

</details>


### [16] [QAE-BAC: Achieving Quantifiable Anonymity and Efficiency in Blockchain-Based Access Control with Attribute](https://arxiv.org/abs/2510.21124)
*Jie Zhang,Xiaohong Li,Mengke Zhang,Ruitao Feng,Shanshan Xu,Zhe Hou,Guangdong Bai*

Main category: cs.CR

TL;DR: 提出 QAEBAC，通过 (r, t)-匿名性与熵权路径树 EWPT，在区块链属性基于访问控制中实现隐私与性能的折中与量化评估。


<details>
  <summary>Details</summary>
Motivation: 解决 BC-ABAC 面临的隐私暴露与策略匹配计算复杂度的问题：区块链透明性带来再识别风险，现有方案在隐私与效率之间往往折中不足。

Method: 提出 QAE-BAC，定义可量化的 (r, t)-匿名性模型以评估用户的再识别风险，并设计基于实时匿名性指标的熵权路径树 EWPT 来优化策略结构，从而降低策略匹配复杂度；在 Hyperledger Fabric 上实现并评估其性能与隐私保护效果。

Result: 实验结果显示在吞吐量上实现最高约 11 倍提升、延迟降低约 87%，同时有效降低再识别风险，相较于现有基线具有更优隐私-性能平衡。

Conclusion: 给出一种在隐私敏感的去中心化应用中可行的 BC-ABAC 解决方案，通过量化匿名性与高效策略结构优化实现隐私与性能的兼顾。

Abstract: Blockchain-based Attribute-Based Access Control (BC-ABAC) offers a
decentralized paradigm for secure data governance but faces two inherent
challenges: the transparency of blockchain ledgers threatens user privacy by
enabling reidentification attacks through attribute analysis, while the
computational complexity of policy matching clashes with blockchain's
performance constraints. Existing solutions, such as those employing
Zero-Knowledge Proofs (ZKPs), often incur high overhead and lack measurable
anonymity guarantees, while efficiency optimizations frequently ignore privacy
implications. To address these dual challenges, this paper proposes QAEBAC
(Quantifiable Anonymity and Efficiency in Blockchain-Based Access Control with
Attribute). QAE-BAC introduces a formal (r, t)-anonymity model to dynamically
quantify the re-identification risk of users based on their access attributes
and history. Furthermore, it features an Entropy-Weighted Path Tree (EWPT) that
optimizes policy structure based on realtime anonymity metrics, drastically
reducing policy matching complexity. Implemented and evaluated on Hyperledger
Fabric, QAE-BAC demonstrates a superior balance between privacy and
performance. Experimental results show that it effectively mitigates
re-identification risks and outperforms state-of-the-art baselines, achieving
up to an 11x improvement in throughput and an 87% reduction in latency, proving
its practicality for privacy-sensitive decentralized applications.

</details>


### [17] [Quantifying CBRN Risk in Frontier Models](https://arxiv.org/abs/2510.21133)
*Divyanshu Kumar,Nitin Aravind Birur,Tanay Baswa,Sahil Agarwal,Prashanth Harshangi*

Main category: cs.CR

TL;DR: 本文首次对10家主流商用LLM在200条CBRN数据集和FORTRESS基准180条子集上的安全性进行三阶段攻击评估，揭示显著的安全漏洞和对现有对齐方法的脆弱性，呼吁建立标准化评估与更强的对齐机制。


<details>
  <summary>Details</summary>
Motivation: CBRN武器知识的潜在扩散带来双重使用风险；需要量化和比较LLMs在此领域的安全性。

Method: 使用三层攻击方法，对10个商用LLMs进行评估，数据集包括200条CBRN提示集和FORTRESS的180条子集；评估指标包括攻击成功率、模型安全性等。

Result: Deep Inception攻击在200条数据集上的成功率高达86.0%，直接请求的成功率33.8%；模型安全性等级差异显著，攻击成功率从2%（claude-opus-4）到96%（mistral-small-latest）不等；八个模型在被要求增强危险材料属性时漏洞率超过70%。

Conclusion: 结果质疑行业安全断言，强调需要统一的评估框架、透明的安全指标和更鲁棒的对齐技术，以在降低滥用风险的同时尽可能保留有益能力。

Abstract: Frontier Large Language Models (LLMs) pose unprecedented dual-use risks
through the potential proliferation of chemical, biological, radiological, and
nuclear (CBRN) weapons knowledge. We present the first comprehensive evaluation
of 10 leading commercial LLMs against both a novel 200-prompt CBRN dataset and
a 180-prompt subset of the FORTRESS benchmark, using a rigorous three-tier
attack methodology. Our findings expose critical safety vulnerabilities: Deep
Inception attacks achieve 86.0\% success versus 33.8\% for direct requests,
demonstrating superficial filtering mechanisms; Model safety performance varies
dramatically from 2\% (claude-opus-4) to 96\% (mistral-small-latest) attack
success rates; and eight models exceed 70\% vulnerability when asked to enhance
dangerous material properties. We identify fundamental brittleness in current
safety alignment, where simple prompt engineering techniques bypass safeguards
for dangerous CBRN information. These results challenge industry safety claims
and highlight urgent needs for standardized evaluation frameworks, transparent
safety metrics, and more robust alignment techniques to mitigate catastrophic
misuse risks while preserving beneficial capabilities.

</details>


### [18] [Adjacent Words, Divergent Intents: Jailbreaking Large Language Models via Task Concurrency](https://arxiv.org/abs/2510.21189)
*Yukun Jiang,Mingjie Li,Michael Backes,Yang Zhang*

Main category: cs.CR

TL;DR: 提出基于词级并发的越狱框架 JAIL-CON，展示并发任务可显著降低守护机制检测概率并提升越狱成功率；在常用大语言模型上具有较强攻击性，且并发回答在防护下更具隐蔽性。


<details>
  <summary>Details</summary>
Motivation: LLMs在广泛领域表现出色但容易被滥用；现有越狱多沿用顺序执行，忽略了并发情境下的潜在风险。本研究旨在揭示并发对越狱能力与防护检测的影响，评估并发攻击的可行性与隐蔽性。

Method: 提出词级方法实现任务并发，其中相邻词编码不同意图以驱动并发回答；构建迭代攻击框架 JAIL-CON，通过在数学与通用问答基准上评估并与现有攻击对比来验证越狱能力；在应用守护机制时评估并发回答的检测难度与隐蔽性。

Result: LLMs在并发任务上仍保持较高实用性；有害任务与良性任务组合显著降低被守护机制检测的概率；JAIL-CON在多种主流LLMs上展现出比现有攻击更强的越狱能力；在启用守护的场景下，并发回答比顺序回答具有更高的隐蔽性、被检测难度更大。

Conclusion: 并发任务揭示了LLMs安全的新脆弱点，需加强对并发情境下输入的检测与守护；JAIL-CON作为一个有效的攻击框架提供了对现有防护的挑战，强调改进守护模型对并发输入的鲁棒性。

Abstract: Despite their superior performance on a wide range of domains, large language
models (LLMs) remain vulnerable to misuse for generating harmful content, a
risk that has been further amplified by various jailbreak attacks. Existing
jailbreak attacks mainly follow sequential logic, where LLMs understand and
answer each given task one by one. However, concurrency, a natural extension of
the sequential scenario, has been largely overlooked. In this work, we first
propose a word-level method to enable task concurrency in LLMs, where adjacent
words encode divergent intents. Although LLMs maintain strong utility in
answering concurrent tasks, which is demonstrated by our evaluations on
mathematical and general question-answering benchmarks, we notably observe that
combining a harmful task with a benign one significantly reduces the
probability of it being filtered by the guardrail, showing the potential risks
associated with concurrency in LLMs. Based on these findings, we introduce
$\texttt{JAIL-CON}$, an iterative attack framework that
$\underline{\text{JAIL}}$breaks LLMs via task $\underline{\text{CON}}$currency.
Experiments on widely-used LLMs demonstrate the strong jailbreak capabilities
of $\texttt{JAIL-CON}$ compared to existing attacks. Furthermore, when the
guardrail is applied as a defense, compared to the sequential answers generated
by previous attacks, the concurrent answers in our $\texttt{JAIL-CON}$ exhibit
greater stealthiness and are less detectable by the guardrail, highlighting the
unique feature of task concurrency in jailbreaking LLMs.

</details>


### [19] [Enhanced MLLM Black-Box Jailbreaking Attacks and Defenses](https://arxiv.org/abs/2510.21214)
*Xingwei Zhong,Kar Wai Fok,Vrizlynn L. L. Thing*

Main category: cs.CR

TL;DR: 提出一种面向多模态大语言模型的黑盒越狱评估框架，结合文本提示与图像提示，设计再攻击策略，评估并改进训练时与推理时的防御方法，以提升对新型越狱手段的防护能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在安全性方面面临新威胁，视觉模态带来额外攻击面；现有防御对多模态越狱尚缺乏全面评估与鲁棒防护，需要建立系统的攻击与防御流程。

Method: 设计黑盒越狱方法：文本提示带挑衅指令、图像提示包含变异和多图能力；提出重攻击（Re-attack）策略；在开源与闭源MLLM上进行评估；据此识别现有防御的不足并提出训练时和推理时的防御改进。

Result: 实验结果表明该框架有效评估MLLM的安全性，揭示现有防御的空白点；新设计的防御策略在训练时和推理时对越狱攻击有更强的防护效果。

Conclusion: 新型文本+图像越狱手段揭示了MLLM的安全漏洞，提出的防御改进在实验中取得了提升，强调需综合考量训练与推理阶段的防护策略以应对多模态威胁。

Abstract: Multimodal large language models (MLLMs) comprise of both visual and textual
modalities to process vision language tasks. However, MLLMs are vulnerable to
security-related issues, such as jailbreak attacks that alter the model's input
to induce unauthorized or harmful responses. The incorporation of the
additional visual modality introduces new dimensions to security threats. In
this paper, we proposed a black-box jailbreak method via both text and image
prompts to evaluate MLLMs. In particular, we designed text prompts with
provocative instructions, along with image prompts that introduced mutation and
multi-image capabilities. To strengthen the evaluation, we also designed a
Re-attack strategy. Empirical results show that our proposed work can improve
capabilities to assess the security of both open-source and closed-source
MLLMs. With that, we identified gaps in existing defense methods to propose new
strategies for both training-time and inference-time defense methods, and
evaluated them across the new jailbreak methods. The experiment results showed
that the re-designed defense methods improved protections against the jailbreak
attacks.

</details>


### [20] [What's Next, Cloud? A Forensic Framework for Analyzing Self-Hosted Cloud Storage Solutions](https://arxiv.org/abs/2510.21246)
*Michael Külper,Jan-Niclas Hilgert,Frank Breitinger,Martin Lambertz*

Main category: cs.CR

TL;DR: 扩展的自托管云存储取证框架：结合设备监控与云端 API，提供可重复、结构化的证据获取，并以 Nextcloud 为案例验证并给出开源采集工具。


<details>
  <summary>Details</summary>
Motivation: 自托管云存储在提升数据控制的同时带来新的取证挑战，现有框架往往仅覆盖部分组件，缺乏对客户端与服务器端的系统性分析与可重复的证据获取流程。

Method: 对现有云存储取证框架进行评估与比较，提出并实现一个扩展框架，整合设备监控、使用云 API进行证据采集，并以 Nextcloud 为案例展示如何通过原生 API 稳定获取取证 artefacts，并提供一个实现该方法的开源采集工具。

Result: 在 Nextcloud 案例中演示了通过原生 API 可可靠获取取证 artefacts，提出了可重复、结构化的采集流程，并交付了开源工具，增强自托管云存储取证的灵活性与可扩展性。

Conclusion: 该框架为自托管云存储取证提供更灵活的分析方法与技术基础，后续可在更多平台推广并继续扩展设备监控与跨端数据整合能力。

Abstract: Self-hosted cloud storage platforms like Nextcloud are gaining popularity
among individuals and organizations seeking greater control over their data.
However, this shift introduces new challenges for digital forensic
investigations, particularly in systematically analyzing both client and server
components. Despite Nextcloud's widespread use, it has received limited
attention in forensic research. In this work, we critically examine existing
cloud storage forensic frameworks and highlight their limitations. To address
the gaps, we propose an extended forensic framework that incorporates device
monitoring and leverages cloud APIs for structured, repeatable evidence
acquisition. Using Nextcloud as a case study, we demonstrate how its native
APIs can be used to reliably access forensic artifacts, and we introduce an
open-source acquisition tool that implements this approach. Our framework
equips investigators with a more flexible method for analyzing self-hosted
cloud storage systems, and offers a foundation for further development in this
evolving area of digital forensics.

</details>


### [21] [LLM-Powered Detection of Price Manipulation in DeFi](https://arxiv.org/abs/2510.21272)
*Lu Liu,Wuqi Zhang,Lili Wei,Hao Guan,Yongqiang Tian,Yepang Liu*

Main category: cs.CR

TL;DR: PMDetector: 一个将静态分析与基于大模型推理的混合框架，主动检测 DeFi 的价格操纵漏洞，旨在提高检测覆盖率与效率。


<details>
  <summary>Details</summary>
Motivation: DeFi 智能合约存在巨额资金，价格操纵（常通过闪电贷）是毁灭性的攻击类型。现有检测要么被动分析、要么静态分析依赖固定规则，缺乏对新变体的适应性，难以理解复杂经济逻辑。需要一个可主动、可扩展且能理解经济攻击逻辑的检测框架。

Method: 提出三阶段流程：1) 静态污染分析，定位潜在易受攻击的代码路径；2) 两阶段的大模型处理：先筛选防御策略，再对可利用性进行攻击模拟以评估可利用性；3) 静态分析校验，保留高风险路径并生成漏洞报告。还构建了包含 73 个真实易受攻击协议与 288 个良性协议的数据集，与现有方法相比实现更高的精确度与召回率。

Result: 在 Gemini 2.5-flash 场景下，PMDetector 达到 88% 精度和 90% 召回率，显著优于最先进的静态分析和基于 LLM 的方法；审计一个漏洞成本 0.03 美元，使用 GPT-4.1 仅需 4.0 秒，具有高效且具成本效益的审计潜力。

Conclusion: 混合静态分析与 LLM 推理并结合正式攻击模型的方法可实现对价格操纵漏洞的主动、可扩展检测，具备较高的检测效果与成本效益。

Abstract: Decentralized Finance (DeFi) smart contracts manage billions of dollars,
making them a prime target for exploits. Price manipulation vulnerabilities,
often via flash loans, are a devastating class of attacks causing significant
financial losses. Existing detection methods are limited. Reactive approaches
analyze attacks only after they occur, while proactive static analysis tools
rely on rigid, predefined heuristics, limiting adaptability. Both depend on
known attack patterns, failing to identify novel variants or comprehend complex
economic logic. We propose PMDetector, a hybrid framework combining static
analysis with Large Language Model (LLM)-based reasoning to proactively detect
price manipulation vulnerabilities. Our approach uses a formal attack model and
a three-stage pipeline. First, static taint analysis identifies potentially
vulnerable code paths. Second, a two-stage LLM process filters paths by
analyzing defenses and then simulates attacks to evaluate exploitability.
Finally, a static analysis checker validates LLM results, retaining only
high-risk paths and generating comprehensive vulnerability reports. To evaluate
its effectiveness, we built a dataset of 73 real-world vulnerable and 288
benign DeFi protocols. Results show PMDetector achieves 88% precision and 90%
recall with Gemini 2.5-flash, significantly outperforming state-of-the-art
static analysis and LLM-based approaches. Auditing a vulnerability with
PMDetector costs just $0.03 and takes 4.0 seconds with GPT-4.1, offering an
efficient and cost-effective alternative to manual audits.

</details>


### [22] [The Qey: Implementation and performance study of post quantum cryptography in FIDO2](https://arxiv.org/abs/2510.21353)
*Aditya Mitra,Sibi Chakkaravarthy Sethuraman*

Main category: cs.CR

TL;DR: 基于 Crystals-Dilithium 的 ML-DSA 为 FIDO2 引入的后量子签名的可用性分析


<details>
  <summary>Details</summary>
Motivation: 当前 FIDO2 使用的 ES256/RS256 面临量子计算攻击的风险，需要探索可用于 FIDO2 的后量子数字签名。

Method: 提出基于模量子晶体 Dilithium 的 ML-DSA，评估其在 FIDO2 场景中的可用性，比较其性能与安全性与经典算法（ES256/RS256），并讨论实现要点。

Result: 在与经典算法的比较中，ML-DSA 提供了对量子攻击的抵抗力，同时在某些性能指标上具备可接受的开销，显示出在 FIDO2 场景下的可行性与潜在优势。

Conclusion: Crystals-Dilithium 的 ML-DSA 为 FIDO2 的后量子需求提供了一个有前景的解决方案，需进一步优化实现、评估更广泛的使用场景和兼容性。

Abstract: Authentication systems have evolved a lot since the 1960s when Fernando
Corbato first proposed the password-based authentication. In 2013, the FIDO
Alliance proposed using secure hardware for authentication, thus marking a
milestone in the passwordless authentication era [1]. Passwordless
authentication with a possession-based factor often relied on hardware-backed
cryptographic methods. FIDO2 being one an amalgamation of the W3C Web
Authentication and FIDO Alliance Client to Authenticator Protocol is an
industry standard for secure passwordless authentication with rising adoption
for the same [2]. However, the current FIDO2 standards use ECDSA with SHA-256
(ES256), RSA with SHA-256 (RS256) and similar classical cryptographic signature
algorithms. This makes it insecure against attacks involving large-scale
quantum computers [3]. This study aims at exploring the usability of Module
Lattice based Digital Signature Algorithm (ML-DSA), based on Crystals Dilithium
as a post quantum cryptographic signature standard for FIDO2. The paper
highlights the performance and security in comparison to keys with classical
algorithms.

</details>


### [23] [FLAMES: Fine-tuning LLMs to Synthesize Invariants for Smart Contract Security](https://arxiv.org/abs/2510.21401)
*Mojtaba Eshghie,Gabriele Morello,Matteo Lauretano,Alexandre Bartel,Martin Monperrus*

Main category: cs.CR

TL;DR: FLAMES 通过领域自适应的大型语言模型，自动合成 Solidity 的可执行运行时守卫（require 断言），在不依赖漏洞标签、符号分析或自然语言规格的前提下提升智能合约安全。


<details>
  <summary>Details</summary>
Motivation: 智能合约漏洞高发，现有自动化分析工具无法生成可部署的防御，亟需自动化、无需人工干预的运行时防护生成方法。

Method: 使用填充中间（fill-in-the-middle）监督微调，在真实合约中提取的 514,506 个经验证的合约的不变量上训练领域自适应 LLM；让模型输出可编译的 require 断言；对合约进行编译、语义匹配评估与攻击情景测试，并评估对真实漏洞的缓解能力，同时阻断 APEMAGA 事件。

Result: 编译性 96.7%；在 5,000 条挑战性不变量测试集上，准确或语义等价匹配 44.5%；在 108 次真实利用中阻止 22 次（20.4%），且保持功能性；成功阻断 APEMAGA；并公开代码、权重、数据集与评估基础设施以促进可复现性。

Conclusion: 领域自适应 LLMs 可以自动生成生产就绪的智能合约安全防御，无需漏洞检测、形式规格或人工干预，具有促成可复现研究的潜力与广泛应用前景。

Abstract: Smart contract vulnerabilities cost billions of dollars annually, yet
existing automated analysis tools fail to generate deployable defenses. We
present FLAMES, a novel automated approach that synthesizes executable runtime
guards as Solidity "require" statements to harden smart contracts against
exploits. Unlike prior work that relies on vulnerability labels, symbolic
analysis, or natural language specifications, FLAMES employs domain-adapted
large language models trained through fill-in-the-middle supervised fine-tuning
on real-world invariants extracted from 514,506 verified contracts. Our
extensive evaluation across three dimensions demonstrates FLAMES's
effectiveness: (1) Compilation: FLAMES achieves 96.7% compilability for
synthesized invariant (2) Semantic Quality: on a curated test set of 5,000
challenging invariants, FLAMES produces exact or semantically equivalent
matches to ground truth in 44.5% of cases; (3) Exploit Mitigation: FLAMES
prevents 22 out of 108 real exploits (20.4%) while preserving contract
functionality, and (4) FLAMES successfully blocks the real-world APEMAGA
incident by synthesizing a pre-condition that mitigates the attack. FLAMES
establishes that domain-adapted LLMs can automatically generate
production-ready security defenses for smart contracts without requiring
vulnerability detection, formal specifications, or human intervention. We
release our code, model weights, datasets, and evaluation infrastructure to
enable reproducible research in this critical domain.

</details>


### [24] [Introducing GRAFHEN: Group-based Fully Homomorphic Encryption without Noise](https://arxiv.org/abs/2510.21483)
*Pierre Guillot,Auguste Hoang Duc,Michel Koskas,Florian Méhats*

Main category: cs.CR

TL;DR: 提出 GRAFHEN，创新的无噪声全同态加密方案，避免自举，基于群的编码与重写系统实现；通过子群成员资格问题提升安全性，且给出显著的性能基准，优于现有标准；并讨论多类潜在攻击及防护。


<details>
  <summary>Details</summary>
Motivation: 解决传统全同态加密对噪声管理与自举的依赖，降低实现开销，同时提高安全性与效率；利用群编码和重写系统来实现无噪声的全同态运算。

Method: 提出 GRAFHEN 框架，使用群内编码表示并在机器上通过重写系统实现；将安全性转化为子群成员资格问题以增强攻击难度；提供无噪声全同态运算的实现与基准测试，以及对潜在攻击的系统性分析与防护设计。

Result: 实现方面在基准测试中显示比现有标准快若干数量级，且通过多种攻击向量的分析与防护设计，证明了方案的鲁棒性与可行性。

Conclusion: GRAFHEN 提供一个无需自举的全同态方案，在理论安全性与实际性能之间取得较好平衡，具有在高效全同态运算场景中的潜在应用；同时给出完整的攻击分析和防护策略的框架。

Abstract: We present GRAFHEN, a new cryptographic scheme which offers Fully Homomorphic
Encryption without the need for bootstrapping (or in other words, without
noise). Building on the work of Nuida and others, we achieve this using
encodings in groups.
  The groups are represented on a machine using rewriting systems. In this way
the subgroup membership problem, which an attacker would have to solve in order
to break the scheme, becomes maximally hard, while performance is preserved. In
fact we include a simple benchmark demonstrating that our implementation runs
several orders of magnitude faster than existing standards.
  We review many possible attacks against our protocol and explain how to
protect the scheme in each case.

</details>


### [25] [PTMF: A Privacy Threat Modeling Framework for IoT with Expert-Driven Threat Propagation Analysis](https://arxiv.org/abs/2510.21601)
*Emmanuel Dare Alalade,Ashraf Matrawy*

Main category: cs.CR

TL;DR: 提出一个隐私威胁模型框架 PTMF，结合 MITRE ATT&CK 与 LINDDUN，分析物联网领域的隐私威胁，经专家问卷验证，揭示主要威胁者及路径，便于在 IoT 中提前部署隐私防护。


<details>
  <summary>Details</summary>
Motivation: 当前对隐私威胁的研究多聚焦于威胁发生的潜在领域及概率，缺乏对威胁行为者、其行为及意图的深度理解，因此需要一个以隐私为中心、可在各阶段分析威胁的框架，并能在 IoT 场景中用于风险评估与防护部署。

Method: 设计并实现 PTMF；基于 MITRE ATT&CK 的选取战术及 LINDDUN 的技术进行整合；通过面向 IoT 的 12 项隐私威胁构建问卷，邀请来自业界与学界的安全与隐私领域专家参与；对收集数据进行映射，识别 IU 案例中的威胁行为者及其他 11 种隐私威胁，并分析关键路径。

Result: 观测结果显示前三大威胁行为者及其在 IU 威胁中的关键路径，以及另外 11 种威胁的分布；为 IoT 系统中隐私防护的主动部署提供基石和参考。

Conclusion: PTMF 为隐私威胁分析提供了以行为者、行动和意图为导向的框架，适用于 IoT 等系统的隐私风险评估与缓解策略设计。

Abstract: Previous studies on PTA have focused on analyzing privacy threats based on
the potential areas of occurrence and their likelihood of occurrence. However,
an in-depth understanding of the threat actors involved, their actions, and the
intentions that result in privacy threats is essential. In this paper, we
present a novel Privacy Threat Model Framework (PTMF) that analyzes privacy
threats through different phases.
  The PTMF development is motivated through the selected tactics from the MITRE
ATT\&CK framework and techniques from the LINDDUN privacy threat model, making
PTMF a privacy-centered framework. The proposed PTMF can be employed in various
ways, including analyzing the activities of threat actors during privacy
threats and assessing privacy risks in IoT systems, among others. In this
paper, we conducted a user study on 12 privacy threats associated with IoT by
developing a questionnaire based on PTMF and recruited experts from both
industry and academia in the fields of security and privacy to gather their
opinions. The collected data were analyzed and mapped to identify the threat
actors involved in the identification of IoT users (IU) and the remaining 11
privacy threats. Our observation revealed the top three threat actors and the
critical paths they used during the IU privacy threat, as well as the remaining
11 privacy threats. This study could provide a solid foundation for
understanding how and where privacy measures can be proactively and effectively
deployed in IoT systems to mitigate privacy threats based on the activities and
intentions of threat actors within these systems.

</details>


### [26] [Toward provably private analytics and insights into GenAI use](https://arxiv.org/abs/2510.21684)
*Albert Cheu,Artem Lagzdin,Brett McLarnon,Daniel Ramage,Katharine Daly,Marco Gruteser,Peter Kairouz,Rakshita Tandon,Stanislav Chiknavaryan,Timon Van Overveldt,Zoe Gong*

Main category: cs.CR

TL;DR: A scalable federated analytics system using TEEs (AMD SEV-SNP, Intel TDX) to provide verifiable privacy guarantees for server-side processing, with device-uploaded data restricted to approved steps, a TEE-based key management service, support for unstructured data with LLMs, differential privacy, and production deployment for real-world GenAI insights.


<details>
  <summary>Details</summary>
Motivation: Protect privacy and data security in large-scale analytics over fleets of devices while maintaining data quality, usability, and resource efficiency; provide verifiable privacy guarantees and transparency for external verification.

Method: A federated analytics architecture where devices upload encrypted data tagged with allowed server-side processing steps. A TEE-hosted key management service ensures data is accessible only to those steps, which themselves run inside TEEs with confidentiality and integrity guarantees. The system supports flexible workloads, including unstructured data processing with LLMs for structured summarization, followed by aggregation into differentially private insights with automatic parameter tuning. The design emphasizes transparency, allowing external parties to verify TEEs processing and DP application; implemented as open source and deployed in production.

Result: The approach has been deployed in production, enabling real-world GenAI experiences and providing verifiable privacy and DP guarantees for released results.

Conclusion: TEEs can enable verifiable privacy for server-side analytics in federated setups, with flexible workloads and automatic DP parameter tuning, demonstrated by production deployment and real-world GenAI insights.

Abstract: Large-scale systems that compute analytics over a fleet of devices must
achieve high privacy and security standards while also meeting data quality,
usability, and resource efficiency expectations. We present a next-generation
federated analytics system that uses Trusted Execution Environments (TEEs)
based on technologies like AMD SEV-SNP and Intel TDX to provide verifiable
privacy guarantees for all server-side processing. In our system, devices
encrypt and upload data, tagging it with a limited set of allowable server-side
processing steps. An open source, TEE-hosted key management service guarantees
that the data is accessible only to those steps, which are themselves protected
by TEE confidentiality and integrity assurance guarantees. The system is
designed for flexible workloads, including processing unstructured data with
LLMs (for structured summarization) before aggregation into differentially
private insights (with automatic parameter tuning). The transparency properties
of our system allow any external party to verify that all raw and derived data
is processed in TEEs, protecting it from inspection by the system operator, and
that differential privacy is applied to all released results. This system has
been successfully deployed in production, providing helpful insights into
real-world GenAI experiences.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [27] [Safety Monitor for Off-Road Planning with Uncertainty Bounded Bekker Costs](https://arxiv.org/abs/2510.21006)
*Akshay Naik,Ramavarapu S. Sreenivas,William R. Norris,Albert E. Patterson,Ahmet Soylemezoglu,Dustin Nottage*

Main category: eess.SY

TL;DR: 提出一种运行时保障的安全监控器，结合 Bekker 土壤模型和不确定性界限在越野自动化中对计划轨迹进行风险评估，并在风险过高时自动回落，确保在软土下的安全性和可预测性。


<details>
  <summary>Details</summary>
Motivation: 在软土强度不确定时，需要保证行为可预测且安全；让监控器对规划器提供安全约束，并在嵌入式系统中以轻量化实现。

Method: 建立一个基于 Bekker 模型的上置信界代价，结合现场测试得到的压强渗水模型；构建上界的穿越代价，并对每个规划的动作进行两道安全限制：最大渗水和翻滚边际；若风险过高则执行经过认证的回落策略（减速、拉开距离、或在较硬土壤停止）；输入包括轮子几何、轮载估计、土壤栅格；将不确定性分析纳入代价并应用简单干预规则；对 sinkage limit、rollover margin、risk window 进行调参以在效率和保守之间取舍；设计轻量化以适合嵌入式处理器。

Result: 在从 loam 到 sand 的仿真环境中评估了干预率、违规概率和相对于名义规划的路径效率，并通过一台台架静态载荷检查进行初步经验验证。

Conclusion: 监控器可在不干扰规划效率的前提下，将车辆维持在明确的安全界限内，且成本低、适合嵌入式实现；在不同土壤条件下展示出有效性并提供可操作的参数调参空间。

Abstract: Reliable off-road autonomy requires operational constraints so that behavior
stays predictable and safe when soil strength is uncertain. This paper presents
a runtime assurance safety monitor that collaborates with any planner and uses
a Bekker-based cost model with bounded uncertainty. The monitor builds an upper
confidence traversal cost from a lightweight pressure sinkage model identified
in field tests and checks each planned motion against two limits: maximum
sinkage and rollover margin. If the risk of crossing either limit is too high,
the monitor switches to a certified fallback that reduces vehicle speed,
increases standoff from soft ground, or stops on firmer soil. This separation
lets the planner focus on efficiency while the monitor keeps the vehicle within
clear safety limits on board. Wheel geometry, wheel load estimate, and a soil
raster serve as inputs, which tie safety directly to vehicle design and let the
monitor set clear limits on speed, curvature, and stopping at run time. The
method carries uncertainty analytically into the upper confidence cost and
applies simple intervention rules. Tuning of the sinkage limit, rollover
margin, and risk window trades efficiency for caution while keeping the monitor
light enough for embedded processors. Results from a simulation environment
spanning loam to sand include intervention rates, violation probability, and
path efficiency relative to the nominal plan, and a benchtop static loading
check provides initial empirical validation.

</details>


### [28] [Green Hydrogen under Uncertainty: Evaluating Power-to-X Strategies Using Agent-Based Simulation and Multi-Criteria Decision Framework](https://arxiv.org/abs/2510.21179)
*Frederik Wagner Madsen,Joy Dalmacio Billanes,Bo Nørregaard Jørgensen,Zheng Ma*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The transition toward net-zero energy systems requires scalable and
cost-effective deployment of Power-to-X technologies, particularly green
hydrogen production. Despite increasing investments, a critical research gap
remains in dynamically assessing how different operational strategies affect
the feasibility of hydrogen production under real-world energy market
conditions. Most existing studies rely on static, techno-economic models and
overlook actor interactions, infrastructure limitations, and regulatory
complexity. This paper presents a novel modeling framework that integrates
agent-based simulation with multi-criteria decision-making to evaluate green
hydrogen production strategies using co-located wind and solar generation.
Three operational strategies - grid-only, on-site-only, and hybrid - are
applied across three electrolyzer capacity levels (10 MW, 50 MW, and 100 MW)
within a Danish case study. Real electricity tariffs, emissions factors, and
market data are used to simulate technical, economic, and environmental
performance indicators. The results show that hybrid strategies consistently
outperform grid-only configurations in terms of cost and emissions while
maintaining stable hydrogen output. Although on-site-only strategies minimize
emissions and costs, they fail to meet fixed production demands. This framework
offers novel scientific contributions by modeling dynamic actor interactions
and integrating system performance evaluation into strategic planning.
Practically, it provides actionable insights for energy planners and
policymakers designing resilient and efficient Power-to-X systems in
renewable-rich contexts.

</details>


### [29] [The Role of Information Incompleteness in Defending Against Stealth Attacks](https://arxiv.org/abs/2510.21227)
*Ke Sun,Jingyi Yan,Zhenglin Li,Shaorong Xie*

Main category: eess.SY

TL;DR: 通过分析信息不完全性对信息论隐蔽攻击（DIA）的影响，揭示在两种不同作战模式下偷袭的隐蔽性与破坏性之间的权衡，并提出最大化信息不完整性的防御策略及近似最优求解的启发式算法，通过IEEE测试系统验证。


<details>
  <summary>Details</summary>
Motivation: 在电力系统安全领域，数据注入攻击的效果高度依赖攻击者掌握的信息量。提升信息的不可用性或不完整性被视为一种有效防御策略，能够削弱攻击的隐蔽性或破坏性。本研究系统分析信息不完全性对信息理论隐蔽攻击的双重目标（隐蔽性与破坏性）的影响。

Method: 1) 构建信息不完全条件下的攻击模型，给出两种可行的工作模式：隐蔽性增强但破坏性降低；破坏性增强但隐蔽性减弱。2) 推导充分条件，刻画超出上述两种模式时的最大全信息不完整策略对攻击隐蔽性的影响。3) 将最优化问题的可行域进行无损化简，以便在不失去最优解的前提下求解；提出一种启发式算法，在缩小的区域内找到近似最优解。4) 在IEEE测试系统上进行数值仿真，验证理论结论。

Result: 给出两类信息不完全性下的攻防权衡条件，以及在其他情形下的“最大不完全性”策略，提出可简化的可行域以降低求解复杂度并给出近似最优解的启发式方法；通过IEEE测试系统的仿真结果验证理论分析与算法有效性。

Conclusion: 信息不完全性可以作为一种有效的防御手段，用于削弱数据注入攻击的隐蔽性和破坏性之间的权衡。本文给出系统性的条件和算法，使在现实场景中实现对DIA的鲁棒性提升成为可能，同时指出将来可进一步完善模型的适用性与扩展性。

Abstract: The effectiveness of Data Injections Attacks (DIAs) critically depends on the
completeness of the system information accessible to adversaries. This
relationship positions information incompleteness enhancement as a vital
defense strategy for degrading DIA performance. In this paper, we focus on the
information-theoretic stealth attacks, where the attacker encounters a
fundamental tradeoff between the attack stealthiness and destructiveness.
Specifically, we systematically characterize how incomplete admittance
information impacts the dual objectives. In particular, we establish sufficient
conditions for two distinct operational regimes: (i) stealthiness intensifies
while destructive potential diminishes and (ii) destructiveness increases while
stealth capability weakens. For scenarios beyond these regimes, we propose a
maximal incompleteness strategy to optimally degrade stealth capability. To
solve the associated optimization problem, the feasible region is reduced
without excluding the optimal solution, and a heuristic algorithm is then
introduced to effectively identify the near-optimal solutions within the
reduced region. Numerical simulations are conducted on IEEE test systems to
validate the findings.

</details>


### [30] [Rate-cost tradeoffs in continuous-time control with a biomolecular application](https://arxiv.org/abs/2510.21612)
*Yorie Nakahira,Fangzhou Xiao,Victoria Kostina,John C. Doyle*

Main category: eess.SY

TL;DR: 针对广义Ornstein-Uhlenbeck过程的限速数据率控制，给出实现期望控制代价所需的数据率下界；当通过加性白噪声高斯信道执行控制时，该下界达到等号。模型近似离散状态分子出生–死亡过程，结果对通过化学反应实现生物分子控制具有直接意义。


<details>
  <summary>Details</summary>
Motivation: 在带控制输入约束与噪声干扰的随机过程的控制中，研究数据传输带宽（数据率）对实现低波动、低控制代价的影响，特别是在信息传输受限条件下的最小数据率需求。

Method: 推导带有控制作用的广义Ornstein-Uhlenbeck过程的下界，考虑控制可为乘法或加法且噪声方差可能依赖于控制。证明该下界在通过加性白高斯信道实现控制时达到等号。将系统离散化为分子出生–死亡过程的近似模型，并从信息论角度分析控制化学反应的可行性与代价。

Result: 给出实现目标控制代价所需的数据率下界；在控制通过加性白噪声高斯信道时，下界达到等号；将该结论应用于分子系统的近似模型，指出乘法控制对应降解速率、加法控制对应生产速率，目标在于降低分子浓度的波动。

Conclusion: 研究建立了带信息率约束的随机控制与生物分子系统控制之间的联系，指出在生物实现中通过选择不同的控制类型可实现对波动的抑制，并为利用通信理论工具分析生物系统提供了理论框架。

Abstract: This paper focuses on rate-limited control of the generalized
Ornstein-Uhlenbeck process where the control action can be either
multiplicative or additive, and the noise variance can depend on the control
action. We derive a lower bound on the data rate necessary to achieve the
desired control cost. The lower bound is attained with equality if the control
is performed via an additive white Gaussian channel. The system model
approximates the dynamics of a discrete-state molecular birth-death process,
and the result has direct implications on the control of a biomolecular system
via chemical reactions, where the multiplicative control corresponds to the
degradation rate, the additive control corresponds to the production rate, and
the control objective is to decrease the fluctuations of the controlled
molecular species around their desired concentration levels.

</details>


### [31] [The PhasorArray Toolbox for Harmonic Analysis and Control Design](https://arxiv.org/abs/2510.21294)
*Maxime Grosso,Pierre Riedinger,Jamal Daafouz*

Main category: eess.SY

TL;DR: A MATLAB toolbox for practical harmonic analysis/control with OO design, operator overloads, Toeplitz construction, and harmonic LMI solvers.


<details>
  <summary>Details</summary>
Motivation: 提升谐波分析与控制方法的实用性与易用性；将谐波分析与基于LMI的控制框架结合，便于工程实现。

Method: 面向对象架构；对周期矩阵的加法、乘法、卷积等算子重载；自动Toeplitz构造；求解谐波Sylvester、Lyapunov、Riccati方程；与YALMIP集成以支持LMIs。

Result: 实现对周期矩阵的直观操作，提供对谐波框架中LMI方法的求解能力，便于在实际控制与分析中应用。

Conclusion: 该工具箱为谐波分析与控制提供一个全面、易用的开发环境，促进基于LMIs的谐波控制方法的应用。

Abstract: We present a MATLAB package called the Pha-sorArray Toolbox that has been
developed to make harmonic analysis and control methods both practical and
user-friendly. The toolbox adopts an object-oriented architecture that enables
intuitive manipulation of periodic matrices through overloaded operators for
addition, multiplication, convolution, and automatic Toeplitz construction. Its
advanced features include harmonic Sylvester, Lyapunov and Riccati equations
solvers, and seamless integration with YALMIP, thereby facilitating advanced
control and analysis techniques based on Linear Matrix Inequalities (LMIs) in
the harmonic framework.

</details>


### [32] [Data-driven Koopman MPC using Mixed Stochastic-Deterministic Tubes](https://arxiv.org/abs/2510.21308)
*Zhengang Zhong,Ehecatl Antonio del Rio-Chanona,Panagiotis Petsagkourakis*

Main category: eess.SY

TL;DR: 提出一种基于数据驱动的随机模型预测控制（MPC）框架，用于离散时间非线性系统在加性扰动下的控制。通过Koopman算子将系统 lifting 到线性空间，获得有限维近似，并通过混合随机-确定性管（tube）来处理建模近似误差与扰动。随机管利用分布鲁棒优化（DRO），确定性管用超立方体包络（hypercube hull）表示。给出两类管的有限样本误差界，并通过数值仿真验证有效性。


<details>
  <summary>Details</summary>
Motivation: 在含扰动的离散时间非线性系统中实现鲁棒且可控的MPC，避免直接求解非线性优化问题的困难；利用Koopman线性化降低计算复杂度，同时通过DRO和管道结构对不确定性和模型误差进行鲁棒性处理。

Method: 将动力学通过Koopman算子提升到线性空间，得到有限维的线性近似；针对 lifted 模型及加性扰动，构建混合的随机-确定性管来界定不确定性影响；随机管通过分布鲁棒优化来考虑样本不确定性，确定性管通过超立方体上界表示；给出两类管的有限样本误差界；在原始系统上实施约束满足性控制并对控制策略进行MPC优化。

Result: 提出的方法具备对模型近似误差与扰动的鲁棒控制能力，并给出两类管的有限样本误差界，数值仿真验证了所提出框架的有效性。

Conclusion: 该数据驱动的鲁棒MPC框架通过Koopman线性化和DRO管道，提供对非线性系统的鲁棒控制并保证约束满足，同时给出理论误差界和实验性证明，具有潜在的实用性与扩展性。

Abstract: This paper presents a novel data-driven stochastic MPC design for
discrete-time nonlinear systems with additive disturbances by leveraging the
Koopman operator and a distributionally robust optimization (DRO) framework. By
lifting the dynamical system into a linear space, we achieve a
finite-dimensional approximation of the Koopman operator. We explicitly account
for the modeling approximation and additive disturbance error by a mixed
stochastic-deterministic tube for the lifted linear model. This ensures the
regulation of the original nonlinear system while complying with the
prespecified constraints. Stochastic and deterministic tubes are constructed
using a DRO and a hyper-cube hull, respectively. We provide finite sample error
bounds for both types of tubes. The effectiveness of the proposed approach is
demonstrated through numerical simulations.

</details>


### [33] [Predictive control barrier functions for piecewise affine systems with non-smooth constraints](https://arxiv.org/abs/2510.21321)
*Kanghui He,Anil Alan,Shengling Shi,Ton van den Boom,Bart De Schutter*

Main category: eess.SY

TL;DR: 提出面向分段仿射系统的预测性安全过滤器（PSF）与广义Clarke对偶导数的CBF设计，以在非光滑约束和控制非仿射性情形下确保安全并降低计算负担，通过对Clarke导数的所有分量强制CBF约束实现安全性，并给出显式PSF近似以提升实时性。


<details>
  <summary>Details</summary>
Motivation: 在复杂非线性系统和复杂约束条件下获得大安全集的控制屏障函数（CBF）具有挑战性。现有预测性CBF在非光滑系统中的梯度与灵敏度难以定义，且对控制非仿射系统计算成本高，亟需处理这类系统的可行、安全控制策略。

Method: 将集合值化的广义Clarke导数引入PSF设计，要求对导数的所有分量施加CBF约束以确保安全；针对通常为控制非仿射的分段仿射系统，处理非线性状态与多面体输入约束；提出PSF的显式近似以降低计算开销。

Result: 证明对广义Clarke导数的所有元素强制CBF约束足以保证安全；通过数值实验验证该方法在提高安全性与降低计算负担方面的有效性。

Conclusion: 将预测性CBF框架扩展到非光滑、分段仿射且带非线性状态约束的场景，提供了一种具有理论安全性保障的显式PSF近似，提升了实时实现的可行性。

Abstract: Obtaining control barrier functions (CBFs) with large safe sets for complex
nonlinear systems and constraints is a challenging task. Predictive CBFs
address this issue by using an online finite-horizon optimal control problem
that implicitly defines a large safe set. The optimal control problem, also
known as the predictive safety filter (PSF), involves predicting the system's
flow under a given backup control policy. However, for non-smooth systems and
constraints, some key elements, such as CBF gradients and the sensitivity of
the flow, are not well-defined, making the current methods inadequate for
ensuring safety. Additionally, for control-non-affine systems, the PSF is
generally nonlinear and non-convex, posing challenges for real-time
computation. This paper considers piecewise affine systems, which are usually
control-non-affine, under nonlinear state and polyhedral input constraints. We
solve the safety issue by incorporating set-valued generalized Clarke
derivatives in the PSF design. We show that enforcing CBF constraints across
all elements of the generalized Clarke derivatives suffices to guarantee
safety. Moreover, to lighten the computational overhead, we propose an explicit
approximation of the PSF. The resulting control methods are demonstrated
through numerical examples.

</details>


### [34] [Auction-Based Responsibility Allocation for Scalable Decentralized Safety Filters in Cooperative Multi-Agent Collision Avoidance](https://arxiv.org/abs/2510.21546)
*Johannes Autenrieb,Mark Spiller*

Main category: eess.SY

TL;DR: A scalable decentralized safety filter for multi-agent systems using high-order control barrier functions (HOCBFs) combined with an auction-based allocation of constraint enforcement to neighbors, yielding a directed responsibility graph that preserves safety while reducing per-agent computation and redundancy.


<details>
  <summary>Details</summary>
Motivation: As multi-agent networks grow, pairwise safety constraints explode and feasibility and real-time computation become challenging under purely decentralized HOCBF formulations. There is a need for scalable mechanisms to enforce safety without overburdening individual agents.

Method: Integrate HOCBF-based safety constraints with an auction-based allocation scheme that assigns constraint enforcement asymmetrically among neighboring agents based on local control effort estimates. Construct a directed responsibility graph that encodes which agent enforces which constraint, reducing redundancy and computation.

Result: The approach guarantees full safety coverage, reduces redundant constraints, and lowers per-agent computational load. Simulations across varying network sizes and interaction densities demonstrate safe and efficient coordination.

Conclusion: An auction-based, decentralized safety framework using HOCBFs can achieve scalable safety enforcement in multi-agent systems by distributing enforcement responsibilities through a directed graph, maintaining safety with improved computational efficiency.

Abstract: This paper proposes a scalable decentralized safety filter for multi-agent
systems based on high-order control barrier functions (HOCBFs) and
auction-based responsibility allocation. While decentralized HOCBF formulations
ensure pairwise safety under input bounds, they face feasibility and
scalability challenges as the number of agents grows. Each agent must evaluate
an increasing number of pairwise constraints, raising the risk of infeasibility
and making it difficult to meet real-time requirements. To address this, we
introduce an auction-based allocation scheme that distributes constraint
enforcement asymmetrically among neighbors based on local control effort
estimates. The resulting directed responsibility graph guarantees full safety
coverage while reducing redundant constraints and per-agent computational load.
Simulation results confirm safe and efficient coordination across a range of
network sizes and interaction densities.

</details>


### [35] [System-Theoretic Analysis of Dynamic Generalized Nash Equilibrium Problems -- Turnpikes and Dissipativity](https://arxiv.org/abs/2510.21556)
*Sophie Hall,Florian Dörfler,Timm Faulwasser*

Main category: eess.SY

TL;DR: 开放式广义纳什均衡（GNE）在多智能体控制中的系统理论性质被研究。严格耗散性会导致GNE解的turnpike现象，turnpike与耗散性的互为充分必要条件，同时给出稳态GNE作为最优工作点的条件，并利用博弈值函数对存储函数的几何形态给出局部刻画；通过设计线性端点惩罚项，能够使GNE的开环轨迹收敛并保持在稳态GNE。此工作为将GNE的分析与最优控制等系统理论方法结合奠定基础。


<details>
  <summary>Details</summary>
Motivation: 动机在于从系统理论角度揭示多智能体系统中耦合成本、动态与约束下的GNE轨迹性质，建立与耗散性、turnpike及存储函数相关的理论框架，并为未来将GNE分析纳入成熟的控制理论提供基础。

Method: 以耗散性理论、turnpike理论及存储函数思想为工具，系统地推导严格耗散性→turnpike、turnpike→严格耗散性的互逆关系；给出稳态GNE作为最优点的充要条件；利用博弈值函数对存储函数的局部几何进行表征；设计线性端点惩罚以实现收敛与保持在稳态GNE。

Result: 得到：1) 严格耗散性导致GNE开环轨迹的turnpike现象；2) turnpike与严格耗散性之间的等价关系；3) 在某些条件下，稳态GNE即为最优工作点；4) 通过博弈值函数可对存储函数的几何在局部作出表征；5) 设计线性端点惩罚项可使GNE轨迹收敛并停留在稳态GNE。

Conclusion: 这些结论将GNE的分析框架与成熟的系统理论（如最优控制中的turnpike、耗散性和存储函数）连接起来，为未来在GNEs中进行系统理论分析奠定基础。

Abstract: Generalized Nash equilibria are used in multi-agent control applications to
model strategic interactions between agents that are coupled in the cost,
dynamics, and constraints. We study the properties of open-loop GNE
trajectories from a system-theoretic perspective. We show how strict
dissipativity generates the turnpike phenomenon in GNE solutions. Moreover, we
establish a converse turnpike result, i.e., the implication from turnpike to
strict dissipativity. We derive conditions under which the steady-state GNE is
the optimal operating point and, using a game value function, we give a local
characterization of the geometry of storage functions. Finally, we design
linear terminal penalties that ensure GNE open-loop trajectories converge to
and remain at the steady-state GNE. These connections provide the foundation
for future system-theoretic analysis of GNEs similar to those existing in
optimal control.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [36] [A Confidence-Constrained Cloud-Edge Collaborative Framework for Autism Spectrum Disorder Diagnosis](https://arxiv.org/abs/2510.21130)
*Qi Deng,Yinghao Zhang,Yalin Liu,Bishenghui Tao*

Main category: cs.NI

TL;DR: 提出了一种层级的云-边知识蒸馏框架C3EKD，在边缘完成大部分推断，只有低置信样本上传云端；云端输出经过温度缩放的软标签并通过跨学校的全局损失蒸馏回边缘模型，提升泛化性，同时保护原始数据隐私。在两组 ASD 面部图像数据集上实现87.4%的准确率。


<details>
  <summary>Details</summary>
Motivation: 纯云端处理带来隐私与延迟问题，纯边缘推理在准确率上受限；需要一种在不集中原始数据的前提下提升跨机构泛化能力的机制。

Method: 提出C3EKD，边缘端执行大部分推断，只有低置信样本上报云端；云端使用温度缩放的软标签进行蒸馏，并通过参与学校的全局损失进行跨站点的知识蒸馏回边缘模型；在多校场景下联合训练以提升泛化。

Result: 在两个公开的 ASD 面部图像数据集上，框架达到87.4%的准确率，显著优于单独边缘或云端方案，展示了在实际应用中可扩展的潜力。

Conclusion: C3EKD实现了隐私、时延与准确率之间的折中，适用于学校环境的 ASD 诊断系统，并可扩展到多机构协作场景。

Abstract: Autism Spectrum Disorder (ASD) diagnosis systems in school environments
increasingly relies on IoT-enabled cameras, yet pure cloud processing raises
privacy and latency concerns while pure edge inference suffers from limited
accuracy. We propose Confidence-Constrained Cloud-Edge Knowledge Distillation
(C3EKD), a hierarchical framework that performs most inference at the edge and
selectively uploads only low-confidence samples to the cloud. The cloud
produces temperature-scaled soft labels and distils them back to edge models
via a global loss aggregated across participating schools, improving
generalization without centralizing raw data. On two public ASD facial-image
datasets, the proposed framework achieves a superior accuracy of 87.4\%,
demonstrating its potential for scalable deployment in real-world applications.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [37] [Incentivizing Consistent, Effective and Scalable Reasoning Capability in Audio LLMs via Reasoning Process Rewards](https://arxiv.org/abs/2510.20867)
*Jiajun Fan,Roger Ren,Jingyuan Li,Rahul Pandey,Prashanth Gurunath Shivakumar,Ivan Bulyko,Ankur Gandhe,Ge Liu,Yile Gu*

Main category: cs.LG

TL;DR: 提出 CESAR 框架，通过在线强化学习重新奖励推理过程本身，而非仅对结果进行验证，解决音频大语言模型中的测试时反向扩展现象（test-time inverse scaling），使推理在测试时长增长时表现提升或保持稳步提升，同时揭示模型的“推理甜点”区域。


<details>
  <summary>Details</summary>
Motivation: 在音频大语言模型中，延长推理链通常导致性能下降，这并非推理本身的固有局限，而是缺乏对推理过程的有效引导，容易产生幻觉与推理错漏累积。通过将奖励聚焦于推理过程的质量而非单一输出结果，可以提升推理的可控性、一致性与可扩展性。

Method: 提出 CESAR（Consistent, Effective, and Scalable Audio Reasoners）。采用在线强化学习，基于 Group Relative Policy Optimization（GRPO）框架，设计多维奖励函数，鼓励正确性与格式之外，还强调推理的一致性、结构化分析模式、因果推理、领域知识融合以及推理深度的标定。训练目标从结果验收转向对推理过程的评价与优化。该框架揭示了推理的“甜点点”——在测试时尺度扩展下性能达到峰值的区间。

Result: 在 MMAU Test-mini 上达到州内最佳（state-of-the-art）成绩，显著超越 Gemini 2.5 Pro 与 GPT-4o Audio；在 MMSU 推理任务上接近人类水平；通过 AI 评审和定性比较提供量化与定性验证，显示提升后的推理质量带来多模态推理与感知能力的协同提升。

Conclusion: CESAR 为音频大语言模型的鲁棒且可扩展推理提供了一个原理性方法，成功解决测试时逆向扩展问题，将推理从负面影响转化为增益，并揭示模型特定的推理甜点区间，提升了多模态推理与感知的整体性能。

Abstract: The role of reasoning in Audio Large Language Models remains widely
underexplored, as introducing a reasoning process often degrades rather than
improves performance during inference, a phenomenon we term test-time inverse
scaling, where longer reasoning chains yield progressively worse results. We
demonstrate that this stems not from fundamental limitations of reasoning
itself, but from inadequate training: models without proper guidance for the
reasoning process produce hallucinatory, inconsistent reasoning that
accumulates errors over longer chains. To address these challenges, we
introduce CESAR (Consistent, Effective, and Scalable Audio Reasoners), shifting
from outcome verification to rewarding the reasoning process. Our online
reinforcement learning framework employs Group Relative Policy Optimization
with a multi-faceted reward suite that incentivizes not only correctness and
format but also consistency, structured analytical patterns, causal reasoning,
domain-knowledge integration, and calibrated reasoning depth. CESAR resolves
test-time inverse scaling, transforming reasoning from detriments into gains
while revealing model-specific ``reasoning sweet spots", where performance
peaks during test-time scaling. We achieve state-of-the-art results on MMAU
Test-mini, substantially outperforming Gemini 2.5 Pro and GPT-4o Audio, and
near-human-level performance on MMSU reasoning tasks. Through AI-as-judge
evaluations and qualitative comparisons, we provide both quantitative and
qualitative validation of our improved reasoning quality. Importantly, enhanced
reasoning creates synergistic effects, simultaneously improving multimodal
reasoning and perception capabilities. Overall, CESAR establishes a principled
method for developing robust and scalable reasoning in Audio LLMs.

</details>


### [38] [MOBO-OSD: Batch Multi-Objective Bayesian Optimization via Orthogonal Search Directions](https://arxiv.org/abs/2510.20872)
*Lam Ngo,Huong Ha,Jeffrey Chan,Hongyu Zhang*

Main category: cs.LG

TL;DR: 提出了一种多目标贝叶斯优化算法 MOBO-OSD，通过与目标函数最小值的凸壳正交搜索方向来覆盖 Pareto 前沿，并通过 Pareto Front Estimation 增强密度，支持批量评估，在两到六个目标的多种基准上优于现有方法，代码可复现。


<details>
  <summary>Details</summary>
Motivation: 多目标优化面临目标之间的权衡与解集多样性问题，现有方法在覆盖性与密度方面还有提升空间。

Method: 定义与逼近目标最小值的凸壳，沿正交搜索方向生成子问题；采用 Pareto Front Estimation 在现有解附近扩展密度；支持批量优化；在多达六个目标的综合基准上评估。

Result: 在合成和真实基准上，MOBO-OSD 在多目标设定下的覆盖性和超体积（hypervolume）表现优于现有方法。

Conclusion: MOBO-OSD 通过系统地覆盖目标空间和密度提升策略，能够稳定提高多目标贝叶斯优化的性能；代码公开。

Abstract: Bayesian Optimization (BO) is a powerful tool for optimizing expensive
black-box objective functions. While extensive research has been conducted on
the single-objective optimization problem, the multi-objective optimization
problem remains challenging. In this paper, we propose MOBO-OSD, a
multi-objective Bayesian Optimization algorithm designed to generate a diverse
set of Pareto optimal solutions by solving multiple constrained optimization
problems, referred to as MOBO-OSD subproblems, along orthogonal search
directions (OSDs) defined with respect to an approximated convex hull of
individual objective minima. By employing a well-distributed set of OSDs,
MOBO-OSD ensures broad coverage of the objective space, enhancing both solution
diversity and hypervolume performance. To further improve the density of the
set of Pareto optimal candidate solutions without requiring an excessive number
of subproblems, we leverage a Pareto Front Estimation technique to generate
additional solutions in the neighborhood of existing solutions. Additionally,
MOBO-OSD supports batch optimization, enabling parallel function evaluations to
accelerate the optimization process when resources are available. Through
extensive experiments and analysis on a variety of synthetic and real-world
benchmark functions with two to six objectives, we demonstrate that MOBO-OSD
consistently outperforms the state-of-the-art algorithms. Our code
implementation can be found at https://github.com/LamNgo1/mobo-osd.

</details>


### [39] [Multimodal Negative Learning](https://arxiv.org/abs/2510.20877)
*Baoquan Gong,Xiyuan Gao,Pengfei Zhu,Qinghua Hu,Bing Cao*

Main category: cs.LG

TL;DR: 提出多模态负学习(MNL)框架，通过主模态动态引导弱模态抑制非目标类别以提升鲁棒性并保留模态特定信息，克服弱模态被强模态过度对齐的问题。


<details>
  <summary>Details</summary>
Motivation: 解决模态不平衡导致的弱模态信息被压制的问题，避免对弱模态的目标类别预测进行过度对齐。

Method: 引入动态引导的负学习机制，主模态对弱模态进行负目标抑制的引导，提出MNL框架，并理论地推导鲁棒性下界的收紧以及提高Unimodal Confidence Margin (UCoM)。

Result: 给出理论分析：提高Unimodal Confidence Margin，降低弱模态经验误差，在噪声和不平衡场景下鲁棒性提升；通过多项基准实验验证方法的有效性和泛化性。

Conclusion: MNL为多模态学习提供新的负学习范式，有效提升鲁棒性与信息保留能力，并在公开代码基础上促成后续研究。

Abstract: Multimodal learning systems often encounter challenges related to modality
imbalance, where a dominant modality may overshadow others, thereby hindering
the learning of weak modalities. Conventional approaches often force weak
modalities to align with dominant ones in "Learning to be (the same)" (Positive
Learning), which risks suppressing the unique information inherent in the weak
modalities. To address this challenge, we offer a new learning paradigm:
"Learning Not to be" (Negative Learning). Instead of enhancing weak modalities'
target-class predictions, the dominant modalities dynamically guide the weak
modality to suppress non-target classes. This stabilizes the decision space and
preserves modality-specific information, allowing weak modalities to preserve
unique information without being over-aligned. We proceed to reveal multimodal
learning from a robustness perspective and theoretically derive the Multimodal
Negative Learning (MNL) framework, which introduces a dynamic guidance
mechanism tailored for negative learning. Our method provably tightens the
robustness lower bound of multimodal learning by increasing the Unimodal
Confidence Margin (UCoM) and reduces the empirical error of weak modalities,
particularly under noisy and imbalanced scenarios. Extensive experiments across
multiple benchmarks demonstrate the effectiveness and generalizability of our
approach against competing methods. The code will be available at
https://github.com/BaoquanGong/Multimodal-Negative-Learning.git.

</details>


### [40] [HA-RAG: Hotness-Aware RAG Acceleration via Mixed Precision and Data Placement](https://arxiv.org/abs/2510.20878)
*Danying Ge,Jianhua Gao,Yixue Yang,Weixing Ji*

Main category: cs.LG

TL;DR: HA-RAG: hotness-aware inference optimization for RAG; speeds TTFT by prioritizing hot KV chunks with mixed-precision compression/loading and hot data placement; avg 2.10x, max 10.49x speedup vs TurboRAG, with negligible accuracy loss.


<details>
  <summary>Details</summary>
Motivation: RAG helps accuracy but external KB introduces long-context processing, high memory and latency; existing methods precompute KV; need to exploit access-frequency distribution to optimize I/O and memory.

Method: Introduce hotness-aware mixed-precision compressing/loading; design hotness-aware data placement to keep frequently accessed KV chunks in high-speed memory; relies on numeric distribution of KV chunks.

Result: TTFT improvements: avg 2.10x, max 10.49x; negligible accuracy loss compared to TurboRAG.

Conclusion: HA-RAG offers efficient inference acceleration for RAG under varying KV hotness; demonstrates practical benefits; potential overheads and applicability to different KBs to be explored.

Abstract: Retrieval-Augmented Generation (RAG) improves model output accuracy by
leveraging external knowledge bases, serving as an effective solution to
address hallucination issues and knowledge-update delays in Large Language
Models (LLMs). However, the introduction of external knowledge bases presents
RAG with challenges in long-context processing, significantly increasing memory
consumption and inference latency. Existing research accelerates inference by
precomputing Key and Value (KV) of the knowledge base and loading them
on-demand during inference. Based on the access frequency of different KV
chunks within the external knowledge base, this paper proposes a hotness-aware
RAG (HA-RAG) inference optimization system. First, leveraging the numerical
distribution of KV chunks, we introduce a hotness-aware mixed-precision
compressing and loading method to reduce disk I/O and memory access overhead.
Second, we design a hotness-aware data placement strategy that prioritizes
storing frequently accessed KV chunks in high-speed memory to improve data
access efficiency. Experimental results demonstrate that, compared with
TurboRAG, the proposed HA-RAG achieves an average speedup of 2.10x and maximum
speedup of 10.49x in Time-To-First-Token (TTFT) with negligible accuracy loss.

</details>


### [41] [Cost Minimization for Space-Air-Ground Integrated Multi-Access Edge Computing Systems](https://arxiv.org/abs/2510.21541)
*Weihong Qin,Aimin Wang,Geng Sun,Zemin Sun,Jiacheng Wang,Dusit Niyato,Dong In Kim,Zhu Han*

Main category: cs.LG

TL;DR: 提出分层 SAGIN-MEC 框架并结合 MADDPG-COCG 的优化算法，显著提升低空经济场景下用户设备的成本、延迟和能耗性能，同时保持良好收敛性与可扩展性。


<details>
  <summary>Details</summary>
Motivation: SAGIN-MEC 在面向低空经济的广域计算服务中具有潜在价值，但在异构节点协同、复杂因素建模以及部分可观测环境下的实时决策方面存在重大挑战。

Method: 提出分层 SAGIN-MEC 架构实现 UD、UAV 与卫星之间的协同；构建 UD 成本最小化优化问题 (UCMOP)，通过联合优化任务卸载比例、无人机轨迹、计算资源分配和 UD 关联来最小化成本，证明该问题 NP-hard；提出 MADDPG-COCG 算法：使用 MADDPG 处理异构节点的连续时序决策，并通过凸优化与 coalitional game 进一步处理混合型和可变维度的决策，以提升性能与鲁棒性。

Result: 仿真结果显示 MADDPG-COCG 在聚合 UD 成本、任务完成延迟和 UD 能耗方面优于基准算法，且 UAV 能耗略有增加；算法具备更好的收敛性和可扩展性。

Conclusion: 给出一种高效且可扩展的分层 SAGIN-MEC 协同优化框架，特别适用于 LAE 场景下的低空计算服务。

Abstract: Space-air-ground integrated multi-access edge computing (SAGIN-MEC) provides
a promising solution for the rapidly developing low-altitude economy (LAE) to
deliver flexible and wide-area computing services. However, fully realizing the
potential of SAGIN-MEC in the LAE presents significant challenges, including
coordinating decisions across heterogeneous nodes with different roles,
modeling complex factors such as mobility and network variability, and handling
real-time decision-making under partially observable environment with hybrid
variables. To address these challenges, we first present a hierarchical
SAGIN-MEC architecture that enables the coordination between user devices
(UDs), uncrewed aerial vehicles (UAVs), and satellites. Then, we formulate a UD
cost minimization optimization problem (UCMOP) to minimize the UD cost by
jointly optimizing the task offloading ratio, UAV trajectory planning,
computing resource allocation, and UD association. We show that the UCMOP is an
NP-hard problem. To overcome this challenge, we propose a multi-agent deep
deterministic policy gradient (MADDPG)-convex optimization and coalitional game
(MADDPG-COCG) algorithm. Specifically, we employ the MADDPG algorithm to
optimize the continuous temporal decisions for heterogeneous nodes in the
partially observable SAGIN-MEC system. Moreover, we propose a convex
optimization and coalitional game (COCG) method to enhance the conventional
MADDPG by deterministically handling the hybrid and varying-dimensional
decisions. Simulation results demonstrate that the proposed MADDPG-COCG
algorithm significantly enhances the user-centric performances in terms of the
aggregated UD cost, task completion delay, and UD energy consumption, with a
slight increase in UAV energy consumption, compared to the benchmark
algorithms. Moreover, the MADDPG-COCG algorithm shows superior convergence
stability and scalability.

</details>


### [42] [Global Dynamics of Heavy-Tailed SGDs in Nonconvex Loss Landscape: Characterization and Control](https://arxiv.org/abs/2510.20905)
*Xingyu Wang,Chang-Han Rhee*

Main category: cs.LG

TL;DR: 重尾噪声的 SGD（并结合梯度裁剪）能显著回避尖锐极小值并提升测试泛化，理论基于大偏差与 metastability 的分析并有实验验证。


<details>
  <summary>Details</summary>
Motivation: 解释为何 SGD 能在全局维度上表现出对尖锐极小值的偏好，揭示重尾噪声在训练过程中的作用，以及如何通过噪声设计提升泛化。

Method: 基于 Wang and Rhee 2023 的大偏差与 metastability 的分析，建立处理重尾噪声的理论框架；在训练中引入并裁剪重尾噪声，结合渐近分析，推导全局动力学特征；通过仿真和深度学习实验验证理论预测。

Result: 给出重尾 SGD 的全局动力学的锐利表征；证明在训练阶段注入并截断重尾噪声可以使 SGD 避免尖锐极小值、找到更平坦的局部极小值并提升泛化；实验结果与理论一致。

Conclusion: 噪声设计（引入并后续裁剪重尾噪声）是提升深度学习泛化的有效策略；重尾 SGD 配合梯度裁剪能实现更平滑的损失景观和更优的测试性能。

Abstract: Stochastic gradient descent (SGD) and its variants enable modern artificial
intelligence. However, theoretical understanding lags far behind their
empirical success. It is widely believed that SGD has a curious ability to
avoid sharp local minima in the loss landscape, which are associated with poor
generalization. To unravel this mystery and further enhance such capability of
SGDs, it is imperative to go beyond the traditional local convergence analysis
and obtain a comprehensive understanding of SGDs' global dynamics. In this
paper, we develop a set of technical machinery based on the recent large
deviations and metastability analysis in Wang and Rhee (2023) and obtain sharp
characterization of the global dynamics of heavy-tailed SGDs. In particular, we
reveal a fascinating phenomenon in deep learning: by injecting and then
truncating heavy-tailed noises during the training phase, SGD can almost
completely avoid sharp minima and achieve better generalization performance for
the test data. Simulation and deep learning experiments confirm our theoretical
prediction that heavy-tailed SGD with gradient clipping finds local minima with
a more flat geometry and achieves better generalization performance.

</details>


### [43] [AL-CoLe: Augmented Lagrangian for Constrained Learning](https://arxiv.org/abs/2510.20995)
*Ignacio Boero,Ignacio Hounie,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: Augmented Lagrangian methods offer a minimally invasive, theoretically grounded approach to constrained, non-convex machine learning, achieving strong duality under mild conditions, convergence to feasible and optimal primal solutions, and PAC-style generalization guarantees, with promising empirical results on fairness-constrained classification.


<details>
  <summary>Details</summary>
Motivation: Many modern ML models are parameterized non-convexly and are trained under constraints (e.g., fairness, resource limits). Constrained optimization in this setting suffers from duality gaps and limited theoretical guarantees, and Augmented Lagrangian (AL) methods have been underexplored as a remedy.

Method: Reexamine Augmented Lagrangian methods for constrained learning, establish strong duality under mild conditions, prove convergence of dual ascent algorithms to feasible and optimal primal solutions, derive PAC-style generalization guarantees, and validate on fairness-constrained classification tasks.

Result: The paper provides theoretical results showing strong duality and convergence of dual ascent in non-convex constrained ML, along with generalization guarantees, and demonstrates effectiveness on fairness-constrained classification tasks.

Conclusion: Augmented Lagrangian methods are a viable, minimally invasive framework for constrained non-convex machine learning, offering solid theoretical guarantees and practical benefits, and warrant broader adoption for constrained learning problems.

Abstract: Despite the non-convexity of most modern machine learning parameterizations,
Lagrangian duality has become a popular tool for addressing constrained
learning problems. We revisit Augmented Lagrangian methods, which aim to
mitigate the duality gap in non-convex settings while requiring only minimal
modifications, and have remained comparably unexplored in constrained learning
settings. We establish strong duality results under mild conditions, prove
convergence of dual ascent algorithms to feasible and optimal primal solutions,
and provide PAC-style generalization guarantees. Finally, we demonstrate its
effectiveness on fairness constrained classification tasks.

</details>


### [44] [Learning from Interval Targets](https://arxiv.org/abs/2510.20925)
*Rattana Pukdee,Ziqi Ke,Chirag Gupta*

Main category: cs.LG

TL;DR: The paper tackles regression with interval targets, deriving non-asymptotic generalization bounds under hypothesis-smoothness, and introduces a robust min–max learning framework over intervals. It reports practical effectiveness with state-of-the-art results on real data.


<details>
  <summary>Details</summary>
Motivation: In many real-world scenarios, exact target values are unavailable or costly to obtain; intervals capture this uncertainty, necessitating learning methods that operate on bounds rather than exact labels.

Method: Two-pronged approach: (i) develop loss functions compatible with interval targets and establish non-asymptotic generalization bounds that rely on smoothness of the hypothesis class rather than realizability; (ii) introduce a min–max learning formulation that minimizes the worst-case (maximized) target within the given intervals, with the non-convex maximization mitigated by incorporating smoothness constraints.

Result: Theoretical results include non-asymptotic generalization bounds under interval targets. Empirically, the proposed methods achieve state-of-the-art performance on real-world datasets.

Conclusion: Learning with interval targets is feasible with provable guarantees and robust optimization. The combination of interval-compatible losses and a smoothness-constrained min–max formulation yields strong empirical performance.

Abstract: We study the problem of regression with interval targets, where only upper
and lower bounds on target values are available in the form of intervals. This
problem arises when the exact target label is expensive or impossible to
obtain, due to inherent uncertainties. In the absence of exact targets,
traditional regression loss functions cannot be used. First, we study the
methodology of using a loss functions compatible with interval targets, for
which we establish non-asymptotic generalization bounds based on smoothness of
the hypothesis class that significantly relaxing prior assumptions of
realizability and small ambiguity degree. Second, we propose a novel min-max
learning formulation: minimize against the worst-case (maximized) target labels
within the provided intervals. The maximization problem in the latter is
non-convex, but we show that good performance can be achieved with the
incorporation of smoothness constraints. Finally, we perform extensive
experiments on real-world datasets and show that our methods achieve
state-of-the-art performance.

</details>


### [45] [Meta-Learning for Cross-Task Generalization in Protein Mutation Property Prediction](https://arxiv.org/abs/2510.20943)
*Srivathsan Badrinarayanan,Yue Su,Janghoon Ock,Alan Pham,Sanya Ahuja,Amir Barati Farimani*

Main category: cs.LG

TL;DR: 通过元学习（MAML）和新的突变编码策略提升蛋白质突变性质预测的跨数据集泛化性；在三组数据集上实现快速适应和更高准确性，显著优于传统微调。


<details>
  <summary>Details</summary>
Motivation: 当前蛋白质突变性质预测受限于跨数据集的异质实验条件和数据稀缺，现有方法对数据集特定模式过拟合，难以实现跨任务的快速泛化。需要一种能够在有限标注数据下快速适应新任务的学习范式。

Method: 将模型无关元学习（MAML）应用于蛋白质突变性质预测，并提出使用分隔符标记的突变编码，将突变直接融入序列上下文。同时将变换器（Transformer）架构与MAML结合，使模型通过极少量梯度步即可在新任务上快速适应。

Result: 在三个多样化的蛋白质突变数据集（功能性适应性、热稳定性、溶解性）上，所提出方法相较传统微调显示显著优势；跨任务评估中，功能性适应性准确率提高29%，训练时间减少65%；溶解性准确率提高94%，训练时间减少55%；且训练效率对数据集大小保持稳定。

Conclusion: 确立了元学习在蛋白质突变分析中的系统性应用，并引入有效的突变编码策略，为蛋白质工程中的跨领域泛化提供变革性方法，特别适用于数据有限的工业应用与早期蛋白设计。

Abstract: Protein mutations can have profound effects on biological function, making
accurate prediction of property changes critical for drug discovery, protein
engineering, and precision medicine. Current approaches rely on fine-tuning
protein-specific transformers for individual datasets, but struggle with
cross-dataset generalization due to heterogeneous experimental conditions and
limited target domain data. We introduce two key innovations: (1) the first
application of Model-Agnostic Meta-Learning (MAML) to protein mutation property
prediction, and (2) a novel mutation encoding strategy using separator tokens
to directly incorporate mutations into sequence context. We build upon
transformer architectures integrating them with MAML to enable rapid adaptation
to new tasks through minimal gradient steps rather than learning
dataset-specific patterns. Our mutation encoding addresses the critical
limitation where standard transformers treat mutation positions as unknown
tokens, significantly degrading performance. Evaluation across three diverse
protein mutation datasets (functional fitness, thermal stability, and
solubility) demonstrates significant advantages over traditional fine-tuning.
In cross-task evaluation, our meta-learning approach achieves 29% better
accuracy for functional fitness with 65% less training time, and 94% better
accuracy for solubility with 55% faster training. The framework maintains
consistent training efficiency regardless of dataset size, making it
particularly valuable for industrial applications and early-stage protein
design where experimental data is limited. This work establishes a systematic
application of meta-learning to protein mutation analysis and introduces an
effective mutation encoding strategy, offering transformative methodology for
cross-domain generalization in protein engineering.

</details>


### [46] [Safety Assessment in Reinforcement Learning via Model Predictive Control](https://arxiv.org/abs/2510.20955)
*Jeff Pflueger,Michael Everett*

Main category: cs.LG

TL;DR: 提出了一种基于可逆性与模型预测路径积分控制的无模型强化学习安全框架，在训练过程中对行动进行安全性检查，能够阻止不安全行为，同时在训练进展上接近可安全但有限制的基线。


<details>
  <summary>Details</summary>
Motivation: 无模型强化学习通常缺乏形式化的安全保证，现有的安全保护通常需要对安全规范有较详细的约束知识。本工作认为很多难以直接指定的安全问题可以通过不变量的视角来刻画，因此通过可逆性在训练过程中持续防止潜在安全问题。

Method: 在训练过程中对学习策略提出的动作使用模型预测路径积分控制(MPPI)进行安全性检查；只需对黑箱动力学进行查询，不需要对动力学模型或安全约束有显式知识。

Result: 实验结果表明，该算法在多数情况下能在动作变得不安全之前就中止执行，同时保持与允许违反安全的PPO基线相当的训练进展。

Conclusion: 该方法不依赖显式的安全约束知识即可在训练中提供安全保障，且与标准无模型RL相比不会显著牺牲学习进展。

Abstract: Model-free reinforcement learning approaches are promising for control but
typically lack formal safety guarantees. Existing methods to shield or
otherwise provide these guarantees often rely on detailed knowledge of the
safety specifications. Instead, this work's insight is that many
difficult-to-specify safety issues are best characterized by invariance.
Accordingly, we propose to leverage reversibility as a method for preventing
these safety issues throughout the training process. Our method uses
model-predictive path integral control to check the safety of an action
proposed by a learned policy throughout training. A key advantage of this
approach is that it only requires the ability to query the black-box dynamics,
not explicit knowledge of the dynamics or safety constraints. Experimental
results demonstrate that the proposed algorithm successfully aborts before all
unsafe actions, while still achieving comparable training progress to a
baseline PPO approach that is allowed to violate safety.

</details>


### [47] [An Ensembled Penalized Federated Learning Framework for Falling People Detection](https://arxiv.org/abs/2510.20960)
*Sizhe Rao,Runqiu Zhang,Sajal Saha,Liang Chen*

Main category: cs.LG

TL;DR: 提出了一个基于联邦学习的EPFL框架，结合持续学习、个性化和专门加权聚合的策略，用于隐私保护的穿戴式传感器秋季跌倒检测，在基准数据集上实现接近90%的召回率和F1-score，显著优于集中式和基线模型。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统跌倒检测在泛化性、数据隐私和个体行为变异方面的挑战。现有的集中式或逐点联邦模型在隐私保护、跨用户适应性和长期记忆方面存在局限，需要一个能在保护隐私的前提下提升个性化与持续学习能力的解决方案。

Method: 提出EPFL（Ensembled Penalized Federated Learning）框架，结合持续学习、个性化建模与专门加权聚合（SWA）策略。在穿戴式传感器数据的基础上，通过同态加密和联邦训练实现隐私保护。与现有的联邦模型不同，EPFL 引入惩罚性本地训练和基于模型集合的推理，以提升跨客户端的一致性和对行为差异的适应性。

Result: 在基准跌倒检测数据集上的实验表明，该方法达到 Recall 88.31% 与 F1-score 89.94%，显著优于集中式和基线模型。强调其可扩展性、安全性与在真实医疗场景中的适用潜力。

Conclusion: 该工作提供了一种可扩展、稳健且隐私友好的跌倒检测解决方案，具备通过自适应反馈机制实现持续改进的潜力，适合在医疗保健环境中部署。

Abstract: Falls among elderly and disabled individuals remain a leading cause of injury
and mortality worldwide, necessitating robust, accurate, and privacy-aware fall
detection systems. Traditional fall detection approaches, whether centralized
or point-wise, often struggle with key challenges such as limited
generalizability, data privacy concerns, and variability in individual movement
behaviors. To address these limitations, we propose EPFL-an Ensembled Penalized
Federated Learning framework that integrates continual learning, personalized
modeling, and a novel Specialized Weighted Aggregation (SWA) strategy. EPFL
leverages wearable sensor data to capture sequential motion patterns while
preserving user privacy through homomorphic encryption and federated training.
Unlike existing federated models, EPFL incorporates both penalized local
training and ensemble-based inference to improve inter-client consistency and
adaptability to behavioral differences. Extensive experiments on a benchmark
fall detection dataset demonstrate the effectiveness of our approach, achieving
a Recall of 88.31 percent and an F1-score of 89.94 percent, significantly
outperforming both centralized and baseline models. This work presents a
scalable, secure, and accurate solution for real-world fall detection in
healthcare settings, with strong potential for continuous improvement via its
adaptive feedback mechanism.

</details>


### [48] [On the accuracy of implicit neural representations for cardiovascular anatomies and hemodynamic fields](https://arxiv.org/abs/2510.20970)
*Jubilee Lee,Daniele E. Schiavazzi*

Main category: cs.LG

TL;DR: 本研究评估了隐式神经表征(INR)在压缩体液动力场和心血管解剖表示中的表现，重点在于谱偏差缓解策略；结果显示在胸主动脉的空间-时间场上，INR实现高压缩比，误差保持在临床可接受范围，且SIREN、MFN-Gabor、MHE架构表现最佳，代码与数据公开。


<details>
  <summary>Details</summary>
Motivation: 理解INR在领域特定医学应用中的准确性和实用性，以及如何缓解谱偏差以提升压缩与表示效果；面向数值仿真生成的血流和解剖表征的高效存储与传输。

Method: 比较多种激活函数、固定/可训练位置编码、以及线性组合非线性核；在现实的胸主动脉时空场上进行评估；考察SIREN、MFN-Gabor、MHE等架构对压力和速度场的近似；在48例解剖学上评估几何误差，统计分析。

Result: 压缩比高达约230，压力误差最大绝对值约1 mmHg，速度误差约5-10 cm/s；在48例解剖学中，平均解剖几何误差<0.5 mm，最大<1.6 mm；SIREN、MFN-Gabor、MHE表现最佳；提供代码和数据。

Conclusion: INR在心血管领域中具备高效压缩与高保真表示的潜力，谱偏差缓解是关键因素；选用合适的架构可实现高效的存储与传输，并推动生物医学仿真的应用。

Abstract: Implicit neural representations (INRs, also known as neural fields) have
recently emerged as a powerful framework for knowledge representation,
synthesis, and compression. By encoding fields as continuous functions within
the weights and biases of deep neural networks-rather than relying on voxel- or
mesh-based structured or unstructured representations-INRs offer both
resolution independence and high memory efficiency. However, their accuracy in
domain-specific applications remains insufficiently understood. In this work,
we assess the performance of state-of-the-art INRs for compressing hemodynamic
fields derived from numerical simulations and for representing cardiovascular
anatomies via signed distance functions. We investigate several strategies to
mitigate spectral bias, including specialized activation functions, both fixed
and trainable positional encoding, and linear combinations of nonlinear
kernels. On realistic, space- and time-varying hemodynamic fields in the
thoracic aorta, INRs achieved remarkable compression ratios of up to
approximately 230, with maximum absolute errors of 1 mmHg for pressure and 5-10
cm/s for velocity, without extensive hyperparameter tuning. Across 48 thoracic
aortic anatomies, the average and maximum absolute anatomical discrepancies
were below 0.5 mm and 1.6 mm, respectively. Overall, the SIREN, MFN-Gabor, and
MHE architectures demonstrated the best performance. Source code and data is
available at https://github.com/desResLab/nrf.

</details>


### [49] [L^2M^3OF: A Large Language Multimodal Model for Metal-Organic Frameworks](https://arxiv.org/abs/2510.20976)
*Jiyu Cui,Fang Wu,Haokai Zhao,Minggao Feng,Xenophon Evangelopoulos,Andrew I. Cooper,Yejin Choi*

Main category: cs.LG

TL;DR: 提出了L2M3OF，一种用于 MOFs 的多模态大语言模型，将晶体表示学习与语言理解结合，实现对结构、文本与知识的联合处理；在结构-性质-知识数据库和与主流闭源LLMs的对比评估中，参数量更少却在性状预测与知识生成任务上表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在科学发现中的表现受限于需跨越语言表达与复杂物理现象的多模态表征，MOF等材料设计尤其需要对三维晶体结构、拓扑和配位规则等的综合理解。构建一个能够同时处理结构、文本和知识的多模态模型，有望提升材料发现的效率与可解释性。

Method: 提出一个以预训练晶体编码器为核心，辅以轻量投影层，将结构信息压缩并映射到token空间，与语言指令对齐；设计并构建结构-性质-知识数据库用于训练与评估；在对比实验中将模型与GPT-5、Gemini-2.5-Pro、DeepSeek-R1等闭源LLMs进行对比，评估属性预测与知识生成能力。

Result: 实验表明，L2M3OF在属性预测和知识生成任务上优于领先文本型闭源LLMs，且所需参数显著更少。

Conclusion: 多模态方法对多孔材料理解至关重要，L2M3OF可作为材料发现领域下一代AI系统的基础。

Abstract: Large language models have demonstrated remarkable reasoning capabilities
across diverse natural language tasks. However, comparable breakthroughs in
scientific discovery are more limited, because understanding complex physical
phenomena demands multifaceted representations far beyond language alone. A
compelling example is the design of functional materials such as MOFs-critical
for a range of impactful applications like carbon capture and hydrogen storage.
Navigating their vast and intricate design space in language-based
representations interpretable by LLMs is challenging due to the numerous
possible three-dimensional atomic arrangements and strict reticular rules of
coordination geometry and topology. Despite promising early results in
LLM-assisted discovery for simpler materials systems, MOF design remains
heavily reliant on tacit human expertise rarely codified in textual information
alone. To overcome this barrier, we introduce L2M3OF, the first multimodal LLM
for MOFs. L2M3OF integrates crystal representation learning with language
understanding to process structural, textual, and knowledge modalities jointly.
L2M3OF employs a pre-trained crystal encoder with a lightweight projection
layer to compress structural information into a token space, enabling efficient
alignment with language instructions. To facilitate training and evaluation, we
curate a structure-property-knowledge database of crystalline materials and
benchmark L2M3OF against state-of-the-art closed-source LLMs such as GPT-5,
Gemini-2.5-Pro and DeepSeek-R1. Experiments show that L2M3OF outperforms
leading text-based closed-source LLMs in property prediction and knowledge
generation tasks, despite using far fewer parameters. These results highlight
the importance of multimodal approaches for porous material understanding and
establish L2M3OF as a foundation for next-generation AI systems in materials
discovery.

</details>


### [50] [Memory Constrained Dynamic Subnetwork Update for Transfer Learning](https://arxiv.org/abs/2510.20979)
*Aël Quélennec,Pavlo Mozharovskyi,Van-Tam Nguyen,Enzo Tartaglione*

Main category: cs.LG

TL;DR: MeDyate introduces memory-constrained dynamic subnetwork adaptation for on-device training, combining Layer Ranking (LaRa) for principled layer pre-selection with a dynamic channel sampling strategy that re-samples channels across epochs based on importance, achieving state-of-the-art performance under very tight memory budgets.


<details>
  <summary>Details</summary>
Motivation: On-device neural network training is hindered by strict memory constraints, which limit the adaptation of pre-trained models to downstream tasks. There is a need for principled, memory-efficient fine-tuning methods that can explore parameter space under tight RAM budgets.

Method: MeDyate uses LaRa (Layer Ranking) to rate layer importance for principled layer pre-selection. It employs a dynamic channel sampling strategy that leverages the temporal stability of channel importance distributions during fine-tuning; channels are resampled between epochs according to importance-weighted probabilities to explore parameter space while respecting a fixed memory budget.

Result: Empirical evaluation across many tasks and architectures shows MeDyate achieves state-of-the-art performance under extreme memory constraints, outperforming static and dynamic baselines while remaining computationally efficient. It demonstrates effective fine-tuning with memory budgets as low as a few hundred kilobytes of RAM.

Conclusion: MeDyate represents a significant step toward practical on-device learning by enabling effective fine-tuning under stringent memory budgets and maintaining high efficiency, suggesting dynamic, importance-guided subnetwork adaptation as a viable approach for memory-constrained neural network training.

Abstract: On-device neural network training faces critical memory constraints that
limit the adaptation of pre-trained models to downstream tasks. We present
MeDyate, a theoretically-grounded framework for memory-constrained dynamic
subnetwork adaptation. Our approach introduces two key innovations: LaRa (Layer
Ranking), an improved layer importance metric that enables principled layer
pre-selection, and a dynamic channel sampling strategy that exploits the
temporal stability of channel importance distributions during fine-tuning.
MeDyate dynamically resamples channels between epochs according to
importance-weighted probabilities, ensuring comprehensive parameter space
exploration while respecting strict memory budgets. Extensive evaluation across
a large panel of tasks and architectures demonstrates that MeDyate achieves
state-of-the-art performance under extreme memory constraints, consistently
outperforming existing static and dynamic approaches while maintaining high
computational efficiency. Our method represents a significant step towards
enabling efficient on-device learning by demonstrating effective fine-tuning
with memory budgets as low as a few hundred kB of RAM.

</details>


### [51] [Learning Grouped Lattice Vector Quantizers for Low-Bit LLM Compression](https://arxiv.org/abs/2510.20984)
*Xi Zhang,Xiaolin Wu,Jiamang Wang,Weisi Lin*

Main category: cs.LG

TL;DR: 提出了分组格点向量量化（GLVQ）框架，用可学习的生成矩阵为每组权重自定义格点码本；在训练中用 Babai 四舍五入近似最近格点搜索，解码后为简单的矩阵-向量乘法。实验表明在低比特下的模型大小与精度权衡优于现有 PTQ 基线，适合资源受限场景。


<details>
  <summary>Details</summary>
Motivation: 在推理阶段通过后训练量化降低大语言模型的计算和内存需求，但传统的均匀量化在低比特位下严重损失性能，需要一种更灵活且高效的量化方案来提升性能与压缩比。

Method: 将权重分组，针对每组学习一个生成矩阵来定义自适应的格点码本；训练时使用 Babai 四舍五入近似最近格点搜索以实现可微分优化，学习得到的生成矩阵用于解码阶段的简单矩阵-向量乘法。

Result: 在多项基准测试中，GLVQ在模型大小与准确率之间取得比现有 PTQ 基线更优的折中效果，显示其在资源受限场景下部署大模型的潜力。

Conclusion: GLVQ提供了一种有效且计算高效的后训练量化解决方案，通过分组和可学习的格点生成矩阵实现更好的量化效果，且解码简单，易于部署。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities but
typically require extensive computational resources and memory for inference.
Post-training quantization (PTQ) can effectively reduce these demands by
storing weights in lower bit-width formats. However, standard uniform
quantization often leads to notable performance degradation, particularly in
low-bit scenarios. In this work, we introduce a Grouped Lattice Vector
Quantization (GLVQ) framework that assigns each group of weights a customized
lattice codebook, defined by a learnable generation matrix. To address the
non-differentiability of the quantization process, we adopt Babai rounding to
approximate nearest-lattice-point search during training, which enables stable
optimization of the generation matrices. Once trained, decoding reduces to a
simple matrix-vector multiplication, yielding an efficient and practical
quantization pipeline. Experiments on multiple benchmarks show that our
approach achieves a better trade-off between model size and accuracy compared
to existing post-training quantization baselines, highlighting its
effectiveness in deploying large models under stringent resource constraints.
Our source code is available on GitHub repository:
https://github.com/xzhang9308/GLVQ.

</details>


### [52] [GPU Memory Requirement Prediction for Deep Learning Task Based on Bidirectional Gated Recurrent Unit Optimization Transformer](https://arxiv.org/abs/2510.20985)
*Chao Wang,Zhizhao Wen,Ruoxin Zhang,Puyang Xu,Yifan Jiang*

Main category: cs.LG

TL;DR: 提出一种将 BiGRU 融合到 Transformer 的内存需求预测模型，在 GPU 内存资源预测任务中优于传统基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习任务中对 GPU 内存资源预测准确性不足的问题，提升资源调度和集群利用率。

Method: 在 Transformer 架构中嵌入双向门控循环单元（BiGRU），并以四个经典基线模型（决策树、随机森林、Adaboost、XGBoost）进行对比评估。通过对比实验评估模型在 MSE、RMSE、MAE、R2 等指标上的表现。

Result: BiGRU-Transformer 优化模型在 MSE、RMSE 方面达到最低值、预测误差最小，MAE 和 R2 指标也表现良好且稳定，综合预测性能显著优于基线方法。

Conclusion: 该模型可高效、准确地完成深度学习任务中的GPU内存需求预测，为资源调度和计算集群的利用效率提升提供技术支撑和理论依据。

Abstract: In response to the increasingly critical demand for accurate prediction of
GPU memory resources in deep learning tasks, this paper deeply analyzes the
current research status and innovatively proposes a deep learning model that
integrates bidirectional gated recurrent units (BiGRU) to optimize the
Transformer architecture, aiming to improve the accuracy of memory demand
prediction. To verify the effectiveness of the model, a carefully designed
comparative experiment was conducted, selecting four representative basic
machine learning models: decision tree, random forest, Adaboost, and XGBoost as
benchmarks. The detailed experimental results show that the BiGRU Transformer
optimization model proposed in this paper exhibits significant advantages in
key evaluation indicators: in terms of mean square error (MSE) and root mean
square error (RMSE), the model achieves the lowest value among all comparison
models, and its predicted results have the smallest deviation from the actual
values; In terms of mean absolute error (MAE) and coefficient of determination
(R2) indicators, the model also performs well and the results are balanced and
stable, with comprehensive predictive performance far exceeding the benchmark
machine learning methods compared. In summary, the Transformer model based on
bidirectional gated recurrent unit optimization successfully constructed in
this study can efficiently and accurately complete GPU memory demand prediction
tasks in deep learning tasks, and its prediction accuracy has been
significantly improved compared to traditional machine learning methods. This
research provides strong technical support and reliable theoretical basis for
optimizing resource scheduling and management of deep learning tasks, and
improving the utilization efficiency of computing clusters.

</details>


### [53] [Fair Representation Learning with Controllable High Confidence Guarantees via Adversarial Inference](https://arxiv.org/abs/2510.21017)
*Yuhong Luo,Austin Hoag,Xintong Wang,Philip S. Thomas,Przemyslaw A. Grabowicz*

Main category: cs.LG

TL;DR: 提出 FRG 框架，在表征学习中实现高置信度的公平性保证：通过一个优化的对抗模型，在用户定义的容忍度 ε 下，确保下游预测的种群差异在高概率下被约束在可控范围内，并对比六种现有方法在三个真实数据集上的表现，结果显示 FRG 在多种下游模型和任务中均能稳定地限制不公平性。


<details>
  <summary>Details</summary>
Motivation: 在表征学习中实现更强的公平性保证，避免对特定人口群体的系统性歧视。用户可设定误差阈值 ε，并在高概率意义上获得不公平性的上限，从而提升跨任务、跨模型的公平性鲁棒性。

Method: 提出 FRG（Fair Representation learning with high-confidence Guarantees）框架，通过一个优化的对抗模型实现高置信度的公平性保证。核心思路是在学习表征时对抗性地去除与敏感属性相关的信息，同时通过概率上界（高置信度）约束使下游预测中的人口差异保持在用户设定的 ε 之内，并在训练中对这一约束进行优化以提升置信度。

Result: 在三个真实数据集上与六种最先进的公平表示学习方法进行对比，FRG 在多种下游模型与任务中，始终能够对不公平性进行界定并保持在设定范围内。

Conclusion: FRG 提供了一种可实践的、高置信度的公平性保障框架，适用于不同下游任务和模型，在表征学习领域实现了稳定的公平性控制。

Abstract: Representation learning is increasingly applied to generate representations
that generalize well across multiple downstream tasks. Ensuring fairness
guarantees in representation learning is crucial to prevent unfairness toward
specific demographic groups in downstream tasks. In this work, we formally
introduce the task of learning representations that achieve high-confidence
fairness. We aim to guarantee that demographic disparity in every downstream
prediction remains bounded by a *user-defined* error threshold $\epsilon$, with
*controllable* high probability. To this end, we propose the ***F**air
**R**epresentation learning with high-confidence **G**uarantees (FRG)*
framework, which provides these high-confidence fairness guarantees by
leveraging an optimized adversarial model. We empirically evaluate FRG on three
real-world datasets, comparing its performance to six state-of-the-art fair
representation learning methods. Our results demonstrate that FRG consistently
bounds unfairness across a range of downstream models and tasks.

</details>


### [54] [More Than Memory Savings: Zeroth-Order Optimization Mitigates Forgetting in Continual Learning](https://arxiv.org/abs/2510.21019)
*Wanhao Yu,Zheng Wang,Shuteng Niu,Sen Lin,Li Yang*

Main category: cs.LG

TL;DR: ZO优化在持续学习中能天然提高稳定性并降低遗忘，因为其更平坦的损失地形，但代价是收敛变慢、学习新任务的塑性下降。为平衡这一权衡，提出ZO-FC：在单个adapter型PEFT模块上使用ZO优化，而分类器保持FO更新，从而实现稳定性与塑性的折中，且内存开销微小。


<details>
  <summary>Details</summary>
Motivation: 在对记忆和计算资源有限的设备上，持续学习需要在 plasticity（学习新任务）、stability（避免遗忘）和 efficiency（内存/计算）之间进行权衡。本研究尝试将记忆高效的ZO优化引入CL，以分析其对稳定性与塑性的影响，并探讨其在现有CL方法中的适配性。

Method: 理论分析表明ZO优化会使损失地形更平坦，从而减小遗忘；通过系统的实证评估，比较不同CL方法下ZO优化的表现，揭示稳定性提升往往以塑性下降为代价；在此基础上提出ZO-FC：在仅一个adapter型PEFT模块上应用ZO优化，同时保持分类器使用FO更新，以兼顾稳定性与适应性，并通过实验验证其在内存开销几乎无增加的前提下达到较好折中。

Result: ZO优化确实提升了CL中的稳定性、减少遗忘，但在有限训练预算下学习新任务的能力下降，尤其与可学习分类器的组合时影响更明显。将ZO应用于现有CL方法时，稳定性增强的同时往往削弱塑性，ZO对FO分类器的影响尤为显著。提出的ZO-FC在保持内存开销极低的前提下，实现在稳定性与塑性之间的折中，实验结果支持该方法在对设备友好型CL场景中的有效性。

Conclusion: ZO优化具备作为可记忆低开销的CL工具的潜力，但需仔细权衡塑性损失。通过在PEFT模块上应用ZO并保留FO分类器，ZO-FC提供了一种在稳定性与塑性之间取得良好平衡的实际方案，适合在资源受限的设备上进行联邦式或任务增量式CL。

Abstract: Zeroth-order (ZO) optimization has gained attention as a memory-efficient
alternative to first-order (FO) methods, particularly in settings where
gradient computation is expensive or even impractical. Beyond its memory
efficiency, in this work, we investigate ZO optimization for continual learning
(CL) as a novel approach to address the plasticity-stability-efficiency
trilemma. Through theoretical analysis and empirical evidence, we show that ZO
optimization naturally leads to flatter loss landscapes, which in turn reduce
forgetting in CL. However, this stability comes at a cost of plasticity: due to
its imprecise gradient estimates and slower convergence, ZO optimization tends
to be less effective than FO in acquiring new task-specific knowledge,
particularly under constrained training budgets. To better understand this
trade-off, we conduct a holistic evaluation of ZO optimization applied to
various existing CL methods. Our findings reveal that ZO optimization enhances
stability but often undermines plasticity, particularly when used with
learnable classifiers. Motivated by this insight, we propose ZO-FC, a simple
but effective approach that applies ZO optimization to a single adapter-based
PEFT module with FO optimized classifier. This design leverages the stability
benefits of ZO while preserving the adaptability of FO updates with negligible
memory overhead. Experiments demonstrate that ZO-FC achieves an effective
balance between stability and plasticity, offering a practical and
memory-efficient solution for on-device CL.

</details>


### [55] [CIPHER: Scalable Time Series Analysis for Physical Sciences with Application to Solar Wind Phenomena](https://arxiv.org/abs/2510.21022)
*Jasmine R. Kobayashi,Daniela Martin,Valmir P Moraes Filho,Connor O'Brien,Jinsu Hong,Sudeshna Boro Saikia,Hala Lamdouar,Nathan D. Miles,Marcella Scoczynski,Mavis Stone,Sairam Sundaresan,Anna Jungbluth,Andrés Muñoz-Jaramillo,Evangelia Samara,Joseph Gallego*

Main category: cs.LG

TL;DR: 提出 CIPHER 框架：将 iSAX、HDBSCAN 和人机交互结合，用于大规模标注物理时间序列，并在太阳风数据上验证可识别现象如 CME 与 SIR，具备可扩展性和可复现性。


<details>
  <summary>Details</summary>
Motivation: 物理科学领域中时间序列的标注稀缺、成本高且不一致，迫切需要一种可扩展、可解释且能结合专家知识的标注策略，以支持机器学习的理解、预测和预报。

Method: 使用 indexable Symbolic Aggregate approXimation (iSAX) 进行可解释的压缩与索引；采用基于密度的聚类（HDBSCAN）对重复现象进行分组；引入人机环节以高效验证。选取代表样本供领域科学家标注，并将标注在簇中传播以实现系统化、可扩展的分类。

Result: 在 OMNI 数据的太阳风现象分类任务中，CIPHER 能恢复有意义的现象，如日冕物质抛射和流相互作用区。该框架展示了将符号表示、无监督学习与专家知识相结合以缓解时序标签稀缺的通用策略。代码与配置文件对外公开以支持复现。

Conclusion: 该工作提出了一种通用策略，将符号表示、无监督学习和专家知识融合，用以解决物理科学中时间序列标签稀缺的问题，且具有可扩展性和可复现性，适用于不同领域的时间序列标注任务。

Abstract: Labeling or classifying time series is a persistent challenge in the physical
sciences, where expert annotations are scarce, costly, and often inconsistent.
Yet robust labeling is essential to enable machine learning models for
understanding, prediction, and forecasting. We present the \textit{Clustering
and Indexation Pipeline with Human Evaluation for Recognition} (CIPHER), a
framework designed to accelerate large-scale labeling of complex time series in
physics. CIPHER integrates \textit{indexable Symbolic Aggregate approXimation}
(iSAX) for interpretable compression and indexing, density-based clustering
(HDBSCAN) to group recurring phenomena, and a human-in-the-loop step for
efficient expert validation. Representative samples are labeled by domain
scientists, and these annotations are propagated across clusters to yield
systematic, scalable classifications. We evaluate CIPHER on the task of
classifying solar wind phenomena in OMNI data, a central challenge in space
weather research, showing that the framework recovers meaningful phenomena such
as coronal mass ejections and stream interaction regions. Beyond this case
study, CIPHER highlights a general strategy for combining symbolic
representations, unsupervised learning, and expert knowledge to address label
scarcity in time series across the physical sciences. The code and
configuration files used in this study are publicly available to support
reproducibility.

</details>


### [56] [DictPFL: Efficient and Private Federated Learning on Encrypted Gradients](https://arxiv.org/abs/2510.21086)
*Jiaqi Xue,Mayank Kumar,Yuzhang Shang,Shangqian Gao,Rui Ning,Mengxin Zheng,Xiaoqian Jiang,Qian Lou*

Main category: cs.LG

TL;DR: DictPFL 提出一种实用的同态加密基于联邦学习框架，通过将模型权重分解为静态字典和可更新查找表，只有后者被加密与聚合，从而实现全梯度保护且开销极低；并通过 PrME 进行加密感知裁剪，显著降低加密参数量，最终实现接近明文FL的性能。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中梯度共享存在隐私风险；同态加密虽能保护，但计算与通信开销高；现有基于HE的FL要么对所有梯度加密要么仅部分加密，存在隐私与效率的折中。

Method: DePE 将权重分解成静态字典和可更新查找表，非更新部分本地保留，不共享也不加密；仅对后者进行加密和聚合。PrME 基于加密感知的剪枝，通过历史一致性掩码来最小化需要加密的参数数量。

Result: 在多项指标上显著优于全加密FL与现有选择性加密方法：通信成本下降 402-748 倍、训练加速 28-65 倍，相对于最先进的选择性加密在开销上提升 51-155 倍、速度提升 4-19 倍；运行时间接近明文FL的两倍内。

Conclusion: 证明了在现实场景中，基于HE的私有联邦学习是可行的，DictPFL成为实现低开销全梯度保护的实用方案；代码公开可获取。

Abstract: Federated Learning (FL) enables collaborative model training across
institutions without sharing raw data. However, gradient sharing still risks
privacy leakage, such as gradient inversion attacks. Homomorphic Encryption
(HE) can secure aggregation but often incurs prohibitive computational and
communication overhead. Existing HE-based FL methods sit at two extremes:
encrypting all gradients for full privacy at high cost, or partially encrypting
gradients to save resources while exposing vulnerabilities. We present DictPFL,
a practical framework that achieves full gradient protection with minimal
overhead. DictPFL encrypts every transmitted gradient while keeping
non-transmitted parameters local, preserving privacy without heavy computation.
It introduces two key modules: Decompose-for-Partial-Encrypt (DePE), which
decomposes model weights into a static dictionary and an updatable lookup
table, only the latter is encrypted and aggregated, while the static dictionary
remains local and requires neither sharing nor encryption; and
Prune-for-Minimum-Encrypt (PrME), which applies encryption-aware pruning to
minimize encrypted parameters via consistent, history-guided masks. Experiments
show that DictPFL reduces communication cost by 402-748$\times$ and accelerates
training by 28-65$\times$ compared to fully encrypted FL, while outperforming
state-of-the-art selective encryption methods by 51-155$\times$ in overhead and
4-19$\times$ in speed. Remarkably, DictPFL's runtime is within 2$\times$ of
plaintext FL, demonstrating for the first time, that HE-based private federated
learning is practical for real-world deployment. The code is publicly available
at https://github.com/UCF-ML-Research/DictPFL.

</details>


### [57] [Amortized Active Generation of Pareto Sets](https://arxiv.org/abs/2510.21052)
*Daniel M. Steinberg,Asiri Wijesinghe,Rafael Oliveira,Piotr Koniusz,Cheng Soon Ong,Edwin V. Bonilla*

Main category: cs.LG

TL;DR: A-GPS是一种在线离散黑盒多目标优化的新框架，通过对 Pareto 集的生成模型进行后验偏好条件化与非支配预测实现对Pareto前沿的高效近似与定制化偏好采样，且无需显式超体积计算。


<details>
  <summary>Details</summary>
Motivation: 在离散离线/在线黑盒多目标优化中，需要快速、可定制地获取Pareto前沿，同时避免昂贵的超体积估计和反复模型重训练；需要一个能够在在线更新中同时考虑Pareto成员性和用户偏好的生成模型。

Method: 构建Pareto集合的生成模型，使用一个类别概率估计器（CPE）来预测非支配关系并将其作为条件信号引导生成模型向高性能区域靠拢；揭示非支配CPE在隐式地估计超体积改进的概率（PHVI）；引入偏好方向向量来编码用户在目标空间中的偏好；在每次迭代中结合Pareto成员性和与偏好方向的对齐来更新模型，形成一个可 amortized 使用、无需重新训练即可在Pare时线性采样前沿的生成模型。

Result: 在合成基准和蛋白质设计任务上，A-GPS显示出较高的样本效率和对偏好整合的有效性，能够获得高质量的Pareto集合近似并避免显式的超体积计算。

Conclusion: A-GPS提供了一个简单而强大的在线离散MOO框架，能够高效捕捉用户偏好并在无需重新训练的情况下对Pareto前沿进行全面采样，具有良好的应用潜力。

Abstract: We introduce active generation of Pareto sets (A-GPS), a new framework for
online discrete black-box multi-objective optimization (MOO). A-GPS learns a
generative model of the Pareto set that supports a-posteriori conditioning on
user preferences. The method employs a class probability estimator (CPE) to
predict non-dominance relations and to condition the generative model toward
high-performing regions of the search space. We also show that this
non-dominance CPE implicitly estimates the probability of hypervolume
improvement (PHVI). To incorporate subjective trade-offs, A-GPS introduces
preference direction vectors that encode user-specified preferences in
objective space. At each iteration, the model is updated using both Pareto
membership and alignment with these preference directions, producing an
amortized generative model capable of sampling across the Pareto front without
retraining. The result is a simple yet powerful approach that achieves
high-quality Pareto set approximations, avoids explicit hypervolume
computation, and flexibly captures user preferences. Empirical results on
synthetic benchmarks and protein design tasks demonstrate strong sample
efficiency and effective preference incorporation.

</details>


### [58] [On the Sample Complexity of Differentially Private Policy Optimization](https://arxiv.org/abs/2510.21060)
*Yi He,Xingyu Zhou*

Main category: cs.LG

TL;DR: 本文开启对差分隐私（DP）在策略优化（PO）中的理论研究，提出适用于PO的DP定义并用统一框架分析了PG、NPG等算法在DP约束下的样本复杂度，结论是隐私成本往往以较低阶项出现，同时揭示了私有PO中的若干微妙现象，为设计隐私保护的PO算法提供实用洞见。


<details>
  <summary>Details</summary>
Motivation: 随着策略优化在机器人、医疗等敏感领域的广泛应用，隐私保护成为关键问题。现有对DP的研究多针对离线或基于批数据的设置，缺乏对在策略学习这一在线/与策略相关的依赖结构中如何定义隐私单元及其对样本效率的影响的系统性分析。因此，需要在PO的具体特性下给出DP定义并评估其样本复杂度。

Method: 提出面向PO的差分隐私定义，解决在基于策略的在线学习中隐私单元的选择及上/下界的挑战。在统一的分析框架下，系统地分析了包括策略梯度（PG）、自然策略梯度（NPG）等在DP约束下的样本复杂度，讨论了不同设置（如对数似然、轨迹级别隐私等）的影响。

Result: 理论结果显示，在多种PO算法中，隐私成本往往以样本复杂度的低阶项出现，不会改变主要收敛速率的阶数；同时揭示了DP下私有PO中的若干微妙现象，如隐私机制的选择对梯度估计与策略更新的影响。这些发现为设计更高效的隐私保护PO算法提供了理论依据和直观指南。

Conclusion: 差分隐私的引入在策略优化中是可行的且成本可控，隐私预算的影响多为低阶项且受框架与实现细节显著影响。本文所提出的DP定义与统一分析框架为未来针对PO的隐私保护研究提供了基础工具和方向。

Abstract: Policy optimization (PO) is a cornerstone of modern reinforcement learning
(RL), with diverse applications spanning robotics, healthcare, and large
language model training. The increasing deployment of PO in sensitive domains,
however, raises significant privacy concerns. In this paper, we initiate a
theoretical study of differentially private policy optimization, focusing
explicitly on its sample complexity. We first formalize an appropriate
definition of differential privacy (DP) tailored to PO, addressing the inherent
challenges arising from on-policy learning dynamics and the subtlety involved
in defining the unit of privacy. We then systematically analyze the sample
complexity of widely-used PO algorithms, including policy gradient (PG),
natural policy gradient (NPG) and more, under DP constraints and various
settings, via a unified framework. Our theoretical results demonstrate that
privacy costs can often manifest as lower-order terms in the sample complexity,
while also highlighting subtle yet important observations in private PO
settings. These offer valuable practical insights for privacy-preserving PO
algorithms.

</details>


### [59] [Scalable Machine Learning Analysis of Parker Solar Probe Solar Wind Data](https://arxiv.org/abs/2510.21066)
*Daniela Martin,Connor O'Brien,Valmir P Moraes Filho,Jinsu Hong,Jasmine R. Kobayashi,Evangelia Samara,Joseph Gallego*

Main category: cs.LG

TL;DR: 提出一种基于分布式计算（Dask）和量子灵感的 Kernel Density Matrices 的可扩展框架，用于分析 Parker Solar Probe 的太阳风数据，估计关键参数分布并给出异常阈值，揭示近日地层的速度-密度关系及相关结构对极端空间天气的影响，并提供开源数据与工具。


<details>
  <summary>Details</summary>
Motivation: 应对 Parker Solar Probe（PSP）数据规模（2018–2024 年超过 150 GB），传统分析方法难以扩展，需可解释、分布式的分析框架来提取关键参数分布、异常阈值及其物理含义。

Method: 使用 Dask 进行大规模分布式统计计算；引入量子灵感的 Kernel Density Matrices (KDM) 来估计单变量和两变量分布（包括太阳风速度、质子密度、质子热速等）并设定异常阈值；分析了内日球层的趋势，提供可重复的数据处理与分析流程，公开数据产品与代码。

Result: 得到的结果包括：1) 观察到太阳风速度随距离增加、质子密度下降、速度与密度呈负相关的特征趋势；2) 通过 KDM 得到关键参数的分布特征和异常阈值；3) 太阳风结构在放大与调控极端空间天气事件方面具有显著作用的定量见解；4) 公开了处理后数据产品与分析工具，促进重复性研究。

Conclusion: 该框架提供一个可扩展、可解释且分布式的分析方法，适用于大规模原位观测数据的研究，提升再现性与开放科学水平；数据与工具公开，将促进未来太阳风动力学研究与空间天气预测的协同发展。

Abstract: We present a scalable machine learning framework for analyzing Parker Solar
Probe (PSP) solar wind data using distributed processing and the
quantum-inspired Kernel Density Matrices (KDM) method. The PSP dataset
(2018--2024) exceeds 150 GB, challenging conventional analysis approaches. Our
framework leverages Dask for large-scale statistical computations and KDM to
estimate univariate and bivariate distributions of key solar wind parameters,
including solar wind speed, proton density, and proton thermal speed, as well
as anomaly thresholds for each parameter. We reveal characteristic trends in
the inner heliosphere, including increasing solar wind speed with distance from
the Sun, decreasing proton density, and the inverse relationship between speed
and density. Solar wind structures play a critical role in enhancing and
mediating extreme space weather phenomena and can trigger geomagnetic storms;
our analyses provide quantitative insights into these processes. This approach
offers a tractable, interpretable, and distributed methodology for exploring
complex physical datasets and facilitates reproducible analysis of large-scale
in situ measurements. Processed data products and analysis tools are made
publicly available to advance future studies of solar wind dynamics and space
weather forecasting. The code and configuration files used in this study are
publicly available to support reproducibility.

</details>


### [60] [The Virtues of Brevity: Avoid Overthinking in Parallel Test-Time Reasoning](https://arxiv.org/abs/2510.21067)
*Raul Cavalcante Dinardi,Bruno Yamamoto,Anna Helena Reali Costa,Artur Jordao*

Main category: cs.LG

TL;DR: 最短答案启发式在并行生成中表现出与自一致性等方法相当的推理能力，但显著降低计算成本，构成帕累托改进。


<details>
  <summary>Details</summary>
Motivation: 为大语言模型的推理任务提供更高效的解答策略，表明在两个基准上，选取最短解比复杂的多解自一致性方法更省资源且效果不下降。

Method: 在两个挑战性基准上，将最短答案启发式与自一致性方法进行对比，分析模型存在的两种推理模式（简短自信的常规模式与冗长思考的中断模式）及转折点，评估计算开销。

Result: 最短答案方法在两项基准上与自一致性相当，同时显著降低计算成本；在输出等式定义不明确的任务上也有效，提供帕累托改进。

Conclusion: 该启发式通过偏向从常规模式抽样来实现高效推理，既保持性能又降低资源消耗，具实用性与普适性。

Abstract: Reasoning models represent a significant advance in LLM capabilities,
particularly for complex reasoning tasks such as mathematics and coding.
Previous studies confirm that parallel test-time compute-sampling multiple
solutions and selecting the best one-can further enhance the predictive
performance of LLMs. However, strategies in this area often require complex
scoring, thus increasing computational cost and complexity. In this work, we
demonstrate that the simple and counterintuitive heuristic of selecting the
shortest solution is highly effective. We posit that the observed effectiveness
stems from models operating in two distinct regimes: a concise, confident
conventional regime and a verbose overthinking regime characterized by
uncertainty, and we show evidence of a critical point where the overthinking
regime begins to be significant. By selecting the shortest answer, the
heuristic preferentially samples from the conventional regime. We confirm that
this approach is competitive with more complex methods such as self-consistency
across two challenging benchmarks while significantly reducing computational
overhead. The shortest-answer heuristic provides a Pareto improvement over
self-consistency and applies even to tasks where output equality is not well
defined.

</details>


### [61] [ESCORT: Efficient Stein-variational and Sliced Consistency-Optimized Temporal Belief Representation for POMDPs](https://arxiv.org/abs/2510.21107)
*Yunuo Zhang,Baiting Luo,Ayan Mukhopadhyay,Gabor Karsai,Abhishek Dubey*

Main category: cs.LG

TL;DR: ESCORT是一种基于粒子的估计框架，扩展了SVGD，加入相关性感知投影和时序一致性约束，用于高维POMDP信念的高保真建模，避免重采样并提升下游决策质量。


<details>
  <summary>Details</summary>
Motivation: 在POMDP中，信念分布往往高度复杂，具有多模态性和高维度，现有方法难以准确表示这些不确定性结构，导致估计误差和次优策略。需要一种可扩展、非参数且能捕捉维度间相关性与时间一致性的信念表示。

Method: ESCORT将SVGD扩展为受拥塞离散粒子动力学影响的框架，提出两大创新：1) 相关性感知投影，建模状态维度之间的依赖关系；2) 时序一致性约束，稳定更新并保持相关结构。保留SVGD的粒子间吸引-排斥动力学，避免简化分布假设，不依赖重采样，能够自适应信念景观的复杂度。对POMDP域及合成多模态高维分布进行广泛评估。

Result: 在信念近似准确性和下游决策质量方面，ESCORT在与最先进方法的对比中表现出一致的优势，尤其在处理高维、多模态信念分布时，显示更高的准确性和鲁棒性。

Conclusion: ESCORT提供了一种高效、可扩展且非重采样的粒子表示方案，能够在现实环境中捕捉复杂的不确定性结构并提升决策性能。

Abstract: In Partially Observable Markov Decision Processes (POMDPs), maintaining and
updating belief distributions over possible underlying states provides a
principled way to summarize action-observation history for effective
decision-making under uncertainty. As environments grow more realistic, belief
distributions develop complexity that standard mathematical models cannot
accurately capture, creating a fundamental challenge in maintaining
representational accuracy. Despite advances in deep learning and probabilistic
modeling, existing POMDP belief approximation methods fail to accurately
represent complex uncertainty structures such as high-dimensional, multi-modal
belief distributions, resulting in estimation errors that lead to suboptimal
agent behaviors. To address this challenge, we present ESCORT (Efficient
Stein-variational and sliced Consistency-Optimized Representation for Temporal
beliefs), a particle-based framework for capturing complex, multi-modal
distributions in high-dimensional belief spaces. ESCORT extends SVGD with two
key innovations: correlation-aware projections that model dependencies between
state dimensions, and temporal consistency constraints that stabilize updates
while preserving correlation structures. This approach retains SVGD's
attractive-repulsive particle dynamics while enabling accurate modeling of
intricate correlation patterns. Unlike particle filters prone to degeneracy or
parametric methods with fixed representational capacity, ESCORT dynamically
adapts to belief landscape complexity without resampling or restrictive
distributional assumptions. We demonstrate ESCORT's effectiveness through
extensive evaluations on both POMDP domains and synthetic multi-modal
distributions of varying dimensionality, where it consistently outperforms
state-of-the-art methods in terms of belief approximation accuracy and
downstream decision quality.

</details>


### [62] [Distributionally Robust Feature Selection](https://arxiv.org/abs/2510.21113)
*Maitreyi Swaroop,Tamar Krishnamurti,Bryan Wilder*

Main category: cs.LG

TL;DR: 提出一种基于持续松弛和噪声机制的模型无关特征选择方法，在特征成本受限下实现跨子群体的均衡预测性能；避免对训练过程的反向传播；在合成与真实数据上得到验证。


<details>
  <summary>Details</summary>
Motivation: 特征获取成本高，需要在多个子群体中获得稳定的高质量下游模型；目标是在有限的特征下兼顾不同群体的预测性能。

Method: 通过对传统变量选择进行持续松弛并引入噪声机制，建立一个不依赖对训练过程进行反向传播的模型无关框架；通过优化贝叶斯最优预测器的方差来平衡不同群体的总体性能。

Result: 在合成数据和真实数据集上进行实验，验证该方法能在多群体场景中实现性能的均衡提升。

Conclusion: 所提出的框架提供一种灵活、成本效益高且模型无关的多群体特征选择解决方案，适用于特征获取成本高的应用场景。

Abstract: We study the problem of selecting limited features to observe such that
models trained on them can perform well simultaneously across multiple
subpopulations. This problem has applications in settings where collecting each
feature is costly, e.g. requiring adding survey questions or physical sensors,
and we must be able to use the selected features to create high-quality
downstream models for different populations. Our method frames the problem as a
continuous relaxation of traditional variable selection using a noising
mechanism, without requiring backpropagation through model training processes.
By optimizing over the variance of a Bayes-optimal predictor, we develop a
model-agnostic framework that balances overall performance of downstream
prediction across populations. We validate our approach through experiments on
both synthetic datasets and real-world data.

</details>


### [63] [SolarBoost: Distributed Photovoltaic Power Forecasting Amid Time-varying Grid Capacity](https://arxiv.org/abs/2510.21129)
*Linyuan Geng,Linxiao Yang,Xinyue Gu,Liang Sun*

Main category: cs.LG

TL;DR: SolarBoost 将分布式光伏输出预测问题建模为小网格输出的加权和，通过将单位输出函数与容量解耦实现对 DPV 的高精度预测；并提出基于上界近似的高效算法以克服损失函数的计算瓶颈，在中国多城部署验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的集中式光伏方法在输出依赖关系建模上表现良好，但难以直接应用于分布式光伏系统，因为 DPV 面临缺失的网格级数据、装机容量的时间漂移、地理异质性与面板多样性等挑战，需要一种能处理聚合输出且考虑容量动态的建模方法。

Method: 将聚合输出建模为来自若干小网格的输出的组合，每个网格的输出等于单位输出函数乘以其容量；通过将单位输出函数与容量分离，提高预测的准确性。为解决损失函数的计算瓶颈，提出对上界近似的高效算法。并提供理论分析和实验验证。

Result: 在理论分析和实验中证明了网格级建模的优越性；在中国多个城市部署验证了该方法，显著降低潜在损失并为电网运行提供有价值的洞察；代码公开可获取。

Conclusion: SolarBoost通过解耦单位输出函数和容量、结合网格级建模与上界近似的高效算法，提供面向分布式光伏的准确、可扩展的输出预测，对实际电网运维具有显著应用价值。

Abstract: This paper presents SolarBoost, a novel approach for forecasting power output
in distributed photovoltaic (DPV) systems. While existing centralized
photovoltaic (CPV) methods are able to precisely model output dependencies due
to uniformity, it is difficult to apply such techniques to DPV systems, as DPVs
face challenges such as missing grid-level data, temporal shifts in installed
capacity, geographic variability, and panel diversity. SolarBoost overcomes
these challenges by modeling aggregated power output as a composite of output
from small grids, where each grid output is modeled using a unit output
function multiplied by its capacity. This approach decouples the homogeneous
unit output function from dynamic capacity for accurate prediction. Efficient
algorithms over an upper-bound approximation are proposed to overcome
computational bottlenecks in loss functions. We demonstrate the superiority of
grid-level modeling via theoretical analysis and experiments. SolarBoost has
been validated through deployment across various cities in China, significantly
reducing potential losses and provides valuable insights for the operation of
power grids. The code for this work is available at
https://github.com/DAMO-DI-ML/SolarBoost.

</details>


### [64] [Cloud-Fog-Edge Collaborative Computing for Sequential MIoT Workflow: A Two-Tier DDPG-Based Scheduling Framework](https://arxiv.org/abs/2510.21135)
*Yuhao Fu,Yinghao Zhang,Yalin Liu,Bishenghui Tao,Junhong Ruan*

Main category: cs.LG

TL;DR: 提出一个两层DDPG调度框架，全球控制器在边缘/雾/云之间进行层级选择，局部控制器在所选层内分配节点，目标为最小化工作流的总完成时间（makespan），在复杂场景下显著优于基线。


<details>
  <summary>Details</summary>
Motivation: MIoT场景需要对串行化的医疗工作流在异构的云-边-雾基础设施上提供端到端的严格时延保证。将调度问题化简为NP-hard，现有方法难以在大规模/高复杂度场景中获得长期有效的调度策略。

Method: 提出两层调度框架：全局控制器进行层级选择（边缘/雾/云），局部控制器在所选层内负责节点分配；使用两层DDPG进行强化学习，以最小化工作流的总完成时间（makespan），实现端到端的自学习调度策略。

Result: 实验结果显示，随着工作流复杂度上升，所提方法对比基线具有越来越显著的性能提升，表明模型能学习到有效的长时记忆策略，适用于复杂、规模化的MIoT调度场景。

Conclusion: 提出的两层DDPG调度框架在大规模MIoT调度中展现出对端到端时延优化的潜力，强调了学习长期策略在复杂系统中的重要性。

Abstract: The Medical Internet of Things (MIoT) demands stringent end-to-end latency
guarantees for sequential healthcare workflows deployed over heterogeneous
cloud-fog-edge infrastructures. Scheduling these sequential workflows to
minimize makespan is an NP-hard problem. To tackle this challenge, we propose a
Two-tier DDPG-based scheduling framework that decomposes the scheduling
decision into a hierarchical process: a global controller performs layer
selection (edge, fog, or cloud), while specialized local controllers handle
node assignment within the chosen layer. The primary optimization objective is
the minimization of the workflow makespan. Experiments results validate our
approach, demonstrating increasingly superior performance over baselines as
workflow complexity rises. This trend highlights the frameworks ability to
learn effective long-term strategies, which is critical for complex,
large-scale MIoT scheduling scenarios.

</details>


### [65] [A Unified Matrix Factorization Framework for Classical and Robust Clustering](https://arxiv.org/abs/2510.21172)
*Angshul Majumdar*

Main category: cs.LG

TL;DR: Unified matrix factorization view of crisp and fuzzy clustering, plus robust variants


<details>
  <summary>Details</summary>
Motivation: Provide a principled unification of clustering (k-means, fuzzy c-means) with matrix factorization to enable robust extensions and a common optimization framework.

Method: Relate crisp k-means to an existing matrix factorization; derive a matrix factorization for fuzzy c-means; cast both as factor-muture optimization problems; replace Frobenius norm with l1,2-norm for robustness; design alternating minimization algorithms; develop IRLS for robust versions; prove convergence to local minima.

Result: New unified interpretations of crisp and fuzzy clustering as matrix factorization problems; robust formulations via l1,2-norm; practical algorithms (alternating minimization, IRLS) with convergence guarantees to local minima.

Conclusion: A principled framework that unifies classical and robust clustering under matrix factorization, enabling straightforward extensions to robust variants and ensuring convergence of the proposed algorithms.

Abstract: This paper presents a unified matrix factorization framework for classical
and robust clustering. We begin by revisiting the well-known equivalence
between crisp k-means clustering and matrix factorization, following and
rigorously rederiving an unpublished formulation by Bauckhage. Extending this
framework, we derive an analogous matrix factorization interpretation for fuzzy
c-means clustering, which to the best of our knowledge has not been previously
formalized. These reformulations allow both clustering paradigms to be
expressed as optimization problems over factor matrices, thereby enabling
principled extensions to robust variants. To address sensitivity to outliers,
we propose robust formulations for both crisp and fuzzy clustering by replacing
the Frobenius norm with the l1,2-norm, which penalizes the sum of Euclidean
norms across residual columns. We develop alternating minimization algorithms
for the standard formulations and IRLS-based algorithms for the robust
counterparts. All algorithms are theoretically proven to converge to a local
minimum.

</details>


### [66] [A visual big data system for the prediction of weather-related variables: Jordan-Spain case study](https://arxiv.org/abs/2510.21176)
*Shadi Aljawarneh,Juan A. Lara,Muneer Bani Yassein*

Main category: cs.LG

TL;DR: 提出一个可视化大数据系统，用于高容量、高维度、存在缺失值的气象数据的分析与预测，覆盖温度与降水等变量；通过本地NoSQL存储、时空聚合融合和邻站训练实现单变量/多变量预测及预测预测；初步评估显示极低的NRMSE（0.00013）和方向性对称性约0.84，专家评审对系统整体给予积极评价。


<details>
  <summary>Details</summary>
Motivation: 气象数据具有高体量、高维度、缺失值频发以及变量之间高度相关等特性，亟需利用大数据和数据挖掘技术来提取有用知识并支持对天气现象的预测。

Method: 设计并实现一个可视化大数据系统，用于收集开放数据并加载到本地NoSQL数据库，对数据按时间和空间进行聚合融合，以进行单变量与多变量分析，以及基于邻近观测站的训练与预测（在缺失值较高的情形下），并通过可视化界面支持用户分析与预测任务。

Result: 在可用性和预测性能方面进行了评估，得到归一化均方误差（NRMSE）约0.00013，方向性对称性约0.84。专家小组对系统的各方面评价较高（图形设计除外，均为3分及以上，满分5分）。

Conclusion: 结果显示系统具备潜在应用价值，初步证实了将可视化大数据方法应用于气象预测的可行性；未来工作可在提升图形设计、增强鲁棒性、扩展数据源与模型类型等方面进一步开展。

Abstract: The Meteorology is a field where huge amounts of data are generated, mainly
collected by sensors at weather stations, where different variables can be
measured. Those data have some particularities such as high volume and
dimensionality, the frequent existence of missing values in some stations, and
the high correlation between collected variables. In this regard, it is crucial
to make use of Big Data and Data Mining techniques to deal with those data and
extract useful knowledge from them that can be used, for instance, to predict
weather phenomena. In this paper, we propose a visual big data system that is
designed to deal with high amounts of weather-related data and lets the user
analyze those data to perform predictive tasks over the considered variables
(temperature and rainfall). The proposed system collects open data and loads
them onto a local NoSQL database fusing them at different levels of temporal
and spatial aggregation in order to perform a predictive analysis using
univariate and multivariate approaches as well as forecasting based on training
data from neighbor stations in cases with high rates of missing values. The
system has been assessed in terms of usability and predictive performance,
obtaining an overall normalized mean squared error value of 0.00013, and an
overall directional symmetry value of nearly 0.84. Our system has been rated
positively by a group of experts in the area (all aspects of the system except
graphic desing were rated 3 or above in a 1-5 scale). The promising preliminary
results obtained demonstrate the validity of our system and invite us to keep
working on this area.

</details>


### [67] [Scalable Principal-Agent Contract Design via Gradient-Based Optimization](https://arxiv.org/abs/2510.21177)
*Tomer Galanti,Aarya Bookseller,Korok Ray*

Main category: cs.LG

TL;DR: A versatile bilevel max-max optimization framework for principal-agent contract design that uses implicit differentiation and conjugate gradients to compute hypergradients, enabling matrix-free, scalable solutions for nonlinear, stochastic contracts beyond closed-form LQ models; validated on CARA-Normal benchmarks and extendable to diverse nonlinear contracts.


<details>
  <summary>Details</summary>
Motivation: Tackle the gap in principal-agent theory where realistic problems with moral hazard, nonlinear utilities, and stochastic dynamics lack closed-form solutions; provide a computational tool to design and study complex contracts.

Method: A generic, matrix-free bilevel optimization framework that uses implicit differentiation with conjugate gradients to compute hypergradients via Hessian-vector products, avoiding explicit Hessian formation or inversion; variance-reduced and problem-agnostic; applicable to nonlinear contracts (sigmoidal pay, relative performance, multi-task, CARA-Poisson).

Result: In CARA-Normal benchmark environments, the method recovers known analytical optima and converges reliably from random initializations; demonstrates efficiency by not forming/inverting Hessians; broad applicability to nonlinear and high-dimensional contracts where closed forms are unavailable.

Conclusion: Provides a new computational tool for contract design, enabling systematic study of models that are analytically intractable and extending ML-based bilevel optimization methods to contract theory and related market-design problems.

Abstract: We study a bilevel \emph{max-max} optimization framework for principal-agent
contract design, in which a principal chooses incentives to maximize utility
while anticipating the agent's best response. This problem, central to moral
hazard and contract theory, underlies applications ranging from market design
to delegated portfolio management, hedge fund fee structures, and executive
compensation. While linear-quadratic models such as Holmstr"om-Milgrom admit
closed-form solutions, realistic environments with nonlinear utilities,
stochastic dynamics, or high-dimensional actions generally do not.
  We introduce a generic algorithmic framework that removes this reliance on
closed forms. Our method adapts modern machine learning techniques for bilevel
optimization -- using implicit differentiation with conjugate gradients (CG) --
to compute hypergradients efficiently through Hessian-vector products, without
ever forming or inverting Hessians. In benchmark CARA-Normal (Constant Absolute
Risk Aversion with Gaussian distribution of uncertainty) environments, the
approach recovers known analytical optima and converges reliably from random
initialization. More broadly, because it is matrix-free, variance-reduced, and
problem-agnostic, the framework extends naturally to complex nonlinear
contracts where closed-form solutions are unavailable, such as sigmoidal wage
schedules (logistic pay), relative-performance/tournament compensation with
common shocks, multi-task contracts with vector actions and heterogeneous
noise, and CARA-Poisson count models with $\mathbb{E}[X\mid a]=e^{a}$. This
provides a new computational tool for contract design, enabling systematic
study of models that have remained analytically intractable.

</details>


### [68] [Reducing the Probability of Undesirable Outputs in Language Models Using Probabilistic Inference](https://arxiv.org/abs/2510.21184)
*Stephen Zhao,Aidan Li,Rob Brekelmans,Roger Grosse*

Main category: cs.LG

TL;DR: 提出 RePULSe，通过在标准 RL 损失基础上增加额外损失，利用学习到的提案来引导对低回报输出的采样并降低其概率，从而在期望奖励与不良输出概率之间取得更好权衡，并提升对抗性鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的 RL 对齐 LM 主要优化平均奖励；但降低不良输出的概率往往以牺牲平均性能为代价，需要在不显著降低平均奖励的前提下减少 undesired outputs 的概率，并提升对对抗性攻击的鲁棒性。

Method: RePULSe 在标准 RL 损失上增加一个额外的损失，该损失使用学习到的提案来引导对低奖励输出的采样，从而降低它们的概率。

Result: 实验显示 RePULSe 在期望奖励与 undesired outputs 的概率之间实现更好的权衡；相较于标准 RL 和其他替代方法，具有更强的对抗性鲁棒性。

Conclusion: RePULSe 提供了一种更高效的对齐训练策略，改善平均奖励与不良输出控制之间的折中，并提高对对抗性攻击的鲁棒性。

Abstract: Reinforcement learning (RL) has become a predominant technique to align
language models (LMs) with human preferences or promote outputs which are
deemed to be desirable by a given reward function. Standard RL approaches
optimize average reward, while methods explicitly focused on reducing the
probability of undesired outputs typically come at a cost to average-case
performance. To improve this tradeoff, we introduce RePULSe, a new training
method that augments the standard RL loss with an additional loss that uses
learned proposals to guide sampling low-reward outputs, and then reduces those
outputs' probability. We run experiments demonstrating that RePULSe produces a
better tradeoff of expected reward versus the probability of undesired outputs
and is more adversarially robust, compared to standard RL alignment approaches
and alternatives.

</details>


### [69] [PLAN: Proactive Low-Rank Allocation for Continual Learning](https://arxiv.org/abs/2510.21188)
*Xiequn Wang,Zhan Zhuang,Yu Zhang*

Main category: cs.LG

TL;DR: PLAN extends LoRA for continual learning by proactive low-rank subspace allocation, introducing orthogonal task-specific bases and a perturbation-based strategy to minimize interference, plus a selection mechanism to choose low-sensitivity bases; achieving state-of-the-art on standard CL benchmarks.


<details>
  <summary>Details</summary>
Motivation: Continual learning with large foundation models suffers from catastrophic forgetting when adapting to new tasks; there is a need for efficient, interference-aware fine-tuning that preserves past knowledge while enabling new task adaptation.

Method: Propose PLAN: extend Low-Rank Adaptation (LoRA) with proactive allocation of task-specific subspaces by maintaining orthogonal basis vectors for each task; optimize these bases via a perturbation-based strategy to minimize conflicts with previously learned parameters; include a selection mechanism to assign basis vectors with minimal sensitivity to interference, reducing degradation of past knowledge while maintaining efficient adaptation to new tasks.

Result: Empirical results on standard continual learning benchmarks show PLAN consistently outperforms existing methods and achieves new state-of-the-art performance for continual learning with foundation models.

Conclusion: PLAN provides an efficient, interference-aware fine-tuning framework for continual learning with large foundation models by proactive subspace allocation and low-rank adaptation, demonstrating strong empirical gains and establishing a new SOTA baseline; future work may explore scalability, stability under longer task sequences, and broader model types.

Abstract: Continual learning (CL) requires models to continuously adapt to new tasks
without forgetting past knowledge. In this work, we propose
\underline{P}roactive \underline{L}ow-rank \underline{A}llocatio\underline{N}
(PLAN), a framework that extends Low-Rank Adaptation (LoRA) to enable efficient
and interference-aware fine-tuning of large pre-trained models in CL settings.
PLAN proactively manages the allocation of task-specific subspaces by
introducing orthogonal basis vectors for each task and optimizing them through
a perturbation-based strategy that minimizes conflicts with previously learned
parameters. Furthermore, PLAN incorporates a novel selection mechanism that
identifies and assigns basis vectors with minimal sensitivity to interference,
reducing the risk of degrading past knowledge while maintaining efficient
adaptation to new tasks. Empirical results on standard CL benchmarks
demonstrate that PLAN consistently outperforms existing methods, establishing a
new state-of-the-art for continual learning with foundation models.

</details>


### [70] [Gen-Review: A Large-scale Dataset of AI-Generated (and Human-written) Peer Reviews](https://arxiv.org/abs/2510.21192)
*Luca Demetrio,Giovanni Apruzzese,Kathrin Grosse,Pavel Laskov,Emil Lupu,Vera Rimmer,Philine Widmer*

Main category: cs.LG

TL;DR: GenReview数据集：81K份LLM撰写评审，三提示（负/正/中性），连结论文与原评审，用于研究LLM在同行评审中的偏见、可检测性、指引遵循性及与接受决定的关系。


<details>
  <summary>Details</summary>
Motivation: 揭示LLMs在科学同行评审中的潜在效用与风险，填补缺乏大规模可研究数据集的空缺，同时讨论在现实评审中的潜在应用与伦理影响。

Method: 为2018–2025年ICLR的所有投稿，提供在三种独立提示下生成的LLM评审，且将这些评审与原论文及原评审绑定，形成81K样本，便于进一步分析；并给出初步研究问题的示例分析（偏见、可检测性、指引遵循、评分与接收关系）。

Result: 初步发现：LLM评审存在偏见，能被自动检测，未必总能严格遵循评审指引，且对已接收论文的评分与接受决定的对应关系更强。

Conclusion: GenReview填补数据空缺，提供一个可扩展的平台来研究LLMs在学术评审中的作用与风险，有助于未来编辑决策和政策制定，数据集可公开访问以促进广泛研究。

Abstract: How does the progressive embracement of Large Language Models (LLMs) affect
scientific peer reviewing? This multifaceted question is fundamental to the
effectiveness -- as well as to the integrity -- of the scientific process.
Recent evidence suggests that LLMs may have already been tacitly used in peer
reviewing, e.g., at the 2024 International Conference of Learning
Representations (ICLR). Furthermore, some efforts have been undertaken in an
attempt to explicitly integrate LLMs in peer reviewing by various editorial
boards (including that of ICLR'25). To fully understand the utility and the
implications of LLMs' deployment for scientific reviewing, a comprehensive
relevant dataset is strongly desirable. Despite some previous research on this
topic, such dataset has been lacking so far. We fill in this gap by presenting
GenReview, the hitherto largest dataset containing LLM-written reviews. Our
dataset includes 81K reviews generated for all submissions to the 2018--2025
editions of the ICLR by providing the LLM with three independent prompts: a
negative, a positive, and a neutral one. GenReview is also linked to the
respective papers and their original reviews, thereby enabling a broad range of
investigations. To illustrate the value of GenReview, we explore a sample of
intriguing research questions, namely: if LLMs exhibit bias in reviewing (they
do); if LLM-written reviews can be automatically detected (so far, they can);
if LLMs can rigorously follow reviewing instructions (not always) and whether
LLM-provided ratings align with decisions on paper acceptance or rejection
(holds true only for accepted papers). GenReview can be accessed at the
following link: https://anonymous.4open.science/r/gen_review.

</details>


### [71] [Mitra: Mixed Synthetic Priors for Enhancing Tabular Foundation Models](https://arxiv.org/abs/2510.21204)
*Xiyuan Zhang,Danielle C. Maddix,Junming Yin,Nick Erickson,Abdul Fatir Ansari,Boran Han,Shuai Zhang,Leman Akoglu,Christos Faloutsos,Michael W. Mahoney,Cuixiong Hu,Huzefa Rangwala,George Karypis,Bernie Wang*

Main category: cs.LG

TL;DR: 提出 Mitra，一种以多样化合成先验为基础的表格 foundation 模型（TFM），在分类与回归任务上显著优于 TabPFNv2/TabICL，且具有更高样本效率。


<details>
  <summary>Details</summary>
Motivation: 揭示合成先验在TFMs泛化中的作用机制，回应目前关于先验设计原则尚不清晰的问题。

Method: 系统分析合成先验的关键属性，基于多样性、辨识度和在真实数据上的表现，设计并训练一个基于混合合成先验的TFM Mitra。

Result: Mitra在公开基准上持续优于现有TFMs，显示出更强的泛化与样本效率。

Conclusion: 表明先验设计是推动TFMs泛化的关键因素；通过挑选具有多样性、辨识度且在真实数据上表现良好的合成先验，可以提升表格学习的性能与数据效率。

Abstract: Since the seminal work of TabPFN, research on tabular foundation models
(TFMs) based on in-context learning (ICL) has challenged long-standing
paradigms in machine learning. Without seeing any real-world data, models
pretrained on purely synthetic datasets generalize remarkably well across
diverse datasets, often using only a moderate number of in-context examples.
This shifts the focus in tabular machine learning from model architecture
design to the design of synthetic datasets, or, more precisely, to the prior
distributions that generate them. Yet the guiding principles for prior design
remain poorly understood. This work marks the first attempt to address the gap.
We systematically investigate and identify key properties of synthetic priors
that allow pretrained TFMs to generalize well. Based on these insights, we
introduce Mitra, a TFM trained on a curated mixture of synthetic priors
selected for their diversity, distinctiveness, and performance on real-world
tabular data. Mitra consistently outperforms state-of-the-art TFMs, such as
TabPFNv2 and TabICL, across both classification and regression benchmarks, with
better sample efficiency.

</details>


### [72] [Adaptive Graph Mixture of Residual Experts: Unsupervised Learning on Diverse Graphs with Heterogeneous Specialization](https://arxiv.org/abs/2510.21207)
*Yunlong Chu,Minglai Shao,Zengyi Wo,Bing Hao,Yuhang Liu,Ruijie Wang,Jianxin Li*

Main category: cs.LG

TL;DR: ADaMoRE: Adaptive Mixture of Residual Experts for unsupervised heterogeneous MoE on graphs; stable end-to-end training with backbone-residual architecture, structurally-aware gating, and diversity regularizer; achieves state-of-the-art on unsupervised node classification and few-shot learning across 16 benchmarks.


<details>
  <summary>Details</summary>
Motivation: GNNs' fixed message-passing architectures struggle to adapt to the diverse and task-specific patterns of real-world graphs. There is a need for robust, unsupervised training of heterogeneous mixture-of-experts (MoE) on graphs to enable adaptive computation without supervised signals.

Method: Propose a backbone-residual expert architecture where base encoders provide stability and specialized residual experts capture diverse computational patterns. Use a structurally-aware gating network for fine-grained node routing. Train end-to-end with a unified unsupervised objective that combines a primary reconstruction task with an information-theoretic diversity regularizer to enforce functional specialization among experts.

Result: The framework achieves state-of-the-art performance in unsupervised node classification and few-shot learning, with better generalization, training efficiency, and faster convergence across diverse graphs and tasks, validated on 16 benchmarks.

Conclusion: ADaMoRE enables robust, unsupervised training of heterogeneous MoEs on graphs, improving data efficiency, stability, and generalization across graph learning tasks.

Abstract: Graph Neural Networks (GNNs) face a fundamental adaptability challenge: their
fixed message-passing architectures struggle with the immense diversity of
real-world graphs, where optimal computational strategies vary by local
structure and task. While Mixture-of-Experts (MoE) offers a promising pathway
to adaptability, existing graph MoE methods remain constrained by their
reliance on supervised signals and instability when training heterogeneous
experts. We introduce ADaMoRE (Adaptive Mixture of Residual Experts), a
principled framework that enables robust, fully unsupervised training of
heterogeneous MoE on graphs. ADaMoRE employs a backbone-residual expert
architecture where foundational encoders provide stability while specialized
residual experts capture diverse computational patterns. A structurally-aware
gating network performs fine-grained node routing. The entire architecture is
trained end-to-end using a unified unsupervised objective, which integrates a
primary reconstruction task with an information-theoretic diversity regularizer
to explicitly enforce functional specialization among the experts. Theoretical
analysis confirms our design improves data efficiency and training stability.
Extensive evaluation across 16 benchmarks validates ADaMoRE's state-of-the-art
performance in unsupervised node classification and few-shot learning,
alongside superior generalization, training efficiency, and faster convergence
on diverse graphs and tasks.

</details>


### [73] [Model Merging with Functional Dual Anchors](https://arxiv.org/abs/2510.21223)
*Kexuan Shi,Yandong Wen,Weiyang Liu*

Main category: cs.LG

TL;DR: 提出了 Functional Dual Anchors (FDAs)，在输入表示空间进行模型合并，通过合成输入使其梯度对齐任务向量，捕捉相对于预训练模型的功能性偏移，并可与参数空间的合并互补。


<details>
  <summary>Details</summary>
Motivation: 解决参数空间合并中存在的冲突与参数不一致问题；提供一个鲁棒、灵活的框架，将联合训练和事后合并的思想连接起来。

Method: 将 FDAs 定义为合成输入，其诱发的梯度与任务向量对齐，以捕捉任务相对于预训练模型的功能性变化；提出系统化初始化方案；并证明 FDAs 与参数空间模型合并具有互补性；通过实验评估其有效性。

Result: 实验证据表明 FDAs 在模型合并任务中提升鲁棒性与灵活性，能够与现有的参数空间合并方法协同工作，显著改善合并效果。

Conclusion: FDAs 为多任务模型合并提供一种新的功能性视角，可能降低参数冲突、连接联合训练与后期合并的研究线，并具有广泛应用前景。

Abstract: Model merging is an efficient post-training strategy for integrating
knowledge from multiple finetuned checkpoints of a shared foundation model.
Existing methods operate in the parameter space, combining task vectors to
mitigate conflicts, but remain constrained by parameter inconsistencies. We
propose Functional Dual Anchors (FDAs), a framework that instead models the
input-representation space. FDAs are synthetic inputs whose induced gradients
align with task vectors, capturing task-specific functional shifts relative to
the pretrained model. This perspective bridges joint multi-task training and
post-hoc merging, offering both robustness and flexibility. We further
introduce a principled initialization scheme and show that FDAs are
complementary to parameter-space model merging. Comprehensive experiments
demonstrate the effectiveness of FDAs in model merging.

</details>


### [74] [Convergence of Stochastic Gradient Langevin Dynamics in the Lazy Training Regime](https://arxiv.org/abs/2510.21245)
*Noah Oberweis,Semih Cayci*

Main category: cs.LG

TL;DR: SGLD在懒散训练下的非渐近收敛分析：在乘性、状态相关噪声下，SGLD可保持非退化内核并实现期望意义下的指数收敛，同时给出有限时间与有限宽度的最优性间隙界，理论与回归实验相吻合。


<details>
  <summary>Details</summary>
Motivation: 通过连续时间的SDE近似，揭示深度学习优化算法的训练动力学，并给出SGLD在懒散训练中的非渐近收敛界，弥补对此场景的理论理解。

Method: 以Itô SDE形式的SGLD作为随机梯度下降的连续时间近似，假设损失 Hessian 满足正则性条件，证明在训练过程中噪声为乘性、状态相关时能够保持非退化的核，并推导出对期望的指数收敛以及有限时间/宽度的误差界，辅以回归问题的数值验证。

Result: 在高概率意义下保持非退化核；实现对经验风险最小化器的指数收敛；给出最优性间隙的有限时间和有限宽度界；数值实验支持理论。

Conclusion: 为SGLD在 lazy 训练中的非渐近收敛提供理论保障，揭示状态相关噪声对训练稳定性及收敛速度的作用，并通过回归实验验证，促进对深度学习优化动力学的理解。

Abstract: Continuous-time models provide important insights into the training dynamics
of optimization algorithms in deep learning. In this work, we establish a
non-asymptotic convergence analysis of stochastic gradient Langevin dynamics
(SGLD), which is an It\^o stochastic differential equation (SDE) approximation
of stochastic gradient descent in continuous time, in the lazy training regime.
We show that, under regularity conditions on the Hessian of the loss function,
SGLD with multiplicative and state-dependent noise (i) yields a non-degenerate
kernel throughout the training process with high probability, and (ii) achieves
exponential convergence to the empirical risk minimizer in expectation, and we
establish finite-time and finite-width bounds on the optimality gap. We
corroborate our theoretical findings with numerical examples in the regression
setting.

</details>


### [75] [Unified Implementations of Recurrent Neural Networks in Multiple Deep Learning Frameworks](https://arxiv.org/abs/2510.21252)
*Francesco Martinuzzi*

Main category: cs.LG

TL;DR: 提出了三个用于RNN研究的开源库（torchrecurrent、RecurrentLayers.jl、LuxRecurrentLayers.jl），在 Julia/Python 上提供统一的框架来集中管理多种循环单元和高阶RNN结构，提升可复现性与实验效率。


<details>
  <summary>Details</summary>
Motivation: RNNs在序列建模中的关键地位及其变体增多，现有工具缺乏统一、可扩展的基线实现，重复实现成本高且影响可重复性。

Method: 开发并开源三个库，跨语言/跨平台，提供一致的接口、可自定义的循环单元和高层结构，MIT 许可证，GitHub 上维护活跃。

Result: 实现多种循环单元和高级RNN架构的集中管理；提供统一的建模框架和自定义机制，促进实验的快速迭代与可重复性；库在 GitHub 上持续维护，MIT 许可。

Conclusion: 为RNN研究提供集中化的资源，降低实现门槛，提升可重复性和探索性。

Abstract: Recurrent neural networks (RNNs) are a cornerstone of sequence modeling
across various scientific and industrial applications. Owing to their
versatility, numerous RNN variants have been proposed over the past decade,
aiming to improve the modeling of long-term dependencies and to address
challenges such as vanishing and exploding gradients. However, no central
library is available to test these variations, and reimplementing diverse
architectures can be time-consuming and error-prone, limiting reproducibility
and exploration. Here, we introduce three open-source libraries in Julia and
Python that centralize numerous recurrent cell implementations and higher-level
recurrent architectures. torchrecurrent, RecurrentLayers.jl, and
LuxRecurrentLayers.jl offer a consistent framework for constructing and
extending RNN models, providing built-in mechanisms for customization and
experimentation. All packages are available under the MIT license and actively
maintained on GitHub.

</details>


### [76] [PINN Balls: Scaling Second-Order Methods for PINNs with Domain Decomposition and Adaptive Sampling](https://arxiv.org/abs/2510.21262)
*Andrea Bonfanti,Ismael Medina,Roman List,Björn Staeves,Roberto Santana,Marco Ellero*

Main category: cs.LG

TL;DR: 提出PINN Balls：一个局部Mixture of Experts框架，用于可扩展的二阶PINN训练，结合自学习的域划分和对抗自适应采样，提升PDE求解的精度。


<details>
  <summary>Details</summary>
Motivation: 二阶优化有利于PINN，但内存需求高，限制模型规模，因此需要参数高效且可扩展的替代方案。

Method: 基于局部MoE与稀疏编码实现参数效率；推出PINN Balls框架，具备可学习的领域划分；通过Adversarial Adaptive Sampling实现DD对PDE域的自适应。

Result: 在科学机器学习领域达到比现有方法更高的精度，同时保持良好可扩展性，并具备理论支撑。

Conclusion: PINN Balls提供一种可扩展且精度更高的二阶训练方案，适用于PDE求解。

Abstract: Recent advances in Scientific Machine Learning have shown that second-order
methods can enhance the training of Physics-Informed Neural Networks (PINNs),
making them a suitable alternative to traditional numerical methods for Partial
Differential Equations (PDEs). However, second-order methods induce large
memory requirements, making them scale poorly with the model size. In this
paper, we define a local Mixture of Experts (MoE) combining the
parameter-efficiency of ensemble models and sparse coding to enable the use of
second-order training. Our model -- \textsc{PINN Balls} -- also features a
fully learnable domain decomposition structure, achieved through the use of
Adversarial Adaptive Sampling (AAS), which adapts the DD to the PDE and its
domain. \textsc{PINN Balls} achieves better accuracy than the state-of-the-art
in scientific machine learning, while maintaining invaluable scalability
properties and drawing from a sound theoretical background.

</details>


### [77] [An Evidence-Based Post-Hoc Adjustment Framework for Anomaly Detection Under Data Contamination](https://arxiv.org/abs/2510.21296)
*Sukanya Patra,Souhaib Ben Taieb*

Main category: cs.LG

TL;DR: EPHAD 是一个面向无监督异常检测的测试时自适应框架，在训练数据污染的情况下通过在测试时融合来自被污染数据训练的模型输出与来自多模态基础模型（如 CLIP）及经典方法（如 Latent Outlier Factor）的证据来更新异常分数，从而提升鲁棒性。该方法在八个视觉数据集、二十六个表格数据集以及一个真实工业数据集上取得了有效性，且对超参数和污染水平具有鲁棒性，并开源实现。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据集常含有未发现的异常或标注错误的样本，训练阶段假设干净数据的前提往往不成立。现有方法往往需要访问训练流程、数据或先验的异常比例信息，限制了实际应用。需一种不依赖额外标签、可在测试时对模型进行自适应、对污染具有鲁棒性的解决方案。

Method: EPHAD 在测试时对已在污染数据上训练的异常检测模型的输出进行更新，通过整合来自污染数据训练所捕获的先验知识与测试时可获得的证据（如来自 CLIP 的多模态证据、传统方法如 Latent Outlier Factor 的证据、以及领域知识等），实现证据融合以修正异常分数。其思路通过一个合成 toy 示例直观展示，并通过在八个视觉AD数据集、二十六个表格AD数据集及一个真实工业数据集上的系统实验进行验证，辅以超参数影响及对污染水平变化的鲁棒性消融分析。实现公开在 GitHub：https://github.com/sukanyapatra1997/EPHAD。

Result: 在多源证据融合的测试时自适应框架下，EPHAD 在多种数据域和污染水平下提升了无监督异常检测的鲁棒性与准确性；对不同的 AD 模型和证据对也具有普适性，且实验与消融分析显示超参数与污染比例对性能的影响可控。代码公开，便于复现与应用。

Conclusion: 将测试时的证据融合引入无监督AD，成为缓解训练数据污染影响的一种务实策略，EPHAD 展示了良好的跨数据域鲁棒性与可扩展性，为后续将多模态证据引入无监督任务的研究提供了可行路径。

Abstract: Unsupervised anomaly detection (AD) methods typically assume clean training
data, yet real-world datasets often contain undetected or mislabeled anomalies,
leading to significant performance degradation. Existing solutions require
access to the training pipelines, data or prior knowledge of the proportions of
anomalies in the data, limiting their real-world applicability. To address this
challenge, we propose EPHAD, a simple yet effective test-time adaptation
framework that updates the outputs of AD models trained on contaminated
datasets using evidence gathered at test time. Our approach integrates the
prior knowledge captured by the AD model trained on contaminated datasets with
evidence derived from multimodal foundation models like Contrastive
Language-Image Pre-training (CLIP), classical AD methods like the Latent
Outlier Factor or domain-specific knowledge. We illustrate the intuition behind
EPHAD using a synthetic toy example and validate its effectiveness through
comprehensive experiments across eight visual AD datasets, twenty-six tabular
AD datasets, and a real-world industrial AD dataset. Additionally, we conduct
an ablation study to analyse hyperparameter influence and robustness to varying
contamination levels, demonstrating the versatility and robustness of EPHAD
across diverse AD models and evidence pairs. To ensure reproducibility, our
code is publicly available at https://github.com/sukanyapatra1997/EPHAD.

</details>


### [78] [Data as a Lever: A Neighbouring Datasets Perspective on Predictive Multiplicity](https://arxiv.org/abs/2510.21303)
*Prakhar Ganesh,Hsiang Hsu,Golnoosh Farnadi*

Main category: cs.LG

TL;DR: 提出了邻近数据集框架以研究单点数据对模型多样性（multiplicity）的影响，发现更大类别分布重叠的邻近数据集反而带来更低的多样性，这由共同的 Rashomon 参数解释。并将该框架扩展到主动学习与数据插补，提出多样性感知的数据获取与插补策略。


<details>
  <summary>Details</summary>
Motivation: 尽管已有工作强调模型选择的重要性，但数据本身如何塑造模型之间的可比性与多样性被较少关注。本工作从数据角度出发，提出“邻近数据集”以研究单数据点微小差异对 multiplicity 的影响，揭示了数据分布与模型多样性之间的深层联系。

Method: 1) 定义邻近数据集的概念并建立理论框架；2) 以类别分布重叠度为研究变量，推导并给出与 Rashomon 参数相关的关系式，给出严格证明；3) 将框架扩展至主动学习与数据插补的自然扩展；4) 对现有算法进行系统性研究并提出新的 multiplicity-aware 策略。

Result: 理论层面揭示：在邻近数据集中，较高的类别分布重叠导致较低的模型多样性，这一现象由共享的 Rashomon 参数驱动并得到严格证明。方法层面建立了可用于主动学习与数据插补的扩展框架，并给出对现有算法的系统性分析与初步实验/分析，以及可操作的多样性感知策略。

Conclusion: 数据的分布特征对模型多样性具有决定性作用，数据设计与获取策略可以用来管理或提升多样性。该工作为数据驱动的多样性研究提供了新的理论工具和应用方向，未来可在更广的任务及数据隐私等场景中验证与扩展。

Abstract: Multiplicity -- the existence of distinct models with comparable performance
-- has received growing attention in recent years. While prior work has largely
emphasized modelling choices, the critical role of data in shaping multiplicity
has been comparatively overlooked. In this work, we introduce a neighbouring
datasets framework to examine the most granular case: the impact of a
single-data-point difference on multiplicity. Our analysis yields a seemingly
counterintuitive finding: neighbouring datasets with greater inter-class
distribution overlap exhibit lower multiplicity. This reversal of conventional
expectations arises from a shared Rashomon parameter, and we substantiate it
with rigorous proofs.
  Building on this foundation, we extend our framework to two practical
domains: active learning and data imputation. For each, we establish natural
extensions of the neighbouring datasets perspective, conduct the first
systematic study of multiplicity in existing algorithms, and finally, propose
novel multiplicity-aware methods, namely, multiplicity-aware data acquisition
strategies for active learning and multiplicity-aware data imputation
techniques.

</details>


### [79] [Revisiting Social Welfare in Bandits: UCB is (Nearly) All You Need](https://arxiv.org/abs/2510.21312)
*Dhruv Sarkar,Nishant Pandey,Sayak Ray Chowdhury*

Main category: cs.LG

TL;DR: 提出一种简单的UCB变体：先进行均匀探索再接入标准UCB，在添加Hoeffding界的基础上实现接近最优的Nash遗憾，并扩展到p-mean遗憾等公平度量，适用于子高斯奖励，打破对乘法型收敛界限的依赖。


<details>
  <summary>Details</summary>
Motivation: 在多臂赌博机中，传统遗憾关注总体收益最大化，忽略不同参与者的公平性。Nash遗憾以Nash社会福利函数为准则，通过对奖励的几何平均进行优化，提供对个体间公平的度量；但现有方法要求苛刻假设，难以扩展。

Method: 初始均匀探索阶段|随后采用标准的上置信界UCB算法；仅依赖加性Hoeffding界限，能推广到子高斯奖励；并推广到一个更广泛的公平性指标族p-mean遗憾，给出几乎最优的遗憾界。

Result: 实现了接近最优的Nash遗憾界，同时对p-mean遗憶给出在所有p值下近似最优的界，且在Gaussian等分布或更广的子高斯分布下也成立，显著放宽了对奖励分布和边界的假设。

Conclusion: 提出了一个普适框架，用于Nash遗憾与p-mean遗憾的近似最优分析，挑战了以往在强假设下才获得良好界的研究，具有更广泛的适用性和实践性。

Abstract: Regret in stochastic multi-armed bandits traditionally measures the
difference between the highest reward and either the arithmetic mean of
accumulated rewards or the final reward. These conventional metrics often fail
to address fairness among agents receiving rewards, particularly in settings
where rewards are distributed across a population, such as patients in clinical
trials. To address this, a recent body of work has introduced Nash regret,
which evaluates performance via the geometric mean of accumulated rewards,
aligning with the Nash social welfare function known for satisfying fairness
axioms.
  To minimize Nash regret, existing approaches require specialized algorithm
designs and strong assumptions, such as multiplicative concentration
inequalities and bounded, non-negative rewards, making them unsuitable for even
Gaussian reward distributions. We demonstrate that an initial uniform
exploration phase followed by a standard Upper Confidence Bound (UCB) algorithm
achieves near-optimal Nash regret, while relying only on additive Hoeffding
bounds, and naturally extending to sub-Gaussian rewards. Furthermore, we
generalize the algorithm to a broad class of fairness metrics called the
$p$-mean regret, proving (nearly) optimal regret bounds uniformly across all
$p$ values. This is in contrast to prior work, which made extremely restrictive
assumptions on the bandit instances and even then achieved suboptimal regret
bounds.

</details>


### [80] [A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization](https://arxiv.org/abs/2510.21314)
*Xuan Tang,Jichu Li,Difan Zou*

Main category: cs.LG

TL;DR: 提出了首个在浮点量化（梯度、权重、以及优化器状态如动量估计）条件下分析自适应优化器（如 Adam 和 Muon）收敛性的理论框架；给出对光滑非凸目标的收敛率，并明确量化误差如何影响收敛性；结果显示若尾数长度随迭代次数仅对数线性增加，则收敛率接近全精度；Adam 对权重和二阶矩量化敏感，Muon 相对鲁棒；并通过合成与真实数据的数值实验验证。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速扩展，低精度训练成为降低显存、提升效率的关键，但现有自适应优化器的收敛性理论通常假设计算结果全精确，忽略硬件量化带来的影响，亟需建立量化条件下的收敛分析，以解释低精度训练的有效性并给出鲁棒性差异。

Method: 建立一个分析自适应优化器（包括 Adam 与 Muon）在梯度、权重和优化器状态量化下的收敛框架；在光滑非凸目标的标准随机梯度假设下，推导收敛率，并明确标量化误差来自不同组件对收敛性的影响；给出 mantissa 长度与迭代次数的对数关系要求，使得收敛率接近全精度。

Result: 在保持对数关系的前提下，算法的收敛速率可接近全精度；Adam 对权重和第二矩量化高度敏感，原因在于其对 β2 接近 1 的依赖；Muon 对误差控制的要求较弱，因而可能更鲁棒。数值实验（合成数据与真实数据）验证理论结果。

Conclusion: 该工作缩小了低精度训练经验成功与理论理解之间的差距，为硬件感知的自适应优化器收敛性提供了理论支撑，并通过实验验证了关键结论。

Abstract: The rapid scaling of large language models (LLMs) has made low-precision
training essential for reducing memory, improving efficiency, and enabling
larger models and datasets. Existing convergence theories for adaptive
optimizers, however, assume all components are exact and neglect hardware-aware
quantization, leaving open the question of why low-precision training remains
effective. We introduce the first theoretical framework for analyzing the
convergence of adaptive optimizers, including Adam and Muon, under
floating-point quantization of gradients, weights, and optimizer states (e.g.,
moment estimates). Within this framework, we derive convergence rates on smooth
non-convex objectives under standard stochastic gradient assumptions,
explicitly characterizing how quantization errors from different components
affect convergence. We show that both algorithms retain rates close to their
full-precision counterparts provided mantissa length scales only
logarithmically with the number of iterations. Our analysis further reveals
that Adam is highly sensitive to weights and second-moment quantization due to
its reliance on $\beta_2 \to 1$, while Muon requires weaker error control and
is thus potentially more robust. These results narrow the gap between empirical
success and theoretical understanding of low-precision training methods.
Numerical experiments on synthetic and real-world data corroborate our theory.

</details>


### [81] [Leverage Unlearning to Sanitize LLMs](https://arxiv.org/abs/2510.21322)
*Antoine Boutet,Lucas Magnana*

Main category: cs.LG

TL;DR: 提出了一种名为 SANI 的语言模型“去记忆”方法，通过对模型最后几层的特定神经元进行擦除，再进行受控的再训练来去除对敏感信息的 memorization。仅需少量额外训练就能显著降低回忆式输出，便于在医疗等行业的模型分享前进行隐私保护。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型在对特定数据微调后可能 memorization 敏感信息（如个人信息、机密数据），存在隐私泄露风险。需要在不进行昂贵的安全数据再训练的情况下对模型进行去记忆化与隐私保护。

Method: 提出两阶段去记忆框架：1) 擦除阶段，重置模型最后几层的某些神经元以打断对细粒度信息的 memorization；2) 修复/再训练阶段，在避免再次 memorizing 的约束下对模型进行有限轮次的再训练。对经过医疗数据微调的模型以及标准预训练模型均进行评估，清除直接/间接标识符和定义为机密的信息项。

Result: 经过少量额外的训练轮次，模型实现去记忆化，回忆/ regurgitation 的输出显著减少。对病历数据等领域的专用模型以及标准模型均有效，能够在保持性能的同时降低敏感信息的泄露风险。

Conclusion: SANI 为已在大数据集上训练并具有专门行业数据的模型的隐私保护提供了一种可行方案，尤其适用于医院等希望在共享前对模型进行安全去记忆化的场景。

Abstract: Pre-trained large language models (LLMs) are becoming useful for various
tasks. To improve their performance on certain tasks, it is necessary to
fine-tune them on specific data corpora (e.g., medical reports, business data).
These specialized data corpora may contain sensitive data (e.g., personal or
confidential data) that will be memorized by the model and likely to be
regurgitated during its subsequent use. This memorization of sensitive
information by the model poses a significant privacy or confidentiality issue.
To remove this memorization and sanitize the model without requiring costly
additional fine-tuning on a secured data corpus, we propose SANI. SANI is an
unlearning approach to sanitize language models. It relies on both an erasure
and repair phases that 1) reset certain neurons in the last layers of the model
to disrupt the memorization of fine-grained information, and then 2) fine-tune
the model while avoiding memorizing sensitive information. We comprehensively
evaluate SANI to sanitize both a model fine-tuned and specialized with medical
data by removing directly and indirectly identifiers from the memorization of
the model, and a standard pre-trained model by removing specific terms defined
as confidential information from the model. Results show that with only few
additional epochs of unlearning, the model is sanitized and the number of
regurgitations is drastically reduced. This approach can be particularly useful
for hospitals or other industries that have already spent significant resources
training models on large datasets and wish to sanitize them before sharing.

</details>


### [82] [SCORENF: Score-based Normalizing Flows for Sampling Unnormalized distributions](https://arxiv.org/abs/2510.21330)
*Vikas Kanaujia,Vipul Arora*

Main category: cs.LG

TL;DR: 提出 ScoreNF——将分数估计学习与正则化流结合，并嵌入独立 Metropolis-Hastings，用于从未经归一化的目标分布高效且无偏采样；在小型训练集合下仍保持良好性能，并提供模式覆盖与崩溃的检测方法，验证于二维混合高斯分布和高维 φ^4 格点场理论分布。


<details>
  <summary>Details</summary>
Motivation: 在多领域的物理系统中，未归一化的概率分布对建模至关重要，但传统采样方法（如 MCMC）往往收敛缓慢、模式混合差且自相关性高；与此相比，基于概率密度/对抗学习的模型需要大量数据并可能出现模式覆盖或崩溃。需要一种在未归一化目标分布上高效、无偏的采样方法，且对小数据集也具有鲁棒性。

Method: 提出 ScoreNF—a score-based learning framework built on the Normalizing Flow architecture，结合独立 Metropolis-Hastings（IMH）模块，以实现对未归一化目标分布的高效、无偏采样，且在小型训练集合下也能保持高性能。同时给出一种用于评估模式覆盖与模式崩溃行为的方法，并在合成的二维分布（MOG-4、MOG-8）以及高维 φ^4 格点场理论分布上进行验证。

Result: 证明 ScoreNF 能在小规模训练数据下仍然实现高效且无偏的采样；IMH 的引入提升对未归一化目标的采样质量，所提出的模式覆盖/崩溃评估方法能够区分并量化不同分布的模式覆盖情况；在 MOG-4、MOG-8 和 φ^4 格点场理论等测试分布上获得有效性证据，展示该框架在高维、未归一化目标上的适用性。

Conclusion: ScoreNF 为从未归一化目标分布进行高效、无偏采样提供了一种新途径，且对小数据集鲁棒，减少对昂贵的 MCMC 训练数据的依赖；该框架及其模式覆盖/崩溃评估方法在合成分布和物理系统分布上均表现出良好的采样能力，具有在高维物理建模中的潜在应用价值。

Abstract: Unnormalized probability distributions are central to modeling complex
physical systems across various scientific domains. Traditional sampling
methods, such as Markov Chain Monte Carlo (MCMC), often suffer from slow
convergence, critical slowing down, poor mode mixing, and high autocorrelation.
In contrast, likelihood-based and adversarial machine learning models, though
effective, are heavily data-driven, requiring large datasets and often
encountering mode covering and mode collapse. In this work, we propose ScoreNF,
a score-based learning framework built on the Normalizing Flow (NF)
architecture, integrated with an Independent Metropolis-Hastings (IMH) module,
enabling efficient and unbiased sampling from unnormalized target
distributions. We show that ScoreNF maintains high performance even with small
training ensembles, thereby reducing reliance on computationally expensive
MCMC-generated training data. We also present a method for assessing
mode-covering and mode-collapse behaviours. We validate our method on synthetic
2D distributions (MOG-4 and MOG-8) and the high-dimensional $\phi^4$ lattice
field theory distribution, demonstrating its effectiveness for sampling tasks.

</details>


### [83] [Weak-to-Strong Generalization under Distribution Shifts](https://arxiv.org/abs/2510.21332)
*Myeongho Jeon,Jan Sobotka,Suhwan Choi,Maria Brbić*

Main category: cs.LG

TL;DR: 提出RAVEN，一种鲁棒的弱到强泛化框架，通过动态学习弱模型的最佳组合以及强模型参数，在分布偏移下显著提升OOD性能，并能自动识别可信的弱监督。


<details>
  <summary>Details</summary>
Motivation: 随着未来超人类模型越来越复杂，单靠人类监督可能难以覆盖全部情形；弱模型对强模型的监督在某些条件下有效，但分布偏移时常失效，因此需要一个能适应性地融合多源弱监督的框架。

Method: 提出RAVEN框架，动态学习弱模型的最优组合并联合优化强模型参数。通过权重分配机制让更准确的弱模型获得更高权重，并在图像分类、文本分类和偏好对齐任务上评估。

Result: 在OOD任务中，RAVEN相较于替代基线提升超过30%；在ID任务上达到或超过现有方法的水平；并且能自动将权重偏向于更准确的弱模型。

Conclusion: RAVEN提供了一种鲁棒的弱到强泛化方案，能够在分布转移场景中保持性能并自动识别可信的弱监督来源。

Abstract: As future superhuman models become increasingly complex, accurately
supervising their behavior may exceed human capabilities. Recent works have
demonstrated that in such scenarios, weak models can effectively supervise
strong models, a phenomenon known as weak-to-strong generalization. However, we
find that naive weak-to-strong generalization fails under distribution shifts,
often leading to worse performance of the strong model than its weak
supervisors. To address this, we propose RAVEN, a robust weak-to-strong
generalization framework that dynamically learns the optimal combinations of
weak models in addition to parameters of the strong model. We demonstrate the
effectiveness of RAVEN on image classification, text classification, and
preference alignment tasks. RAVEN outperforms alternative baselines by over 30%
on out-of-distribution tasks while matching or surpassing existing methods on
in-distribution tasks. Moreover, our results show that RAVEN assigns higher
weights to more accurate weak models, demonstrating its ability to
automatically identify trustworthy supervision.

</details>


### [84] [$α$-LoRA: Effective Fine-Tuning via Base Model Rescaling](https://arxiv.org/abs/2510.21345)
*Aymane El Firdoussi,El Mahdi Chayti,Mohamed El Amine Seddik,Martin Jaggi*

Main category: cs.LG

TL;DR: 提出一种新型的基于重参数化的迁移学习方法，结合低秩适配（LoRA）思路，旨在用少量数据提升微调模型的泛化能力；通过随机矩阵理论（RMT）建立理论分析，并在高维二分类及LLM微调等场景进行实验验证。


<details>
  <summary>Details</summary>
Motivation: 在以少量数据对预训练模型进行自适应微调时，如何提高泛化能力一直是核心挑战。LoRA等重参数化方法通过在冻结权重上增添可训练分量来提升性能，但仍需更系统的泛化分析与更广泛的验证。本文提出一种新类型的重参数化方法，目标是在保持参数高效的同时增强泛化性，并通过理论与实证双轮驱动进行验证。

Method: 提出一种新类的重参数化方法，通过在冻结权重矩阵上叠加可训练的增量矩阵来实现参数更新；利用随机矩阵理论建立在高维二分类任务中的泛化分析框架，并对理论结论进行现实场景验证，包含对大模型（LLM）微调的实验。

Result: 理论上借助随机矩阵理论给出对新方法在高维设置下泛化性的定量分析，实验结果在高维二分类任务与LLM微调等场景中与理论预测一致，验证了该方法在实际迁移学习中的有效性。

Conclusion: 该新类重参数化方法在既有轻量化微调框架中显著提升泛化能力，理论与实验一致性较好，展示了将随机矩阵理论用于分析和指导高维迁移学习的潜力。

Abstract: Fine-tuning has proven to be highly effective in adapting pre-trained models
to perform better on new desired tasks with minimal data samples. Among the
most widely used approaches are reparameterization methods, which update a
target module by augmenting its frozen weight matrix with an additional
trainable weight matrix. The most prominent example is Low Rank Adaption
(LoRA), which gained significant attention in recent years. In this paper, we
introduce a new class of reparameterization methods for transfer learning,
designed to enhance the generalization ability of fine-tuned models. We
establish the effectiveness of our approach in a high-dimensional binary
classification setting using tools from Random Matrix Theory, and further
validate our theoretical findings through more realistic experiments, such as
fine-tuning LLMs.

</details>


### [85] [Compositional Monte Carlo Tree Diffusion for Extendable Planning](https://arxiv.org/abs/2510.21361)
*Jaesik Yoon,Hyeonseo Cho,Sungjin Ahn*

Main category: cs.LG

TL;DR: 提出 C-MCTD，通过跨计划组合的全局搜索提升 MCTD 的规划能力，包含 Online Composer、Distributed Composer 与 Preplan Composer 三大组件。


<details>
  <summary>Details</summary>
Motivation: 解决 MCTD 受限于局部个体轨迹搜索与训练轨迹长度的瓶颈，提升长距离、全局一致性的计划能力。

Method: Online Composer：全局搜索跨越整个计划组成；Distributed Composer：多起点并行探索以降低复杂度；Preplan Composer：通过缓存的计划图加速推理。

Result: 仅在摘要中提出框架与方法，未给出具体实验结果。强调可实现对完整计划组合的推理，改善全局上下文利用与推理速度。

Conclusion: C-MCTD 提供一个模块化框架，克服局部限制，通过计划组合实现更长序列的推理与更高效的推理过程。

Abstract: Monte Carlo Tree Diffusion (MCTD) integrates diffusion models with structured
tree search to enable effective trajectory exploration through stepwise
reasoning. However, MCTD remains fundamentally limited by training trajectory
lengths. While periodic replanning allows plan concatenation for longer plan
generation, the planning process remains locally confined, as MCTD searches
within individual trajectories without access to global context. We propose
Compositional Monte Carlo Tree Diffusion (C-MCTD), a framework that elevates
planning from individual trajectory optimization to reasoning over complete
plan compositions. C-MCTD introduces three complementary components: (1) Online
Composer, which performs globally-aware planning by searching across entire
plan compositions; (2) Distributed Composer, which reduces search complexity
through parallel exploration from multiple starting points; and (3) Preplan
Composer, which accelerates inference by leveraging cached plan graphs.

</details>


### [86] [FairImagen: Post-Processing for Bias Mitigation in Text-to-Image Models](https://arxiv.org/abs/2510.21363)
*Zihao Fu,Ryan Brown,Shun Shao,Kai Rawal,Eoin Delaney,Chris Russell*

Main category: cs.LG

TL;DR: FairImagen is a post-hoc debiasing framework for text-to-image diffusion models that debiases prompt embeddings using Fair PCA, with noise injection and cross-demographic projection to reduce gender/race biases without retraining the model; it improves fairness at a moderate cost to image quality and prompt fidelity and is model-agnostic.


<details>
  <summary>Details</summary>
Motivation: Text-to-image diffusion models reproduce and amplify social biases across demographic attributes. There is a need to mitigate bias without retraining the underlying diffusion models, enabling scalable, model-agnostic debiasing.

Method: Apply Fair PCA to CLIP-based prompt embeddings to project them into a subspace that minimizes group-specific information while preserving semantic content; introduce empirical noise injection to enhance debiasing; propose unified cross-demographic projection for simultaneous debiasing across multiple demographic attributes; operate as post-hoc on prompts without retraining the diffusion model.

Result: Extensive experiments across gender, race, and intersectional settings show that FairImagen significantly improves fairness with a moderate trade-off in image quality and prompt fidelity, outperforming existing post-hoc methods and offering a simple, scalable, model-agnostic solution.

Conclusion: FairImagen provides an effective, scalable post-hoc debiasing approach for text-to-image generation that can mitigate demographic biases without modifying the diffusion model, at the cost of some image quality and fidelity trade-offs.

Abstract: Text-to-image diffusion models, such as Stable Diffusion, have demonstrated
remarkable capabilities in generating high-quality and diverse images from
natural language prompts. However, recent studies reveal that these models
often replicate and amplify societal biases, particularly along demographic
attributes like gender and race. In this paper, we introduce FairImagen
(https://github.com/fuzihaofzh/FairImagen), a post-hoc debiasing framework that
operates on prompt embeddings to mitigate such biases without retraining or
modifying the underlying diffusion model. Our method integrates Fair Principal
Component Analysis to project CLIP-based input embeddings into a subspace that
minimizes group-specific information while preserving semantic content. We
further enhance debiasing effectiveness through empirical noise injection and
propose a unified cross-demographic projection method that enables simultaneous
debiasing across multiple demographic attributes. Extensive experiments across
gender, race, and intersectional settings demonstrate that FairImagen
significantly improves fairness with a moderate trade-off in image quality and
prompt fidelity. Our framework outperforms existing post-hoc methods and offers
a simple, scalable, and model-agnostic solution for equitable text-to-image
generation.

</details>


### [87] [Assessing the Real-World Utility of Explainable AI for Arousal Diagnostics: An Application-Grounded User Study](https://arxiv.org/abs/2510.21389)
*Stefan Kraft,Andreas Theissler,Vera Wienhausen-Wilke,Gjergji Kasneci,Hendrik Lensch*

Main category: cs.LG

TL;DR: 本研究在应用场景中比较了手工评分、黑盒AI和透明白盒AI在多阶段辅助下对睡眠相关事件评分的影响，发现把透明AI以QC的形式进行定向辅助能在事件级别提升约30%的表现，相对黑盒有优势；起始提示的辅助更快且更受欢迎，WB与QC会增加评分时间，但透明协作有助于可解释性和一致性，七位参与者愿意采用。


<details>
  <summary>Details</summary>
Motivation: AI系统在生物医学信号解读中已能与甚至超过人类专家，但要在临床实践落地，需要理解何时以及为何信任算法推荐，并将其有效整合入工作流程。

Method: 进行中的应用场景用户研究，8名专业睡眠医学从业者对睡眠脑电图等多导睡眠监测数据在三种条件下进行事件评分：人工手工、黑盒AI辅助、透明白盒AI辅助；辅助分为从起始阶段的协助和仅作为事后质量控制（QC）的复核；评估事件级和计数型临床性能、耗时以及用户体验。

Result: AI与人- AI 团队在与用于训练AI的临床标准对比时显著优于无辅助的专家，协作还能降低评估者间变异。作为定向的QC步骤，透明AI辅助在事件级表现上较BB提升约30%，且QC时机还能提高计数型结果。WB和QC会增加评分时间，而起始阶段的辅助更快、被大多数参与者偏好。参与者普遍倾向透明性，7/8愿意在小幅修改或无修改的前提下采用系统。

Conclusion: 有策略地在合适时点使用透明AI辅助，能够在保持或提升诊断准确性的同时兼顾临床工作流效率，为临床上可信赖的AI整合与用户接受度提供了可行路径。

Abstract: Artificial intelligence (AI) systems increasingly match or surpass human
experts in biomedical signal interpretation. However, their effective
integration into clinical practice requires more than high predictive accuracy.
Clinicians must discern \textit{when} and \textit{why} to trust algorithmic
recommendations. This work presents an application-grounded user study with
eight professional sleep medicine practitioners, who score nocturnal arousal
events in polysomnographic data under three conditions: (i) manual scoring,
(ii) black-box (BB) AI assistance, and (iii) transparent white-box (WB) AI
assistance. Assistance is provided either from the \textit{start} of scoring or
as a post-hoc quality-control (\textit{QC}) review. We systematically evaluate
how the type and timing of assistance influence event-level and clinically most
relevant count-based performance, time requirements, and user experience. When
evaluated against the clinical standard used to train the AI, both AI and
human-AI teams significantly outperform unaided experts, with collaboration
also reducing inter-rater variability. Notably, transparent AI assistance
applied as a targeted QC step yields median event-level performance
improvements of approximately 30\% over black-box assistance, and QC timing
further enhances count-based outcomes. While WB and QC approaches increase the
time required for scoring, start-time assistance is faster and preferred by
most participants. Participants overwhelmingly favor transparency, with seven
out of eight expressing willingness to adopt the system with minor or no
modifications. In summary, strategically timed transparent AI assistance
effectively balances accuracy and clinical efficiency, providing a promising
pathway toward trustworthy AI integration and user acceptance in clinical
workflows.

</details>


### [88] [Disentangled Representation Learning via Modular Compositional Bias](https://arxiv.org/abs/2510.21402)
*Whie Jung,Dong Hoon Lee,Seunghoon Hong*

Main category: cs.LG

TL;DR: 提出了一种组合偏置的DRL框架，通过把潜在变量按因子规则进行重新混合来实现对属性、对象及两者的解耦，不依赖专门的目标或架构的改动。引入先验损失与组合一致性损失来训练编码器，使混合后的图像保持现实性并对应该的潜在组合。


<details>
  <summary>Details</summary>
Motivation: 现有的DRL方法往往依赖于针对特定因子的目标或模型结构，导致新因子出现时需要重新设计架构或目标函数；需要一种与目标/架构解耦的模块化 inductive bias，以便在多因子共存和新的因子出现时保持灵活性。

Method: 提出组合偏置框架，通过因子特定的混合策略对潜在变量进行随机重新组合。训练目标包括：(i) 先验损失，确保任意重混后的图像仍然是现实可识别的；(ii) 组合一致性损失（来自 Wiedemer et al.），使每个复合图像与相应的复合潜在向量对齐。mixing策略的调整即可实现对属性、对象甚至两者的解耦，而无需修改目标函数或架构。

Result: 在属性、对象以及两者的联合解耦方面均达到具有竞争力的表现，并且首次实现全局样式与对象的联合解耦。提供代码实现。

Conclusion: 给出一个通用的 DRL 框架：通过可组合的偏置实现对不同因子的解耦，关键在于选择合适的混合策略即可扩展到新的因子类别，降低架构/目标的耦合成本，同时在多因子场景中保持有效性。

Abstract: Recent disentangled representation learning (DRL) methods heavily rely on
factor specific strategies-either learning objectives for attributes or model
architectures for objects-to embed inductive biases. Such divergent approaches
result in significant overhead when novel factors of variation do not align
with prior assumptions, such as statistical independence or spatial
exclusivity, or when multiple factors coexist, as practitioners must redesign
architectures or objectives. To address this, we propose a compositional bias,
a modular inductive bias decoupled from both objectives and architectures. Our
key insight is that different factors obey distinct recombination rules in the
data distribution: global attributes are mutually exclusive, e.g., a face has
one nose, while objects share a common support (any subset of objects can
co-exist). We therefore randomly remix latents according to factor-specific
rules, i.e., a mixing strategy, and force the encoder to discover whichever
factor structure the mixing strategy reflects through two complementary
objectives: (i) a prior loss that ensures every remix decodes into a realistic
image, and (ii) the compositional consistency loss introduced by Wiedemer et
al. (arXiv:2310.05327), which aligns each composite image with its
corresponding composite latent. Under this general framework, simply adjusting
the mixing strategy enables disentanglement of attributes, objects, and even
both, without modifying the objectives or architectures. Extensive experiments
demonstrate that our method shows competitive performance in both attribute and
object disentanglement, and uniquely achieves joint disentanglement of global
style and objects. Code is available at
https://github.com/whieya/Compositional-DRL.

</details>


### [89] [Large Language Models as Model Organisms for Human Associative Learning](https://arxiv.org/abs/2510.21408)
*Camila Kolling,Vy Ai Vo,Mariya Toneva*

Main category: cs.LG

TL;DR: 通过六种大型语言模型，用类认知神经科学的联想学习范式研究表征演变，发现非单调可塑性下的中等相似项目在学习后区分开来；词汇干扰（词汇覆盖度）越高，区分越显著，提示表征变化受项目相似性与全局竞争共同影响；LLMs因此可作为研究人类记忆重组的可访问计算模型。


<details>
  <summary>Details</summary>
Motivation: 研究联想学习中表征改变的机制，挑战在于直接观察生物系统中的表征重组较难。利用LLMs的在上下文学习能力，迁移认知神经科学范式，比较六种模型的表征动态，探索记忆重组的普适性与边界条件。

Method: 将认知神经科学中的联想学习范式迁移到六种LLMs，观察学习前后的表征演变；分析项间的相似性对区分的影响，尤其关注中等相似性情形是否更易出现区分；通过操纵相关项在更大 vocab 中的重叠度来实现词汇干扰，评估干扰对表征改变的调控作用。

Result: 观察到与非单调可塑性假说一致的非单调模式：中等相似性项在学习后出现表征区分；增加词汇干扰（更高的词汇覆盖度/竞争）放大了这种区分，表征变化由项间相似性与全局词汇竞争共同驱动。

Conclusion: 证实LLMs可作为研究人类学习系统表征动力学的可控模型，并为脑内记忆重组原理的理论假设提供新的生成与验证平台。

Abstract: Associative learning--forming links between co-occurring items--is
fundamental to human cognition, reshaping internal representations in complex
ways. Testing hypotheses on how representational changes occur in biological
systems is challenging, but large language models (LLMs) offer a scalable
alternative. Building on LLMs' in-context learning, we adapt a cognitive
neuroscience associative learning paradigm and investigate how representations
evolve across six models. Our initial findings reveal a non-monotonic pattern
consistent with the Non-Monotonic Plasticity Hypothesis, with moderately
similar items differentiating after learning. Leveraging the controllability of
LLMs, we further show that this differentiation is modulated by the overlap of
associated items with the broader vocabulary--a factor we term vocabulary
interference, capturing how new associations compete with prior knowledge. We
find that higher vocabulary interference amplifies differentiation, suggesting
that representational change is influenced by both item similarity and global
competition. Our findings position LLMs not only as powerful tools for studying
representational dynamics in human-like learning systems, but also as
accessible and general computational models for generating new hypotheses about
the principles underlying memory reorganization in the brain.

</details>


### [90] [Self-diffusion for Solving Inverse Problems](https://arxiv.org/abs/2510.21417)
*Guanxiong Luo,Shoujin Huang,Yanlong Yang*

Main category: cs.LG

TL;DR: Self-diffusion is a self-contained diffusion-like method for inverse problems that does not use pretrained generative models. It iteratively noises and denoises using a randomly initialized self-denoiser trained via data fidelity loss, achieving competitive results on linear inverse problems.


<details>
  <summary>Details</summary>
Motivation: Eliminate reliance on large pretrained score models and external denoisers for inverse problems; enable flexible, model-free adaptivity to arbitrary forward operators and noisy observations.

Method: An iterative process that alternates adding noise to the current estimate and training a single untrained convolutional network (self-denoiser) from scratch to predict the clean solution from the noisy estimate using a data-fidelity loss. The method leverages the spectral bias of neural networks and a scheduled noise process to guide refinement, without pretrained score functions.

Result: Demonstrates competitive or superior performance to existing methods across a variety of linear inverse problems.

Conclusion: Self-diffusion provides a flexible, self-contained alternative to pretrained diffusion approaches, capable of adapting to different forward models without external denoisers or score functions.

Abstract: We propose self-diffusion, a novel framework for solving inverse problems
without relying on pretrained generative models. Traditional diffusion-based
approaches require training a model on a clean dataset to learn to reverse the
forward noising process. This model is then used to sample clean solutions --
corresponding to posterior sampling from a Bayesian perspective -- that are
consistent with the observed data under a specific task. In contrast,
self-diffusion introduces a self-contained iterative process that alternates
between noising and denoising steps to progressively refine its estimate of the
solution. At each step of self-diffusion, noise is added to the current
estimate, and a self-denoiser, which is a single untrained convolutional
network randomly initialized from scratch, is continuously trained for certain
iterations via a data fidelity loss to predict the solution from the noisy
estimate. Essentially, self-diffusion exploits the spectral bias of neural
networks and modulates it through a scheduled noise process. Without relying on
pretrained score functions or external denoisers, this approach still remains
adaptive to arbitrary forward operators and noisy observations, making it
highly flexible and broadly applicable. We demonstrate the effectiveness of our
approach on a variety of linear inverse problems, showing that self-diffusion
achieves competitive or superior performance compared to other methods.

</details>


### [91] [DreamerV3-XP: Optimizing exploration through uncertainty estimation](https://arxiv.org/abs/2510.21418)
*Lukas Bierling,Davide Pasero,Jan-Henrik Bertrand,Kiki Van Gerwen*

Main category: cs.LG

TL;DR: DreamerV3-XP 在 DreamerV3 基础上通过优先回放和基于世界模型集合预测不一致的内在奖励提升探索和学习效率，在 Atari100k 子集与 DeepMind Control 可视化基准上验证原始 DreamerV3 的结果并显示在稀疏奖励设置下学习更快、动态模型损失更低。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中低样本效率与探索困难的问题，尤其是稀疏奖励环境。通过引入（1）基于返回值、重建损失和价值误差的优先回放缓冲区，以及（2）来自世界模型集合对奖励预测不一致的内在奖励，提升数据利用率与探索驱动。

Method: 1) 引入一个优先级回放缓存，对轨迹按包含的返回、重建损失和价值误差进行评分；2) 通过一个世界模型集合对预测奖励的不一致性产生内在奖励，用以驱动探索；3) 将上述机制并入 DreamerV3 的训练循环；4) 在 Atari100k 的子集和 DeepMind Control 可视基准上评估学习速度、动态模型损失等指标。

Result: 在保留原始 DreamerV3 结果的同时，DreamerV3-XP 显示出更快的学习进展和更低的动态模型损失，尤其在稀疏奖励情境下效果更显著。

Conclusion: 通过将优先回放与基于集合不一致性的内在奖励相结合，DreamerV3-XP 提高了模型基 RL 的数据效率与探索能力，特别是在挑战性任务中实现更快的学习与更稳定的动态模型。

Abstract: We introduce DreamerV3-XP, an extension of DreamerV3 that improves
exploration and learning efficiency. This includes (i) a prioritized replay
buffer, scoring trajectories by return, reconstruction loss, and value error
and (ii) an intrinsic reward based on disagreement over predicted environment
rewards from an ensemble of world models. DreamerV3-XP is evaluated on a subset
of Atari100k and DeepMind Control Visual Benchmark tasks, confirming the
original DreamerV3 results and showing that our extensions lead to faster
learning and lower dynamics model loss, particularly in sparse-reward settings.

</details>


### [92] [Causality Meets Locality: Provably Generalizable and Scalable Policy Learning for Networked Systems](https://arxiv.org/abs/2510.21427)
*Hao Liang,Shuqing Shi,Yudi Zhang,Biwei Huang,Yali Du*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large-scale networked systems, such as traffic, power, and wireless grids,
challenge reinforcement-learning agents with both scale and environment shifts.
To address these challenges, we propose GSAC (Generalizable and Scalable
Actor-Critic), a framework that couples causal representation learning with
meta actor-critic learning to achieve both scalability and domain
generalization. Each agent first learns a sparse local causal mask that
provably identifies the minimal neighborhood variables influencing its
dynamics, yielding exponentially tight approximately compact representations
(ACRs) of state and domain factors. These ACRs bound the error of truncating
value functions to $\kappa$-hop neighborhoods, enabling efficient learning on
graphs. A meta actor-critic then trains a shared policy across multiple source
domains while conditioning on the compact domain factors; at test time, a few
trajectories suffice to estimate the new domain factor and deploy the adapted
policy. We establish finite-sample guarantees on causal recovery, actor-critic
convergence, and adaptation gap, and show that GSAC adapts rapidly and
significantly outperforms learning-from-scratch and conventional adaptation
baselines.

</details>


### [93] [Unified token representations for sequential decision models](https://arxiv.org/abs/2510.21448)
*Zhuojing Tian,Yushu Chen*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Transformers have demonstrated strong potential in offline reinforcement
learning (RL) by modeling trajectories as sequences of return-to-go, states,
and actions. However, existing approaches such as the Decision Transformer(DT)
and its variants suffer from redundant tokenization and quadratic attention
complexity, limiting their scalability in real-time or resource-constrained
settings. To address this, we propose a Unified Token Representation (UTR) that
merges return-to-go, state, and action into a single token, substantially
reducing sequence length and model complexity. Theoretical analysis shows that
UTR leads to a tighter Rademacher complexity bound, suggesting improved
generalization. We further develop two variants: UDT and UDC, built upon
transformer and gated CNN backbones, respectively. Both achieve comparable or
superior performance to state-of-the-art methods with markedly lower
computation. These findings demonstrate that UTR generalizes well across
architectures and may provide an efficient foundation for scalable control in
future large decision models.

</details>


### [94] [Towards Explainable Personalized Recommendations by Learning from Users' Photos](https://arxiv.org/abs/2510.21455)
*Jorge Díez,Pablo Pérez-Núñez,Oscar Luaces,Beatriz Remeseiro,Antonio Bahamonde*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Explaining the output of a complex system, such as a Recommender System (RS),
is becoming of utmost importance for both users and companies. In this paper we
explore the idea that personalized explanations can be learned as
recommendation themselves. There are plenty of online services where users can
upload some photos, in addition to rating items. We assume that users take
these photos to reinforce or justify their opinions about the items. For this
reason we try to predict what photo a user would take of an item, because that
image is the argument that can best convince her of the qualities of the item.
In this sense, an RS can explain its results and, therefore, increase its
reliability. Furthermore, once we have a model to predict attractive images for
users, we can estimate their distribution. Thus, the companies acquire a vivid
knowledge about the aspects that the clients highlight of their products. The
paper includes a formal framework that estimates the authorship probability for
a given pair (user, photo). To illustrate the proposal, we use data gathered
from TripAdvisor containing the reviews (with photos) of restaurants in six
cities of different sizes.

</details>


### [95] [Parameter-Free Hypergraph Neural Network for Few-Shot Node Classification](https://arxiv.org/abs/2510.21462)
*Chaewoon Bae,Doyun Choi,Jaehyun Lee,Jaemin Yoo*

Main category: cs.LG

TL;DR: ZEN is a parameter-free, fully linear hypergraph neural network with a closed-form weight solution and redundancy-aware propagation, enabling fast, interpretable few-shot node classification with strong accuracy across 11 benchmarks.


<details>
  <summary>Details</summary>
Motivation: There is a need for models that generalize from scarce labels while capturing high-order hypergraph structures, addressing overfitting and scalability issues of complex, black-box HNNs.

Method: Unifies linearized hypergraph neural networks and derives a closed-form solution for the weight matrix; introduces redundancy-aware propagation to avoid iterative training and remove redundant self-information.

Result: ZEN achieves superior classification accuracy over eight baselines on 11 real-world hypergraph datasets and provides up to 696x speedups compared to the fastest competitor.

Conclusion: The model offers fully interpretable decisions; code and datasets are publicly available, highlighting efficient and transparent hypergraph learning.

Abstract: Few-shot node classification on hypergraphs requires models that generalize
from scarce labels while capturing high-order structures. Existing hypergraph
neural networks (HNNs) effectively encode such structures but often suffer from
overfitting and scalability issues due to complex, black-box architectures. In
this work, we propose ZEN (Zero-Parameter Hypergraph Neural Network), a fully
linear and parameter-free model that achieves both expressiveness and
efficiency. Built upon a unified formulation of linearized HNNs, ZEN introduces
a tractable closed-form solution for the weight matrix and a redundancy-aware
propagation scheme to avoid iterative training and to eliminate redundant self
information. On 11 real-world hypergraph benchmarks, ZEN consistently
outperforms eight baseline models in classification accuracy while achieving up
to 696x speedups over the fastest competitor. Moreover, the decision process of
ZEN is fully interpretable, providing insights into the characteristic of a
dataset. Our code and datasets are fully available at
https://github.com/chaewoonbae/ZEN.

</details>


### [96] [Benchmarking Catastrophic Forgetting Mitigation Methods in Federated Time Series Forecasting](https://arxiv.org/abs/2510.21491)
*Khaled Hallak,Oudom Kem*

Main category: cs.LG

TL;DR: 提出了面向联邦持续时间序列预测的灾变性遗忘基准框架，并评估了多种缓解策略在非独立同分布数据上的表现。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中持续学习的灾变性遗忘问题，特别是在回归型时间序列预测的IoT/边缘场景，现有研究多聚焦分类任务，缺乏时序回归基准。

Method: 在北京多站空气质量数据集（12个客户端）上构建非独立同分布的时间序列联邦学习场景，比较Replay、EWC、LwF、Synaptic Intelligence等CF缓解方法，并提供可重复的开源框架。

Result: 进行了系统比较分析，揭示各方法在FL-非IID时间序列预测中的优劣和适用场景，提供对CF缓解策略的全面认识。

Conclusion: 本工作首次构建面向联邦持续时间序列预测的CF基准，促进方法比较与可重复研究，为后续在实时IoT/边缘场景中的持续学习提供工具与洞察。

Abstract: Catastrophic forgetting (CF) poses a persistent challenge in continual
learning (CL), especially within federated learning (FL) environments
characterized by non-i.i.d. time series data. While existing research has
largely focused on classification tasks in vision domains, the regression-based
forecasting setting prevalent in IoT and edge applications remains
underexplored. In this paper, we present the first benchmarking framework
tailored to investigate CF in federated continual time series forecasting.
Using the Beijing Multi-site Air Quality dataset across 12 decentralized
clients, we systematically evaluate several CF mitigation strategies, including
Replay, Elastic Weight Consolidation, Learning without Forgetting, and Synaptic
Intelligence. Key contributions include: (i) introducing a new benchmark for CF
in time series FL, (ii) conducting a comprehensive comparative analysis of
state-of-the-art methods, and (iii) releasing a reproducible open-source
framework. This work provides essential tools and insights for advancing
continual learning in federated time-series forecasting systems.

</details>


### [97] [Uniform Convergence Beyond Glivenko-Cantelli](https://arxiv.org/abs/2510.21506)
*Tanmay Devale,Pramith Devulapalli,Steve Hanneke*

Main category: cs.LG

TL;DR: 本文提出并研究 Uniform Mean Estimability (UME)，在 {0,1}^N 上的分布族的均值统一估计条件；给出均值向量可分性是充分条件但非必要条件，并给出非分离性但可UME学习的构造；并证明可数并的UME学习性闭性，解决 Cohen 等人(2025) 的猜想。


<details>
  <summary>Details</summary>
Motivation: 扩展对统一收敛（P-Glivenko–Cantelli）之外的均值统一估计的理论，提出UME学习性以包容任意估计器；回答何条件使得分布族的均值可统一估计。

Method: 引入由每个分布的均值向量构成的空间，研究分离性与UME学习性的关系；构造非分离但UME可学习的例子；证明可数并的UME学习性闭性；给出证明和必要性分析。

Result: 分离性足以保证UME学习性；但并非必要；给出非分离但UME可学习的分布族；并证明任意可数并的UME学习性保留。

Conclusion: 提出UME学习性的概念，拓展均值学习理论，解答关于分离性与并集闭性的关键问题，并解决 Cohen 等人提出的猜想。

Abstract: We characterize conditions under which collections of distributions on
$\{0,1\}^\mathbb{N}$ admit uniform estimation of their mean. Prior work from
Vapnik and Chervonenkis (1971) has focused on uniform convergence using the
empirical mean estimator, leading to the principle known as $P-$
Glivenko-Cantelli. We extend this framework by moving beyond the empirical mean
estimator and introducing Uniform Mean Estimability, also called $UME-$
learnability, which captures when a collection permits uniform mean estimation
by any arbitrary estimator. We work on the space created by the mean vectors of
the collection of distributions. For each distribution, the mean vector records
the expected value in each coordinate. We show that separability of the mean
vectors is a sufficient condition for $UME-$ learnability. However, we show
that separability of the mean vectors is not necessary for $UME-$ learnability
by constructing a collection of distributions whose mean vectors are
non-separable yet $UME-$ learnable using techniques fundamentally different
from those used in our separability-based analysis. Finally, we establish that
countable unions of $UME-$ learnable collections are also $UME-$ learnable,
solving a conjecture posed in Cohen et al. (2025).

</details>


### [98] [Probe-based Fine-tuning for Reducing Toxicity](https://arxiv.org/abs/2510.21531)
*Jan Wehner,Mario Fritz*

Main category: cs.LG

TL;DR: 探针（基于模型激活的检测器）可用于发现不良行为并为训练提供信号；对探针进行训练可能触发 Goodhart 定律；通过对比监督微调（SFT）与直接偏好优化（DPO），初步评估在抑制毒性等任务中的可行性，并考察是否需要维护探针集合以维持检测能力。


<details>
  <summary>Details</summary>
Motivation: 研究在将可解释性探针作为训练目标时，是否仍能保持探针的检测能力与稳定性，以及探针的使用在对齐中的实际价值，尤其是在降低有害行为/毒性的场景下。

Method: 比较两种基于探针的训练方法：监督微调（SFT）与直接偏好优化（DPO）。在毒性抑制的测试框架中评估训练对探针准确性的下降程度；探究通过训练一个探针集合、保留未用于训练的保持探针以及训练后重新训练新探针来缓解性能损失的策略。

Result: 与基于分类器的方法相比，基于偏好优化的探针保留检测能力的效果出人意料地好；探针多样性的实际收益有限；仅通过训练后重新训练探针即可恢复高昂的检测准确度；在某些对齐场景中，基于探针的训练是可行的，但在可重新训练的条件下，探针集合的优势不明显。

Conclusion: 探针为对齐提供了有前景的信号源，尤其在避免仅以输出为目标的偏差方面，但其作为训练目标时需谨慎设计；若能通过重新训练探针等手段恢复能力，探针方法的应用空间将更大，且探针集合的必要性在大多数情况下并不高。

Abstract: Probes trained on model activations can detect undesirable behaviors like
deception or biases that are difficult to identify from outputs alone. This
makes them useful detectors to identify misbehavior. Furthermore, they are also
valuable training signals, since they not only reward outputs, but also good
internal processes for arriving at that output. However, training against
interpretability tools raises a fundamental concern: when a monitor becomes a
training target, it may cease to be reliable (Goodhart's Law). We propose two
methods for training against probes based on Supervised Fine-tuning and Direct
Preference Optimization. We conduct an initial exploration of these methods in
a testbed for reducing toxicity and evaluate the amount by which probe accuracy
drops when training against them. To retain the accuracy of probe-detectors
after training, we attempt (1) to train against an ensemble of probes, (2)
retain held-out probes that aren't used for training, and (3) retrain new
probes after training.
  First, probe-based preference optimization unexpectedly preserves probe
detectability better than classifier-based methods, suggesting the preference
learning objective incentivizes maintaining rather than obfuscating relevant
representations. Second, probe diversity provides minimal practical benefit -
simply retraining probes after optimization recovers high detection accuracy.
Our findings suggest probe-based training can be viable for certain alignment
methods, though probe ensembles are largely unnecessary when retraining is
feasible.

</details>


### [99] [FrameShield: Adversarially Robust Video Anomaly Detection](https://arxiv.org/abs/2510.21532)
*Mojtaba Nafez,Mobina Poulaei,Nikan Vasei,Bardia Soltani Moakhar,Mohammad Sabokrou,MohammadHossein Rohban*

Main category: cs.LG

TL;DR: A novel Pseudo-Anomaly Generation method called Spatiotemporal Region Distortion (SRD) is proposed to enhance the robustness of Weakly Supervised Video Anomaly Detection (WSVAD) against adversarial attacks by synthesizing localized, temporally consistent anomalies in normal videos and using them to train with noisy pseudo-labels, significantly improving AUROC across benchmarks (~71% average).


<details>
  <summary>Details</summary>
Motivation: WSVAD is vulnerable to adversarial attacks and weak supervision (video-level labels only) hampers effective defenses. Traditional adversarial training is ineffective due to weakly perturbed video-level signals and noisy frame-level labels derived from pseudo-labels.

Method: Introduce Spatiotemporal Region Distortion (SRD) to generate synthetic, tightly localized anomalies in normal videos via severe augmentations while preserving temporal consistency. Annotate these syntheses and integrate with noisy pseudo-labels to perform effective frame-level adversarial training, reducing label noise and improving robustness.

Result: Extensive experiments show substantially improved robustness of WSVAD models against adversarial attacks, with an average AUROC improvement of 71.0% across multiple benchmarks, outperforming state-of-the-art methods.

Conclusion: SRD enables effective adversarial training for WSVAD under noisy pseudo-labels, offering a practical and robust defense against adversarial perturbations. The approach is validated across benchmarks and the code is publicly available.

Abstract: Weakly Supervised Video Anomaly Detection (WSVAD) has achieved notable
advancements, yet existing models remain vulnerable to adversarial attacks,
limiting their reliability. Due to the inherent constraints of weak
supervision, where only video-level labels are provided despite the need for
frame-level predictions, traditional adversarial defense mechanisms, such as
adversarial training, are not effective since video-level adversarial
perturbations are typically weak and inadequate. To address this limitation,
pseudo-labels generated directly from the model can enable frame-level
adversarial training; however, these pseudo-labels are inherently noisy,
significantly degrading performance. We therefore introduce a novel
Pseudo-Anomaly Generation method called Spatiotemporal Region Distortion (SRD),
which creates synthetic anomalies by applying severe augmentations to localized
regions in normal videos while preserving temporal consistency. Integrating
these precisely annotated synthetic anomalies with the noisy pseudo-labels
substantially reduces label noise, enabling effective adversarial training.
Extensive experiments demonstrate that our method significantly enhances the
robustness of WSVAD models against adversarial attacks, outperforming
state-of-the-art methods by an average of 71.0\% in overall AUROC performance
across multiple benchmarks. The implementation and code are publicly available
at https://github.com/rohban-lab/FrameShield.

</details>


### [100] [Excision Score: Evaluating Edits with Surgical Precision](https://arxiv.org/abs/2510.21537)
*Nikolai Gruzinov,Ksenia Sycheva,Earl T. Barr,Alex Bezzubov*

Main category: cs.LG

TL;DR: 提出 Excision Score（ES）作为静态修订相似性度量，通过最长公共子序列（LCS）去除与原文的共享内容，只比较剩余的差异区域，从而实现对修订相似性的更接近人类判断的度量；在代码编辑评估和 HumanEvalFix 数据集上表现优于 BLEU、SARI 等传统度量，且对共享上下文不敏感。


<details>
  <summary>Details</summary>
Motivation: 修订通常只改变文档的少量部分；现有的逐对相似性度量（如 BLEU）被共享上下文主导，难以与人类判断对齐，因此需要新的评估准则和度量。

Method: 定义 ES，先用 LCS 去除原文与 Ground Truth/预测修订之间的共享内容，再对剩余的差异区域进行比较。采用近似方式将 LCS 的计算从立方时间降至二次时间。通过在代码编辑评估和 HumanEvalFix 上与 SARI、BLEU 等进行比较，显示 ES 的优越性。

Result: ES 在 HumanEvalFix 上相对于最近邻的 SARI 提升了 12% 的 Pearson 相关性，相对于 BLEU 提升超过 21%。在增加共享上下文的情境下，ES 相对 SARI 的提升可达约 20%，相对 BLEU 超过 30%。ES 还能正确对齐移动的代码块、正确奖励匹配的插入或删除等边界情形。

Conclusion: 对共享上下文不敏感是关键；ES 提供了更契合人类判断的修订相似性评估，适用于代码编辑评估等场景；未来工作可将该思路扩展到其他文本/代码编辑评估任务。

Abstract: Many tasks revolve around editing a document, whether code or text. We
formulate the revision similarity problem to unify a wide range of machine
learning evaluation problems whose goal is to assess a revision to an existing
document. We observe that revisions usually change only a small portion of an
existing document, so the existing document and its immediate revisions share a
majority of their content. We formulate five adequacy criteria for revision
similarity measures, designed to align them with human judgement. We show that
popular pairwise measures, like BLEU, fail to meet these criteria, because
their scores are dominated by the shared content. They report high similarity
between two revisions when humans would assess them as quite different. This is
a fundamental flaw we address. We propose a novel static measure, Excision
Score (ES), which computes longest common subsequence (LCS) to remove content
shared by an existing document with the ground truth and predicted revisions,
before comparing only the remaining divergent regions. This is analogous to a
surgeon creating a sterile field to focus on the work area. We use
approximation to speed the standard cubic LCS computation to quadratic. In
code-editing evaluation, where static measures are often used as a cheap proxy
for passing tests, we demonstrate that ES surpasses existing measures. When
aligned with test execution on HumanEvalFix, ES improves over its nearest
competitor, SARI, by 12% Pearson correlation and by >21% over standard measures
like BLEU. The key criterion is invariance to shared context; when we perturb
HumanEvalFix with increased shared context, ES' improvement over SARI increases
to 20% and >30% over standard measures. ES also handles other corner cases that
other measures do not, such as correctly aligning moved code blocks, and
appropriately rewarding matching insertions or deletions.

</details>


### [101] [Interpretable Multimodal Zero-Shot ECG Diagnosis via Structured Clinical Knowledge Alignment](https://arxiv.org/abs/2510.21551)
*Jialu Tang,Hung Manh Pham,Ignace De Lathauwer,Henk S. Schipper,Yuan Lu,Dong Ma,Aaqib Saeed*

Main category: cs.LG

TL;DR: 提出 ZETA：一个零-shot多模态心电图诊断框架，利用结构化正负临床观察进行对比，实现可解释且无需疾病特定微调的诊断，同时结合临床工作流程。


<details>
  <summary>Details</summary>
Motivation: 心电图解释对心血管疾病诊断至关重要，但现有自动系统在透明度和对未见条件的泛化性方面存在问题。通过构建受LLM辅助、专家验证的结构化观察集合，模拟鉴别诊断，以提高可解释性和可信度。

Method: ZETA 使用预训练的多模态模型，在不进行疾病特异性微调的情况下，将心电图信号与文本嵌入对齐；通过与结构化的正/负诊断观察进行对比，进行零-shot分类。观察集由LLM辅助的专家验证过程编 curate，以模拟差异诊断的流程。

Result: 在零-shot分类任务中，ZETA 表现具有竞争力；并且在定性和定量层面提供了增强可解释性的证据，将预测 grounding 于具体且临床相关的正负诊断特征。

Conclusion: 将心电分析与结构化临床知识对齐，有望提升AI诊断系统的透明度、泛化性与可信度；计划公开观测集合和代码以促进未来研究。

Abstract: Electrocardiogram (ECG) interpretation is essential for cardiovascular
disease diagnosis, but current automated systems often struggle with
transparency and generalization to unseen conditions. To address this, we
introduce ZETA, a zero-shot multimodal framework designed for interpretable ECG
diagnosis aligned with clinical workflows. ZETA uniquely compares ECG signals
against structured positive and negative clinical observations, which are
curated through an LLM-assisted, expert-validated process, thereby mimicking
differential diagnosis. Our approach leverages a pre-trained multimodal model
to align ECG and text embeddings without disease-specific fine-tuning.
Empirical evaluations demonstrate ZETA's competitive zero-shot classification
performance and, importantly, provide qualitative and quantitative evidence of
enhanced interpretability, grounding predictions in specific, clinically
relevant positive and negative diagnostic features. ZETA underscores the
potential of aligning ECG analysis with structured clinical knowledge for
building more transparent, generalizable, and trustworthy AI diagnostic
systems. We will release the curated observation dataset and code to facilitate
future research.

</details>


### [102] [Leveraging Classical Algorithms for Graph Neural Networks](https://arxiv.org/abs/2510.21574)
*Jason Wu,Petar Veličković*

Main category: cs.LG

TL;DR: 通过在经典算法上对GNN进行预训练，结合原始GNN的冻结层，提升分子性质预测的性能；Segments Intersect和Dijkstra等算法的预训练取得显著增益。


<details>
  <summary>Details</summary>
Motivation: GNN对分布外数据的泛化能力有限；传统算法在正确性方面有保证但灵活性不足。将经典算法先验嵌入GNN，通过预训练注入有用的归纳偏置，提升对真实复杂图数据的表现。

Method: 在CLRS算法推理基准中的24个经典算法上对GNN进行预训练；用这些预训练参数初始化并冻结第二个GNN的选定层，然后在omg/ ogbg-molhiv与ogbg-molclintox两项分子预测任务上进行微调比较；与随机初始化基线比较，评估性能提升。

Result: 与随机初始化基线相比，预训练模型表现稳定领先或并列；Segments Intersect预训练在ogbg-molhiv上带来6个百分点的绝对提升，Dijkstra预训练在ogbg-molclintox上带来3个百分点提升。

Conclusion: 将经典算法先验嵌入GNN，提供有效的归纳偏置，提升在复杂现实图数据上的分子性质预测性能。

Abstract: Neural networks excel at processing unstructured data but often fail to
generalise out-of-distribution, whereas classical algorithms guarantee
correctness but lack flexibility. We explore whether pretraining Graph Neural
Networks (GNNs) on classical algorithms can improve their performance on
molecular property prediction tasks from the Open Graph Benchmark: ogbg-molhiv
(HIV inhibition) and ogbg-molclintox (clinical toxicity). GNNs trained on 24
classical algorithms from the CLRS Algorithmic Reasoning Benchmark are used to
initialise and freeze selected layers of a second GNN for molecular prediction.
Compared to a randomly initialised baseline, the pretrained models achieve
consistent wins or ties, with the Segments Intersect algorithm pretraining
yielding a 6% absolute gain on ogbg-molhiv and Dijkstra pretraining achieving a
3% gain on ogbg-molclintox. These results demonstrate embedding classical
algorithmic priors into GNNs provides useful inductive biases, boosting
performance on complex, real-world graph data.

</details>


### [103] [REVE: A Foundation Model for EEG -- Adapting to Any Setup with Large-Scale Pretraining on 25,000 Subjects](https://arxiv.org/abs/2510.21585)
*Yassine El Ouahidi,Jonathan Lys,Philipp Thölke,Nicolas Farrugia,Bastien Pasdeloup,Vincent Gripon,Karim Jerbi,Giulia Lioi*

Main category: cs.LG

TL;DR: 提出REVE，一种可泛化到多种 EEG 配置的表示学习模型，通过4D位置编码和掩码自编码预训练，在60k小时、92数据集、25k受试者上训练，在10个下游任务上达到SOTA，且少量微调即可实现强泛化；同时公开代码和权重。


<details>
  <summary>Details</summary>
Motivation: EEG数据在协议、设备、电极配置上的异质性，阻碍基金会模型在EEG中的广泛应用，需要一个能跨配置泛化的模型。

Method: 引入4D定位编码以处理任意长度和电极排列；采用掩码自编码(MAE)目标进行预训练；在60k小时、92数据集、25k受试者规模上进行大规模预训练；核心以4D编码为特征处理过程，可能依赖Transformer等结构。

Result: 在10个下游任务（运动想象分类、癫痫检测、睡眠分期、认知负荷、情绪识别等）上达到SOTA；在只需很少微调的情况下具有良好泛化和时空建模能力。

Conclusion: 发布代码、预训练权重和教程，推动标准化 EEG 研究和临床神经科学进展。

Abstract: Foundation models have transformed AI by reducing reliance on task-specific
data through large-scale pretraining. While successful in language and vision,
their adoption in EEG has lagged due to the heterogeneity of public datasets,
which are collected under varying protocols, devices, and electrode
configurations. Existing EEG foundation models struggle to generalize across
these variations, often restricting pretraining to a single setup, resulting in
suboptimal performance, in particular under linear probing. We present REVE
(Representation for EEG with Versatile Embeddings), a pretrained model
explicitly designed to generalize across diverse EEG signals. REVE introduces a
novel 4D positional encoding scheme that enables it to process signals of
arbitrary length and electrode arrangement. Using a masked autoencoding
objective, we pretrain REVE on over 60,000 hours of EEG data from 92 datasets
spanning 25,000 subjects, representing the largest EEG pretraining effort to
date. REVE achieves state-of-the-art results on 10 downstream EEG tasks,
including motor imagery classification, seizure detection, sleep staging,
cognitive load estimation, and emotion recognition. With little to no
fine-tuning, it demonstrates strong generalization, and nuanced spatio-temporal
modeling. We release code, pretrained weights, and tutorials to support
standardized EEG research and accelerate progress in clinical neuroscience.

</details>


### [104] [Accelerating Data Generation for Nonlinear temporal PDEs via homologous perturbation in solution space](https://arxiv.org/abs/2510.21592)
*Lei Liu,Zhenxin Huang,Hong Wang,huanshuo dong,Haiyang Xin,Hongwei Zhao,Bin Li*

Main category: cs.LG

TL;DR: HOPSS通过在解空间进行时间对齐的下采样和同源扰动，快速生成具有可比精度的PDE训练数据，显著降低数据准备时间（如Navier–Stokes获得1万样本仅用传统方法约10%时间）。


<details>
  <summary>Details</summary>
Motivation: 数据驱动PDE求解方法需要大量的解-右端项对，传统求解器为了获得这些对需进行大量时间步迭代，导致计算成本高且耗时长。需要一种在保持近似精度的前提下更高效的数据生成策略。

Method: 步骤包括：1) 从可靠求解器获得基解，时间步数通常很大；2) 通过下采样使基解与训练数据在时间上对齐；3) 采用同源扰动：将主解与以小标量缩放的同源扰动项及随机噪声组合，生成等价的PDE数据点；4) 基于这些数据点计算原方程 RHS 的变化，得到新的解对；5) 理论与实验均表明降低时间复杂度，Navier–Stokes 案例下可生成1万样本仅用传统方法约10%时间，训练性能相近。

Result: 理论和实验结果表明HOPSS显著降低数据生成的时间成本，同时在Navier–Stokes等问题上实现大量数据的快速产生，而模型训练性能保持与传统方法相当。

Conclusion: HOPSS为数据驱动PDE学习提供了一种高效的数据生成策略，在保持精度的前提下显著缩短数据准备时间，便于对神经算子等复杂时变PDE的有效训练。

Abstract: Data-driven deep learning methods like neural operators have advanced in
solving nonlinear temporal partial differential equations (PDEs). However,
these methods require large quantities of solution pairs\u2014the solution
functions and right-hand sides (RHS) of the equations. These pairs are
typically generated via traditional numerical methods, which need thousands of
time steps iterations far more than the dozens required for training, creating
heavy computational and temporal overheads. To address these challenges, we
propose a novel data generation algorithm, called HOmologous Perturbation in
Solution Space (HOPSS), which directly generates training datasets with fewer
time steps rather than following the traditional approach of generating large
time steps datasets. This algorithm simultaneously accelerates dataset
generation and preserves the approximate precision required for model training.
Specifically, we first obtain a set of base solution functions from a reliable
solver, usually with thousands of time steps, and then align them in time steps
with training datasets by downsampling. Subsequently, we propose a "homologous
perturbation" approach: by combining two solution functions (one as the primary
function, the other as a homologous perturbation term scaled by a small scalar)
with random noise, we efficiently generate comparable-precision PDE data
points. Finally, using these data points, we compute the variation in the
original equation's RHS to form new solution pairs. Theoretical and
experimental results show HOPSS lowers time complexity. For example, on the
Navier-Stokes equation, it generates 10,000 samples in approximately 10% of
traditional methods' time, with comparable model training performance.

</details>


### [105] [Generalised Flow Maps for Few-Step Generative Modelling on Riemannian Manifolds](https://arxiv.org/abs/2510.21608)
*Oscar Davis,Michael S. Albergo,Nicholas M. Boffi,Michael M. Bronstein,Avishek Joey Bose*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Geometric data and purpose-built generative models on them have become
ubiquitous in high-impact deep learning application domains, ranging from
protein backbone generation and computational chemistry to geospatial data.
Current geometric generative models remain computationally expensive at
inference -- requiring many steps of complex numerical simulation -- as they
are derived from dynamical measure transport frameworks such as diffusion and
flow-matching on Riemannian manifolds. In this paper, we propose Generalised
Flow Maps (GFM), a new class of few-step generative models that generalises the
Flow Map framework in Euclidean spaces to arbitrary Riemannian manifolds. We
instantiate GFMs with three self-distillation-based training methods:
Generalised Lagrangian Flow Maps, Generalised Eulerian Flow Maps, and
Generalised Progressive Flow Maps. We theoretically show that GFMs, under
specific design decisions, unify and elevate existing Euclidean few-step
generative models, such as consistency models, shortcut models, and meanflows,
to the Riemannian setting. We benchmark GFMs against other geometric generative
models on a suite of geometric datasets, including geospatial data, RNA torsion
angles, and hyperbolic manifolds, and achieve state-of-the-art sample quality
for single- and few-step evaluations, and superior or competitive
log-likelihoods using the implicit probability flow.

</details>


### [106] [Generative Correlation Manifolds: Generating Synthetic Data with Preserved Higher-Order Correlations](https://arxiv.org/abs/2510.21610)
*Jens E. d'Hondt,Wieger R. Punter,Odysseas Papapetrou*

Main category: cs.LG

TL;DR: 提出一种名为 Generative Correlation Manifolds (GCM) 的合成数据生成方法，通过对目标相关矩阵进行 Cholesky 分解，理论上能够保持源数据的全部相关结构（包括一阶的配对关系和高阶交互），提供一种高效且具有隐私潜力的数据生成方案。


<details>
  <summary>Details</summary>
Motivation: 现有的合成数据方法往往只复现简单的统计量，难以保留数据中复杂的相关性结构，导致在需要多变量交互建模的场景下合成数据的有效性受限。因此，需要一种能严格保留整个相关结构且高效可扩展的生成方法，以支持隐私保护数据共享、鲁棒模型训练与仿真。

Method: 通过对目标相关矩阵执行 Cholesky 分解，利用分解得到的结构直接生成符合目标相关性的多变量数据集。作者声称有数学证明，表明所生成的数据在统计意义上保持原数据的全相关结构，从简单的配对关系到高阶交互均得到保留。该方法强调计算效率与可扩展性。

Result: 在理论层面上，GCM 能保证生成数据保持原数据的完整相关结构，具备对隐私保护数据共享、稳健模型训练和仿真等应用的潜在价值。摘要未给出具体实验细节，因此分析侧重于理论保证与潜在应用前景。

Conclusion: GCM 为合成数据生成提供了一个严格保持相关性的框架，可能提升对复杂多变量系统的建模能力并促进隐私友好的数据共享；未来工作可能涉及对高维数据的可扩展性评估、对方法的实证验证和对隐私风险的量化分析。

Abstract: The increasing need for data privacy and the demand for robust machine
learning models have fueled the development of synthetic data generation
techniques. However, current methods often succeed in replicating simple
summary statistics but fail to preserve both the pairwise and higher-order
correlation structure of the data that define the complex, multi-variable
interactions inherent in real-world systems. This limitation can lead to
synthetic data that is superficially realistic but fails when used for
sophisticated modeling tasks. In this white paper, we introduce Generative
Correlation Manifolds (GCM), a computationally efficient method for generating
synthetic data. The technique uses Cholesky decomposition of a target
correlation matrix to produce datasets that, by mathematical proof, preserve
the entire correlation structure -- from simple pairwise relationships to
higher-order interactions -- of the source dataset. We argue that this method
provides a new approach to synthetic data generation with potential
applications in privacy-preserving data sharing, robust model training, and
simulation.

</details>


### [107] [Few-Shot Knowledge Distillation of LLMs With Counterfactual Explanations](https://arxiv.org/abs/2510.21631)
*Faisal Hamman,Pasan Dissanayake,Yanjun Fu,Sanghamitra Dutta*

Main category: cs.LG

TL;DR: 提出了一种基于反事实解释（CFEs）的少样本任务感知知识蒸馏方法 CoD，在极低数据场景下通过CFEs更准确地刻画教师的决策边界，提升学生蒸馏效果。


<details>
  <summary>Details</summary>
Motivation: 在任务感知蒸馏中，通常需要大量数据来覆盖教师的决策边界；现实情景常面临数据匮乏或昂贵的问题。引入高信息量的CFEs作为边界探针，可在少量样本条件下更有效地近似边界。

Method: 提出 Counterfactual-explanation-infused Distillation CoD，将CFEs作为知识探针融入蒸馏过程，并给出统计与几何角度的理论分析，说明CFEs在边界附近提供更具信息量的样本。通过实证在多数据集和多种LLMs上验证，在极少样本（8-512）下优于标准蒸馏；并显示只用原样本量的一半并配套CFEs也能提升性能。

Result: 实验结果表明CoD在few-shot情境下显著优于传统蒸馏，且在使用大约一半的原始样本量时仍实现性能提升，证明CFEs能有效提高样本信息利用率。

Conclusion: CFEs作为知识探针能更好地逼近教师边界，改善参数估计及几何对齐，从而提升task-aware蒸馏效果；该方法为数据受限场景下的高效知识蒸馏提供新思路。

Abstract: Knowledge distillation is a promising approach to transfer capabilities from
complex teacher models to smaller, resource-efficient student models that can
be deployed easily, particularly in task-aware scenarios. However, existing
methods of task-aware distillation typically require substantial quantities of
data which may be unavailable or expensive to obtain in many practical
scenarios. In this paper, we address this challenge by introducing a novel
strategy called Counterfactual-explanation-infused Distillation CoD for
few-shot task-aware knowledge distillation by systematically infusing
counterfactual explanations. Counterfactual explanations (CFEs) refer to inputs
that can flip the output prediction of the teacher model with minimum
perturbation. Our strategy CoD leverages these CFEs to precisely map the
teacher's decision boundary with significantly fewer samples. We provide
theoretical guarantees for motivating the role of CFEs in distillation, from
both statistical and geometric perspectives. We mathematically show that CFEs
can improve parameter estimation by providing more informative examples near
the teacher's decision boundary. We also derive geometric insights on how CFEs
effectively act as knowledge probes, helping the students mimic the teacher's
decision boundaries more effectively than standard data. We perform experiments
across various datasets and LLMs to show that CoD outperforms standard
distillation approaches in few-shot regimes (as low as 8-512 samples). Notably,
CoD only uses half of the original samples used by the baselines, paired with
their corresponding CFEs and still improves performance.

</details>


### [108] [DEEDEE: Fast and Scalable Out-of-Distribution Dynamics Detection](https://arxiv.org/abs/2510.21638)
*Tala Aljaafari,Varun Kanade,Philip Torr,Christian Schroeder de Witt*

Main category: cs.LG

TL;DR: DEEDEE：一个仅用episode级均值和训练摘要的RBF相似度的两统计检测器，在鲁棒性与效率之间实现兼顾，适用于RL的OOD检测。


<details>
  <summary>Details</summary>
Motivation: RL在分布漂移下脆弱，针对安全关键场景需要鲁棒的OOD检测；当前 representation-heavy管线计算成本高，DEEDEE希望用简单统计实现高效检测。

Method: 提出DEEDEE：两统计量检测器，使用episode级均值和对训练摘要的RBF核相似度，捕捉全局与局部偏差，替代复杂表示学习管线。

Result: 在标准RL OOD测试集上与现有检测器相当或优越，计算量降低约600倍，平均提升约5个百分点的绝对准确率。

Conclusion: 结果表明不同异常类型往往通过少量低阶统计印记在RL轨迹中，为RL环境中OOD检测提供紧凑的基础。

Abstract: Deploying reinforcement learning (RL) in safety-critical settings is
constrained by brittleness under distribution shift. We study
out-of-distribution (OOD) detection for RL time series and introduce DEEDEE, a
two-statistic detector that revisits representation-heavy pipelines with a
minimal alternative. DEEDEE uses only an episodewise mean and an RBF kernel
similarity to a training summary, capturing complementary global and local
deviations. Despite its simplicity, DEEDEE matches or surpasses contemporary
detectors across standard RL OOD suites, delivering a 600-fold reduction in
compute (FLOPs / wall-time) and an average 5% absolute accuracy gain over
strong baselines. Conceptually, our results indicate that diverse anomaly types
often imprint on RL trajectories through a small set of low-order statistics,
suggesting a compact foundation for OOD detection in complex environments.

</details>


### [109] [Optimal Graph Clustering without Edge Density Signals](https://arxiv.org/abs/2510.21669)
*Maximilien Dreveton,Elaine Siyu Liu,Matthias Grossglauser,Patrick Thiran*

Main category: cs.LG

TL;DR: 本论文提出并分析Popularity-Adjusted Block Model（PABM），给出在PABM下的聚类最优错误率界限。与 SBM 和 DCBM 不同，PABM 允许簇内外连接的“人气”参数不同，从而在边密度信号消失时仍可实现簇的分离；PABM 的期望邻接矩阵秩介于 k 与 k^2 之间，导致仅依赖前 k 个特征向量的谱聚类可能失效，使用 k^2 个特征向量的谱方法在实验中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有 SBM/DCBM 模型对度异质性的刻画不足，难以解释在边密度信号不明显时的聚类可行性；需要建立在更丰富结构下的聚类上界与算法设计。

Method: 理论分析：给出 PABM 下聚类的最优错误率界限与可行性条件；分析期望邻接矩阵的秩介于 k 与 k^2 之间；提出基于 k^2 个特征向量的谱嵌入与聚类策略，并与传统仅使用前 k 个特征向量的方法比较；数值实验在合成和真实数据上验证。

Result: 得到在 PABM 下的聚类可行性与错误率的理论界限，揭示在局部连接模式差异存在时即使边密度信号消失也能实现聚类；证实 PABM 的秩介于 k 与 k^2，导致传统谱嵌入可能不足；实验证明使用 k^2 个特征向量的谱聚类优于常规方法。

Conclusion: PABM 提供了比 DCBM/ SBM 更丰富的度异质性视角，显著提升聚类可行性与分辨力；需要扩展谱聚类以利用更高维的特征信息（k^2 维），以捕获其结构特征；理论与实证均支持这一结论。

Abstract: This paper establishes the theoretical limits of graph clustering under the
Popularity-Adjusted Block Model (PABM), addressing limitations of existing
models. In contrast to the Stochastic Block Model (SBM), which assumes uniform
vertex degrees, and to the Degree-Corrected Block Model (DCBM), which applies
uniform degree corrections across clusters, PABM introduces separate popularity
parameters for intra- and inter-cluster connections. Our main contribution is
the characterization of the optimal error rate for clustering under PABM, which
provides novel insights on clustering hardness: we demonstrate that unlike SBM
and DCBM, cluster recovery remains possible in PABM even when traditional
edge-density signals vanish, provided intra- and inter-cluster popularity
coefficients differ. This highlights a dimension of degree heterogeneity
captured by PABM but overlooked by DCBM: local differences in connectivity
patterns can enhance cluster separability independently of global edge
densities. Finally, because PABM exhibits a richer structure, its expected
adjacency matrix has rank between $k$ and $k^2$, where $k$ is the number of
clusters. As a result, spectral embeddings based on the top $k$ eigenvectors
may fail to capture important structural information. Our numerical experiments
on both synthetic and real datasets confirm that spectral clustering algorithms
incorporating $k^2$ eigenvectors outperform traditional spectral approaches.

</details>


### [110] [Equivariance by Contrast: Identifiable Equivariant Embeddings from Unlabeled Finite Group Actions](https://arxiv.org/abs/2510.21706)
*Tobias Schmidt,Steffen Schneider,Matthias Bethge*

Main category: cs.LG

TL;DR: 提出 EbC，通过观察对(y, g·y)学习等变嵌入，联合学习潜在空间和群表示，使群作用在潜在空间中变换为可逆线性映射；在离散的有限群上验证，通过对dSprites和其他合成数据的实验证明高保真等变性，并给出可辨识性的理论证明，首次实现对非阿贝尔群和乘积群的通用编码器级等变学习，且不依赖特定群的先验诱导。


<details>
  <summary>Details</summary>
Motivation: 在不依赖手工先验的情况下从观测对中学习对群作用等变的表示，以实现对广义群变换的一致性与可解释性；同时探索编码器只模型对非阿贝尔群的适用性。

Method: 提出 EbC 框架，学习潜在嵌入与群表示，使群作用在潜在空间中映射为可逆线性算子；仅通过观测对(y, g y)来训练，无需群特定的归纳偏置；在结构化变换的有限群 G=(R_m × Z_n × Z_n) 的数据上实现嵌入的等变性；对 O(n) 与 GL(n) 进行合成数据验证。

Result: 嵌入在高保真等变性下表现良好，能够在潜在空间中忠实重现群运算；在合成数据上给出对非阿贝尔群的验证和对乘积群的建模能力；提供 identifiability 的理论证明；当前结果来自合成数据，未来在真实世界数据上进行广泛评估。

Conclusion: 这是首次展示对广义群作用观测下的通用编码器层面的等变学习，涵盖非阿贝尔群和乘积群等复杂群，并提出可辨识性的理论基础；未来工作包括在真实数据上的广泛评估以及扩展到更多群类型。

Abstract: We propose Equivariance by Contrast (EbC) to learn equivariant embeddings
from observation pairs $(\mathbf{y}, g \cdot \mathbf{y})$, where $g$ is drawn
from a finite group acting on the data. Our method jointly learns a latent
space and a group representation in which group actions correspond to
invertible linear maps -- without relying on group-specific inductive biases.
We validate our approach on the infinite dSprites dataset with structured
transformations defined by the finite group $G:= (R_m \times \mathbb{Z}_n
\times \mathbb{Z}_n)$, combining discrete rotations and periodic translations.
The resulting embeddings exhibit high-fidelity equivariance, with group
operations faithfully reproduced in latent space. On synthetic data, we further
validate the approach on the non-abelian orthogonal group $O(n)$ and the
general linear group $GL(n)$. We also provide a theoretical proof for
identifiability. While broad evaluation across diverse group types on
real-world data remains future work, our results constitute the first
successful demonstration of general-purpose encoder-only equivariant learning
from group action observations alone, including non-trivial non-abelian groups
and a product group motivated by modeling affine equivariances in computer
vision.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [111] [A Multiscale Approach for Enhancing Weak Signal Detection](https://arxiv.org/abs/2510.20828)
*Dixon Vimalajeewa,Ursula U. Muller,Brani Vidakovic*

Main category: eess.SP

TL;DR: 提出了一种双阈值SR检测器，将两个单阈值检测器结合，以提升弱信号检测能力；并在原数据域与多尺度域（通过小波变换）进行评估，结果显示在原数据域显著优于单阈值方法，在频域/多尺度域表现更佳，且需要的噪声水平更低，优于现有检测系统。


<details>
  <summary>Details</summary>
Motivation: 传统的随机共振（SR）多基于单阈值检测器，无法处理随时间变化的信号且往往需要较高噪声来检测弱信号，易扭曲信号特征。引入多阈值系统和多尺度分析，利用小波变换在不同分辨率下分析信号，提升对弱信号的鲁棒检测。

Method: 提出一个双阈值检测系统，将两个单阈值检测器组合以增强对弱信号的检测能力。评估在原始数据域和多尺度域（使用小波变换）中的性能，采用仿真和真实世界信号，并与现有方法进行比较。

Result: 在原始数据域，所提双阈值检测器显著改善弱信号检测，优于传统单阈值方法。在频域/多尺度域，性能进一步提升且对噪声的需求更低，超越现有检测系统。

Conclusion: 通过引入鲁棒的双阈值SR检测策略，推动基于SR的检测方法的发展，为各种学科中的弱信号识别提供更强的工具，具有广泛的应用潜力。

Abstract: Stochastic resonance (SR), a phenomenon originally introduced in climate
modeling, enhances signal detection by leveraging optimal noise levels within
non-linear systems. Traditional SR techniques, mainly based on single-threshold
detectors, are limited to signals whose behavior does not depend on time. Often
large amounts of noise are needed to detect weak signals, which can distort
complex signal characteristics. To address these limitations, this study
explores multi-threshold systems and the application of SR in multiscale
applications using wavelet transforms. In the multiscale domain signals can be
analyzed at different levels of resolution to better understand the underlying
dynamics.
  We propose a double-threshold detection system that integrates two
single-threshold detectors to enhance weak signal detection. We evaluate it
both in the original data domain and in the multiscale domain using simulated
and real-world signals and compare its performance with existing methods.
  Experimental results demonstrate that, in the original data domain, the
proposed double-threshold detector significantly improves weak signal detection
compared to conventional single-threshold approaches. Its performance is
further improved in the frequency domain, requiring lower noise levels while
outperforming existing detection systems. This study advances SR-based
detection methodologies by introducing a robust approach to weak signal
identification, with potential applications in various disciplines.

</details>


### [112] [6D Movable Holographic Surface Assisted Integrated Data and Energy Transfer: A Sensing Enhanced Approach](https://arxiv.org/abs/2510.21137)
*Zhonglun Wang,Yizhe Zhao,Gangming Hu,Yali Zheng,Kun Yang*

Main category: eess.SP

TL;DR: 提出一种6D可移动全息表面用于IDET系统的三阶段协议，结合RHS幅度控制的波束成形与6DMA的定位自由度，提升能量与数据传输效率。


<details>
  <summary>Details</summary>
Motivation: 解决再配置全息表面在幅度控制下的方向性波动问题，利用6D移动天线的定位与朝向自由度来实现更稳定且可控的高增益波束，以充分发挥RHS的大尺度阵列增益用于IDET场景。

Method: 提出三阶段协议：1) 上行感知阶段提取IDET接收端信息；2) 固定朝向后求解RHS波束成形与6DMHS平移，使波束指向各IDET接收端的最大增益方向；3) 在固定朝向与波束成形的前提下建立等效信道，优化数字波束成形、能量分配（功率分配/分配比）与能量捕获功率以提升IDET性能。

Result: 仿真结果表明所提方案能显著提升IDET系统的性能，相较基准在数据传输和能量传输方面具有更优的对齐和效率。

Conclusion: 将6D移动全息表面与再配置全息表面的波束管理结合，提出的三阶段协同方案能在不牺牲感知信息的前提下实现对齐且提升IDET性能，为大规模高增益阵列的应用提供可行方案。

Abstract: Reconfigurable holographic surface (RHS) enables cost-effective large-scale
arrays with high spatial gain. However, its amplitude-controlled holographic
beamforming suffers from directional fluctuations, making it difficult to fully
exploit the spatial gain of RHS. Fortunately, the promising 6D movable antenna
(6DMA) provides a potential solution to this problem. In this paper, we study a
6D movable holographic surface (6DMHS) integrated data and energy transfer
(IDET) system, where a three-stage protocol is proposed, consisting of an
uplink sensing stage, an orientation adjustment stage and a downlink
transmission stage, to coordinate the 6DMHS and effectively serve the IDET
receivers. Firstly, the holographic-based sensing technology is proposed and
the sensing information of the IDET receivers is exploited. Secondly, by fixing
the rotations with the sensing information, the orientation optimization
problem is formulated for designing the holographic beamforming of the RHS and
adjusting the translations of the 6DMHS. As a result, the directions with
maximum beamforming gain are aligned with each IDET receiver. Thirdly, by
fixing the orientation of the 6DMHS and the holographic beamforming, the
equivalent wireless channel is obtained. The IDET performance optimization
problem is formulated for obtaining the optimal digital beamforming, power
splitting factor and energy harvesting (EH) power. Simulation results
demonstrate that the proposed scheme is capable of improving the IDET
performance compared to the benchmarks.

</details>


### [113] [Track-to-Track Association for Collective Perception based on Stochastic Optimization](https://arxiv.org/abs/2510.21278)
*Laura M. Wolf,Vincent Albert Wolff,Simon Steuernagel,Kolja Thormann,Marcus Baum*

Main category: eess.SP

TL;DR: 提出基于随机优化的跟踪对跟踪关联算法，用多维似然量化轨迹集合，生成多种关联假设，在蒙特卡洛仿真和现实场景中验证在模棱两可情况的高似然关联。


<details>
  <summary>Details</summary>
Motivation: 解决多车感知中轨迹对轨迹关联的计算复杂度与依赖启发式方法的局限性；通过跨车感知提升环境建模准确性与传感器盲区覆盖。

Method: 构建基于随机优化的关联算法，设计包含轨迹数量与空间分布的多维似然函数，并同时计算并比较若干关联假设。

Result: 在蒙特卡洛仿真和现实集体感知场景中证明方法有效性，能够在模棱两可情景下获取高似然的关联。

Conclusion: 基于随机优化的多假设轨迹关联为集体感知提供鲁棒、可扩展的解决方案，缓解传统方法的计算复杂度和启发式局限。

Abstract: Collective perception is a key aspect for autonomous driving in smart cities
as it aims to combine the local environment models of multiple intelligent
vehicles in order to overcome sensor limitations. A crucial part of
multi-sensor fusion is track-to-track association. Previous works often suffer
from high computational complexity or are based on heuristics. We propose an
association algorithms based on stochastic optimization, which leverages a
multidimensional likelihood incorporating the number of tracks and their
spatial distribution and furthermore computes several association hypotheses.
We demonstrate the effectiveness of our approach in Monte Carlo simulations and
a realistic collective perception scenario computing high-likelihood
associations in ambiguous settings.

</details>


### [114] [On Irradiance Distributions for Weakly Turbulent FSO Links: Log-Normal vs. Gamma-Gamma](https://arxiv.org/abs/2510.21509)
*Carmen Álvarez Roa,Yunus Can Gültekin,Vincent van Vliet,Menno van den Hout,Chigo Okonkwo,Alex Alvarado*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Weak turbulence is commonly modeled using the log-normal distribution. Our
experimental results show that this distribution fails to capture irradiance
fluctuations in this regime. The Gamma-Gamma model is shown to be more
accurate.

</details>
