{"id": "2511.19558", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19558", "abs": "https://arxiv.org/abs/2511.19558", "authors": ["Mohammed Talha Alam", "Nada Saadi", "Fahad Shamshad", "Nils Lukas", "Karthik Nandakumar", "Fahkri Karray", "Samuele Poppi"], "title": "SPQR: A Standardized Benchmark for Modern Safety Alignment Methods in Text-to-Image Diffusion Models", "comment": "20 pages, 8 figures, 10 tables", "summary": "Text-to-image diffusion models can emit copyrighted, unsafe, or private content. Safety alignment aims to suppress specific concepts, yet evaluations seldom test whether safety persists under benign downstream fine-tuning routinely applied after deployment (e.g., LoRA personalization, style/domain adapters). We study the stability of current safety methods under benign fine-tuning and observe frequent breakdowns. As true safety alignment must withstand even benign post-deployment adaptations, we introduce the SPQR benchmark (Safety-Prompt adherence-Quality-Robustness). SPQR is a single-scored metric that provides a standardized and reproducible framework to evaluate how well safety-aligned diffusion models preserve safety, utility, and robustness under benign fine-tuning, by reporting a single leaderboard score to facilitate comparisons. We conduct multilingual, domain-specific, and out-of-distribution analyses, along with category-wise breakdowns, to identify when safety alignment fails after benign fine-tuning, ultimately showcasing SPQR as a concise yet comprehensive benchmark for T2I safety alignment techniques for T2I models.", "AI": {"tldr": "\u63d0\u51fa SPQR \u57fa\u51c6\uff0c\u7528\u5355\u4e00\u5206\u6570\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u5728 benign \u5fae\u8c03\u540e\u7684\u5b89\u5168\u6027\u3001\u6548\u7528\u548c\u9c81\u68d2\u6027\uff0c\u63ed\u793a\u73b0\u6709\u5b89\u5168\u65b9\u6cd5\u5728\u5fae\u8c03\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u5e76\u7ed9\u51fa\u8de8\u8bed\u8a00/\u9886\u57df/OD \u7684\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u6027\u5bf9\u6297\u5e38\u5728\u90e8\u7f72\u540e\u8fdb\u884c\u5fae\u8c03\u65f6\u5931\u6548\uff0c\u9700\u9a8c\u8bc1\u5728 benign \u5fae\u8c03\u4e0b\u7684\u7a33\u5065\u6027\u3002", "method": "\u63d0\u51fa SPQR \u6307\u6807\uff0c\u8fdb\u884c\u591a\u8bed\u8a00\u3001\u9886\u57df\u7279\u5b9a\u3001\u5206\u5e03\u5916\u5206\u6790\u548c\u7c7b\u522b\u5206\u89e3\uff0c\u6bd4\u8f83\u4e0d\u540c\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u5728\u5fae\u8c03\u540e\u7684\u8868\u73b0\u3002", "result": "SPQR \u63d0\u4f9b\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u5355\u5206\u6570\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u603b\u7ed3\u5b89\u5168\u6027\u3001\u5b9e\u7528\u6027\u548c\u9c81\u68d2\u6027\u5728\u5fae\u8c03\u540e\u7684\u4fdd\u6301\u60c5\u51b5\uff0c\u5c55\u793a\u4e86\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u5b89\u5168\u5bf9\u9f50\u4f1a\u4e0b\u964d\u7684\u60c5\u51b5\u3002", "conclusion": "SPQR \u53ef\u4f5c\u4e3a T2I \u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u7684\u7b80\u6d01\u4e14\u7efc\u5408\u7684\u57fa\u51c6\uff0c\u4fbf\u4e8e\u6a2a\u5411\u6bd4\u8f83\u548c\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2511.19805", "categories": ["eess.SP", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19805", "abs": "https://arxiv.org/abs/2511.19805", "authors": ["Y. A. Rouzoumka", "E. Terreaux", "C. Morisseau", "J. -P. Ovarlez", "C. Ren"], "title": "Latent-space metrics for Complex-Valued VAE out-of-distribution detection under radar clutter", "comment": "Under review at ICASSP 2026", "summary": "We investigate complex-valued Variational AutoEncoders (CVAE) for radar Out-Of-Distribution (OOD) detection in complex radar environments. We proposed several detection metrics: the reconstruction error of CVAE (CVAE-MSE), the latent-based scores (Mahalanobis, Kullback-Leibler divergence (KLD)), and compared their performance against the classical ANMF-Tyler detector (ANMF-FP). The performance of all these detectors is analyzed on synthetic and experimental radar data, showing the advantages and the weaknesses of each detector.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u590d\u6742\u503c\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08CVAE\uff09\u7684\u96f7\u8fbeOOD\u63a2\u6d4b\u6846\u67b6\uff0c\u63d0\u51faCVAE-MSE\u3001\u6f5c\u5728\u5206\u6570\uff08Mahalanobis\u3001KLD\uff09\uff0c\u5e76\u4e0e\u7ecf\u5178ANMF-Tyler\u63a2\u6d4b\u5668\u5bf9\u6bd4\uff0c\u5728\u5408\u6210\u4e0e\u5b9e\u9a8c\u96f7\u8fbe\u6570\u636e\u4e0a\u8bc4\u4f30\u5404\u68c0\u6d4b\u5668\u7684\u4f18\u52a3\u4e0e\u9002\u7528\u6027\u3002", "motivation": "\u5728\u590d\u6742\u96f7\u8fbe\u73af\u5883\u4e2d\u8fdb\u884c\u9c81\u68d2\u7684ODD\uff08Out-Of-Distribution\uff09\u63a2\u6d4b\uff0c\u4f20\u7edf\u68c0\u6d4b\u5668\u5728\u5206\u5e03\u504f\u79bb\u65f6\u6027\u80fd\u4e0b\u964d\u3002CVAE\u901a\u8fc7\u91cd\u6784\u4e0e\u6f5c\u5728\u53d8\u91cf\u8868\u8fbe\uff0c\u53ef\u80fd\u63d0\u5347\u5bf9\u5f02\u5e38\u5206\u5e03\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u5e0c\u671b\u5728\u5b9e\u9645\u96f7\u8fbe\u6570\u636e\u4e2d\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\u3002", "method": "\u8bad\u7ec3\u4e00\u4e2a\u590d\u6742\u503cCVAE\uff0c\u5bf9\u8f93\u5165\u96f7\u8fbe\u4fe1\u53f7\u8fdb\u884c\u91cd\u6784\uff0c\u63d0\u51faCVAE-MSE\u4f5c\u4e3a\u91cd\u6784\u8bef\u5dee\u6307\u6807\uff1b\u5e76\u57fa\u4e8e\u6f5c\u5728\u53d8\u91cf\u5206\u5e03\u8ba1\u7b97Mahalanobis\u8ddd\u79bb\u548cKullback-Leibler\u6563\u5ea6\uff08KLD\uff09\u4f5c\u4e3a\u989d\u5916\u5206\u6570\uff1b\u5c06\u5176\u4e0e\u7ecf\u5178ANMF-FP\u68c0\u6d4b\u5668\u5728\u5408\u6210\u4e0e\u5b9e\u9a8c\u96f7\u8fbe\u6570\u636e\u4e0a\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "CVAE\u76f8\u5173\u6307\u6807\u5728\u67d0\u4e9b\u60c5\u5883\u4e0b\u4f18\u4e8eANMF-FP\uff0c\u663e\u793a\u51fa\u5bf9\u590d\u6742\u73af\u5883\u7684\u9c81\u68d2\u6027\u63d0\u5347\uff0c\u4f46\u5728\u5176\u4ed6\u573a\u666f\u4e0b\u4e5f\u5b58\u5728\u52a3\u52bf\uff0c\u8868\u660e\u5355\u4e00\u6307\u6807\u5e76\u975e\u901a\u7528\u6700\u4f18\uff0c\u9700\u8981\u7ed3\u5408\u591a\u79cd\u68c0\u6d4b\u4fe1\u53f7\u8fdb\u884c\u7efc\u5408\u5224\u65ad\u3002", "conclusion": "CVAE\u4e3a\u96f7\u8fbeOOD\u63a2\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6f5c\u529b\u7684\u8865\u5145\u5de5\u5177\uff0c\u4e0e\u4f20\u7edf\u68c0\u6d4b\u5668\u5177\u6709\u4e92\u8865\u6027\u3002\u672a\u6765\u5de5\u4f5c\u53ef\u805a\u7126\u4e8e\u591a\u6307\u6807\u878d\u5408\u3001\u6a21\u578b\u6539\u8fdb\u53ca\u5bf9\u4e0d\u540c\u5e72\u6270\u6761\u4ef6\u7684\u81ea\u9002\u5e94\u6027\u7814\u7a76\u3002"}}
{"id": "2511.19449", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19449", "abs": "https://arxiv.org/abs/2511.19449", "authors": ["Adeline Gu\u00e9ret"], "title": "Power sector models featuring individual BEV profiles: Assessing the time-accuracy trade-off", "comment": null, "summary": "Electrifying passenger cars will impact future power systems. To understand the challenges and opportunities that arise, it is necessary to reflect \"sector coupling\" in the modeling space. This paper focuses on a specific modeling approach that includes dozens of individual BEV profiles rather than one aggregated BEV profile. Although including additional BEV profiles increases model complexity and runtime, it avoids losing information in the aggregation process. We investigate how many profiles are needed to ensure the accuracy of the results and the extent to which fewer profiles can be traded for runtime efficiency gains. We also examine whether selecting specific profiles influences optimal results. We demonstrate that including too few profiles may result in distorted optimal solutions. However, beyond a certain threshold, adding more profiles does not significantly enhance the robustness of the results. More generally, for fleets of 5 to 20 million BEVs, we derive a rule of thumb consisting in including enough profiles such that each profile represents 200,000 to 250,000 vehicles, ensuring accurate results without excessive runtime.", "AI": {"tldr": "\u5bf9\u4e8e\u5927\u89c4\u6a21\u7535\u52a8\u6c7d\u8f66\u8f66\u961f\u7684\u7535\u529b\u7cfb\u7edf\u5efa\u6a21\uff0c\u4f7f\u7528\u82e5\u5e72\u4e2a\u5177\u4f53\u7684 BEV \u914d\u7f6e\u6863\u6bd4\u5355\u4e00\u805a\u5408\u6863\u80fd\u4fdd\u7559\u4fe1\u606f\uff1b\u5b58\u5728\u201c\u6863\u4f4d\u9608\u503c\u201d\uff1a\u592a\u5c11\u4f1a\u626d\u66f2\u6700\u4f18\u89e3\uff0c\u8d85\u8fc7\u67d0\u9608\u503c\u6536\u76ca\u9012\u51cf\u3002\u7ed9\u51fa\u5b9e\u7528\u89c4\u5219\uff1a\u5bf9\u4e8e 500 \u4e07\u5230 2000 \u4e07\u7ea7\u522b\u7684 BEV \u8f66\u961f\uff0c\u6bcf\u4e2a\u6863\u4f4d\u8986\u76d6\u7ea6 20 \u4e07\u5230 25 \u4e07\u8f86\u8f66\uff0c\u65e2\u80fd\u4fddAccuracy\u53c8\u63a7\u5236\u8fd0\u884c\u65f6\u95f4\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u5316\u5e7f\u6cdb\u63a8\u8fdb\uff0c\u8de8\u90e8\u95e8\u8026\u5408\uff08sector coupling\uff09\u7684\u5efa\u6a21\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684 BEV \u8868\u5f81\u4ee5\u907f\u514d\u805a\u5408\u5e26\u6765\u7684\u4fe1\u606f\u635f\u5931\uff1b\u7814\u7a76\u5e94\u56de\u7b54\uff1a\u9700\u8981\u591a\u5c11\u4e2a\u6863\u4f4d\u6765\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u5f00\u9500\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "method": "\u5728\u5305\u542b\u9010\u4e2a BEV \u914d\u7f6e\u6863\u7684\u6a21\u578b\u6846\u67b6\u4e2d\uff0c\u4e0e\u4ec5\u7528\u4e00\u4e2a\u805a\u5408 BEV \u914d\u7f6e\u6863\u7684\u57fa\u7ebf\u8fdb\u884c\u5bf9\u6bd4\uff0c\u8003\u5bdf\u4e0d\u540c\u6863\u4f4d\u6570\u91cf\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\uff1b\u8bc4\u4f30\u662f\u5426\u9009\u62e9\u7279\u5b9a\u5b50\u96c6\u7684 BEV \u914d\u7f6e\u4f1a\u6539\u53d8\u6700\u4f18\u89e3\uff1b\u4ee5\u8f66\u961f\u89c4\u6a21\u5728 5\u201320 \u767e\u4e07\u7ea7\u522b\u7684\u60c5\u666f\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u53d1\u73b0\u8fc7\u5c11\u7684 BEV \u914d\u7f6e\u4f1a\u5bfc\u81f4\u6700\u4f18\u89e3\u5931\u771f\uff1b\u4f46\u8fbe\u5230\u67d0\u4e00\u9608\u503c\u540e\uff0c\u589e\u52a0\u66f4\u591a\u914d\u7f6e\u5bf9\u9c81\u68d2\u6027\u63d0\u5347\u7684\u6536\u76ca\u663e\u8457\u4e0b\u964d\u3002\u7ed9\u51fa\u4e00\u4e2a\u7ecf\u9a8c\u6cd5\u5219\uff1a\u5bf9\u4e8e 5\u201320 \u767e\u4e07\u8f86\u7684\u8f66\u961f\uff0c\u786e\u4fdd\u6bcf\u4e2a\u914d\u7f6e\u6863\u8986\u76d6\u7ea6 20\u201325 \u4e07\u8f86\u8f66\uff0c\u80fd\u5728\u4fdd\u6301\u7ed3\u679c\u51c6\u786e\u6027\u7684\u540c\u65f6\u63a7\u5236\u8fd0\u884c\u65f6\u3002", "conclusion": "\u5728\u5927\u89c4\u6a21\u8f66\u961f\u7684 sector coupling \u6a21\u578b\u4e2d\uff0c\u91c7\u7528\u6bcf\u6863 20\u201325 \u4e07\u8f66\u8f86\u7684\u5206\u6863\u7b56\u7565\u53ef\u5728\u51c6\u786e\u6027\u4e0e\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u5b9e\u52a1\u5206\u6790\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6307\u5357\u3002"}}
{"id": "2511.19446", "categories": ["cs.IT", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.19446", "abs": "https://arxiv.org/abs/2511.19446", "authors": ["Serkan G\u00fcr"], "title": "The Quality of Information: A Weighted Entropy Approach to Near-Optimal Mastermind", "comment": null, "summary": "This paper presents a novel class of information-theoretic strategies for solving the game of Mastermind, achieving state-of-the-art performance among known heuristic methods. The core contribution is the application of a weighted entropy heuristic, based on the Belis-Guias, u framework, which assigns context- dependent utility values to each of the possible feedback types. A genetic algorithm optimization approach discovers interpret-able weight patterns that reflect strategic game dynamics. First, I demonstrate that a single, fixed vector of optimized weights achieves a remarkable 4.3565 average guesses with a maximum of 5. Building upon this, I introduce a stage-weighted heuristic with distinct utility vectors for each turn, achieving 4.3488 average guesses with a maximum of 6, approaching the theoretical optimum of 4.3403 by less than 0.2%. The method retains the computational efficiency of classical one-step-ahead heuristics while significantly improving performance through principled information valuation. A complete implementation and all optimized parameters are provided for full reproducibility.", "AI": {"tldr": "\u4f7f\u7528\u52a0\u6743\u71b5\u542f\u53d1\u5f0f\u7684Mastermind\u4fe1\u606f\u7406\u8bba\u7b56\u7565\uff0c\u7ed3\u5408Belis-Guias\u6846\u67b6\u4e0e\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\uff0c\u8fbe\u5230\u540c\u7c7b\u542f\u53d1\u5f0f\u65b9\u6cd5\u4e2d\u7684\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u63d0\u9ad8Mastermind\u6c42\u89e3\u7684\u4fe1\u606f\u4ef7\u503c\u4f30\u8ba1\uff0c\u901a\u8fc7\u5bf9\u53cd\u9988\u7c7b\u578b\u8d4b\u4e88\u4e0a\u4e0b\u6587\u76f8\u5173\u6548\u7528\uff0c\u5229\u7528\u9057\u4f20\u7b97\u6cd5\u53d1\u73b0\u53ef\u89e3\u91ca\u7684\u6743\u91cd\u6a21\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u5e73\u5747\u731c\u6d4b\u6b21\u6570\u4e0e\u4e0a\u9650\u3002", "method": "\u57fa\u4e8e\u52a0\u6743\u71b5\u542f\u53d1\u5f0f\uff0c\u91c7\u7528Belis-Guias\u6846\u67b6\u5bf9\u6bcf\u79cd\u53cd\u9988\u7c7b\u578b\u5206\u914d\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u6548\u7528\uff1b\u4ee5\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u6743\u91cd\uff0c\u5f62\u6210\u5355\u4e00\u56fa\u5b9a\u5411\u91cf\uff1b\u540e\u53c8\u63d0\u51fa\u5206\u9636\u6bb5\u6743\u91cd\uff0c\u5728\u4e0d\u540c\u56de\u5408\u4f7f\u7528\u4e0d\u540c\u7684\u6548\u7528\u5411\u91cf\u3002", "result": "\u5728\u5355\u4e00\u6743\u91cd\u5411\u91cf\u4e0b\u5e73\u5747\u731c\u6d4b4.3565\u6b21\uff0c\u6700\u59275\u6b21\uff1b\u5728\u5206\u9636\u6bb5\u6743\u91cd\u4e0b\u5e73\u57474.3488\u6b21\uff0c\u6700\u59276\u6b21\uff0c\u63a5\u8fd1\u7406\u8bba\u6700\u4f184.3403\uff0c\u8bef\u5dee\u4e0d\u8db30.2%\u3002", "conclusion": "\u6240\u63d0\u51fa\u65b9\u6cd5\u5728\u4ecd\u5177\u5907\u7ecf\u5178\u4e00\u6b65\u5230\u4f4d\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fe1\u606f\u4ef7\u503c\u4f30\u8ba1\u7684\u6548\u679c\uff1b\u5b9e\u73b0\u53ef\u590d\u73b0\u7684\u5b8c\u6574\u5b9e\u73b0\u4e0e\u4f18\u5316\u53c2\u6570\u3002"}}
{"id": "2511.19649", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19649", "abs": "https://arxiv.org/abs/2511.19649", "authors": ["Angelo Gaspar Diniz Nogueira", "Kayua Oleques Paim", "Hendrio Bragan\u00e7a", "Rodrigo Brand\u00e3o Mansilha", "Diego Kreutz"], "title": "Synthetic Data: AI's New Weapon Against Android Malware", "comment": "23 pages, 18 figures, 8 tables. Accepted for publication at the JBCS", "summary": "The ever-increasing number of Android devices and the accelerated evolution of malware, reaching over 35 million samples by 2024, highlight the critical importance of effective detection methods. Attackers are now using Artificial Intelligence to create sophisticated malware variations that can easily evade traditional detection techniques. Although machine learning has shown promise in malware classification, its success relies heavily on the availability of up-to-date, high-quality datasets. The scarcity and high cost of obtaining and labeling real malware samples presents significant challenges in developing robust detection models. In this paper, we propose MalSynGen, a Malware Synthetic Data Generation methodology that uses a conditional Generative Adversarial Network (cGAN) to generate synthetic tabular data. This data preserves the statistical properties of real-world data and improves the performance of Android malware classifiers. We evaluated the effectiveness of this approach using various datasets and metrics that assess the fidelity of the generated data, its utility in classification, and the computational efficiency of the process. Our experiments demonstrate that MalSynGen can generalize across different datasets, providing a viable solution to address the issues of obsolescence and low quality data in malware detection.", "AI": {"tldr": "MalSynGen uses a conditional GAN to generate synthetic tabular data for Android malware detection, addressing data scarcity and obsolescence, and improving classifier performance while maintaining data fidelity and efficiency.", "motivation": "The rapid growth of Android devices and malware, coupled with the high cost of real malware labeling, necessitates high-quality synthetic data to train robust detectors.", "method": "A conditional GAN (cGAN) is trained to produce synthetic tabular features that preserve the statistical properties of real malware-related data; the approach is evaluated across multiple datasets and metrics for data fidelity, utility in classification, and computational efficiency.", "result": "Synthetic data from MalSynGen improves Android malware classifiers, demonstrates generalization across datasets, and provides efficient data generation.", "conclusion": "MalSynGen offers a viable solution to data obsolescence and quality issues in Android malware detection, enabling better ML-based defense through synthetic data generation."}}
{"id": "2511.19866", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.19866", "abs": "https://arxiv.org/abs/2511.19866", "authors": ["Yutaka Jitsumatsu", "Liangchen Sun"], "title": "Parallel Delay-Doppler Estimation via Order-Reversed Two-Stage Prony Method", "comment": "5pages and 3 figures", "summary": "This paper proposes a Prony-based parallel two-stage method for delay-Doppler estimation in OTFS systems. By performing delay-first and Doppler-first estimations in parallel and fusing the results, the method resolves ambiguities caused by similar path characteristics. The simulation results demonstrate the superior accuracy and robustness of the proposed method under various conditions. This method provides a promising solution for future applications such as Vehicle-to-Vehicle (V2V) and Integrated Sensing and Communication (ISAC).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eProny\u7684\u5e76\u884c\u4e24\u9636\u6bb5\u5ef6\u65f6-\u591a\u666e\u52d2\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8eOTFS\u7cfb\u7edf\u3002\u901a\u8fc7\u5ef6\u65f6\u4f18\u5148\u548c\u591a\u666e\u52d2\u4f18\u5148\u7684\u5e76\u884c\u4f30\u8ba1\u5e76\u878d\u5408\u7ed3\u679c\uff0c\u89e3\u51b3\u4e86\u7c7b\u4f3c\u8def\u5f84\u7279\u5f81\u9020\u6210\u7684\u6a21\u7cca\u6027\uff1b\u4eff\u771f\u663e\u793a\u5728\u591a\u79cd\u6761\u4ef6\u4e0b\u5177\u6709\u66f4\u9ad8\u7684\u7cbe\u5ea6\u4e0e\u9c81\u68d2\u6027\uff0c\u5e76\u5bf9V2V/ISAC\u7b49\u672a\u6765\u5e94\u7528\u5177\u6f5c\u5728\u610f\u4e49\u3002", "motivation": "\u5728OTFS\u4fe1\u9053\u4e2d\uff0c\u5ef6\u65f6-\u591a\u666e\u52d2\u4f30\u8ba1\u6613\u53d7\u8def\u5f84\u7279\u5f81\u76f8\u4f3c\u6027\u5f71\u54cd\uff0c\u5bfc\u81f4\u89e3\u6a21\u7cca\u548c\u7cbe\u5ea6\u4e0b\u964d\uff0c\u9700\u8981\u4e00\u79cd\u9c81\u68d2\u4e14\u51c6\u786e\u7684\u4f30\u8ba1\u65b9\u6848\u4ee5\u6ee1\u8db3\u9ad8\u52a8\u6001\u4e0e\u591a\u5f84\u573a\u666f\u7684\u9700\u6c42\uff0c\u7279\u522b\u662f\u9762\u5411V2V\u548cISAC\u7b49\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e00\u79cdProny\u57fa\u7684\u5e76\u884c\u4e24\u9636\u6bb5\u4f30\u8ba1\u6846\u67b6\uff1a\u5148\u8fdb\u884c\u5ef6\u65f6\u4f18\u5148\u4f30\u8ba1\u4e0e\u591a\u666e\u52d2\u4f18\u5148\u4f30\u8ba1\uff0c\u5e76\u5728\u5e76\u884c\u9636\u6bb5\u5b8c\u6210\u4e24\u8def\u4f30\u8ba1\u540e\u8fdb\u884c\u878d\u5408\u4ee5\u6d88\u9664\u6a21\u7cca\u6027\u3002\u8be5\u65b9\u6cd5\u5728OTFS\u7cfb\u7edf\u7684\u5ef6\u65f6-\u591a\u666e\u52d2\u57df\u4e2d\u5b9e\u73b0\uff0c\u5229\u7528Prony\u7cfb\u5217\u53c2\u6570\u63d0\u53d6\u5b9e\u73b0\u9ad8\u6548\u7684\u53c2\u6570\u4f30\u8ba1\u4e0e\u878d\u5408\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u6bd4\u5bf9\u6bd4\u65b9\u6cd5\u66f4\u9ad8\u7684\u7cbe\u5ea6\u4e0e\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u6709\u6548\u964d\u4f4e\u8def\u5f84\u7279\u5f81\u76f8\u4f3c\u5e26\u6765\u7684\u6b67\u4e49\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aOTFS\u7cfb\u7edf\u4e2d\u7684\u5ef6\u65f6-\u591a\u666e\u52d2\u4f30\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u601d\u8def\uff0c\u5c24\u5176\u5728V2V\u53caISAC\u7b49\u672a\u6765\u5e94\u7528\u573a\u666f\u4e2d\u5177\u6709\u6f5c\u5728\u7684\u5e94\u7528\u4ef7\u503c\u4e0e\u6269\u5c55\u6027\u3002"}}
{"id": "2511.19451", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19451", "abs": "https://arxiv.org/abs/2511.19451", "authors": ["Apurva Patil", "Alfredo Duarte", "Fabrizio Bisetti", "Takashi Tanaka"], "title": "Strong Duality and Dual Ascent Approach to Continuous-Time Chance-Constrained Stochastic Optimal Control", "comment": "arXiv admin note: substantial text overlap with arXiv:2504.17154", "summary": "The paper addresses a continuous-time continuous-space chance-constrained stochastic optimal control (SOC) problem where the probability of failure to satisfy given state constraints is explicitly bounded. We leverage the notion of exit time from continuous-time stochastic calculus to formulate a chance-constrained SOC problem. Without any conservative approximation, the chance constraint is transformed into an expectation of an indicator function which can be incorporated into the cost function by considering a dual formulation. We then express the dual function in terms of the solution to a Hamilton-Jacobi-Bellman partial differential equation parameterized by the dual variable. Under a certain assumption on the system dynamics and cost function, it is shown that a strong duality holds between the primal chance-constrained problem and its dual. The Path integral approach is utilized to numerically solve the dual problem via gradient ascent using open-loop samples of system trajectories. We present simulation studies on chance-constrained motion planning for spatial navigation of mobile robots and the solution of the path integral approach is compared with that of the finite difference method.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5bf9\u5076\u7684\u8fde\u7eed\u65f6\u95f4\u8fde\u7eed\u7a7a\u95f4\u673a\u4f1a\u7ea6\u675f\u968f\u673a\u6700\u4f18\u63a7\u5236\u6846\u67b6\u3002\u901a\u8fc7\u9000\u51fa\u65f6\u95f4\u5c06\u673a\u4f1a\u7ea6\u675f\u53d8\u4e3a\u6307\u6807\u51fd\u6570\u7684\u671f\u671b\uff0c\u7ed3\u5408\u8def\u5f84\u79ef\u5206\u65b9\u6cd5\u4ee5\u68af\u5ea6\u4e0a\u5347\u6c42\u89e3\u5bf9\u5076\u95ee\u9898\uff0c\u5e76\u7528\u5f00\u73af\u8f68\u8ff9\u6837\u672c\u8fdb\u884c\u6570\u503c\u5b9e\u73b0\uff1b\u5728\u673a\u5668\u4eba\u5bfc\u822a\u4efb\u52a1\u4e2d\u7ed9\u51fa\u6570\u503c\u5bf9\u6bd4\u3002", "motivation": "\u5728\u8fde\u7eed\u65f6\u95f4/\u8fde\u7eed\u7a7a\u95f4\u7684\u968f\u673a\u6700\u4f18\u63a7\u5236\u95ee\u9898\u4e2d\u5f15\u5165\u660e\u786e\u7684\u5931\u8d25\u6982\u7387\u7ea6\u675f\uff0c\u800c\u4e0d\u91c7\u7528\u4fdd\u5b88\u8fd1\u4f3c\uff1b\u5229\u7528\u9000\u51fa\u65f6\u95f4\u7684\u6027\u8d28\u4ee5\u53ca\u5bf9\u5076\u6027\u5efa\u7acb\u4e00\u4e2a\u53ef\u6570\u503c\u6c42\u89e3\u7684\u6846\u67b6\uff0c\u63d0\u5347\u5bf9\u7ea6\u675f\u7684\u5904\u7406\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "method": "\u5c06\u673a\u4f1a\u7ea6\u675f\u901a\u8fc7\u9000\u51fa\u65f6\u95f4\u7684\u6846\u67b6\u8868\u8fbe\uff1b\u5c06\u7ea6\u675f\u8f6c\u5316\u4e3a\u76ee\u6807\u51fd\u6570\u4e2d\u6307\u6807\u51fd\u6570\u7684\u671f\u671b\uff0c\u5e76\u901a\u8fc7\u5bf9\u5076\u5316\u5c06\u5176\u5199\u6210\u5bf9\u5076\u95ee\u9898\uff1b\u5bf9\u5076\u51fd\u6570\u7531\u53c2\u6570\u5316\u7684HJB\u504f\u5fae\u5206\u65b9\u7a0b\u89e3\u8868\u793a\uff1b\u5728\u7ed9\u5b9a\u7cfb\u7edf\u52a8\u529b\u5b66\u548c\u6210\u672c\u7684\u5047\u8bbe\u4e0b\u8bc1\u660e\u539f\u95ee\u9898\u4e0e\u5bf9\u5076\u95ee\u9898\u5b58\u5728\u5f3a\u5bf9\u5076\u6027\uff1b\u91c7\u7528\u8def\u5f84\u79ef\u5206\u65b9\u6cd5\u901a\u8fc7\u68af\u5ea6\u4e0a\u5347\u6cd5\uff0c\u7ed3\u5408\u5f00\u73af\u8f68\u8ff9\u91c7\u6837\u6765\u6570\u503c\u6c42\u89e3\u5bf9\u5076\u95ee\u9898\uff1b\u5728\u57fa\u4e8e\u7a7a\u95f4\u5bfc\u822a\u7684\u79fb\u52a8\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u4e2d\u8fdb\u884c\u4eff\u771f\uff0c\u5e76\u5c06\u8def\u5f84\u79ef\u5206\u89e3\u4e0e\u6709\u9650\u5dee\u5206\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u7406\u8bba\u5c42\u9762\uff1a\u5efa\u7acb\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u539f\u59cb\u673a\u4f1a\u7ea6\u675f\u95ee\u9898\u4e0e\u5bf9\u5076\u95ee\u9898\u4e4b\u95f4\u7684\u5f3a\u5bf9\u5076\u6027\uff1b\u6570\u503c\u5c42\u9762\uff1a\u8def\u5f84\u79ef\u5206\u6cd5\u53ef\u901a\u8fc7\u68af\u5ea6\u4e0a\u5347\u548c\u5f00\u73af\u6837\u672c\u5b9e\u73b0\u5bf9\u5076\u95ee\u9898\u7684\u6c42\u89e3\uff0c\u4e14\u5728\u4eff\u771f\u4e2d\u4e0e\u6709\u9650\u5dee\u5206\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "conclusion": "\u7ed9\u51fa\u4e00\u79cd\u5c06\u8fde\u7eed\u65f6\u95f4/\u7a7a\u95f4\u7684\u673a\u4f1a\u7ea6\u675f\u95ee\u9898\u4ee5\u5bf9\u5076-\u8def\u5f84\u79ef\u5206\u7684\u7ec4\u5408\u65b9\u5f0f\u6c42\u89e3\u7684\u7cfb\u7edf\u6846\u67b6\uff0c\u907f\u514d\u4fdd\u5b88\u8fd1\u4f3c\u5e76\u63d0\u4f9b\u53ef\u6570\u503c\u5b9e\u73b0\uff0c\u5bf9\u79fb\u52a8\u673a\u5668\u4eba\u7b49\u573a\u666f\u7684\u673a\u4f1a\u7ea6\u675f\u6700\u4f18\u63a7\u5236\u5177\u6709\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.19550", "categories": ["cs.IT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19550", "abs": "https://arxiv.org/abs/2511.19550", "authors": ["Davide Picca"], "title": "The Semiotic Channel Principle: Measuring the Capacity for Meaning in LLM Communication", "comment": null, "summary": "This paper proposes a novel semiotic framework for analyzing Large Language Models (LLMs), conceptualizing them as stochastic semiotic engines whose outputs demand active, asymmetric human interpretation. We formalize the trade-off between expressive richness (semiotic breadth) and interpretive stability (decipherability) using information-theoretic tools. Breadth is quantified as source entropy, and decipherability as the mutual information between messages and human interpretations. We introduce a generative complexity parameter (lambda) that governs this trade-off, as both breadth and decipherability are functions of lambda. The core trade-off is modeled as an emergent property of their distinct responses to $\u03bb$. We define a semiotic channel, parameterized by audience and context, and posit a capacity constraint on meaning transmission, operationally defined as the maximum decipherability by optimizing lambda. This reframing shifts analysis from opaque model internals to observable textual artifacts, enabling empirical measurement of breadth and decipherability. We demonstrate the framework's utility across four key applications: (i) model profiling; (ii) optimizing prompt/context design; (iii) risk analysis based on ambiguity; and (iv) adaptive semiotic systems. We conclude that this capacity-based semiotic approach offers a rigorous, actionable toolkit for understanding, evaluating, and designing LLM-mediated communication.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u534a\u7b26\u53f7\u6846\u67b6\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89c6\u4e3a\u968f\u673a\u534a\u7b26\u53f7\u53d1\u52a8\u673a\uff0c\u5176\u8f93\u51fa\u9700\u8981\u4eba\u7c7b\u4e3b\u52a8\u4e14\u975e\u5bf9\u79f0\u5730\u89e3\u8bfb\u3002\u4f7f\u7528\u4fe1\u606f\u7406\u8bba\u523b\u753b\u8868\u8fbe\u4e30\u5bcc\u6027\uff08\u6e90\u71b5\uff09\u4e0e\u53ef\u89e3\u8bfb\u6027\uff08\u6d88\u606f\u4e0e\u4eba\u7c7b\u89e3\u8bfb\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\uff09\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e76\u5f15\u5165\u751f\u6210\u590d\u6742\u6027\u53c2\u6570\u03bb\u6765\u9a71\u52a8\u8be5\u6743\u8861\u3002\u8fd9\u4e00\u6838\u5fc3\u5f20\u529b\u6e90\u81ea\u5b83\u4eec\u5bf9\u03bb\u7684\u4e0d\u540c\u54cd\u5e94\u3002\u5b9a\u4e49\u4e00\u4e2a\u7531\u53d7\u4f17\u548c\u60c5\u5883\u53c2\u6570\u5316\u7684\u534a\u7b26\u53f7\u901a\u9053\uff0c\u5e76\u63d0\u51fa\u610f\u4e49\u4f20\u8f93\u7684\u5bb9\u91cf\u7ea6\u675f\uff08\u901a\u8fc7\u4f18\u5316\u03bb\u5b9e\u73b0\u6700\u5927\u53ef\u89e3\u8bfb\u6027\uff09\u3002\u63d0\u4f9b\u4ece\u6a21\u578b\u5206\u6790\u5230\u53ef\u89c2\u6d4b\u6587\u672c\u7684\u53ef\u5ea6\u91cf\u6846\u67b6\uff0c\u5e76\u5728\u56db\u4e2a\u5e94\u7528\u573a\u666f\u4e2d\u6f14\u793a\u5176\u6548\u7528\uff1a\u6a21\u578b\u753b\u50cf\u3001\u63d0\u793a/\u60c5\u5883\u8bbe\u8ba1\u4f18\u5316\u3001\u57fa\u4e8e\u6b67\u4e49\u7684\u98ce\u9669\u5206\u6790\u3001\u4ee5\u53ca\u81ea\u9002\u5e94\u534a\u7b26\u53f7\u7cfb\u7edf\u3002\u7ed3\u8bba\u8ba4\u4e3a\u8be5\u5bb9\u91cf\u9a71\u52a8\u7684\u534a\u7b26\u53f7\u65b9\u6cd5\u4e3a\u7406\u89e3\u3001\u8bc4\u4f30\u548c\u8bbe\u8ba1LLM\u5a92\u4ecb\u7684\u6c9f\u901a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u683c\u3001\u53ef\u64cd\u4f5c\u7684\u5de5\u5177\u3002", "motivation": "\u9a71\u52a8\u7814\u7a76\u7684\u6838\u5fc3\u52a8\u673a\u662f\u5c06LLM\u7684\u8f93\u51fa\u7406\u89e3\u4e3a\u4e00\u79cd\u534a\u7b26\u53f7\u8fc7\u7a0b\uff0c\u5173\u6ce8\u53ef\u89c2\u6d4b\u6587\u672c\u800c\u975e\u6a21\u578b\u5185\u5728\u7ec6\u8282\uff0c\u5efa\u7acb\u4e00\u4e2a\u53ef\u91cf\u5316\u7684\u6846\u67b6\u6765\u8861\u91cf\u8868\u8fbe\u4e30\u5bcc\u6027\u4e0e\u89e3\u8bfb\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4ee5\u63d0\u9ad8\u5bf9LLM\u6c9f\u901a\u6548\u679c\u7684\u8bc4\u4f30\u4e0e\u8bbe\u8ba1\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u534a\u7b26\u53f7\u6846\u67b6\uff1a\u5c06\u8868\u8fbe\u4e30\u5bcc\u6027\u5b9a\u4e49\u4e3a\u6e90\u71b5\uff0c\u5c06 decipherability \u5b9a\u4e49\u4e3a\u6d88\u606f\u4e0e\u4eba\u7c7b\u89e3\u8bfb\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\uff1b\u5f15\u5165\u751f\u6210\u590d\u6742\u6027\u53c2\u6570\u03bb\uff0c\u5f62\u6210\u5bf9\u03bb\u7684\u4f9d\u8d56\u4ee5\u51b3\u5b9a\u6574\u4f53\u73b0\u8c61\uff1b\u5c06\u610f\u4e49\u4f20\u8f93\u5efa\u7acb\u5728\u4e00\u4e2a\u7531\u53d7\u4f17\u4e0e\u60c5\u5883\u53c2\u6570\u5316\u7684\u534a\u7b26\u53f7\u901a\u9053\u4e0a\uff0c\u5e76\u8bbe\u5b9a\u5bb9\u91cf\u7ea6\u675f\uff0c\u901a\u8fc7\u4f18\u5316\u03bb\u6765\u5b9e\u73b0\u6700\u5927\u53ef\u89e3\u8bfb\u6027\uff1b\u5f3a\u8c03\u4ece\u6a21\u578b\u5185\u90e8\u4e0d\u53ef\u89c2\u7684\u6027\u8d28\u8f6c\u5411\u5bf9\u6587\u672c\u4ea7\u51fa\u672c\u8eab\u7684\u53ef\u89c2\u6d4b\u5206\u6790\uff0c\u5e76\u63d0\u4f9b\u53ef\u7528\u4e8e\u7ecf\u9a8c\u6d4b\u91cf\u7684\u5de5\u5177\u3002", "result": "\u4f5c\u4e3a\u6846\u67b6\u6027\u5de5\u4f5c\uff0c\u8bba\u6587\u5c55\u793a\u4e86\u5728\u56db\u4e2a\u5e94\u7528\u573a\u666f\u4e2d\u7684\u6f5c\u5728\u6548\u7528\uff1a\u2460\u5bf9\u6a21\u578b\u8fdb\u884c\u753b\u50cf\uff1b\u2461\u4f18\u5316\u63d0\u793a\u4e0e\u60c5\u5883\u8bbe\u8ba1\uff1b\u2462\u57fa\u4e8e\u6a21\u7cca\u6027\u4e0e\u6b67\u4e49\u7684\u98ce\u9669\u5206\u6790\uff1b\u2463\u6784\u5efa\u81ea\u9002\u5e94\u534a\u7b26\u53f7\u7cfb\u7edf\u3002\u8fd9\u4e9b\u5e94\u7528\u5171\u540c\u4f53\u73b0\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u64cd\u4f5c\u6027\u4e0e\u666e\u904d\u6027\u3002\u4f5c\u8005\u4e3b\u5f20\u8be5\u5bb9\u91cf\u9a71\u52a8\u7684\u534a\u7b26\u53f7\u5206\u6790\u80fd\u591f\u63d0\u4f9b\u4e00\u4e2a\u4e25\u8c28\u4e14\u53ef\u6267\u884c\u7684\u5de5\u5177\u7bb1\uff0c\u7528\u4e8e\u7406\u89e3\u3001\u8bc4\u4f30\u548c\u8bbe\u8ba1LLM\u4ecb\u5bfc\u7684\u6c9f\u901a\u3002", "conclusion": "\u5bb9\u91cf\u9a71\u52a8\u7684\u534a\u7b26\u53f7\u65b9\u6cd5\u4e3a\u7406\u89e3\u3001\u8bc4\u4f30\u548c\u8bbe\u8ba1LLM-mediated\u6c9f\u901a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u683c\u4e14\u53ef\u64cd\u4f5c\u7684\u5de5\u5177\u7bb1\uff0c\u9002\u7528\u4e8e\u6a21\u578b\u753b\u50cf\u3001\u63d0\u793a\u4f18\u5316\u3001\u98ce\u9669\u5206\u6790\u548c\u81ea\u9002\u5e94\u7cfb\u7edf\u7b49\u573a\u666f\u3002"}}
{"id": "2511.19470", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19470", "abs": "https://arxiv.org/abs/2511.19470", "authors": ["Padegal Amit", "Omkar Mahesh Kashyap", "Namitha Rayasam", "Nidhi Shekhar", "Surabhi Narayan"], "title": "Quantifying Modality Contributions via Disentangling Multimodal Representations", "comment": "16 pages, 11 figures", "summary": "Quantifying modality contributions in multimodal models remains a challenge, as existing approaches conflate the notion of contribution itself. Prior work relies on accuracy-based approaches, interpreting performance drops after removing a modality as indicative of its influence. However, such outcome-driven metrics fail to distinguish whether a modality is inherently informative or whether its value arises only through interaction with other modalities. This distinction is particularly important in cross-attention architectures, where modalities influence each other's representations. In this work, we propose a framework based on Partial Information Decomposition (PID) that quantifies modality contributions by decomposing predictive information in internal embeddings into unique, redundant, and synergistic components. To enable scalable, inference-only analysis, we develop an algorithm based on the Iterative Proportional Fitting Procedure (IPFP) that computes layer and dataset-level contributions without retraining. This provides a principled, representation-level view of multimodal behavior, offering clearer and more interpretable insights than outcome-based metrics.", "AI": {"tldr": "\u7528\u90e8\u5206\u4fe1\u606f\u5206\u89e3\uff08PID\uff09\u6765\u5206\u89e3\u591a\u6a21\u6001\u6a21\u578b\u5185\u90e8\u5d4c\u5165\u7684\u4fe1\u606f\uff0c\u533a\u5206\u72ec\u7279\u3001\u5197\u4f59\u548c\u534f\u540c\u4fe1\u606f\uff0c\u5e76\u7528\u8fed\u4ee3\u6bd4\u4f8b\u62df\u5408\uff08IPFP\uff09\u5b9e\u73b0\u65e0\u518d\u8bad\u7ec3\u7684\u63a8\u65ad\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u51c6\u786e\u7387\u7684\u5ea6\u91cf\u6df7\u6dc6\u4e86\u6a21\u6001\u672c\u8d28\u4fe1\u606f\u6027\u4e0e\u6a21\u6001\u4e4b\u95f4\u4ea4\u4e92\u5e26\u6765\u7684\u4f5c\u7528\uff0c\u9700\u8981\u4e00\u79cd\u5728\u8868\u793a\u5c42\u9762\u4e0a\u5206\u89e3\u8d21\u732e\u7684\u539f\u7406\u5316\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u8de8\u6ce8\u610f\u529b\u7ed3\u6784\u4e2d\u6a21\u6001\u76f8\u4e92\u5f71\u54cd\u7684\u60c5\u5f62\u3002", "method": "\u5c06\u90e8\u5206\u4fe1\u606f\u5206\u89e3\u5e94\u7528\u4e8e\u5185\u90e8\u5d4c\u5165\uff0c\u5206\u89e3\u9884\u6d4b\u4fe1\u606f\u4e3a\u72ec\u6709\u3001\u5197\u4f59\u4e0e\u534f\u540c\u6210\u5206\uff1b\u4e3a\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u63a8\u7406\u5206\u6790\uff0c\u5f00\u53d1\u57fa\u4e8e\u8fed\u4ee3\u6bd4\u4f8b\u62df\u5408\u7684\u7b97\u6cd5\uff0c\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u524d\u63d0\u4e0b\u8ba1\u7b97\u5c42\u7ea7\u548c\u6570\u636e\u96c6\u7ea7\u522b\u7684\u8d21\u732e\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u63a8\u7406\u5206\u6790\u65b9\u6cd5\uff0c\u4f7f\u5f97\u4ece\u8868\u793a\u5c42\u9762\u7406\u89e3\u6a21\u6001\u8d21\u732e\u6210\u4e3a\u53ef\u80fd\uff0c\u76f8\u8f83\u4e8e\u4ee5\u7ed3\u679c\u4e3a\u5bfc\u5411\u7684\u5ea6\u91cf\uff0c\u5177\u6709\u66f4\u6e05\u6670\u3001\u53ef\u89e3\u91ca\u7684\u6d1e\u5bdf\u529b\u3002", "conclusion": "\u5229\u7528PID\u5bf9\u591a\u6a21\u6001\u4ea4\u4e92\u4e2d\u7684\u6a21\u6001\u8d21\u732e\u8fdb\u884c\u8868\u793a\u5c42\u9762\u7684\u5206\u89e3\uff0c\u7ed3\u5408IPFP\u5b9e\u73b0\u7684\u65e0\u518d\u8bad\u7ec3\u5206\u6790\uff0c\u4e3a\u8de8\u6a21\u6001\u67b6\u6784\u4e2d\u7684\u72ec\u7279\u3001\u5197\u4f59\u4e0e\u534f\u540c\u4fe1\u606f\u63d0\u4f9b\u4e86 principled \u7684\u89e3\u91ca\u6846\u67b6\u3002"}}
{"id": "2511.19654", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19654", "abs": "https://arxiv.org/abs/2511.19654", "authors": ["Stephen C. Gravereaux", "Sheikh Rabiul Islam"], "title": "Accuracy and Efficiency Trade-Offs in LLM-Based Malware Detection and Explanation: A Comparative Study of Parameter Tuning vs. Full Fine-Tuning", "comment": "Accepted in IEEE Big Data 2025", "summary": "This study examines whether Low-Rank Adaptation (LoRA) fine-tuned Large Language Models (LLMs) can approximate the performance of fully fine-tuned models in generating human-interpretable decisions and explanations for malware classification. Achieving trustworthy malware detection, particularly when LLMs are involved, remains a significant challenge. We developed an evaluation framework using Bilingual Evaluation Understudy (BLEU), Recall-Oriented Understudy for Gisting Evaluation (ROUGE), and Semantic Similarity Metrics to benchmark explanation quality across five LoRA configurations and a fully fine-tuned baseline. Results indicate that full fine-tuning achieves the highest overall scores, with BLEU and ROUGE improvements of up to 10% over LoRA variants. However, mid-range LoRA models deliver competitive performance exceeding full fine-tuning on two metrics while reducing model size by approximately 81% and training time by over 80% on a LoRA model with 15.5% trainable parameters. These findings demonstrate that LoRA offers a practical balance of interpretability and resource efficiency, enabling deployment in resource-constrained environments without sacrificing explanation quality. By providing feature-driven natural language explanations for malware classifications, this approach enhances transparency, analyst confidence, and operational scalability in malware detection systems.", "AI": {"tldr": "LoRA \u5fae\u8c03\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u53ef\u89e3\u91ca\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u51b3\u7b56\u65b9\u9762\uff0c\u80fd\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u63a5\u8fd1\u5b8c\u5168\u5fae\u8c03\u6a21\u578b\u7684\u8868\u73b0\uff1b\u5b8c\u6574\u5fae\u8c03\u603b\u4f53\u5206\u6570\u6700\u9ad8\uff0c\u4f46\u4e2d\u7b49\u89c4\u6a21\u7684 LoRA \u5728\u4e24\u9879\u6307\u6807\u4e0a\u8d85\u8d8a\u5168\u91cf\u5fae\u8c03\uff0c\u540c\u65f6\u5728\u663e\u8457\u964d\u4f4e\u6a21\u578b\u89c4\u6a21\uff08\u7ea681% \u53c2\u6570\uff09\u4e0e\u8bad\u7ec3\u65f6\u95f4\uff08>80%\uff09\u7684\u60c5\u51b5\u4e0b\u4fdd\u6301\u7ade\u4e89\u529b\uff0c15.5%\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u6bd4\u4f8b\u5b9e\u73b0\u4e86\u8f83\u9ad8\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u5f15\u5165\u53ef\u89e3\u91ca\u6027\u4e0e\u53ef\u4fe1\u5ea6\u7684\u6311\u6218\uff0c\u6bd4\u8f83\u5168\u5fae\u8c03\u4e0e LoRA \u5fae\u8c03\u5728\u89e3\u91ca\u8d28\u91cf\u4e0e\u8d44\u6e90\u6548\u7387\u4e0a\u7684\u6743\u8861\uff0c\u4ee5\u4fbf\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e94\u79cd LoRA \u914d\u7f6e\u4e0e\u4e00\u4e2a\u5168\u5fae\u8c03\u57fa\u7ebf\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8e BLEU\u3001ROUGE \u548c\u8bed\u4e49\u76f8\u4f3c\u6027\u7b49\u6307\u6807\u5bf9\u89e3\u91ca\u8d28\u91cf\u8fdb\u884c\u57fa\u51c6\u8bc4\u6d4b\uff1b\u6bd4\u8f83\u4e0d\u540c\u914d\u7f6e\u5728\u201c\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u4e0e\u89e3\u91ca\u201d\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5168\u5fae\u8c03\u5728\u603b\u4f53\u8bc4\u5206\u4e0a\u6700\u9ad8\uff0cBLEU \u4e0e ROUGE \u76f8\u5bf9 LoRA \u7684\u63d0\u5347\u53ef\u8fbe\u7ea610%\uff1b\u4e2d\u7b49\u89c4\u6a21\u7684 LoRA \u6a21\u578b\u5728\u4e24\u9879\u6307\u6807\u4e0a\u8d85\u8fc7\u5168\u5fae\u8c03\uff0c\u4e14\u5728\u53c2\u6570\u89c4\u6a21\u4e0b\u964d\u7ea681%\u3001\u8bad\u7ec3\u65f6\u95f4\u964d\u4f4e>80%\u7684\u524d\u63d0\u4e0b\uff0c\u4ecd\u4fdd\u6301\u7ade\u4e89\u529b\uff08\u4ee5\u4e00\u4e2a 15.5% \u53ef\u8bad\u7ec3\u53c2\u6570\u7684 LoRA \u6a21\u578b\u4e3a\u4f8b\uff09\u3002", "conclusion": "LoRA \u4e3a\u89e3\u91ca\u6027\u4e0e\u8d44\u6e90\u6548\u7387\u4e4b\u95f4\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6298\u8877\uff0c\u9002\u5408\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u90e8\u7f72\uff0c\u540c\u65f6\u4ecd\u80fd\u63d0\u4f9b\u53ef\u89e3\u91ca\u4e14\u5177\u6709\u8f83\u597d\u900f\u660e\u5ea6\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u89e3\u91ca\uff0c\u63d0\u5347\u5206\u6790\u5e08\u4fe1\u5fc3\u4e0e\u7cfb\u7edf\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.19556", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.19556", "abs": "https://arxiv.org/abs/2511.19556", "authors": ["Yanxiao Liu"], "title": "One-Shot Coding and Applications", "comment": "A Thesis for the Degree of Doctor of Philosophy in Information Engineering, The Chinese University of Hong Kong", "summary": "One-shot information theory addresses scenarios in source coding and channel coding where the signal blocklength is assumed to be 1. In this case, each source and channel can be used only once, and the sources and channels are arbitrary and not required to be memoryless or ergodic. We study the achievability part of one-shot information theory, i.e., we consider explicit coding schemes in the oneshot scenario. The objective is to derive one-shot achievability results that can imply existing (first-order and second-order) asymptotic results when applied to memoryless sources and channels, or applied to systems with memory that behave ergodically.\n  Poisson functional representation was first proposed as a one-shot channel simulation technique by Li and El Gamal [118] for proving a strong functional representation lemma. It was later extended to the Poisson matching lemma by Li and Anantharam [117], which provided a unified one-shot coding scheme for a broad class of information-theoretic problems. The main contribution of this thesis is to extend the applicability of Poisson functional representation to various more complicated scenarios, where the original version cannot be applied directly and further extensions must be developed.", "AI": {"tldr": "\u8be5\u6458\u8981\u63cf\u8ff0\u4e86\u4e00\u79cd\u9762\u5411\u201c\u4e00\u6b21\u4fe1\u606f\u8bba\u201d\u7684 achievability \u7814\u7a76\u6846\u67b6\uff0c\u5229\u7528\u6cca\u677e\u51fd\u6570\u8868\u793a\u4ee5\u53ca\u6cca\u677e\u5339\u914d\u5f15\u7406\uff0c\u5c06\u4e00\u7c7b\u7edf\u4e00\u7684\u4e00\u6b21\u6027\u7f16\u7801\u65b9\u6848\u6269\u5c55\u5230\u66f4\u590d\u6742\u573a\u666f\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u5bf9\u7167\u5e76\u63a8\u5bfc\u51fa\u5bf9\u8bb0\u5fc6\u6027\u6216\u904d\u5386\u6027\u7cfb\u7edf\u7684\u6e10\u8fd1\u7ed3\u8bba\u3002", "motivation": "\u65e8\u5728\u7ed9\u51fa\u660e\u786e\u7684\u4e00\u6b21\u6027 achievability \u7ed3\u679c\uff0c\u8fd9\u4e9b\u7ed3\u679c\u80fd\u591f\u5728\u5bf9\u8bb0\u5fc6\u65e0\u5173\u6216\u904d\u5386\u7cfb\u7edf\u5e94\u7528\u65f6\u63a8\u5bfc\u51fa\u4e00\u9636\u3001\u4e8c\u9636\u7b49\u6e10\u8fd1\u7ed3\u8bba\uff1b\u540c\u65f6\u901a\u8fc7\u6269\u5c55\u6cca\u677e\u57fa\u65b9\u6cd5\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u4fe1\u606f\u5904\u7406\u573a\u666f\u3002", "method": "\u56de\u987e\u5e76\u6269\u5c55\u6cca\u677e\u51fd\u6570\u8868\u793a\uff08Poisson functional representation\uff09\u53ca\u5176\u76f8\u5173\u7684\u6cca\u677e\u5339\u914d\u5f15\u7406\uff08Poisson matching lemma\uff09\uff0c\u63d0\u51fa\u9002\u7528\u4e8e\u66f4\u590d\u6742\u573a\u666f\u7684\u6269\u5c55\u7248\u672c\uff0c\u5e76\u7ed9\u51fa\u5728\u4e00\u6b21\u4fe1\u606f\u5355\u4f4d\u957f\u5ea6\u60c5\u5f62\u4e0b\u7684\u663e\u5f0f\u7f16\u7801\u65b9\u6848\uff0c\u5f62\u6210\u4e00\u4e2a\u53ef\u7528\u4e8e\u591a\u7c7b\u4fe1\u606f\u8bba\u95ee\u9898\u7684\u4e00\u4f53\u5316\u6846\u67b6\u3002", "result": "\u4e3b\u8981\u8d21\u732e\u5728\u4e8e\u5c06\u6cca\u677e\u51fd\u6570\u8868\u793a\u7684\u9002\u7528\u6027\u6269\u5c55\u5230\u539f\u59cb\u7248\u672c\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u7684\u66f4\u590d\u6742\u60c5\u5883\uff0c\u8fdb\u800c\u53d1\u5c55\u51fa\u66f4\u5e7f\u6cdb\u7684\u4e00\u6b21\u6027\u7f16\u7801\u65b9\u6848\u7684\u7edf\u4e00\u65b9\u6cd5\uff0c\u80fd\u591f\u8986\u76d6\u591a\u79cd\u4fe1\u606f\u8bba\u95ee\u9898\u7684\u5355\u6b21\u5206\u6790\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u4e00\u6b21\u4fe1\u606f\u8bba\u4e2d\u7684\u8bc1\u660e\u5de5\u5177\u7bb1\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u9002\u7528\u6027\uff0c\u5efa\u7acb\u4e86\u4ece\u4e00\u6b21\u6027\u53ef\u8bc1\u660e\u7684 achievability \u63a8\u5bfc\u6e10\u8fd1\u7ed3\u679c\u7684\u9014\u5f84\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5177\u6709\u8bb0\u5fc6\u6216\u975e\u7b80\u5355\u7edf\u8ba1\u7279\u6027\u7684\u7cfb\u7edf\u7684\u5206\u6790\u3002"}}
{"id": "2511.19472", "categories": ["cs.LG", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.19472", "abs": "https://arxiv.org/abs/2511.19472", "authors": ["Ruogu Ding", "Xin Ning", "Ulf Schlichtmann", "Weikang Qian"], "title": "PrefixGPT: Prefix Adder Optimization by a Generative Pre-trained Transformer", "comment": "An extended version that has been accepted by AAAI-2026 conference", "summary": "Prefix adders are widely used in compute-intensive applications for their high speed. However, designing optimized prefix adders is challenging due to strict design rules and an exponentially large design space. We introduce PrefixGPT, a generative pre-trained Transformer (GPT) that directly generates optimized prefix adders from scratch. Our approach represents an adder's topology as a two-dimensional coordinate sequence and applies a legality mask during generation, ensuring every design is valid by construction. PrefixGPT features a customized decoder-only Transformer architecture. The model is first pre-trained on a corpus of randomly synthesized valid prefix adders to learn design rules and then fine-tuned to navigate the design space for optimized design quality. Compared with existing works, PrefixGPT not only finds a new optimal design with a 7.7% improved area-delay product (ADP) but exhibits superior exploration quality, lowering the average ADP by up to 79.1%. This demonstrates the potential of GPT-style models to first master complex hardware design principles and then apply them for more efficient design optimization.", "AI": {"tldr": "PrefixGPT \u4f7f\u7528GPT\u67b6\u6784\u76f4\u63a5\u4ece\u5934\u751f\u6210\u4f18\u5316\u7684\u524d\u7f00\u52a0\u6cd5\u5668\uff0c\u901a\u8fc7\u5c06\u62d3\u6251\u8868\u793a\u4e3a\u4e8c\u7ef4\u5750\u6807\u5e8f\u5217\u5e76\u5f15\u5165\u5408\u6cd5\u6027\u63a9\u7801\u786e\u4fdd\u8bbe\u8ba1\u5728\u751f\u6210\u65f6\u5c31\u6709\u6548\u3002\u91c7\u7528\u89e3\u7801\u5668\u5f0fTransformer\uff0c\u5148\u5728\u968f\u673a\u5408\u6210\u7684\u6709\u6548\u524d\u7f00\u52a0\u6cd5\u5668\u5e93\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u518d\u5fae\u8c03\u4ee5\u63d0\u5347\u8bbe\u8ba1\u8d28\u91cf\u3002", "motivation": "\u5728\u9ad8\u901f\u524d\u7f00\u52a0\u6cd5\u5668\u8bbe\u8ba1\u4e2d\uff0c\u8bbe\u8ba1\u7a7a\u95f4\u5e9e\u5927\u4e14\u53d7\u4e25\u683c\u89c4\u5219\u7ea6\u675f\uff0c\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u96be\u4ee5\u9ad8\u6548\u63a2\u7d22\u5e76\u627e\u5230\u5168\u5c40\u6700\u4f18\u89e3\u3002", "method": "\u5c06\u52a0\u6cd5\u5668\u7684\u62d3\u6251\u8868\u793a\u4e3a\u4e8c\u7ef4\u5750\u6807\u5e8f\u5217\uff0c\u751f\u6210\u9636\u6bb5\u5e94\u7528 legality mask\uff08\u5408\u6cd5\u6027\u63a9\u7801\uff09\u786e\u4fdd\u6bcf\u4e00\u6b65\u751f\u6210\u7684\u8bbe\u8ba1\u90fd\u662f\u6709\u6548\u7684\uff1b\u4f7f\u7528\u5b9a\u5236\u7684\u89e3\u7801\u5668\u5f0fTransformer\u67b6\u6784\uff0c\u5148\u8fdb\u884c\u5bf9\u968f\u673a\u5408\u6210\u7684\u6709\u6548\u524d\u7f00\u52a0\u6cd5\u5668\u8fdb\u884c\u9884\u8bad\u7ec3\u4ee5\u638c\u63e1\u8bbe\u8ba1\u89c4\u5f8b\uff0c\u7136\u540e\u5728\u76ee\u6807\u8bbe\u8ba1\u7a7a\u95f4\u4e0a\u8fdb\u884c\u5fae\u8c03\u4ee5\u63d0\u9ad8\u4f18\u5316\u8d28\u91cf\u3002", "result": "\u76f8\u8f83\u4e8e\u73b0\u6709\u5de5\u4f5c\uff0cPrefixGPT \u627e\u5230\u4e86\u65b0\u7684\u6700\u4f18\u8bbe\u8ba1\uff0cADP \u63d0\u5347\u7ea67.7%\uff0c\u5e76\u4e14\u5728\u63a2\u7d22\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u51fa\u66f4\u4f4e\u7684\u5e73\u5747ADP\uff0c\u964d\u4f4e\u5e45\u5ea6\u9ad8\u8fbe79.1%\u3002", "conclusion": "\u8bc1\u660e\u4e86GPT\u98ce\u683c\u6a21\u578b\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u6f5c\u529b\uff1a\u5148\u638c\u63e1\u590d\u6742\u8bbe\u8ba1\u539f\u5219\uff0c\u518d\u7528\u4e8e\u9ad8\u6548\u7684\u8bbe\u8ba1\u4f18\u5316\u3002"}}
{"id": "2511.19670", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.19670", "abs": "https://arxiv.org/abs/2511.19670", "authors": ["Luis Ferreirinha", "Iberia Medeiros"], "title": "BASICS: Binary Analysis and Stack Integrity Checker System for Buffer Overflow Mitigation", "comment": "17 pages, Submitted to IEEE Transactions on Reliability", "summary": "Cyber-Physical Systems have played an essential role in our daily lives, providing critical services such as power and water, whose operability, availability, and reliability must be ensured. The C programming language, prevalent in CPS development, is crucial for system control where reliability is critical. However, it is also commonly susceptible to vulnerabilities, particularly buffer overflows. Traditional vulnerability discovery techniques often struggle with scalability and precision when applied directly to the binary code of C programs, which can thereby keep programs vulnerable. This work introduces a novel approach designed to overcome these limitations by leveraging model checking and concolic execution techniques to automatically verify security properties of a program's stack memory in binary code, trampoline techniques to perform automated repair of the issues, and crash-inducing inputs to verify if they were successfully removed. The approach constructs a Memory State Space - MemStaCe- from the binary program's control flow graph and simulations, provided by concolic execution, of C function calls and loop constructs. The security properties, defined in LTL, model the correct behaviour of functions associated with vulnerabilities and allow the approach to identify vulnerabilities in MemStaCe by analysing counterexample traces that are generated when a security property is violated. These vulnerabilities are then addressed with a trampoline-based binary patching method, and the effectiveness of the patches is checked with crash-inducing inputs extracted during concolic execution. We implemented the approach in the BASICS tool for BO mitigation and evaluated using the Juliet C/C++ and SARD datasets and real applications, achieving an accuracy and precision above 87%, both in detection and correction. Also, we compared it with CWE Checker, outperforming it.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e MemStaCe \u7684\u4e8c\u8fdb\u5236\u7ea7\u6f0f\u6d1e\u53d1\u73b0\u4e0e\u4fee\u590d\u6846\u67b6\uff0c\u7ed3\u5408\u6a21\u578b\u68c0\u67e5\u4e0e\u6df7\u5408\u6267\u884c\uff0c\u5229\u7528 trampoline \u8865\u4e01\u548c crash-inducing \u8f93\u5165\u9a8c\u8bc1\uff0c\u5728 BASICS \u5de5\u5177\u4e2d\u5b9e\u73b0\u5e76\u5728 Juliet/SARD \u6570\u636e\u96c6\u53ca\u5b9e\u9645\u5e94\u7528\u4e2d\u8fbe\u5230\u7ea6 87% \u4ee5\u4e0a\u7684\u68c0\u6d4b\u4e0e\u4fee\u590d\u51c6\u786e\u6027\uff0c\u4f18\u4e8e CWE Checker\u3002", "motivation": "CPS \u5bf9\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7684\u4f9d\u8d56\u9700\u8981\u9ad8\u53ef\u9760\u6027\uff0c\u4f46\u7528 C \u7f16\u5199\u7684 CPS \u8f6f\u4ef6\u6613\u53d7\u7f13\u51b2\u533a\u6ea2\u51fa\u7b49\u6f0f\u6d1e\u5f71\u54cd\uff0c\u4f20\u7edf\u4e8c\u8fdb\u5236\u6f0f\u6d1e\u53d1\u73b0\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u51c6\u786e\u6027\u65b9\u9762\u5b58\u5728\u74f6\u9888\uff0c\u9700\u65e0\u7f1d\u7684\u81ea\u52a8\u5316\u9a8c\u8bc1\u4e0e\u4fee\u590d\u65b9\u6cd5\u3002", "method": "\u6784\u5efa Memory State Space MemStaCe\uff0c\u57fa\u4e8e\u4e8c\u8fdb\u5236\u7a0b\u5e8f\u7684\u63a7\u5236\u6d41\u56fe\u548c concolic \u6267\u884c\u5bf9 C \u51fd\u6570\u8c03\u7528\u4e0e\u5faa\u73af\u8fdb\u884c\u6a21\u62df\uff1b\u4f7f\u7528 LTL \u5f62\u5f0f\u5316\u5b89\u5168\u5c5e\u6027\u4ee5\u5efa\u6a21\u4e0e\u6f0f\u6d1e\u76f8\u5173\u51fd\u6570\u7684\u6b63\u786e\u884c\u4e3a\uff1b\u901a\u8fc7\u5bf9\u4e0d\u6ee1\u8db3\u5c5e\u6027\u7684 counterexample \u8def\u5f84\u8bc6\u522b\u6f0f\u6d1e\uff1b\u4ee5 trampoline \u57fa\u4e8e\u7684\u4e8c\u8fdb\u5236\u8865\u4e01\u4fee\u590d\u6f0f\u6d1e\u5e76\u7528\u901a\u8fc7 concolic \u8fd0\u884c\u751f\u6210\u7684 crash-inducing \u8f93\u5165\u6765\u9a8c\u8bc1\u4fee\u590d\u6548\u679c\uff1b\u6700\u7ec8\u5728 BASICS \u5de5\u5177\u4e2d\u5b9e\u73b0\u5e76\u5bf9\u516c\u5f00\u6570\u636e\u96c6\u4e0e\u5b9e\u9645\u5e94\u7528\u8bc4\u4f30\u3002", "result": "\u5728 Juliet C/C++\u3001SARD \u6570\u636e\u96c6\u53ca\u771f\u5b9e\u5e94\u7528\u4e0a\uff0c\u68c0\u6d4b\u4e0e\u4fee\u590d\u7684\u51c6\u786e\u6027\u4e0e\u7cbe\u786e\u6027\u5747\u8d85\u8fc7 87%\uff1b\u5e76\u4e14\u5728\u4e0e CWE Checker \u7684\u5bf9\u6bd4\u4e2d\u5b9e\u73b0\u4e86\u4f18\u8d8a\u8868\u73b0\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5bf9\u4e8c\u8fdb\u5236\u7ea7\u6f0f\u6d1e\u7684\u81ea\u52a8\u5206\u6790\u3001\u4fee\u590d\u4e0e\u9a8c\u8bc1\uff0c\u63d0\u5347\u4e86 CPS \u8f6f\u4ef6\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u5b89\u5168\u6027\u4e0e\u53ef\u9760\u6027\uff0c\u5e76\u5bf9\u73b0\u6709\u68c0\u6d4b\u5de5\u5177\u63d0\u4f9b\u4e86\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2511.19943", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19943", "abs": "https://arxiv.org/abs/2511.19943", "authors": ["Akash Doshi", "Pinar Sen", "Kirill Ivanov", "Wei Yang", "June Namgoong", "Runxin Wang", "Rachel Wang", "Taesang Yoo", "Jing Jiang", "Tingfang Ji"], "title": "AI/ML based Joint Source and Channel Coding for HARQ-ACK Payload", "comment": "39 pages, 15 figures. Under consideration for publication in Journal of Sel. Areas in Information Theory. This paper was presented in part at the International Symposium on Topics in Coding, August 2025 in the Session for Coding and AI", "summary": "Channel coding from 2G to 5G has assumed the inputs bits at the physical layer to be uniformly distributed. However, hybrid automatic repeat request acknowledgement (HARQ-ACK) bits transmitted in the uplink are inherently non-uniformly distributed. For such sources, significant performance gains could be obtained by employing joint source channel coding, aided by deep learning-based techniques. In this paper, we learn a transformer-based encoder using a novel \"free-lunch\" training algorithm and propose per-codeword power shaping to exploit the source prior at the encoder whilst being robust to small changes in the HARQ-ACK distribution. Furthermore, any HARQ-ACK decoder has to achieve a low negative acknowledgement (NACK) error rate to avoid radio link failures resulting from multiple NACK errors. We develop an extension of the Neyman-Pearson test to a coded bit system with multiple information bits to achieve Unequal Error Protection of NACK over ACK bits at the decoder. Finally, we apply the proposed encoder and decoder designs to a 5G New Radio (NR) compliant uplink setup under a fading channel, describing the optimal receiver design and a low complexity coherent approximation to it. Our results demonstrate 3-6 dB reduction in the average transmit power required to achieve the target error rates compared to the NR baseline, while also achieving a 2-3 dB reduction in the maximum transmit power, thus providing for significant coverage gains and power savings.", "AI": {"tldr": "\u9762\u5411 HARQ-ACK \u975e\u5747\u5300\u5206\u5e03\u7684\u4e0a\u884c\u4fe1\u9053\u7f16\u7801\uff1a\u57fa\u4e8e Transformer \u7684\u8054\u5408\u6e90\u901a\u9053\u7f16\u7801\u3001\u6bcf\u7801\u5b57\u529f\u7387\u6574\u5f62\u548c\u57fa\u4e8e Neyman-Pearson \u7684 NACK \u4fdd\u62a4\uff0c\u9002\u7528\u4e8e 5G NR \u4e0a\u884c\uff0c\u5728\u8870\u843d\u4fe1\u9053\u4e0b\u5b9e\u73b0\u8f83\u57fa\u7ebf\u663e\u8457\u7684\u529f\u7387\u8282\u7701\u3002", "motivation": "\u8003\u8651\u5230\u4e0a\u884c HARQ-ACK \u4f4d\u662f\u975e\u5747\u5300\u5206\u5e03\uff0c\u4f20\u7edf\u5047\u8bbe\u8f93\u5165\u4e3a\u5747\u5300\u5206\u5e03\u5bfc\u81f4\u7684\u8d44\u6e90\u6d6a\u8d39\uff0c\u63d0\u51fa\u5229\u7528\u6e90\u5148\u9a8c\u4fe1\u606f\u8fdb\u884c\u8054\u5408\u6e90\u901a\u9053\u7f16\u7801\u4ee5\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u786e\u4fdd NACK \u7684\u4f4e\u8bef\u7801\u7387\u4ee5\u907f\u514d\u91cd\u4f20\u5931\u8d25\uff0c\u540c\u65f6\u63d0\u5347\u8986\u76d6\u548c\u529f\u7387\u6548\u7387\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e Transformer \u7684\u7f16\u7801\u5668\uff0c\u4f7f\u7528\u65b0\u9896\u7684\u201cfree-lunch\u201d\u8bad\u7ec3\u7b97\u6cd5\uff1b\u5f15\u5165\u9010\u7801\u5b57\u529f\u7387\u6574\u5f62\u4ee5\u5229\u7528\u6e90\u5206\u5e03\u4e14\u5bf9 HARQ-ACK \u5206\u5e03\u53d8\u5316\u9c81\u68d2\uff1b\u5c06 Neyman-Pearson \u6d4b\u8bd5\u6269\u5c55\u5230\u5177\u6709\u591a\u4fe1\u606f\u6bd4\u7279\u7684\u7f16\u7801\u4f4d\u7cfb\u7edf\uff0c\u5b9e\u73b0 ACK/NACK \u7684\u4e0d\u7b49\u9519\u8bef\u4fdd\u62a4\uff08UEP\uff09\uff1b\u5c06\u8bbe\u8ba1\u5e94\u7528\u4e8e\u7b26\u5408 5G NR \u7684\u4e0a\u884c\u65e0\u7ebf\u573a\u666f\uff0c\u7ed9\u51fa\u63a5\u6536\u7aef\u7684\u6700\u4f18\u63a5\u6536\u673a\u548c\u4f4e\u590d\u6742\u5ea6\u76f8\u5e72\u8fd1\u4f3c\u3002", "result": "\u4e0e NR \u57fa\u7ebf\u76f8\u6bd4\uff0c\u5728\u8fbe\u5230\u76ee\u6807\u8bef\u7801\u7387\u7684\u524d\u63d0\u4e0b\uff0c\u5e73\u5747\u53d1\u9001\u529f\u7387\u964d\u4f4e 3\u20136 dB\uff1b\u6700\u5927\u53d1\u9001\u529f\u7387\u964d\u4f4e 2\u20133 dB\uff0c\u663e\u8457\u63d0\u5347\u8986\u76d6\u548c\u529f\u7387\u6548\u7387\u3002", "conclusion": "\u8bc1\u660e\u5728 5G NR \u4e0a\u884c\u8870\u843d\u4fe1\u9053\u4e2d\uff0c\u7ed3\u5408 DL \u7aef\u5230\u7aef\u7684\u8054\u5408\u6e90\u901a\u9053\u7f16\u7801\u3001\u529f\u7387\u6574\u5f62\u4ee5\u53ca UEP \u673a\u5236\uff0c\u80fd\u591f\u5728\u663e\u8457\u964d\u4f4e\u5e73\u5747\u548c\u6700\u5927\u529f\u7387\u7684\u540c\u65f6\u7ef4\u6301\u76ee\u6807\u8bef\u7801\u7387\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u6f5c\u529b\uff1b\u672a\u6765\u5de5\u4f5c\u5305\u62ec\u5728\u66f4\u5e7f\u6cdb\u7684\u573a\u666f\u4e0b\u9a8c\u8bc1\u9c81\u68d2\u6027\u3001\u964d\u4f4e\u590d\u6742\u5ea6\u5e76\u8bc4\u4f30\u6807\u51c6\u5316\u5f71\u54cd\u3002"}}
{"id": "2511.19473", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19473", "abs": "https://arxiv.org/abs/2511.19473", "authors": ["Haojin Yang", "Rui Hu", "Zequn Sun", "Rui Zhou", "Yujun Cai", "Yiwei Wang"], "title": "WavefrontDiffusion: Dynamic Decoding Schedule or Improved Reasoning", "comment": "19 pages. 3 figures", "summary": "Diffusion Language Models (DLMs) have shown strong potential for text generation and are becoming a competitive alternative to autoregressive models. The denoising strategy plays an important role in determining the quality of their outputs. Mainstream denoising strategies include Standard Diffusion and BlockDiffusion. Standard Diffusion performs global denoising without restricting the update range, often finalizing incomplete context and causing premature end-of-sequence predictions. BlockDiffusion updates fixed-size blocks in a preset order, but its rigid structure can break apart coherent semantic units and disrupt reasoning. We present WavefrontDiffusion, a dynamic decoding approach that expands a wavefront of active tokens outward from finalized positions. This adaptive process follows the natural flow of semantic structure while keeping computational cost equal to block-based methods. Across four benchmarks in reasoning and code generation, WavefrontDiffusion achieves state-of-the-art performance while producing outputs with higher semantic fidelity, showing the value of adaptive scheduling for more coherent and efficient generation.", "AI": {"tldr": "\u63d0\u51fa WavefrontDiffusion\uff0c\u4e00\u79cd\u52a8\u6001\u89e3\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u5df2\u786e\u5b9a\u4f4d\u7f6e\u5411\u5916\u6269\u5c55\u7684\u6ce2\u524d\u6765\u66f4\u65b0\uff0c\u8fbe\u5230\u6bd4\u6807\u51c6\u6269\u6563\u548c BlockDiffusion \u66f4\u9ad8\u7684\u8bed\u4e49\u4fdd\u771f\u5ea6\u4e0e\u6027\u80fd\uff0c\u5728\u56db\u4e2a\u63a8\u7406\u4e0e\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u4e0a\u8fbe\u5230\u6700\u4f18\u3002", "motivation": "\u73b0\u6709\u53bb\u566a\u7b56\u7565\uff08\u6807\u51c6\u6269\u6563\u4e0e BlockDiffusion\uff09\u5728\u751f\u6210\u8d28\u91cf\u4e0a\u5404\u6709\u5c40\u9650\uff1a\u524d\u8005\u53ef\u80fd\u5bfc\u81f4\u4e0a\u4e0b\u6587\u4e0d\u5b8c\u6574\u548c\u63d0\u524d\u7ed3\u675f\uff0c\u540e\u8005\u7684\u56fa\u5b9a\u5757\u7ed3\u6784\u53ef\u80fd\u7834\u574f\u8fde\u8d2f\u8bed\u4e49\u5355\u5143\u548c\u63a8\u7406\u8fc7\u7a0b\u3002\u9700\u8981\u4e00\u79cd\u65e2\u4fdd\u6301\u6210\u672c\u3001\u53c8\u80fd\u66f4\u597d\u6355\u6349\u8bed\u4e49\u7ed3\u6784\u7684\u81ea\u9002\u5e94\u53bb\u566a/\u89e3\u7801\u7b56\u7565\u3002", "method": "\u63d0\u51fa WavefrontDiffusion\uff1a\u4e00\u79cd\u52a8\u6001\u89e3\u7801\u65b9\u6cd5\uff0c\u4ece\u5df2\u5b8c\u6210\u4f4d\u7f6e\u5411\u5916\u6269\u5c55\u6ce2\u524d\u7684\u6d3b\u52a8\u6807\u8bb0\uff0c\u6309\u81ea\u9002\u5e94\u8c03\u5ea6\u66f4\u65b0\uff0c\u4fdd\u6301\u8ba1\u7b97\u6210\u672c\u7b49\u540c\u4e8e\u57fa\u4e8e\u5757\u7684\u65b9\u6cd5\u3002\u8be5\u7b56\u7565\u4e0e\u8bed\u4e49\u7ed3\u6784\u7684\u81ea\u7136\u6d41\u5411\u4e00\u81f4\uff0c\u63d0\u5347\u8f93\u51fa\u7684\u8fde\u8d2f\u6027\u3002", "result": "\u5728\u56db\u4e2a\u63a8\u7406\u4e0e\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8f93\u51fa\u5177\u6709\u66f4\u9ad8\u7684\u8bed\u4e49\u4fdd\u771f\u5ea6\uff0c\u8bc1\u660e\u81ea\u9002\u5e94\u8c03\u5ea6\u5bf9\u4e8e\u66f4\u8fde\u8d2f\u4e14\u9ad8\u6548\u7684\u751f\u6210\u6709\u663e\u8457\u4ef7\u503c\u3002", "conclusion": "\u81ea\u9002\u5e94\u8c03\u5ea6\u7684\u89e3\u7801\u7b56\u7565\uff0c\u5982 WavefrontDiffusion\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u8ba1\u7b97\u6210\u672c\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u751f\u6210\u7684\u8fde\u8d2f\u6027\u4e0e\u8bed\u4e49\u4fdd\u771f\u5ea6\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.19711", "categories": ["cs.CR", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.19711", "abs": "https://arxiv.org/abs/2511.19711", "authors": ["Jinyu Liu", "Gang Tan", "Kiwan Maeng"], "title": "CrypTorch: PyTorch-based Auto-tuning Compiler for Machine Learning with Multi-party Computation", "comment": "28 pages, 17 figures. Submitted to PLDI 2026", "summary": "Machine learning (ML) involves private data and proprietary model parameters. MPC-based ML allows multiple parties to collaboratively run an ML workload without sharing their private data or model parameters using multi-party computing (MPC). Because MPC cannot natively run ML operations such as Softmax or GELU, existing frameworks use different approximations. Our study shows that, on a well-optimized framework, these approximations often become the dominating bottleneck. Popular approximations are often insufficiently accurate or unnecessarily slow, and these issues are hard to identify and fix in existing frameworks. To tackle this issue, we propose a compiler for MPC-based ML, CrypTorch. CrypTorch disentangles these approximations with the rest of the MPC runtime, allows easily adding new approximations through its programming interface, and automatically selects approximations to maximize both performance and accuracy. Built as an extension to PyTorch 2's compiler, we show that CrypTorch's auto-tuning alone provides 1.20--1.7$\\times$ immediate speedup without sacrificing accuracy, and 1.31--1.8$\\times$ speedup when some accuracy degradation is allowed, compared to our well-optimized baseline. Combined with better engineering and adoption of state-of-the-art practices, the entire framework brings 3.22--8.6$\\times$ end-to-end speedup compared to the popular framework, CrypTen.", "AI": {"tldr": "CrypTorch \u662f\u4e00\u4e2a\u9762\u5411 MPC-based \u673a\u5668\u5b66\u4e60\u7684\u7f16\u8bd1\u5668\uff0c\u80fd\u591f\u5c06\u8fd1\u4f3c\u5b9e\u73b0\uff08\u5982 Softmax\u3001GELU\uff09\u4e0e MPC \u8fd0\u884c\u65f6\u89e3\u8026\u5e76\u81ea\u52a8\u9009\u62e9\u4ee5\u5728\u6027\u80fd\u548c\u51c6\u786e\u5ea6\u4e4b\u95f4\u5b9e\u73b0\u6298\u4e2d\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u7aef\u5230\u7aef\u6027\u80fd\uff0c\u76f8\u8f83 CrypTen \u5177\u6709\u66f4\u5927\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u6846\u67b6\u5728\u5b9e\u73b0 MPC \u673a\u5668\u5b66\u4e60\u65f6\u5bf9 Softmax\u3001GELU \u7b49\u8fd0\u7b97\u91c7\u7528\u8fd1\u4f3c\uff0c\u5bfc\u81f4\u6210\u4e3a\u6027\u80fd\u74f6\u9888\uff1b\u8fd9\u4e9b\u8fd1\u4f3c\u5f80\u5f80\u4e0d\u591f\u51c6\u786e\u6216\u8fc7\u6162\uff0c\u4e14\u96be\u4ee5\u5728\u73b0\u6709\u6846\u67b6\u5185\u5b9a\u4f4d\u4e0e\u4fee\u590d\u3002\u9700\u8981\u4e00\u4e2a\u80fd\u628a\u8fd1\u4f3c\u4e0e MPC \u8fd0\u884c\u65f6\u89e3\u8026\u3001\u53ef\u6269\u5c55\u5e76\u81ea\u52a8\u4f18\u5316\u8fd1\u4f3c\u9009\u62e9\u7684\u7f16\u8bd1\u5668\uff0c\u4ee5\u63d0\u5347\u6027\u80fd\u4e0e\u51c6\u786e\u6027\u3002", "method": "\u6784\u5efa\u4e3a PyTorch 2 \u7f16\u8bd1\u5668\u7684\u6269\u5c55 CrypTorch\uff0c\u901a\u8fc7\u5c06\u8fd1\u4f3c\u8fd0\u7b97\u4e0e MPC \u8fd0\u884c\u65f6\u89e3\u8026\u3001\u63d0\u4f9b\u6613\u6269\u5c55\u7684\u8fd1\u4f3c\u63a5\u53e3\u3001\u5e76\u5b9e\u73b0\u81ea\u52a8\u9009\u53d6\u7b56\u7565\u6765\u5728\u6027\u80fd\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u505a\u6743\u8861\u3002\u8be5\u6846\u67b6\u8fd8\u5177\u5907\u81ea\u52a8\u8c03\u4f18\u80fd\u529b\uff0c\u5728\u5b9e\u9645\u57fa\u7ebf\u57fa\u51c6\u4e0a\u8fdb\u884c\u7aef\u5230\u7aef\u4f18\u5316\u3002", "result": "\u81ea\u52a8\u8c03\u4f18\u672c\u8eab\u5373\u53ef\u5728\u4e0d\u635f\u5931\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\u5e26\u67651.20\u20131.7\u00d7\u7684\u5373\u65f6\u52a0\u901f\uff1b\u5728\u5141\u8bb8\u4e00\u5b9a\u7cbe\u5ea6\u4e0b\u964d\u65f6\u53ef\u8fbe1.31\u20131.8\u00d7\u7684\u52a0\u901f\uff1b\u76f8\u6bd4\u6d41\u884c\u6846\u67b6 CrypTen\uff0c\u7aef\u5230\u7aef\u53ef\u5b9e\u73b03.22\u20138.6\u00d7\u7684\u52a0\u901f\u3002", "conclusion": "\u5c06\u8fd1\u4f3c\u8fd0\u7b97\u4ece MPC \u8fd0\u884c\u65f6\u4e2d\u89e3\u8026\u5e76\u4ee5\u7f16\u8bd1\u5668\u5c42\u5b9e\u73b0\u81ea\u52a8\u5316\u7684\u8fd1\u4f3c\u9009\u62e9\uff0c\u80fd\u663e\u8457\u63d0\u5347\u57fa\u4e8e MPC \u7684\u673a\u5668\u5b66\u4e60\u7684\u6027\u80fd\uff1b\u7ed3\u5408\u66f4\u5f3a\u7684\u5de5\u7a0b\u5b9e\u8df5\u4e0e\u524d\u6cbf\u5b9e\u8df5\uff0cCrypTorch \u4e3a\u7aef\u5230\u7aef\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u529b\u7684\u6846\u67b6\u548c\u65b9\u6cd5\u3002"}}
{"id": "2511.20000", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.20000", "abs": "https://arxiv.org/abs/2511.20000", "authors": ["Mingyi Lu", "Guowei Liu", "Le Liang", "Chongtao Guo", "Hao Ye", "Shi Jin"], "title": "Cross-Modal Semantic Communication for Heterogeneous Collaborative Perception", "comment": null, "summary": "Collaborative perception, an emerging paradigm in autonomous driving, has been introduced to mitigate the limitations of single-vehicle systems, such as limited sensor range and occlusion. To improve the robustness of inter-vehicle data sharing, semantic communication has recently further been integrated into collaborative perception systems to enhance overall performance. However, practical deployment of such systems is challenged by the heterogeneity of sensors across different connected autonomous vehicles (CAVs). This diversity in perceptual data complicates the design of a unified communication framework and impedes the effective fusion of shared information. To address this challenge, we propose a novel cross-modal semantic communication (CMSC) framework to facilitate effective collaboration among CAVs with disparate sensor configurations. Specifically, the framework first transforms heterogeneous perceptual features from different sensor modalities into a unified and standardized semantic space. Subsequently, encoding, transmission, and decoding are performed within this semantic space, enabling seamless and effective information fusion. Extensive experiments demonstrate that CMSC achieves significantly stronger perception performance than existing methods, particularly in low signal-to-noise ratio (SNR) regimes.", "AI": {"tldr": "A cross-modal semantic communication (CMSC) framework for collaborative perception in connected autonomous vehicles (CAVs) that maps heterogeneous sensor features into a unified semantic space, enabling robust encoding, transmission, and fusion; it yields stronger perception performance than existing methods, especially under low SNR.", "motivation": "To overcome sensor heterogeneity across CAVs that hinders unified communication and effective information fusion in collaborative perception, aiming to improve robustness and overall perception performance.", "method": "Transform heterogeneous perceptual features from different sensor modalities into a unified semantic space; perform encoding, transmission, and decoding entirely within this semantic space to enable seamless fusion of shared information across vehicles.", "result": "CMSC achieves significantly stronger perception performance than existing methods, with especially notable gains in low signal-to-noise ratio (SNR) regimes.", "conclusion": "CMSC provides a robust cross-modal semantic representation that facilitates inter-vehicle collaboration across diverse sensors, improving perception under challenging communication conditions; practical deployment will require careful design of semantic mappings, synchronization, and bandwidth considerations."}}
{"id": "2511.19639", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.19639", "abs": "https://arxiv.org/abs/2511.19639", "authors": ["Niccol\u00f2 Brembilla", "Yinbin Ma", "Pietro Belotti", "Federico Malucelli", "Daniela Tuninetti"], "title": "Computer-aided Characterization of Fundamental Limits of Coded Caching with Linear Coding", "comment": null, "summary": "Inspired by prior work by Tian and by Cao and Xu, this paper presents an efficient computer-aided framework to characterize the fundamental limits of coded caching systems under the constraint of linear coding. The proposed framework considers non-Shannon-type inequalities which are valid for representable polymatroids (and hence for linear codes), and leverages symmetric structure and problem-specific constraints of coded caching to reduce the complexity of the linear program. The derived converse bounds are tighter compared to previous known analytic methods, and prove the optimality of some achievable memory-load tradeoff points under the constraint of linear coding placement and delivery. These results seem to indicate that small, structured demand subsets combined with minimal common information constructions may be sufficient to characterize optimal tradeoffs under linear coding.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u7535\u8111\u8f85\u52a9\u6846\u67b6\uff0c\u7528\u975e\u9999\u519c\u578b\u4e0d\u7b49\u5f0f\u5904\u7406\u53ef\u8868\u793a\u591a\u6001\u80de\u7ed3\u6784\uff08\u4ee5\u53ca\u7ebf\u6027\u7801\uff09\uff0c\u5728\u5bf9\u79f0\u6027\u548c\u95ee\u9898\u7ea6\u675f\u4e0b\u7b80\u5316LP\u6c42\u89e3\uff0c\u4ee5\u5f97\u5230\u66f4\u7d27\u7684\u7ebf\u6027\u7f16\u7801\u4e0b\u7684\u7f13\u5b58-\u52a0\u8f7d\u6743\u8861\u754c\u9650\uff0c\u5e76\u5728\u67d0\u4e9b\u60c5\u5f62\u8bc1\u660e\u4e86\u53ef\u5b9e\u73b0\u89e3\u7684\u6700\u4f18\u6027\u3002", "motivation": "\u5728\u7ebf\u6027\u7f16\u7801\u7ea6\u675f\u4e0b\u8868\u5f81\u7f16\u7801\u7f13\u5b58\u7cfb\u7edf\u7684\u57fa\u672c\u6781\u9650\uff1b\u73b0\u6709\u5206\u6790\u65b9\u6cd5\u5f80\u5f80\u4fdd\u5b88\uff0c\u96be\u4ee5\u83b7\u5f97\u7d27\u81f4\u754c\u9650\uff0c\u56e0\u6b64\u9700\u8981\u5229\u7528\u975e\u9999\u519c\u578b\u4e0d\u7b49\u5f0f\u548c\u591a\u6001\u80de\u7ed3\u6784\u6765\u63d0\u5347\u754c\u9650\uff0c\u5e76\u63a2\u8ba8\u653e\u7f6e\u4e0e\u4f20\u9001\u9636\u6bb5\u7684\u7ebf\u6027\u7f16\u7801\u4e0b\u7684\u6700\u4f18\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7535\u8111\u8f85\u52a9\u6846\u67b6\uff0c\u7ed3\u5408\u53ef\u8868\u793a\u591a\u6001\u80de\u7684\u975e\u9999\u519c\u578b\u4e0d\u7b49\u5f0f\u3001\u5bf9\u79f0\u6027\u3001\u4ee5\u53ca\u7f13\u5b58\u7f16\u7801\u95ee\u9898\u7684\u7279\u5b9a\u7ea6\u675f\uff0c\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u53d7\u63a7\u7684\u7ebf\u6027\u89c4\u5212\uff0c\u51cf\u5c11\u53d8\u91cf\u4e0e\u7ea6\u675f\uff1b\u5e76\u5728\u653e\u7f6e\u4e0e\u4f20\u9001\u9636\u6bb5\u5047\u8bbe\u7ebf\u6027\u7f16\u7801\u3001\u91c7\u7528\u5c0f\u89c4\u6a21\u9700\u6c42\u5b50\u96c6\u6765\u63a8\u5bfc\u53cd\u4f8b\u754c\u4e0e\u53ef\u884c\u70b9\u7684\u6700\u4f18\u6027\u3002", "result": "\u83b7\u5f97\u6bd4\u4ee5\u5f80\u5206\u6790\u65b9\u6cd5\u66f4\u7d27\u7684\u5bf9\u5076\u754c\uff0c\u8bc1\u660e\u5728\u7ebf\u6027\u7f16\u7801\u653e\u7f6e\u4e0e\u4f20\u9001\u7ea6\u675f\u4e0b\uff0c\u67d0\u4e9b\u53ef\u5b9e\u73b0\u7684\u5185\u5b58-\u8d1f\u8f7d\u6743\u8861\u70b9\u662f\u6700\u4f18\u7684\uff1b\u5e76\u6307\u51fa\u5c0f\u89c4\u6a21\u6709\u7ed3\u6784\u7684\u9700\u6c42\u5b50\u96c6\u4e0e\u6700\u5c0f\u516c\u5171\u4fe1\u606f\u6784\u9020\u53ef\u80fd\u8db3\u4ee5\u523b\u753b\u7ebf\u6027\u7f16\u7801\u4e0b\u7684\u6700\u4f18\u6743\u8861\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5728\u7ebf\u6027\u7f13\u5b58\u7f16\u7801\u7ea6\u675f\u4e0b\u7cfb\u7edf\u6781\u9650\u7684\u8ba1\u7b97\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u8868\u660e\u901a\u8fc7\u6709\u9650\u7684\u7ed3\u6784\u4e0e\u5c0f\u89c4\u6a21\u9700\u6c42\u96c6\u5373\u53ef\u63a5\u8fd1\u751a\u81f3\u8fbe\u5230\u6700\u4f18\u754c\uff0c\u5e76\u53ef\u80fd\u542f\u53d1\u8bbe\u8ba1\u57fa\u4e8e\u7ebf\u6027\u7f16\u7801\u7684\u7f13\u5b58\u7b56\u7565\u3002"}}
{"id": "2511.19480", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19480", "abs": "https://arxiv.org/abs/2511.19480", "authors": ["Pinaki Prasad Guha Neogi", "Ahmad Mohammadshirazi", "Dheeraj Kulshrestha", "Rajiv Ramnath"], "title": "Exploiting the Experts: Unauthorized Compression in MoE-LLMs", "comment": null, "summary": "Mixture-of-Experts (MoE) architectures are increasingly adopted in large language models (LLMs) for their scalability and efficiency. However, their modular structure introduces a unique vulnerability: adversaries can attempt to compress or repurpose models by pruning experts and cheaply fine-tuning the remainder, effectively bypassing licensing and security constraints. In this paper, we systematically study the prunability of MoE-LLMs under task-specific usage. We first develop an expert attribution framework that identifies the subset of experts most responsible for a given task, then evaluate the performance trade-offs of pruning and re-aligning these experts using active learning-driven fine-tuning. Our findings reveal a critical knowledge loss--recovery trade-off: while certain experts can be isolated to retain task accuracy, significant degradation occurs without targeted re-alignment. Based on this analysis, we propose defense strategies that aim to make MoE models harder to compress and fine-tune without authorization, including entangled expert training and selective fine-tuning protocols that resist unauthorized adaptation. By positioning expert pruning as both a threat vector and a defense target, this work highlights the dual-use nature of MoE modularity and provides the first systematic evaluation framework for secure specialization of MoE-LLMs.", "AI": {"tldr": "MoE-LLMs\u5b58\u5728\u53ef\u88ab\u88c1\u526a\u518d\u5b9a\u4f4d\uff0c\u4ece\u800c\u89c4\u907f\u8bb8\u53ef\u548c\u5b89\u5168\u7ea6\u675f\u7684\u98ce\u9669\uff1b\u901a\u8fc7\u4e13\u5bb6\u5f52\u56e0\u548c\u4e3b\u52a8\u5b66\u4e60\u5fae\u8c03\u8bc4\u4f30\u88c1\u526a\u4e0e\u91cd\u5b9a\u4f4d\u7684\u4efb\u52a1\u76f8\u5173\u6027\u4e0e\u7ed3\u679c\uff0c\u63d0\u51fa\u6297\u538b\u7f29\u548c\u6709\u9009\u62e9\u7684\u5fae\u8c03\u7b56\u7565\u6765\u63d0\u9ad8\u5b89\u5168\u6027\u3002", "motivation": "\u7cfb\u7edf\u6027\u7814\u7a76MoE\u5728\u7279\u5b9a\u4efb\u52a1\u4e0b\u7684\u53ef\u88c1\u526a\u6027\u53ca\u5176\u5bf9\u5b89\u5168\u6027\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e13\u5bb6\u5b50\u96c6\u5bf9\u4efb\u52a1\u7684\u91cd\u8981\u6027\u4e0e\u77e5\u8bc6\u635f\u5931/\u6062\u590d\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5f3a\u8c03MoE\u6a21\u5757\u5316\u7684\u53cc\u91cd\u7528\u9014\uff08\u5a01\u80c1\u4e0e\u9632\u5fa1\uff09\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u4e13\u5bb6\u5f52\u56e0\u6846\u67b6\u4ee5\u8bc6\u522b\u5bf9\u7279\u5b9a\u4efb\u52a1\u6700\u8d1f\u8d23\u7684\u4e13\u5bb6\u5b50\u96c6\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u8bc4\u4f30\u901a\u8fc7\u88c1\u526a\u548c\u57fa\u4e8e\u4e3b\u52a8\u5b66\u4e60\u7684\u5fae\u8c03\u8fdb\u884c\u91cd\u5bf9\u9f50\u7684\u6027\u80fd\u6743\u8861\uff1b\u5e76\u63d0\u51fa\u57fa\u4e8e entangled expert training \u4e0e\u9009\u62e9\u6027\u5fae\u8c03\u7684\u9632\u5fa1\u7b56\u7565\u3002", "result": "\u53d1\u73b0\u77e5\u8bc6\u635f\u5931-\u6062\u590d\u7684\u6743\u8861\uff1a\u53ef isolating \u67d0\u4e9b\u4e13\u5bb6\u4ee5\u7ef4\u6301\u4efb\u52a1\u7cbe\u5ea6\uff0c\u4f46\u82e5\u4e0d\u8fdb\u884c\u9488\u5bf9\u6027\u91cd\u65b0\u5bf9\u9f50\uff0c\u4ecd\u4f1a\u51fa\u73b0\u663e\u8457\u9000\u5316\uff1b\u88c1\u526a-\u91cd\u5bf9\u9f50\u7684\u6548\u679c\u53d6\u51b3\u4e8e\u76ee\u6807\u4efb\u52a1\u4e0e\u6570\u636e\u7684\u53ef\u83b7\u5f97\u6027\u53ca\u6a21\u578b\u7684\u6a21\u5757\u8026\u5408\u7a0b\u5ea6\u3002", "conclusion": "MoE \u7684\u4e13\u5bb6\u88c1\u526a\u65e2\u662f\u6f5c\u5728\u5a01\u80c1\u4e5f\u53ef\u6210\u4e3a\u9632\u5fa1\u5bf9\u8c61\uff0c\u9700\u5f00\u53d1\u4f7f\u6a21\u578b\u66f4\u96be\u88ab\u65e0\u6388\u6743\u538b\u7f29\u4e0e\u5fae\u8c03\u7684\u8bad\u7ec3\u4e0e\u90e8\u7f72\u7b56\u7565\uff1b\u672c\u6587\u9996\u6b21\u7ed9\u51fa\u7cfb\u7edf\u6027\u7684\u5b89\u5168\u4e13\u95e8\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86 MoE \u6a21\u5757\u5316\u7684\u53cc\u91cd\u7528\u9014\u3002"}}
{"id": "2511.19727", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19727", "abs": "https://arxiv.org/abs/2511.19727", "authors": ["Steven Peh"], "title": "Prompt Fencing: A Cryptographic Approach to Establishing Security Boundaries in Large Language Model Prompts", "comment": "44 pages, 1 figure", "summary": "Large Language Models (LLMs) remain vulnerable to prompt injection attacks, representing the most significant security threat in production deployments. We present Prompt Fencing, a novel architectural approach that applies cryptographic authentication and data architecture principles to establish explicit security boundaries within LLM prompts. Our approach decorates prompt segments with cryptographically signed metadata including trust ratings and content types, enabling LLMs to distinguish between trusted instructions and untrusted content. While current LLMs lack native fence awareness, we demonstrate that simulated awareness through prompt instructions achieved complete prevention of injection attacks in our experiments, reducing success rates from 86.7% (260/300 successful attacks) to 0% (0/300 successful attacks) across 300 test cases with two leading LLM providers. We implement a proof-of-concept fence generation and verification pipeline with a total overhead of 0.224 seconds (0.130s for fence generation, 0.094s for validation) across 100 samples. Our approach is platform-agnostic and can be incrementally deployed as a security layer above existing LLM infrastructure, with the expectation that future models will be trained with native fence awareness for optimal security.", "AI": {"tldr": "\u63d0\u51fa\u540d\u4e3a Prompt Fencing \u7684\u65b0\u67b6\u6784\uff0c\u901a\u8fc7\u5bf9\u63d0\u793a\u6bb5\u843d\u8fdb\u884c\u5bc6\u7801\u5b66\u7b7e\u540d\u4ee5\u5efa\u7acb\u5b89\u5168\u8fb9\u754c\uff0c\u4ece\u800c\u9632\u6b62\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u5b9e\u9a8c\u5728\u4e24\u5bb6\u4e3b\u6d41 LLM \u4e0a\u5c06\u653b\u51fb\u6210\u529f\u7387\u4ece 86.7% \u964d\u81f3 0%\uff0c\u5e76\u4e14\u603b\u5f00\u9500\u4e3a 0.224 \u79d2\u3002\u8be5\u65b9\u6cd5\u53ef\u5e73\u53f0\u65e0\u5173\u5730\u90e8\u7f72\u4e3a\u73b0\u6709 LLM \u57fa\u7840\u8bbe\u65bd\u4e4b\u4e0a\uff0c\u672a\u6765\u6a21\u578b\u5c06\u5177\u5907\u672c\u5730\u5316 fence Awareness\u3002", "motivation": "LLMs \u5728\u751f\u4ea7\u90e8\u7f72\u4e2d\u6613\u53d7\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u6784\u6210\u6700\u4e25\u91cd\u7684\u5b89\u5168\u5a01\u80c1\u4e4b\u4e00\uff1b\u9700\u8981\u5728\u63d0\u793a\u4e2d\u5efa\u7acb\u660e\u786e\u7684\u4fe1\u4efb\u4e0e\u5185\u5bb9\u8fb9\u754c\u3002\u5f53\u524d\u6a21\u578b\u7f3a\u4e4f fence awareness\uff0c\u56e0\u6b64\u9700\u5f15\u5165\u53ef\u9a8c\u8bc1\u7684\u5143\u6570\u636e\u6765\u533a\u5206\u53ef\u4fe1\u6307\u4ee4\u4e0e\u672a\u53ef\u4fe1\u5185\u5bb9\u3002", "method": "\u5bf9\u63d0\u793a\u6bb5\u843d\u8fdb\u884c\u5e26\u6709\u7b7e\u540d\u5143\u6570\u636e\u7684\u88c5\u9970\uff0c\u5305\u62ec\u4fe1\u4efb\u7b49\u7ea7\u548c\u5185\u5bb9\u7c7b\u578b\uff1b\u901a\u8fc7\u5efa\u7acb fence \u751f\u6210\u4e0e\u9a8c\u8bc1\u7ba1\u7ebf\u5b9e\u73b0\u5bf9\u63d0\u793a\u7684\u52a0\u5bc6\u8ba4\u8bc1\u4e0e\u9a8c\u8bc1\uff1b\u5728\u4eff\u771f\u4e2d\u901a\u8fc7\u6307\u793a\u6765\u5b9e\u73b0\u611f\u77e5\uff1b\u6d4b\u91cf\u5f00\u9500\u4e3a 0.130sFence generation \u4e0e 0.094s\u9a8c\u8bc1\uff0c\u603b\u5171 0.224s\uff1b\u65b9\u6cd5\u5e73\u53f0\u65e0\u5173\uff0c\u80fd\u5728\u73b0\u6709 LLM \u57fa\u7840\u8bbe\u65bd\u4e0a\u5206\u6b65\u90e8\u7f72\u3002", "result": "\u5728 300 \u4e2a\u6d4b\u8bd5\u7528\u4f8b\u3001\u4e24\u5bb6\u9886\u5148 LLM \u63d0\u4f9b\u5546\u7684\u5b9e\u9a8c\u4e2d\uff0c\u672a\u68c0\u6d4b\u5230\u6ce8\u5165\u653b\u51fb\u6210\u529f\uff08\u6210\u529f\u7387\u4ece 86.7% \u964d\u81f3 0%\uff09\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff1b\u5e76\u7ed9\u51fa 100 \u4e2a\u6837\u672c\u7684\u603b\u5f00\u9500\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4f5c\u4e3a\u73b0\u6709 LLM \u57fa\u7840\u8bbe\u65bd\u4e4b\u4e0a\u7684\u5b89\u5168\u5c42\u5b9e\u73b0\u6e10\u8fdb\u5f0f\u90e8\u7f72\uff1b\u672a\u6765\u6a21\u578b\u5e94\u5177\u5907\u672c\u5730\u5316 fence awareness \u4ee5\u5b9e\u73b0\u6700\u4f73\u5b89\u5168\u6027\uff1b\u65b9\u6cd5\u5177\u5e73\u53f0\u65e0\u5173\u7279\u6027\uff0c\u4e14\u53ef\u9010\u6b65\u63a8\u8fdb\u3002"}}
{"id": "2511.19683", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19683", "abs": "https://arxiv.org/abs/2511.19683", "authors": ["Eugene Lavretsky"], "title": "State Feedback Controllers with Operational Constraints", "comment": "33 pages, 13 figures. These are the original detailed design notes where my recent CBF-related papers came from", "summary": "In this paper, a state feedback control design with min/max operational limiting constraints is developed for multi-input-multi-output linear time invariant systems. Specifically, servo-tracking control problems with input and output constraints are considered. For static servo-controllers, the output design limits are imposed component-wise on the system selected output, which is of the same dimension as the control input. For dynamic servo-controllers, operational constraints are applied to the system inputs and outputs. The proposed control solution also includes an anti-windup protection logic for dynamic servo-controllers with integral action. The developed method is based on the Nagumo Theorem for forward invariance, the Comparison Lemma for inclusion of input/output inequality constraints, and on the min-norm optimal controllers for synthesis. The derived design is similar and directly related to the method of Control Barrier Functions. Simulation trade studies are presented to illustrate benefits of the proposed control methodology for aerial flight critical systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u591a\u8f93\u5165\u591a\u8f93\u51fa\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf\u7684\u72b6\u6001\u53cd\u9988\u63a7\u5236\u5668\u8bbe\u8ba1\uff0c\u5728\u9759\u6001/\u52a8\u6001\u4f3a\u670d\u63a7\u5236\u5668\u4e2d\u5bf9\u8f93\u5165/\u8f93\u51fa\u65bd\u52a0\u6700\u5c0f/\u6700\u5927\u7ea6\u675f\uff0c\u5305\u542b\u53cd windup\uff0c\u6838\u5fc3\u57fa\u4e8e Nagumo \u5b9a\u7406\u3001\u6bd4\u8f83\u5f15\u7406\u548c\u6700\u5c0f\u8303\u6570\u63a7\u5236\u5668\uff0c\u65b9\u6cd5\u4e0e\u63a7\u5236\u969c\u788d\u51fd\u6570\u76f8\u5173\uff0c\u901a\u8fc7\u4eff\u771f\u5728\u822a\u7a7a\u822a\u5929\u573a\u666f\u9a8c\u8bc1\u3002", "motivation": "\u5728\u4f3a\u670d\u8ddf\u8e2a\u95ee\u9898\u4e2d\u9700\u8981\u786e\u4fdd\u8f93\u5165\u8f93\u51fa\u7ea6\u675f\u7684\u5b89\u5168\u6027\u4e0e\u53ef\u5b9e\u73b0\u6027\uff0c\u5c24\u5176\u5728\u822a\u7a7a\u822a\u5929\u7b49\u5173\u952e\u7cfb\u7edf\u4e2d\uff0c\u9700\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u6ee1\u8db3\u524d\u5411\u4e0d\u53d8\u6027\u4e0e\u6297\u9971\u548c\u80fd\u529b\u3002", "method": "\u57fa\u4e8e Nagumo \u524d\u5411\u4e0d\u53d8\u6027\u5b9a\u7406\u3001\u8f93\u5165/\u8f93\u51fa\u7ea6\u675f\u5305\u542b\u7684\u6bd4\u8f83\u5f15\u7406\u4ee5\u53ca\u6700\u5c0f\u8303\u6570\u6700\u4f18\u63a7\u5236\u5668\uff0c\u63a8\u5bfc\u9759\u6001\u4e0e\u52a8\u6001\u4f3a\u670d\u63a7\u5236\u5668\u7684\u7ea6\u675f\u8bbe\u8ba1\uff1b\u9759\u6001\u63a7\u5236\u5668\u5bf9\u9009\u5b9a\u8f93\u51fa\u7684\u5206\u91cf\u65bd\u52a0\u4e0e\u63a7\u5236\u8f93\u5165\u540c\u7ef4\u5ea6\u7684\u8f93\u51fa\u9650\u5236\uff1b\u52a8\u6001\u63a7\u5236\u5668\u5bf9\u7cfb\u7edf\u8f93\u5165/\u8f93\u51fa\u65bd\u52a0\u7ea6\u675f\u5e76\u5f15\u5165\u5e26\u79ef\u5206\u7684 anti-windup \u903b\u8f91\uff1b\u4e0e\u63a7\u5236\u969c\u788d\u51fd\u6570\uff08CBF\uff09\u7684\u65b9\u6cd5\u76f4\u63a5\u76f8\u5173\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u5bf9\u6bd4\u7814\u7a76\uff0c\u5c55\u793a\u6240\u63d0\u7ea6\u675f\u63a7\u5236\u5728\u5b9e\u73b0\u7ea6\u675f\u540c\u65f6\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u7684\u4f18\u52bf\uff0c\u7279\u522b\u9488\u5bf9\u7a7a\u5929\u7b49\u9ad8\u5371\u98de\u884c\u63a7\u5236\u7cfb\u7edf\u3002", "conclusion": "\u7ed9\u51fa\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u53d7\u7ea6\u675f\u4f3a\u670d\u63a7\u5236\u8bbe\u8ba1\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u591a\u8f93\u5165\u591a\u8f93\u51fa\u7ebf\u6027\u7cfb\u7edf\uff0c\u5177\u6709\u6297\u9971\u548c\u7684\u80fd\u529b\u548c\u4e0e CBF \u7684\u5173\u7cfb\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u63d0\u4f9b\u53ef\u884c\u7684\u5b9e\u73b0\u8def\u5f84\u3002"}}
{"id": "2511.19745", "categories": ["cs.IT", "eess.SP", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.19745", "abs": "https://arxiv.org/abs/2511.19745", "authors": ["Yassine Afif", "Mohammed Almekhlafi", "Antoine Lesage-Landry", "Gunes Karabulut Kurt"], "title": "Joint Satellite Power Consumption and Handover Optimization for LEO Constellations", "comment": null, "summary": "In satellite constellation-based communication systems, continuous user coverage requires frequent handoffs due to the dynamic topology induced by the Low Earth Orbit (LEO) satellites. Each handoff between a satellite and ground users introduces additional signaling and power consumption, which can become a significant burden as the size of the constellation continues to increase. This work focuses on the optimization of the total transmission rate in a LEO-to-user system, by jointly considering the total transmitted power, user-satellite associations, and power consumption, the latter being handled through a penalty on handoff events. We consider a system where LEO satellites serve users located in remote areas with no terrestrial connectivity, and formulate the power allocation problem as a mixed-integer concave linear program (MICP) subject to power and association constraints. Our approach can be solved with off-the-shelf solvers and is benchmarked against a naive baseline where users associate to their closest visible satellite. Extensive Monte Carlo simulations demonstrate the effectiveness of the proposed method in controlling the handoff frequency while maintaining high user throughput. These performance gains highlight the effectiveness of our handover-aware optimization strategy, which ensures that user rates improve significantly, by about 40%, without incurring a disproportionate rise in the handoff frequency.", "AI": {"tldr": "Proposes a handover-aware optimization for LEO-to-user links to maximize total transmission rate while controlling handoffs.", "motivation": "LEO constellation handoffs cause frequent signaling and energy overhead; as constellations grow, there is a need to balance coverage, throughput, and handoff costs.", "method": "Formulates the problem as a mixed-integer concave linear program (MICP) that jointly optimizes total transmit power, user-satellite associations, and a penalty for handoff events; solvable with standard solvers.", "result": "Monte Carlo simulations show significant gains in user throughput (\u224840%) with a controlled increase in handoff frequency compared to a naive nearest-satellite association baseline.", "conclusion": "A handover-aware optimization framework can substantially improve user rates without triggering disproportionate handoff growth, offering a practical solution for LEO-to-user systems."}}
{"id": "2511.19481", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19481", "abs": "https://arxiv.org/abs/2511.19481", "authors": ["Ruoxin Zhang", "Zhizhao Wen", "Chao Wang", "Chenchen Tang", "Puyang Xu", "Yifan Jiang"], "title": "Quality analysis and evaluation prediction of RAG retrieval based on machine learning algorithms", "comment": null, "summary": "With the rapid evolution of large language models, retrieval enhanced generation technology has been widely used due to its ability to integrate external knowledge to improve output accuracy. However, the performance of the system is highly dependent on the quality of the retrieval module. If the retrieval results have low relevance to user needs or contain noisy information, it will directly lead to distortion of the generated content. In response to the performance bottleneck of existing models in processing tabular features, this paper proposes an XGBoost machine learning regression model based on feature engineering and particle swarm optimization. Correlation analysis shows that answer_quality is positively correlated with doc_delevance by 0.66, indicating that document relevance has a significant positive effect on answer quality, and improving document relevance may enhance answer quality; The strong negative correlations between semantic similarity, redundancy, and diversity were -0.89 and -0.88, respectively, indicating a trade- off between semantic similarity, redundancy, and diversity. In other words, as the former two increased, diversity significantly decreased. The experimental results comparing decision trees, AdaBoost, etc. show that the VMD PSO BiLSTM model is superior in all evaluation indicators, with significantly lower MSE, RMSE, MAE, and MAPE compared to the comparison model. The R2 value is higher, indicating that its prediction accuracy, stability, and data interpretation ability are more outstanding. This achievement provides an effective path for optimizing the retrieval quality and improving the generation effect of RAG system, and has important value in promoting the implementation and application of related technologies.", "AI": {"tldr": "\u4ee5\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e3a\u80cc\u666f\uff0c\u63d0\u51fa\u57fa\u4e8e\u7279\u5f81\u5de5\u7a0b\u4e0e\u7c92\u5b50\u7fa4\u4f18\u5316\u7684 XGBoost \u56de\u5f52\u6a21\u578b\u4ee5\u63d0\u5347\u68c0\u7d22\u8d28\u91cf\u5bf9\u751f\u6210\u6548\u679c\u7684\u5f71\u54cd\uff0c\u5b9e\u9a8c\u8868\u660e VMD-PSO BiLSTM \u5728\u591a\u6307\u6807\u4e0a\u4f18\u4e8e\u5bf9\u6bd4\u6a21\u578b.", "motivation": "\u68c0\u7d22\u6a21\u5757\u8d28\u91cf\u76f4\u63a5\u51b3\u5b9a RAG \u7684\u8f93\u51fa\u51c6\u786e\u6027\uff1b\u73b0\u6709\u6a21\u578b\u5728\u5904\u7406\u8868\u683c\u7279\u5f81\u65b9\u9762\u5b58\u5728\u74f6\u9888\uff0c\u9700\u901a\u8fc7\u5efa\u7acb\u68c0\u7d22\u76f8\u5173\u6027\u4e0e\u751f\u6210\u8d28\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\u6765\u63d0\u5347\u7cfb\u7edf\u6027\u80fd.", "method": "\u5728\u7279\u5f81\u5de5\u7a0b\u4e0e\u7c92\u5b50\u7fa4\u4f18\u5316\u57fa\u7840\u4e0a\u6784\u5efa XGBoost \u56de\u5f52\u6a21\u578b\uff1b\u8fdb\u884c\u6587\u6863\u76f8\u5173\u6027\u3001\u8bed\u4e49\u76f8\u4f3c\u5ea6\u3001\u5197\u4f59\u4e0e\u591a\u6837\u6027\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u5206\u6790\uff1b\u63d0\u51fa VMD-PSO-BiLSTM \u7b49\u6a21\u578b\u7528\u4e8e\u56de\u5f52\u4e0e\u5e8f\u5217\u5efa\u6a21\uff0c\u5e76\u4e0e\u51b3\u7b56\u6811\u3001AdaBoost \u7b49\u6a21\u578b\u5bf9\u6bd4.", "result": "\u6587\u6863\u76f8\u5173\u6027\u5bf9\u56de\u7b54\u8d28\u91cf\u6709\u663e\u8457\u6b63\u76f8\u5173\uff08r=0.66\uff09\uff0c\u8bed\u4e49\u76f8\u4f3c\u6027\u4e0e\u5197\u4f59\u5bf9\u591a\u6837\u6027\u5448\u663e\u8457\u8d1f\u76f8\u5173\uff08\u5206\u522b\u4e3a -0.89 \u548c -0.88\uff09\u3002VMD PSO BiLSTM \u5728\u6240\u6709\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8e\u5bf9\u6bd4\u6a21\u578b\uff0cMSE\u3001RMSE\u3001MAE\u3001MAPE \u663e\u8457\u964d\u4f4e\uff0cR2 \u63d0\u9ad8\uff0c\u8868\u660e\u9884\u6d4b\u7cbe\u5ea6\u3001\u7a33\u5b9a\u6027\u4e0e\u89e3\u91ca\u80fd\u529b\u66f4\u5f3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4f18\u5316\u68c0\u7d22\u8d28\u91cf\u3001\u63d0\u5347 RAG \u7cfb\u7edf\u751f\u6210\u6548\u679c\u63d0\u4f9b\u6709\u6548\u8def\u5f84\uff0c\u5bf9\u76f8\u5173\u6280\u672f\u7684\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.19874", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19874", "abs": "https://arxiv.org/abs/2511.19874", "authors": ["Arun Chowdary Sanna"], "title": "Cross-LLM Generalization of Behavioral Backdoor Detection in AI Agent Supply Chains", "comment": "10 pages, 2 figures, 8 tables. Evaluation across 6 production LLMs with 1,198 traces", "summary": "As AI agents become integral to enterprise workflows, their reliance on shared tool libraries and pre-trained components creates significant supply chain vulnerabilities. While previous work has demonstrated behavioral backdoor detection within individual LLM architectures, the critical question of cross-LLM generalization remains unexplored, a gap with serious implications for organizations deploying multiple AI systems. We present the first systematic study of cross-LLM behavioral backdoor detection, evaluating generalization across six production LLMs (GPT-5.1, Claude Sonnet 4.5, Grok 4.1, Llama 4 Maverick, GPT-OSS 120B, and DeepSeek Chat V3.1). Through 1,198 execution traces and 36 cross-model experiments, we quantify a critical finding: single-model detectors achieve 92.7% accuracy within their training distribution but only 49.2% across different LLMs, a 43.4 percentage point generalization gap equivalent to random guessing. Our analysis reveals that this gap stems from model-specific behavioral signatures, particularly in temporal features (coefficient of variation > 0.8), while structural features remain stable across architectures. We show that model-aware detection incorporating model identity as an additional feature achieves 90.6% accuracy universally across all evaluated models. We release our multi-LLM trace dataset and detection framework to enable reproducible research.", "AI": {"tldr": "\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u8de8\u5927\u6a21\u578b\u7684\u884c\u4e3a\u540e\u95e8\u68c0\u6d4b\uff0c\u63ed\u793a\u5355\u6a21\u578b\u5728\u8de8LLMs\u6cdb\u5316\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff1b\u901a\u8fc7\u5f15\u5165\u6a21\u578b\u8eab\u4efd\u4f5c\u4e3a\u7279\u5f81\u5b9e\u73b0\u8de8\u6a21\u578b\u9ad8\u51c6\u786e\u5ea6\u68c0\u6d4b\uff0c\u5e76\u53d1\u5e03\u591aLLM\u8f68\u8ff9\u6570\u636e\u96c6\u4e0e\u68c0\u6d4b\u6846\u67b6\u3002", "motivation": "\u4f01\u4e1a\u5de5\u4f5c\u6d41\u5bf9\u5171\u4eab\u5de5\u5177\u5e93\u548c\u9884\u8bad\u7ec3\u7ec4\u4ef6\u7684\u4f9d\u8d56\u5e26\u6765\u4f9b\u5e94\u94fe\u5c42\u9762\u7684\u540e\u95e8\u98ce\u9669\u3002\u73b0\u6709\u5de5\u4f5c\u591a\u805a\u7126\u4e8e\u5355\u4e00LLM\u7684\u540e\u95e8\u68c0\u6d4b\uff0c\u7f3a\u4e4f\u8de8\u6a21\u578b\u7684\u6cdb\u5316\u7814\u7a76\uff0c\u5371\u53ca\u90e8\u7f72\u591a\u6a21\u578b\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002", "method": "\u5bf9\u516d\u4e2a\u751f\u4ea7\u7ea7LLM\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u9a8c\uff08GPT-5.1\u3001Claude Sonnet 4.5\u3001Grok 4.1\u3001Llama 4 Maverick\u3001GPT-OSS 120B\u3001DeepSeek Chat V3.1\uff09\uff0c\u6536\u96c61198\u6761\u6267\u884c\u8f68\u8ff9\u4e0e36\u7ec4\u8de8\u6a21\u578b\u5b9e\u9a8c\u3002\u6bd4\u8f83\u5355\u6a21\u578b\u68c0\u6d4b\u5668\u5728\u540c\u5206\u5e03\u4e0e\u8de8\u6a21\u578b\u4e0a\u7684\u8868\u73b0\uff0c\u5206\u6790\u65f6\u95f4\u7279\u5f81\u4e0e\u7ed3\u6784\u7279\u5f81\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u51fa\u5c06\u6a21\u578b\u8eab\u4efd\u4f5c\u4e3a\u9644\u52a0\u7279\u5f81\u4ee5\u5b9e\u73b0\u8de8\u6a21\u578b\u68c0\u6d4b\u3002", "result": "\u5355\u6a21\u578b\u68c0\u6d4b\u5728\u8bad\u7ec3\u5206\u5e03\u5185\u51c6\u786e\u7387\u4e3a92.7%\uff0c\u8de8\u6a21\u578b\u4ec549.2%\uff0c\u6cdb\u5316\u5dee\u8ddd43.4\u4e2a\u767e\u5206\u70b9\uff0c\u63a5\u8fd1\u968f\u673a\u731c\u6d4b\uff1b\u65f6\u95f4\u7279\u5f81\uff08\u5982\u53d8\u5f02\u7cfb\u6570CV>0.8\uff09\u662f\u5173\u952e\u4fe1\u53f7\uff0c\u7ed3\u6784\u7279\u5f81\u8f83\u4e3a\u7a33\u5b9a\u3002\u5f15\u5165\u6a21\u578b\u8eab\u4efd\u7b49\u5143\u4fe1\u606f\u540e\uff0c\u68c0\u6d4b\u51c6\u786e\u7387\u63d0\u5347\u81f390.6%\uff0c\u5b9e\u73b0\u5bf9\u6240\u6709\u8bc4\u4f30\u6a21\u578b\u7684\u8de8\u6a21\u578b\u4e00\u81f4\u6027\u3002", "conclusion": "\u63d0\u51fa\u6a21\u578b\u611f\u77e5\u7684\u540e\u95e8\u68c0\u6d4b\u6846\u67b6\uff0c\u63d0\u5347\u8de8\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u5e76\u516c\u5f00\u591aLLM\u8f68\u8ff9\u6570\u636e\u96c6\u4e0e\u68c0\u6d4b\u6846\u67b6\uff0c\u4fc3\u8fdb\u53ef\u91cd\u590d\u6027\u7814\u7a76\u3002"}}
{"id": "2511.19715", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19715", "abs": "https://arxiv.org/abs/2511.19715", "authors": ["Theodor Hagstr\u00f6m", "Lars Herre"], "title": "Understanding Risk and Revenue in the Nordic 15-minute mFRR market: An EV Aggregation Study", "comment": null, "summary": "Decarbonisation, decentralisation, and intermittency are driving the development of flexibility markets towards shorter market time units (MTU). Shorter MTUs and shorter gate closures lower the entrance barriers of demand side aggregators that face significant uncertainty on longer time scales. We study the business case for aggregated EV fleets participating in the Nordic 15-minute mFRR Energy Activation Market (EAM). Motivated by increasing system granularity and rapid EV uptake, we represent fleet flexibility as a virtual battery with time-varying power and energy envelopes and formulate a risk-aware stochastic optimisation that co-ordinates day-ahead scheduling with quarter-hour mFRR bidding. Using synthetic residential charging cohorts and observed day-ahead prices on two stylised days, we compare an independent day-ahead baseline to a co-optimised strategy under conservative availability and a CVaR-augmented objective. Across both price cases, co-optimisation increases expected profit and lowers downside risk: the model buys less energy day-ahead and shifts procurement toward mFRR down while flattening the charging plan to retain eligibility for mFRR up. Profit decomposition shows that the uplift is driven by higher mFRR down revenues and reduced reliance on unwinding day-ahead positions. We discuss operational implications for bidding and outline two extensions: rolling 45-minute re-optimisation and a V2G framework.", "AI": {"tldr": "\u5bf9\u805a\u5408\u7535\u52a8\u6c7d\u8f66\u8f66\u961f\u53c2\u4e0e\u5317\u6b2715\u5206\u949fmFRR\u80fd\u6e90\u6fc0\u6d3b\u5e02\u573a\u7684\u98ce\u9669\u610f\u8bc6\u578b\u534f\u540c\u4f18\u5316\u6846\u67b6\u8fdb\u884c\u5206\u6790\u3002\u5c06\u8f66\u961f\u4f5c\u4e3a\u5177\u6709\u65f6\u53d8\u529f\u7387\u4e0e\u80fd\u91cf\u5305\u7edc\u7684\u865a\u62df\u7535\u6c60\u5efa\u6a21\uff0c\u901a\u8fc7\u5bf9\u65e5\u8c03\u5ea6\u4e0e\u5b63\u5ea6\u91cf\u5316\u7684mFRR\u7ade\u4ef7\u8fdb\u884c\u98ce\u9669\u63a7\u5236\u7684\u968f\u673a\u4f18\u5316\u3002\u7ed3\u679c\u8868\u660e\uff1a\u4e0e\u72ec\u7acb\u65e5\u8c03\u5ea6\u57fa\u7ebf\u76f8\u6bd4\uff0c\u534f\u540c\u4f18\u5316\u5728\u4e24\u79cd\u4ef7\u683c\u60c5\u666f\u4e0b\u63d0\u5347\u671f\u671b\u5229\u6da6\u5e76\u964d\u4f4e\u4e0b\u884c\u98ce\u9669\uff0c\u5177\u4f53\u8868\u73b0\u4e3a\uff1a\u51cf\u5c11\u65e5\u524d\u8d2d\u7535\u3001\u5411mFRR\u4e0b\u4fa7\u91c7\u8d2d\u8f6c\u79fb\u3001\u5e76\u4f7f\u5145\u7535\u8ba1\u5212\u8d8b\u5411\u5e73\u6ed1\u4ee5\u7ef4\u6301mFRR\u4e0a\u884c\u8d44\u683c\u3002\u76c8\u5229\u63d0\u5347\u6765\u81ea\u66f4\u9ad8\u7684mFRR\u4e0b\u6536\u5165\u53ca\u5bf9\u65e5\u524d\u5934\u5bf8\u7684\u51cf unwind\u3002\u672c\u6587\u8fd8\u8ba8\u8bba\u4e86 bidding \u7684\u8fd0\u8425\u542b\u4e49\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u6269\u5c55\uff1a\u6eda\u52a845\u5206\u949f\u518d\u4f18\u5316\u548cV2G\u6846\u67b6\u3002", "motivation": "\u968f\u7740 decarbonisation\u3001\u5206\u6563\u5316\u548c\u95f4\u6b47\u6027\u5bf9\u7535\u529b\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u5e02\u573a\u65f6\u95f4\u5355\u4f4d\uff08MTU\uff09\u7f29\u77ed\u3001\u5173\u53e3\u4e0b\u653e\uff0c\u964d\u4f4e\u4e86\u9700\u6c42\u4fa7\u805a\u5408\u5546\u7684\u51c6\u5165\u95e8\u69db\u3002EV\u8f66\u961f\u4f5c\u4e3a\u5173\u952e\u7075\u6d3b\u6027\u8d44\u6e90\uff0c\u4e0e\u65e5\u8c03\u5ea6\u548c\u5feb\u901f\u8c03\u5cf0\u5e02\u573a\u7684\u8026\u5408\u5728\u63d0\u5347\u7cfb\u7edf granularity \u4e0e\u98ce\u9669\u7ba1\u7406\u65b9\u9762\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u5c06\u8f66\u961f\u7075\u6d3b\u6027\u8868\u793a\u4e3a\u5177\u6709\u65f6\u53d8\u529f\u7387\u548c\u80fd\u91cf\u5305\u7edc\u7684\u865a\u62df\u7535\u6c60\uff0c\u5efa\u7acb\u4ee5CVaR\u4e3a\u76ee\u6807\u7684\u98ce\u9669\u611f\u77e5\u968f\u673a\u4f18\u5316\u6a21\u578b\uff0c\u8054\u5408\u65e5\u524d\u8c03\u5ea6\u4e0e\u5b63\u5ea6mFRR\u7ade\u4ef7\u7684\u534f\u540c\u51b3\u7b56\u3002\u4ee5\u5408\u6210\u5bb6\u5ead\u5145\u7535\u6837\u672c\u548c\u4e24\u5929\u7684\u65e5\u524d\u4ef7\u683c\u4e3a\u6570\u636e\u57fa\u7840\uff0c\u5728\u4e24\u79cd\u4ef7\u683c\u60c5\u666f\u4e0b\u6bd4\u8f83\u72ec\u7acb\u65e5\u8c03\u57fa\u7ebf\u4e0e\u5bf9\u6bd4\u7684\u534f\u540c\u4f18\u5316\uff08\u5728\u4fdd\u5b88\u53ef\u7528\u6027\u7ea6\u675f\u4e0b\uff09\u53ca\u5e26CVaR\u76ee\u6807\u7684\u65b9\u6848\u3002\u8fdb\u4e00\u6b65\u505a\u5229\u6da6\u5206\u89e3\u4ee5\u5206\u6790\u6536\u76ca\u6765\u6e90\u3002", "result": "\u534f\u540c\u4f18\u5316\u5728\u4e24\u79cd\u4ef7\u683c\u60c5\u666f\u4e0b\u90fd\u63d0\u9ad8\u4e86\u671f\u671b\u5229\u6da6\u5e76\u964d\u4f4e\u4e0b\u884c\u98ce\u9669\uff1b\u6a21\u578b\u5728\u65e5\u524d\u8d2d\u7535\u91cf\u4e0a\u505a\u51fa\u66f4\u4fdd\u5b88\u7684\u9009\u62e9\uff0c\u589e\u52a0\u5bf9mFRR\u4e0b\u7684\u91c7\u8d2d\u5e76\u901a\u8fc7\u5145\u7535\u8ba1\u5212\u7684\u5e73\u6ed1\u5316\u6765\u7ef4\u6301mFRR\u4e0a\u884c\u7684\u8d44\u683c\u3002\u5229\u6da6\u63d0\u5347\u6765\u6e90\u4e8e\u66f4\u9ad8\u7684mFRR\u4e0b\u6536\u5165\u4ee5\u53ca\u5bf9\u65e5\u524d\u5934\u5bf8 unwind \u7684\u964d\u4f4e\u3002", "conclusion": "\u7ed3\u679c\u652f\u6301\u5bf9EV\u8f66\u961f\u53c2\u4e0e\u77edMTU\u7075\u6d3b\u6027\u5e02\u573a\u7684\u534f\u540c\u4f18\u5316\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c31 bidding \u7684\u64cd\u4f5c\u6027\u63d0\u51fa\u5f71\u54cd\u3002\u672a\u6765\u6269\u5c55\u5305\u62ec\u6eda\u52a845\u5206\u949f\u518d\u4f18\u5316\u4ee5\u53caV2G\u6846\u67b6\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u76c8\u5229\u4e0e\u98ce\u9669\u63a7\u5236\u80fd\u529b\u3002"}}
{"id": "2511.19812", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.19812", "abs": "https://arxiv.org/abs/2511.19812", "authors": ["Hao Wu", "Bocong Chen", "Guanghui Zhang", "Hongwei Liu"], "title": "Two-Step Decoding of Binary $2\\times2$ Sum-Rank-Metric Codes", "comment": "16 pages", "summary": "We resolve an open problem posed by Chen--Cheng--Qi (IEEE Trans.\\ Inf.\\ Theory, 2025): can decoding of binary sum-rank-metric codes $\\SR(C_1,C_2)$ with $2\\times2$ matrix blocks be reduced entirely to decoding the constituent Hamming-metric codes $C_1$ and $C_2$ without the additional requirement $d_1\\ge\\tfrac{2}{3}d_{\\mathrm{sr}}$ that underlies their fast decoder? We answer this in the affirmative by exhibiting a simple two-step procedure: first uniquely decode $C_2$, then apply a single error/erasure decoding of $C_1$.This shows that the restrictive hypothesis $d_1\\ge\\tfrac{2}{3}d_{\\mathrm{sr}}$ is theoretically unnecessary.The resulting decoder achieves unique decoding up to $\\lfloor (d_{\\mathrm{sr}}-1)/2\\rfloor$ with overall cost $T_2+T_1$, where $T_2$ and $T_1$ are the complexities of the Hamming decoders for $C_2$ and $C_1$, respectively. We further show that this reduction is asymptotically optimal in a black-box model, as any sum-rank decoder must inherently decode the constituent Hamming codes.For BCH or Goppa instantiations over $\\F_4$, the decoder runs in $O(\\ell^2)$ time.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4e24\u6b65\u89e3\u7801\u7b56\u7565\uff1a\u5148\u5bf9 C2 \u505a\u552f\u4e00\u89e3\u7801\uff0c\u7136\u540e\u5bf9 C1 \u505a\u4e00\u6b21\u9519\u8bef/\u64e6\u9664\u89e3\u7801\u5373\u53ef\u5c06\u4e8c\u8fdb\u5236\u548c\u548c\u79e9\u5ea6\u7801 SR(C1, C2) \u7684\u89e3\u7801\u7b80\u5316\u4e3a\u5bf9\u5206\u91cf\u7801\u7684\u89e3\u7801\uff1b\u53bb\u9664\u4e86 d1 \u2265 2/3 d_sr \u7684\u9650\u5236\uff1b\u603b\u4f53\u590d\u6742\u5ea6\u4e3a T2+T1\uff1b\u5728\u9ed1\u7bb1\u6a21\u578b\u4e0b\u8be5\u6298\u8877\u662f\u6e10\u8fd1\u6700\u4f18\u7684\uff1b\u5728 BCH \u6216 Goppa\uff08F4 \u4e0a\uff09\u5b9e\u73b0\u65f6\u590d\u6742\u5ea6\u4e3a O(l^2)\u3002", "motivation": "\u56de\u5e94 Chen\u2013Cheng\u2013Qi \u7684\u5f00\u653e\u95ee\u9898\uff1a\u662f\u5426\u80fd\u5c06 SR(C1, C2) \u7684\u89e3\u7801\u5b8c\u5168\u964d\u7ef4\u5230\u5bf9\u5206\u91cf\u7684 Hamming \u89e3\u7801\u800c\u4e0d\u9700\u8981\u989d\u5916\u7684\u7ea6\u675f d1\u22652/3 d_sr\uff1b\u5982\u679c\u53ef\u884c\uff0c\u5219\u63d0\u5347\u89e3\u7801\u6548\u7387\u4e0e\u7b80\u5316\u5b9e\u73b0\u3002", "method": "\u63d0\u51fa\u4e24\u6b65\u89e3\u7801\u6d41\u7a0b\uff1a\u7b2c\u4e00\u6b65\u5bf9 C2 \u8fdb\u884c\u552f\u4e00\u89e3\u7801\uff1b\u7b2c\u4e8c\u6b65\u5bf9 C1 \u8fdb\u884c\u4e00\u6b21\u9519\u8bef/\u64e6\u9664\u89e3\u7801\uff1b\u5206\u6790\u8868\u660e\u4e0d\u518d\u9700\u8981 d1\u22652/3 d_sr\uff1b\u7ed9\u51fa\u603b\u590d\u6742\u5ea6 T2+T1\uff1b\u7ed9\u51fa\u5728\u9ed1\u7bb1\u6a21\u578b\u4e0b\u7684\u6e10\u8fd1\u6700\u4f18\u6027\u8bc1\u660e\u3002", "result": "\u7ed9\u51fa\u7ed3\u8bba\uff1a\u53ef\u5c06 SR(C1, C2) \u7684\u89e3\u7801\u5b8c\u5168\u964d\u7ef4\u5230\u5bf9 C2\u3001C1 \u7684\u89e3\u7801\uff1b\u552f\u4e00\u89e3\u7801\u754c\u4e3a floor((d_sr - 1)/2)\uff1b\u5b9e\u73b0\u5bf9 BCH/Goppa over F4 \u7684\u7b80\u5316\uff0c\u65f6\u95f4\u590d\u6742\u5ea6 O(l^2)\u3002", "conclusion": "\u9650\u5236\u6027\u5047\u8bbe\u88ab\u79fb\u9664\uff0c\u89e3\u7801\u5668\u5728\u7406\u8bba\u548c\u5b9e\u9645\u590d\u6742\u5ea6\u4e0a\u90fd\u5177\u5907\u4f18\u52bf\uff1b\u5728\u5177\u4f53\u4ee3\u6570\u6784\u9020\uff0c\u5982 BCH/Goppa over F4\uff0c\u5177\u6709\u9ad8\u6548\u5b9e\u73b0\u3002"}}
{"id": "2511.20229", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.20229", "abs": "https://arxiv.org/abs/2511.20229", "authors": ["Pascal Ruffing", "Denis Petrov", "Sebastian Zillien", "Steffen Wendzel"], "title": "Improving the Identification of Real-world Malware's DNS Covert Channels Using Locality Sensitive Hashing", "comment": null, "summary": "Nowadays, malware increasingly uses DNS-based covert channels in order to evade detection and maintain stealthy communication with its command-and-control servers. While prior work has focused on detecting such activity, identifying specific malware families and their behaviors from captured network traffic remains challenging due to the variability of DNS. In this paper, we present the first application of Locality Sensitive Hashing to the detection and identification of real-world malware utilizing DNS covert channels. Our approach encodes DNS subdomain sequences into statistical similarity features that effectively capture anomalies indicative of malicious activity. Combined with a Random Forest classifier, our method achieves higher accuracy and reduced false positive rates than prior approaches, while demonstrating improved robustness and generalization to previously unseen or modified malware samples. We further demonstrate that our approach enables reliable classification of malware behavior (e.g., uploading or downloading of files), based solely on DNS subdomains.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.19485", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19485", "abs": "https://arxiv.org/abs/2511.19485", "authors": ["Wanzhe Xu", "Yutong Dai", "Yitao Yang", "Martin Loza", "Weihang Zhang", "Yang Cui", "Xin Zeng", "Sung Joon Park", "Kenta Nakai"], "title": "OmniTFT: Omni Target Forecasting for Vital Signs and Laboratory Result Trajectories in Multi Center ICU Data", "comment": "23 pages, 5 figures, 2 tables", "summary": "Accurate multivariate time-series prediction of vital signs and laboratory results is crucial for early intervention and precision medicine in intensive care units (ICUs). However, vital signs are often noisy and exhibit rapid fluctuations, while laboratory tests suffer from missing values, measurement lags, and device-specific bias, making integrative forecasting highly challenging. To address these issues, we propose OmniTFT, a deep learning framework that jointly learns and forecasts high-frequency vital signs and sparsely sampled laboratory results based on the Temporal Fusion Transformer (TFT). Specifically, OmniTFT implements four novel strategies to enhance performance: sliding window equalized sampling to balance physiological states, frequency-aware embedding shrinkage to stabilize rare-class representations, hierarchical variable selection to guide model attention toward informative feature clusters, and influence-aligned attention calibration to enhance robustness during abrupt physiological changes. By reducing the reliance on target-specific architectures and extensive feature engineering, OmniTFT enables unified modeling of multiple heterogeneous clinical targets while preserving cross-institutional generalizability. Across forecasting tasks, OmniTFT achieves substantial performance improvement for both vital signs and laboratory results on the MIMIC-III, MIMIC-IV, and eICU datasets. Its attention patterns are interpretable and consistent with known pathophysiology, underscoring its potential utility for quantitative decision support in clinical care.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.19886", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19886", "abs": "https://arxiv.org/abs/2511.19886", "authors": ["Chi Liu", "Tianqing Zhu", "Wanlei Zhou", "Wei Zhao"], "title": "Frequency Bias Matters: Diving into Robust and Generalized Deep Image Forgery Detection", "comment": "Accepted for publication in IEEE Transactions on Dependable and Secure Computing", "summary": "As deep image forgery powered by AI generative models, such as GANs, continues to challenge today's digital world, detecting AI-generated forgeries has become a vital security topic. Generalizability and robustness are two critical concerns of a forgery detector, determining its reliability when facing unknown GANs and noisy samples in an open world. Although many studies focus on improving these two properties, the root causes of these problems have not been fully explored, and it is unclear if there is a connection between them. Moreover, despite recent achievements in addressing these issues from image forensic or anti-forensic aspects, a universal method that can contribute to both sides simultaneously remains practically significant yet unavailable. In this paper, we provide a fundamental explanation of these problems from a frequency perspective. Our analysis reveals that the frequency bias of a DNN forgery detector is a possible cause of generalization and robustness issues. Based on this finding, we propose a two-step frequency alignment method to remove the frequency discrepancy between real and fake images, offering double-sided benefits: it can serve as a strong black-box attack against forgery detectors in the anti-forensic context or, conversely, as a universal defense to improve detector reliability in the forensic context. We also develop corresponding attack and defense implementations and demonstrate their effectiveness, as well as the effect of the frequency alignment method, in various experimental settings involving twelve detectors, eight forgery models, and five metrics.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9891\u7387\u5bf9\u9f50\u7684\u4e24\u6b65\u65b9\u6cd5\uff0c\u63ed\u793a\u9891\u7387\u504f\u5dee\u662f\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u6cdb\u5316\u4e0e\u9c81\u68d2\u6027\u95ee\u9898\u7684\u6f5c\u5728\u6839\u6e90\uff0c\u5e76\u63d0\u4f9b\u53ef\u53cc\u5411\u4f7f\u7528\u7684\u653b\u51fb\u4e0e\u9632\u5fa1\u673a\u5236\uff0c\u572812\u4e2a\u68c0\u6d4b\u5668\u30018\u4e2a\u4f2a\u9020\u6a21\u578b\u30015\u9879\u6307\u6807\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "motivation": "\u968f\u7740 AI \u751f\u6210\u7684\u56fe\u50cf\u4f2a\u9020\u8d8a\u6765\u8d8a\u666e\u904d\uff0c\u68c0\u6d4b\u5728\u672a\u77e5 GAN \u4e0e\u5f00\u653e\u4e16\u754c\u4e0b\u7684\u9c81\u68d2\u6027\u4e0e\u6cdb\u5316\u80fd\u529b\u6210\u4e3a\u6838\u5fc3\u95ee\u9898\u3002\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u5c1d\u8bd5\u63d0\u5347\u8fd9\u4e24\u8005\uff0c\u4f46\u5f80\u5f80\u672a\u660e\u786e\u4e24\u8005\u7684\u6839\u672c\u539f\u56e0\u53ca\u5176\u5173\u7cfb\uff0c\u4e5f\u7f3a\u4e4f\u80fd\u540c\u65f6\u670d\u52a1\u4e8e\u653b\u51fb\u548c\u9632\u5fa1\u7684\u901a\u7528\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u9891\u7387\u5c42\u9762\u7684\u5206\u6790\uff0c\u53d1\u73b0 DNN \u4f2a\u9020\u68c0\u6d4b\u5668\u5b58\u5728\u5bf9\u9891\u7387\u7684\u504f\u7f6e\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u5bf9\u65b0\u578b\u4f2a\u9020\u6837\u672c\u7684\u6cdb\u5316\u4e0e\u5bf9\u566a\u58f0\u6837\u672c\u7684\u9c81\u68d2\u6027\u4e0b\u964d\u3002\u63d0\u51fa\u4e24\u6b65\u9891\u7387\u5bf9\u9f50\u65b9\u6cd5\uff0c\u65e8\u5728\u6d88\u9664\u771f\u5b9e\u4e0e\u4f2a\u9020\u56fe\u50cf\u4e4b\u95f4\u7684\u9891\u7387\u5dee\u5f02\uff0c\u4f5c\u4e3a\u9ed1\u76d2\u653b\u51fb\u4ee5\u6311\u6218\u73b0\u6709\u68c0\u6d4b\u5668\uff0c\u4ea6\u53ef\u4f5c\u4e3a\u666e\u9002\u9632\u5fa1\u4ee5\u63d0\u5347\u68c0\u6d4b\u5668\u7684\u53ef\u9760\u6027\u3002\u5b9e\u73b0\u4e86\u5bf9\u5e94\u7684\u653b\u51fb\u4e0e\u9632\u5fa1\u7b97\u6cd5\uff0c\u5e76\u572812\u4e2a\u68c0\u6d4b\u5668\u30018\u4e2a\u4f2a\u9020\u6a21\u578b\u30015\u9879\u8bc4\u4f30\u6307\u6807\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u9891\u7387\u5bf9\u9f50\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u8bc1\u5b9e\u8be5\u65b9\u6cd5\u5728\u53cc\u5411\u5e94\u7528\uff08\u653b\u51fb\u4e0e\u9632\u5fa1\uff09\u4e0a\u7684\u53ef\u884c\u6027\uff1b\u5b9e\u9a8c\u8986\u76d6\u5e7f\u6cdb\u8bbe\u7f6e\uff0c\u8868\u660e\u9891\u7387\u504f\u5dee\u662f\u4e00\u4e2a\u5177\u6709\u89e3\u91ca\u529b\u7684\u6839\u6e90\u3002", "conclusion": "\u9891\u7387\u504f\u5dee\u662f\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5728\u6cdb\u5316\u4e0e\u9c81\u68d2\u6027\u65b9\u9762\u7684\u6f5c\u5728\u6839\u6e90\uff1b\u63d0\u51fa\u7684\u4e24\u6b65\u9891\u7387\u5bf9\u9f50\u65b9\u6cd5\u4e3a\u9632\u5fa1\u63d0\u4f9b\u7edf\u4e00\u3001\u666e\u9002\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u4e5f\u53ef\u7528\u4e8e\u53cd\u5411\u653b\u51fb\uff0c\u63ed\u793a\u4e86\u9891\u57df\u7279\u6027\u5728\u4f2a\u9020\u68c0\u6d4b\u4e0e\u5bf9\u6297\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u672a\u6765\u53ef\u6269\u5c55\u5230\u66f4\u5e7f\u7684\u53d6\u8bc1\u573a\u666f\u3002"}}
{"id": "2511.20113", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.20113", "abs": "https://arxiv.org/abs/2511.20113", "authors": ["Xiaojing Yan", "Carlo Fischione"], "title": "Joint Bit-Partitioning and Modulation Design for Digital AirComp", "comment": null, "summary": "For digital over-the-air computation, the ChannelComp framework has recently been proposed to design digital modulations to compute any arbitrary function over a multiple access channel. To reduce modulation design complexity while increasing computation reliability, this paper integrates a bit-partitioning procedure into ChannelComp. The key process is to partition the input bit sequence into several groups, map each group to a single modulation symbol and transmit the encoded symbol sequence across multiple time slots. With the objective to maximize a worst-case constellation distance, we develop two bit-partitioning methods. In uniform bit-partitioning, bits are evenly distributed across groups and modulation is designed via a max-min optimization, which is handled by a CCCP that solves a sequence of second-order cone programming subproblems. In importance-adaptive bit-partitioning (IABP), the bit allocation is adapted to the significance of individual bit positions, and the modulation and partitioning are jointly optimized. To keep the overall complexity manageable, simulated annealing is employed in the outer loop to update the partitioning, while a CCCP-based solver is used in the inner loop for modulation design. Numerical results show that both methods provide robust computation in noisy channels, and IABP achieves up to a 5 dB reduction in computation error compared to Sequential Modulation for AirComp, especially for product computation.", "AI": {"tldr": "\u5c06\u8f93\u5165\u6bd4\u7279\u5212\u5206\u4e3a\u82e5\u5e72\u7ec4\u5e76\u6620\u5c04\u5230\u5355\u4e2a\u8c03\u5236\u7b26\u53f7\uff0c\u901a\u8fc7\u591a\u65f6\u9699\u4f20\u8f93\u5b9e\u73b0\u6570\u5b57AirComp\u4e2d\u7684\u4efb\u610f\u51fd\u6570\u8ba1\u7b97\uff1b\u63d0\u51fauniform bit-partitioning\u548cimportance-adaptive bit-partitioning(IABP)\u4e24\u79cd\u65b9\u6cd5\uff0c\u524d\u8005\u901a\u8fc7max-min\u4f18\u5316\u5e76\u7531CCCP\u6c42\u89e3\u4e00\u7cfb\u5217SOCP\u5b50\u95ee\u9898\uff0c\u540e\u8005\u5728\u6bd4\u7279\u4f4d\u91cd\u8981\u6027\u57fa\u7840\u4e0a\u8fdb\u884c\u81ea\u9002\u5e94\u5206\u533a\u4e0e\u8c03\u5236\u8bbe\u8ba1\uff0c\u5916\u5c42\u7528\u6a21\u62df\u9000\u706b\u4f18\u5316\u5206\u533a\uff0c\u5185\u5c42\u7528CCCP\u6c42\u89e3\u8c03\u5236\uff1b\u7ed3\u679c\u8868\u660e\u4e24\u79cd\u65b9\u6cd5\u5728\u566a\u58f0\u4fe1\u9053\u4e2d\u9c81\u68d2\uff0cIABP\u5728\u4e58\u79ef\u8ba1\u7b97\u573a\u666f\u4e0b\u5bf9\u6bd4Sequential Modulation for AirComp\u8bef\u5dee\u53ef\u964d\u4f4e\u6700\u591a5 dB\u3002", "motivation": "\u5728\u6570\u5b57AirComp\u4e2d\u7684ChannelComp\u6846\u67b6\u4e0b\uff0c\u964d\u4f4e\u8c03\u5236\u8bbe\u8ba1\u590d\u6742\u5ea6\u5e76\u63d0\u5347\u8ba1\u7b97\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u63d0\u5347\u5bf9\u566a\u58f0\u4fe1\u9053\u7684\u9c81\u68d2\u6027\u4e0e\u8ba1\u7b97\u7cbe\u5ea6\u3002", "method": "\u628a\u8f93\u5165\u6bd4\u7279\u5e8f\u5217\u5206\u6210\u82e5\u5e72\u7ec4\uff0c\u6bcf\u7ec4\u6620\u5c04\u5230\u4e00\u4e2a\u8c03\u5236\u7b26\u53f7\uff0c\u901a\u8fc7\u591a\u65f6\u9699\u4f20\u8f93\u5b9e\u73b0\u6240\u9700\u7684\u51fd\u6570\u8ba1\u7b97\u3002uniform bit-partitioning\uff1a\u6bd4\u7279\u5747\u5300\u5206\u5e03\uff0c\u91c7\u7528max-min\u4f18\u5316\uff0cCCCP\u6c42\u89e3\u4e00\u7cfb\u5217SOCP\u5b50\u95ee\u9898\u3002IABP\uff1a\u6bd4\u7279\u4f4d\u7684\u91cd\u8981\u6027\u51b3\u5b9a\u5206\u914d\uff0c\u8c03\u5236\u4e0e\u5206\u533a\u8054\u5408\u4f18\u5316\uff0c\u5916\u5c42\u7528 simulated annealing \u66f4\u65b0\u5206\u533a\uff0c\u5185\u5c42\u7528 CCCP \u6c42\u89e3\u8c03\u5236\u8bbe\u8ba1\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u5728\u566a\u58f0\u4fe1\u9053\u4e0b\u5747\u663e\u793a\u9c81\u68d2\u6027\uff1bIABP\u76f8\u8f83\u4e8eSequential Modulation for AirComp\u5728\u8ba1\u7b97\u8bef\u5dee\u65b9\u9762\u63d0\u5347\u663e\u8457\uff0c\u8fbe\u5cf0\u503c\u7ea65 dB\uff0c\u5c24\u5176\u5728\u4e58\u79ef\u8ba1\u7b97\u573a\u666f\u3002", "conclusion": "\u5f15\u5165\u7684\u6bd4\u7279\u5206\u533a\u8c03\u5236\u8bbe\u8ba1\u6709\u6548\u964d\u4f4e\u8c03\u5236\u8bbe\u8ba1\u590d\u6742\u5ea6\u5e76\u63d0\u5347AirComp\u7684\u8ba1\u7b97\u9c81\u68d2\u6027\uff0cIABP\u5728\u9700\u8981\u5bf9\u6bd4\u5ea6\u8f83\u9ad8\u7684\u4e58\u79ef\u8ba1\u7b97\u4e2d\u5177\u6709\u66f4\u4f18\u8868\u73b0\uff0c\u9a8c\u8bc1\u4e86\u4f4d\u5206\u533a\u7684ChannelComp\u6846\u67b6\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2511.19770", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19770", "abs": "https://arxiv.org/abs/2511.19770", "authors": ["Peter Iwer Hoedt Karstensen", "Roberto Galeazzi"], "title": "Multi-Hypotheses Ego-Tracking for Resilient Navigation", "comment": null, "summary": "Autonomous robots relying on radio frequency (RF)-based localization such as global navigation satellite system (GNSS), ultra-wide band (UWB), and 5G integrated sensing and communication (ISAC) are vul- nerable to spoofing and sensor manipulation. This paper presents a resilient navigation architecture that combines multi-hypothesis estimation with a Poisson binomial windowed-count detector for anomaly identi- fication and isolation. A state machine coordinates transitions between operation, diagnosis, and mitigation, enabling adaptive response to adversarial conditions. When attacks are detected, trajectory re-planning based on differential flatness allows information-gathering maneuvers minimizing performance loss. Case studies demonstrate effective detection of biased sensors, maintenance of state estimation, and recovery of nominal operation under persistent spoofing attacks", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9c81\u68d2\u5bfc\u822a\u4f53\u7cfb\uff0c\u901a\u8fc7\u591a\u5047\u8bbe\u4f30\u8ba1\u4e0e\u6cca\u677e\u4e8c\u9879\u7a97\u8ba1\u6570\u68c0\u6d4b\u5b9e\u73b0\u5f02\u5e38\u8bc6\u522b\u4e0e\u9694\u79bb\uff1b\u4ee5\u72b6\u6001\u673a\u534f\u8c03\u8fd0\u884c/\u8bca\u65ad/\u7f13\u89e3\uff0c\u5e76\u5728\u653b\u51fb\u53d1\u751f\u65f6\u5229\u7528\u5fae\u5206\u5e73\u76f4\u6027\u8fdb\u884c\u8f68\u8ff9\u91cd\u89c4\u5212\u4ee5\u964d\u4f4e\u6027\u80fd\u635f\u5931\uff1b\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u5bf9\u504f\u7f6e\u4f20\u611f\u5668\u7684\u6709\u6548\u68c0\u6d4b\u3001\u72b6\u6001\u4f30\u8ba1\u7684\u7ef4\u6301\u53ca\u5728\u6301\u7eed\u6b3a\u9a97\u653b\u51fb\u4e0b\u6062\u590d\u5230\u6807\u79f0\u64cd\u4f5c\u3002", "motivation": "RF\u5b9a\u4f4d\u7cfb\u7edf\u6613\u53d7 spoofing\u3001\u4f20\u611f\u5668\u64cd\u63a7\u7684\u5f71\u54cd\uff0c\u4e9f\u9700\u5728\u5bf9\u6297\u6761\u4ef6\u4e0b\u4fdd\u6301\u5bfc\u822a\u53ef\u7528\u6027\u4e0e\u9c81\u68d2\u6027\u3002", "method": "\u5c06\u591a\u5047\u8bbe\u4f30\u8ba1\u3001\u6cca\u677e\u4e8c\u9879\u5f0f\u7a97\u8ba1\u6570\u68c0\u6d4b\u7ed3\u5408\uff0c\u8fdb\u884c\u5f02\u5e38\u8bc6\u522b\u4e0e\u9694\u79bb\uff1b\u7528\u72b6\u6001\u673a\u5728\u6b63\u5e38\u3001\u8bca\u65ad\u3001\u7f13\u89e3\u4e4b\u95f4\u5207\u6362\u5b9e\u73b0\u81ea\u9002\u5e94\u54cd\u5e94\uff1b\u5728\u68c0\u6d4b\u5230\u653b\u51fb\u65f6\uff0c\u57fa\u4e8e\u5fae\u5206\u5e73\u76f4\u6027\u5b9e\u73b0\u8f68\u8ff9\u91cd\u89c4\u5212\u4ee5\u8fdb\u884c\u4fe1\u606f\u6536\u96c6\u5e76\u6700\u5c0f\u5316\u6027\u80fd\u635f\u5931\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u504f\u7f6e\u4f20\u611f\u5668\u3001\u7ef4\u6301\u72b6\u6001\u4f30\u8ba1\u7684\u8fde\u8d2f\u6027\uff0c\u5e76\u5728\u6301\u7eed\u7684\u6b3a\u9a97\u653b\u51fb\u4e0b\u6062\u590d\u5230\u540d\u4e49\u64cd\u4f5c\u3002", "conclusion": "\u63d0\u51fa\u7684\u9c81\u68d2\u5bfc\u822a\u6846\u67b6\u5728\u5bf9\u6297\u6027\u6761\u4ef6\u4e0b\u63d0\u9ad8\u4f20\u611f\u5668\u5197\u4f59\u5229\u7528\u3001\u5feb\u901f\u9694\u79bb\u6545\u969c\u3001\u4ee5\u53ca\u6267\u884c\u4fe1\u606f\u83b7\u53d6\u884c\u52a8\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u9c81\u68d2\u6027\u7684\u7efc\u5408\u589e\u5f3a\u3002"}}
{"id": "2511.19486", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19486", "abs": "https://arxiv.org/abs/2511.19486", "authors": ["Lei Wang", "Zikun Ye", "Jinglong Zhao"], "title": "Efficient Inference Using Large Language Models with Limited Human Data: Fine-Tuning then Rectification", "comment": null, "summary": "Driven by recent advances in artificial intelligence (AI), a growing body of work demonstrates the potential of using large language models (LLMs) to generate human-like responses in market research and social science applications. Two primary approaches can be applied to improve the performance of LLMs: fine-tuning, which aligns LLM predictions more closely with human responses, and rectification, which corrects biases in LLM outputs. In this paper, we develop a framework that combines fine-tuning and rectification, and optimally allocates limited labeled samples across the two stages. Unlike the conventional objective that minimizes the mean squared prediction errors, we propose to minimize the variance of the prediction errors as the fine-tuning objective, which is optimal for the downstream rectification stage. Building on this insight, we leverage empirical scaling laws to develop a data-driven method for optimally splitting samples between the fine-tuning and rectification stages. Empirical analysis validates our framework, demonstrating improved estimation and inference performance compared to using either fine-tuning or rectification alone.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5c06\u5fae\u8c03\uff08fine-tuning\uff09\u4e0e\u4fee\u6b63\uff08rectification\uff09\u76f8\u7ed3\u5408\u7684\u6846\u67b6\uff0c\u9488\u5bf9\u6709\u9650\u6807\u6ce8\u6837\u672c\u5728\u4e24\u9636\u6bb5\u4e4b\u95f4\u7684\u6700\u4f18\u5206\u914d\u8fdb\u884c\u6570\u636e\u9a71\u52a8\u5206\u914d\u3002\u5fae\u8c03\u76ee\u6807\u4ece\u5747\u65b9\u8bef\u5dee\u6539\u4e3a\u9884\u6d4b\u8bef\u5dee\u65b9\u5dee\uff0c\u4ee5\u5229\u4e8e\u540e\u7eed\u4fee\u6b63\u9636\u6bb5\u3002\u5e76\u57fa\u4e8e\u7ecf\u9a8c\u5c3a\u5ea6\u5b9a\u5f8b\u63a8\u5bfc\u51fa\u6700\u4f73\u6837\u672c\u5206\u5272\u7b56\u7565\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u8054\u5408\u65b9\u5f0f\u5728\u4f30\u8ba1\u548c\u63a8\u65ad\u6027\u80fd\u4e0a\u4f18\u4e8e\u4ec5\u4f7f\u7528\u5fae\u8c03\u6216\u4fee\u6b63\u7684\u5355\u72ec\u7b56\u7565\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\uff0cLLMs\u5728\u5e02\u573a\u7814\u7a76\u4e0e\u793e\u4f1a\u79d1\u5b66\u4e2d\u5177\u5907\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u66f4\u597d\u7684\u5bf9\u9f50\u4e0e\u504f\u5dee\u4fee\u6b63\uff0c\u540c\u65f6\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\uff0c\u9700\u9ad8\u6548\u7684\u6570\u636e\u5206\u914d\u7b56\u7565\u6765\u63d0\u5347\u4e0b\u6e38\u63a8\u65ad\u7684\u51c6\u786e\u6027\u4e0e\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5c06\u5fae\u8c03\u4e0e\u4fee\u6b63\u7ed3\u5408\u7684\u6846\u67b6\uff0c\u5e76\u5c06\u5fae\u8c03\u76ee\u6807\u8bbe\u5b9a\u4e3a\u6700\u5c0f\u5316\u9884\u6d4b\u8bef\u5dee\u65b9\u5dee\uff1b\u5229\u7528\u7ecf\u9a8c\u5c3a\u5ea6\u5b9a\u5f8b\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u5728\u4e24\u9636\u6bb5\u4e4b\u95f4\u5206\u914d\u6709\u9650\u6807\u6ce8\u6837\u672c\u3002", "result": "\u5b9e\u8bc1\u5206\u6790\u663e\u793a\uff0c\u4e0e\u4ec5\u4f7f\u7528\u5fae\u8c03\u6216\u4ec5\u4f7f\u7528\u4fee\u6b63\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u5728\u4f30\u8ba1\u4e0e\u63a8\u65ad\u6027\u80fd\u4e0a\u5177\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u8054\u5408\u4f18\u5316\u7684\u5fae\u8c03\u4e0e\u4fee\u6b63\u6846\u67b6\u53ca\u5176\u6570\u636e\u5206\u5272\u7b56\u7565\u80fd\u591f\u5728\u6570\u636e\u53d7\u9650\u573a\u666f\u4e0b\u63d0\u5347LLMs\u7684\u4e0b\u6e38\u8868\u73b0\u4e0e\u63a8\u65ad\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.19902", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19902", "abs": "https://arxiv.org/abs/2511.19902", "authors": ["Yunxiao Wang"], "title": "Zero-Knowledge Proof Based Verifiable Inference of Models", "comment": null, "summary": "Recent advances in artificial intelligence (AI), particularly deep learning, have led to widespread adoption across various applications. Yet, a fundamental challenge persists: how can we verify the correctness of AI model inference when model owners cannot (or will not) reveal their parameters? These parameters represent enormous training costs and valuable intellectual property, making transparent verification difficult. In this paper, we introduce a zero-knowledge framework capable of verifying deep learning inference without exposing model internal parameters. Built on recursively composed zero-knowledge proofs and requiring no trusted setup, our framework supports both linear and nonlinear neural network layers, including matrix multiplication, normalization, softmax, and SiLU. Leveraging the Fiat-Shamir heuristic, we obtain a succinct non-interactive argument of knowledge (zkSNARK) with constant-size proofs. To demonstrate the practicality of our approach, we translate the DeepSeek model into a fully SNARK-verifiable version named ZK-DeepSeek and show experimentally that our framework delivers both efficiency and flexibility in real-world AI verification workloads.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u96f6\u77e5\u8bc6\u6846\u67b6\uff0c\u5728\u4e0d\u66b4\u9732\u6a21\u578b\u53c2\u6570\u7684\u524d\u63d0\u4e0b\u9a8c\u8bc1\u6df1\u5ea6\u5b66\u4e60\u63a8\u65ad\uff0c\u652f\u6301\u7ebf\u6027/\u975e\u7ebf\u6027\u5c42\uff0c\u4f7f\u7528\u9012\u5f52\u96f6\u77e5\u8bc6\u8bc1\u660e\u548cFiat-Shamir\uff0c\u5f97\u5230zkSNARK\uff0c\u4e14\u5bf9DeepSeek\u6a21\u578b\u5b9e\u73b0ZK-DeepSeek\uff0c\u5b9e\u9a8c\u8868\u660e\u9ad8\u6548\u3001\u7075\u6d3b\u3002", "motivation": "\u5f53\u524dAI\u63a8\u65ad\u9a8c\u8bc1\u9700\u8981\u66b4\u9732\u5185\u90e8\u53c2\u6570\uff0c\u4f46\u6a21\u578b\u53c2\u6570\u6210\u672c\u9ad8\u3001\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u9700\u6c42\u5f3a\uff0c\u9700\u4e00\u79cd\u65e0\u9700\u4fe1\u4efb\u8bbe\u7f6e\u7684\u96f6\u77e5\u8bc6\u9a8c\u8bc1\u65b9\u6cd5\u6765\u9a8c\u8bc1\u63a8\u65ad\u6b63\u786e\u6027\u3002", "method": "\u57fa\u4e8e\u9012\u5f52\u6784\u6210\u7684\u96f6\u77e5\u8bc6\u8bc1\u660e\u6846\u67b6\uff0c\u4e0d\u9700\u8981\u4fe1\u4efb\u8bbe\u7f6e\uff0c\u8986\u76d6\u77e9\u9635\u4e58\u6cd5\u3001\u5f52\u4e00\u5316\u3001softmax\u3001SiLU\u7b49\u7ebf\u6027/\u975e\u7ebf\u6027\u5c42\uff0c\u7ed3\u5408Fiat-Shamir\u5c06\u591a\u6bb5\u8bc1\u660e\u53d8\u4e3azkSNARK\u5e76\u63d0\u4f9b\u5e38\u6570\u5927\u5c0f\u8bc1\u660e\u3002\u5c06DeepSeek\u6a21\u578b\u6539\u5199\u4e3aZK-DeepSeek\u4ee5\u4fbf\u53ef\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u4e0a\u5b9e\u73b0\u53ef\u8bc1\u660e\u6027\u548c\u5e38\u6570\u5927\u5c0f\u8bc1\u636e\uff1b\u5728\u5b9e\u8df5\u4e2d\u5c06DeepSeek\u6539\u5199\u4e3aZK-DeepSeek\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5c55\u793a\u5728\u771f\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u6548\u7387\u4e0e\u7075\u6d3b\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u96f6\u77e5\u8bc6\u6846\u67b6\u53ef\u5728\u4e0d\u6cc4\u9732\u6a21\u578b\u5185\u90e8\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684\u6df1\u5ea6\u5b66\u4e60\u63a8\u65ad\u9a8c\u8bc1\uff0c\u4e14\u901a\u8fc7\u65e0\u4fe1\u4efb\u8bbe\u7f6e\u548czkSNARK\u5b9e\u73b0\u5177\u5907\u53ef\u90e8\u7f72\u6027\uff1b\u5bf9AI\u5b89\u5168\u3001\u8de8\u673a\u6784\u9a8c\u8bc1\u7b49\u573a\u666f\u5177\u6709\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.20203", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.20203", "abs": "https://arxiv.org/abs/2511.20203", "authors": ["Junjie Ye", "Zhaolin Wang", "Yuanwei Liu", "Peichang Zhang", "Lei Huang", "Arumugam Nallanathan"], "title": "Optimal Waveform Design for Continuous Aperture Array (CAPA)-aided ISAC Systems", "comment": "Submitted to IEEE journal for future publication", "summary": "A novel continuous-aperture-array (CAPA)-aided integrated sensing and communication (ISAC) framework is proposed. Specifically, an optimal continuous ISAC waveform is designed to form a directive beampattern for multi-target sensing while suppressing the multi-user interference (MUI). To achieve the goal of optimal waveform design, the directional beampattern of CAPA is first derived based on Green's function, whereafter a reference sensing waveform is obtained through wavenumber-domain optimization. Based on the reference sensing waveform, a weighted functional programming on the tradeoff between sensing beampattern mismatch and MUI is formulated. To solve the resulting problem, an optimal CAPA-ISAC waveform structure is analytically derived using a Lagrangian-transformation and calculus-of-variations method, where the Lagrangian multiplier associated with the optimal waveform structure is determined via Bisection search. The obtained optimal waveform reveals that it is concurrently affected by the reference sensing waveform, the channel correlations and the channel-symbol correlations. Finally, numerical results validate the effectiveness of the proposed system and waveform design, demonstrating that CAPA can achieve significant performance gains against the ISAC designs based on conventional spatially discrete array in both sensing accuracy and communication reliability.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8fde\u7eed\u5b54\u5f84\u9635\u5217(CAPA)\u7684ISAC\u6846\u67b6\uff0c\u8bbe\u8ba1\u6700\u4f18\u8fde\u7eed\u6ce2\u5f62\u4ee5\u5b9e\u73b0\u6307\u5411\u6027\u76ee\u6807\u611f\u77e5\u7684\u6ce2\u675f\u6a21\u5f0f\u5e76\u6291\u5236\u591a\u7528\u6237\u5e72\u6270\uff08MUI\uff09\u3002\u901a\u8fc7Green\u51fd\u6570\u63a8\u5bfcCAPA\u5b9a\u5411\u6ce2\u675f\uff0c\u57fa\u4e8e\u6ce2\u6570\u57df\u4f18\u5316\u83b7\u5f97\u53c2\u8003\u611f\u77e5\u6ce2\u5f62\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u5bf9\u611f\u77e5\u6ce2\u675f\u4e0eMUI\u4e4b\u95f4\u7684\u6743\u8861\u8fdb\u884c\u52a0\u6743\u6cdb\u51fd\u89c4\u5212\uff0c\u5229\u7528\u62c9\u683c\u6717\u65e5\u53d8\u6362\u4e0e\u53d8\u5206\u6cd5\u5f97\u5230\u6700\u4f18\u6ce2\u5f62\u7ed3\u6784\uff0c\u62c9\u683c\u6717\u65e5\u4e58\u5b50\u901a\u8fc7\u4e8c\u5206\u6cd5\u7ed9\u51fa\u3002\u6570\u503c\u7ed3\u679c\u8868\u660eCAPA\u76f8\u8f83\u4e8e\u4f20\u7edf\u79bb\u6563\u9635\u5217\u5728\u611f\u77e5\u7cbe\u5ea6\u4e0e\u901a\u4fe1\u53ef\u9760\u6027\u65b9\u9762\u5177\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u5728\u8054\u5408\u611f\u77e5\u548c\u901a\u4fe1\uff08ISAC\uff09\u573a\u666f\u4e2d\uff0c\u79bb\u6563\u9635\u5217\u7684\u6ce2\u675f\u5f62\u6210\u5bf9\u611f\u77e5\u4e0e\u5e72\u6270\u6291\u5236\u7684\u9650\u5236\uff0c\u63d0\u51fa\u5229\u7528\u8fde\u7eed\u5b54\u5f84\u9635\u5217\u4ee5\u63d0\u5347\u611f\u77e5\u4e0e\u901a\u4fe1\u7684\u7efc\u5408\u6027\u80fd\u3002", "method": "1) \u57fa\u4e8eGreen\u51fd\u6570\u63a8\u5bfcCAPA\u7684\u5b9a\u5411\u6ce2\u675f\u6a21\u5f0f\uff1b2) \u901a\u8fc7\u6ce2\u6570\u57df\u4f18\u5316\u5f97\u5230\u53c2\u8003\u611f\u77e5\u6ce2\u5f62\uff1b3) \u5728\u53c2\u8003\u6ce2\u5f62\u57fa\u7840\u4e0a\u5efa\u7acb\u5bf9\u611f\u77e5\u6ce2\u675f\u5931\u914d\u4e0eMUI\u4e4b\u95f4\u6743\u8861\u7684\u52a0\u6743\u6cdb\u51fd\u89c4\u5212\uff1b4) \u91c7\u7528\u62c9\u683c\u6717\u65e5\u53d8\u6362\u4e0e\u53d8\u5206\u6cd5\u63a8\u5bfc\u6700\u4f18\u6ce2\u5f62\u7ed3\u6784\uff0c\u5e76\u7528\u4e8c\u5206\u6cd5\u6c42\u89e3\u76f8\u5e94\u7684\u62c9\u683c\u6717\u65e5\u4e58\u5b50\uff1b5) \u5206\u6790\u6700\u4f18\u6ce2\u5f62\u5bf9\u53c2\u8003\u6ce2\u5f62\u3001\u4fe1\u9053\u76f8\u5173\u4e0e\u4fe1\u9053\u7b26\u53f7\u76f8\u5173\u6027\u7684\u5f71\u54cd\u3002", "result": "\u5f97\u5230\u7684\u6700\u4f18\u6ce2\u5f62\u7ed3\u6784\u8868\u660e\u6ce2\u5f62\u53d7\u53c2\u8003\u611f\u77e5\u6ce2\u5f62\u3001\u4fe1\u9053\u76f8\u5173\u6027\u4ee5\u53ca\u4fe1\u9053-\u7b26\u53f7\u76f8\u5173\u6027\u5171\u540c\u5f71\u54cd\u3002\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0CAPA\u5728\u611f\u77e5\u51c6\u786e\u6027\u548c\u901a\u4fe1\u53ef\u9760\u6027\u65b9\u9762\u5bf9\u6bd4\u79bb\u6563\u9635\u5217ISAC\u7684\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684CAPA-ISAC\u603b\u4f53\u8bbe\u8ba1\u4e0e\u6700\u4f18\u6ce2\u5f62\u63a8\u5bfc\u4e3a\u8fde\u7eed\u5b54\u5f84\u9635\u5217\u5728ISAC\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u529b\u7406\u8bba\u4e0e\u5b9e\u9a8c\u4f9d\u636e\uff0c\u663e\u793a\u51fa\u5728\u591a\u76ee\u6807\u611f\u77e5\u548c\u591a\u7528\u6237\u5e72\u6270\u6291\u5236\u65b9\u9762\u7684\u6f5c\u5728\u4f18\u52bf\u3002"}}
{"id": "2511.19487", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19487", "abs": "https://arxiv.org/abs/2511.19487", "authors": ["Ben Shaw", "Adam Rustad", "Sofia Pelagalli Maia", "Jake S. Rhodes", "Kevin R. Moon"], "title": "The Generalized Proximity Forest", "comment": null, "summary": "Recent work has demonstrated the utility of Random Forest (RF) proximities for various supervised machine learning tasks, including outlier detection, missing data imputation, and visualization. However, the utility of the RF proximities depends upon the success of the RF model, which itself is not the ideal model in all contexts. RF proximities have recently been extended to time series by means of the distance-based Proximity Forest (PF) model, among others, affording time series analysis with the benefits of RF proximities. In this work, we introduce the generalized PF model, thereby extending RF proximities to all contexts in which supervised distance-based machine learning can occur. Additionally, we introduce a variant of the PF model for regression tasks. We also introduce the notion of using the generalized PF model as a meta-learning framework, extending supervised imputation capability to any pre-trained classifier. We experimentally demonstrate the unique advantages of the generalized PF model compared with both the RF model and the $k$-nearest neighbors model.", "AI": {"tldr": "Generalized Proximity Forest (PF) extends Random Forest (RF) proximities to any supervised distance-based learning, including regression and a meta-learning framework for imputation, with demonstrated advantages over RF and k-NN.", "motivation": "RF proximities are powerful but limited by RF's own model; extending proximities to broader contexts (time series, regression, imputation) can enhance supervised distance-based tasks and provide versatile tools for data analysis.", "method": "Introduce the generalized PF model, along with a regression-specific PF variant; propose using generalized PF as a meta-learning framework to enable imputation with any pre-trained classifier; conduct experiments comparing generalized PF to RF and k-NN across relevant tasks.", "result": "Show that generalized PF offers unique advantages over traditional RF proximities and k-NN in supervised distance-based tasks, including outlier detection, missing data imputation, and regression, with benefits also seen in visualization contexts.", "conclusion": "Generalized PF broadens the applicability of RF proximities to all supervised distance-based learning scenarios and can serve as a versatile meta-learning tool for imputation, potentially outperforming standard RF and k-NN in key tasks."}}
{"id": "2511.20265", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.20265", "abs": "https://arxiv.org/abs/2511.20265", "authors": ["Can Zheng", "Jiguang He", "Chung G. Kang", "Guofa Cai", "Chongwen Huang", "Henk Wymeersch"], "title": "Rectified Flow for Vision-Aided mmWave V2I Beam Prediction", "comment": "6 pages, 5 figures, submitted to conference", "summary": "This paper proposes a flow matching (FM) framework based on rectified flow for vision-aided beam prediction in vehicle-to-infrastructure (V2I) links. Instead of modeling discrete beam index sequences, the method learns a continuous latent flow governed by an ordinary differential equation (ODE)-based vector field, enabling smooth beam trajectories and fast sampling. A terminal flow constraint enforces global consistency under finite-step integration, stabilizing long-term prediction. The resulting FM-based model significantly improves top-K accuracy over RNN and LSTM baselines, approaches the performance of large language model-based approaches, and achieves inference speedups on the order of 10 x and 10^4 x on identical GPU and CPU deployments, respectively.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e rectified flow \u7684\u6d41\u5339\u914d\u6846\u67b6\uff0c\u7528\u4e8e V2I \u89c6\u89c9\u8f85\u52a9\u6ce2\u675f\u9884\u6d4b\uff1b\u901a\u8fc7 ODE \u5411\u91cf\u573a\u5b66\u4e60\u8fde\u7eed\u6f5c\u5728\u6d41\uff0c\u5b9e\u73b0\u5e73\u6ed1\u8f68\u8ff9\u548c\u5feb\u901f\u91c7\u6837\uff1b\u5f15\u5165\u7ec8\u7aef\u6d41\u7ea6\u675f\u4ee5\u63d0\u5347\u5168\u5c40\u4e00\u81f4\u6027\u5e76\u7a33\u5b9a\u957f\u65f6\u9884\u6d4b\uff1b\u5728 top-K \u7cbe\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e RNN/LSTM \u57fa\u7ebf\uff0c\u63a5\u8fd1\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\uff0c\u5e76\u5728 GPU/CPU \u4e0a\u5206\u522b\u5b9e\u73b0\u7ea6 10x \u7684\u63a8\u7406\u52a0\u901f\u3002", "motivation": "V2I \u573a\u666f\u4e0b\u9700\u8981\u9ad8\u7cbe\u5ea6\u3001\u4f4e\u5ef6\u8fdf\u7684\u6ce2\u675f\u9884\u6d4b\u3002\u5c06\u79bb\u6563\u6ce2\u675f\u7d22\u5f15\u5e8f\u5217\u5efa\u6a21\u5e26\u6765\u4e0d\u7a33\u5b9a\u6027\u4e0e\u590d\u6742\u6027\uff0c\u8fde\u7eed\u6f5c\u5728\u6d41\u4e0e ODE \u5411\u91cf\u573a\u4e3a\u9884\u6d4b\u63d0\u4f9b\u66f4\u5e73\u6ed1\u3001\u53ef\u63a7\u7684\u8f68\u8ff9\uff0c\u540c\u65f6\u5feb\u901f\u91c7\u6837\u4ee5\u63d0\u5347\u5b9e\u65f6\u6027\uff1b\u7ec8\u7aef\u7ea6\u675f\u786e\u4fdd\u5728\u6709\u9650\u6b65\u79ef\u5206\u4e0b\u4ecd\u5177\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u6539\u5584\u957f\u671f\u9884\u6d4b\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e rectified flow \u7684\u6d41\u5339\u914d\u6846\u67b6\u3002\u5c06\u89c6\u89c9\u4fe1\u606f\u6620\u5c04\u5230\u6f5c\u5728\u6d41\uff0c\u901a\u8fc7\u4e00\u4e2a\u7531\u5e38\u5fae\u5206\u65b9\u7a0b\u63cf\u8ff0\u7684\u5411\u91cf\u573a\u6765\u9a71\u52a8\u8be5\u6d41\uff1b\u4f7f\u7528\u7ec8\u7aef\u6d41\u7ea6\u675f\u5728\u6709\u9650\u6b65\u79ef\u5206\u4e0b\u5b9e\u73b0\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u5e76\u63d0\u9ad8\u7a33\u5b9a\u6027\uff1b\u8bad\u7ec3\u4ee5\u63d0\u5347 top-K \u7cbe\u5ea6\u4e0e\u63a8\u7406\u901f\u5ea6\u3002", "result": "\u4e0e RNN\u3001LSTM \u57fa\u7ebf\u76f8\u6bd4\uff0cFM \u80fd\u663e\u8457\u63d0\u5347 top-K \u7cbe\u5ea6\uff1b\u63a5\u8fd1\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u7684\u6027\u80fd\uff1b\u5728\u76f8\u540c GPU \u4e0a\u5b9e\u73b0\u7ea6 10x \u7684\u63a8\u7406\u52a0\u901f\uff0c\u5728 CPU \u4e0a\u5b9e\u73b0\u7ea6 10^4x \u7684\u52a0\u901f\u3002", "conclusion": "\u57fa\u4e8e rectified flow \u7684\u6d41\u5339\u914d\u6846\u67b6\u5728\u89c6\u89c9\u8f85\u52a9\u6ce2\u675f\u9884\u6d4b\u4e2d\u63d0\u4f9b\u4e86\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u63a8\u7406\uff0c\u514b\u670d\u79bb\u6563\u5e8f\u5217\u5efa\u6a21\u7684\u5c40\u9650\uff0c\u5177\u5907\u826f\u597d\u7684\u957f\u65f6\u7a33\u5b9a\u6027\u4e0e\u53ef\u6269\u5c55\u6027\uff0c\u9002\u5408\u5bf9\u5b9e\u65f6\u6027\u8981\u6c42\u8f83\u9ad8\u7684 V2I \u5e94\u7528\u3002"}}
{"id": "2511.20117", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.20117", "abs": "https://arxiv.org/abs/2511.20117", "authors": ["Min Xu", "Xuejiao Han", "Kai Wan", "Gennian Ge"], "title": "On hierarchical secure aggregation against relay and user collusion", "comment": null, "summary": "Secure aggregation (SA) is fundamental to privacy preservation in federated learning (FL), enabling model aggregation while preventing disclosure of individual user updates. This paper addresses hierarchical secure aggregation (HSA) against relay and user collusion in homogeneous networks, where each user connects to $n$ relays and each relay serves $m$ users. In the two-phase communication framework, users transmit masked data to relays, which then process and forward compiled messages to the server for exact sum recovery. The primary objective is to devise a transmission scheme such that the server can finish the aggregation task, while any group of $T_h$ colluding relays and $T_u$ colluding users cannot reveal any information about the data owned by the non-colluding users. In this study, we establish fundamental limits on the communication load, defined as the ratio of transmitted information size to original data size, for each user-relay link and each relay-server link. Achievable thresholds for collusion resilience are also derived. When the number of colluding relays and users falls below certain critical thresholds, we construct communication-optimal schemes using methods from network function computation. A limitation of these schemes is their reliance on large random keys. To address this, we derive a lower bound on the required key size and prove its achievability in cyclic networks, where users are connected to relays in a cyclic wrap-around manner. By establishing a connection between HSA and network function computation, this work advances the theoretical limits of communication efficiency and information-theoretic security in secure aggregation.", "AI": {"tldr": "This work analyzes hierarchical secure aggregation (HSA) in federated learning under relay and user collusion, derives fundamental limits on communication loads, provides collusion-resilient schemes, and links HSA with network function computation to advance information-theoretic security and efficiency.", "motivation": "To enable privacy-preserving federated learning with hierarchical secure aggregation in the presence of colluding relays and users, while optimizing communication efficiency.", "method": "Modeling a homogeneous network where each user connects to n relays and each relay serves m users. A two-phase communication protocol is analyzed: users send masked data to relays, relays process and forward to a server to enable exact sum recovery. The paper derives lower bounds on per-link communication load, constructs collusion-resilient schemes when colluding parties are below thresholds, and addresses large random-key requirements. It also provides a key-size bound and achievability results for cyclic networks, and connects HSA to network function computation.", "result": "Fundamental limits on per-link communication loads and collusion thresholds are established. When the number of colluding relays/users is below critical values, communication-optimal schemes are constructed. A lower bound on required key size is derived, with achievability proven in cyclic networks. The work also links HSA with network function computation to broaden theoretical insights.", "conclusion": "The study advances the theoretical limits of communication efficiency and information-theoretic security in secure aggregation by integrating hierarchical secure aggregation with network function computation, and by providing practical insights for key-size requirements and collusion-resilient schemes."}}
{"id": "2511.19490", "categories": ["cs.LG", "cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.19490", "abs": "https://arxiv.org/abs/2511.19490", "authors": ["Guijun Liu", "Yuwen Cao", "Tomoaki Ohtsuki", "Jiguang He", "Shahid Mumtaz"], "title": "Generative Model-Aided Continual Learning for CSI Feedback in FDD mMIMO-OFDM Systems", "comment": null, "summary": "Deep autoencoder (DAE) frameworks have demonstrated their effectiveness in reducing channel state information (CSI) feedback overhead in massive multiple-input multiple-output (mMIMO) orthogonal frequency division multiplexing (OFDM) systems. However, existing CSI feedback models struggle to adapt to dynamic environments caused by user mobility, requiring retraining when encountering new CSI distributions. Moreover, returning to previously encountered environments often leads to performance degradation due to catastrophic forgetting. Continual learning involves enabling models to incorporate new information while maintaining performance on previously learned tasks. To address these challenges, we propose a generative adversarial network (GAN)-based learning approach for CSI feedback. By using a GAN generator as a memory unit, our method preserves knowledge from past environments and ensures consistently high performance across diverse scenarios without forgetting. Simulation results show that the proposed approach enhances the generalization capability of the DAE framework while maintaining low memory overhead. Furthermore, it can be seamlessly integrated with other advanced CSI feedback models, highlighting its robustness and adaptability.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eGAN\u7684\u6301\u7eed\u5b66\u4e60\u6846\u67b6\u7528\u4e8eCSI\u53cd\u9988\uff0c\u5c06GAN\u751f\u6210\u5668\u4f5c\u4e3a\u8bb0\u5fc6\u5355\u5143\u4ee5\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\uff0c\u63d0\u5347DAE\u5728mMIMO-OFDM\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e14\u5185\u5b58\u5f00\u9500\u4f4e\uff0c\u80fd\u4e0e\u5176\u5b83CSI\u53cd\u9988\u6a21\u578b\u517c\u5bb9\u3002", "motivation": "\u7531\u4e8e\u7528\u6237\u79fb\u52a8\u5bfc\u81f4CSI\u5206\u5e03\u968f\u73af\u5883\u52a8\u6001\u53d8\u5316\uff0c\u73b0\u6709DAE\u9700\u91cd\u65b0\u8bad\u7ec3\uff1b\u8fd4\u56de\u5230\u5df2\u89c1\u73af\u5883\u65f6\u4f1a\u53d1\u751f\u707e\u96be\u6027\u9057\u5fd8\u3002\u9700\u8981\u4e00\u79cd\u5728\u4fdd\u6301\u65e7\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u5b66\u4e60\u65b0\u4efb\u52a1\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u5728GAN\u6846\u67b6\u4e2d\uff0c\u5c06\u751f\u6210\u5668\u4f5c\u4e3a\u8bb0\u5fc6\u5355\u5143\uff0c\u4fdd\u5b58\u8fc7\u53bb\u73af\u5883\u7684\u77e5\u8bc6\uff0c\u901a\u8fc7\u5bf9\u65b0\u73af\u5883\u8fdb\u884c\u589e\u91cf\u8bad\u7ec3\u800c\u4e0d\u663e\u8457\u524a\u5f31\u65e7\u77e5\u8bc6\uff1b\u7ed3\u5408DAE\u7684CSI\u53cd\u9988\u4efb\u52a1\uff0c\u4e14\u5177\u6709\u4f4e\u989d\u5916\u5185\u5b58\u5f00\u9500\uff0c\u80fd\u591f\u4e0e\u5176\u4ed6CSI\u53cd\u9988\u6a21\u578b\u96c6\u6210\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86DAE\u6846\u67b6\u5728\u591a\u6837\u573a\u666f\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5185\u5b58\u5f00\u9500\u4f4e\uff1b\u540c\u6837\u5177\u5907\u4e0e\u5176\u4ed6\u5148\u8fdbCSI\u53cd\u9988\u6a21\u578b\u7684\u65e0\u7f1d\u96c6\u6210\u80fd\u529b\uff0c\u4f53\u73b0\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "GAN\u9a71\u52a8\u7684\u8bb0\u5fc6\u6027\u6301\u7eed\u5b66\u4e60\u4e3aCSI\u53cd\u9988\u63d0\u4f9b\u4e00\u79cd\u9ad8\u6548\u7684\u8bb0\u5fc6\u673a\u5236\uff0c\u80fd\u5728\u52a8\u6001mMIMO-OFDM\u73af\u5883\u4e2d\u5b9e\u73b0\u7a33\u5065\u6027\u80fd\u5e76\u5177\u5907\u826f\u597d\u6269\u5c55\u6027\u3002"}}
{"id": "2511.20252", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.20252", "abs": "https://arxiv.org/abs/2511.20252", "authors": ["Gabriel K. Gegenhuber", "Philipp \u00c9. Frenzel", "Maximilian G\u00fcnther", "Johanna Ullrich", "Aljosha Judmayer"], "title": "Hey there! You are using WhatsApp: Enumerating Three Billion Accounts for Security and Privacy", "comment": "Accepted to NDSS2026, Artifacts available at https://github.com/sbaresearch/whatsapp-census", "summary": "WhatsApp, with 3.5 billion active accounts as of early 2025, is the world's largest instant messaging platform. Given its massive user base, WhatsApp plays a critical role in global communication.\n  To initiate conversations, users must first discover whether their contacts are registered on the platform. This is achieved by querying WhatsApp's servers with mobile phone numbers extracted from the user's address book (if they allowed access). This architecture inherently enables phone number enumeration, as the service must allow legitimate users to query contact availability. While rate limiting is a standard defense against abuse, we revisit the problem and show that WhatsApp remains highly vulnerable to enumeration at scale. In our study, we were able to probe over a hundred million phone numbers per hour without encountering blocking or effective rate limiting.\n  Our findings demonstrate not only the persistence but the severity of this vulnerability. We further show that nearly half of the phone numbers disclosed in the 2021 Facebook data leak are still active on WhatsApp, underlining the enduring risks associated with such exposures. Moreover, we were able to perform a census of WhatsApp users, providing a glimpse on the macroscopic insights a large messaging service is able to generate even though the messages themselves are end-to-end encrypted. Using the gathered data, we also discovered the re-use of certain X25519 keys across different devices and phone numbers, indicating either insecure (custom) implementations, or fraudulent activity.\n  In this updated version of the paper, we also provide insights into the collaborative remediation process through which we confirmed that the underlying rate-limiting issue had been resolved.", "AI": {"tldr": "WhatsApp \u7684\u8054\u7cfb\u4eba\u67e5\u8be2\u673a\u5236\u66b4\u9732\u51fa\u5927\u89c4\u6a21\u7684\u53f7\u7801\u679a\u4e3e\u98ce\u9669\uff0c\u7814\u7a76\u91cf\u5316\u4e86\u89c4\u6a21\u4e0e\u5f71\u54cd\uff0c\u63ed\u793a\u6570\u636e\u6cc4\u9732\u6b8b\u7559\u3001\u5bc6\u94a5\u91cd\u7528\u7b49\u95ee\u9898\uff0c\u5e76\u8bb0\u5f55\u901f\u7387\u9650\u5236\u7684\u6539\u8fdb\u8fdb\u5c55\u3002", "motivation": "\u5728\u5168\u7403\u6700\u5927\u7684\u5373\u65f6\u901a\u8baf\u5e73\u53f0\u4e0a\uff0c\u7528\u6237\u901a\u8fc7\u5730\u5740\u7c3f\u67e5\u8be2\u8054\u7cfb\u4eba\u662f\u5426\u6ce8\u518c\uff0c\u5bfc\u81f4\u6f5c\u5728\u9690\u79c1\u66b4\u9732\u4e0e\u6ee5\u7528\u98ce\u9669\uff1b\u9700\u8981\u8bc4\u4f30\u53ef\u679a\u4e3e\u6027\u3001\u5f71\u54cd\u8303\u56f4\u53ca\u6709\u6548\u7684\u7f13\u89e3\u7b56\u7565\u3002", "method": "\u901a\u8fc7\u5411 WhatsApp \u670d\u52a1\u5668\u67e5\u8be2\u624b\u673a\u53f7\u7801\u4ee5\u5224\u65ad\u8d26\u53f7\u662f\u5426\u6ce8\u518c\uff0c\u7edf\u8ba1\u5355\u4f4d\u65f6\u95f4\u7684\u67e5\u8be2\u91cf\uff08\u9054\u767e\u842c\u7d1a/\u5c0f\u6642\uff09\uff0c\u5bf9 2021 \u5e74 Facebook \u6570\u636e\u6cc4\u9732\u4e2d\u7684\u53f7\u7801\u6d3b\u8dc3\u6027\u8fdb\u884c\u6bd4\u5bf9\uff0c\u5e76\u5206\u6790\u8de8\u8bbe\u5907/\u8de8\u53f7\u7801\u7684 X25519 \u5bc6\u94a5\u91cd\u7528\u73b0\u8c61\uff0c\u6700\u540e\u8bc4\u4f30\u901f\u7387\u9650\u5236\u7684\u6539\u8fdb\u4e0e\u534f\u540c\u4fee\u590d\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e WhatsApp \u5728\u5927\u89c4\u6a21\u679a\u4e3e\u9762\u524d\u4ecd\u5177\u9ad8\u53ef\u7528\u6027\uff0c\u672a\u53d1\u73b0\u6709\u6548\u7684\u963b\u585e\u6216\u4e25\u683c\u7684\u901f\u7387\u9650\u5236\uff1b\u7ea6\u4e00\u534a\u6765\u81ea 2021 \u5e74\u6570\u636e\u6cc4\u9732\u7684\u53f7\u7801\u4ecd\u5728 WhatsApp \u6d3b\u8dc3\uff1b\u80fd\u591f\u5bf9\u5168\u7403\u7528\u6237\u8fdb\u884c\u5b8f\u89c2\u7edf\u8ba1\uff0c\u63ed\u793a\u5143\u6570\u636e\u5c42\u9762\u7684\u9690\u79c1\u98ce\u9669\uff1b\u53d1\u73b0\u67d0\u4e9b X25519 \u5bc6\u94a5\u5728\u4e0d\u540c\u8bbe\u5907/\u53f7\u7801\u95f4\u91cd\u590d\u4f7f\u7528\uff1b\u66f4\u65b0\u7248\u672c\u6307\u660e\u901f\u7387\u9650\u5236\u95ee\u9898\u5df2\u901a\u8fc7\u534f\u4f5c\u4fee\u590d\u5f97\u5230\u89e3\u51b3\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u7aef\u5bf9\u7aef\u52a0\u5bc6\u5e76\u4e0d\u80fd\u6d88\u9664\u5bf9\u5143\u6570\u636e\u4e0e\u8d26\u6237\u53ef\u7528\u6027\u4fe1\u606f\u7684\u66b4\u9732\u98ce\u9669\uff0c\u63d0\u51fa\u9700\u8981\u52a0\u5f3a\u901f\u7387\u9650\u5236\u3001\u6570\u636e\u62ab\u9732\u63a7\u5236\u4e0e\u5bc6\u94a5\u7ba1\u7406\u7b49\u9632\u62a4\uff0c\u540c\u65f6\u8868\u660e\u5bf9\u5927\u89c4\u6a21\u679a\u4e3e\u7684\u6301\u7eed\u76d1\u6d4b\u4e0e\u4fee\u590d\u5de5\u4f5c\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.20298", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.20298", "abs": "https://arxiv.org/abs/2511.20298", "authors": ["Godfred Kumi Tenkorang", "Michel Daoud Yacoub"], "title": "Log-Mu Fading Process: Second-Order Statistics for Diversity-Combining Techniques", "comment": null, "summary": "This paper derives second-order statistics for diversity-combining techniques over Log-mu fading channels. Closed-form expressions for the level crossing rate (LCR) and average fading duration (AFD) are derived for pure selection combining (PSC), while exact multidimensional integral expressions are obtained for equal gain combining (EGC) and maximal ratio combining (MRC). The analysis considers M unbalanced, independent, and non-identically distributed (i.n.i.d.) Log-mu fading channels. Monte Carlo simulations are conducted to validate the theoretical results, demonstrating excellent agreement and confirming the accuracy of the proposed expressions.", "AI": {"tldr": "\u672c\u6587\u63a8\u5bfc\u4e86\u5bf9\u6570mu\u8870\u843d\u4fe1\u9053\u4e0b\u7684\u591a\u8def\u5206\u96c6\u6280\u672f\u7684\u4e8c\u9636\u7edf\u8ba1\u91cf\u3002\u5bf9\u7eaf\u9009\u62e9\u5e76\u884c\uff08PSC\uff09\u7ed9\u51fa\u7ea7\u4ea4\u7387\uff08LCR\uff09\u548c\u5e73\u5747\u8870\u843d\u6301\u7eed\u65f6\u95f4\uff08AFD\uff09\u7684\u95ed\u5f0f\u8868\u8fbe\uff1b\u5bf9\u7b49\u589e\u76ca\u5e76\u884c\uff08EGC\uff09\u548c\u6700\u5927\u6bd4\u5408\u5e76\uff08MRC\uff09\u7ed9\u51fa\u786e\u5207\u7684\u591a\u7ef4\u79ef\u5206\u8868\u8fbe\u5f0f\u3002\u8003\u8651M\u4e2a\u4e0d\u5e73\u8861\u3001\u72ec\u7acb\u4e14\u975e\u540c\u5206\u5e03(i.n.i.d.)\u7684\u5bf9\u6570mu\u8870\u843d\u4fe1\u9053\u3002\u7528\u8499\u7279\u5361\u6d1b\u4eff\u771f\u9a8c\u8bc1\u7406\u8bba\u7ed3\u679c\uff0c\u7ed3\u679c\u4e0e\u4eff\u771f\u4e00\u81f4\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u8868\u8fbe\u5f0f\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u5bf9\u6570mu\u8870\u843d\u4fe1\u9053\u4e2d\u83b7\u53d6\u591a\u8def\u5206\u96c6\u7cfb\u7edf\u7684\u4e8c\u9636\u7edf\u8ba1\u91cf\uff0c\u4ee5\u4fbf\u8bc4\u4f30\u4fe1\u9053\u968f\u65f6\u95f4\u7684\u6ce2\u52a8\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5bfc\u51faLCR\u548cAFD\uff1bPSC\u5f97\u5230\u95ed\u5f0f\u8868\u8fbe\uff1bEGC\u548cMRC\u5f97\u5230\u786e\u5207\u7684\u591a\u7ef4\u79ef\u5206\u8868\u8fbe\uff1b\u5206\u6790\u5bf9\u8c61\u662fM\u4e2a\u4e0d\u5e73\u8861\u3001\u72ec\u7acb\u4e14\u975e\u540c\u5206\u5e03\u7684\u5bf9\u6570mu\u8870\u843d\u4fe1\u9053\uff1b\u7528\u8499\u7279\u5361\u6d1b\u4eff\u771f\u6765\u9a8c\u8bc1\u7406\u8bba\u63a8\u5bfc\u3002", "result": "\u7ed9\u51fa\u95ed\u5f0fLCR/AFD\uff08PSC\uff09\u4ee5\u53caEGC/MRC\u7684\u591a\u7ef4\u79ef\u5206\u8868\u8fbe\u5f0f\uff1b\u4eff\u771f\u9a8c\u8bc1\u4e0e\u7406\u8bba\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u6240\u63d0\u89e3\u6790\u8868\u8fbe\u5f0f\u53ef\u51c6\u786e\u63cf\u8ff0\u5bf9\u6570mu\u8870\u843d\u4fe1\u9053\u4e0b\u7684\u4e8c\u9636\u7edf\u8ba1\u91cf\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u8bc1\u5b9e\uff0c\u9002\u7528\u4e8e\u8bc4\u4f30\u548c\u8bbe\u8ba1\u91c7\u7528PSC/EGC/MRC\u7684\u5206\u96c6\u7cfb\u7edf\u5728\u6b64\u8870\u843d\u6a21\u578b\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2511.19491", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19491", "abs": "https://arxiv.org/abs/2511.19491", "authors": ["Jitendra Parmar", "Praveen Singh Thakur"], "title": "OpenCML: End-to-End Framework of Open-world Machine Learning to Learn Unknown Classes Incrementally", "comment": "Introduces an open-world machine learning model for continual and adaptive learning Discovers unknown classes and dynamically creates new class categories.Performs class-incremental learning to retain and extend prior knowledge. Enables continuous model improvement across multiple learning iterations. Achieved superior performance with an average accuracy of 82.54", "summary": "Open-world machine learning is an emerging technique in artificial intelligence, where conventional machine learning models often follow closed-world assumptions, which can hinder their ability to retain previously learned knowledge for future tasks. However, automated intelligence systems must learn about novel classes and previously known tasks. The proposed model offers novel learning classes in an open and continuous learning environment. It consists of two different but connected tasks. First, it discovers unknown classes in the data and creates novel classes; next, it learns how to perform class incrementally for each new class. Together, they enable continual learning, allowing the system to expand its understanding of the data and improve over time. The proposed model also outperformed existing approaches in open-world learning. Furthermore, it demonstrated strong performance in continuous learning, achieving a highest average accuracy of 82.54% over four iterations and a minimum accuracy of 65.87%.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5f00\u653e\u4e16\u754c\u8fde\u7eed\u5b66\u4e60\u6846\u67b6\uff1a\u5148\u53d1\u73b0\u672a\u77e5\u7c7b\u522b\u518d\u5bf9\u65b0\u7c7b\u522b\u8fdb\u884c\u589e\u91cf\u5b66\u4e60\uff0c\u80fd\u5728\u56db\u6b21\u8fed\u4ee3\u4e2d\u8fbe\u5230\u5e73\u5747\u51c6\u786e\u738782.54%\uff0c\u6700\u4f4e65.87%\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u5f00\u653e\u4e16\u754c\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u95ed\u4e16\u754c\u5047\u8bbe\u4e0b\u7684\u6a21\u578b\u96be\u4ee5\u5728\u540e\u7eed\u4efb\u52a1\u4e2d\u4fdd\u7559\u5148\u524d\u77e5\u8bc6\u5e76\u9002\u5e94\u65b0\u7c7b\u522b\uff0c\u56e0\u6b64\u9700\u8981\u5728\u5f00\u653e\u3001\u8fde\u7eed\u5b66\u4e60\u573a\u666f\u4e2d\u5177\u5907\u53d1\u73b0\u672a\u77e5\u7c7b\u522b\u548c\u589e\u91cf\u5b66\u4e60\u80fd\u529b\u7684\u7cfb\u7edf\u3002", "method": "\u8bbe\u8ba1\u4e00\u4e2a\u4e24\u9636\u6bb5\u3001\u76f8\u4e92\u8fde\u63a5\u7684\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u53d1\u73b0\u6570\u636e\u4e2d\u7684\u672a\u77e5\u7c7b\u522b\u5e76\u521b\u5efa\u65b0\u7c7b\u522b\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5bf9\u6bcf\u4e2a\u65b0\u7c7b\u522b\u8fdb\u884c\u589e\u91cf\u5b66\u4e60\u4ee5\u5b8c\u6210\u5206\u7c7b\u3002\u8be5\u6846\u67b6\u5728\u5f00\u653e\u4e16\u754c\u5b66\u4e60\u73af\u5883\u4e2d\u5b9e\u73b0 continual learning\uff0c\u5141\u8bb8\u6a21\u578b\u6301\u7eed\u6269\u5c55\u77e5\u8bc6\u5e76\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728\u5f00\u653e\u4e16\u754c\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u8be5\u6846\u67b6\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\uff1b\u5728\u8fde\u7eed\u5b66\u4e60\u8bc4\u4f30\u4e2d\uff0c\u56db\u8f6e\u8fed\u4ee3\u540e\u8fbe\u5230\u6700\u9ad8\u5e73\u5747\u51c6\u786e\u738782.54%\uff0c\u6700\u4f4e\u4e3a65.87%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5f00\u653e\u4e16\u754c\u6301\u7eed\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u53d1\u73b0\u65b0\u7c7b\u522b\u5e76\u5c06\u5176\u589e\u91cf\u6574\u5408\u5230\u6a21\u578b\u4e2d\uff0c\u4ece\u800c\u5b9e\u73b0\u957f\u671f\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2511.20284", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20284", "abs": "https://arxiv.org/abs/2511.20284", "authors": ["Friederike Groschupp", "Daniele Lain", "Aritra Dhar", "Lara Magdalena Lazier", "Srdjan \u010capkun"], "title": "Can LLMs Make (Personalized) Access Control Decisions?", "comment": null, "summary": "Precise access control decisions are crucial to the security of both traditional applications and emerging agent-based systems. Typically, these decisions are made by users during app installation or at runtime. Due to the increasing complexity and automation of systems, making these access control decisions can add a significant cognitive load on users, often overloading them and leading to suboptimal or even arbitrary access control decisions. To address this problem, we propose to leverage the processing and reasoning capabilities of large language models (LLMs) to make dynamic, context-aware decisions aligned with the user's security preferences. For this purpose, we conducted a user study, which resulted in a dataset of 307 natural-language privacy statements and 14,682 access control decisions made by users. We then compare these decisions against those made by two versions of LLMs: a general and a personalized one, for which we also gathered user feedback on 1,446 of its decisions.\n  Our results show that in general, LLMs can reflect users' preferences well, achieving up to 86\\% accuracy when compared to the decision made by the majority of users. Our study also reveals a crucial trade-off in personalizing such a system: while providing user-specific privacy preferences to the LLM generally improves agreement with individual user decisions, adhering to those preferences can also violate some security best practices. Based on our findings, we discuss design and risk considerations for implementing a practical natural-language-based access control system that balances personalization, security, and utility.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u52a8\u6001\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8bbf\u95ee\u63a7\u5236\u51b3\u7b56\uff0c\u4ee5\u51cf\u8f7b\u7528\u6237\u5728\u5b89\u88c5\u548c\u8fd0\u884c\u65f6\u7684\u8ba4\u77e5\u8d1f\u62c5\uff0c\u5e76\u4e0e\u7528\u6237\u9690\u79c1\u504f\u597d\u5bf9\u9f50\u3002\u901a\u8fc7\u4e00\u9879\u7528\u6237\u7814\u7a76\u6784\u5efa\u6570\u636e\u96c6\uff08307\u6761\u81ea\u7136\u8bed\u8a00\u9690\u79c1\u9648\u8ff0\u4e0e14,682\u6761\u7528\u6237\u51b3\u7b56\uff09\uff0c\u5e76\u6bd4\u8f83\u4e00\u822c\u548c\u4e2a\u6027\u5316\u4e24\u7248LLMs\u7684\u51b3\u7b56\uff08\u5e76\u6536\u96c61,446\u6761\u51b3\u7b56\u7684\u7528\u6237\u53cd\u9988\uff09\u3002\u7ed3\u679c\u663e\u793a\uff1a\u5728\u591a\u6570\u60c5\u51b5\u4e0b\uff0cLLMs\u53ef\u8f83\u597d\u53cd\u6620\u7528\u6237\u504f\u597d\uff0c\u6700\u9ad8\u53ef\u8fbe86%\u7684\u4e00\u81f4\u6027\uff1b\u4e2a\u6027\u5316\u504f\u597d\u867d\u63d0\u5347\u4e0e\u4e2a\u4eba\u51b3\u7b56\u7684\u4e00\u81f4\u6027\uff0c\u4f46\u4e5f\u53ef\u80fd\u8fdd\u53cd\u67d0\u4e9b\u5b89\u5168\u6700\u4f73\u5b9e\u8df5\u3002\u6700\u540e\u7ed9\u51fa\u5728\u5b9e\u9645NL\u8bed\u8a00\u57fa\u7840\u8bbf\u95ee\u63a7\u5236\u7cfb\u7edf\u4e2d\u5e73\u8861\u4e2a\u6027\u5316\u3001\u5b89\u5168\u6027\u4e0e\u5b9e\u7528\u6027\u7684\u8bbe\u8ba1\u4e0e\u98ce\u9669\u8003\u91cf\u3002", "motivation": "\u968f\u7740\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\u4e0e\u81ea\u52a8\u5316\uff0c\u73b0\u6709\u7684\u8bbf\u95ee\u63a7\u5236\u51b3\u7b56\u9700\u7528\u6237\u5728\u5b89\u88c5/\u8fd0\u884c\u65f6\u505a\u51fa\uff0c\u9020\u6210\u8ba4\u77e5\u8d1f\u62c5\u548c\u4e0d\u7406\u6027\u51b3\u7b56\u3002\u5e94\u63a2\u7d22\u5982\u4f55\u5229\u7528LLMs\u7684\u63a8\u7406\u80fd\u529b\u5b9e\u73b0\u52a8\u6001\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u4e14\u7b26\u5408\u7528\u6237\u5b89\u5168\u504f\u597d\u7684\u8bbf\u95ee\u63a7\u5236\u3002", "method": "\u901a\u8fc7\u4e00\u9879\u7528\u6237\u7814\u7a76\uff0c\u6536\u96c6307\u6761\u81ea\u7136\u8bed\u8a00\u9690\u79c1\u9648\u8ff0\u4e0e14,682\u6761\u7528\u6237\u8bbf\u95ee\u63a7\u5236\u51b3\u7b56\uff0c\u5e76\u4e0e\u4e24\u7248LLMs\uff08\u4e00\u822c\u4e0e\u4e2a\u6027\u5316\uff09\u5bf9\u6bd4\u51b3\u7b56\uff0c\u540c\u65f6\u6536\u96c61,446\u6761\u51b3\u7b56\u7684\u7528\u6237\u53cd\u9988\u3002\u8bc4\u4f30LLMs\u5728\u5339\u914d\u591a\u6570\u7528\u6237\u51b3\u7b56\u4e0e\u4e2a\u4eba\u51b3\u7b56\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u4e00\u822cLLMs\u5728\u4e0e\u591a\u6570\u7528\u6237\u51b3\u7b56\u7684\u4e00\u81f4\u6027\u65b9\u9762\u53ef\u8fbe\u9ad8\u8fbe86%\uff1b\u4e2a\u6027\u5316\u504f\u597d\u6709\u52a9\u4e8e\u63d0\u9ad8\u4e0e\u4e2a\u4eba\u51b3\u7b56\u7684\u4e00\u81f4\u6027\uff0c\u4f46\u53ef\u80fd\u4e0e\u5b89\u5168\u6700\u4f73\u5b9e\u8df5\u53d1\u751f\u51b2\u7a81\u3002", "conclusion": "\u57fa\u4e8e\u7ed3\u679c\uff0c\u63d0\u51fa\u5728\u5b9e\u73b0\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u8bbf\u95ee\u63a7\u5236\u7cfb\u7edf\u65f6\u7684\u8bbe\u8ba1\u4e0e\u98ce\u9669\u8003\u91cf\uff0c\u91cd\u70b9\u5728\u4e8e\u5728\u4e2a\u6027\u5316\u3001\u5b89\u5168\u6027\u4e0e\u6548\u7528\u4e4b\u95f4\u7684\u6743\u8861\u3002"}}
{"id": "2511.20239", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20239", "abs": "https://arxiv.org/abs/2511.20239", "authors": ["Jan Krej\u010d\u00ed", "Oliver Kost", "Yuxuan Xia", "Lennart Svensson", "Ond\u0159ej Straka"], "title": "Occlusion-Aware Multi-Object Tracking via Expected Probability of Detection", "comment": "Submitted to IEEE Transactions on Aerospace and Electronic Systems (TAES)", "summary": "This paper addresses multi-object systems, where objects may occlude one another relative to the sensor. The standard point-object model for detection-based sensors is enhanced so that the probability of detection considers the presence of all objects. A principled tracking method is derived, assigning each object an expected probability of detection, where the expectation is taken over the reduced Palm density, which means conditionally on the object's existence. The assigned probability thus considers the object's visibility relative to the sensor, under the presence of other objects. Unlike existing methods, the proposed method systematically accounts for uncertainties related to all objects in a clear and manageable way. The method is demonstrated through a visual tracking application using the multi-Bernoulli mixture (MBM) filter with marks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u591a\u76ee\u6807\u573a\u666f\u4e2d\u8003\u8651\u906e\u6321\u7684\u68c0\u6d4b\u6982\u7387\u5efa\u6a21\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230 MBM \u62df\u5408\u8ddf\u8e2a\u4e2d\uff0c\u901a\u8fc7\u5bf9\u6bcf\u4e2a\u5bf9\u8c61\u5728\u5b58\u5728\u6027\u6761\u4ef6\u4e0b\u7684\u51cf\u5c11 Palm \u5bc6\u5ea6\u671f\u671b\u6765\u4f30\u8ba1\u53ef\u89c1\u6027\u4e0e\u68c0\u6d4b\u6982\u7387\u3002", "motivation": "\u5728\u4f20\u611f\u5668\u68c0\u6d4b\u4e2d\uff0c\u76ee\u6807\u4e4b\u95f4\u7684\u906e\u6321\u5bfc\u81f4\u68c0\u6d4b\u6982\u7387\u76f8\u4e92\u4f9d\u8d56\uff0c\u4f20\u7edf\u70b9\u5bf9\u8c61\u6a21\u578b\u5ffd\u7565\u8be5\u4f9d\u8d56\uff0c\u5bfc\u81f4\u8ddf\u8e2a\u4e0d\u51c6\u786e\u3002\u9700\u8981\u4e00\u4e2a\u53ef\u8ba1\u7b97\u4e14\u6e05\u6670\u7684\u6846\u67b6\u6765\u63cf\u8ff0\u5bf9\u8c61\u96c6\u5408\u5bf9\u5355\u4e2a\u5bf9\u8c61\u68c0\u6d4b\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5728\u5b58\u5728\u6027\u6761\u4ef6\u4e0b\u5bf9\u5bf9\u8c61\u7684\u68c0\u6d4b\u6982\u7387\u8fdb\u884c\u671f\u671b\uff0c\u5229\u7528 reduced Palm density \u8868\u793a\u5bf9\u5176\u4ed6\u5bf9\u8c61\u5b58\u5728\u6027\u7684\u6761\u4ef6\u5316\u5f71\u54cd\uff1b\u5e76\u5728\u591a\u4f2f\u52aa\u5229\u6df7\u5408\uff08MBM\uff09\u6ee4\u6ce2\u5668\uff08\u5e26\u6807\u8bb0\uff09\u4e2d\u5b9e\u73b0\u8be5\u6982\u7387\u7684\u81ea\u9002\u5e94\u5206\u914d\uff0c\u5f62\u6210\u4e00\u4e2a\u5bf9\u6240\u6709\u5bf9\u8c61\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u7cfb\u7edf\u5efa\u6a21\u7684\u8ddf\u8e2a\u6846\u67b6\u3002", "result": "\u4ee5\u53ef\u89c6\u5316\u8ffd\u8e2a\u4e3a\u5e94\u7528\u573a\u666f\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u906e\u6321\u60c5\u51b5\u4e0b\u5bf9\u68c0\u6d4b\u6982\u7387\u7684\u9002\u914d\u6027\u53ca\u5bf9\u8ddf\u8e2a\u9c81\u68d2\u6027\u7684\u63d0\u5347\uff0c\u76f8\u5bf9\u4e8e\u4f20\u7edf\u6a21\u578b\u5177\u6709\u66f4\u6e05\u6670\u7684\u8bef\u5dee\u6e90\u5206\u89e3\u3002", "conclusion": "\u5c06\u5bf9\u8c61\u906e\u6321\u5f71\u54cd\u7cfb\u7edf\u5730\u7eb3\u5165\u68c0\u6d4b\u6982\u7387\u5efa\u6a21\uff0c\u63d0\u4f9b\u4e00\u4e2a\u6e05\u6670\u3001\u53ef\u7ba1\u7406\u7684\u591a\u5bf9\u8c61\u6570\u636e\u5173\u8054\u4e0e\u8ddf\u8e2a\u6846\u67b6\uff0c\u5177\u6709\u666e\u9002\u6027\u548c\u6269\u5c55\u6027\u3002"}}
{"id": "2511.19495", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19495", "abs": "https://arxiv.org/abs/2511.19495", "authors": ["Shivansh Chhawri", "Rahul Mahadik", "Suparna Rooj"], "title": "A Systematic Study of Compression Ordering for Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) require substantial computational resources, making model compression essential for efficient deployment in constrained environments. Among the dominant compression techniques: knowledge distillation, structured pruning, and low-bit quantization, their individual effects are well studied, but their interactions and optimal sequencing remain unclear. This work systematically examines how these techniques perform both independently and in combination when applied to the Qwen2.5 3B model. We evaluate multiple compression pipelines, including single, and proposed three-technique sequences, using perplexity, G-Eval, clarity, prompt alignment, and compression ratio as metrics. Our experiments show that quantization provides the greatest standalone compression, while pruning introduces moderate quality degradation. Critically, the ordering of techniques significantly affects the final model quality: the sequence Pruning, Knowledge Distillation, Quantization (P-KD-Q) yields the best balance, achieving a 3.68x compression ratio while preserving strong instruction-following and language understanding capabilities. Conversely, pipelines applying quantization early suffer severe performance degradation due to irreversible information loss that impairs subsequent training. Overall, this study offers practical insight into designing effective, ordering-aware compression pipelines for deploying LLMs in resource-limited settings.", "AI": {"tldr": "\u5bf9\u6bd4\u5355\u72ec\u4e0e\u7ec4\u5408\u7684\u6a21\u578b\u538b\u7f29\uff0c\u53d1\u73b0\u538b\u7f29\u987a\u5e8f\u5bf9\u6700\u7ec8\u6027\u80fd\u5f71\u54cd\u663e\u8457\uff0cP-KD-Q\uff08\u526a\u679d-\u84b8\u998f-\u91cf\u5316\uff09\u57283.68x\u538b\u7f29\u6bd4\u4e0b\u7ef4\u6301\u826f\u597d\u6307\u4ee4\u9075\u5faa\u4e0e\u8bed\u8a00\u7406\u89e3\uff1b\u8fc7\u65e9\u91cf\u5316\u4f1a\u9020\u6210\u4e0d\u53ef\u9006\u4fe1\u606f\u635f\u5931\uff0c\u524a\u5f31\u540e\u7eed\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u538b\u7f29\u5e38\u7528\u6280\u672f\u5305\u62ec\u77e5\u8bc6\u84b8\u998f\u3001\u7ed3\u6784\u5316\u88c1\u526a\u3001\u4f4e\u4f4d\u6bd4\u7279\u91cf\u5316\uff0c\u4f46\u5b83\u4eec\u7684\u76f8\u4e92\u4f5c\u7528\u548c\u6709\u6548\u6392\u5e8f\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u7814\u7a76\u7cfb\u7edf\u5730\u8bc4\u4f30\u5355\u4e00\u4e0e\u7ec4\u5408\u538b\u7f29\u5728\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e2d\u7684\u6027\u80fd\u4e0e trade-offs\u3002", "method": "\u5728 Qwen2.5 3B \u6a21\u578b\u4e0a\u8bbe\u8ba1\u591a\u6761\u538b\u7f29\u7ba1\u7ebf\uff0c\u8986\u76d6\u5355\u4e00\u6280\u672f\u4e0e\u4e09-technique \u5e8f\u5217\uff0c\u4f7f\u7528 perplexity\u3001G-Eval\u3001clarity\u3001prompt alignment\u3001compression ratio\u7b49\u6307\u6807\u6bd4\u8f83\u3002", "result": "\u91cf\u5316\u63d0\u4f9b\u6700\u5927\u7684\u72ec\u7acb\u538b\u7f29\uff1b\u88c1\u526a\u5e26\u6765\u4e2d\u7b49\u7a0b\u5ea6\u7684\u8d28\u91cf\u4e0b\u964d\uff1b\u6280\u672f\u987a\u5e8f\u5bf9\u7ed3\u679c\u5f71\u54cd\u663e\u8457\uff0cP-KD-Q \u8fbe\u5230\u7ea63.68x \u538b\u7f29\uff0c\u540c\u65f6\u4fdd\u6301\u6307\u4ee4\u9075\u5faa\u4e0e\u8bed\u8a00\u7406\u89e3\u80fd\u529b\uff1b\u65e9\u91cf\u5316\u4f1a\u5bfc\u81f4\u4e0d\u53ef\u9006\u4fe1\u606f\u4e22\u5931\uff0c\u9650\u5236\u540e\u7eed\u8bad\u7ec3\u6548\u679c\u3002", "conclusion": "\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\uff0c\u5e94\u91cd\u89c6\u538b\u7f29\u987a\u5e8f\u8bbe\u8ba1\uff0cP-KD-Q \u4e3a\u5728\u4fdd\u6301\u8f83\u597d\u6027\u80fd\u524d\u63d0\u4e0b\u5b9e\u73b0\u9ad8\u538b\u7f29\u7684\u4e00\u79cd\u6709\u6548\u8def\u5f84\u3002"}}
{"id": "2511.20313", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.20313", "abs": "https://arxiv.org/abs/2511.20313", "authors": ["Li Zhou", "Marc Dacier", "Charalambos Konstantinou"], "title": "A Reality Check on SBOM-based Vulnerability Management: An Empirical Study and A Path Forward", "comment": null, "summary": "The Software Bill of Materials (SBOM) is a critical tool for securing the software supply chain (SSC), but its practical utility is undermined by inaccuracies in both its generation and its application in vulnerability scanning. This paper presents a large-scale empirical study on 2,414 open-source repositories to address these issues from a practical standpoint. First, we demonstrate that using lock files with strong package managers enables the generation of accurate and consistent SBOMs, establishing a reliable foundation for security analysis. Using this high-fidelity foundation, however, we expose a more fundamental flaw in practice: downstream vulnerability scanners produce a staggering 97.5\\% false positive rate. We pinpoint the primary cause as the flagging of vulnerabilities within unreachable code. We then demonstrate that function call analysis can effectively prune 63.3\\% of these false alarms. Our work validates a practical, two-stage approach for SSC security: first, generate an accurate SBOM using lock files and strong package managers, and second, enrich it with function call analysis to produce actionable, low-noise vulnerability reports that alleviate developers' alert fatigue.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u9762\u5411SSC\u5b89\u5168\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u5148\u4f7f\u7528\u5e26\u9501\u6587\u4ef6\u7684\u5f3a\u5305\u7ba1\u7406\u5668\u751f\u6210\u9ad8\u4fdd\u771fSBOM\uff0c\u518d\u901a\u8fc7\u51fd\u6570\u8c03\u7528\u5206\u6790\u6765\u6d88\u9664\u6f0f\u6d1e\u626b\u63cf\u4e2d\u7684\u5927\u91cf\u5047\u9633\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u4f4e\u566a\u58f0\u3001\u53ef\u64cd\u4f5c\u7684\u6f0f\u6d1e\u62a5\u544a\u3002", "motivation": "SBOM\u7684\u51c6\u786e\u6027\u548c\u6f0f\u6d1e\u626b\u63cf\u7684\u53ef\u7528\u6027\u76f4\u63a5\u5f71\u54cd\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\uff0c\u4f46\u73b0\u6709\u505a\u6cd5\u5728\u751f\u6210SBOM\u548c\u5e94\u7528\u6f0f\u6d1e\u5206\u6790\u65f6\u5b58\u5728\u663e\u8457\u4e0d\u4e00\u81f4\u6027\u548c\u9ad8\u8bef\u62a5\u3002\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\uff082,414\u4e2a\u5f00\u6e90\u4ed3\u5e93\uff09\u6765\u8bc4\u4f30\u73b0\u72b6\u5e76\u63d0\u51fa\u53ef\u843d\u5730\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u6bd4\u8f83\u4e86\u5728\u4f7f\u7528\u9501\u6587\u4ef6\u4e0e\u5f3a\u5305\u7ba1\u7406\u5668\u65f6\u751f\u6210\u7684SBOM\u7684\u51c6\u786e\u6027\uff1b\u8861\u91cf\u4e0b\u6e38\u6f0f\u6d1e\u626b\u63cf\u7684\u8bef\u62a5\u7387\uff0c\u53d1\u73b097.5%\u7684\u8bef\u62a5\u6765\u81ea\u4e0d\u53ef\u8fbe\u4ee3\u7801\u4e2d\u7684\u6f0f\u6d1e\u3002\u968f\u540e\u91c7\u7528\u51fd\u6570\u8c03\u7528\u5206\u6790\u5bf9\u4ee3\u7801\u8def\u5f84\u8fdb\u884c prune\uff0c\u5b9e\u8bc1\u964d\u4f4e63.3%\u7684\u8bef\u62a5\u3002\u63d0\u51fa\u4e00\u4e2a\u4e24\u9636\u6bb5\u6d41\u7a0b\uff1a\u7b2c\u4e00\u9636\u6bb5\u7528\u9501\u6587\u4ef6+\u5f3a\u5305\u7ba1\u7406\u5668\u751f\u6210\u9ad8\u4fdd\u771fSBOM\uff1b\u7b2c\u4e8c\u9636\u6bb5\u7528\u51fd\u6570\u8c03\u7528\u5206\u6790\u63d0\u5347\u6f0f\u6d1e\u62a5\u544a\u7684\u53ef\u7528\u6027\u3002", "result": "\u9ad8\u4fdd\u771fSBOM\u53ef\u4f5c\u4e3a\u5b89\u5168\u5206\u6790\u7684\u53ef\u9760\u57fa\u7840\uff1b\u4e0b\u6e38\u6f0f\u6d1e\u626b\u63cf\u5b58\u5728\u6781\u9ad8\u8bef\u62a5\uff0c\u4e3b\u56e0\u662f\u4e0d\u53ef\u8fbe\u4ee3\u7801\u4e2d\u7684\u6f0f\u6d1e\u88ab\u9519\u8bef\u6807\u8bb0\uff1b\u51fd\u6570\u8c03\u7528\u5206\u6790\u80fd\u591f\u663e\u8457\u964d\u4f4e\u8bef\u62a5\u6bd4\u4f8b\uff08\u7ea663.3%\uff09\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u62a5\u544a\u7684\u53ef\u64cd\u4f5c\u6027\u3002", "conclusion": "\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e00\u4e2a\u5b9e\u7528\u7684\u4e24\u9636\u6bb5SSC\u5b89\u5168\u65b9\u6848\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u9501\u6587\u4ef6\u751f\u6210\u9ad8\u4fdd\u771fSBOM\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u51fd\u6570\u8c03\u7528\u5206\u6790\u4e30\u5bcc\u5e76\u51c0\u5316\u6f0f\u6d1e\u62a5\u544a\uff0c\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u66f4\u6709\u6548\u5730\u54cd\u5e94\u5b89\u5168\u4e8b\u4ef6\u3002"}}
{"id": "2511.20453", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20453", "abs": "https://arxiv.org/abs/2511.20453", "authors": ["Ziqin Zhou", "Hui Chen", "Gerhard Steinb\u00f6ck", "Henk Wymeersch"], "title": "Digital Twin-Assisted High-Precision Massive MIMO Localization in Urban Canyons", "comment": "6 pages, 5 figures. accepted to 2026 IEEE JC&S", "summary": "High-precision wireless localization in urban canyons is challenged by noisy measurements and severe non-line-of-sight (NLOS) propagation. This paper proposes a robust three-stage algorithm synergizing a digital twin (DT) model with the random sample consensus (RANSAC) algorithm to overcome these limitations. The method leverages the DT for geometric path association and employs RANSAC to identify reliable line-of-sight (LOS) and single-bounce NLOS paths while rejecting multi-bounce outliers. A final optimization on the resulting inlier set estimates the user's position and clock bias. Simulations validate that by effectively turning NLOS paths into valuable geometric information via the DT, the approach enables accurate localization, reduces reliance on direct LOS, and significantly lowers system deployment costs, making it suitable for practical deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\uff08DT\uff09\u4e0eRANSAC\u7684\u4e09\u9636\u6bb5\u9c81\u68d2\u5b9a\u4f4d\u7b97\u6cd5\uff0c\u5728\u57ce\u5e02\u5ce1\u8c37\u573a\u666f\u4e2d\u901a\u8fc7\u5c06NLOS\u4fe1\u606f\u8f6c\u5316\u4e3a\u51e0\u4f55\u4fe1\u606f\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u5e76\u964d\u4f4e\u90e8\u7f72\u6210\u672c\u3002", "motivation": "\u5728\u57ce\u5e02\u9ad8\u697c\u73af\u5883\u4e2d\uff0c\u6d4b\u91cf\u566a\u58f0\u548c\u4e25\u91cd\u7684NLOS\u5bfc\u81f4\u4f20\u7edf\u5b9a\u4f4d\u96be\u4ee5\u53ef\u9760\uff1b\u9700\u8981\u5229\u7528\u975e LOS \u53ca\u591a\u5f84\u4fe1\u606f\u6765\u63d0\u5347\u5b9a\u4f4d\u9c81\u68d2\u6027\u5e76\u964d\u4f4e\u5bf9\u76f4\u63a5 LOS \u7684\u4f9d\u8d56\u3002", "method": "\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a1) \u7528DT\u8fdb\u884c\u51e0\u4f55\u8def\u5f84\u5173\u8054\uff1b2) \u7528RANSAC\u7b5b\u9009\u51faLOS\u548c\u5355\u6b21\u5355\u6b21NLOS\u8def\u5f84\uff0c\u6392\u9664\u591a\u8df3\u591a\u5f84\u79bb\u7fa4\uff1b3) \u5728\u5185\u70b9\u96c6\u4e0a\u8fdb\u884c\u4f18\u5316\uff0c\u4f30\u8ba1\u4f4d\u7f6e\u548c\u65f6\u949f\u504f\u7f6e\u3002", "result": "\u4eff\u771f\u9a8c\u8bc1\u8be5DT\u9a71\u52a8\u7684\u51e0\u4f55\u4fe1\u606f\u5316\u5904\u7406\u4f7fNLOS\u8def\u5f84\u6210\u4e3a\u6709\u4ef7\u503c\u7684\u51e0\u4f55\u4fe1\u606f\uff0c\u63d0\u5347\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u964d\u4f4e\u5bf9\u76f4\u63a5LOS\u7684\u4f9d\u8d56\uff0c\u5e76\u964d\u4f4e\u7cfb\u7edf\u90e8\u7f72\u6210\u672c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5b9e\u7528\u90e8\u7f72\u65b9\u9762\u5177\u6709\u6f5c\u5728\u6548\u76ca\uff0c\u80fd\u591f\u63d0\u5347\u5728\u590d\u6742\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u5b9a\u4f4d\u9c81\u68d2\u6027\u5e76\u964d\u4f4e\u6210\u672c\u3002"}}
{"id": "2511.20276", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20276", "abs": "https://arxiv.org/abs/2511.20276", "authors": ["Lianzhe Hu", "Yu Wang", "Bikash Pal"], "title": "LLM-Driven Transient Stability Assessment: From Automated Simulation to Neural Architecture Design", "comment": null, "summary": "This paper presents an LLM-driven, end-to-end workflow that addresses the lack of automation and intelligence in power system transient stability assessment (TSA). The proposed agentic framework integrates large language models (LLMs) with a professional simulator (ANDES) to automatically generate and filter disturbance scenarios from natural language, and employs an LLM-driven Neural Network Design (LLM-NND) pipeline to autonomously design and optimize TSA models through performance-guided, closed-loop feedback. On the IEEE 39-bus system, the LLM-NND models achieve 93.71% test accuracy on four-class TSA with only 4.78M parameters, while maintaining real-time inference latency (less than 0.95 ms per sample). Compared with a manually designed DenseNet (25.9M parameters, 80.05% accuracy), the proposed approach jointly improves accuracy and efficiency. Ablation studies confirm that the synergy among domain-grounded retrieval, reasoning augmentation, and feedback mechanisms is essential for robust automation. The results demonstrate that LLM agents can reliably accelerate TSA research from scenario generation and data acquisition to model design and interpretation, offering a scalable paradigm that is readily extensible to other power system tasks such as optimal power flow, fault analysis, and market operations.", "AI": {"tldr": "An LLM-driven, end-to-end workflow automates TSA using LLMs and a professional simulator (ANDES) to generate disturbance scenarios and autonomously design TSA models via performance-guided feedback. On IEEE 39-bus, LLM-NND achieves 93.71% accuracy on four-class TSA with 4.78M parameters and <0.95 ms latency, outperforming a manually designed DenseNet (80.05% with 25.9M params). Ablations show synergy of retrieval, reasoning, and feedback. The approach promises scalable automation extendable to OPF, fault analysis, and market operations.", "motivation": "Power system transient stability assessment (TSA) suffers from limited automation and inadequate intelligence in scenario generation, model design, and interpretation. There is a need for end-to-end, scalable automation that can convert natural-language inputs into disturbance scenarios and optimally design lightweight models that meet real-time requirements.", "method": "Proposes an LLM-driven agentic framework that (1) uses LLMs with a professional simulator (ANDES) to automatically extract and filter disturbance scenarios from natural language, and (2) introduces an LLM-driven Neural Network Design (LLM-NND) pipeline that iteratively designs and optimizes TSA models via performance-guided, closed-loop feedback. Key components include domain-grounded retrieval, reasoning augmentation, and feedback mechanisms to ensure robust automation.", "result": "Empirical evaluation on the IEEE 39-bus system shows LLM-NND achieving 93.71% test accuracy for four-class TSA with 4.78M parameters and real-time inference latency (<0.95 ms/sample). The baseline DenseNet (25.9M parameters) achieves 80.05% accuracy. Ablation studies confirm the necessity of synergy among domain-grounded retrieval, reasoning augmentation, and feedback for robustness.", "conclusion": "LLM agents can reliably accelerate TSA research from scenario generation and data acquisition to model design and interpretation, offering a scalable paradigm extendable to other power system tasks such as optimal power flow, fault analysis, and market operations."}}
{"id": "2511.20294", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20294", "abs": "https://arxiv.org/abs/2511.20294", "authors": ["Dnyandeep Mandaokar", "Bernhard Rinner"], "title": "SAFE-IMM: Robust and Lightweight Radar-Based Object Tracking on Mobile Platforms", "comment": null, "summary": "Tracking maneuvering targets requires estimators that are both responsive and robust. Interacting Multiple Model (IMM) filters are a standard tracking approach, but fusing models via Gaussian mixtures can lag during maneuvers. Recent winnertakes-all (WTA) approaches react quickly but may produce discontinuities. We propose SAFE-IMM, a lightweight IMM variant for tracking on mobile and resource-limited platforms with a safe covariance-aware gate that permits WTA only when the implied jump from the mixture to the winner is provably bounded. In simulations and on nuScenes front-radar data, SAFE-IMM achieves high accuracy at real-time rates, reducing ID switches while maintaining competitive performance. The method is simple to integrate, numerically stable, and clutter-robust, offering a practical balance between responsiveness and smoothness.", "AI": {"tldr": "SAFE-IMM \u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684 IMM \u53d8\u4f53\uff0c\u7ed3\u5408\u534f\u65b9\u5dee\u611f\u77e5\u95e8\u63a7\uff0c\u5728\u6df7\u5408\u6a21\u578b\u8df3\u8dc3\u65f6\u4ec5\u5728\u7406\u8bba\u4e0a\u6709\u754c\u7684\u524d\u63d0\u4e0b\u624d\u542f\u7528 WTA\uff0c\u65e8\u5728\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u7684\u5b9e\u65f6\u8ddf\u8e2a\u3002\u5b9e\u9a8c\u8868\u660e\u5728 nuScenes \u524d\u7aef\u96f7\u8fbe\u6570\u636e\u4e0a\u5177\u6709\u9ad8\u7cbe\u5ea6\u3001\u4f4e ID \u5207\u6362\u7387\u3001\u9c81\u68d2\u6027\u4e0e\u5b9e\u65f6\u6027\u3002", "motivation": "\u89e3\u51b3\u5728 maneuvering \u76ee\u6807\u8ddf\u8e2a\u4e2d\uff0c\u4f20\u7edf IMM \u57fa\u4e8e\u9ad8\u65af\u6df7\u5408\u7684\u878d\u5408\u5728\u673a\u52a8\u671f\u95f4\u54cd\u5e94\u6162\uff0c\u4ee5\u53ca WTA \u65b9\u6cd5\u867d\u7136\u5feb\u901f\u4f46\u53ef\u80fd\u5bfc\u81f4\u8ddf\u8e2a\u4e0d\u8fde\u7eed\u7684\u95ee\u9898\uff1b\u9700\u8981\u4e00\u79cd\u5728\u54cd\u5e94\u6027\u3001\u5e73\u6ed1\u6027\u548c\u9c81\u68d2\u6027\u4e4b\u95f4\u53d6\u5f97\u5b9e\u9645\u5e73\u8861\u7684\u8f7b\u91cf\u5316\u65b9\u6848\u3002", "method": "\u63d0\u51fa SAFE-IMM\uff1a\u4e00\u79cd\u5e26\u6709\u5b89\u5168\u534f\u65b9\u5dee\u611f\u77e5\u95e8\u63a7\u7684 IMM \u53d8\u4f53\u3002\u4ec5\u5728\u4ece\u6df7\u5408\u5230\u83b7\u80dc\u8005\u7684\u201c\u8df3\u8dc3\u201d\u88ab\u8bc1\u660e\u6709\u754c\u65f6\uff0c\u624d\u5141\u8bb8\u4f7f\u7528 wta \u7b56\u7565\u3002\u65b9\u6cd5\u5f3a\u8c03\u7b80\u5355\u6574\u5408\u3001\u6570\u503c\u7a33\u5b9a\u4e14\u5bf9\u6742\u6ce2\u9c81\u68d2\uff0c\u4fbf\u4e8e\u5728\u8d44\u6e90\u53d7\u9650\u7684\u5e73\u53f0\u5b9e\u73b0\u3002\u5b9e\u9a8c\u5728 nuScenes \u524d\u96f7\u8fbe\u6570\u636e\u548c\u4eff\u771f\u4e2d\u9a8c\u8bc1\u3002", "result": "\u5728\u5b9e\u65f6\u7387\u4e0b\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u8ddf\u8e2a\uff0c\u663e\u8457\u51cf\u5c11 ID \u5207\u6362\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u6027\u80fd\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u5177\u5907\u53ef\u6bd4\u751a\u81f3\u66f4\u4f18\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "SAFE-IMM \u5728\u4fdd\u6301\u5bf9\u54cd\u5e94\u6027\u548c\u5149\u6ed1\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u65b9\u9762\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u3001\u7a33\u5b9a\u3001\u6613\u96c6\u6210\u7684\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u79fb\u52a8\u5e73\u53f0\u548c\u771f\u5b9e\u573a\u666f\u8ddf\u8e2a\u3002"}}
{"id": "2511.19497", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19497", "abs": "https://arxiv.org/abs/2511.19497", "authors": ["Bowen Zhao", "Huanlai Xing", "Zhiwen Xiao", "Jincheng Peng", "Li Feng", "Xinhan Wang", "Rong Qu", "Hui Li"], "title": "PeriodNet: Boosting the Potential of Attention Mechanism for Time Series Forecasting", "comment": null, "summary": "The attention mechanism has demonstrated remarkable potential in sequence modeling, exemplified by its successful application in natural language processing with models such as Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-trained Transformer (GPT). Despite these advancements, its utilization in time series forecasting (TSF) has yet to meet expectations. Exploring a better network structure for attention in TSF holds immense significance across various domains. In this paper, we present PeriodNet with a brand new structure to forecast univariate and multivariate time series. PeriodNet incorporates period attention and sparse period attention mechanism for analyzing adjacent periods. It enhances the mining of local characteristics, periodic patterns, and global dependencies. For efficient cross-variable modeling, we introduce an iterative grouping mechanism which can directly reduce the cross-variable redundancy. To fully leverage the extracted features on the encoder side, we redesign the entire architecture of the vanilla Transformer and propose a period diffuser for precise multi-period prediction. Through comprehensive experiments conducted on eight datasets, we demonstrate that PeriodNet outperforms six state-of-the-art models in both univariate and multivariate TSF scenarios in terms of mean square error and mean absolute error. In particular, PeriodNet achieves a relative improvement of 22% when forecasting time series with a length of 720, in comparison to other models based on the conventional encoder-decoder Transformer architecture.", "AI": {"tldr": "PeriodNet\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u65f6\u5e8f\u6ce8\u610f\u529b\u7ed3\u6784\uff0c\u7ed3\u5408\u5468\u671f\u6ce8\u610f\u529b\u548c\u7a00\u758f\u5468\u671f\u6ce8\u610f\u529b\uff0c\u914d\u5408\u8fed\u4ee3\u5206\u7ec4\u673a\u5236\u548c\u5468\u671f\u6269\u6563\u5668\uff0c\u5bf9\u5355\u53d8\u91cf\u4e0e\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u7684\u9884\u6d4b\u8868\u73b0\u4f18\u4e8e\u516d\u4e2a\u72b6\u6001-of-the-art\u6a21\u578b\uff0c\u4e14\u5728\u957f\u5ea6720\u7684\u5e8f\u5217\u4e0a\u76f8\u5bf9\u63d0\u5347\u7ea622%\u3002", "motivation": "\u5c3d\u7ba1\u6ce8\u610f\u529b\u673a\u5236\u5728NLP\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u53d1\u6325\u6f5c\u529b\u3002\u9700\u8981\u4e00\u79cd\u66f4\u5951\u5408\u65f6\u95f4\u5e8f\u5217\u5c40\u90e8\u7279\u5f81\u3001\u5468\u671f\u6a21\u5f0f\u4e0e\u5168\u5c40\u4f9d\u8d56\u7684\u6ce8\u610f\u529b\u7ed3\u6784\uff0c\u5e76\u9ad8\u6548\u5730\u5b9e\u73b0\u8de8\u53d8\u91cf\u5efa\u6a21\u3002", "method": "\u63d0\u51faPeriodNet\uff1a\u5305\u542b\u5468\u671f\u6ce8\u610f\u529b\u4e0e\u7a00\u758f\u5468\u671f\u6ce8\u610f\u529b\u4ee5\u5206\u6790\u76f8\u90bb\u5468\u671f\uff1b\u5f15\u5165\u8fed\u4ee3\u5206\u7ec4\u673a\u5236\u5b9e\u73b0\u8de8\u53d8\u91cf\u53bb\u5197\uff1b\u91cd\u65b0\u8bbe\u8ba1Transformer\u7f16\u7801\u5668\u67b6\u6784\u5e76\u63d0\u51fa\u5468\u671f\u6269\u6563\u5668\u4ee5\u5b9e\u73b0\u66f4\u7cbe\u786e\u7684\u591a\u5468\u671f\u9884\u6d4b\u3002", "result": "\u5728\u516b\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0cPeriodNet\u5728\u5355\u53d8\u91cf\u4e0e\u591a\u53d8\u91cfTSF\u4efb\u52a1\u4e2d\u5747\u8d85\u8d8a\u516d\u4e2a\u4e3b\u8981\u7ade\u4e89\u6a21\u578b\uff0c\u4f7f\u7528MSE\u4e0eMAE\u8bc4\u4f30\uff1b\u5728\u5e8f\u5217\u957f\u5ea6\u4e3a720\u65f6\uff0c\u76f8\u8f83\u57fa\u4e8e\u4f20\u7edf\u7f16\u7801\u5668-\u89e3\u7801\u5668Transformer\u7684\u6a21\u578b\u5b9e\u73b0\u7ea622%\u7684\u76f8\u5bf9\u63d0\u5347\u3002", "conclusion": "PeriodNet\u901a\u8fc7\u6574\u5408\u5468\u671f\u4fe1\u606f\u3001\u7a00\u758f\u5173\u6ce8\u548c\u8de8\u53d8\u91cf\u9ad8\u6548\u5efa\u6a21\uff0c\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5c55\u793a\u4e86\u5bf9\u590d\u6742\u5468\u671f\u6027\u4e0e\u8de8\u53d8\u91cf\u4f9d\u8d56\u7684\u6709\u6548\u6355\u83b7\u80fd\u529b\u3002"}}
{"id": "2511.20572", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.20572", "abs": "https://arxiv.org/abs/2511.20572", "authors": ["Mohamadreza Delbari", "George C. Alexandropoulos", "Robert Schober", "H. Vincent Poor", "Vahid Jamali"], "title": "Near-Field Multipath MIMO Channels: Modeling Reflectors and Exploiting NLOS Paths", "comment": null, "summary": "Near-field (NF) communications is receiving renewed interest in the context of multiple-input multiple-output (MIMO) systems involving large physical apertures with respect to the signal wavelength. While line-of-sight (LOS) links are typically expected to dominate in NF scenarios, the impact of non-LOS (NLOS) components at both in centimeter- and millimeter-wave frequencies may be in general non-negligible. Moreover, although weaker than the LOS path, NLOS links may be essential for achieving multiplexing gains in MIMO systems. The commonly used NF channel models for NLOS links in the literature are based on the point scattering assumption, which is not valid for large reflectors such as walls, ceilings, and the ground. In this paper, we develop a generalized statistical NF MIMO channel model that extends the widely adopted point scattering framework to account for imperfect reflections from large surfaces. This model is then leveraged to investigate how the physical characteristics of these reflectors influence the resulting NF MIMO channel. In addition, using the proposed channel model, we analytically demonstrate for a multi-user scenario that, even when users are located within the NF regime, relying solely on LOS NF links may be insufficient to achieve multiplexing gains, thus exploiting NLOS links becomes essential. Our simulation results validate the accuracy of the proposed model and show that, in many practical settings, the contribution of NLOS components is non-negligible and must be carefully accounted for in the system design.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e00\u4e2a\u6269\u5c55\u7684\u8fd1\u573aMIMO\u4fe1\u9053\u6a21\u578b\uff0c\u8003\u8651\u5927\u5c3a\u5bf8\u53cd\u5c04\u9762\u7684\u4e0d\u5b8c\u7f8e\u53cd\u5c04\uff0c\u63ed\u793aNLOS\u5206\u91cf\u5728\u8fd1\u573a\u591a\u7528\u6237MIMO\u4e2d\u7684\u5173\u952e\u6027\uff0c\u5355\u9760LOS\u4e0d\u8db3\u4ee5\u5b9e\u73b0\u591a\u8def\u590d\u7528\u3002", "motivation": "\u8fd1\u573a\u901a\u4fe1\u5728\u5927\u5c3a\u5ea6MIMO/\u5927\u7269\u7406\u5929\u7ebf\u573a\u666f\u4e2d\u5177\u6709\u6f5c\u5728\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u73b0\u6709NLOS\u8fd1\u573a\u6a21\u578b\u591a\u57fa\u4e8e\u70b9\u6563\u5c04\u5047\u8bbe\uff0c\u4e0d\u80fd\u771f\u5b9e\u53cd\u6620\u5927\u9762\u79ef\u53cd\u5c04\u9762\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u771f\u5b9e\u7684\u7edf\u8ba1\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u5e7f\u4e49\u7edf\u8ba1\u8fd1\u573aMIMO\u4fe1\u9053\u6a21\u578b\uff0c\u6269\u5c55\u70b9\u6563\u5c04\u6846\u67b6\u4ee5\u8003\u8651\u5bf9\u5927\u9762\u79ef\u53cd\u5c04\u9762\u7684\u4e0d\u5b8c\u7f8e\u53cd\u5c04\uff1b\u5229\u7528\u8be5\u6a21\u578b\u5206\u6790\u53cd\u5c04\u9762\u7684\u7269\u7406\u7279\u6027\u5bf9\u8fd1\u573a\u4fe1\u9053\u7684\u5f71\u54cd\uff1b\u5728\u591a\u7528\u6237\u573a\u666f\u7ed9\u51fa\u89e3\u6790\u7ed3\u8bba\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u3002", "result": "\u4eff\u771f\u548c\u5206\u6790\u7ed3\u679c\u8868\u660eNLOS\u5206\u91cf\u8d21\u732e\u5728\u591a\u6570\u73b0\u5b9e\u6761\u4ef6\u4e0b\u4e0d\u5bb9\u5ffd\u89c6\uff0c\u80fd\u663e\u8457\u5f71\u54cd\u8fd1\u573aMIMO\u7684\u591a\u8def\u590d\u7528\u80fd\u529b\uff1b\u6a21\u578b\u51c6\u786e\u6027\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u8fd1\u573a\u5927\u9762\u79efMIMO\u7cfb\u7edf\u8bbe\u8ba1\u5e94\u540c\u65f6\u8003\u8651NLOS\u5206\u91cf\uff1b\u5ffd\u7565\u5b83\u4eec\u53ef\u80fd\u5bfc\u81f4\u9519\u4f30\u6027\u80fd\uff0c\u672a\u6765\u5de5\u4f5c\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u53c2\u6570\u5982\u6781\u5316\u3001\u9891\u7387\u4f9d\u8d56\u7b49\u3002"}}
{"id": "2511.19956", "categories": ["cs.LG", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.19956", "abs": "https://arxiv.org/abs/2511.19956", "authors": ["Meiyu Zhong", "Noel Teku", "Ravi Tandon"], "title": "Prompt Fairness: Sub-group Disparities in LLMs", "comment": null, "summary": "Large Language Models (LLMs), though shown to be effective in many applications, can vary significantly in their response quality. In this paper, we investigate this problem of prompt fairness: specifically, the phrasing of a prompt by different users/styles, despite the same question being asked in principle, may elicit different responses from an LLM. To quantify this disparity, we propose to use information-theoretic metrics that can capture two dimensions of bias: subgroup sensitivity, the variability of responses within a subgroup and cross group consistency, the variability of responses across subgroups. Our analysis reveals that certain subgroups exhibit both higher internal variability and greater divergence from others. Our empirical analysis reveals that certain demographic sub groups experience both higher internal variability and greater divergence from others, indicating structural inequities in model behavior. To mitigate these disparities, we propose practical interventions, including majority voting across multiple generations and prompt neutralization, which together improve response stability and enhance fairness across user populations. In the experiments, we observe clear prompt sensitivity disparities across demographic subgroups: before mitigation, cross-group divergence values reach 0.28 and typically fall in the from 0.14 to 0.22 range. After applying our neutralization and multi generation strategy, these divergences consistently decrease, with the largest gap reduced to 0.22 and many distances falling to 0.17 or below, indicating more stable and consistent outputs across subgroups.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u63d0\u793a\u516c\u5e73\u6027\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4f53\u73b0\uff0c\u63d0\u51fa\u4ee5\u4fe1\u606f\u8bba\u5ea6\u91cf\u5b50\u7fa4\u5185\u90e8\u53d8\u5f02\u548c\u8de8\u7fa4\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u591a\u4ee3\u751f\u6210\u4e0e\u63d0\u793a\u4e2d\u548c\u4e2d\u6027\u7684\u5e72\u9884\u4e0b\u964d\u4f4e\u7fa4\u4f53\u95f4\u8f93\u51fa\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u63d0\u793a\u98ce\u683c\u7684\u5dee\u5f02\u5316\uff0cLLMs \u5bf9\u540c\u4e00\u95ee\u9898\u53ef\u80fd\u7ed9\u51fa\u4e0d\u540c\u8d28\u91cf\u7684\u56de\u7b54\uff0c\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u9700\u8981\u91cf\u5316\u4e0e\u7f13\u89e3\u4ee5\u5b9e\u73b0\u66f4\u516c\u5e73\u7684\u670d\u52a1\u3002", "method": "\u63d0\u51fa\u4fe1\u606f\u8bba\u6307\u6807\u6765\u8861\u91cf\u5b50\u7fa4\u5185\u90e8\u53d8\u5f02\u6027\uff08subgroup sensitivity\uff09\u548c\u8de8\u7fa4\u4e00\u81f4\u6027\uff08cross-group consistency\uff09\uff0c\u57fa\u4e8e Demographic \u5b50\u7fa4\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff1b\u63d0\u51fa\u4e24\u79cd\u5e72\u9884\uff1a\u591a\u6570\u6295\u7968\uff08\u591a\u4ee3\u751f\u6210\uff09\u4e0e\u63d0\u793a\u4e2d\u6027\u5316\uff08prompt neutralization\uff09\uff1b\u5728\u5b9e\u9a8c\u4e2d\u6bd4\u8f83\u5e72\u9884\u524d\u540e\u7684\u8de8\u7fa4\u8ddd\u79bb\uff080.28 -> 0.17\u20130.22\u533a\u95f4\uff0c\u6700\u5927\u5dee\u8ddd\u964d\u81f30.22\uff0c\u5f88\u591a\u4f4e\u4e8e0.17\uff09\u3002", "result": "\u53d1\u73b0\u67d0\u4e9b\u5b50\u7fa4\u5728\u5185\u90e8\u53d8\u5f02\u6027\u548c\u5bf9\u5176\u4ed6\u7fa4\u4f53\u7684\u5dee\u5f02\u6027\u4e0a\u5747\u9ad8\u4e8e\u5176\u4ed6\u7fa4\u4f53\uff0c\u5b58\u5728\u7ed3\u6784\u6027\u4e0d\u5e73\u7b49\uff1b\u5e72\u9884\u540e\u8de8\u7fa4\u8ddd\u79bb\u663e\u8457\u4e0b\u964d\uff0c\u8f93\u51fa\u66f4\u7a33\u5b9a\u3002", "conclusion": "\u901a\u8fc7\u591a\u4ee3\u751f\u6210\u548c\u63d0\u793a\u4e2d\u6027\u5316\u7b49\u7b56\u7565\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u6a21\u578b\u8f93\u51fa\u5728\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u4e2d\u7684\u516c\u5e73\u6027\u4e0e\u7a33\u5b9a\u6027\u3002"}}
{"id": "2511.19498", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.19498", "abs": "https://arxiv.org/abs/2511.19498", "authors": ["Yi Zhang", "Tianxiang Xu", "Zijian Li", "Chao Zhang", "Kunyu Zhang", "Zhan Gao", "Meinuo Li", "Xiaohan Zhang", "Qichao Qi", "Bing Chen"], "title": "Hierarchical Dual-Strategy Unlearning for Biomedical and Healthcare Intelligence Using Imperfect and Privacy-Sensitive Medical Data", "comment": null, "summary": "Large language models (LLMs) exhibit exceptional performance but pose substantial privacy risks due to training data memorization, particularly within healthcare contexts involving imperfect or privacy-sensitive patient information. We present a hierarchical dual-strategy framework for selective knowledge unlearning that precisely removes specialized knowledge while preserving fundamental medical competencies. Our approach synergistically integrates geometric-constrained gradient updates to selectively modulate target parameters with concept-aware token-level interventions that distinguish between preservation-critical and unlearning-targeted tokens via a unified four-level medical concept hierarchy. Comprehensive evaluations on the MedMCQA (surgical) and MHQA (anxiety, depression, trauma) datasets demonstrate superior performance, achieving an 82.7% forgetting rate and 88.5% knowledge preservation. Notably, our framework maintains robust privacy guarantees while requiring modification of only 0.1% of parameters, addressing critical needs for regulatory compliance, auditability, and ethical standards in clinical research.", "AI": {"tldr": "A hierarchical dual-strategy framework for selective knowledge unlearning in LLMs that deletes specialized medical knowledge while preserving core medical competencies, achieving high forgetting with minimal parameter changes.", "motivation": "Privacy risks from training data memorization in large language models, particularly in healthcare where patient information is sensitive; need methods to erase specific knowledge to meet regulatory and ethical standards.", "method": "A two-pronged approach combining geometric-constrained gradient updates to selectively modulate target parameters and concept-aware token-level interventions that distinguish preservation-critical from unlearning-targeted tokens using a four-level medical concept hierarchy.", "result": "On MedMCQA (surgical) and MHQA (anxiety, depression, trauma) datasets, the method achieves 82.7% forgetting rate and 88.5% knowledge preservation, modifying only 0.1% of parameters, indicating strong privacy guarantees with minimal model alteration.", "conclusion": "The framework provides effective selective knowledge unlearning that balances privacy protection with medical competence preservation, supporting regulatory compliance and ethical standards in clinical research."}}
{"id": "2511.20443", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20443", "abs": "https://arxiv.org/abs/2511.20443", "authors": ["Amy K. Strong", "Samuel Akinwande", "Leila Bridgeman"], "title": "Adaptive Meshing for CPA Lyapunov Function Synthesis", "comment": null, "summary": "Continuous piecewise affine (CPA) Lyapunov function synthesis is one method to perform Lyapunov stability analysis for nonlinear systems. This method first generates a mesh over the region of interest in the system's state space and then solves a linear program (LP), which enforces constraints on each vertex of the mesh, to synthesize a Lyapunov function. Finer meshes broaden the class of Lyapunov function candidates, but CPA function synthesis is more computationally expensive for finer meshes -- particularly so in higher dimensional systems. This paper explores methods to mesh the region of interest more efficiently so that a Lyapunov function can be synthesized using less computational effort. Three methods are explored -- adaptive meshing, meshing using knowledge of the system model, and a combination of the two. Numerical examples for two and three dimensional nonlinear dynamical systems are used to compare the efficacy of the three methods.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u79cd\u7f51\u683c\u5316\u7b56\u7565\u6765\u63d0\u9ad8 CPA-Lyapunov \u51fd\u6570\u7efc\u5408\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u5728\u4e8c\u7ef4\u4e0e\u4e09\u7ef4\u975e\u7ebf\u6027\u7cfb\u7edf\u4e0a\u6bd4\u8f83\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u975e\u7ebf\u6027\u7cfb\u7edf\u7684 CPA-Lyapunov \u7efc\u5408\u4e2d\uff0c\u968f\u7740\u7f51\u683c\u7ec6\u5316\uff0c\u7ebf\u6027\u89c4\u5212\u6c42\u89e3\u6210\u672c\u663e\u8457\u589e\u52a0\uff0c\u5c24\u5176\u5728\u9ad8\u7ef4\u60c5\u5f62\u3002\u9700\u8981\u66f4\u9ad8\u6548\u7684\u7f51\u683c\u6784\u5efa\u65b9\u6cd5\u4ee5\u5728\u4fdd\u6301\u5224\u5b9a\u80fd\u529b\u7684\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u91cf\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u7f51\u683c\u5316\u65b9\u6cd5\uff1a\u81ea\u9002\u5e94\u7f51\u683c\u3001\u5229\u7528\u7cfb\u7edf\u6a21\u578b\u7684\u7f51\u683c\u5316\uff0c\u4ee5\u53ca\u4e8c\u8005\u7684\u7ec4\u5408\uff1b\u5728\u4e8c\u7ef4\u548c\u4e09\u7ef4\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u4e0a\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u6bd4\u8f83\u5b83\u4eec\u7684\u6548\u679c\u3002", "result": "\u901a\u8fc7\u5bf9\u4e24\u7ef4\u4e0e\u4e09\u7ef4\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u6570\u503c\u793a\u4f8b\u6bd4\u8f83\u4e09\u79cd\u65b9\u6cd5\u7684\u6548\u7528\uff0c\u8bc4\u4f30\u4e86\u5728\u4fdd\u6301\u53ef\u884c\u6027\u524d\u63d0\u4e0b\u7684\u8ba1\u7b97\u6548\u7387\u6539\u8fdb\u4e0e\u6743\u8861\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\u901a\u8fc7\u66f4\u667a\u6167\u7684\u7f51\u683c\u5316\u7b56\u7565\u53ef\u4ee5\u964d\u4f4e CPA-Lyapunov \u7efc\u5408\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4e0d\u540c\u7b56\u7565\u5728\u51c6\u786e\u6027\u4e0e\u8ba1\u7b97\u8d1f\u62c5\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u7ec4\u5408\u65b9\u6cd5\u53ef\u80fd\u63d0\u4f9b\u66f4\u4f18\u7684\u7efc\u5408\u8868\u73b0\u3002"}}
{"id": "2511.19499", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19499", "abs": "https://arxiv.org/abs/2511.19499", "authors": ["Hong-Hanh Nguyen-Le", "Van-Tuan Tran", "Dinh-Thuc Nguyen", "Nhien-An Le-Khac"], "title": "Beyond Binary Classification: A Semi-supervised Approach to Generalized AI-generated Image Detection", "comment": "Accepted to The 40th Annual AAAI Conference on Artificial Intelligence - 2025", "summary": "The rapid advancement of generators (e.g., StyleGAN, Midjourney, DALL-E) has produced highly realistic synthetic images, posing significant challenges to digital media authenticity. These generators are typically based on a few core architectural families, primarily Generative Adversarial Networks (GANs) and Diffusion Models (DMs). A critical vulnerability in current forensics is the failure of detectors to achieve cross-generator generalization, especially when crossing architectural boundaries (e.g., from GANs to DMs). We hypothesize that this gap stems from fundamental differences in the artifacts produced by these \\textbf{distinct architectures}. In this work, we provide a theoretical analysis explaining how the distinct optimization objectives of the GAN and DM architectures lead to different manifold coverage behaviors. We demonstrate that GANs permit partial coverage, often leading to boundary artifacts, while DMs enforce complete coverage, resulting in over-smoothing patterns. Motivated by this analysis, we propose the \\textbf{Tri}archy \\textbf{Detect}or (TriDetect), a semi-supervised approach that enhances binary classification by discovering latent architectural patterns within the \"fake\" class. TriDetect employs balanced cluster assignment via the Sinkhorn-Knopp algorithm and a cross-view consistency mechanism, encouraging the model to learn fundamental architectural distincts. We evaluate our approach on two standard benchmarks and three in-the-wild datasets against 13 baselines to demonstrate its generalization capability to unseen generators.", "AI": {"tldr": "\u5bf9\u6bd4GAN\u4e0e\u6269\u6563\u6a21\u578b\u5728\u4f2a\u9020\u56fe\u50cf\u68c0\u6d4b\u4e2d\u7684\u8de8\u751f\u6210\u67b6\u6784\u6cdb\u5316\u5dee\u5f02\uff0c\u63d0\u51faTriDetect\u534a\u76d1\u7763\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7Sinkhorn-Knopp\u7c07\u5206\u914d\u4e0e\u8de8\u89c6\u56fe\u4e00\u81f4\u6027\u63d0\u5347\u5bf9\u672a\u89c1\u751f\u6210\u5668\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u968f\u7740StyleGAN\u3001Midjourney\u3001DALL-E\u7b49\u751f\u6210\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5408\u6210\u56fe\u50cf\u7684\u771f\u5b9e\u6027\u663e\u8457\u63d0\u9ad8\uff0c\u5bf9\u6570\u5b57\u5a92\u4f53\u771f\u5b9e\u6027\u6784\u6210\u6311\u6218\u3002\u73b0\u6709\u4f2a\u9020\u68c0\u6d4b\u5668\u5728\u8de8\u67b6\u6784\uff08\u5982\u4eceGAN\u5230\u6269\u6563\u6a21\u578b\uff09\u65f6\u5f80\u5f80\u6cdb\u5316\u4e0d\u8db3\uff0c\u56e0\u4e0d\u540c\u67b6\u6784\u4ea7\u751f\u7684\u4f2a\u9020\u75d5\u8ff9\u5177\u6709\u672c\u8d28\u5dee\u5f02\u3002", "method": "\u7ed9\u51faGAN\u4e0eDM\u5728\u4f18\u5316\u76ee\u6807\u4e0a\u7684\u672c\u8d28\u5dee\u5f02\u5982\u4f55\u5bfc\u81f4\u4e0d\u540c\u7684\u8986\u76d6\u884c\u4e3a\u7684\u7406\u8bba\u5206\u6790\u3002\u57fa\u4e8e\u5206\u6790\u63d0\u51faTriDetect\uff0c\u4e00\u79cd\u534a\u76d1\u7763\u4e8c\u5206\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7Sinkhorn-Knopp\u5b9e\u73b0\u5bf9\u201cfake\u201d\u7c7b\u522b\u7684\u5e73\u8861\u7c07\u5206\u914d\uff0c\u5e76\u5f15\u5165\u8de8\u89c6\u56fe\u4e00\u81f4\u6027\u6765\u4fc3\u4f7f\u6a21\u578b\u5b66\u4e60\u57fa\u7840\u7684\u67b6\u6784\u5dee\u5f02\u3002\u5bf9\u4e24\u9879\u6807\u51c6\u57fa\u51c6\u4e0e\u4e09\u9879\u91ce\u5916\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4e0e13\u4e2a\u57fa\u7ebf\u8fdb\u884c\u5bf9\u6bd4\uff0c\u9a8c\u8bc1\u5bf9\u672a\u89c1\u751f\u6210\u5668\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTriDetect\u5728\u5bf9\u672a\u89c1\u751f\u6210\u5668\u7684\u6cdb\u5316\u80fd\u529b\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u4e14\u5728\u4e24\u9879\u6807\u51c6\u57fa\u51c6\u548c\u4e09\u9879\u91ce\u5916\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "\u4ece\u67b6\u6784\u5c42\u9762\u63ed\u793a\u4e86GAN\u4e0eDM\u5728\u4f2a\u9020\u75d5\u8ff9\u4e0a\u7684\u4e0d\u540c\u8986\u76d6\u884c\u4e3a\uff0cTriDetect\u901a\u8fc7\u6316\u6398\u6f5c\u5728\u7684\u67b6\u6784\u6a21\u5f0f\u63d0\u5347\u534a\u76d1\u7763\u4f2a\u9020\u68c0\u6d4b\u7684\u6cdb\u5316\u6027\uff0c\u4e3a\u8de8\u67b6\u6784\u4f2a\u9020\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2511.20463", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20463", "abs": "https://arxiv.org/abs/2511.20463", "authors": ["Amy K. Strong", "Ali Kashani", "Claus Danielson", "Leila Bridgeman"], "title": "Learning Control Barrier Functions with Deterministic Safety Guarantees", "comment": null, "summary": "Barrier functions (BFs) characterize safe sets of dynamical systems, where hard constraints are never violated as the system evolves over time. Computing a valid safe set and BF for a nonlinear (and potentially unmodeled), non-autonomous dynamical system is a difficult task. This work explores the design of BFs using data to obtain safe sets with deterministic assurances of control invariance. We leverage ReLU neural networks (NNs) to create continuous piecewise affine (CPA) BFs with deterministic safety guarantees for Lipschitz continuous, discrete-time dynamical system using sampled one-step trajectories. The CPA structure admits a novel classifier term to create a relaxed \\ac{bf} condition and construction via a data driven constrained optimization. We use iterative convex overbounding (ICO) to solve this nonconvex optimization problem through a series of convex optimization steps. We then demonstrate our method's efficacy on two-dimensional autonomous and non-autonomous dynamical systems.", "AI": {"tldr": "A data-driven design of barrier functions using ReLU networks to obtain deterministically safe, control-invariant sets for discrete-time Lipschitz systems, via a continuous piecewise affine barrier and iterative convex overbounding (ICO) optimization, validated on 2D autonomous and non-autonomous dynamics.", "motivation": "Safety-critical control requires guarantees that system trajectories stay within safe sets despite nonlinear and potentially unmodeled dynamics. Barrier functions provide invariance, but computing valid BFs for nonlinear/non-autonomous systems from data with deterministic guarantees is challenging.", "method": "Construct continuous piecewise affine barrier functions using ReLU neural networks. Introduce a classifier term to yield a relaxed barrier condition. Formulate a data-driven constrained optimization problem and solve it via iterative convex overbounding (ICO) which reduces nonconvex steps to a sequence of convex problems using sampled one-step trajectories.", "result": "Demonstrates the method on two-dimensional autonomous and non-autonomous dynamical systems, showing effective design of BFs with deterministic safety guarantees.", "conclusion": "The approach offers a practical, data-driven framework for designing CPA barrier functions with deterministic safety guarantees for Lipschitz, discrete-time systems, leveraging ICO to handle nonconvex optimization and data-driven constraints."}}
{"id": "2511.19504", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19504", "abs": "https://arxiv.org/abs/2511.19504", "authors": ["Subramanyam Sahoo", "Aman Chadha", "Vinija Jain", "Divya Chaudhary"], "title": "Position: The Complexity of Perfect AI Alignment -- Formalizing the RLHF Trilemma", "comment": "Accepted at NeurIPS 2025 Workshop on Socially Responsible and Trustworthy Foundation Models (ResponsibleFM)", "summary": "Reinforcement Learning from Human Feedback (RLHF) is widely used for aligning large language models, yet practitioners face a persistent puzzle: improving safety often reduces fairness, scaling to diverse populations becomes computationally intractable, and making systems robust often amplifies majority biases. We formalize this tension as the Alignment Trilemma: no RLHF system can simultaneously achieve (i) epsilon-representativeness across diverse human values, (ii) polynomial tractability in sample and compute complexity, and (iii) delta-robustness against adversarial perturbations and distribution shift. Through a complexity-theoretic analysis integrating statistical learning theory and robust optimization, we prove that achieving both representativeness (epsilon <= 0.01) and robustness (delta <= 0.001) for global-scale populations requires Omega(2^{d_context}) operations, which is super-polynomial in the context dimensionality. We show that current RLHF implementations resolve this trilemma by sacrificing representativeness: they collect only 10^3--10^4 samples from homogeneous annotator pools while 10^7--10^8 samples are needed for true global representation. Our framework provides a unified explanation for documented RLHF pathologies including preference collapse, sycophancy, and systematic bias amplification. We conclude with concrete directions for navigating these fundamental trade-offs through strategic relaxations of alignment requirements.", "AI": {"tldr": "Formalizes the Alignment Trilemma in RLHF: cannot achieve epsilon-representativeness, polynomial tractability, and delta-robustness simultaneously. Proves super-polynomial lower bound for representativeness plus robustness; current RLHF sacrifices representativeness by using small, homogeneous samples; explains pathologies; suggests relaxations to navigate trade-offs.", "motivation": "Understand fundamental trade-offs in aligning large language models with diverse human values using RLHF, balancing safety, fairness, scalability, and robustness.", "method": "Complexity-theoretic analysis that combines statistical learning theory and robust optimization. Proves Omega(2^{d_context}) lower bound for achieving joint representativeness (epsilon <= 0.01) and robustness (delta <= 0.001) at global scale. Analyzes sample regimes (1e3\u20131e4 vs 1e7\u20131e8) and interprets observed RLHF pathologies.", "result": "Establishes a formal trilemma with a super-polynomial lower bound, showing current RLHF setups trade representativeness for tractability and robustness. Provides a unified explanation for preference collapse, sycophancy, and bias amplification.", "conclusion": "Recommend strategic relaxations of alignment requirements and deliberate trade-offs to navigate the trilemma, outlining concrete directions for practical RLHF deployment."}}
{"id": "2511.20508", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20508", "abs": "https://arxiv.org/abs/2511.20508", "authors": ["Elise Zhang", "Fran\u00e7ois Mirall\u00e8s", "St\u00e9phane Dellacherie", "Di Wu", "Benoit Boulet"], "title": "Causal Feature Selection for Weather-Driven Residential Load Forecasting", "comment": "5 pages, 3 figures, 3 tables", "summary": "Weather is a dominant external driver of residential electricity demand, but adding many meteorological covariates can inflate model complexity and may even impair accuracy. Selecting appropriate exogenous features is non-trivial and calls for a principled selection framework, given the direct operational implications for day-to-day planning and reliability. This work investigates whether causal feature selection can retain the most informative weather drivers while improving parsimony and robustness for short-term load forecasting. We present a case study on Southern Ontario with two open-source datasets: (i) IESO hourly electricity consumption by Forward Sortation Areas; (ii) ERA5 weather reanalysis data. We compare different feature selection regimes (no feature selection, non-causal selection, PCMCI-causal selection) on city-level forecasting with three different time series forecasting models: GRU, TCN, PatchTST. In the feature analysis, non-causal selection prioritizes radiation and moisture variables that show correlational dependence, whereas PCMCI-causal selection emphasizes more direct thermal drivers and prunes the indirect covariates. We detail the evaluation pipeline and report diagnostics on prediction accuracy and extreme-weather robustness, positioning causal feature selection as a practical complement to modern forecasters when integrating weather into residential load forecasting.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u56e0\u679c\u7279\u5f81\u9009\u62e9\u4e0e\u4f20\u7edf\u7279\u5f81\u9009\u62e9\u5728\u5c45\u4f4f\u7528\u7535\u8d1f\u8377\u9884\u6d4b\u4e2d\u7684\u5929\u6c14\u7279\u5f81\u7b5b\u9009\u6548\u679c\uff0c\u7ed3\u679c\u663e\u793aPCMCI\u56e0\u679c\u9009\u62e9\u5728\u63d0\u5347\u6a21\u578b\u7b80\u7ea6\u6027\u548c\u5bf9\u6781\u7aef\u5929\u6c14\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e\u65e0\u9009\u62e9\u548c\u975e\u56e0\u679c\u9009\u62e9\uff0c\u4e14\u9002\u7528\u4e8eGRU\u3001TCN\u3001PatchTST\u7b49\u6a21\u578b\u3002", "motivation": "\u5929\u6c14\u5bf9\u7528\u7535\u9700\u6c42\u5f71\u54cd\u663e\u8457\uff0c\u4f46\u8fc7\u591a\u6c14\u8c61\u53d8\u91cf\u4f1a\u589e\u52a0\u6a21\u578b\u590d\u6742\u5ea6\u5e76\u53ef\u80fd\u964d\u4f4e\u9884\u6d4b\u6027\u80fd\u3002\u56e0\u6b64\u9700\u8981\u4e00\u4e2a principled \u7684\u7279\u5f81\u9009\u62e9\u6846\u67b6\uff0c\u4ee5\u7b5b\u9009\u6700\u5177\u4fe1\u606f\u91cf\u4e14\u5bf9\u65e5\u5e38\u8c03\u5ea6\u4e0e\u53ef\u9760\u6027\u6700\u6709\u5e2e\u52a9\u7684\u5929\u6c14\u9a71\u52a8\u53d8\u91cf\uff0c\u5c24\u5176\u5728\u77ed\u671f\u8d1f\u8377\u9884\u6d4b\u573a\u666f\u4e2d\u3002", "method": "\u4ee5\u52a0\u62ff\u5927\u5b89\u5927\u7565\u7701\u5357\u90e8\u7684\u4e24\u4e2a\u5f00\u6e90\u6570\u636e\u96c6\u4e3a\u57fa\u7840\uff1aIESO \u6309 Forward Sortation Areas \u7684\u5c0f\u65f6\u7528\u7535\u91cf\uff0c\u4ee5\u53ca ERA5 \u5929\u6c14\u518d\u5206\u6790\u6570\u636e\u3002\u6bd4\u8f83\u4e09\u79cd\u7279\u5f81\u9009\u62e9\u7b56\u7565\uff08\u65e0\u7279\u5f81\u9009\u62e9\u3001\u975e\u56e0\u679c\u9009\u62e9\u3001PCMCI\u56e0\u679c\u9009\u62e9\uff09\u5728\u57ce\u5e02\u7ea7\u9884\u6d4b\u4e2d\u5bf9 GRU\u3001TCN\u3001PatchTST \u4e09\u79cd\u65f6\u5e8f\u6a21\u578b\u7684\u5f71\u54cd\u3002\u7279\u5f81\u5206\u6790\u663e\u793a\uff0c\u975e\u56e0\u679c\u9009\u62e9\u504f\u597d\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u8f90\u5c04\u4e0e\u6e7f\u5ea6\u53d8\u91cf\uff1bPCMCI\u56e0\u679c\u9009\u62e9\u5219\u805a\u7126\u76f4\u63a5\u70ed\u9a71\u52a8\u5e76\u53bb\u9664\u95f4\u63a5\u534f\u53d8\u91cf\u3002\u62a5\u544a\u9884\u6d4b\u7cbe\u5ea6\u4e0e\u6781\u7aef\u5929\u6c14\u9c81\u68d2\u6027\u7684\u8bca\u65ad\uff0c\u5f3a\u8c03\u5c06\u56e0\u679c\u7279\u5f81\u9009\u62e9\u4f5c\u4e3a\u73b0\u4ee3\u8d1f\u8377\u9884\u6d4b\u5668\u7684\u5b9e\u7528\u8865\u5145\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u6307\u5411 PCMCI \u56e0\u679c\u9009\u62e9\u66f4\u503e\u5411\u4e8e\u4fdd\u7559\u76f4\u63a5\u70ed\u9a71\u52a8\u3001\u88c1\u526a\u5197\u4f59\u7279\u5f81\uff0c\u4ece\u800c\u63d0\u5347\u5728\u6781\u7aef\u5929\u6c14\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\uff1b\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u975e\u56e0\u679c\u9009\u62e9\u66f4\u6613\u88ab\u76f8\u5173\u6027\u9a71\u52a8\u7684\u8f90\u5c04\u3001\u6e7f\u5ea6\u7b49\u53d8\u91cf\u4e3b\u5bfc\u3002\u4e0d\u540c\u9884\u6d4b\u6a21\u578b\u5728\u76f8\u540c\u9009\u62e9\u7b56\u7565\u4e0b\u663e\u793a\u51fa\u5bf9\u7b80\u7ea6\u7279\u5f81\u7684\u517c\u5bb9\u6027\uff0c\u652f\u6301\u56e0\u679c\u7279\u5f81\u9009\u62e9\u5728\u77ed\u671f\u5c45\u4f4f\u8d1f\u8377\u9884\u6d4b\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u5c06\u56e0\u679c\u7279\u5f81\u9009\u62e9\u89c6\u4e3a\u4e0e\u73b0\u4ee3\u9884\u6d4b\u5668\u4e92\u8865\u7684\u6709\u6548\u5de5\u5177\uff0c\u6709\u671b\u63d0\u5347\u5929\u6c14\u7279\u5f81\u5728\u65e5\u5e38\u89c4\u5212\u4e0e\u53ef\u9760\u6027\u8bc4\u4f30\u4e2d\u7684\u5229\u7528\u6548\u7387\u4e0e\u9c81\u68d2\u6027\uff0c\u5c24\u5176\u5728\u6781\u7aef\u5929\u6c14\u573a\u666f\u4e0b\u8868\u73b0\u7a81\u51fa\u3002\u8be5\u65b9\u6cd5\u53ef\u96c6\u6210\u5230\u73b0\u6709\u8d1f\u8377\u9884\u6d4b\u6d41\u6c34\u7ebf\uff0c\u4f46\u9700\u5173\u6ce8\u6570\u636e\u8d28\u91cf\u3001\u8ba1\u7b97\u6210\u672c\u4ee5\u53ca\u5730\u533a\u9002\u7528\u6027\u7b49\u6f5c\u5728\u9650\u5236\u3002"}}
{"id": "2511.20552", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20552", "abs": "https://arxiv.org/abs/2511.20552", "authors": ["Haoyu Wang", "Andrea Alfonsi", "Roberto Ponciroli", "Richard Vilim"], "title": "From Features to States: Data-Driven Selection of Measured State Variables via RFE-DMDc", "comment": null, "summary": "The behavior of a dynamical system under a given set of inputs can be captured by tracking the response of an optimal subset of process variables (\\textit{state variables}). For many engineering systems, however, first-principles, model-based identification is impractical, motivating data-driven approaches for Digital Twins used in control and diagnostics. In this paper, we present RFE-DMDc, a supervised, data-driven workflow that uses Recursive Feature Elimination (RFE) to select a minimal, physically meaningful set of variables to monitor and then derives a linear state-space model via Dynamic Mode Decomposition with Control (DMDc). The workflow includes a cross-subsystem selection step that mitigates feature \\textit{overshadowing} in multi-component systems. To corroborate the results, we implement a GA-DMDc baseline that jointly optimizes the state set and model fit under a common accuracy cost on states and outputs. Across a truth-known RLC benchmark and a realistic Integrated Energy System (IES) with multiple thermally coupled components and thousands of candidate variables, RFE-DMDc consistently recovers compact state sets (\\(\\approx 10\\) variables) that achieve test errors comparable to GA-DMDc while requiring an order of magnitude less computational time. The selected variables retain clear physical interpretation across subsystems, and the resulting models demonstrate competitive predictive accuracy, computational efficiency, and robustness to overfitting.", "AI": {"tldr": "\u63d0\u51fa RFE-DMDc \u6846\u67b6\uff0c\u901a\u8fc7\u9012\u5f52\u7279\u5f81\u6d88\u9664\u9009\u62e9\u6700\u5c0f\u3001\u7269\u7406\u610f\u4e49\u6e05\u6670\u7684\u53d8\u91cf\u96c6\u5408\uff0c\u5e76\u7ed3\u5408 DMDc \u6784\u5efa\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff1b\u5e76\u4e0e GA-DMDc \u57fa\u7ebf\u5728 RLC \u4e0e\u7efc\u5408\u80fd\u6e90\u7cfb\u7edf\u4e0a\u5bf9\u6bd4\uff0c\u663e\u793a\u5728\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u7cbe\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5728\u5de5\u7a0b\u7cfb\u7edf\u4e2d\uff0c\u57fa\u4e8e\u7b2c\u4e00\u6027\u539f\u7406\u7684\u5efa\u6a21\u5f80\u5f80\u4e0d\u53ef\u884c\uff0c\u9700\u6570\u636e\u9a71\u52a8\u7684\u6570\u5b57\u5b6a\u751f\u7528\u4e8e\u63a7\u5236\u4e0e\u8bca\u65ad\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u7d27\u51d1\u3001\u53ef\u89e3\u91ca\u4e14\u9c81\u68d2\u7684\u72b6\u6001\u96c6\u5408\u548c\u76f8\u5e94\u7ebf\u6027\u6a21\u578b\u3002", "method": "\u5148\u5e94\u7528\u9012\u5f52\u7279\u5f81\u6d88\u9664(RFE)\u9009\u62e9\u4e00\u4e2a\u6700\u5c0f\u4e14\u7269\u7406\u610f\u4e49\u660e\u786e\u7684\u72b6\u6001\u53d8\u91cf\u96c6\u5408\uff1b\u5f15\u5165\u8de8\u5b50\u7cfb\u7edf\u9009\u62e9\u4ee5\u7f13\u89e3\u591a\u7ec4\u4ef6\u7cfb\u7edf\u4e2d\u7684\u7279\u5f81\u8986\u76d6\u95ee\u9898\uff1b\u518d\u7528 DMDc \u6784\u5efa\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3002\u4ee5 GA-DMDc \u4e3a\u57fa\u7ebf\uff0c\u5728\u5171\u540c\u7684\u51c6\u786e\u6027\u6210\u672c\u4e0b\u540c\u65f6\u4f18\u5316\u72b6\u6001\u96c6\u5408\u4e0e\u6a21\u578b\u62df\u5408\u3002\u5bf9 RLC \u57fa\u51c6\u4e0e\u591a\u70ed\u8026\u5408\u7ec4\u4ef6\u7684\u771f\u5b9e\u80fd\u6e90\u7cfb\u7edf\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5f97\u5230\u7ea6 10 \u4e2a\u53d8\u91cf\u7684\u7d27\u51d1\u96c6\u5408\uff0c\u6d4b\u8bd5\u8bef\u5dee\u4e0e GA-DMDc \u76f8\u5f53\u4f46\u8ba1\u7b97\u65f6\u95f4\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "result": "RFE-DMDc \u5728\u591a\u7ec4\u4ef6\u7cfb\u7edf\u4e2d\u6210\u529f\u56de\u6536\u7d27\u51d1\u7684\u72b6\u6001\u96c6\u5408\uff08\u7ea6 10 \u4e2a\u53d8\u91cf\uff09\uff0c\u5b9e\u73b0\u4e0e GA-DMDc \u76f8\u4f3c\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff1b\u6240\u9009\u53d8\u91cf\u5177\u6709\u8de8\u5b50\u7cfb\u7edf\u7684\u7269\u7406\u53ef\u89e3\u91ca\u6027\uff0c\u6a21\u578b\u5c55\u73b0\u51fa\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u80fd\u529b\u3001\u8ba1\u7b97\u6548\u7387\u53ca\u5bf9\u8fc7\u62df\u5408\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u7684 RFE-DMDc \u4e3a\u5177\u6709\u5927\u91cf\u5019\u9009\u53d8\u91cf\u7684\u591a\u7ec4\u4ef6\u7cfb\u7edf\u63d0\u4f9b\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u4f4e\u5f00\u9500\u4e14\u53ef\u89e3\u91ca\u7684\u6570\u5b57\u5b6a\u751f\u5efa\u6a21\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u63a7\u5236\u4e0e\u8bca\u65ad\u4efb\u52a1\uff0c\u5e76\u5177\u5907\u826f\u597d\u7684\u63a8\u5e7f\u6f5c\u529b\u3002"}}
{"id": "2511.20603", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20603", "abs": "https://arxiv.org/abs/2511.20603", "authors": ["Winfrey Paul Sagayam Dennis"], "title": "Exploring Urban Air Mobility Adoption Potential in San Francisco Bay Area Region A Systems of Systems Level Case Study on Passenger Waiting Times and Travel Efficiency", "comment": null, "summary": "Urban Air mobility has gained momentum with recent advancements in the electric vertical take-off and landing (eVTOL) vehicles, offering faster point-to-point air taxi services that could help relieve traffic congestion in chronically overburdened cities. The research assesses the feasibility and systems-of-systems level adoption potential of UAM operations in the San Francisco Bay Area by comparing passenger departure, waiting, travel, and arrival times across key regional nodes, including San Francisco, Oakland, San Jose, and Palo Alto airports, with conventional ground transportation. A multi-agent simulation was developed in MATLAB to evaluate the fleet operations and to model demand arrival using a Poisson process under stochastic passenger flows and turnaround constraints. Results indicate that utilizing UAM during peak demand could reduce total travel times up to eighty percent across the region. The findings of this paper highlight the critical operational factors for fleet schedule optimization. Especially how the fleet size, passengers' request volumes, and turnaround time directly influence waiting time, operating cost, and overall user acceptance.", "AI": {"tldr": "UAM with eVTOL could dramatically cut regional travel times in SF Bay Area; a MATLAB multi-agent model suggests up to 80% time reduction during peak demand, with fleet size, demand volume, and turnaround time as key levers for cost, waiting times, and user acceptance.", "motivation": "Explore the feasibility and systems-level adoption of Urban Air Mobility (UAM) in a congested metropolitan area, addressing whether eVTOL air taxis can alleviate ground congestion and how a systems-of-systems perspective affects implementation.", "method": "Develop a MATLAB-based multi-agent simulation to evaluate fleet operations and model demand arrival with a Poisson process under stochastic passenger flows and turnaround constraints; compare UAM to conventional ground transport across regional nodes (San Francisco, Oakland, San Jose, Palo Alto airports).", "result": "The simulation indicates substantial travel-time savings (up to ~80%) during peak demand when using UAM. Critical factors\u2014fleet size, passenger request volumes, and turnaround time\u2014significantly influence waiting times, operating costs, and user acceptance.", "conclusion": "UAM deployment in the SF Bay Area shows strong potential under appropriate fleet scheduling and operational parameters. Successful adoption hinges on optimizing fleet size and turnaround, and managing demand to balance travel-time savings with costs and acceptance."}}
{"id": "2511.19513", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19513", "abs": "https://arxiv.org/abs/2511.19513", "authors": ["Bing Liu", "Boao Kong", "Limin Lu", "Kun Yuan", "Chengcheng Zhao"], "title": "Row-stochastic matrices can provably outperform doubly stochastic matrices in decentralized learning", "comment": "41 pages, 38 figures", "summary": "Decentralized learning often involves a weighted global loss with heterogeneous node weights $\u03bb$. We revisit two natural strategies for incorporating these weights: (i) embedding them into the local losses to retain a uniform weight (and thus a doubly stochastic matrix), and (ii) keeping the original losses while employing a $\u03bb$-induced row-stochastic matrix. Although prior work shows that both strategies yield the same expected descent direction for the global loss, it remains unclear whether the Euclidean-space guarantees are tight and what fundamentally differentiates their behaviors. To clarify this, we develop a weighted Hilbert-space framework $L^2(\u03bb;\\mathbb{R}^d)$ and obtain convergence rates that are strictly tighter than those from Euclidean analysis. In this geometry, the row-stochastic matrix becomes self-adjoint whereas the doubly stochastic one does not, creating additional penalty terms that amplify consensus error, thereby slowing convergence. Consequently, the difference in convergence arises not only from spectral gaps but also from these penalty terms. We then derive sufficient conditions under which the row-stochastic design converges faster even with a smaller spectral gap. Finally, by using a Rayleigh-quotient and Loewner-order eigenvalue comparison, we further obtain topology conditions that guarantee this advantage and yield practical topology-design guidelines.", "AI": {"tldr": "\u5728\u5f02\u8d28\u8282\u70b9\u6743\u91cd \u03bb \u4e0b\uff0c\u63d0\u51fa\u5728\u52a0\u6743\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4 L^2(\u03bb; R^d) \u4e2d\u7684\u5206\u6790\u6846\u67b6\uff0c\u63ed\u793a\u4e24\u79cd\u7b56\u7565\u7684\u6536\u655b\u5dee\u5f02\uff1a\u5c06\u6743\u91cd\u5d4c\u5165\u5c40\u90e8\u635f\u5931\u4ee5\u83b7\u5f97\u7edf\u4e00\u6743\u91cd\uff08\u4ece\u800c\u5f97\u5230\u4e00\u4e2a\u884c/\u5217\u53cc\u968f\u673a\u77e9\u9635\u7684\u7b49\u4ef7\u6027\uff09\uff0c\u6216\u8005\u4fdd\u6301\u539f\u59cb\u635f\u5931\u4f46\u4f7f\u7528 \u03bb \u5f15\u5bfc\u7684\u884c\u968f\u673a\u77e9\u9635\u3002\u5c3d\u7ba1\u5df2\u6709\u5de5\u4f5c\u8868\u660e\u4e24\u8005\u5728\u5168\u7403\u635f\u5931\u7684\u671f\u671b\u4e0b\u964d\u65b9\u5411\u4e0a\u76f8\u540c\uff0c\u4f46 Euclidean \u7a7a\u95f4\u4e0b\u7684\u4fdd\u8bc1\u662f\u5426\u7d27\u81f4\u5c1a\u4e0d\u6e05\u695a\u3002\u901a\u8fc7\u65b0\u6846\u67b6\uff0c\u5f97\u5230\u6bd4\u6b27\u51e0\u91cc\u5f97\u5206\u6790\u66f4\u7d27\u7684\u6536\u655b\u7387\u754c\uff0c\u4e14\u5728\u8be5\u51e0\u4f55\u4e0b\uff0c\u884c\u968f\u673a\u77e9\u9635\u4e3a\u81ea\u4f34\u800c\u53cc\u968f\u673a\u77e9\u9635\u5e76\u975e\u81ea\u4f34\uff0c\u4ece\u800c\u4ea7\u751f\u989d\u5916\u7684\u7f5a\u9879\u6765\u653e\u5927\u5171\u8bc6\u8bef\u5dee\uff0c\u4f7f\u6536\u655b\u901f\u5ea6\u53d7\u5230\u5f71\u54cd\u3002\u7814\u7a76\u8fd8\u7ed9\u51fa\u5728\u8c31\u9699\u8f83\u5c0f\u7684\u60c5\u51b5\u4e0b\uff0c\u884c\u968f\u673a\u8bbe\u8ba1\u4ecd\u7136\u53ef\u4ee5\u66f4\u5feb\u6536\u655b\u7684\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u5229\u7528 Rayleigh \u5546\u548c Loewner \u987a\u5e8f\u7684\u7279\u5f81\u503c\u6bd4\u8f83\uff0c\u63a8\u5bfc\u51fa\u62d3\u6251\u7ed3\u6784\u7684\u8bbe\u8ba1\u51c6\u5219\u3002", "motivation": "\u63ed\u793a\u5f02\u8d28\u6743\u91cd\u6761\u4ef6\u4e0b\u4e24\u79cd\u6743\u91cd\u5904\u7406\u7b56\u7565\u5728\u6536\u655b\u6027\u548c\u62d3\u6251\u8bbe\u8ba1\u4e0a\u7684\u6839\u672c\u5dee\u5f02\uff0c\u8d28\u7591\u5728 Euclidean \u6846\u67b6\u4e0b\u5f97\u5230\u7684\u7b49\u4ef7\u6027\u662f\u5426\u9c81\u68d2\uff0c\u4ee5\u53ca\u662f\u5426\u5b58\u5728\u66f4\u7d27\u7684\u6536\u655b\u6027\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u5e76\u5229\u7528\u52a0\u6743\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4 L^2(\u03bb; R^d) \u7684\u5206\u6790\u6846\u67b6\uff0c\u63a8\u5bfc\u51fa\u4e25\u683c\u7684\u6536\u655b\u7387\u754c\uff0c\u5e76\u5206\u6790\u884c\u968f\u673a\u77e9\u9635\u4e0e\u53cc\u968f\u673a\u77e9\u9635\u5728\u8be5\u51e0\u4f55\u4e0b\u7684\u81ea\u4f34\u6027\u5dee\u5f02\u53ca\u7531\u6b64\u5f15\u5165\u7684\u7f5a\u9879\uff1b\u901a\u8fc7 Rayleigh \u5546\u548c Loewner-order \u7684\u8c31\u6bd4\u8f83\u6765\u5f97\u5230\u62d3\u6251\u6761\u4ef6\u548c\u8bbe\u8ba1\u6307\u5357\u3002", "result": "\u5f97\u5230\u6bd4\u6b27\u51e0\u91cc\u5f97\u5206\u6790\u66f4\u7d27\u7684\u6536\u655b\u754c\uff1b\u5728\u6743\u91cd\u52a0\u6743\u51e0\u4f55\u4e0b\uff0c\u884c\u968f\u673a\u77e9\u9635\u4e3a\u81ea\u4f34\uff0c\u53cc\u968f\u673a\u77e9\u9635\u975e\u81ea\u4f34\uff0c\u56e0\u800c\u5b58\u5728\u989d\u5916\u7f5a\u9879\u6765\u6269\u5927\u5171\u8bc6\u8bef\u5dee\uff0c\u4ece\u800c\u89e3\u91ca\u4e24\u79cd\u7b56\u7565\u5728\u6536\u655b\u884c\u4e3a\u4e0a\u7684\u5dee\u5f02\uff1b\u7ed9\u51fa\u5728\u8c31\u9699\u8f83\u5c0f\u4f46\u4ecd\u53ef\u5feb\u901f\u6536\u655b\u7684\u5145\u8981\u6216\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u7ed9\u51fa\u5229\u7528 Rayleigh \u5546\u548c Loewner \u6bd4\u8f83\u5f97\u5230\u7684\u62d3\u6251\u8bbe\u8ba1\u51c6\u5219\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u52a0\u6743\u51e0\u4f55\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u8c31\u9699\u4e4b\u5916\u7684\u7f5a\u9879\u5bf9\u6536\u655b\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u5e76\u7ed9\u51fa\u53ef\u64cd\u4f5c\u7684\u62d3\u6251\u8bbe\u8ba1\u6307\u5357\uff0c\u5e2e\u52a9\u5728\u5f02\u8d28\u6743\u91cd\u73af\u5883\u4e0b\u9009\u62e9\u66f4\u5feb\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u7b56\u7565\u3002"}}
{"id": "2511.19517", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19517", "abs": "https://arxiv.org/abs/2511.19517", "authors": ["Adarsh Kumarappan", "Ananya Mujoo"], "title": "Automating Deception: Scalable Multi-Turn LLM Jailbreaks", "comment": null, "summary": "Multi-turn conversational attacks, which leverage psychological principles like Foot-in-the-Door (FITD), where a small initial request paves the way for a more significant one, to bypass safety alignments, pose a persistent threat to Large Language Models (LLMs). Progress in defending against these attacks is hindered by a reliance on manual, hard-to-scale dataset creation. This paper introduces a novel, automated pipeline for generating large-scale, psychologically-grounded multi-turn jailbreak datasets. We systematically operationalize FITD techniques into reproducible templates, creating a benchmark of 1,500 scenarios across illegal activities and offensive content. We evaluate seven models from three major LLM families under both multi-turn (with history) and single-turn (without history) conditions. Our results reveal stark differences in contextual robustness: models in the GPT family demonstrate a significant vulnerability to conversational history, with Attack Success Rates (ASR) increasing by as much as 32 percentage points. In contrast, Google's Gemini 2.5 Flash exhibits exceptional resilience, proving nearly immune to these attacks, while Anthropic's Claude 3 Haiku shows strong but imperfect resistance. These findings highlight a critical divergence in how current safety architectures handle conversational context and underscore the need for defenses that can resist narrative-based manipulation.", "AI": {"tldr": "\u901a\u8fc7\u81ea\u52a8\u5316\u7ba1\u7ebf\u751f\u62101,500\u4e2a\u57fa\u4e8eFITD\u7684\u591a\u8f6e\u8d8a\u72f1\u573a\u666f\uff0c\u6784\u5efa\u5927\u89c4\u6a21\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e03\u4e2a\u6a21\u578b\u5728\u6709\u65e0\u5bf9\u8bdd\u5386\u53f2\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u7ed3\u679c\u663e\u793aGPT\u5bb6\u65cf\u5bf9\u4e0a\u4e0b\u6587\u654f\u611f\u5ea6\u9ad8\u3001Gemini 2.5 Flash\u5f02\u5e38\u5f3a\u5065\u3001Claude 3 Haiku\u5177\u5907\u8f83\u5f3a\u4f46\u4e0d\u5b8c\u7f8e\u7684\u9632\u62a4\uff1b\u63d0\u793a\u9700\u8981\u6539\u8fdb\u5bf9\u53d9\u4e8b\u6027\u64cd\u63a7\u7684\u9632\u5fa1\u3002", "motivation": "\u89e3\u51b3\u591a\u8f6e\u5bf9\u8bdd\u653b\u51fb\u7684\u53ef\u6269\u5c55\u6570\u636e\u96c6\u7f3a\u4e4f\u95ee\u9898\uff0c\u5229\u7528\u5fc3\u7406\u5b66\u539f\u7406\u7cfb\u7edf\u5316\u8bc4\u4f30\u5927\u6a21\u578b\u5b89\u5168\u6027\uff1b\u5f53\u524d\u9632\u5fa1\u591a\u4f9d\u8d56\u4eba\u5de5\u6570\u636e\u96c6\uff0c\u96be\u4ee5\u6269\u5c55\uff0c\u5e94\u53d1\u5c55\u53ef\u91cd\u590d\u7684\u3001\u5927\u89c4\u6a21\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u5c06FITD\u6280\u5de7\u5177\u4f53\u5316\u4e3a\u53ef\u590d\u73b0\u7684\u6a21\u677f\uff0c\u81ea\u52a8\u751f\u62101,500\u4e2a\u8de8\u9886\u57df\u573a\u666f\u7684\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\uff1b\u5728\u4e09\u4e2a\u5927\u578bLLM\u5bb6\u65cf\u4e2d\u7684\u4e03\u4e2a\u6a21\u578b\u4e0a\uff0c\u5206\u522b\u5728\u6709\u5386\u53f2\uff08\u591a\u8f6e\uff09\u548c\u65e0\u5386\u53f2\uff08\u5355\u8f6e\uff09\u6761\u4ef6\u4e0b\u8bc4\u4f30\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\u3002", "result": "GPT\u5bb6\u65cf\u5728\u6709\u5386\u53f2\u4e0a\u4e0b\u6587\u6761\u4ef6\u4e0b\u653b\u51fb\u6210\u529f\u7387\u663e\u8457\u4e0a\u5347\uff0c\u6700\u9ad8\u53ef\u589e\u81f332\u4e2a\u767e\u5206\u70b9\uff1bGemini 2.5 Flash\u51e0\u4e4e\u5b8c\u5168\u62b5\u5fa1\u6b64\u7c7b\u653b\u51fb\uff0cAnthropic Claude 3 Haiku\u80fd\u62b5\u5fa1\u4f46\u5e76\u975e\u5b8c\u7f8e\uff1b\u4e0d\u540c\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u9c81\u68d2\u6027\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u5b89\u5168\u67b6\u6784\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u7684\u5904\u7406\u5b58\u5728\u660e\u663e\u5dee\u5f02\uff0c\u5f53\u524d\u9632\u5fa1\u4f53\u7cfb\u9700\u63d0\u5347\u5bf9\u53d9\u4e8b\u6027\u64cd\u63a7\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u5c55\u80fd\u62b5\u5fa1\u591a\u8f6e\u53d9\u4e8b\u653b\u51fb\u7684\u9632\u5fa1\u7b56\u7565\u3002"}}
{"id": "2511.20015", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20015", "abs": "https://arxiv.org/abs/2511.20015", "authors": ["Xiucheng Wang", "Tingwei Yuan", "Yang Cao", "Nan Cheng", "Ruijin Sun", "Weihua Zhuang"], "title": "iRadioDiff: Physics-Informed Diffusion Model for Indoor Radio Map Construction and Localization", "comment": null, "summary": "Radio maps (RMs) serve as environment-aware electromagnetic (EM) representations that connect scenario geometry and material properties to the spatial distribution of signal strength, enabling localization without costly in-situ measurements. However, constructing high-fidelity indoor RMs remains challenging due to the prohibitive latency of EM solvers and the limitations of learning-based methods, which often rely on sparse measurements or assumptions of homogeneous material, which are misaligned with the heterogeneous and multipath-rich nature of indoor environments. To overcome these challenges, we propose iRadioDiff, a sampling-free diffusion-based framework for indoor RM construction. iRadioDiff is conditioned on access point (AP) positions, and physics-informed prompt encoded by material reflection and transmission coefficients. It further incorporates multipath-critical priors, including diffraction points, strong transmission boundaries, and line-of-sight (LoS) contours, to guide the generative process via conditional channels and boundary-weighted objectives. This design enables accurate modeling of nonstationary field discontinuities and efficient construction of physically consistent RMs. Experiments demonstrate that iRadioDiff achieves state-of-the-art performance in indoor RM construction and received signal strength based indoor localization, which offers effective generalization across layouts and material configurations. Code is available at https://github.com/UNIC-Lab/iRadioDiff.", "AI": {"tldr": "iRadioDiff is a sampling-free diffusion-based framework for indoor radio-map construction, conditioned on AP positions with physics-informed prompts and multipath priors, achieving state-of-the-art RM construction and RSS-based localization with strong generalization.", "motivation": "Indoor environments are heterogeneous and rich in multipath, making high-fidelity radio map construction challenging due to slow EM solvers and limitations of learning-based methods that rely on sparse measurements or homogeneous-material assumptions.", "method": "A diffusion-based generative model that is sampling-free and conditioned on AP positions. It uses physics-informed prompts encoded by material reflection and transmission coefficients, and incorporates multipath-critical priors (diffraction points, strong transmission boundaries, LoS contours) through conditional channels and boundary-weighted objectives to model nonstationary field discontinuities and ensure physical consistency.", "result": "Experiments show state-of-the-art performance in indoor RM construction and RSS-based indoor localization, with good generalization across layouts and material configurations.", "conclusion": "iRadioDiff enables accurate, efficient construction of physically consistent indoor radio maps and demonstrates strong generalization; code is available at the provided GitHub URL."}}
{"id": "2511.20220", "categories": ["cs.LG", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.20220", "abs": "https://arxiv.org/abs/2511.20220", "authors": ["Ruxandra-Stefania Tudose", "Moritz H. W. Gr\u00fcss", "Grace Ra Kim", "Karl H. Johansson", "Nicola Bastianello"], "title": "Communication-Efficient Learning for Satellite Constellations", "comment": null, "summary": "Satellite constellations in low-Earth orbit are now widespread, enabling positioning, Earth imaging, and communications. In this paper we address the solution of learning problems using these satellite constellations. In particular, we focus on a federated approach, where satellites collect and locally process data, with the ground station aggregating local models. We focus on designing a novel, communication-efficient algorithm that still yields accurate trained models. To this end, we employ several mechanisms to reduce the number of communications with the ground station (local training) and their size (compression). We then propose an error feedback mechanism that enhances accuracy, which yields, as a byproduct, an algorithm-agnostic error feedback scheme that can be more broadly applied. We analyze the convergence of the resulting algorithm, and compare it with the state of the art through simulations in a realistic space scenario, showcasing superior performance.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.19544", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19544", "abs": "https://arxiv.org/abs/2511.19544", "authors": ["Kaidi Wan", "Minghao Liu", "Yong Lai"], "title": "Learning to Solve Weighted Maximum Satisfiability with a Co-Training Architecture", "comment": "10 pages, 4 figures", "summary": "Wepropose SplitGNN, a graph neural network (GNN)-based\n  approach that learns to solve weighted maximum satisfiabil ity (MaxSAT) problem. SplitGNN incorporates a co-training\n  architecture consisting of supervised message passing mech anism and unsupervised solution boosting layer. A new graph\n  representation called edge-splitting factor graph is proposed\n  to provide more structural information for learning, which is\n  based on spanning tree generation and edge classification. To\n  improve the solutions on challenging and weighted instances,\n  we implement a GPU-accelerated layer applying efficient\n  score calculation and relaxation-based optimization. Exper iments show that SplitGNN achieves 3* faster convergence\n  and better predictions compared with other GNN-based ar chitectures. More notably, SplitGNN successfully finds solu tions that outperform modern heuristic MaxSAT solvers on\n  much larger and harder weighted MaxSAT benchmarks, and\n  demonstrates exceptional generalization abilities on diverse\n  structural instances.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.19548", "categories": ["cs.LG", "cs.AI", "cs.CY", "econ.GN", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2511.19548", "abs": "https://arxiv.org/abs/2511.19548", "authors": ["Yiven", "Zhu"], "title": "When Should Neural Data Inform Welfare? A Critical Framework for Policy Uses of Neuroeconomics", "comment": "Durham Economic Journal 2025", "summary": "Neuroeconomics promises to ground welfare analysis in neural and computational evidence about how people value outcomes, learn from experience and exercise self-control. At the same time, policy and commercial actors increasingly invoke neural data to justify paternalistic regulation, \"brain-based\" interventions and new welfare measures. This paper asks under what conditions neural data can legitimately inform welfare judgements for policy rather than merely describing behaviour. I develop a non-empirical, model-based framework that links three levels: neural signals, computational decision models and normative welfare criteria. Within an actor-critic reinforcement-learning model, I formalise the inference path from neural activity to latent values and prediction errors and then to welfare claims. I show that neural evidence constrains welfare judgements only when the neural-computational mapping is well validated, the decision model identifies \"true\" interests versus context-dependent mistakes, and the welfare criterion is explicitly specified and defended. Applying the framework to addiction, neuromarketing and environmental policy, I derive a Neuroeconomic Welfare Inference Checklist for regulators and for designers of NeuroAI systems. The analysis treats brains and artificial agents as value-learning systems while showing that internal reward signals, whether biological or artificial, are computational quantities and cannot be treated as welfare measures without an explicit normative model.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.19555", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19555", "abs": "https://arxiv.org/abs/2511.19555", "authors": ["Ruiyang Xu"], "title": "Online Sparse Feature Selection in Data Streams via Differential Evolution", "comment": null, "summary": "The processing of high-dimensional streaming data commonly utilizes online streaming feature selection (OSFS) techniques. However, practical implementations often face challenges with data incompleteness due to equipment failures and technical constraints. Online Sparse Streaming Feature Selection (OS2FS) tackles this issue through latent factor analysis-based missing data imputation. Despite this advancement, existing OS2FS approaches exhibit substantial limitations in feature evaluation, resulting in performance deterioration. To address these shortcomings, this paper introduces a novel Online Differential Evolution for Sparse Feature Selection (ODESFS) in data streams, incorporating two key innovations: (1) missing value imputation using a latent factor analysis model, and (2) feature importance evaluation through differential evolution. Comprehensive experiments conducted on six real-world datasets demonstrate that ODESFS consistently outperforms state-of-the-art OSFS and OS2FS methods by selecting optimal feature subsets and achieving superior accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u6570\u636e\u6d41\u4e2d\u8fdb\u884c\u5728\u7ebf\u7a00\u758f\u7279\u5f81\u9009\u62e9\u7684\u65b0\u65b9\u6cd5 ODESFS\uff0c\u7ed3\u5408\u57fa\u4e8e\u6f5c\u5728\u56e0\u5b50\u5206\u6790\u7684\u7f3a\u5931\u503c\u586b\u5145\u4e0e\u57fa\u4e8e\u5dee\u5206\u8fdb\u5316\u7684\u7279\u5f81\u91cd\u8981\u6027\u8bc4\u4f30\uff0c\u80fd\u5728\u7f3a\u5931\u6570\u636e\u4e0b\u6301\u7eed outperform \u73b0\u6709 OSFS/OS2FS \u7684\u65b9\u6cd5\uff0c\u9009\u51fa\u6700\u4f18\u5b50\u96c6\u5e76\u63d0\u5347\u51c6\u786e\u7387\u3002", "motivation": "\u5728\u9ad8\u7ef4\u6d41\u6570\u636e\u5904\u7406\u4e2d\uff0c\u6570\u636e\u7f3a\u5931\u666e\u904d\u5b58\u5728\uff0c\u73b0\u6709\u7684 OSFS \u65b9\u6cd5\u5728\u7f3a\u5931\u6570\u636e\u573a\u666f\u4e0b\u7684\u7279\u5f81\u8bc4\u4f30\u8868\u73b0\u4e0d\u8db3\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u5728\u7f3a\u5931\u6570\u636e\u4e0b\u5b9e\u73b0\u66f4\u7a33\u5065\u7684\u5728\u7ebf\u7279\u5f81\u9009\u62e9\u3002", "method": "\u63d0\u51fa Online Differential Evolution for Sparse Feature Selection (ODESFS)\u3002\u6838\u5fc3\u5305\u542b\u4e24\u70b9\uff1a\u4e00\u662f\u91c7\u7528\u6f5c\u5728\u56e0\u5b50\u5206\u6790\u6a21\u578b\u5bf9\u7f3a\u5931\u503c\u8fdb\u884c\u586b\u5145\uff1b\u4e8c\u662f\u5229\u7528\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\u5bf9\u7279\u5f81\u7684\u91cd\u8981\u6027\u8fdb\u884c\u8bc4\u4f30\u4ee5\u8fdb\u884c\u9009\u62e9\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u6570\u636e\u6d41\u4e2d\u7684\u7a00\u758f\u7279\u5f81\u9009\u62e9\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5168\u9762\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e ODESFS \u5728\u51c6\u786e\u7387\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u7684 OSFS \u4e0e OS2FS \u65b9\u6cd5\uff0c\u80fd\u591f\u9009\u51fa\u6700\u4f18\u7684\u7279\u5f81\u5b50\u96c6\u5e76\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "ODESFS \u6709\u6548\u89e3\u51b3\u4e86\u5e26\u7f3a\u5931\u503c\u7684\u5728\u7ebf\u7a00\u758f\u7279\u5f81\u9009\u62e9\u95ee\u9898\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u7a33\u5065\u7684\u7279\u5f81\u8bc4\u4f30\u548c\u66f4\u9ad8\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2511.19561", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19561", "abs": "https://arxiv.org/abs/2511.19561", "authors": ["Zecheng Pan", "Zhikang Chen", "Ding Li", "Min Zhang", "Sen Cui", "Hongshuo Jin", "Luqi Tao", "Yi Yang", "Deheng Ye", "Yu Zhang", "Tingting Zhu", "Tianling Ren"], "title": "Merging without Forgetting: Continual Fusion of Task-Specific Models via Optimal Transport", "comment": null, "summary": "Merging models fine-tuned for different tasks into a single unified model has become an increasingly important direction for building versatile, efficient multi-task systems. Existing approaches predominantly rely on parameter interpolation in weight space, which we show introduces significant distribution shift in the feature space and undermines task-specific knowledge. In this paper, we propose OTMF (Optimal Transport-based Masked Fusion), a novel model merging framework rooted in optimal transport theory to address the distribution shift that arises from naive parameter interpolation. Instead of directly aggregating features or weights, OTMF aligns the semantic geometry of task-specific models by discovering common masks applied to task vectors through optimal transport plans. These masks selectively extract transferable and task-agnostic components while preserving the unique structural identities of each task. To ensure scalability in real-world settings, OTMF further supports a continual fusion paradigm that incrementally integrates each new task vector without revisiting previous ones, maintaining a bounded memory footprint and enabling efficient fusion across a growing number of tasks. We conduct comprehensive experiments on multiple vision and language benchmarks, and results show that OTMF achieves state-of-the-art performance in terms of both accuracy and efficiency. These findings highlight the practical and theoretical value of our approach to model merging.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u63a9\u7801\u878d\u5408\uff08OTMF\uff09\u7684\u6a21\u578b\u5408\u5e76\u6846\u67b6\uff0c\u901a\u8fc7\u53d1\u73b0\u4efb\u52a1\u5411\u91cf\u4e4b\u95f4\u7684\u516c\u5171\u63a9\u7801\u6765\u5bf9\u9f50\u8bed\u4e49\u51e0\u4f55\uff0c\u907f\u514d\u76f4\u63a5\u5728\u6743\u91cd\u7a7a\u95f4\u63d2\u503c\u5bfc\u81f4\u7684\u5206\u5e03\u504f\u79fb\uff0c\u5b9e\u73b0\u5bf9\u591a\u4efb\u52a1\u7684\u53ef\u6269\u5c55\u3001\u6301\u7eed\u878d\u5408\uff0c\u5177\u6709\u4f18\u8d8a\u7684\u51c6\u786e\u6027\u4e0e\u6548\u7387\u3002", "motivation": "\u76f4\u63a5\u5728\u6743\u91cd\u7a7a\u95f4\u8fdb\u884c\u53c2\u6570\u63d2\u503c\u4f1a\u5f15\u5165\u663e\u8457\u7684\u7279\u5f81\u7a7a\u95f4\u5206\u5e03\u504f\u79fb\uff0c\u524a\u5f31\u4efb\u52a1\u7279\u5f02\u6027\u77e5\u8bc6\uff1b\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5bf9\u9f50\u4efb\u52a1\u6a21\u578b\u7684\u8bed\u4e49\u51e0\u4f55\u7ed3\u6784\u3001\u4fdd\u7559\u5404\u4efb\u52a1\u7ed3\u6784\u8eab\u4efd\u4e14\u5b9e\u73b0\u53ef\u6269\u5c55\u878d\u5408\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faOTMF\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u4f18\u4f20\u8f93\u5bfb\u627e\u4efb\u52a1\u5411\u91cf\u7684\u516c\u5171\u63a9\u7801\uff0c\u9009\u62e9\u6027\u5730\u63d0\u53d6\u53ef\u8fc1\u79fb\u4e14\u4e0e\u4efb\u52a1\u65e0\u5173\u7684\u7ec4\u4ef6\uff0c\u540c\u65f6\u4fdd\u62a4\u6bcf\u4e2a\u4efb\u52a1\u7684\u72ec\u7279\u7ed3\u6784\u8eab\u4efd\u3002\u7136\u540e\u5728\u6301\u7eed\u878d\u5408\u8303\u5f0f\u4e0b\uff0c\u80fd\u591f\u589e\u91cf\u5730\u96c6\u6210\u65b0\u4efb\u52a1\u5411\u91cf\u800c\u4e0d\u56de\u8bbf\u5148\u524d\u4efb\u52a1\uff0c\u786e\u4fdd\u5185\u5b58\u5360\u7528\u6709\u754c\u5e76\u5b9e\u73b0\u5bf9\u8d8a\u6765\u8d8a\u591a\u4efb\u52a1\u7684\u9ad8\u6548\u878d\u5408\u3002", "result": "\u5728\u591a\u79cd\u89c6\u89c9\u4e0e\u8bed\u8a00\u57fa\u51c6\u4e0a\u8fdb\u884c\u4e86\u7cfb\u7edf\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793aOTMF\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u8fbe\u5230\u6216\u63a5\u8fd1\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u8bc1\u660e\u5176\u5728\u6a21\u578b\u878d\u5408\u4e2d\u7684\u5b9e\u7528\u6027\u4e0e\u7406\u8bba\u4ef7\u503c\u3002", "conclusion": "OTMF\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ee5\u6700\u4f18\u4f20\u8f93\u4e3a\u7406\u8bba\u652f\u6491\u7684\u3001\u53ef\u6269\u5c55\u7684\u591a\u4efb\u52a1\u6a21\u578b\u878d\u5408\u6846\u67b6\u3002\u901a\u8fc7\u5728\u4efb\u52a1\u5411\u91cf\u4e4b\u95f4\u5b66\u4e60\u516c\u5171\u63a9\u7801\u6765\u5bf9\u9f50\u8bed\u4e49\u51e0\u4f55\uff0c\u514b\u670d\u4e86\u76f4\u63a5\u6743\u91cd\u63d2\u503c\u5e26\u6765\u7684\u5206\u5e03\u504f\u79fb\uff0c\u5e76\u5b9e\u73b0\u9ad8\u6548\u7684\u6301\u7eed\u878d\u5408\u4e0e\u8bb0\u5fc6\u9ad8\u6548\u6027\uff0c\u540c\u65f6\u5728\u591a\u9886\u57df\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2511.19569", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19569", "abs": "https://arxiv.org/abs/2511.19569", "authors": ["Wentao Ye", "Jiaqi Hu", "Haobo Wang", "Xinpeng Ti", "Zhiqing Xiao", "Hao Chen", "Liyao Li", "Lei Feng", "Sai Wu", "Junbo Zhao"], "title": "An Invariant Latent Space Perspective on Language Model Inversion", "comment": "The Fortieth AAAI Conference on Artificial Intelligence (AAAI-26)", "summary": "Language model inversion (LMI), i.e., recovering hidden prompts from outputs, emerges as a concrete threat to user privacy and system security. We recast LMI as reusing the LLM's own latent space and propose the Invariant Latent Space Hypothesis (ILSH): (1) diverse outputs from the same source prompt should preserve consistent semantics (source invariance), and (2) input<->output cyclic mappings should be self-consistent within a shared latent space (cyclic invariance). Accordingly, we present Inv^2A, which treats the LLM as an invariant decoder and learns only a lightweight inverse encoder that maps outputs to a denoised pseudo-representation. When multiple outputs are available, they are sparsely concatenated at the representation layer to increase information density. Training proceeds in two stages: contrastive alignment (source invariance) and supervised reinforcement (cyclic invariance). An optional training-free neighborhood search can refine local performance. Across 9 datasets covering user and system prompt scenarios, Inv^2A outperforms baselines by an average of 4.77% BLEU score while reducing dependence on large inverse corpora. Our analysis further shows that prevalent defenses provide limited protection, underscoring the need for stronger strategies. The source code and data involved in this paper can be found in https://github.com/yyy01/Invariant_Attacker.", "AI": {"tldr": " Inv^2A \u5c06 LLM \u89c6\u4e3a\u4e0d\u53d8\u89e3\u7801\u5668\uff0c\u8bad\u7ec3\u8f7b\u91cf\u9006\u7f16\u7801\u5668\u5c06\u8f93\u51fa\u6620\u5c04\u5230\u53bb\u566a\u4f2a\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u591a\u8f93\u51fa\u62fc\u63a5\u63d0\u9ad8\u4fe1\u606f\u5bc6\u5ea6\uff0c\u5229\u7528\u5bf9\u6bd4\u5bf9\u9f50\u4e0e\u6709\u76d1\u7763\u5f3a\u5316\u5b9e\u73b0\u6e90\u4e0d\u53d8\u6027\u4e0e\u5faa\u73af\u4e0d\u53d8\u6027\uff0c\u57289\u6570\u636e\u96c6\u4e0aBLEU\u5e73\u5747\u63d0\u53474.77%\uff0c\u4e14\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u9006\u5411\u8bed\u6599\u7684\u4f9d\u8d56\uff1b\u4ee3\u7801\u53ef\u7528\u3002", "motivation": " Language model inversion\uff08LMI\uff09\u5bf9\u7528\u6237\u9690\u79c1\u4e0e\u7cfb\u7edf\u5b89\u5168\u6784\u6210\u73b0\u5b9e\u5a01\u80c1\uff0c\u4f46\u73b0\u6709\u9632\u5fa1\u5f80\u5f80\u4fdd\u62a4\u4e0d\u8db3\uff0c\u8feb\u5207\u9700\u8981\u4ece\u6f5c\u5728\u7a7a\u95f4\u7684\u4e00\u81f4\u6027\u89d2\u5ea6\u63d0\u51fa\u65b0\u578b\u653b\u51fb\u6846\u67b6\u3002", "method": " \u63d0\u51fa\u4e0d\u53d8\u6f5c\u5728\u7a7a\u95f4\u5047\u8bbe\uff08ILSH\uff09\uff1a\u6e90\u4e0d\u53d8\u6027\uff08\u540c\u6e90\u63d0\u793a\u7684\u591a\u6837\u8f93\u51fa\u5e94\u4fdd\u7559\u4e00\u81f4\u8bed\u4e49\uff09\u4e0e\u5faa\u73af\u4e0d\u53d8\u6027\uff08\u8f93\u5165<->\u8f93\u51fa\u7684\u5faa\u73af\u6620\u5c04\u5728\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\u5185\u81ea\u6d3d\uff09\u3002Inv^2A \u5c06 LLM \u89c6\u4e3a\u4e0d\u53d8\u89e3\u7801\u5668\uff0c\u4ec5\u5b66\u4e60\u8f7b\u91cf\u7684\u9006\u7f16\u7801\u5668\uff0c\u5c06\u8f93\u51fa\u6620\u5c04\u5230\u53bb\u566a\u7684\u4f2a\u8868\u793a\uff1b\u5728\u8868\u793a\u5c42\u5bf9\u591a\u4e2a\u8f93\u51fa\u8fdb\u884c\u7a00\u758f\u62fc\u63a5\u4ee5\u63d0\u9ad8\u4fe1\u606f\u5bc6\u5ea6\u3002\u8bad\u7ec3\u5206\u4e24\u9636\u6bb5\uff1a\u5bf9\u6bd4\u5bf9\u9f50\uff08\u6e90\u4e0d\u53d8\u6027\uff09\u4e0e\u6709\u76d1\u7763\u5f3a\u5316\uff08\u5faa\u73af\u4e0d\u53d8\u6027\uff09\uff0c\u8fd8\u53ef\u9009\u8bad\u7ec3-free \u7684\u90bb\u57df\u641c\u7d22\u7528\u4e8e\u5c40\u90e8\u7cbe\u7ec6\u5316\u3002", "result": " \u57289\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cInv^2A \u76f8\u6bd4\u57fa\u7ebf\u5e73\u5747\u63d0\u5347BLEU\u7ea64.77%\uff0c\u5e76\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u9006\u5411\u8bed\u6599\u7684\u4f9d\u8d56\u3002\u5206\u6790\u8fd8\u8868\u660e\u4e3b\u6d41\u9632\u5fa1\u7b56\u7565\u5bf9\u8be5\u653b\u51fb\u4fdd\u62a4\u6709\u9650\u3002", "conclusion": " \u63d0\u51fa\u4e00\u9879\u9ad8\u6548\u7684\u9006\u5411\u653b\u51fb\u6846\u67b6\u5e76\u8bc1\u5b9e\u6f5c\u5728\u7a7a\u95f4\u4e00\u81f4\u6027\u7684\u91cd\u8981\u6027\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u5f3a\u7684\u9632\u62a4\u7b56\u7565\uff1b\u4ee3\u7801\u4e0e\u6570\u636e\u5df2\u5728\u516c\u5f00\u4ed3\u5e93\u63d0\u4f9b\u3002"}}
{"id": "2511.19573", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19573", "abs": "https://arxiv.org/abs/2511.19573", "authors": ["Jialiang Li", "Weitong Chen", "Mingyu Guo"], "title": "Neural Tractability via Structure: Learning-Augmented Algorithms for Graph Combinatorial Optimization", "comment": null, "summary": "Neural models have shown promise in solving NP-hard graph combinatorial optimization (CO) problems. Once trained, they offer fast inference and reasonably high-quality solutions for in-distribution testing instances, but they generally fall short in terms of absolute solution quality compared to classical search-based algorithms that are admittedly slower but offer optimality guarantee once search finishes.\n  We propose a novel framework that combines the inference efficiency and exploratory power of neural models with the solution quality guarantee of search-based algorithms. In particular, we use parameterized algorithms (PAs) as the search component. PAs are dedicated to identifying easy instances of generally NP-hard problems, and allow for practically efficient search by exploiting structural simplicity (of the identified easy instances). Under our framework, we use parameterized analysis to identify the structurally hard parts of a CO instance. The neural model handles the hard parts by generating advisory signals based on its data-driven understanding. The PA-based search component then integrates the advisory signals to systematically and efficiently searches through the remaining structurally easy parts. Notably, our framework is agnostic to the choice of neural model and produces strictly better solutions than neural solvers alone.\n  We examine our framework on multiple CO tasks. Empirical results show that it achieves superior solution quality, competitive with that of commercial solvers. Furthermore, by using the neural model only for exploratory advisory signals, our framework exhibits improved out-of-distribution generalization, addressing a key limitation of existing neural CO solvers.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5c06\u795e\u7ecf\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u4e0e\u641c\u7d22\u7b97\u6cd5\u7684\u89e3\u8d28\u91cf\u4fdd\u8bc1\u7ed3\u5408\u8d77\u6765\u7684\u6846\u67b6\u3002\u901a\u8fc7\u53c2\u6570\u5316\u7b97\u6cd5\uff08PA\uff09\u4f5c\u4e3a\u641c\u7d22\u7ec4\u4ef6\uff0c\u5229\u7528\u53c2\u6570\u5316\u5206\u6790\u8bc6\u522b\u7ed3\u6784\u4e0a\u56f0\u96be\u7684\u90e8\u5206\uff0c\u7531\u795e\u7ecf\u6a21\u578b\u63d0\u4f9b advisory \u4fe1\u53f7\uff0c\u518d\u7531 PA \u641c\u7d22\u9ad8\u6548\u5730\u5728\u6613\u4e8e\u5904\u7406\u7684\u90e8\u5206\u8fdb\u884c\u7cfb\u7edf\u641c\u7d22\uff0c\u4ece\u800c\u83b7\u5f97\u6bd4\u4ec5\u4f7f\u7528\u795e\u7ecf solver \u66f4\u597d\u7684\u89e3\u8d28\u91cf\uff0c\u4e14\u5bf9\u5206\u5e03\u5916\u6570\u636e\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u6027\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u6c42\u89e3\u5668\u5728\u63a8\u7406\u901f\u5ea6\u548c\u5bf9\u5206\u5e03\u5185\u89e3\u7684\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u7edd\u5bf9\u6700\u4f18\u6027\u65b9\u9762\u5f80\u5f80\u843d\u540e\u4e8e\u4f20\u7edf\u57fa\u4e8e\u641c\u7d22\u7684\u7b97\u6cd5\u3002\u9700\u8981\u4e00\u4e2a\u6846\u67b6\u5728\u4fdd\u6301\u63a8\u7406\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u89e3\u7684\u8d28\u91cf\uff0c\u5e76\u63d0\u5347\u5bf9\u5206\u5e03\u5916\u6570\u636e\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4ee5\u53c2\u6570\u5316\u7b97\u6cd5\uff08PA\uff09\u4e3a\u6838\u5fc3\u7684\u641c\u7d22\u7ec4\u4ef6\u3002\u901a\u8fc7\u53c2\u6570\u5316\u5206\u6790\u8bc6\u522b\u95ee\u9898\u5b9e\u4f8b\u4e2d\u7684\u7ed3\u6784\u6027\u56f0\u96be\u90e8\u5206\uff0c\u5c06\u795e\u7ecf\u6a21\u578b\u751f\u6210\u7684 advisory \u4fe1\u53f7\u878d\u5165\u5230 PA \u7684\u641c\u7d22\u7b56\u7565\u4e2d\uff0c\u4f7f\u5176\u80fd\u591f\u7cfb\u7edf\u5730\u3001\u6709\u6548\u5730\u641c\u7d22\u5269\u4f59\u7684\u7ed3\u6784\u6027\u6613\u89e3\u90e8\u5206\u3002\u8be5\u6846\u67b6\u5bf9\u795e\u7ecf\u6a21\u578b\u7684\u5177\u4f53\u9009\u62e9\u662f\u4e0d\u53ef\u77e5\u7684\uff0c\u5177\u5907\u6a21\u578b\u65e0\u5173\u6027\u3002", "result": "\u5728\u591a\u79cd\u7ec4\u5408\u4f18\u5316\u4efb\u52a1\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u6846\u67b6\u5f97\u5230\u7684\u89e3\u8d28\u91cf\u4f18\u4e8e\u4ec5\u4f7f\u7528\u795e\u7ecf\u6c42\u89e3\u5668\u7684\u65b9\u6cd5\uff0c\u4e0e\u5546\u7528\u6c42\u89e3\u5668\u7684\u89e3\u8d28\u91cf\u76f8\u5f53\uff1b\u5e76\u4e14\u7531\u4e8e\u5c06\u795e\u7ecf\u6a21\u578b\u4ec5\u7528\u4e8e\u63a2\u7d22\u6027 advisory \u4fe1\u53f7\uff0c\u6846\u67b6\u5bf9\u5206\u5e03\u5916\u6570\u636e\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5c06\u63a8\u7406\u9ad8\u6548\u7684\u795e\u7ecf\u6a21\u578b\u4e0e\u5e26\u6709\u89e3\u8d28\u91cf\u4fdd\u8bc1\u7684\u641c\u7d22\u7b97\u6cd5\u7ed3\u5408\u8d77\u6765\uff0c\u53ef\u4ee5\u83b7\u5f97\u6bd4\u5355\u72ec\u795e\u7ecf\u6c42\u89e3\u5668\u66f4\u9ad8\u7684\u89e3\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u5f3a\u7684\u63a8\u7406\u6548\u7387\u4e0e\u5bf9\u65b0\u5206\u5e03\u7684\u9c81\u68d2\u6027\uff0c\u4e14\u6846\u67b6\u5bf9\u795e\u7ecf\u6a21\u578b\u7684\u9009\u62e9\u5177\u5907\u4e00\u5b9a\u7684\u81ea\u7531\u5ea6\u3002"}}
{"id": "2511.19636", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19636", "abs": "https://arxiv.org/abs/2511.19636", "authors": ["Shihan Feng", "Cheng Zhang", "Michael Xi", "Ethan Hsu", "Lesia Semenova", "Chudi Zhong"], "title": "Many Ways to be Right: Rashomon Sets for Concept-Based Neural Networks", "comment": null, "summary": "Modern neural networks rarely have a single way to be right. For many tasks, multiple models can achieve identical performance while relying on different features or reasoning patterns, a property known as the Rashomon Effect. However, uncovering this diversity in deep architectures is challenging as their continuous parameter spaces contain countless near-optimal solutions that are numerically distinct but often behaviorally similar. We introduce Rashomon Concept Bottleneck Models, a framework that learns multiple neural networks which are all accurate yet reason through distinct human-understandable concepts. By combining lightweight adapter modules with a diversity-regularized training objective, our method constructs a diverse set of deep concept-based models efficiently without retraining from scratch. The resulting networks provide fundamentally different reasoning processes for the same predictions, revealing how concept reliance and decision making vary across equally performing solutions. Our framework enables systematic exploration of data-driven reasoning diversity in deep models, offering a new mechanism for auditing, comparison, and alignment across equally accurate solutions.", "AI": {"tldr": "\u63d0\u51fa\u9c81\u68d2\u7684 Rashomon Concept Bottleneck \u6a21\u578b\uff0c\u8bad\u7ec3\u591a\u79cd\u51c6\u786e\u4f46\u5728\u6982\u5ff5\u4e0a\u4e0d\u540c\u7684\u6a21\u578b\uff0c\u5229\u7528\u8f7b\u91cf\u9002\u914d\u5668\u548c\u591a\u6837\u6027\u6b63\u5219\u5b9e\u73b0\u4e0d\u4ece\u5934\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u83b7\u5f97\u591a\u6837\u63a8\u7406\u7684\u96c6\u5408\u3002", "motivation": "\u5728\u6df1\u5ea6\u6a21\u578b\u4e2d\u666e\u904d\u5b58\u5728\u7684 Rashomon \u6548\u5e94\u5bfc\u81f4\u591a\u79cd\u8fd1\u4f3c\u6700\u4f18\u89e3\u5728\u6027\u80fd\u4e0a\u76f8\u8fd1\u4e14\u884c\u4e3a\u5dee\u5f02\u9690\u533f\u3002\u9700\u8981\u4e00\u79cd\u6846\u67b6\u6765\u63ed\u793a\u3001\u6bd4\u8f83\u5e76\u5bf9\u9f50\u4e0d\u540c\u89e3\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u4ee5\u4fbf\u5ba1\u8ba1\u548c\u7406\u89e3\u6a21\u578b\u7684\u51b3\u7b56\u4f9d\u636e\u3002", "method": "\u5728\u4e0d\u4ece\u96f6\u5f00\u59cb\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u6a21\u5757\u4e0e\u591a\u6837\u6027\u6b63\u5219\u5316\u8bad\u7ec3\u76ee\u6807\uff0c\u5b66\u4e60\u4e00\u7ec4\u51c6\u786e\u4f46\u4f7f\u7528\u4e0d\u540c\u4eba\u7c7b\u53ef\u7406\u89e3\u6982\u5ff5\u7684\u6a21\u578b\u3002\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u6a21\u578b\u5f15\u5165\u4e0d\u540c\u6982\u5ff5\u4fe1\u53f7\u5e76\u5bf9\u5176\u4f9d\u8d56\u8fdb\u884c\u6b63\u5219\u5316\uff0c\u5b9e\u73b0\u5bf9\u540c\u4e00\u4efb\u52a1\u7684\u591a\u6837\u63a8\u7406\u8def\u5f84\u3002", "result": "\u5f97\u5230\u4e00\u7ec4\u5728\u540c\u4e00\u4efb\u52a1\u4e0a\u6027\u80fd\u7b49\u6548\u4f46\u63a8\u7406\u8fc7\u7a0b\u4e0d\u540c\u7684\u6982\u5ff5\u57fa\u7840\u6a21\u578b\uff0c\u80fd\u591f\u63ed\u793a\u6982\u5ff5\u4f9d\u8d56\u548c\u51b3\u7b56\u673a\u5236\u7684\u5dee\u5f02\uff0c\u4fbf\u4e8e\u5ba1\u8ba1\u3001\u6bd4\u8f83\u4e0e\u5bf9\u9f50\u3002", "conclusion": "\u63d0\u4f9b\u4e00\u4e2a\u7cfb\u7edf\u5316\u63a2\u7d22\u6df1\u5ea6\u6a21\u578b\u6570\u636e\u9a71\u52a8\u63a8\u7406\u591a\u6837\u6027\u7684\u6846\u67b6\uff0c\u4e3a equally accurate \u65b9\u6848\u95f4\u7684\u5bf9\u9f50\u4e0e\u5ba1\u8ba1\u63d0\u4f9b\u65b0\u5de5\u5177\u3002"}}
{"id": "2511.19656", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19656", "abs": "https://arxiv.org/abs/2511.19656", "authors": ["Kaiyi Ji"], "title": "Lower Complexity Bounds for Nonconvex-Strongly-Convex Bilevel Optimization with First-Order Oracles", "comment": "24 pages, 1 figure", "summary": "Although upper bound guarantees for bilevel optimization have been widely studied, progress on lower bounds has been limited due to the complexity of the bilevel structure. In this work, we focus on the smooth nonconvex-strongly-convex setting and develop new hard instances that yield nontrivial lower bounds under deterministic and stochastic first-order oracle models. In the deterministic case, we prove that any first-order zero-respecting algorithm requires at least $\u03a9(\u03ba^{3/2}\u03b5^{-2})$ oracle calls to find an $\u03b5$-accurate stationary point, improving the optimal lower bounds known for single-level nonconvex optimization and for nonconvex-strongly-convex min-max problems. In the stochastic case, we show that at least $\u03a9(\u03ba^{5/2}\u03b5^{-4})$ stochastic oracle calls are necessary, again strengthening the best known bounds in related settings. Our results expose substantial gaps between current upper and lower bounds for bilevel optimization and suggest that even simplified regimes, such as those with quadratic lower-level objectives, warrant further investigation toward understanding the optimal complexity of bilevel optimization under standard first-order oracles.", "AI": {"tldr": "\u5728\u5149\u6ed1\u7684\u975e\u51f8-\u5f3a\u51f8\u53cc\u5c42\u4f18\u5316\u8bbe\u5b9a\u4e0b\uff0c\u63d0\u51fa\u65b0\u7684\u96be\u4f8b\u5e76\u7ed9\u51fa\u4e25\u683c\u7684\u4e0b\u754c\uff1a\u786e\u5b9a\u6027\u4e00\u9636\u96f6\u4fdd\u6301\u7b97\u6cd5\u81f3\u5c11\u9700\u8981 \u03a9(\u03ba^{3/2} \u03b5^{-2}) \u6b21\u8c03\u7528\u4ee5\u627e\u5230 \u03b5-\u8fd1\u4f3c\u9a7b\u70b9\uff1b\u968f\u673a\u60c5\u5f62\u81f3\u5c11\u9700\u8981 \u03a9(\u03ba^{5/2} \u03b5^{-4}) \u6b21\u968f\u673a\u4e00\u9636\u67e5\u8be2\u3002\u7ed3\u679c\u8868\u660e\u53cc\u5c42\u4f18\u5316\u7684\u4e0a\u4e0b\u754c\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u5e76\u63d0\u793a\u5728\u7b80\u5316\u60c5\u5f62\u4e0b\uff08\u5982\u4e8c\u6b21\u4e0b\u5c42\u76ee\u6807\uff09\u4ecd\u9700\u7814\u7a76\u4ee5\u786e\u5b9a\u6807\u51c6\u4e00\u9636\u67e5\u8be2\u4e0b\u7684\u6700\u4f18\u590d\u6742\u5ea6\u3002", "motivation": "\u5f25\u8865\u53cc\u5c42\u4f18\u5316\u4e2d\u4e0b\u754c\u7814\u7a76\u7684\u4e0d\u8db3\uff0c\u91cf\u5316\u5728\u6807\u51c6\u4e00\u9636/\u968f\u673a\u4e00\u9636\u6a21\u578b\u4e0b\u7684\u57fa\u672c\u590d\u6742\u5ea6\uff0c\u5e76\u4e0e\u73b0\u6709\u5355\u5c42\u975e\u51f8\u548c\u975e\u51f8-\u5f3a\u51f8\u6781\u503c/\u6781\u5c0f\u503c\u7684\u4e0b\u754c\u6bd4\u8f83\uff0c\u63ed\u793a\u66f4\u9ad8\u7684\u7406\u8bba\u6781\u9650\u3002", "method": "\u6784\u9020\u65b0\u7684\u56f0\u96be\u5b9e\u4f8b\uff0c\u9488\u5bf9\u5149\u6ed1\u7684\u975e\u51f8-\u5f3a\u51f8\u53cc\u5c42\u76ee\u6807\uff1b\u5728\u786e\u5b9a\u6027\u548c\u968f\u673a\u4e00\u9636\u67e5\u8be2\u6a21\u578b\u4e0b\uff0c\u5efa\u7acb\u96f6\u4fdd\u6301\uff08zero-respecting\uff09\u7b97\u6cd5\u7684\u6700\u574f\u60c5\u5f62\u5e76\u63a8\u5bfc\u65f6\u95f4\u590d\u6742\u5ea6\u4e0b\u754c\uff1b\u5bf9 \u03ba\uff08\u6761\u4ef6\u6570\uff09\u548c \u03b5 \u7684\u4f9d\u8d56\u7ed9\u51fa \u03a9 \u754c\u3002", "result": "\u7ed9\u51fa\u4e0b\u754c \u03a9(\u03ba^{3/2} \u03b5^{-2})\uff08\u786e\u5b9a\u6027\uff09\u548c \u03a9(\u03ba^{5/2} \u03b5^{-4})\uff08\u968f\u673a\uff09; \u8fd9\u4e9b\u4e0b\u754c\u8d85\u8fc7\u4e86\u76ee\u524d\u5df2\u77e5\u7684\u5355\u5c42\u975e\u51f8\u548c\u975e\u51f8-\u5f3a\u51f8\u6781\u503c\u95ee\u9898\u7684\u4e0b\u754c\uff0c\u663e\u793a\u53cc\u5c42\u4f18\u5316\u7684\u7406\u8bba\u6781\u9650\u8fdc\u672a\u88ab\u6ee1\u8db3\u3002", "conclusion": "\u5f53\u524d\u4e0a\u754c\u4e0e\u4e0b\u754c\u4e4b\u95f4\u5dee\u8ddd\u663e\u8457\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u7f29\u5c0f\u5dee\u8ddd\uff1b\u5373\u4fbf\u5728\u7b80\u5316\u60c5\u5f62\uff08\u5982\u4e8c\u6b21\u4e0b\u5c42\uff09\u4e5f\u503c\u5f97\u7cfb\u7edf\u7814\u7a76\uff0c\u4ee5\u660e\u786e\u5728\u6807\u51c6\u4e00\u9636\u6a21\u578b\u4e0b\u7684\u6700\u4f18\u590d\u6742\u5ea6\u3002"}}
{"id": "2511.19657", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19657", "abs": "https://arxiv.org/abs/2511.19657", "authors": ["Sepideh Koohfar"], "title": "Structured Noise Modeling for Enhanced Time-Series Forecasting", "comment": null, "summary": "Time-series forecasting remains difficult in real-world settings because temporal patterns operate at multiple scales, from broad contextual trends to fast, fine-grained fluctuations that drive critical decisions. Existing neural models often struggle to represent these interacting dynamics, leading to unstable predictions and reduced reliability in downstream applications. This work introduces a forecast-blur-denoise framework that improves temporal fidelity through structured noise modeling. The approach incorporates a learnable Gaussian Process module that generates smooth, correlated perturbations, encouraging the forecasting backbone to capture long-range structure while a dedicated refinement model restores high-resolution temporal detail. Training the components jointly enables natural competence division and avoids the artifacts commonly produced by isotropic corruption methods. Experiments across electricity, traffic, and solar datasets show consistent gains in multi-horizon accuracy and stability. The modular design also allows the blur-denoise layer to operate as a lightweight enhancement for pretrained models, supporting efficient adaptation in limited-data scenarios. By strengthening the reliability and interpretability of fine-scale temporal predictions, this framework contributes to more trustworthy AI systems used in forecasting-driven decision support across energy, infrastructure, and other time-critical domains.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2aforecast-blur-denoise\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u9ad8\u65af\u8fc7\u7a0b\u6a21\u5757\u751f\u6210\u5e73\u6ed1\u76f8\u5173\u6270\u52a8\uff0c\u8f85\u4ee5\u7cbe\u7ec6\u5316\u6a21\u578b\u6062\u590d\u9ad8\u5206\u8fa8\u7387\u65f6\u95f4\u7ec6\u8282\uff1b\u8054\u5408\u8bad\u7ec3\u5b9e\u73b0\u5206\u5de5\u534f\u4f5c\uff0c\u4e14\u53ef\u4f5c\u4e3a\u8f7b\u91cf\u5316\u7684\u9884\u8bad\u7ec3\u589e\u5f3a\u6a21\u5757\u4f7f\u7528\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u65f6\u95f4\u5e8f\u5217\u5177\u6709\u591a\u5c3a\u5ea6\u7684\u65f6\u5e8f\u6a21\u5f0f\uff08\u5b8f\u89c2\u8d8b\u52bf\u5230\u7ec6\u7c92\u5ea6\u6ce2\u52a8\uff09\uff0c\u73b0\u6709\u795e\u7ecf\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u6355\u6349\u8fd9\u4e9b\u4ea4\u4e92\u52a8\u6001\uff0c\u5bfc\u81f4\u9884\u6d4b\u4e0d\u7a33\u5b9a\u548c\u4e0b\u6e38\u5e94\u7528\u53ef\u9760\u6027\u4e0b\u964d\u3002", "method": "\u5f15\u5165forecast-blur-denoise\u6846\u67b6\uff1a\u7528\u53ef\u5b66\u4e60\u7684\u9ad8\u65af\u8fc7\u7a0b\u6a21\u5757\u751f\u6210\u5e73\u6ed1\u7684\u76f8\u5173\u6270\u52a8\uff0c\u4fc3\u4f7f\u9884\u6d4b\u9aa8\u5e72\u6355\u6349\u957f\u671f\u7ed3\u6784\uff1b\u4e13\u95e8\u7684\u7cbe\u7ec6\u5316\u6a21\u578b\u6062\u590d\u9ad8\u5206\u8fa8\u7387\u65f6\u95f4\u7ec6\u8282\uff1b\u7aef\u5230\u7aef\u8054\u5408\u8bad\u7ec3\u5b9e\u73b0\u81ea\u7136\u7684\u80fd\u529b\u5206\u5de5\uff0c\u4e14blur-denoise\u5c42\u53ef\u4f5c\u4e3a\u8f7b\u91cf\u5316\u7684\u9884\u8bad\u7ec3\u589e\u5f3a\u5c42\u3002", "result": "\u5728\u7535\u529b\u3001\u4ea4\u901a\u548c\u592a\u9633\u80fd\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u591a\u6b65\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u63d0\u5347\uff1b\u6a21\u5757\u5316\u8bbe\u8ba1\u4fbf\u4e8e\u5bf9\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u8f7b\u91cf\u5316\u589e\u5f3a\uff0c\u9002\u7528\u4e8e\u6570\u636e\u53d7\u9650\u573a\u666f\u3002", "conclusion": "\u589e\u5f3a\u7ec6\u7c92\u5ea6\u65f6\u95f4\u9884\u6d4b\u7684\u53ef\u9760\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u80fd\u6e90\u3001\u57fa\u7840\u8bbe\u65bd\u7b49\u65f6\u95f4\u9a71\u52a8\u51b3\u7b56\u7cfb\u7edf\u4e2d\u7684\u53ef\u4fe1AI\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2511.19664", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19664", "abs": "https://arxiv.org/abs/2511.19664", "authors": ["Jiaxin Shi", "Michalis K. Titsias"], "title": "Demystifying Diffusion Objectives: Reweighted Losses are Better Variational Bounds", "comment": null, "summary": "We derive a new theoretical interpretation of the reweighted losses that are widely used for training diffusion models. Our method is based on constructing a cascade of time-dependent variational lower bounds on the data log-likelihood, that provably improves upon the standard evidence lower bound and results in reduced data-model KL-divergences. Combining such bounds gives rise to reweighted objectives that can be applied to any generative diffusion model including both continuous Gaussian diffusion and masked (discrete) diffusion models. Then, we showcase this framework in masked diffusion and report significant improvements over previous training losses in pixel-space image modeling, approaching sample quality comparable to continuous diffusion models. Our results also provide a theoretical justification for the simple weighting scheme widely used in masked image models.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u91cd\u52a0\u6743\u635f\u5931\u89c6\u4e3a\u591a\u5c42\u65f6\u95f4\u4f9d\u8d56\u7684\u53d8\u5206\u4e0b\u754c\u7ea7\u8054\u7684\u7406\u8bba\u89e3\u91ca\uff0c\u80fd\u591f\u63d0\u5347\u6570\u636e\u5bf9\u6570\u4f3c\u7136\u7684\u4e0b\u754c\u5e76\u964d\u4f4e\u6570\u636e-\u6a21\u578bKL\u6563\u5ea6\uff0c\u4ece\u800c\u5f97\u5230\u5bf9\u4efb\u4f55\u6269\u6563\u6a21\u578b\u53ef\u5e94\u7528\u7684\u91cd\u52a0\u6743\u76ee\u6807\uff0c\u5c24\u5176\u5728\u63a9\u7801\u5316\u79bb\u6563\u6269\u6563\u7684\u50cf\u7d20\u7ea7\u56fe\u50cf\u5efa\u6a21\u4e2d\u53d6\u5f97\u663e\u8457\u6539\u5584\uff0c\u63a5\u8fd1\u8fde\u7eed\u6269\u6563\u6a21\u578b\u7684\u6837\u672c\u8d28\u91cf\u3002", "motivation": "\u89e3\u91ca\u5e7f\u6cdb\u7528\u4e8e\u6269\u6563\u6a21\u578b\u7684\u91cd\u52a0\u6743\u635f\u5931\u7684\u7406\u8bba\u6765\u6e90\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u5c06\u8fde\u7eed\u9ad8\u65af\u6269\u6563\u4e0e\u63a9\u7801\u5316\u79bb\u6563\u6269\u6563\u7eb3\u5165\u540c\u4e00\u91cd\u52a0\u6743\u76ee\u6807\uff0c\u4ece\u800c\u63d0\u5347\u8bad\u7ec3\u6548\u80fd\u4e0e\u6837\u672c\u8d28\u91cf\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u65f6\u95f4\u4f9d\u8d56\u7684\u53d8\u5206\u4e0b\u754c\u7684\u7ea7\u8054\uff0c\u9010\u6b65\u5bf9\u6570\u636e\u5bf9\u6570\u4f3c\u7136\u8fdb\u884c\u4e0b\u754c\u63a8\u5bfc\uff0c\u8bc1\u660e\u8be5\u7ea7\u8054\u4e0b\u754c\u4f18\u4e8e\u6807\u51c6ELBO\u5e76\u964d\u4f4e\u6570\u636e-\u6a21\u578bKL\uff1b\u901a\u8fc7\u5c06\u8fd9\u4e9b\u4e0b\u754c\u7ec4\u5408\uff0c\u5f97\u5230\u53ef\u5e94\u7528\u4e8e\u4efb\u610f\u6269\u6563\u6a21\u578b\u7684\u91cd\u52a0\u6743\u76ee\u6807\uff1b\u5728\u63a9\u7801\u5316\u6269\u6563\u4e2d\u5177\u4f53\u5b9e\u73b0\u5e76\u6bd4\u8f83\u3002", "result": "\u5728\u63a9\u7801\u5316\u6269\u6563\u7684\u50cf\u7d20\u7ea7\u56fe\u50cf\u5efa\u6a21\u4e2d\uff0c\u4f7f\u7528\u65b0\u7684\u91cd\u52a0\u6743\u8bad\u7ec3\u635f\u5931\u663e\u8457\u4f18\u4e8e\u4ee5\u5f80\u7684\u8bad\u7ec3\u635f\u5931\uff0c\u6837\u672c\u8d28\u91cf\u63a5\u8fd1\u8fde\u7eed\u6269\u6563\u6a21\u578b\uff1b\u63d0\u4f9b\u4e86\u5bf9\u63a9\u7801\u5316\u56fe\u50cf\u6a21\u578b\u5e38\u7528\u7b80\u5355\u52a0\u6743\u7b56\u7565\u7684\u7406\u8bba\u89e3\u91ca\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u7edf\u4e00\u4e86\u8fde\u7eed\u4e0e\u79bb\u6563/\u63a9\u7801\u5316\u6269\u6563\u7684\u91cd\u52a0\u6743\u76ee\u6807\uff0c\u8fd8\u7406\u8bba\u5316\u5730\u652f\u6491\u4e86\u5e38\u89c1\u7684\u63a9\u7801\u5316\u56fe\u50cf\u6a21\u578b\u52a0\u6743\u7b56\u7565\uff0c\u5e76\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u679c\u4e0e\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2511.19694", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19694", "abs": "https://arxiv.org/abs/2511.19694", "authors": ["Chin-Chia Michael Yeh", "Uday Singh Saini", "Junpeng Wang", "Xin Dai", "Xiran Fan", "Jiarui Sun", "Yujie Fan", "Yan Zheng"], "title": "TiCT: A Synthetically Pre-Trained Foundation Model for Time Series Classification", "comment": null, "summary": "The ubiquity of time series data creates a strong demand for general-purpose foundation models, yet developing them for classification remains a significant challenge, largely due to the high cost of labeled data. Foundation models capable of in-context learning (ICL) offer a powerful solution, adapting to new tasks with minimal examples and reducing the need for extensive retraining. However, prior work on large-scale time series models has predominantly focused on forecasting, leaving a critical gap for versatile, fine-tuning-free classification. To address this, we introduce TiCT (Time-series in-Context Transformer), a transformer-based model pre-trained exclusively on synthetic data to perform in-context classification. We make two primary technical contributions: 1) a novel architecture featuring a scalable bit-based label encoding and a special output attention mechanism to handle an arbitrary number of classes; and 2) a synthetic pre-training framework that combines a Mixup-inspired process with data augmentation to foster generalization and noise invariance. Extensive evaluations on the UCR Archive show that TiCT achieves competitive performance against state-of-the-art supervised methods. Crucially, this is accomplished using only in-context examples at inference time, without updating a single model weight.", "AI": {"tldr": "TiCT\uff08Time-series in-Context Transformer\uff09\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u6a21\u578b\uff0c\u901a\u8fc7\u4ec5\u5728\u63a8\u7406\u9636\u6bb5\u4f7f\u7528\u4e0a\u4e0b\u6587\u793a\u4f8b\u5b8c\u6210\u5206\u7c7b\uff0c\u800c\u4e0d\u5bf9\u6a21\u578b\u6743\u91cd\u8fdb\u884c\u66f4\u65b0\u3002\u5b83\u5728\u5408\u6210\u6570\u636e\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7ed3\u5408Bit\u7f16\u7801\u7684\u6807\u7b7e\u8868\u793a\u548c\u8f93\u51fa\u6ce8\u610f\u529b\u673a\u5236\u6765\u5904\u7406\u4efb\u610f\u7c7b\u522b\u6570\uff0c\u5e76\u901a\u8fc7Mixup\u98ce\u683c\u7684\u6570\u636e\u589e\u5f3a\u63d0\u5347\u6cdb\u5316\u4e0e\u566a\u58f0\u9c81\u68d2\u6027\u3002\u5728UCR\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u4e0e\u6709\u76d1\u7763\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5e7f\u6cdb\u5b58\u5728\uff0c\u51fa\u73b0\u4e86\u5bf9\u901a\u7528 foundation \u6a21\u578b\u7528\u4e8e\u5206\u7c7b\u7684\u5f3a\u70c8\u9700\u6c42\u3002\u7136\u800c\uff0c\u9488\u5bf9\u5927\u89c4\u6a21\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u7684\u5de5\u4f5c\u591a\u805a\u7126\u4e8e\u9884\u6d4b\u4efb\u52a1\uff0c\u7f3a\u4e4f\u9488\u5bf9\u5206\u7c7b\u4efb\u52a1\u7684\u3001\u65e0\u9700\u5fae\u8c03\u5c31\u53ef\u4f7f\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e14\u6807\u6ce8\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51faTiCT\u67b6\u6784\uff1a1) \u91c7\u7528\u53ef\u6269\u5c55\u7684\u57fa\u4e8e\u6bd4\u7279\u7684\u6807\u7b7e\u7f16\u7801\u548c\u7279\u6b8a\u7684\u8f93\u51fa\u6ce8\u610f\u529b\u673a\u5236\uff0c\u80fd\u591f\u5904\u7406\u4efb\u610f\u6570\u91cf\u7684\u7c7b\u522b\uff1b2) \u901a\u8fc7\u5408\u6210\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7ed3\u5408\u53d7\u5230Mixup\u542f\u53d1\u7684\u8fc7\u7a0b\u4e0e\u6570\u636e\u589e\u5f3a\uff0c\u63d0\u5347\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u4e0e\u5bf9\u566a\u58f0\u7684\u9c81\u68d2\u6027\u3002\u63a8\u7406\u9636\u6bb5\u4ec5\u4f7f\u7528\u4e0a\u4e0b\u6587\u793a\u4f8b\uff0c\u4e0d\u66f4\u65b0\u6a21\u578b\u6743\u91cd\u3002", "result": "\u5728UCR\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cTiCT\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e0e\u6700\u5148\u8fdb\u7684\u6709\u76d1\u7763\u65b9\u6cd5\u76f8\u7ade\u4e89\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u65e0\u6743\u91cd\u66f4\u65b0\u7684\u63a8\u7406\u7279\u6027\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5728\u5408\u6210\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\u3001\u5e76\u901a\u8fc7\u4ee5\u4e0a\u4e0b\u6587\u4e3a\u6838\u5fc3\u7684\u5206\u7c7b\u673a\u5236\u5b9e\u73b0\u65e0\u5fae\u8c03\u63a8\u65ad\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684\u53ef\u884c\u6027\uff0c\u62d3\u5bbd\u4e86 foundation \u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9886\u57df\u7684\u5e94\u7528\u573a\u666f\uff0c\u663e\u8457\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u3002"}}
{"id": "2511.19730", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2511.19730", "abs": "https://arxiv.org/abs/2511.19730", "authors": ["Hongchen Wang", "Rafael Espinosa Casta\u00f1eda", "Jay R. Werber", "Yao Fehlis", "Edward Kim", "Jason Hattrick-Simpers"], "title": "Training-Free Active Learning Framework in Materials Science with Large Language Models", "comment": null, "summary": "Active learning (AL) accelerates scientific discovery by prioritizing the most informative experiments, but traditional machine learning (ML) models used in AL suffer from cold-start limitations and domain-specific feature engineering, restricting their generalizability. Large language models (LLMs) offer a new paradigm by leveraging their pretrained knowledge and universal token-based representations to propose experiments directly from text-based descriptions. Here, we introduce an LLM-based active learning framework (LLM-AL) that operates in an iterative few-shot setting and benchmark it against conventional ML models across four diverse materials science datasets. We explored two prompting strategies: one using concise numerical inputs suited for datasets with more compositional and structured features, and another using expanded descriptive text suited for datasets with more experimental and procedural features to provide additional context. Across all datasets, LLM-AL could reduce the number of experiments needed to reach top-performing candidates by over 70% and consistently outperformed traditional ML models. We found that LLM-AL performs broader and more exploratory searches while still reaching the optima with fewer iterations. We further examined the stability boundaries of LLM-AL given the inherent non-determinism of LLMs and found its performance to be broadly consistent across runs, within the variability range typically observed for traditional ML approaches. These results demonstrate that LLM-AL can serve as a generalizable alternative to conventional AL pipelines for more efficient and interpretable experiment selection and potential LLM-driven autonomous discovery.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e3b\u52a8\u5b66\u4e60\u6846\u67b6LLM-AL\uff0c\u901a\u8fc7\u6587\u672c\u63cf\u8ff0\u6216\u7b80\u77ed\u6570\u5b57\u8f93\u5165\u8fdb\u884c\u8fed\u4ee3\u5f0ffew-shot\u63d0\u793a\uff0c\u4e0e\u4f20\u7edfML\u5bf9\u6bd4\uff0c\u5728\u56db\u4e2a\u6750\u6599\u6570\u636e\u96c6\u4e0a\u663e\u8457\u964d\u4f4e\u5b9e\u9a8c\u6570\u91cf\uff08>70%\uff09\u5e76\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\uff0c\u4e14\u5728\u975e\u786e\u5b9a\u6027\u5f71\u54cd\u4e0b\u8868\u73b0\u7a33\u5b9a\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u4e3b\u52a8\u5b66\u4e60\u5728\u51b7\u542f\u52a8\u548c\u9886\u57df\u7279\u5b9a\u7279\u5f81\u5de5\u7a0b\u4e0a\u7684\u5c40\u9650\uff0c\u5229\u7528LLMs\u7684\u9884\u8bad\u7ec3\u77e5\u8bc6\u548c\u901a\u7528\u8868\u793a\u6765\u4ece\u6587\u672c\u63cf\u8ff0\u76f4\u63a5\u63d0\u51fa\u5b9e\u9a8c\uff0c\u63d0\u5347\u6cdb\u5316\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5728\u8fed\u4ee3\u7684few-shot\u8bbe\u7f6e\u4e0b\uff0c\u63d0\u51fa\u4e24\u79cd\u63d0\u793a\u7b56\u7565\uff1a1) \u9488\u5bf9\u7ed3\u6784\u5316/\u6210\u5206\u6027\u7279\u5f81\u7684\u6570\u636e\u4f7f\u7528\u7b80\u6d01\u6570\u503c\u8f93\u5165\uff1b2) \u9488\u5bf9\u5b9e\u9a8c/\u8fc7\u7a0b\u7279\u5f81\u7684\u6570\u636e\u4f7f\u7528\u6269\u5c55\u6587\u672c\u63cf\u8ff0\u4ee5\u63d0\u4f9b\u4e0a\u4e0b\u6587\u3002\u5c06LLM-AL\u4e0e\u4f20\u7edfML\u5728\u56db\u4e2a\u6750\u6599\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5bf9\u6bd4\uff0c\u8bc4\u4f30\u7a33\u5b9a\u6027\u4e0e\u9c81\u68d2\u6027\u3002", "result": "\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\uff0cLLM-AL\u628a\u8fbe\u5230\u9876\u5c16\u5019\u9009\u7684\u5b9e\u9a8c\u6570\u91cf\u51cf\u5c11\u8d85\u8fc770%\uff0c\u5e76\u59cb\u7ec8\u4f18\u4e8e\u4f20\u7edfML\u3002LLM-AL\u503e\u5411\u4e8e\u66f4\u5e7f\u6cdb\u3001\u63a2\u7d22\u6027\u641c\u7d22\uff0c\u540c\u65f6\u4ee5\u66f4\u5c11\u8fed\u4ee3\u8fbe\u5230\u6700\u4f18\u89e3\u3002\u975e\u786e\u5b9a\u6027\u5bfc\u81f4\u7684\u7a33\u5b9a\u6027\u65b9\u9762\uff0c\u8868\u73b0\u4e0e\u4f20\u7edfML\u6ce2\u52a8\u5728\u53ef\u63a5\u53d7\u8303\u56f4\u5185\u3002", "conclusion": "LLM-AL\u53ef\u4f5c\u4e3a\u901a\u7528\u66ff\u4ee3\u7684\u4e3b\u52a8\u5b66\u4e60\u7ba1\u7ebf\uff0c\u63d0\u5347\u5b9e\u9a8c\u9009\u62e9\u7684\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u5177\u5907\u6f5c\u5728\u7684LLM\u9a71\u52a8\u81ea\u52a8\u53d1\u73b0\u80fd\u529b\u3002"}}
{"id": "2511.19750", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19750", "abs": "https://arxiv.org/abs/2511.19750", "authors": ["Julien T. T. Vignoud", "Val\u00e9rian Rousset", "Hugo El Guedj", "Ignacio Aleman", "Walid Bennaceur", "Batuhan Faik Derinbay", "Eduard \u010eurech", "Damien Gengler", "Lucas Giordano", "Felix Grimberg", "Franziska Lippoldt", "Christina Kopidaki", "Jiafan Liu", "Lauris Lopata", "Nathan Maire", "Paul Mansat", "Martin Milenkoski", "Emmanuel Omont", "G\u00fcne\u015f \u00d6zg\u00fcn", "Mina Petrovi\u0107", "Francesco Posa", "Morgan Ridel", "Giorgio Savini", "Marcel Torne", "Lucas Trognon", "Alyssa Unell", "Olena Zavertiaieva", "Sai Praneeth Karimireddy", "Tahseen Rabbani", "Mary-Anne Hartley", "Martin Jaggi"], "title": "DISCO: A Browser-Based Privacy-Preserving Framework for Distributed Collaborative Learning", "comment": null, "summary": "Data is often impractical to share for a range of well considered reasons, such as concerns over privacy, intellectual property, and legal constraints. This not only fragments the statistical power of predictive models, but creates an accessibility bias, where accuracy becomes inequitably distributed to those who have the resources to overcome these concerns. We present DISCO: an open-source DIStributed COllaborative learning platform accessible to non-technical users, offering a means to collaboratively build machine learning models without sharing any original data or requiring any programming knowledge. DISCO's web application trains models locally directly in the browser, making our tool cross-platform out-of-the-box, including smartphones. The modular design of \\disco offers choices between federated and decentralized paradigms, various levels of privacy guarantees and several approaches to weight aggregation strategies that allow for model personalization and bias resilience in the collaborative training. Code repository is available at https://github.com/epfml/disco and a showcase web interface at https://discolab.ai", "AI": {"tldr": "\u63d0\u51fa\u5f00\u6e90\u7684\u5206\u5e03\u5f0f\u534f\u4f5c\u5b66\u4e60\u5e73\u53f0 DISCO\uff0c\u80fd\u5728\u6d4f\u89c8\u5668\u7aef\u672c\u5730\u8bad\u7ec3\u6a21\u578b\u3001\u65e0\u9700\u5206\u4eab\u539f\u59cb\u6570\u636e\u3001\u9762\u5411\u975e\u6280\u672f\u7528\u6237\uff0c\u652f\u6301\u8054\u90a6\u4e0e\u53bb\u4e2d\u5fc3\u5316\u8303\u5f0f\u53ca\u591a\u79cd\u805a\u5408\u7b56\u7565\uff0c\u63d0\u5347\u9690\u79c1\u4fdd\u62a4\u4e0e\u6a21\u578b\u53ef\u53ca\u6027\u3002", "motivation": "\u56e0\u9690\u79c1\u3001\u77e5\u8bc6\u4ea7\u6743\u4e0e\u6cd5\u5f8b\u7ea6\u675f\u7b49\u539f\u56e0\uff0c\u6570\u636e\u96be\u4ee5\u5171\u4eab\uff0c\u5bfc\u81f4\u7edf\u8ba1\u80fd\u529b\u5206\u6563\u3001\u6a21\u578b\u504f\u5dee\u4e0e\u53ef\u53ca\u6027\u4e0d\u5e73\u7b49\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u65e0\u9700\u6570\u636e\u5206\u4eab\u3001\u6613\u4e0a\u624b\u4e14\u8de8\u5e73\u53f0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6269\u5927\u53c2\u4e0e\u8303\u56f4\u4e0e\u516c\u5e73\u6027\u3002", "method": "\u901a\u8fc7\u7f51\u9875\u5e94\u7528\u5728\u672c\u5730\u6d4f\u89c8\u5668\u8bad\u7ec3\u6a21\u578b\uff0c\u8de8\u5e73\u53f0\uff08\u542b\u624b\u673a\uff09\u51fa\u5382\u5373\u7528\u3002\u6a21\u5757\u5316\u8bbe\u8ba1\u63d0\u4f9b\u8054\u90a6\u4e0e\u53bb\u4e2d\u5fc3\u5316\u8bad\u7ec3\u8303\u5f0f\u3001\u4e0d\u540c\u9690\u79c1\u4fdd\u969c\u7b49\u7ea7\uff0c\u4ee5\u53ca\u591a\u79cd\u6743\u91cd\u805a\u5408\u7b56\u7565\uff0c\u652f\u6301\u6a21\u578b\u4e2a\u6027\u5316\u4e0e\u504f\u5dee\u9c81\u68d2\u6027\u3002\u4ee3\u7801\u5728 GitHub\uff08epfml/disco\uff09\uff0c\u5c55\u793a\u7f51\u9875\u754c\u9762\u5728 discolab.ai\u3002", "result": "\u63d0\u51fa\u4e00\u4e2a\u7cfb\u7edf\u7ea7\u6846\u67b6\u4e0e\u5b9e\u73b0\u8981\u70b9\uff0c\u5f3a\u8c03\u53ef\u8bbf\u95ee\u6027\u3001\u9690\u79c1\u4fdd\u62a4\u4e0e\u53ef\u6269\u5c55\u6027\uff1b\u5c1a\u672a\u5728\u6458\u8981\u4e2d\u7ed9\u51fa\u5177\u4f53\u7684\u5b9e\u8bc1\u8bc4\u4f30\u7ed3\u679c\u7ec6\u8282\u3002", "conclusion": "DISCO \u63d0\u4f9b\u4e00\u4e2a\u65e0\u6570\u636e\u5171\u4eab\u7684\u5f00\u6e90\u534f\u4f5c\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u9762\u5411\u975e\u6280\u672f\u7528\u6237\uff0c\u8de8\u5e73\u53f0\u4e14\u5177\u5907\u9690\u79c1\u4fdd\u62a4\u4e0e\u5b9a\u5236\u5316\u80fd\u529b\u3002"}}
{"id": "2511.19794", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19794", "abs": "https://arxiv.org/abs/2511.19794", "authors": ["Wenzhang Du"], "title": "When +1% Is Not Enough: A Paired Bootstrap Protocol for Evaluating Small Improvements", "comment": "13 pages, 3 figures", "summary": "Recent machine learning papers often report 1-2 percentage point improvements from a single run on a benchmark. These gains are highly sensitive to random seeds, data ordering, and implementation details, yet are rarely accompanied by uncertainty estimates or significance tests. It is therefore unclear when a reported +1-2% reflects a real algorithmic advance versus noise.\n  We revisit this problem under realistic compute budgets, where only a few runs are affordable. We propose a simple, PC-friendly evaluation protocol based on paired multi-seed runs, bias-corrected and accelerated (BCa) bootstrap confidence intervals, and a sign-flip permutation test on per-seed deltas. The protocol is intentionally conservative and is meant as a guardrail against over-claiming.\n  We instantiate it on CIFAR-10, CIFAR-10N, and AG News using synthetic no-improvement, small-gain, and medium-gain scenarios. Single runs and unpaired t-tests often suggest significant gains for 0.6-2.0 point improvements, especially on text. With only three seeds, our paired protocol never declares significance in these settings. We argue that such conservative evaluation is a safer default for small gains under tight budgets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4fdd\u5b88\u7684\u3001\u4e0e\u8ba1\u7b97\u9884\u7b97\u53cb\u597d\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u7528\u4e8e\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u5bf9\u5c0f\u5e45\u5ea6\u6539\u8fdb\u8fdb\u884c\u7edf\u8ba1\u663e\u8457\u6027\u68c0\u9a8c\u3002\u901a\u8fc7\u6210\u5bf9\u591a\u79cd\u5b50\u8fd0\u884c\u3001BCa\u81ea\u4e3e\u7f6e\u4fe1\u533a\u95f4\u4ee5\u53ca\u5bf9\u6bcf\u4e2a\u79cd\u5b50\u5dee\u5f02\u7684\u7b26\u53f7\u7f6e\u6362\u68c0\u9a8c\uff0c\u5728\u6709\u9650\u7684\u9884\u7b97\u4e0b\u8bc4\u4f300.6-2.0\u70b9\u7684\u6539\u8fdb\u662f\u5426\u771f\u5b9e\u53ef\u4fe1\u3002", "motivation": "\u5f53\u524d\u7684ML\u7814\u7a76\u5e38\u62a5\u544a\u5728\u57fa\u51c6\u4e0a1-2\u4e2a\u767e\u5206\u70b9\u7684\u6539\u8fdb\uff0c\u4f46\u8fd9\u4e9b\u6539\u8fdb\u9ad8\u5ea6\u53d7\u968f\u673a\u79cd\u5b50\u3001\u6570\u636e\u987a\u5e8f\u548c\u5b9e\u73b0\u7ec6\u8282\u5f71\u54cd\uff0c\u4e14\u5f80\u5f80\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u663e\u8457\u6027\u68c0\u9a8c\uff0c\u96be\u4ee5\u5224\u65ad\u662f\u5426\u662f\u771f\u6b63\u7684\u7b97\u6cd5\u8fdb\u6b65\u3002", "method": "\u5728\u73b0\u5b9e\u8ba1\u7b97\u9884\u7b97\u4e0b\uff0c\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6210\u5bf9\u591a\u79cd\u5b50\uff08paired multi-seed\uff09\u8fd0\u884c\u3001\u504f\u501a\u6821\u6b63\u4e0e\u52a0\u901f\u7684BCa\u81ea\u4e3e\u7f6e\u4fe1\u533a\u95f4\uff0c\u4ee5\u53ca\u5bf9\u6bcf\u4e2a\u79cd\u5b50\u5dee\u5f02\u8fdb\u884c\u7b26\u53f7\u7ffb\u8f6c\u7684\u7f6e\u6362\u68c0\u9a8c\u7684\u8bc4\u4f30\u534f\u8bae\u3002\u534f\u8bae\u4fdd\u5b88\uff0c\u4f5c\u4e3a\u907f\u514d\u5938\u5927\u7ed3\u8bba\u7684\u62a4\u680f\u3002", "result": "\u5728CIFAR-10\u3001CIFAR-10N\u3001AG News\u4e0a\u7528\u5408\u6210\u7684\u65e0\u6539\u8fdb\u3001\u5c11\u91cf\u6536\u76ca\u548c\u4e2d\u7b49\u6536\u76ca\u573a\u666f\u8fdb\u884c\u4e86\u5b9e\u4f8b\u9a8c\u8bc1\u3002\u5355\u6b21\u8fd0\u884c\u548c\u975e\u914d\u5bf9t\u68c0\u9a8c\u57280.6-2.0\u70b9\u6539\u8fdb\u7684\u60c5\u51b5\u4e0b\u7ecf\u5e38\u88ab\u8ba4\u4e3a\u663e\u8457\uff0c\u4e14\u5728\u6587\u672c\u6570\u636e\u4e0a\u5c24\u4e3a\u660e\u663e\uff1b\u4f46\u4ec5\u67093\u4e2a\u79cd\u5b50\u65f6\uff0c\u6210\u5bf9\u534f\u8bae\u5728\u8fd9\u4e9b\u8bbe\u7f6e\u4e2d\u4ece\u672a\u5ba3\u79f0\u663e\u8457\u3002", "conclusion": "\u5bf9\u4e8e\u5728\u7d27\u5f20\u9884\u7b97\u4e0b\u8ffd\u6c42\u5c0f\u5e45\u6539\u8fdb\u7684\u7814\u7a76\uff0c\u91c7\u7528\u4fdd\u5b88\u7684\u8bc4\u4f30\u9ed8\u8ba4\u66f4\u5b89\u5168\uff0c\u80fd\u6709\u6548\u907f\u514d\u8fc7\u5ea6\u58f0\u79f0\u3002"}}
{"id": "2511.19797", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19797", "abs": "https://arxiv.org/abs/2511.19797", "authors": ["Linqi Zhou", "Mathias Parger", "Ayaan Haque", "Jiaming Song"], "title": "Terminal Velocity Matching", "comment": "Code available at: https://github.com/lumalabs/tvm", "summary": "We propose Terminal Velocity Matching (TVM), a generalization of flow matching that enables high-fidelity one- and few-step generative modeling. TVM models the transition between any two diffusion timesteps and regularizes its behavior at its terminal time rather than at the initial time. We prove that TVM provides an upper bound on the $2$-Wasserstein distance between data and model distributions when the model is Lipschitz continuous. However, since Diffusion Transformers lack this property, we introduce minimal architectural changes that achieve stable, single-stage training. To make TVM efficient in practice, we develop a fused attention kernel that supports backward passes on Jacobian-Vector Products, which scale well with transformer architectures. On ImageNet-256x256, TVM achieves 3.29 FID with a single function evaluation (NFE) and 1.99 FID with 4 NFEs. It similarly achieves 4.32 1-NFE FID and 2.94 4-NFE FID on ImageNet-512x512, representing state-of-the-art performance for one/few-step models from scratch.", "AI": {"tldr": "TVM generalizes flow matching to terminal-time transitions to enable high-fidelity one-/few-step diffusion models, with a theoretical 2-Wasserstein bound under Lipschitzness, practical fixes for non-Lipschitz transformers, and efficient fused-attention for Jacobian-vector backpropagation; achieves state-of-the-art FID on ImageNet with 1\u20134 NFEs.", "motivation": "\u89e3\u51b3\u591a\u6b65\u6269\u6563\u6a21\u578b\u5728\u63a8\u7406\u6210\u672c\u4e0e\u8bad\u7ec3\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u63d0\u5347\u5355\u6b65/\u5c11\u6b65\u751f\u6210\u7684\u4fdd\u771f\u5ea6\uff0c\u5e76\u5c06\u6d41\u5f0f\u5339\u914d\u63a8\u5e7f\u5230\u7ec8\u7aef\u65f6\u95f4\u3002", "method": "\u63d0\u51fa Terminal Velocity Matching (TVM)\uff0c\u5bf9\u4efb\u610f\u4e24\u4e2a\u6269\u6563\u65f6\u95f4\u6b65\u4e4b\u95f4\u7684\u8fc7\u6e21\u5efa\u6a21\uff0c\u5e76\u5728\u7ec8\u7aef\u65f6\u95f4\u8fdb\u884c\u6b63\u5219\u5316\uff1b\u5728\u6a21\u578b\u4e3a Lipschitz \u65f6\u7ed9\u51fa\u5bf9\u6570\u636e\u4e0e\u6a21\u578b\u5206\u5e03\u76842-Wasserstein\u8ddd\u79bb\u4e0a\u754c\uff1b\u9274\u4e8e Diffusion Transformer \u7f3a\u4e4f Lipschitz \u6027\uff0c\u7ed9\u51fa\u6700\u5c0f\u7684\u7ed3\u6784\u6539\u52a8\u4ee5\u5b9e\u73b0\u7a33\u5b9a\u7684\u5355\u9636\u6bb5\u8bad\u7ec3\uff1b\u63d0\u51fa\u878d\u5408\u6ce8\u610f\u529b\u6838\u4ee5\u5b9e\u73b0\u5bf9 Jacobian-Vector Product \u7684\u53cd\u5411\u4f20\u64ad\uff0c\u4ece\u800c\u63d0\u9ad8\u5728\u53d8\u6362\u5668\u4e0a\u7684\u8bad\u7ec3\u6548\u7387\u4e0e\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5728 ImageNet-256x256 \u4e0a\uff0c1 \u6b21\u529f\u80fd\u8bc4\u4f30\uff08NFE\uff09\u5f97\u5230 3.29 \u7684 FID\uff0c4 \u6b21 NFE \u5f97\u5230 1.99 \u7684 FID\uff1b\u5728 ImageNet-512x512 \u4e0a\uff0c1-NFE FID \u4e3a 4.32\uff0c4-NFE FID \u4e3a 2.94\uff0c\u8fbe\u5230\u5355/\u5c11\u6b65\u6a21\u578b\u4ece\u5934\u8bad\u7ec3\u7684\u6700\u65b0\u6027\u80fd\u3002", "conclusion": "TVM \u4e3a\u6d41\u5f0f\u5339\u914d\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5728\u7406\u8bba\u4e0e\u5b9e\u8bc1\u4e0a\u7684\u65b0\u8303\u5f0f\uff0c\u517c\u5177\u5bf9\u5076\u65f6\u95f4\u7684\u7ec8\u7aef\u6b63\u5219\u5316\u548c\u5b9e\u9645\u53ef\u884c\u7684\u9ad8\u6548\u8bad\u7ec3\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5355\u6b65/\u5c11\u6b65\u6269\u6563\u6a21\u578b\u5728\u5927\u5c3a\u5ea6\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2511.19803", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19803", "abs": "https://arxiv.org/abs/2511.19803", "authors": ["Sibo Ma", "Julian Nyarko"], "title": "Scalable Data Attribution via Forward-Only Test-Time Inference", "comment": "8 pages. Work in progress", "summary": "Data attribution seeks to trace model behavior back to the training examples that shaped it, enabling debugging, auditing, and data valuation at scale. Classical influence-function methods offer a principled foundation but remain impractical for modern networks because they require expensive backpropagation or Hessian inversion at inference. We propose a data attribution method that preserves the same first-order counterfactual target while eliminating per-query backward passes. Our approach simulates each training example's parameter influence through short-horizon gradient propagation during training and later reads out attributions for any query using only forward evaluations. This design shifts computation from inference to simulation, reflecting real deployment regimes where a model may serve billions of user queries but originate from a fixed, finite set of data sources (for example, a large language model trained on diverse corpora while compensating a specific publisher such as the New York Times). Empirically, on standard MLP benchmarks, our estimator matches or surpasses state-of-the-art baselines such as TRAK on standard attribution metrics (LOO and LDS) while offering orders-of-magnitude lower inference cost. By combining influence-function fidelity with first-order scalability, our method provides a theoretical framework for practical, real-time data attribution in large pretrained models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5feb\u901f\u6570\u636e\u5f52\u56e0\u65b9\u6cd5\uff0c\u5728\u4e0d\u5bf9\u6bcf\u6b21\u67e5\u8be2\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u7684\u60c5\u51b5\u4e0b\uff0c\u4fdd\u6301\u4e0e\u7b2c\u4e00\u9636\u5bf9\u6bd4\u76ee\u6807\u7684\u4e00\u81f4\u6027\u3002\u901a\u8fc7\u5728\u8bad\u7ec3\u9636\u6bb5\u8fdb\u884c\u77ed\u671f\u68af\u5ea6\u4f20\u64ad\u6765\u6a21\u62df\u6bcf\u4e2a\u8bad\u7ec3\u6837\u672c\u7684\u53c2\u6570\u5f71\u54cd\uff0c\u968f\u540e\u4ec5\u4f7f\u7528\u524d\u5411\u8bc4\u4f30\u5c31\u80fd\u5bf9\u4efb\u610f\u67e5\u8be2\u5f97\u5230\u5f52\u56e0\u3002\u5b9e\u73b0\u4e0a\u628a\u63a8\u7406\u9636\u6bb5\u7684\u8ba1\u7b97\u8f6c\u79fb\u5230\u8bad\u7ec3\u9636\u6bb5\u7684\u4eff\u771f\u4e2d\uff0c\u8d34\u5408\u5b9e\u9645\u90e8\u7f72\u573a\u666f\u3002", "motivation": "\u5728\u5927\u89c4\u6a21\u6a21\u578b\u4e2d\u5b9e\u73b0\u6570\u636e\u5f52\u56e0\u4ee5\u4fbf\u8c03\u8bd5\u3001\u5ba1\u8ba1\u548c\u6570\u636e\u4f30\u503c\uff0c\u4f46\u4f20\u7edf\u5f71\u54cd\u51fd\u6570\u65b9\u6cd5\u5728\u63a8\u7406\u65f6\u9700\u8981\u6602\u8d35\u7684\u53cd\u5411\u4f20\u64ad\u6216Hessian\u6c42\u9006\uff0c\u96be\u4ee5\u6269\u5c55\u3002\u672c\u6587\u65e8\u5728\u5728\u4fdd\u6301\u4e00\u9636\u5bf9\u6bd4\u76ee\u6807\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u53ef\u6269\u5c55\u6027\uff0c\u4f7f\u5f52\u56e0\u6210\u672c\u5728\u63a8\u7406\u7aef\u5927\u5e45\u964d\u4f4e\u3002", "method": "\u5728\u8bad\u7ec3\u9636\u6bb5\u5bf9\u6bcf\u4e2a\u8bad\u7ec3\u6837\u672c\u8fdb\u884c\u77ed\u671f\u68af\u5ea6\u4f20\u64ad\u4ee5\u4eff\u771f\u5176\u5bf9\u6a21\u578b\u53c2\u6570\u7684\u5f71\u54cd\uff1b\u8bad\u7ec3\u5b8c\u6210\u540e\uff0c\u91c7\u7528\u4ec5\u9700\u524d\u5411\u8ba1\u7b97\u7684\u65b9\u5f0f\u5bf9\u4efb\u610f\u67e5\u8be2\u8fdb\u884c\u5f52\u56e0\u8bfb\u53d6\uff0c\u4e0d\u518d\u5728\u63a8\u7406\u65f6\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u3002\u8bbe\u8ba1\u4e0a\u5c06\u5927\u91cf\u63a8\u7406\u6210\u672c\u8f6c\u79fb\u81f3\u8bad\u7ec3\u9636\u6bb5\u7684\u4eff\u771f\uff0c\u4e0e\u73b0\u5b9e\u90e8\u7f72\uff08\u5927\u89c4\u6a21\u67e5\u8be2\u3001\u6709\u9650\u6570\u636e\u6e90\uff09\u76f8\u543b\u5408\u3002", "result": "\u5728\u6807\u51c6MLP\u57fa\u51c6\u4e0a\uff0c\u8be5\u5f52\u56e0\u4f30\u8ba1\u5668\u5728LOO\u4e0eLDS\u7b49\u5f52\u56e0\u6307\u6807\u4e0a\u8fbe\u5230\u4e0e\u6216\u8d85\u8fc7\u5982TRAK\u7b49\u5148\u8fdb\u57fa\u7ebf\uff0c\u5e76\u4e14\u63a8\u7406\u6210\u672c\u6570\u91cf\u7ea7\u964d\u4f4e\u3002\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u5f71\u54cd\u51fd\u6570\u7684\u4fdd\u771f\u5ea6\u540c\u65f6\u5b9e\u73b0\u7b2c\u4e00\u9636\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u5c06\u5f71\u54cd\u51fd\u6570\u7684\u4fdd\u771f\u5ea6\u4e0e\u7b2c\u4e00\u9636\u53ef\u6269\u5c55\u6027\u7ed3\u5408\uff0c\u63d0\u51fa\u53ef\u5728\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u5b9e\u73b0\u5b9e\u65f6\u6570\u636e\u5f52\u56e0\u7684\u7406\u8bba\u6846\u67b6\u4e0e\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2511.19810", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19810", "abs": "https://arxiv.org/abs/2511.19810", "authors": ["Divyansh Chaurasia", "Manoj Daram", "Roshan Kumar", "Nihal Thukarama Rao", "Vipul Sangode", "Pranjal Srivastava", "Avnish Tripathi", "Shoubhik Chakraborty", "Akanksha", "Ambasht Kumar", "Davender Sethi", "Sachchida Nand Tripathi", "Purushottam Kar"], "title": "Provably Outlier-resistant Semi-parametric Regression for Transferable Calibration of Low-cost Air-quality Sensors", "comment": "20 pages, 14 figures, under peer review", "summary": "We present a case study for the calibration of Low-cost air-quality (LCAQ) CO sensors from one of the largest multi-site-multi-season-multi-sensor-multi-pollutant mobile air-quality monitoring network deployments in India. LCAQ sensors have been shown to play a critical role in the establishment of dense, expansive air-quality monitoring networks and combating elevated pollution levels. The calibration of LCAQ sensors against regulatory-grade monitors is an expensive, laborious and time-consuming process, especially when a large number of sensors are to be deployed in a geographically diverse layout. In this work, we present the RESPIRE technique to calibrate LCAQ sensors to detect ambient CO (Carbon Monoxide) levels. RESPIRE offers specific advantages over baseline calibration methods popular in literature, such as improved prediction in cross-site, cross-season, and cross-sensor settings. RESPIRE offers a training algorithm that is provably resistant to outliers and an explainable model with the ability to flag instances of model overfitting. Empirical results are presented based on data collected during an extensive deployment spanning four sites, two seasons and six sensor packages. RESPIRE code is available at https://github.com/purushottamkar/respire.", "AI": {"tldr": "RESPIRE\u662f\u4e00\u79cd\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684\u4f4e\u6210\u672cCO\u4f20\u611f\u5668\u6821\u51c6\u65b9\u6cd5\uff0c\u80fd\u5728\u8de8\u7ad9\u70b9\u3001\u8de8\u5b63\u8282\u548c\u8de8\u4f20\u611f\u5668\u73af\u5883\u4e2d\u63d0\u9ad8\u9884\u6d4b\uff0c\u4e0e\u6cd5\u89c4\u7ea7\u76d1\u6d4b\u5bf9\u6bd4\uff1b\u5e76\u516c\u5f00\u4ee3\u7801\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u591a\u7ad9\u70b9\u90e8\u7f72\u4e2d\u4f4e\u6210\u672c\u4f20\u611f\u5668\u6821\u51c6\u6210\u672c\u9ad8\u3001\u56f0\u96be\u7684\u95ee\u9898\uff1b\u7279\u522b\u662f\u5728\u5730\u7406\u591a\u6837\u6027\u60c5\u51b5\u4e0b\uff0c\u4f20\u7edf\u57fa\u7ebf\u6821\u51c6\u5bf9\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u63d0\u51faRESPIRE\u6821\u51c6\u6846\u67b6\uff0c\u5177\u5907\u5bf9\u5f02\u5e38\u503c\u9c81\u68d2\u7684\u8bad\u7ec3\u7b97\u6cd5\u3001\u53ef\u89e3\u91ca\u7684\u6a21\u578b\uff0c\u4ee5\u53ca\u53ef\u6807\u8bb0\u6a21\u578b\u8fc7\u62df\u5408\u7684\u80fd\u529b\u3002\u57fa\u4e8e\u56db\u4e2a\u7ad9\u70b9\u3001\u4e24\u5b63\u3001\u516d\u4f20\u611f\u5668\u5305\u7684\u6570\u636e\uff0c\u5bf9LCAQ\u4f20\u611f\u5668\u8fdb\u884cCO\u6d53\u5ea6\u7684\u73b0\u573a\u6807\u5b9a\uff0c\u540c\u65f6\u4e0e\u76d1\u7ba1\u7ea7\u76d1\u6d4b\u5668\u5bf9\u6bd4\u3002\u5f00\u6e90\u5b9e\u73b0\u4ee3\u7801\u5728GitHub\u3002", "result": "\u5728\u8de8\u7ad9\u70b9\u3001\u8de8\u5b63\u8282\u3001\u8de8\u4f20\u611f\u5668\u8bbe\u7f6e\u4e2d\u7684\u9884\u6d4b\u6027\u80fd\u6709\u6240\u63d0\u5347\uff1b\u56db\u7ad9\u70b9\u3001\u4e24\u5b63\u3001\u516d\u4f20\u611f\u5668\u5305\u7684\u5b9e\u8bc1\u6570\u636e\u8868\u660e\u65b9\u6cd5\u7684\u7a33\u5065\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff1b\u5b9e\u73b0\u53ef\u91cd\u590d\u6027\uff0c\u4ee3\u7801\u516c\u5f00.", "conclusion": "RESPIRE\u4e3aLCAQ\u4f20\u611f\u5668\u7684\u53ef\u5927\u89c4\u6a21\u90e8\u7f72\u63d0\u4f9b\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684\u6821\u51c6\u65b9\u6848\uff0c\u964d\u4f4e\u73b0\u573a\u4eba\u5de5\u6821\u51c6\u6210\u672c\uff0c\u6539\u5584\u8de8\u57df\u6cdb\u5316\uff0c\u5e76\u901a\u8fc7\u5f00\u6e90\u4ee3\u7801\u4fc3\u8fdb\u91c7\u7528\u4e0e\u590d\u73b0\u3002"}}
{"id": "2511.19837", "categories": ["cs.LG", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.19837", "abs": "https://arxiv.org/abs/2511.19837", "authors": ["Zhentao Zhan", "Xiaoliang Xu", "Jingjing Wang", "Junmei Wang"], "title": "GED-Consistent Disentanglement of Aligned and Unaligned Substructures for Graph Similarity Learning", "comment": null, "summary": "Graph Similarity Computation (GSC) is a fundamental graph related task where Graph Edit Distance (GED) serves as a prevalent metric. GED is determined by an optimal alignment between a pair of graphs that partitions each into aligned (zero-cost) and unaligned (cost-incurring) substructures. Due to NP-hard nature of exact GED computation, GED approximations based on Graph Neural Network(GNN) have emerged. Existing GNN-based GED approaches typically learn node embeddings for each graph and then aggregate pairwise node similarities to estimate the final similarity. Despite their effectiveness, we identify a mismatch between this prevalent node-centric matching paradigm and the core principles of GED. This discrepancy leads to two critical limitations: (1) a failure to capture the global structural correspondence for optimal alignment, and (2) a misattribution of edit costs driven by spurious node level signals. To address these limitations, we propose GCGSim, a GED-consistent graph similarity learning framework centering on graph-level matching and substructure-level edit costs. Specifically, we make three core technical contributions. Extensive experiments on four benchmark datasets show that GCGSim achieves state-of-the-art performance. Our comprehensive analyses further validate that the framework effectively learns disentangled and semantically meaningful substructure representations.", "AI": {"tldr": "\u63d0\u51fa GCGSim\uff0c\u4e00\u81f4\u6027\u5730\u5b66\u4e60 GED \u7684\u56fe\u76f8\u4f3c\u6027\uff0c\u901a\u8fc7\u56fe\u7ea7\u5339\u914d\u548c\u5b50\u7ed3\u6784\u7ea7\u7f16\u8f91\u6210\u672c\uff0c\u514b\u670d\u57fa\u4e8e\u8282\u70b9\u5d4c\u5165\u7684\u5c40\u9650\u6027\u3002", "motivation": "GED \u7684\u672c\u8d28\u662f\u5168\u5c40\u7ed3\u6784\u5bf9\u9f50\uff0c\u4f46\u73b0\u6709\u57fa\u4e8e GNN \u7684\u65b9\u6cd5\u4ee5\u8282\u70b9\u5d4c\u5165\u4e3a\u4e2d\u5fc3\uff0c\u96be\u4ee5\u6355\u6349\u5168\u5c40\u6700\u4f18\u5bf9\u9f50\u5e76\u6613\u5c06\u7f16\u8f91\u6210\u672c\u8bef\u5f52\u56e0\u4e8e\u5c40\u90e8\u8282\u70b9\u4fe1\u53f7\uff0c\u4ece\u800c\u5bfc\u81f4\u5339\u914d\u4e0d\u5145\u5206\u548c\u6210\u672c\u8bef\u89e3\u3002", "method": "\u63d0\u51fa GCGSim \u6846\u67b6\uff0c\u56f4\u7ed5\u56fe\u7ea7\u5339\u914d\u548c\u5b50\u7ed3\u6784\u7ea7\u7f16\u8f91\u6210\u672c\u5efa\u7acb GED \u4e00\u81f4\u7684\u56fe\u76f8\u4f3c\u6027\u5b66\u4e60\uff0c\u901a\u8fc7\u89e3\u8026\u5b50\u7ed3\u6784\u8868\u793a\u5b9e\u73b0\u66f4\u53ef\u89e3\u91ca\u7684\u5bf9\u9f50\u4e0e\u6210\u672c\u4f30\u8ba1\u3002\u5e76\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\u4ee5\u9a8c\u8bc1\u6027\u80fd\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6216\u63a5\u8fd1\u6700\u65b0\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u4e14\u5206\u6790\u8868\u660e\u6240\u5b66\u7684\u5b50\u7ed3\u6784\u8868\u793a\u5177\u5907\u89e3\u8026\u6027\u548c\u8bed\u4e49\u610f\u4e49\uff0c\u6709\u52a9\u4e8e\u63d0\u5347 GED \u4f30\u8ba1\u7684\u51c6\u786e\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "GCGSim \u901a\u8fc7 GED \u4e00\u81f4\u6027\u89c6\u89d2\u8fdb\u884c\u56fe\u76f8\u4f3c\u6027\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u8282\u70b9\u7ea7\u4fe1\u53f7\u5e72\u6270\u4e0e\u5168\u5c40\u5bf9\u9f50\u5efa\u6a21\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e14\u63d0\u4f9b\u66f4\u5177\u89e3\u91ca\u6027\u7684\u5b50\u7ed3\u6784\u8868\u5f81\u3002"}}
{"id": "2511.19841", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19841", "abs": "https://arxiv.org/abs/2511.19841", "authors": ["Liang Gou", "Archit Khare", "Praneet Pabolu", "Prachi Patel", "Joseph Ross", "Hercy Shen", "Yuhan", "Song", "Jingze Sun", "Kristal Curtis", "Vedant Dharnidharka", "Abhinav Mathur", "Hao Yang"], "title": "Cisco Time Series Model Technical Report", "comment": null, "summary": "We introduce the Cisco Time Series Model, a univariate zero-shot forecaster. This time series foundation model is the result of a general architectural innovation to a time series model enabling it to accept multiresolution input, applied to a popular decoder-only time series model (TimesFM). The resulting multiresolution decoder-only model is trained on over 300B unique data points, with more than half coming from the observability domain. Quantitative and qualitative evaluations demonstrate that the resulting model achieves superior performance on observability datasets while retaining very similar performance on a standard general-purpose forecasting benchmark (GIFT-Eval), and suggest that the multiresolution structure enables the model to make more accurate predictions on long context input.", "AI": {"tldr": "\u63d0\u51fa\u4e86 Cisco Time Series Model\uff0c\u4e00\u79cd\u5355\u53d8\u91cf\u7684\u96f6-shot \u9884\u6d4b\u6a21\u578b\uff0c\u57fa\u4e8e TimesFM \u7684\u591a\u5206\u8fa8\u7387\u89e3\u7801\u5668\u7ed3\u6784\uff0c\u4f5c\u4e3a\u65f6\u95f4\u5e8f\u5217 foundation \u6a21\u578b\u3002\u5df2\u5728\u8d85\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u4f18\u4e8e\u53ef\u89c2\u6d4b\u6027\u6570\u636e\u96c6\u4e0a\u7684\u57fa\u7ebf\uff0c\u5728\u901a\u7528\u9884\u6d4b\u57fa\u51c6\u4e0a\u8868\u73b0\u76f8\u8fd1\uff0c\u5e76\u4e14\u5728\u957f\u4e0a\u4e0b\u6587\u8f93\u5165\u4e0b\u9884\u6d4b\u66f4\u51c6\u786e\u3002", "motivation": "\u89e3\u51b3\u5355\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u7684\u96f6-shot\u9884\u6d4b\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u591a\u5206\u8fa8\u7387\u8f93\u5165\u7684\u7ed3\u6784\u6765\u63d0\u5347\u5728\u53ef\u89c2\u6d4b\u6027\u57df\u4e2d\u7684\u9884\u6d4b\u80fd\u529b\u548c\u5bf9\u957f\u4e0a\u4e0b\u6587\u7684\u5229\u7528\u3002\u5e0c\u671b\u5c06\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u63d0\u5347\u4e3a foundation \u6a21\u578b\uff0c\u901a\u8fc7\u8de8\u57df\u6570\u636e\u548c\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u83b7\u5f97\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5728\u73b0\u6709\u7684 TimesFM \u57fa\u7840\u4e0a\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e00\u4e2a\u652f\u6301\u591a\u5206\u8fa8\u7387\u8f93\u5165\u7684\u89e3\u7801\u5668-\u53ea\u6709\u6a21\u578b\uff0c\u5c06\u5176\u6574\u5408\u4e3a\u4e00\u4e2a\u591a\u5206\u8fa8\u7387\u7684\u65f6\u95f4\u5e8f\u5217 foundation \u6a21\u578b\u3002\u5bf9\u6a21\u578b\u8fdb\u884c\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\uff0c\u6570\u636e\u70b9\u6570\u91cf\u8d85\u8fc7 3e11\uff0c\u5176\u4e2d\u6765\u81ea\u53ef\u89c2\u6d4b\u6027\u57df\u7684\u6570\u636e\u5360\u6bd4\u8d85\u8fc7\u4e00\u534a\u3002\u901a\u8fc7\u5728\u53ef\u89c2\u6d4b\u6027\u6570\u636e\u96c6\u548c\u901a\u7528\u57fa\u51c6 GIFT-Eval \u4e0a\u8fdb\u884c\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "result": "\u5728\u53ef\u89c2\u6d4b\u6027\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5728\u901a\u7528\u9884\u6d4b\u57fa\u51c6\u4e0a\u4fdd\u6301\u4e0e\u5f3a\u57fa\u7ebf\u76f8\u8fd1\u7684\u6027\u80fd\uff1b\u591a\u5206\u8fa8\u7387\u7ed3\u6784\u663e\u8457\u63d0\u5347\u5bf9\u957f\u4e0a\u4e0b\u6587\u8f93\u5165\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u591a\u5206\u8fa8\u7387\u89e3\u7801\u5668\u7ed3\u6784\u6709\u52a9\u4e8e\u63d0\u5347\u5355\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u96f6-shot\u9884\u6d4b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u5728\u53ef\u89c2\u6d4b\u6027\u57df\u548c\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e2d\u8868\u73b0\u66f4\u4f73\uff0c\u663e\u793a\u51fa\u6210\u4e3a\u65f6\u95f4\u5e8f\u5217\u9886\u57df foundation \u6a21\u578b\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.19893", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19893", "abs": "https://arxiv.org/abs/2511.19893", "authors": ["Shuoyan Xu", "Yu Zhang", "Eric J. Miller"], "title": "Frailty-Aware Transformer for Recurrent Survival Modeling of Driver Retention in Ride-Hailing Platforms", "comment": "13 pages, 6 figures, under review, Accepted by KDD Workshop 2025", "summary": "Ride-hailing platforms are characterized by high-frequency, behavior-driven environments. Although survival analysis has been applied to recurrent events in other domains, its use in modeling ride-hailing driver behavior remains largely unexplored. This study formulates idle behavior as a recurrent survival process using large-scale platform data and proposes a Transformer-based framework that captures long-term temporal dependencies with causal masking and incorporates driver-specific embeddings to model latent heterogeneity. Results on Toronto ride-hailing data demonstrate that the proposed Frailty-Aware Cox Transformer (FACT) achieves the highest time-dependent C-indices and lowest Brier Scores, outperforming classical and deep learning survival models. This approach enables more accurate risk estimation, supports platform retention strategies, and provides policy-relevant insights.", "AI": {"tldr": "\u63d0\u51fa FACT\uff0c\u4e00\u79cd\u5c06\u7a7a\u95f2\u884c\u4e3a\u5efa\u6a21\u4e3a\u91cd\u590d\u751f\u5b58\u8fc7\u7a0b\u7684 Frailty-Aware Cox Transformer\uff0c\u7ed3\u5408\u56e0\u679c\u63a9\u853d\u7684 Transformer \u4e0e\u9a7e\u9a76\u5458\u5d4c\u5165\uff0c\u80fd\u6355\u6349\u957f\u671f\u4f9d\u8d56\u4e0e\u4e2a\u4f53\u5f02\u8d28\u6027\uff0c\u5728\u591a\u4f26\u591a\u6570\u636e\u4e0a\u5b9e\u73b0\u6700\u4f18\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u8bc4\u4f30\u3002", "motivation": "\u5728 ride-hailing \u5e73\u53f0\u4e2d\uff0c\u9a7e\u9a76\u5458\u7a7a\u95f2\u884c\u4e3a\u53ef\u89c6\u4e3a\u9ad8\u9891\u7684\u91cd\u590d\u4e8b\u4ef6\uff0c\u4f46\u73b0\u6709\u751f\u5b58\u5206\u6790\u591a\u7528\u4e8e\u5355\u6b21\u4e8b\u4ef6\uff0c\u4e14\u96be\u4ee5\u6355\u6349\u957f\u671f\u4f9d\u8d56\u548c\u53f8\u673a\u5f02\u8d28\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u5904\u7406\u91cd\u590d\u4e8b\u4ef6\u3001\u957f\u65f6\u4f9d\u8d56\u4e0e\u5f02\u8d28\u6027\u7684\u6a21\u578b\u3002", "method": "\u5c06 idle \u884c\u4e3a\u5efa\u6a21\u4e3a\u91cd\u590d\u751f\u5b58\u8fc7\u7a0b\uff0c\u63d0\u51fa Frailty-Aware Cox Transformer (FACT)\uff1a\u4f7f\u7528 Transformer \u6355\u6349\u957f\u671f\u65f6\u5e8f\u4f9d\u8d56\u5e76\u91c7\u7528\u56e0\u679c\u63a9\u853d\u6765\u4fdd\u8bc1\u56e0\u679c\u6027\uff1b\u52a0\u5165\u9a7e\u9a76\u5458\u7279\u5b9a\u5d4c\u5165\u4ee5\u5efa\u6a21\u6f5c\u5728\u5f02\u8d28\u6027\uff1b\u5e76\u4ee5\u751f\u5b58\u5206\u6790\u6846\u67b6\u878d\u5408\u8282\u5f8b\u6027\u4e0e\u7fa4\u4f53\u534f\u53d8\u91cf\uff0c\u9488\u5bf9\u91cd\u590d\u4e8b\u4ef6\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5728\u591a\u4f26\u591a\u6570\u636e\u96c6\u4e0a\uff0cFACT \u8fbe\u5230\u6700\u9ad8\u7684\u65f6\u95f4\u4f9d\u8d56\u6027 C \u6307\u6570\u5e76\u5177\u6709\u6700\u4f4e\u7684 Brier Score\uff0c\u663e\u8457\u4f18\u4e8e\u7ecf\u5178\u548c\u6df1\u5ea6\u5b66\u4e60\u751f\u5b58\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u5b9e\u73b0\u66f4\u7cbe\u51c6\u7684\u98ce\u9669\u4f30\u8ba1\uff0c\u652f\u6301\u5e73\u53f0\u7684\u7559\u5b58\u7b56\u7565\u4e0e\u653f\u7b56\u5c42\u9762\u7684\u6d1e\u89c1\u3002"}}
{"id": "2511.19935", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19935", "abs": "https://arxiv.org/abs/2511.19935", "authors": ["Songlin Zhao", "Michael Pitts", "Zhuwei Qin"], "title": "EfficientXpert: Efficient Domain Adaptation for Large Language Models via Propagation-Aware Pruning", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has increased the demand for domain-specialized variants in areas such as law, healthcare, and finance. However, their large size remains a barrier to deployment in resource-constrained environments, and existing compression methods either generalize poorly across domains or incur high overhead. In this work, we propose \\textbf{EfficientXpert}, a lightweight domain-pruning framework that combines a propagation-aware pruning criterion (Foresight Mask) with an efficient adapter-update algorithm (Partial Brain Surgeon). Integrated into the LoRA fine-tuning process, EfficientXpert enables a one-step transformation of general pretrained models into sparse, domain-adapted experts. Across health and legal tasks, it retains up to 98% of dense-model performance at 40% sparsity, outperforming state-of-the-art methods. Further analysis reveals substantial domain-dependent structural shifts that degrade the effectiveness of general pruning masks, underscoring the need for adaptive, domain-aware pruning strategies tailored to each domain.", "AI": {"tldr": "\u63d0\u51fa EfficientXpert\uff0c\u7ed3\u5408\u524d\u5411\u526a\u679d\u63a9\u7801\uff08Foresight Mask\uff09\u548c\u9ad8\u6548\u7684\u9002\u914d\u5668\u66f4\u65b0\u7b97\u6cd5\uff08Partial Brain Surgeon\uff09\uff0c\u5728 LoRA \u5fae\u8c03\u4e2d\u5b9e\u73b0\u4ece\u901a\u7528\u6a21\u578b\u5230\u7a00\u758f\u3001\u57df\u9002\u5e94\u4e13\u5bb6\u7684\u4e00\u6b65\u8f6c\u6362\uff1b\u5728\u5065\u5eb7\u4e0e\u6cd5\u5f8b\u4efb\u52a1\u4e2d\uff0c\u5728 40% \u7a00\u758f\u4e0b\u4fdd\u7559\u63a5\u8fd1 Dense \u7684\u6027\u80fd\u5e76\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u7684\u6301\u7eed\u589e\u957f\uff0c\u9762\u5411\u4e13\u4e1a\u9886\u57df\uff08\u5982\u6cd5\u5f8b\u3001\u533b\u7597\u3001\u91d1\u878d\uff09\u7684\u5b9a\u5236\u5316\u53d8\u4f53\u5bf9\u8d44\u6e90\u7684\u9700\u6c42\u4e0e\u90e8\u7f72\u96be\u5ea6\u65e5\u76ca\u589e\u52a0\u3002\u73b0\u6709\u7684\u6a21\u578b\u526a\u679d\u65b9\u6cd5\u8981\u4e48\u5bf9\u4e0d\u540c\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u8981\u4e48\u5e26\u6765\u8f83\u9ad8\u7684\u5f00\u9500\uff0c\u56e0\u6b64\u4e9f\u9700\u57df\u81ea\u9002\u5e94\u3001\u4f4e\u5f00\u9500\u7684\u526a\u679d\u4e0e\u9002\u914d\u7b56\u7565\u3002", "method": "\u63d0\u51fa EfficientXpert\uff1a\u91c7\u7528\u4f20\u64ad\u611f\u77e5\u7684\u526a\u679d\u51c6\u5219 Foresight Mask\uff0c\u4ee5\u53ca\u9ad8\u6548\u7684\u9002\u914d\u5668\u66f4\u65b0\u7b97\u6cd5 Partial Brain Surgeon\uff0c\u5c06\u4e24\u8005\u96c6\u6210\u5230 LoRA \u5fae\u8c03\u6d41\u7a0b\u4e2d\uff0c\u4f7f\u5f97\u5bf9\u901a\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u53ef\u5728\u5355\u6b65\u5185\u8f6c\u6362\u4e3a\u7a00\u758f\u3001\u9886\u57df\u4e13\u7528\u7684\u4e13\u5bb6\u6a21\u578b\u3002", "result": "\u5728\u5065\u5eb7\u4e0e\u6cd5\u5f8b\u4efb\u52a1\u4e0a\uff0c\u65b9\u6cd5\u53ef\u5728 40% \u7a00\u758f\u5ea6\u4e0b\u4fdd\u6301\u63a5\u8fd1 98% \u7684\u5bc6\u96c6\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u663e\u793a\u9886\u57df\u76f8\u5173\u7684\u7ed3\u6784\u6027\u504f\u79fb\u663e\u8457\u524a\u5f31\u4e86\u901a\u7528\u526a\u679d\u63a9\u7801\u7684\u6548\u679c\uff0c\u5f3a\u8c03\u9700\u8981\u9488\u5bf9\u6bcf\u4e2a\u9886\u57df\u7684\u81ea\u9002\u5e94\u526a\u679d\u7b56\u7565\u3002", "conclusion": "\u57df\u76f8\u5173\u7684\u7ed3\u6784\u6027\u53d8\u5316\u964d\u4f4e\u4e86\u901a\u7528\u526a\u679d\u63a9\u7801\u7684\u6709\u6548\u6027\uff0c\u9700\u53d1\u5c55\u9762\u5411\u5177\u4f53\u9886\u57df\u7684\u81ea\u9002\u5e94\u526a\u679d\u4e0e\u5feb\u901f\u9002\u914d\u673a\u5236\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u3001\u57df\u5b9a\u5236\u7684\u6a21\u578b\u538b\u7f29\u4e0e\u90e8\u7f72\u3002"}}
{"id": "2511.19941", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.19941", "abs": "https://arxiv.org/abs/2511.19941", "authors": ["Shenjun Zhong", "Zhifeng Chen", "Zhaolin Chen"], "title": "Optimize Flip Angle Schedules In MR Fingerprinting Using Reinforcement Learning", "comment": "4 pages, 5 figures, submitted to conference", "summary": "Magnetic Resonance Fingerprinting (MRF) leverages transient-state signal dynamics generated by the tunable acquisition parameters, making the design of an optimal, robust sequence a complex, high-dimensional sequential decision problem, such as optimizing one of the key parameters, flip angle. Reinforcement learning (RL) offers a promising approach to automate parameter selection, to optimize pulse sequences that maximize the distinguishability of fingerprints across the parameter space. In this work, we introduce an RL framework for optimizing the flip-angle schedule in MRF and demonstrate a learned schedule exhibiting non-periodic patterns that enhances fingerprint separability. Additionally, an interesting observation is that the RL-optimized schedule may enable a reduction in the number of repetition time, potentially accelerate MRF acquisitions.", "AI": {"tldr": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316MRF\u7684\u7ffb\u8f6c\u89d2\u65f6\u95f4\u8868\uff0c\u5f97\u5230\u975e\u5468\u671f\u6027\u4f18\u5316\u6a21\u5f0f\uff0c\u63d0\u5347\u6307\u7eb9\u533a\u5206\u5ea6\uff0c\u5e76\u53ef\u80fd\u7f29\u77ed\u91cd\u590d\u65f6\u95f4\u4ee5\u52a0\u901f\u6210\u50cf\u3002", "motivation": "MRF\u7684\u4fe1\u53f7\u4f9d\u8d56\u4e8e\u77ac\u6001\u52a8\u6001\u548c\u53ef\u8c03\u91c7\u96c6\u53c2\u6570\uff0c\u4f18\u5316\u7ffb\u8f6c\u89d2\u662f\u9ad8\u7ef4\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0cRL\u6709\u6f5c\u529b\u81ea\u52a8\u5316\u53c2\u6570\u9009\u62e9\u4ee5\u63d0\u9ad8\u6307\u7eb9\u4e0d\u53ef\u8fa8\u6027\u5206\u79bb\u5ea6\u3002", "method": "\u6784\u5efa\u4e00\u4e2aRL\u6846\u67b6\u6765\u4f18\u5316\u7ffb\u8f6c\u89d2\u5e8f\u5217\uff0c\u8bad\u7ec3\u4ee5\u63d0\u9ad8\u6307\u7eb9\u5728\u53c2\u6570\u7a7a\u95f4\u4e2d\u7684\u53ef\u5206\u79bb\u6027\uff1b\u89c2\u5bdf\u5f97\u5230\u7684\u6700\u4f18\u5e8f\u5217\u5448\u73b0\u975e\u5468\u671f\u6027\u6a21\u5f0f\uff1b\u8bc4\u4f30\u5bf9\u6307\u7eb9\u533a\u5206\u5ea6\u7684\u5f71\u54cd\uff0c\u53ca\u5bf9\u91cd\u590d\u65f6\u95f4\u7684\u5f71\u54cd\u6f5c\u529b\u3002", "result": "\u5b66\u4e60\u5f97\u5230\u7684\u7ffb\u8f6c\u89d2\u5e8f\u5217\u5728\u6307\u7eb9\u533a\u5206\u5ea6\u4e0a\u63d0\u5347\uff0c\u4e14\u8868\u73b0\u51fa\u975e\u5468\u671f\u6027\u6a21\u5f0f\uff1b\u53ef\u80fd\u51cf\u5c11\u91cd\u590d\u65f6\u95f4\uff0c\u63d0\u5347\u91c7\u96c6\u901f\u5ea6\u3002", "conclusion": "RL\u4f18\u5316\u7684\u7ffb\u8f6c\u89d2\u5e8f\u5217\u53ef\u663e\u8457\u63d0\u5347MRF\u7684\u6307\u7eb9\u53ef\u533a\u5206\u6027\u5e76\u6709\u671b\u52a0\u901f\u6210\u50cf\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u5728\u5b9e\u9645\u6570\u636e\u548c\u786c\u4ef6\u7ea6\u675f\u4e0b\u9a8c\u8bc1\u3002"}}
{"id": "2511.19942", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19942", "abs": "https://arxiv.org/abs/2511.19942", "authors": ["Jingchu Gai", "Guanning Zeng", "Huaqing Zhang", "Aditi Raghunathan"], "title": "Differential Smoothing Mitigates Sharpening and Improves LLM Reasoning", "comment": null, "summary": "It is widely recognized that reinforcement learning (RL) fine-tuning of large language models often leads to \\textit{diversity collapse}, where outputs lack variety. Prior work has proposed a range of heuristics to counteract this effect, but these methods are ad hoc: they frequently trade off correctness for diversity, their effectiveness varies across tasks, and in some cases they even contradict one another. In this work, we place these observations on a rigorous foundation. We first provide a formal proof of why RL fine-tuning exhibits diversity collapse via a selection and reinforcement bias. Next, we make a key observation that any reward modification to address diversity collapse only needs to be applied on the correct trajectories. Building directly on this analysis, we introduce a principled method -- \\textit{differential smoothing} -- that provably improves both correctness and diversity, outperforming vanilla RL as well as widely used entropy-based heuristics. Our theory precisely characterizes when existing heuristics help and why they fail, while showing that differential smoothing is universally superior. Extensive experiments with models from 1B to 7B parameters, across domains including CountDown and real-world mathematical reasoning, demonstrate consistent gains. Differential smoothing improves both Pass@1 and Pass@k, with up to 6.7\\% improvements on AIME24 dataset.", "AI": {"tldr": "\u63d0\u51fa\u5dee\u5206\u5e73\u6ed1\uff08differential smoothing\uff09\u4f5c\u4e3a\u4e00\u79cd principled RL \u5fae\u8c03\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728 RL \u5fae\u8c03\u4e2d\u51fa\u73b0\u7684\u591a\u6837\u6027\u5d29\u6e83\u95ee\u9898\uff0c\u901a\u8fc7\u5728\u6b63\u786e\u8f68\u8ff9\u4e0a\u4fee\u6b63\u5956\u52b1\uff0c\u7406\u8bba\u4e0e\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u6b63\u786e\u6027\u548c\u591a\u6837\u6027\u4e4b\u95f4\u53d6\u5f97\u6743\u8861\uff0c\u4f18\u4e8e vanilla RL \u4e0e\u71b5\u57fa\u542f\u53d1\u5f0f\uff0c\u57281B-7B\u53c2\u6570\u6a21\u578b\u548c CountDown\u3001AIME24 \u7b49\u4efb\u52a1\u4e0a\u5b9e\u73b0\u7a33\u5b9a\u63d0\u5347\u3002", "motivation": "RL \u5fae\u8c03\u5f80\u5f80\u5bfc\u81f4\u8f93\u51fa\u7f3a\u4e4f\u591a\u6837\u6027\uff08\u591a\u6837\u6027\u5d29\u6e83\uff09\uff0c\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u5f80\u5f80\u5728\u6b63\u786e\u6027\u4e0e\u591a\u6837\u6027\u4e4b\u95f4\u53d6\u820d\u4e14\u5bf9\u4efb\u52a1\u4e0d\u7a33\u5065\uff0c\u9700\u8981\u4e00\u4e2a\u5177\u6709\u7406\u8bba\u652f\u6491\u4e14\u666e\u9002\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5728\u7406\u8bba\u5c42\u9762\u5206\u6790 RL \u5fae\u8c03\u4e2d\u7684\u9009\u62e9\u504f\u5dee\u4e0e\u5f3a\u5316\u504f\u5dee\u5982\u4f55\u5bfc\u81f4\u591a\u6837\u6027\u5d29\u6e83\uff1b\u63d0\u51fa differential smoothing\uff0c\u5bf9\u5956\u52b1\u8fdb\u884c\u9009\u62e9\u6027\u4fee\u6539\uff0c\u4ec5\u5bf9\u6b63\u786e\u8f68\u8ff9\u8fdb\u884c\u5e72\u9884\uff0c\u5e76\u7ed9\u51fa\u53ef\u8bc1\u660e\u7684\u63d0\u5347\u6b63\u786e\u6027\u4e0e\u591a\u6837\u6027\u7684\u7406\u8bba\u7ed3\u679c\uff1b\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u7684\u6709\u6548\u6027\uff0c\u4e14\u4f18\u4e8e\u5e38\u7528\u71b5\u57fa heuristics\u3002", "result": "\u7406\u8bba\u4e0a\u7ed9\u51fa\u591a\u6837\u6027\u5d29\u6e83\u7684\u4ea7\u751f\u673a\u5236\uff08\u9009\u62e9\u504f\u5dee\u548c\u5f3a\u5316\u504f\u5dee\uff09\u4ee5\u53ca\u5bf9\u6b63\u786e\u8f68\u8ff9\u8fdb\u884c\u5956\u52b1\u4fee\u6b63\u7684\u6709\u6548\u6027\uff1b\u5728 1B\u20137B \u53c2\u6570\u91cf\u7ea7\u7684\u6a21\u578b\uff0c\u4ee5\u53ca CountDown \u4e0e\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u5dee\u5206\u5e73\u6ed1\u5b9e\u73b0\u4e86\u7a33\u5b9a\u7684\u6027\u80fd\u63d0\u5347\uff0cPass@1 \u4e0e Pass@k \u5747\u6709\u63d0\u5347\uff0c\u4e14\u5728 AIME24 \u6570\u636e\u96c6\u4e0a\u6700\u9ad8\u63d0\u5347\u7ea6 6.7%\u3002", "conclusion": "\u5dee\u5206\u5e73\u6ed1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u624e\u6839\u3001\u666e\u9002\u6709\u6548\u7684\u89e3\u51b3 RL \u5fae\u8c03\u4e2d\u591a\u6837\u6027\u5d29\u6e83\u7684\u65b9\u6cd5\uff0c\u4f18\u4e8e vanilla RL \u4e0e\u71b5\u57fa\u542f\u53d1\u5f0f\uff0c\u5efa\u8bae\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4f18\u5148\u91c7\u7528\u4ee5\u517c\u987e\u6b63\u786e\u6027\u4e0e\u591a\u6837\u6027\u3002"}}
{"id": "2511.19959", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.19959", "abs": "https://arxiv.org/abs/2511.19959", "authors": ["Yujia Wang", "Yuanpu Cao", "Jinghui Chen"], "title": "ParaBlock: Communication-Computation Parallel Block Coordinate Federated Learning for Large Language Models", "comment": "32 pages, 2 figures", "summary": "Federated learning (FL) has been extensively studied as a privacy-preserving training paradigm. Recently, federated block coordinate descent scheme has become a popular option in training large-scale models, as it allows clients to train only a subset of the model locally instead of the entire model. However, in the era of large language models (LLMs), even a single block can contain a significant number of parameters, posing substantial communication latency, particularly for resource-constrained clients. To address this challenge in federated training/fine-tuning LLMs, we propose ParaBlock, a novel approach that establishes two parallel threads for communication and computation to enhance communication efficiency. We theoretically prove that the proposed ParaBlock achieves the same convergence rate as the standard federated block coordinate descent methods. Empirical evaluations on fine-tuning LLMs on general instruction following and mathematical reasoning confirm that ParaBlock not only maintains strong performance but also significantly improves communication efficiency.", "AI": {"tldr": "ParaBlock\u901a\u8fc7\u5728\u8054\u90a6\u533a\u5757\u5750\u6807\u4e0b\u964d\u4e2d\u5f15\u5165\u8ba1\u7b97\u4e0e\u901a\u4fe1\u7684\u53cc\u7ebf\u7a0b\u5e76\u884c\u5b9e\u73b0\uff0c\u63d0\u9ad8\u5bf9LLM\u5fae\u8c03\u7684\u901a\u4fe1\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6807\u51c6\u7684\u8054\u90a6\u533a\u5757\u5750\u6807\u4e0b\u964d\u76f8\u540c\u7684\u6536\u655b\u901f\u7387\uff0c\u5e76\u5728\u6307\u4ee4\u9075\u5faa\u548c\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u83b7\u5f97\u826f\u597d\u6027\u80fd\u3002", "motivation": "\u5728\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e2d\uff0c\u5355\u4e2a\u533a\u5757\u901a\u5e38\u5305\u542b\u5927\u91cf\u53c2\u6570\uff0c\u5bfc\u81f4\u8d44\u6e90\u53d7\u9650\u7684\u5ba2\u6237\u7aef\u901a\u4fe1\u5ef6\u8fdf\u6210\u4e3a\u74f6\u9888\u3002\u73b0\u6709\u7684\u8054\u90a6\u533a\u5757\u5750\u6807\u4e0b\u964d\u5728\u9ad8\u7ef4\u6a21\u578b\u4e0b\u96be\u4ee5\u9ad8\u6548\u901a\u4fe1\uff0c\u9700\u8981\u65b0\u7684\u673a\u5236\u6765\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u5e76\u4fdd\u7559\u6536\u655b\u6027\u3002", "method": "\u63d0\u51faParaBlock\uff1a\u4e3a\u901a\u4fe1\u4e0e\u8ba1\u7b97\u5efa\u7acb\u4e24\u6761\u5e76\u884c\u7ebf\u7a0b\uff0c\u4f7f\u5f97\u533a\u5757\u5750\u6807\u4e0b\u964d\u7684\u66f4\u65b0\u4e0e\u901a\u4fe1\u53ef\u4ee5\u5e76\u884c\u8fdb\u884c\uff1b\u7ed9\u51fa\u7406\u8bba\u6536\u655b\u6027\u8bc1\u660e\uff0c\u8868\u660e\u5728\u7b49\u4ef7\u8bbe\u5b9a\u4e0b\u5176\u6536\u655b\u901f\u7387\u4e0e\u6807\u51c6\u65b9\u6cd5\u4e00\u81f4\u3002", "result": "\u7406\u8bba\u4e0a\uff0cParaBlock\u4fdd\u6301\u4e0e\u6807\u51c6Fed BCD\u76f8\u540c\u7684\u6536\u655b\u901f\u7387\uff1b\u5728\u5bf9\u901a\u7528\u6307\u4ee4\u8ddf\u968f\u548c\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7684LLM\u5fae\u8c03\u4e0a\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aParaBlock\u5728\u4fdd\u6301\u5f3a\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u901a\u4fe1\u6548\u7387\u3002", "conclusion": "ParaBlock\u4e3aLLM\u7684\u8054\u90a6\u8bad\u7ec3/\u5fae\u8c03\u63d0\u4f9b\u4e00\u79cd\u9ad8\u6548\u7684\u901a\u4fe1\u65b9\u6848\uff0c\u5728\u4e0d\u727a\u7272\u6536\u655b\u6027\u548c\u6a21\u578b\u6027\u80fd\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u901a\u4fe1\u8d1f\u62c5\uff0c\u5177\u6709\u63a8\u5e7f\u5230\u5927\u89c4\u6a21\u8054\u90a6\u5b66\u4e60\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.19966", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.19966", "abs": "https://arxiv.org/abs/2511.19966", "authors": ["Yujia Wang", "Fenglong Ma", "Jinghui Chen"], "title": "Stragglers Can Contribute More: Uncertainty-Aware Distillation for Asynchronous Federated Learning", "comment": "28 pages", "summary": "Asynchronous federated learning (FL) has recently gained attention for its enhanced efficiency and scalability, enabling local clients to send model updates to the server at their own pace without waiting for slower participants. However, such a design encounters significant challenges, such as the risk of outdated updates from straggler clients degrading the overall model performance and the potential bias introduced by faster clients dominating the learning process, especially under heterogeneous data distributions. Existing methods typically address only one of these issues, creating a conflict where mitigating the impact of outdated updates can exacerbate the bias created by faster clients, and vice versa. To address these challenges, we propose FedEcho, a novel framework that incorporates uncertainty-aware distillation to enhance the asynchronous FL performances under large asynchronous delays and data heterogeneity. Specifically, uncertainty-aware distillation enables the server to assess the reliability of predictions made by straggler clients, dynamically adjusting the influence of these predictions based on their estimated uncertainty. By prioritizing more certain predictions while still leveraging the diverse information from all clients, FedEcho effectively mitigates the negative impacts of outdated updates and data heterogeneity. Through extensive experiments, we demonstrate that FedEcho consistently outperforms existing asynchronous federated learning baselines, achieving robust performance without requiring access to private client data.", "AI": {"tldr": "\u63d0\u51fa FedEcho\uff1a\u5728\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u4e2d\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u84b8\u998f\u6765\u63d0\u5347\u5728\u5927\u5ef6\u8fdf\u548c\u6570\u636e\u5f02\u8d28\u6027\u4e0b\u7684\u9c81\u68d2\u6027\u4e0e\u6027\u80fd\u3002", "motivation": "\u5f02\u6b65FL\u53ef\u51cf\u5c11\u7b49\u5f85\u4f46\u6613\u53d7\u6162\u53c2\u4e0e\u8005\u7684\u8fc7\u65f6\u66f4\u65b0\u548c\u6570\u636e\u5206\u5e03\u5f02\u8d28\u6027\u5f71\u54cd\uff0c\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u53ea\u89e3\u51b3\u5176\u4e2d\u4e00\u4e2a\u95ee\u9898\uff0c\u5bfc\u81f4\u4e24\u8005\u51b2\u7a81\u3002", "method": "\u63d0\u51fa FedEcho \u6846\u67b6\uff0c\u7ed3\u5408\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u84b8\u998f\u3002\u670d\u52a1\u5668\u901a\u8fc7\u8bc4\u4f30\u6765\u81ea\u6162\u5ba2\u6237\u7aef\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u52a8\u6001\u8c03\u8282\u5176\u9884\u6d4b\u5f71\u54cd\u529b\uff0c\u5728\u4fdd\u7559\u591a\u6837\u4fe1\u606f\u7684\u540c\u65f6\u964d\u4f4e\u8fc7\u65f6\u66f4\u65b0\u7684\u8d1f\u9762\u4f5c\u7528\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\uff0cFedEcho \u5728\u5f02\u6b65FL\u57fa\u7ebf\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u5177\u9c81\u68d2\u6027\u4e14\u65e0\u9700\u8bbf\u95ee\u79c1\u6709\u6570\u636e\u3002", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u84b8\u998f\u4f7f\u5f02\u6b65FL\u5728\u5927\u5ef6\u8fdf\u548c\u5f02\u8d28\u6570\u636e\u4e0b\u66f4\u7a33\u5065\uff0c\u5e73\u8861\u4e86\u5168\u90e8\u5ba2\u6237\u7aef\u7684\u8d21\u732e\u5e76\u7f13\u89e3\u4e86\u8fc7\u65f6\u66f4\u65b0\u4e0e\u6570\u636e\u5f02\u8d28\u6027\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2511.19986", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19986", "abs": "https://arxiv.org/abs/2511.19986", "authors": ["Lianming Huang", "Haibo Hu", "Qiao Li", "Nan Guan", "Chun Jason Xue"], "title": "On-Demand Multi-Task Sparsity for Efficient Large-Model Deployment on Edge Devices", "comment": null, "summary": "Sparsity is essential for deploying large models on resource constrained edge platforms. However, optimizing sparsity patterns for individual tasks in isolation ignores the significant I/O overhead incurred during frequent task switching. We introduce an on-demand multi-task sparsity framework specifically designed to minimize switching costs by maximizing parameter reuse. Unlike monolithic approaches, we decompose weights into reusable block-granular units and align sparse structures across tasks to maximize overlap. By dynamically loading only the small differential set of blocks required for the next task, our method effectively mitigates the cold-start latency inherent in traditional monolithic approaches.Experiments on a real-world autonomous driving platform demonstrate that our framework achieves superior switching efficiency, accelerating task switching by over 6.6X on average compared to existing sparsity methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6309\u9700\u591a\u4efb\u52a1\u7a00\u758f\u6846\u67b6\uff0c\u901a\u8fc7\u5757\u7ea7\u53ef\u91cd\u7528\u7ed3\u6784\u8de8\u4efb\u52a1\u5bf9\u9f50\uff0c\u964d\u4f4e\u4efb\u52a1\u5207\u6362\u7684I/O\u5f00\u9500\uff0c\u5e76\u5728\u5b9e\u9645\u81ea\u9a7e\u5e73\u53f0\u4e0a\u5b9e\u73b06.6\u500d\u52a0\u901f\u3002", "motivation": "\u89e3\u51b3\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u5927\u6a21\u578b\u65f6\uff0c\u5355\u4efb\u52a1\u7a00\u758f\u5316\u5ffd\u7565\u4efb\u52a1\u5207\u6362\u5e26\u6765\u7684I/O\u6210\u672c\uff1b\u9700\u8981\u51cf\u5c11\u51b7\u542f\u52a8\u548c\u5207\u6362\u5ef6\u8fdf\u3002", "method": "\u5c06\u6743\u91cd\u5206\u89e3\u4e3a\u53ef\u91cd\u7528\u7684\u5757\u7c92\u5ea6\u5355\u5143\uff0c\u8de8\u4efb\u52a1\u5bf9\u9f50\u7a00\u758f\u7ed3\u6784\uff0c\u4ee5\u5b9e\u73b0\u6700\u5927\u91cd\u53e0\uff1b\u6309\u9700\u52a0\u8f7d\u4ec5\u4e3a\u4e0b\u4e00\u4e2a\u4efb\u52a1\u6240\u9700\u7684\u5c11\u91cf\u5757\u7684\u5dee\u5f02\u96c6\u5408\u3002", "result": "\u5728\u771f\u5b9e\u81ea\u9a7e\u5e73\u53f0\u4e0a\uff0c\u5207\u6362\u6548\u7387\u663e\u8457\u63d0\u5347\uff0c\u4efb\u52a1\u5207\u6362\u5e73\u5747\u52a0\u901f\u8d85\u8fc76.6X\uff0c\u76f8\u6bd4\u73b0\u6709\u7a00\u758f\u5316\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u52a8\u6001\u52a0\u8f7d\u6700\u5c0f\u5dee\u5f02\u5757\uff0c\u5b9e\u73b0\u7a00\u758f\u6027\u4e0e\u591a\u4efb\u52a1\u4e4b\u95f4\u7684\u9ad8\u91cd\u7528\u6027\uff0c\u7f13\u89e3\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u63d0\u5347\u8fb9\u7f18\u5e73\u53f0\u7684\u4efb\u52a1\u5207\u6362\u6027\u80fd\u3002"}}
{"id": "2511.19996", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19996", "abs": "https://arxiv.org/abs/2511.19996", "authors": ["Dishanika Denipitiyage", "Naveen Karunanayake", "Suranga Seneviratne", "Sanjay Chawla"], "title": "RankOOD - Class Ranking-based Out-of-Distribution Detection", "comment": null, "summary": "We propose RankOOD, a rank-based Out-of-Distribution (OOD) detection approach based on training a model with the Placket-Luce loss, which is now extensively used for preference alignment tasks in foundational models. Our approach is based on the insight that with a deep learning model trained using the Cross Entropy Loss, in-distribution (ID) class prediction induces a ranking pattern for each ID class prediction. The RankOOD framework formalizes the insight by first extracting a rank list for each class using an initial classifier and then uses another round of training with the Plackett-Luce loss, where the class rank, a fixed permutation for each class, is the predicted variable. An OOD example may get assigned with high probability to an ID example, but the probability of it respecting the ranking classification is likely to be small. RankOOD, achieves SOTA performance on the near-ODD TinyImageNet evaluation benchmark, reducing FPR95 by 4.3%.", "AI": {"tldr": "RankOOD\u662f\u4e00\u79cd\u57fa\u4e8e\u6392\u5e8f\u7684OOD\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528Plackett-Luce\u635f\u5931\u5bf9\u6a21\u578b\u8fdb\u884c\u4e8c\u9636\u6bb5\u8bad\u7ec3\u4ee5\u5229\u7528ID\u6570\u636e\u4e2d\u7684\u9690\u542b\u6392\u5e8f\u6a21\u5f0f\uff0c\u5728TinyImageNet\u8fd1OOD\u8bc4\u4f30\u4e2d\u8fbe\u5230SOTA\uff0cFPR95\u964d\u4f4e4.3%\u3002", "motivation": "OOD\u68c0\u6d4b\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u9700\u8981\u5145\u5206\u5229\u7528ID\u6570\u636e\u7684\u7ed3\u6784\u4fe1\u606f\u3002\u5c3d\u7ba1\u5e38\u7528\u7684\u4ea4\u53c9\u71b5\u8bad\u7ec3\u4f1a\u4ea7\u751fID\u7c7b\u522b\u7684\u6392\u5e8f\u6a21\u5f0f\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u5ffd\u7565\u8fd9\u4e00\u6f5c\u5728\u4fe1\u53f7\u3002\u4f5c\u8005\u63d0\u51fa\u5c06ID\u7c7b\u522b\u7684\u6392\u5e8f\u4fe1\u606f\u663e\u5f0f\u5efa\u6a21\u4e3a\u4e00\u4e2a\u6392\u5217\u9884\u6d4b\u4efb\u52a1\uff0c\u4ee5\u63d0\u5347\u5bf9OOD\u6837\u672c\u7684\u533a\u5206\u80fd\u529b\u3002", "method": "1) \u4f7f\u7528\u521d\u59cb\u5206\u7c7b\u5668\u63d0\u53d6\u6bcf\u4e2a\u7c7b\u522b\u7684\u6392\u5e8f\u5217\u8868\uff08rank list\uff09\u30022) \u4ee5Plackett-Luce\u635f\u5931\u5bf9\u6a21\u578b\u8fdb\u884c\u518d\u8bad\u7ec3\uff0c\u5c06\u6bcf\u4e2a\u7c7b\u522b\u7684\u56fa\u5b9a\u6392\u5217\u4f5c\u4e3a\u5f85\u9884\u6d4b\u53d8\u91cf\uff0c\u901a\u8fc7\u6392\u5e8f\u6982\u7387\u6765\u8fdb\u884c\u5b66\u4e60\u3002\u8be5\u6846\u67b6\u4f7fOOD\u6837\u672c\u66f4\u53ef\u80fd\u8fdd\u80ccID\u7684\u6392\u5e8f\u7ea6\u675f\uff0c\u4ece\u800c\u63d0\u9ad8\u68c0\u6d4b\u80fd\u529b\u3002", "result": "\u5728\u8fd1OOD TinyImageNet\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86SOTA\u6027\u80fd\uff0cFPR95\u4e0b\u964d\u7ea64.3%\u3002", "conclusion": "\u57fa\u4e8e\u6392\u5e8f\u7684PL\u635f\u5931\u53ef\u4ee5\u6709\u6548\u5229\u7528ID\u6570\u636e\u7684\u9690\u542b\u6392\u5e8f\u6a21\u5f0f\u6765\u6539\u5584OOD\u68c0\u6d4b\uff0cRankOOD\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u8fd1OOD\u573a\u666f\u7684\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2511.19998", "categories": ["cs.LG", "cs.DS", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.19998", "abs": "https://arxiv.org/abs/2511.19998", "authors": ["Nikit Phadke"], "title": "REWA: Witness-Overlap Theory -- Foundations for Composable Binary Similarity Systems", "comment": null, "summary": "REWA introduces a general theory of similarity based on witness-overlap structures. We show that whenever similarity between concepts can be expressed as monotone witness overlap -- whether arising from graph neighborhoods, causal relations, temporal structure, topological features, symbolic patterns, or embedding-based neighborhoods -- it admits a reduction to compact encodings with provable ranking preservation guarantees. REWA systems consist of: (1) finite witness sets $W(v)$, (2) semi-random bit assignments generated from each witness, and (3) monotonicity of expected similarity in the overlap $\u0394(u, v) = |W(u) \\cap W(v)|$. We prove that under an overlap-gap condition on the final witness sets -- independent of how they were constructed -- top-$k$ rankings are preserved using $m = O(\\log(|V|/\u03b4))$ bits. The witness-set formulation is compositional: any sequence of structural, temporal, causal, topological, information-theoretic, or learned transformations can be combined into pipelines that terminate in discrete witness sets. The theory applies to the final witness overlap, enabling modular construction of similarity systems from reusable primitives. This yields a vast design space: millions of composable similarity definitions inherit logarithmic encoding complexity. REWA subsumes and unifies Bloom filters, minhash, LSH bitmaps, random projections, sketches, and hierarchical filters as special cases. It provides a principled foundation for similarity systems whose behavior is governed by witness overlap rather than hash-function engineering. This manuscript presents the axioms, the main reducibility theorem, complete proofs with explicit constants, and a detailed discussion of compositional design, limitations, and future extensions including multi-bit encodings, weighted witnesses, and non-set representations.", "AI": {"tldr": "\u63d0\u51faREWA\uff0c\u4e00\u79cd\u57fa\u4e8e\u89c1\u8bc1\u91cd\u53e0\u7684\u666e\u9002\u76f8\u4f3c\u6027\u7406\u8bba\uff0c\u80fd\u5c06\u4efb\u610f\u5355\u8c03\u7684\u89c1\u8bc1\u91cd\u53e0\u76f8\u4f3c\u6027\u6620\u5c04\u4e3a\u5bf9\u6570\u7f16\u7801\u4e14\u4fdd\u6301\u524dk\u6392\u5e8f\uff0c\u5728\u6a21\u5757\u5316\u8bbe\u8ba1\u4e0b\u53ef\u7ec4\u5408\u591a\u79cd\u7ed3\u6784\u5316\u53d8\u6362\uff0c\u7edf\u4e00 Bloom filters\u3001minhash\u3001LSH \u7b49\u65b9\u6cd5\u3002", "motivation": "\u5bfb\u6c42\u4e00\u4e2a\u7edf\u4e00\u3001\u53ef\u7ec4\u5408\u4e14\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u76f8\u4f3c\u6027\u6846\u67b6\uff0c\u8986\u76d6\u56fe\u3001\u65f6\u5e8f\u3001\u56e0\u679c\u3001\u62d3\u6251\u3001\u7b26\u53f7\u6a21\u5f0f\u3001\u5d4c\u5165\u8fd1\u90bb\u7b49\u573a\u666f\uff0c\u8d85\u8d8a\u5355\u7eaf\u7684\u54c8\u5e0c/\u8fd1\u4f3c\u6280\u5de7\u3002", "method": "\u63d0\u51faREWA\u7cfb\u7edf\uff1a\u6709\u9650\u89c1\u8bc1\u96c6W(v)\uff0c\u5bf9\u6bcf\u4e2a\u89c1\u8bc1\u751f\u6210\u534a\u968f\u673a\u6bd4\u7279\u5206\u914d\uff0c\u89c1\u8bc1\u91cd\u53e0\u0394(u,v)=|W(u)\u2229W(v)|\u4e0e\u671f\u671b\u76f8\u4f3c\u6027\u5355\u8c03\u76f8\u5173\uff1b\u5728\u5177\u5907\u6700\u7ec8\u89c1\u8bc1\u96c6\u7684\u91cd\u53e0\u7f3a\u53e3\u6761\u4ef6\u65f6\uff0c\u7ed9\u51fatop-k\u6392\u5e8f\u53ef\u7528\u7684\u4f4d\u6570m=O(log(|V|/\u03b4))\u7684\u7f16\u7801\uff0c\u5e76\u5b9e\u73b0\u53ef\u7ec4\u5408\u7ba1\u7ebf\uff0c\u4f7f\u4efb\u610f\u5e8f\u5217\u7684\u7ed3\u6784\u6027\u3001\u65f6\u5e8f\u6027\u3001\u56e0\u679c\u3001\u62d3\u6251\u3001\u4fe1\u606f\u7406\u8bba\u6216\u5b66\u4e60\u53d8\u6362\u5747\u53ef\u805a\u5408\u4e3a\u79bb\u6563\u7684\u89c1\u8bc1\u96c6\u5408\u3002", "result": "\u7ed9\u51fa\u53ef\u8bc1\u660e\u7684\u53ef\u8fd8\u539f\u6027/\u53ef\u6bd4\u6027\u5b9a\u7406\uff08top-k\u4fdd\u6301\uff09\u4ee5\u53ca\u5b8c\u6574\u8bc1\u660e\uff0c\u5305\u542b\u660e\u786e\u5e38\u6570\uff0c\u5f3a\u8c03\u6a21\u5757\u5316\u8bbe\u8ba1\u4e0e\u53ef\u91cd\u590d\u7ec4\u5408\uff1b\u7406\u8bba\u6846\u67b6\u53ef\u7edf\u4e00\u591a\u79cd\u76f8\u4f3c\u6027\u5de5\u5177\uff08Bloom Filter\u3001MinHash\u3001LSH\u4f4d\u56fe\u3001\u968f\u673a\u6295\u5f71\u3001\u6458\u8981\u7b49\uff09\u7684\u6838\u5fc3\u601d\u60f3\u3002", "conclusion": "REWA\u4e3a\u57fa\u4e8e\u89c1\u8bc1\u91cd\u53e0\u7684\u76f8\u4f3c\u6027\u7cfb\u7edf\u63d0\u4f9b\u539f\u7406\u5316\u57fa\u7840\uff0c\u5f3a\u8c03\u4ee5\u53ef\u590d\u7528\u539f\u8bed\u6784\u5efa\u8bbe\u8ba1\uff1b\u5e76\u8ba8\u8bba\u5c40\u9650\u6027\u53ca\u672a\u6765\u6269\u5c55\uff0c\u5982\u591a\u6bd4\u7279\u7f16\u7801\u3001\u52a0\u6743\u89c1\u8bc1\u3001\u975e\u96c6\u5408\u8868\u793a\u7b49\u3002"}}
{"id": "2511.20004", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.20004", "abs": "https://arxiv.org/abs/2511.20004", "authors": ["Peining Zhang", "Hongchen Qin", "Haochen Zhang", "Ziqi Guo", "Guiling Wang", "Jinbo Bi"], "title": "Zero-Shot Transfer Capabilities of the Sundial Foundation Model for Leaf Area Index Forecasting", "comment": null, "summary": "This work investigates the zero-shot forecasting capability of time-series foundation models for Leaf Area Index (LAI) forecasting in agricultural monitoring. Using the HiQ dataset (U.S., 2000-2022), we systematically compare statistical baselines, a fully supervised LSTM, and the Sundial foundation model under multiple evaluation protocols. We find that Sundial, in the zero-shot setting, can outperform a fully trained LSTM provided that the input context window is sufficiently long-specifically, when covering more than one or two full seasonal cycles. This demonstrates, for the first time, that a general-purpose foundation model can surpass specialized supervised models on remote-sensing time series prediction without any task-specific tuning. These results highlight the strong potential of pretrained time-series foundation models to serve as effective plug-and-play forecasters in agricultural and environmental applications.", "AI": {"tldr": "\u96f6-shot \u9884\u6d4b\uff1aTime-series foundation model Sundial \u5728 LAI \u7684\u9065\u611f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\uff0c\u80fd\u5728\u4e0d\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u8d85\u8d8a\u8bad\u7ec3\u826f\u597d\u7684 LSTM\uff0c\u5f53\u8f93\u5165\u4e0a\u4e0b\u6587\u7a97\u53e3\u8db3\u591f\u957f\uff08\u8986\u76d6\u4e00\u4e2a\u4ee5\u4e0a\u4e24\u4e2a\u5b8c\u6574\u5b63\u8282\u5faa\u73af\uff09\u65f6\u3002", "motivation": "\u63a2\u7a76\u901a\u7528\u9884\u8bad\u7ec3\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u662f\u5426\u80fd\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7684\u9884\u6d4b\u5668\uff0c\u5728\u6ca1\u6709\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u9065\u611f\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u9ad8\u8d28\u91cf\u9884\u6d4b\uff0c\u7279\u522b\u662f\u519c\u4e1a/\u73af\u5883\u5e94\u7528\u4e2d\u7684 LAI \u9884\u6d4b\u3002", "method": "\u5728 HiQ \u6570\u636e\u96c6\uff08\u7f8e\u56fd\uff0c2000-2022\uff09\u4e0a\uff0c\u7cfb\u7edf\u6bd4\u8f83\u7edf\u8ba1\u57fa\u7ebf\u3001\u4e00\u4e2a\u5168\u76d1\u7763\u7684 LSTM\uff0c\u4ee5\u53ca Sundial \u57fa\u7840\u6a21\u578b\uff0c\u5728\u591a\u79cd\u8bc4\u4f30\u534f\u8bae\u4e0b\u8fdb\u884c\u96f6-shot \u9884\u6d4b\uff1b\u5e76\u53d8\u66f4\u8f93\u5165\u4e0a\u4e0b\u6587\u7a97\u53e3\u957f\u5ea6\u4ee5\u8003\u5bdf\u5bf9\u9884\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5728\u96f6-shot \u8bbe\u7f6e\u4e2d\uff0cSundial \u80fd\u5728\u8f93\u5165\u4e0a\u4e0b\u6587\u8db3\u591f\u957f\uff08\u8986\u76d6\u4e00\u4e2a\u4ee5\u4e0a\u4e24\u4e2a\u5b8c\u6574\u5b63\u8282\u5faa\u73af\uff09\u65f6\u8d85\u8fc7\u7ecf\u8fc7\u5b8c\u6574\u8bad\u7ec3\u7684 LSTM\uff0c\u9996\u6b21\u663e\u793a\u901a\u7528\u578b\u57fa\u7840\u6a21\u578b\u5728\u6ca1\u6709\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u53ef\u4f18\u4e8e\u4e13\u95e8\u76d1\u7763\u6a21\u578b\u8fdb\u884c\u9065\u611f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002", "conclusion": "\u8fd9\u8868\u660e\u9884\u8bad\u7ec3\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u5177\u6709\u4f5c\u4e3a\u9ad8\u6548\u201c\u5373\u63d2\u5373\u7528\u201d\u9884\u6d4b\u5668\u7684\u6f5c\u529b\uff0c\u53ef\u5728\u519c\u4e1a\u4e0e\u73af\u5883\u5e94\u7528\u4e2d\u76f4\u63a5\u7528\u4e8e\u9065\u611f\u65f6\u95f4\u5e8f\u5217\u7684\u9884\u6d4b\u4efb\u52a1\u3002"}}
{"id": "2511.20030", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20030", "abs": "https://arxiv.org/abs/2511.20030", "authors": ["Haoran Zheng", "Renchi Yang", "Hongtao Wang", "Jianliang Xu"], "title": "Cross-Contrastive Clustering for Multimodal Attributed Graphs with Dual Graph Filtering", "comment": "Accepted by SIGKDD 2026. The code is available at https://github.com/HaoranZ99/DGF", "summary": "Multimodal Attributed Graphs (MMAGs) are an expressive data model for representing the complex interconnections among entities that associate attributes from multiple data modalities (text, images, etc.). Clustering over such data finds numerous practical applications in real scenarios, including social community detection, medical data analytics, etc. However, as revealed by our empirical studies, existing multi-view clustering solutions largely rely on the high correlation between attributes across various views and overlook the unique characteristics (e.g., low modality-wise correlation and intense feature-wise noise) of multimodal attributes output by large pre-trained language and vision models in MMAGs, leading to suboptimal clustering performance.\n  Inspired by foregoing empirical observations and our theoretical analyses with graph signal processing, we propose the Dual Graph Filtering (DGF) scheme, which innovatively incorporates a feature-wise denoising component into node representation learning, thereby effectively overcoming the limitations of traditional graph filters adopted in the extant multi-view graph clustering approaches. On top of that, DGF includes a tri-cross contrastive training strategy that employs instance-level contrastive learning across modalities, neighborhoods, and communities for learning robust and discriminative node representations. Our comprehensive experiments on eight benchmark MMAG datasets exhibit that DGF is able to outperform a wide range of state-of-the-art baselines consistently and significantly in terms of clustering quality measured against ground-truth labels.", "AI": {"tldr": "\u63d0\u51fa DGF \u6846\u67b6\u7528\u4e8e\u591a\u6a21\u6001\u5c5e\u6027\u56fe\u7684\u805a\u7c7b\uff0c\u901a\u8fc7\u7279\u5f81\u7ea7\u53bb\u566a\u548c\u4e09\u91cd\u5bf9\u6bd4\u5b66\u4e60\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u5728\u516b\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u4e3b\u6d41\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u591a\u89c6\u56fe\u805a\u7c7b\u8fc7\u5ea6\u4f9d\u8d56\u8de8\u6a21\u6001\u5c5e\u6027\u9ad8\u76f8\u5173\u6027\u3001\u5ffd\u89c6\u6a21\u6001\u7279\u6709\u566a\u58f0\u4e0e\u4f4e\u76f8\u5173\u6027\u7684\u6311\u6218\uff1b\u9700\u8981\u7ed3\u5408\u56fe\u4fe1\u53f7\u5904\u7406\u7406\u8bba\u5b9e\u73b0\u7279\u5f81\u7ea7\u53bb\u566a\u5e76\u63d0\u5347\u8282\u70b9\u8868\u5f81\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa Dual Graph Filtering (DGF) \u65b9\u6848\uff0c\u5728\u8282\u70b9\u8868\u793a\u5b66\u4e60\u4e2d\u5f15\u5165\u7279\u5f81\u7ea7\u53bb\u566a\u7ec4\u4ef6\uff1b\u5e76\u8bbe\u8ba1 tri-cross \u5bf9\u6bd4\u5b66\u4e60\u7b56\u7565\uff0c\u5728\u5b9e\u4f8b\u5c42\u9762\u8de8\u6a21\u6001\u3001\u90bb\u57df\u4e0e\u793e\u533a\u7ef4\u5ea6\u8fdb\u884c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u4ee5\u83b7\u5f97\u9c81\u68d2\u4e14\u5177\u8fa8\u522b\u6027\u7684\u8282\u70b9\u5d4c\u5165\u3002", "result": "\u5728\u516b\u4e2a\u57fa\u51c6 MMAG \u6570\u636e\u96c6\u4e0a\uff0cDGF \u80fd\u6301\u7eed\u4e14\u663e\u8457\u5730\u4f18\u4e8e\u5e7f\u6cdb\u7684 state-of-the-art \u57fa\u7ebf\uff0c\u63d0\u5347\u805a\u7c7b\u8d28\u91cf\u3002", "conclusion": "DGF \u6709\u6548\u514b\u670d\u4e86\u4f20\u7edf\u56fe\u6ee4\u6ce2\u5728\u591a\u6a21\u6001\u56fe\u805a\u7c7b\u4e2d\u7684\u5c40\u9650\uff0c\u8bc1\u5b9e\u7279\u5f81\u7ea7\u53bb\u566a\u4e0e\u4e09\u91cd\u5bf9\u6bd4\u5b66\u4e60\u7684\u7ec4\u5408\u80fd\u663e\u8457\u63d0\u5347\u805a\u7c7b\u6027\u80fd\u3002"}}
{"id": "2511.20044", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20044", "abs": "https://arxiv.org/abs/2511.20044", "authors": ["PengYu Chen", "Xiaohou Shi", "Yuan Chang", "Yan Sun", "Sajal K. Das"], "title": "RED-F: Reconstruction-Elimination based Dual-stream Contrastive Forecasting for Multivariate Time Series Anomaly Prediction", "comment": "13 pages, 12 figures", "summary": "The proactive prediction of anomalies (AP) in mul- tivariate time series (MTS) is a critical challenge to ensure system dependability. The difficulty lies in identifying subtle anomaly precursors concealed within normal signals. However, existing unsupervised methods, trained exclusively on normal data, demonstrate a fundamental propensity to reconstruct normal patterns. Consequently, when confronted with weak precursors, their predictions are dominated by the normal pattern, submerging the very signal required for prediction. To contend with the limitation, we propose RED-F, a Reconstruction- Elimination based Dual-stream Contrastive Forecasting frame- work, comprising the Reconstruction-Elimination Model (REM) and the Dual-stream Contrastive Forecasting Model (DFM). The REM utilizes a hybrid time-frequency mechanism to mitigate the precursor, generating a purified, normal-pattern baseline. The DFM then receives this purified baseline and the original sequence which retains the precursor as parallel inputs. At the core of our framework, RED-F employs a contrastive forecast that transforms the difficult task of absolute signal detection into a simpler, more robust task of relative trajectory comparison by computing the divergence between these two predictive streams. This contrastive mechanism serves to amplify the faint precursor signal. Furthermore, the DFM is trained with a novel Multi-Series Prediction (MSP) objective, which leverages distant future con- text to enhance its predictive sensitivity. Extensive experiments on six real-world datasets demonstrate the superior capability of RED-F in anomaly prediction tasks.", "AI": {"tldr": "\u63d0\u51fa RED-F\uff1a\u4e00\u4e2a\u53cc\u6d41\u5bf9\u6bd4\u9884\u6d4b\u6846\u67b6\u7528\u4e8e\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u9884\u6d4b\uff0c\u7ed3\u5408\u91cd\u5efa-\u53bb\u9664\u6a21\u578b\uff08REM\uff09\u4e0e\u53cc\u6d41\u9884\u6d4b\u6a21\u578b\uff08DFM\uff09\uff0c\u901a\u8fc7\u6df7\u5408\u65f6\u9891\u7684 REM \u63d0\u7eaf\u6b63\u5e38\u6a21\u5f0f\uff0c\u5e76\u4ee5\u5bf9\u6bd4\u9884\u6d4b\u5f3a\u5316\u524d\u5bfc\u4fe1\u53f7\uff0c\u540c\u65f6\u5f15\u5165 MSP \u76ee\u6807\u63d0\u5347\u5bf9\u8fdc\u671f\u4e0a\u4e0b\u6587\u7684\u5229\u7528\uff0c\u5728\u516d\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5c55\u73b0\u51fa\u8272\u6027\u80fd\u3002", "motivation": "\u65e0\u76d1\u7763\u65b9\u6cd5\u5728\u4ec5\u4ee5\u6b63\u5e38\u6570\u636e\u8bad\u7ec3\u65f6\uff0c\u5bb9\u6613\u91cd\u5efa\u6b63\u5e38\u6a21\u5f0f\uff0c\u4ece\u800c\u63a9\u76d6\u5fae\u5f31\u7684\u5f02\u5e38\u524d\u5bfc\u4fe1\u53f7\uff0c\u9700\u4e00\u5957\u80fd\u591f\u5206\u79bb\u6216\u653e\u5927\u524d\u5bfc\u4fe1\u53f7\u7684\u6846\u67b6\u4ee5\u63d0\u5347\u5f02\u5e38\u9884\u6d4b\u3002", "method": "\u63d0\u51fa REM \u91c7\u7528\u6df7\u5408\u65f6\u9891\u673a\u5236\u5bf9\u5e8f\u5217\u8fdb\u884c\u53bb\u566a/\u63d0\u7eaf\uff0c\u5f97\u5230\u7eaf\u51c0\u7684\u6b63\u5e38\u6a21\u5f0f\u57fa\u7ebf\uff1bDFM \u5c06\u8be5\u57fa\u7ebf\u4e0e\u539f\u59cb\u5e8f\u5217\uff08\u4fdd\u7559\u524d\u5bfc\u4fe1\u53f7\uff09\u4f5c\u4e3a\u5e76\u884c\u8f93\u5165\uff1b\u901a\u8fc7\u5bf9\u6bd4\u9884\u6d4b\u5c06\u7edd\u5bf9\u4fe1\u53f7\u68c0\u6d4b\u8f6c\u5316\u4e3a\u76f8\u5bf9\u8f68\u8ff9\u6bd4\u8f83\u4ee5\u653e\u5927\u524d\u5bfc\u4fe1\u53f7\uff1bMSP \u76ee\u6807\u5229\u7528\u8fdc\u671f\u4e0a\u4e0b\u6587\u63d0\u5347\u9884\u6d4b\u7075\u654f\u5ea6\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e RED-F \u5728\u5f02\u5e38\u9884\u6d4b\u4efb\u52a1\u4e2d\u5177\u5907\u4f18\u8d8a\u80fd\u529b\u3002", "conclusion": "RED-F \u901a\u8fc7\u91cd\u5efa-\u53bb\u9664\u4e0e\u5bf9\u6bd4\u9884\u6d4b\u76f8\u7ed3\u5408\uff0c\u6709\u6548\u653e\u5927\u5fae\u5f31\u524d\u5bfc\u4fe1\u53f7\uff0c\u63d0\u4f9b\u5728\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u9c81\u68d2\u65e0\u76d1\u7763\u5f02\u5e38\u9884\u6d4b\u3002"}}
{"id": "2511.20066", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20066", "abs": "https://arxiv.org/abs/2511.20066", "authors": ["Bhavya Sukhija", "Lenart Treven", "Carmelo Sferrazza", "Florian D\u00f6rfler", "Pieter Abbeel", "Andreas Krause"], "title": "SOMBRL: Scalable and Optimistic Model-Based RL", "comment": null, "summary": "We address the challenge of efficient exploration in model-based reinforcement learning (MBRL), where the system dynamics are unknown and the RL agent must learn directly from online interactions. We propose Scalable and Optimistic MBRL (SOMBRL), an approach based on the principle of optimism in the face of uncertainty. SOMBRL learns an uncertainty-aware dynamics model and greedily maximizes a weighted sum of the extrinsic reward and the agent's epistemic uncertainty. SOMBRL is compatible with any policy optimizers or planners, and under common regularity assumptions on the system, we show that SOMBRL has sublinear regret for nonlinear dynamics in the (i) finite-horizon, (ii) discounted infinite-horizon, and (iii) non-episodic settings. Additionally, SOMBRL offers a flexible and scalable solution for principled exploration. We evaluate SOMBRL on state-based and visual-control environments, where it displays strong performance across all tasks and baselines. We also evaluate SOMBRL on a dynamic RC car hardware and show SOMBRL outperforms the state-of-the-art, illustrating the benefits of principled exploration for MBRL.", "AI": {"tldr": "\u63d0\u51fa SOMBRL\uff0c\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u57fa\u4e8e\u4e50\u89c2\u539f\u7406\u7684\u6a21\u578b\u57fa\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002\u901a\u8fc7\u5b66\u4e60\u5e26\u4e0d\u786e\u5b9a\u6027\u7684\u52a8\u529b\u5b66\u6a21\u578b\u5e76\u8d2a\u5fc3\u5730\u6700\u5927\u5316\u5916\u5728\u5956\u52b1\u4e0e epistemic \u4e0d\u786e\u5b9a\u6027\u7684\u52a0\u6743\u548c\uff0c\u5b9e\u73b0\u5bf9\u672a\u77e5\u7cfb\u7edf\u7684\u9ad8\u6548\u63a2\u7d22\uff0c\u5728\u591a\u79cd\u8bbe\u7f6e\u4e0b\u5177\u6709 sublinear regret\uff0c\u5e76\u5728\u4eff\u771f\u4e0e\u786c\u4ef6\u5e73\u53f0\u4e0a\u5c55\u73b0\u5f3a\u52b2\u6027\u80fd\u3002", "motivation": "\u5728\u6a21\u578b\u672a\u77e5\u4e14\u9700\u5728\u7ebf\u4ea4\u4e92\u5b66\u4e60\u7684\u6a21\u578b\u57fa\u5f3a\u5316\u5b66\u4e60\uff08MBRL\uff09\u4e2d\uff0c\u63a2\u7d22\u6548\u7387\u548c\u6837\u672c\u6548\u7387\u53d7\u9650\u3002\u9700\u8981\u4e00\u79cd\u7406\u8bba\u4e0a\u6709\u754c\u3001\u53ef\u6269\u5c55\u4e14\u80fd\u6709\u6548\u63a2\u7d22\u7684\u7b56\u7565\u6765\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u4e0e\u590d\u6742\u52a8\u529b\u5b66\u3002", "method": "\u57fa\u4e8e\u4e50\u89c2\u539f\u7406\uff0cSOMBRL \u5b66\u4e60\u4e00\u4e2a\u5e26\u4e0d\u786e\u5b9a\u6027\u7684\u52a8\u529b\u5b66\u6a21\u578b\uff1b\u901a\u8fc7\u5bf9\u5916\u5728\u5956\u52b1\u4e0e epistemic \u4e0d\u786e\u5b9a\u6027\u7684\u52a0\u6743\u548c\u8fdb\u884c\u8d2a\u5fc3\u4f18\u5316\u6765\u89c4\u5212\u6216\u5b66\u4e60\u7b56\u7565\u3002\u8be5\u65b9\u6cd5\u4e0e\u5177\u4f53\u7b56\u7565\u4f18\u5316\u5668/\u89c4\u5212\u5668\u89e3\u8026\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u4efb\u52a1\u8bbe\u7f6e\uff0c\u5728\u5e38\u89c4\u6b63\u5219\u6027\u5047\u8bbe\u4e0b\u53ef\u83b7\u5f97\u5b50\u7ebf\u6027\u8f68\u8ff9\u8bef\u5dee/\u7d2f\u79ef\u5956\u52b1\u7684 regret\u3002", "result": "\u5728\u72b6\u6001\u57fa\u4e0e\u89c6\u89c9\u63a7\u5236\u73af\u5883\u4e2d\uff0cSOMBRL \u5c55\u73b0\u51fa\u4e0e\u57fa\u7ebf\u76f8\u6bd4\u66f4\u5f3a\u7684\u63a2\u7d22\u6548\u7387\u4e0e\u4efb\u52a1\u6027\u80fd\uff1b\u5728\u52a8\u6001 RC \u5c0f\u8f66\u7684\u786c\u4ef6\u5b9e\u9a8c\u4e2d\u4e5f\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u4f53\u73b0\u4e86\u57fa\u4e8e\u4e0d certainty \u7684\u63a2\u7d22\u7b56\u7565\u7684\u73b0\u5b9e\u6548\u7528\u3002", "conclusion": "SOMBRL \u63d0\u4f9b\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u7406\u8bba\u6027\u5f3a\u7684\u63a2\u7d22\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u79cd MBRL \u573a\u666f\uff0c\u7406\u8bba\u4fdd\u8bc1\u4e0e\u5b9e\u9a8c\u7ed3\u679c\u5171\u540c\u652f\u6491\u5176\u5728\u63d0\u5347\u63a2\u7d22\u6548\u7387\u548c\u957f\u671f\u56de\u62a5\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.20099", "categories": ["cs.LG", "cs.AR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.20099", "abs": "https://arxiv.org/abs/2511.20099", "authors": ["Lei Huang", "Rui Zhang", "Jiaming Guo", "Yang Zhang", "Di Huang", "Shuyao Cheng", "Pengwei Jin", "Chongxiao Li", "Zidong Du", "Xing Hu", "Qi Guo", "Yunji Chen"], "title": "QiMeng-CRUX: Narrowing the Gap between Natural Language and Verilog via Core Refined Understanding eXpression", "comment": "Accepted by the AAAI26 Conference Main Track", "summary": "Large language models (LLMs) have shown promising capabilities in hardware description language (HDL) generation. However, existing approaches often rely on free-form natural language descriptions that are often ambiguous, redundant, and unstructured, which poses significant challenges for downstream Verilog code generation. We treat hardware code generation as a complex transformation from an open-ended natural language space to a domain-specific, highly constrained target space. To bridge this gap, we introduce Core Refined Understanding eXpression (CRUX), a structured intermediate space that captures the essential semantics of user intent while organizing the expression for precise Verilog code generation. We further design a two-stage training framework, comprising Joint Expression Modeling and Dual-Space Optimization, to enhance the quality of both CRUX and Verilog code. Experiments across multiple Verilog generation benchmarks demonstrate that our model, CRUX-V, achieves state-of-the-art performance among general models, particularly under challenging design tasks. Furthermore, the CRUX space proves transferable and beneficial when used as input prompts for other code models, highlighting its effectiveness in narrowing the gap between free-form natural language descriptions and precise Verilog generation.", "AI": {"tldr": "\u63d0\u51fa CRUX \u4f5c\u4e3a\u4e00\u4e2a\u7ed3\u6784\u5316\u4e2d\u95f4\u8868\u793a\uff0c\u7528\u4ee5\u628a\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u8f6c\u6362\u4e3a Verilog \u4ee3\u7801\uff0c\u5e76\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u63d0\u5347 CRUX \u4e0e Verilog \u751f\u6210\u8d28\u91cf\uff0cCRUX-V \u5728\u591a\u9879\u57fa\u51c6\u4e0a\u8fbe\u5230 SOTA \u5e76\u53ef\u4f5c\u4e3a\u5176\u4ed6\u6a21\u578b\u7684\u63d0\u793a\u7a7a\u95f4\u3002", "motivation": "\u81ea\u7531\u6587\u672c\u63cf\u8ff0\u5f80\u5f80\u542b\u7cca\u3001\u5197\u4f59\u4e14\u65e0\u7ed3\u6784\uff0c\u96be\u4ee5\u76f4\u63a5\u751f\u6210\u51c6\u786e\u7684 Verilog \u4ee3\u7801\uff1b\u9700\u8981\u4e00\u4e2a\u65e2\u4fdd\u7559\u7528\u6237\u610f\u56fe\u53c8\u4fbf\u4e8e\u673a\u5668\u63a8\u7406\u7684\u4e2d\u95f4\u8868\u793a\u3002", "method": "\u63d0\u51fa CRUX \u4f5c\u4e3a\u7ed3\u6784\u5316\u8868\u8fbe\u7684\u4e2d\u95f4\u7a7a\u95f4\uff0c\u6355\u6349\u7528\u6237\u610f\u56fe\u7684\u672c\u8d28\u8bed\u4e49\u5e76\u7ec4\u7ec7\u8868\u8fbe\u4ee5\u5b9e\u73b0\u7cbe\u51c6\u7684 Verilog \u4ee3\u7801\u751f\u6210\u3002\u8bbe\u8ba1\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a\u8054\u5408\u8868\u8fbe\u5efa\u6a21\uff08Joint Expression Modeling\uff09\u548c\u53cc\u7a7a\u95f4\u4f18\u5316\uff08Dual-Space Optimization\uff09\uff0c\u4ee5\u63d0\u5347 CRUX \u548c Verilog \u4ee3\u7801\u7684\u8d28\u91cf\u3002", "result": "\u5728\u591a\u4e2a Verilog \u751f\u6210\u57fa\u51c6\u4e0a\uff0cCRUX-V \u76f8\u6bd4\u901a\u7528\u6a21\u578b\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5c24\u5176\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\u3002CRUX \u7a7a\u95f4\u5728\u4f5c\u4e3a\u5176\u4ed6\u4ee3\u7801\u6a21\u578b\u7684\u8f93\u5165\u63d0\u793a\u65f6\u4e5f\u5177\u5907\u53ef\u79fb\u690d\u6027\u4e0e\u9644\u52a0\u6536\u76ca\uff0c\u8bc1\u660e\u5176\u5728\u7f29\u5c0f\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u4e0e Verilog \u751f\u6210\u4e4b\u95f4\u7684\u5dee\u8ddd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "CRUX \u63d0\u4f9b\u4e00\u79cd\u53ef\u8fc1\u79fb\u3001\u63d0\u9ad8 HDL \u751f\u6210\u7684\u7ed3\u6784\u5316\u4e2d\u95f4\u8868\u793a\uff0c\u4e14\u53ef\u4f5c\u4e3a\u66f4\u5e7f\u6cdb\u6a21\u578b\u7684\u63d0\u793a\u7a7a\u95f4\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347 HDL \u81ea\u52a8\u751f\u6210\u7684\u6548\u679c\u3002"}}
{"id": "2511.20105", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20105", "abs": "https://arxiv.org/abs/2511.20105", "authors": ["Grzegorz Dudek", "Mateusz Kasprzyk", "Pawe\u0142 Pe\u0142ka"], "title": "Multivariate Forecasting of Bitcoin Volatility with Gradient Boosting: Deterministic, Probabilistic, and Feature Importance Perspectives", "comment": null, "summary": "This study investigates the application of the Light Gradient Boosting Machine (LGBM) model for both deterministic and probabilistic forecasting of Bitcoin realized volatility. Utilizing a comprehensive set of 69 predictors -- encompassing market, behavioral, and macroeconomic indicators -- we evaluate the performance of LGBM-based models and compare them with both econometric and machine learning baselines. For probabilistic forecasting, we explore two quantile-based approaches: direct quantile regression using the pinball loss function, and a residual simulation method that transforms point forecasts into predictive distributions. To identify the main drivers of volatility, we employ gain-based and permutation feature importance techniques, consistently highlighting the significance of trading volume, lagged volatility measures, investor attention, and market capitalization. The results demonstrate that LGBM models effectively capture the nonlinear and high-variance characteristics of cryptocurrency markets while providing interpretable insights into the underlying volatility dynamics.", "AI": {"tldr": "\u7528 LightGBM \u5bf9\u6bd4\u7ecf\u6d4e\u5b66\u4e0e\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\uff0c\u8fdb\u884c\u6bd4\u7279\u5e01\u5b9e\u73b0\u6ce2\u52a8\u7387\u7684\u70b9\u9884\u6d4b\u4e0e\u5206\u4f4d\u6570\u9884\u6d4b\uff0c\u4f7f\u7528 69 \u4e2a\u9884\u6d4b\u56e0\u5b50\uff0c\u63ed\u793a\u4ea4\u6613\u91cf\u3001\u6ede\u540e\u6ce2\u52a8\u3001\u6295\u8d44\u8005\u5173\u6ce8\u4e0e\u5e02\u503c\u7b49\u4e3a\u4e3b\u8981\u9a71\u52a8\u3002", "motivation": "\u5728\u9ad8\u5ea6\u975e\u7ebf\u6027\u3001\u5f3a\u6ce2\u52a8\u6027\u7279\u5f81\u7684\u52a0\u5bc6\u5e02\u573a\u4e2d\uff0c\u4f20\u7edf\u6a21\u578b\u53ef\u80fd\u4e0d\u8db3\u4ee5\u6355\u6349\u590d\u6742\u5173\u7cfb\uff0cLight Gradient Boosting Machine \u5177\u5907\u5904\u7406\u975e\u7ebf\u6027\u4e0e\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u7684\u6f5c\u529b\uff1b\u540c\u65f6\u63a2\u7d22\u4e24\u7c7b\u6982\u7387\u9884\u6d4b\u9014\u5f84\u4ee5\u751f\u6210\u9884\u6d4b\u533a\u95f4\u3002", "method": "\u91c7\u7528 69 \u4e2a\u5e02\u573a\u3001\u884c\u4e3a\u4e0e\u5b8f\u89c2\u6307\u6807\u4f5c\u4e3a\u8f93\u5165\uff0c\u5bf9\u5b9e\u73b0\u6ce2\u52a8\u7387\u8fdb\u884c\u70b9\u9884\u6d4b\u548c\u5206\u4f4d\u6570\u9884\u6d4b\uff1b\u6982\u7387\u9884\u6d4b\u5305\u62ec\u76f4\u63a5\u5206\u4f4d\u56de\u5f52\uff08binary/ pinball \u635f\u5931\u51fd\u6570\uff09\u4ee5\u53ca\u901a\u8fc7\u6b8b\u5dee\u4eff\u771f\u5c06\u70b9\u9884\u6d4b\u8f6c\u5316\u4e3a\u9884\u6d4b\u5206\u5e03\uff1b\u901a\u8fc7\u589e\u76ca\u57fa\u548c\u7f6e\u6362\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u6765\u8bc6\u522b\u4e3b\u5bfc\u56e0\u7d20\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cLightGBM \u80fd\u6709\u6548\u6355\u6349\u52a0\u5bc6\u5e02\u573a\u7684\u975e\u7ebf\u6027\u548c\u9ad8\u6ce2\u52a8\u6027\u7279\u5f81\uff1b\u5728\u6982\u7387\u9884\u6d4b\u65b9\u9762\uff0c\u4e24\u79cd\u65b9\u6cd5\u5747\u80fd\u751f\u6210\u6709\u7528\u7684\u9884\u6d4b\u5206\u5e03\uff1b\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u4e00\u81f4\u6307\u5411\u4ea4\u6613\u91cf\u3001\u6ede\u540e\u6ce2\u52a8\u3001\u6295\u8d44\u8005\u5173\u6ce8\u4e0e\u5e02\u503c\u7b49\u4e3a\u5173\u952e\u9a71\u52a8\u3002", "conclusion": "LightGBM \u4e3a\u52a0\u5bc6\u5e02\u573a\u6ce2\u52a8\u7387\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u529b\u7684\u5de5\u5177\uff0c\u517c\u5177\u53ef\u89e3\u91ca\u6027\uff0c\u53ef\u7528\u4e8e\u98ce\u9669\u7ba1\u7406\u548c\u4ea4\u6613\u7b56\u7565\u7684\u51b3\u7b56\u652f\u6301\uff0c\u672a\u6765\u53ef\u6269\u5c55\u66f4\u591a\u7279\u5f81\u4e0e\u6a21\u578b\u5bf9\u6bd4\u3002"}}
{"id": "2511.20109", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20109", "abs": "https://arxiv.org/abs/2511.20109", "authors": ["Hyeonjae Kim", "Chenyue Li", "Wen Deng", "Mengxi Jin", "Wen Huang", "Mengqian Lu", "Binhang Yuan"], "title": "CLIMATEAGENT: Multi-Agent Orchestration for Complex Climate Data Science Workflows", "comment": "30 pages, 6 figures, 3 tables", "summary": "Climate science demands automated workflows to transform comprehensive questions into data-driven statements across massive, heterogeneous datasets. However, generic LLM agents and static scripting pipelines lack climate-specific context and flexibility, thus, perform poorly in practice. We present ClimateAgent, an autonomous multi-agent framework that orchestrates end-to-end climate data analytic workflows. ClimateAgent decomposes user questions into executable sub-tasks coordinated by an Orchestrate-Agent and a Plan-Agent; acquires data via specialized Data-Agents that dynamically introspect APIs to synthesize robust download scripts; and completes analysis and reporting with a Coding-Agent that generates Python code, visualizations, and a final report with a built-in self-correction loop. To enable systematic evaluation, we introduce Climate-Agent-Bench-85, a benchmark of 85 real-world tasks spanning atmospheric rivers, drought, extreme precipitation, heat waves, sea surface temperature, and tropical cyclones. On Climate-Agent-Bench-85, ClimateAgent achieves 100% task completion and a report quality score of 8.32, outperforming GitHub-Copilot (6.27) and a GPT-5 baseline (3.26). These results demonstrate that our multi-agent orchestration with dynamic API awareness and self-correcting execution substantially advances reliable, end-to-end automation for climate science analytic tasks.", "AI": {"tldr": "ClimateAgent\u2014a multi-agent framework for end-to-end climate data analytics with dynamic API awareness and self-correction; introduces Climate-Agent-Bench-85; claims superior task completion and report quality.", "motivation": "To address climate-specific context gaps in generic LLM agents and static pipelines, enabling robust, automated climate data workflows.", "method": "Architectural design with Orchestrate-Agent, Plan-Agent, Data-Agents that introspect APIs to generate download scripts, and Coding-Agent for code, visualizations, and reports; built-in self-correction loop; introduces Climate-Agent-Bench-85 benchmark across climate tasks.", "result": "On Climate-Agent-Bench-85, achieved 100% task completion and a report quality score of 8.32; outperformed GitHub-Copilot (6.27) and GPT-5 baseline (3.26).", "conclusion": "Demonstrates that multi-agent orchestration with dynamic API awareness and self-correcting execution significantly advances reliable, end-to-end climate data analytics."}}
{"id": "2511.20168", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20168", "abs": "https://arxiv.org/abs/2511.20168", "authors": ["Riccardo Zaccone", "Sai Praneeth Karimireddy", "Carlo Masone"], "title": "On the Limits of Momentum in Decentralized and Federated Optimization", "comment": "Accepted at the 17th Workshop on Optimization for Machine Learning (OPT@NeurIPS2025)", "summary": "Recent works have explored the use of momentum in local methods to enhance distributed SGD. This is particularly appealing in Federated Learning (FL), where momentum intuitively appears as a solution to mitigate the effects of statistical heterogeneity. Despite recent progress in this direction, it is still unclear if momentum can guarantee convergence under unbounded heterogeneity in decentralized scenarios, where only some workers participate at each round. In this work we analyze momentum under cyclic client participation, and theoretically prove that it remains inevitably affected by statistical heterogeneity. Similarly to SGD, we prove that decreasing step-sizes do not help either: in fact, any schedule decreasing faster than $\u0398\\left(1/t\\right)$ leads to convergence to a constant value that depends on the initialization and the heterogeneity bound. Numerical results corroborate the theory, and deep learning experiments confirm its relevance for realistic settings.", "AI": {"tldr": "\u5e26\u52a8\u91cf\u7684\u672c\u5730\u65b9\u6cd5\u5728\u5faa\u73af\u53c2\u4e0e\u7684\u53bb\u4e2d\u5fc3\u5316\u573a\u666f\u4e2d\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u6536\u655b\uff0c\u4e14\u6bd4 1/t \u66f4\u5feb\u4e0b\u964d\u7684\u5b66\u4e60\u7387\u4e5f\u4f1a\u6536\u655b\u5230\u4e0e\u521d\u59cb\u5316\u548c\u5f02\u8d28\u6027\u754c\u76f8\u5173\u7684\u5e38\u6570\u3002", "motivation": "\u7814\u7a76\u5728\u5206\u5e03\u5f0f SGD \u7684\u672c\u5730\u65b9\u6cd5\u4e2d\u5f15\u5165\u52a8\u91cf\u7684\u6548\u679c\uff0c\u7279\u522b\u662f\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u52a8\u91cf\u662f\u5426\u80fd\u7f13\u89e3\u7edf\u8ba1\u5f02\u8d28\u6027\u5e76\u4fdd\u8bc1\u5728\u5f02\u8d28\u6027\u5b58\u5728\u4e0b\u7684\u6536\u655b\u6027\u3002", "method": "\u5bf9\u5e26\u52a8\u91cf\u7684\u5faa\u73af\u53c2\u4e0e\u7684\u53bb\u4e2d\u5fc3\u5316\u8bbe\u7f6e\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u52a8\u91cf\u4f1a\u53d7\u7edf\u8ba1\u5f02\u8d28\u6027\u5f71\u54cd\uff1b\u63a8\u5bfc\u51fa\u82e5\u5b66\u4e60\u7387\u4e0b\u964d\u7684\u901f\u7387\u5feb\u4e8e \u0398(1/t) \u5c06\u5bfc\u81f4\u6536\u655b\u5230\u4e0e\u521d\u59cb\u5316\u548c\u5f02\u8d28\u6027\u4e0a\u754c\u76f8\u5173\u7684\u5e38\u6570\uff1b\u5e76\u901a\u8fc7\u6570\u503c\u7ed3\u679c\u548c\u6df1\u5ea6\u5b66\u4e60\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u8bc1\u660e\u52a8\u91cf\u5728\u5faa\u73af\u53c2\u4e0e\u4e0b\u4ecd\u53d7\u5f02\u8d28\u6027\u5f71\u54cd\uff1b\u4efb\u610f\u5feb\u4e8e 1/t \u7684\u4e0b\u964d\u5e8f\u5217\u5bfc\u81f4\u6536\u655b\u5230\u4f9d\u8d56\u521d\u59cb\u503c\u548c\u5f02\u8d28\u6027\u4e0a\u754c\u7684\u5e38\u6570\uff1b\u6570\u503c\u4e0e\u6df1\u5ea6\u5b66\u4e60\u5b9e\u9a8c\u652f\u6301\u7406\u8bba\u3002", "conclusion": "\u5728\u5177\u6709\u5faa\u73af\u5ba2\u6237\u7aef\u53c2\u4e0e\u7684\u53bb\u4e2d\u5fc3\u5316\u8bbe\u7f6e\u4e2d\uff0c\u52a8\u91cf\u5e76\u4e0d\u80fd\u514b\u670d\u7edf\u8ba1\u5f02\u8d28\u6027\u5bf9\u6536\u655b\u6027\u7684\u5f71\u54cd\uff1b\u8981\u5b9e\u73b0\u6536\u655b\uff0c\u9700\u8981\u989d\u5916\u7684\u65b9\u6cd5\u6216\u5bf9\u5b66\u4e60\u7387\u7684\u66f4\u8c28\u614e\u63a7\u5236\uff0c\u7279\u522b\u662f\u8d85\u8fc7 1/t \u9608\u503c\u7684\u4e0b\u964d\u5e76\u4e0d\u6709\u5229\u3002"}}
{"id": "2511.20189", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20189", "abs": "https://arxiv.org/abs/2511.20189", "authors": ["Lincen Yang", "Zhong Li", "Matthijs van Leeuwen", "Saber Salehkaleybar"], "title": "Learning Subgroups with Maximum Treatment Effects without Causal Heuristics", "comment": "The full version (including the Appendix). Accepted at AAAI 2026", "summary": "Discovering subgroups with the maximum average treatment effect is crucial for targeted decision making in domains such as precision medicine, public policy, and education. While most prior work is formulated in the potential outcome framework, the corresponding structural causal model (SCM) for this task has been largely overlooked. In practice, two approaches dominate. The first estimates pointwise conditional treatment effects and then fits a tree on those estimates, effectively turning subgroup estimation into the harder problem of accurate pointwise estimation. The second constructs decision trees or rule sets with ad-hoc 'causal' heuristics, typically without rigorous justification for why a given heuristic may be used or whether such heuristics are necessary at all. We address these issues by studying the problem directly under the SCM framework. Under the assumption of a partition-based model, we show that optimal subgroup discovery reduces to recovering the data-generating models and hence a standard supervised learning problem (regression or classification). This allows us to adopt any partition-based methods to learn the subgroup from data. We instantiate the approach with CART, arguably one of the most widely used tree-based methods, to learn the subgroup with maximum treatment effect. Finally, on a large collection of synthetic and semi-synthetic datasets, we compare our method against a wide range of baselines and find that our approach, which avoids such causal heuristics, more accurately identifies subgroups with maximum treatment effect. Our source code is available at https://github.com/ylincen/causal-subgroup.", "AI": {"tldr": "\u5c06\u6700\u5927\u5e73\u5747\u5904\u7406\u6548\u679c\u7684\u5b50\u7ec4\u53d1\u73b0\u8fc1\u79fb\u5230\u5206\u5272\u578b\u6a21\u578b\u4e0b\uff0c\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u6807\u51c6\u76d1\u7763\u5b66\u4e60\uff0c\u4ece\u800c\u53ef\u7528 CART \u7b49\u5206\u5272\u65b9\u6cd5\u76f4\u63a5\u5b66\u4e60\u5177\u6709\u6700\u5927\u5904\u7406\u6548\u5e94\u7684\u5b50\u7ec4\uff1b\u5b9e\u9a8c\u8bc1\u660e\u4f18\u4e8e\u591a\u79cd\u57fa\u7ebf\uff0c\u4e14\u907f\u514d\u56e0\u679c\u542f\u53d1\u5f0f\u3002", "motivation": "\u5728\u56e0\u679c\u63a8\u65ad\u7684\u6f5c\u5728\u7ed3\u679c\u6846\u67b6\u4e0b\uff0c\u6700\u5927\u6cbb\u7597\u6548\u5e94\u5b50\u7ec4\u53d1\u73b0\u5e38\u53d7\u9650\u4e8e\u70b9\u4f30\u8ba1\u540e\u518d\u62df\u5408\u6811\u6216\u4f9d\u8d56\u5570\u55e6\u7684\u56e0\u679c\u542f\u53d1\u5f0f\u65b9\u6cd5\uff1b\u9700\u8981\u4e00\u4e2a\u57fa\u4e8e\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u3001\u5206\u5272\u578b\u5047\u8bbe\u7684\u7cfb\u7edf\u6027\u65b9\u6cd5\u6765\u5b9a\u4f4d\u9ad8\u6548\u7684\u5b50\u7ec4\u3002", "method": "\u5728\u5206\u5272\u578b\uff08partition-based\uff09\u6a21\u578b\u5047\u8bbe\u4e0b\uff0c\u6700\u4f18\u5b50\u7ec4\u53d1\u73b0\u7b49\u4ef7\u4e8e\u6062\u590d\u6570\u636e\u4ea7\u751f\u7684\u6a21\u578b\uff0c\u56e0\u6b64\u53ef\u89c6\u4e3a\u6807\u51c6\u7684\u56de\u5f52/\u5206\u7c7b\u5b66\u4e60\u95ee\u9898\uff1b\u56e0\u6b64\u53ef\u4ee5\u91c7\u7528\u73b0\u6709\u7684\u5206\u5272\u65b9\u6cd5\u6765\u5b66\u4e60\u5b50\u7ec4\u3002\u672c\u8bba\u6587\u4ee5 CART \u4e3a\u4f8b\u6765\u5b66\u4e60\u6700\u5927\u6cbb\u7597\u6548\u5e94\u7684\u5b50\u7ec4\u3002", "result": "\u5728\u5927\u91cf\u5408\u6210\u548c\u534a\u5408\u6210\u6570\u636e\u96c6\u4e0a\uff0c\u4e0e\u5e7f\u6cdb\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u56e0\u679c\u542f\u53d1\u5f0f\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8bc6\u522b\u5177\u6709\u6700\u5927\u6cbb\u7597\u6548\u5e94\u7684\u5b50\u7ec4\u3002", "conclusion": "\u57fa\u4e8e SCM \u7684\u5206\u5272\u578b\u5b50\u7ec4\u53d1\u73b0\u63d0\u4f9b\u4e00\u79cd\u65e0\u987b\u989d\u5916\u56e0\u679c\u542f\u53d1\u5f0f\u7684\u901a\u7528\u6846\u67b6\uff0c\u80fd\u591f\u5229\u7528\u73b0\u6709\u7684\u6811\u65b9\u6cd5\u63d0\u5347\u5b50\u7ec4\u53d1\u73b0\u7684\u6027\u80fd\uff0c\u4e14\u4ee3\u7801\u53ef\u7528\u3002"}}
{"id": "2511.20194", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20194", "abs": "https://arxiv.org/abs/2511.20194", "authors": ["Wei Chen", "Jingxi Yu", "Zichen Miao", "Qiang Qiu"], "title": "In-Context Compositional Learning via Sparse Coding Transformer", "comment": "NeurIPS 2025", "summary": "Transformer architectures have achieved remarkable success across language, vision, and multimodal tasks, and there is growing demand for them to address in-context compositional learning tasks. In these tasks, models solve the target problems by inferring compositional rules from context examples, which are composed of basic components structured by underlying rules. However, some of these tasks remain challenging for Transformers, which are not inherently designed to handle compositional tasks and offer limited structural inductive bias. In this work, inspired by the principle of sparse coding, we propose a reformulation of the attention to enhance its capability for compositional tasks. In sparse coding, data are represented as sparse combinations of dictionary atoms with coefficients that capture their compositional rules. Specifically, we reinterpret the attention block as a mapping of inputs into outputs through projections onto two sets of learned dictionary atoms: an encoding dictionary and a decoding dictionary. The encoding dictionary decomposes the input into a set of coefficients, which represent the compositional structure of the input. To enhance structured representations, we impose sparsity on these coefficients. The sparse coefficients are then used to linearly combine the decoding dictionary atoms to generate the output. Furthermore, to assist compositional generalization tasks, we propose estimating the coefficients of the target problem as a linear combination of the coefficients obtained from the context examples. We demonstrate the effectiveness of our approach on the S-RAVEN and RAVEN datasets. For certain compositional generalization tasks, our method maintains performance even when standard Transformers fail, owing to its ability to learn and apply compositional rules.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u6ce8\u610f\u529b\u91cd\u6784\u4e3a\u7a00\u758f\u7f16\u7801\u6846\u67b6\u7684\u5b57\u5178\u5206\u89e3\uff0c\u4ee5\u83b7\u5f97\u66f4\u5f3a\u7684\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5728 S-RAVEN/RAVEN \u4e0a\u8868\u73b0\u51fa\u5bf9\u67d0\u4e9b\u7ec4\u5408\u6cdb\u5316\u4efb\u52a1\u7684\u9c81\u68d2\u6027\u3002", "motivation": "Transformer \u7f3a\u4e4f\u5904\u7406\u7ec4\u5408\u7ed3\u6784\u4efb\u52a1\u7684\u56fa\u6709\u7ed3\u6784\u6027\u5f52\u7eb3\u504f\u7f6e\uff0c\u9700\u63d0\u5347\u5bf9\u7ec4\u5408\u89c4\u5219\u7684\u5b66\u4e60\u548c\u5e94\u7528\u80fd\u529b\u3002", "method": "\u5c06\u6ce8\u610f\u529b\u6620\u5c04\u89c6\u4e3a\u5bf9\u8f93\u5165\u5728\u7f16\u7801\u5b57\u5178\u548c\u89e3\u7801\u5b57\u5178\u4e0a\u7684\u6295\u5f71\uff0c\u5f3a\u5236\u7cfb\u6570\u7a00\u758f\uff1b\u7528\u4e0a\u4e0b\u6587\u793a\u4f8b\u7684\u7cfb\u6570\u7ebf\u6027\u7ec4\u5408\u6765\u4f30\u8ba1\u76ee\u6807\u95ee\u9898\u7684\u7cfb\u6570\uff1b\u8f93\u51fa\u901a\u8fc7\u89e3\u7801\u5b57\u5178\u7684\u7ebf\u6027\u7ec4\u5408\u4ea7\u751f\u3002", "result": "\u5728\u67d0\u4e9b\u7ec4\u5408\u6cdb\u5316\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301 Transformer \u539f\u6709\u6027\u80fd\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86\u5bf9\u7ec4\u5408\u89c4\u5219\u7684\u5b66\u4e60\u4e0e\u5e94\u7528\u80fd\u529b\uff0c\u4e14\u5728 S-RAVEN/RAVEN \u4e0a\u8868\u73b0\u6709\u7ade\u4e89\u529b\uff0c\u5c24\u5176\u5728\u6807\u51c6 Transformer \u65e0\u6cd5\u5f88\u597d\u6cdb\u5316\u7684\u573a\u666f\u3002", "conclusion": "\u7a00\u758f\u7f16\u7801\u98ce\u683c\u7684\u6ce8\u610f\u529b\u63d0\u5347\u4e86\u7ed3\u6784\u5316\u8868\u793a\u548c\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\uff0c\u663e\u793a\u51fa\u5728 S-RAVEN/RAVEN \u8fd9\u7c7b\u57fa\u51c6\u4e0a\u7684\u6f5c\u529b\uff0c\u8868\u660e\u672a\u6765\u5c06\u7ed3\u6784\u6027\u504f\u7f6e\u5f15\u5165\u6ce8\u610f\u529b\u53ef\u80fd\u662f\u63d0\u5347\u6cdb\u5316\u7684\u6709\u6548\u65b9\u5411\u3002"}}
{"id": "2511.20234", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20234", "abs": "https://arxiv.org/abs/2511.20234", "authors": ["Olivier Moulin", "Vincent Francois-lavet", "Paul Elbers", "Mark Hoogendoorn"], "title": "Leveraging weights signals - Predicting and improving generalizability in reinforcement learning", "comment": null, "summary": "Generalizability of Reinforcement Learning (RL) agents (ability to perform on environments different from the ones they have been trained on) is a key problem as agents have the tendency to overfit to their training environments. In order to address this problem and offer a solution to increase the generalizability of RL agents, we introduce a new methodology to predict the generalizability score of RL agents based on the internal weights of the agent's neural networks. Using this prediction capability, we propose some changes in the Proximal Policy Optimization (PPO) loss function to boost the generalization score of the agents trained with this upgraded version. Experimental results demonstrate that our improved PPO algorithm yields agents with stronger generalizability compared to the original version.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.20257", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20257", "abs": "https://arxiv.org/abs/2511.20257", "authors": ["Zhiguo Zhang", "Xiaoliang Ma", "Daniel Schlesinger"], "title": "Interpretable Air Pollution Forecasting by Physics-Guided Spatiotemporal Decoupling", "comment": "Accepted to 2025 IEEE International Conference on Big Data", "summary": "Accurate and interpretable air pollution forecasting is crucial for public health, but most models face a trade-off between performance and interpretability. This study proposes a physics-guided, interpretable-by-design spatiotemporal learning framework. The model decomposes the spatiotemporal behavior of air pollutant concentrations into two transparent, additive modules. The first is a physics-guided transport kernel with directed weights conditioned on wind and geography (advection). The second is an explainable attention mechanism that learns local responses and attributes future concentrations to specific historical lags and exogenous drivers. Evaluated on a comprehensive dataset from the Stockholm region, our model consistently outperforms state-of-the-art baselines across multiple forecasting horizons. Our model's integration of high predictive performance and spatiotemporal interpretability provides a more reliable foundation for operational air-quality management in real-world applications.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.20273", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20273", "abs": "https://arxiv.org/abs/2511.20273", "authors": ["Areeb Ahmad", "Abhinav Joshi", "Ashutosh Modi"], "title": "Beyond Components: Singular Vector-Based Interpretability of Transformer Circuits", "comment": "Accepted at NeurIPS 2025", "summary": "Transformer-based language models exhibit complex and distributed behavior, yet their internal computations remain poorly understood. Existing mechanistic interpretability methods typically treat attention heads and multilayer perceptron layers (MLPs) (the building blocks of a transformer architecture) as indivisible units, overlooking possibilities of functional substructure learned within them. In this work, we introduce a more fine-grained perspective that decomposes these components into orthogonal singular directions, revealing superposed and independent computations within a single head or MLP. We validate our perspective on widely used standard tasks like Indirect Object Identification (IOI), Gender Pronoun (GP), and Greater Than (GT), showing that previously identified canonical functional heads, such as the name mover, encode multiple overlapping subfunctions aligned with distinct singular directions. Nodes in a computational graph, that are previously identified as circuit elements show strong activation along specific low-rank directions, suggesting that meaningful computations reside in compact subspaces. While some directions remain challenging to interpret fully, our results highlight that transformer computations are more distributed, structured, and compositional than previously assumed. This perspective opens new avenues for fine-grained mechanistic interpretability and a deeper understanding of model internals.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.20277", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20277", "abs": "https://arxiv.org/abs/2511.20277", "authors": ["Yiheng Zhang", "Shaowu Wu", "Yuanzhuo Xu", "Jiajun Wu", "Shang Xu", "Steve Drew", "Xiaoguang Niu"], "title": "HVAdam: A Full-Dimension Adaptive Optimizer", "comment": null, "summary": "Adaptive optimizers such as Adam have achieved great success in training large-scale models like large language models and diffusion models. However, they often generalize worse than non-adaptive methods, such as SGD on classical architectures like CNNs. We identify a key cause of this performance gap: adaptivity in pre-conditioners, which limits the optimizer's ability to adapt to diverse optimization landscapes. To address this, we propose Anon (Adaptivity Non-restricted Optimizer with Novel convergence technique), a novel optimizer with continuously tunable adaptivity\n  , allowing it to interpolate between SGD-like and Adam-like behaviors and even extrapolate beyond both. To ensure convergence across the entire adaptivity spectrum, we introduce incremental delay update (IDU), a novel mechanism that is more flexible than AMSGrad's hard max-tracking strategy and enhances robustness to gradient noise. We theoretically establish convergence guarantees under both convex and non-convex settings. Empirically, Anon consistently outperforms state-of-the-art optimizers on representative image classification, diffusion, and language modeling tasks. These results demonstrate that adaptivity can serve as a valuable tunable design principle, and Anon provides the first unified and reliable framework capable of bridging the gap between classical and modern optimizers and surpassing their advantageous properties.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u8fde\u7eed\u8c03\u8282\u81ea\u9002\u5e94\u6027\u7684\u4f18\u5316\u5668Anon\uff0c\u5e76\u901a\u8fc7\u589e\u91cf\u5ef6\u8fdf\u66f4\u65b0(IDU)\u5b9e\u73b0\u5bf9SGD\u548cAdam\u7684\u63d2\u503c\uff0c\u5177\u5907\u7406\u8bba\u6536\u655b\u6027\u5e76\u5728\u591a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u4f18\u5316\u5668\u3002", "motivation": "\u89e3\u51b3\u81ea\u9002\u5e94\u4f18\u5316\u5668\u5728\u6cdb\u5316\u65b9\u9762\u901a\u5e38\u4e0d\u5982SGD\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u524d\u7f6e\u9884\u6761\u4ef6\u4e2d\u7684\u81ea\u9002\u5e94\u6027\u9650\u5236\u4e86\u5728\u4e0d\u540c\u4f18\u5316\u666f\u89c2\u4e2d\u7684\u9002\u5e94\u6027\uff1b\u9700\u8981\u4e00\u4e2a\u81ea\u9002\u5e94\u6027\u53ef\u63a7\u4e14\u5177\u6709\u9c81\u68d2\u6027\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u8bbe\u8ba1Anon\uff0c\u4f7f\u81ea\u9002\u5e94\u6027\u5728SGD-like\u548cAdam-like\u884c\u4e3a\u4e4b\u95f4\u8fde\u7eed\u63d2\u503c\uff0c\u751a\u81f3\u53ef\u8d85\u8d8a\u4e24\u8005\uff1b\u5f15\u5165\u589e\u91cf\u5ef6\u8fdf\u66f4\u65b0(IDU)\uff0c\u76f8\u6bd4AMSGrad\u7684\u786c\u6700\u5927\u8ddf\u8e2a\u66f4\u7075\u6d3b\uff0c\u63d0\u5347\u5bf9\u68af\u5ea6\u566a\u58f0\u7684\u9c81\u68d2\u6027\u3002", "result": "\u7406\u8bba\u5c42\u9762\uff0c\u5728\u51f8\u548c\u975e\u51f8\u8bbe\u5b9a\u4e0b\u5747\u53ef\u8bc1\u660e\u6536\u655b\uff1b\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\uff0c\u5728\u56fe\u50cf\u5206\u7c7b\u3001\u6269\u6563\u6a21\u578b\u548c\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u4f18\u5316\u5668\u3002", "conclusion": "\u81ea\u9002\u5e94\u6027\u662f\u4e00\u79cd\u53ef\u8c03\u8282\u7684\u8bbe\u8ba1\u539f\u5219\uff0cAnon\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u4e14\u53ef\u9760\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5728\u7ecf\u5178\u4e0e\u73b0\u4ee3\u4f18\u5316\u5668\u4e4b\u95f4\u6865\u63a5\u5e76\u8d85\u8d8a\u5b83\u4eec\u7684\u4f18\u70b9\u3002"}}
{"id": "2511.20315", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20315", "abs": "https://arxiv.org/abs/2511.20315", "authors": ["Abhinav Joshi", "Divyanshu Bhatt", "Ashutosh Modi"], "title": "Geometry of Decision Making in Language Models", "comment": "Accepted at NeurIPS 2025", "summary": "Large Language Models (LLMs) show strong generalization across diverse tasks, yet the internal decision-making processes behind their predictions remain opaque. In this work, we study the geometry of hidden representations in LLMs through the lens of \\textit{intrinsic dimension} (ID), focusing specifically on decision-making dynamics in a multiple-choice question answering (MCQA) setting. We perform a large-scale study, with 28 open-weight transformer models and estimate ID across layers using multiple estimators, while also quantifying per-layer performance on MCQA tasks. Our findings reveal a consistent ID pattern across models: early layers operate on low-dimensional manifolds, middle layers expand this space, and later layers compress it again, converging to decision-relevant representations. Together, these results suggest LLMs implicitly learn to project linguistic inputs onto structured, low-dimensional manifolds aligned with task-specific decisions, providing new geometric insights into how generalization and reasoning emerge in language models.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5728\u591a\u5c42\u53d8\u6362\u6a21\u578b\u4e2d\u4f30\u8ba1\u201c\u5185\u5728\u7ef4\u5ea6\u201d\uff08ID\uff09\uff0c\u63ed\u793aMCQA\u4efb\u52a1\u4e2d\u9690\u85cf\u8868\u793a\u7684\u51e0\u4f55\u6f14\u5316\uff1a\u65e9\u5c42\u5904\u4e8e\u4f4e\u7ef4\u6d41\u5f62\uff0c\u4e2d\u5c42\u6269\u5f20\uff0c\u540e\u5c42\u6536\u655b\u5230\u4e0e\u51b3\u7b56\u76f8\u5173\u7684\u4f4e\u7ef4\u8868\u793a\u3002", "motivation": "\u63ed\u793aLLMs\u5185\u90e8\u51b3\u7b56\u8fc7\u7a0b\u4e0e\u6cdb\u5316\u80fd\u529b\u7684\u51e0\u4f55\u6839\u6e90\uff0c\u5229\u7528ID\u8fd9\u4e00\u5ea6\u91cf\u63a2\u7d22\u9690\u85cf\u8868\u793a\u5728\u4e0d\u540c\u5c42\u7684\u7ef4\u5ea6\u53d8\u5316\u53ca\u5176\u4e0e\u4efb\u52a1\u51b3\u7b56\u7684\u5173\u7cfb\u3002", "method": "\u5bf928\u4e2a\u5f00\u6e90\u6743\u91cd\u7684Transformer\u6a21\u578b\u8fdb\u884c\u8de8\u5c42ID\u4f30\u8ba1\uff0c\u4f7f\u7528\u591a\u79cdID\u4f30\u8ba1\u5668\uff0c\u5e76\u540c\u65f6\u91cf\u5316\u5404\u5c42\u5728MCQA\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u6bd4\u8f83\u4e0d\u540c\u5c42\u7684\u51e0\u4f55\u7ed3\u6784\u4e0e\u51b3\u7b56\u76f8\u5173\u6027\u3002", "result": "\u5728\u8de8\u6a21\u578b\u7684\u5e7f\u6cdb\u5206\u6790\u4e2d\u89c2\u5bdf\u5230\u4e00\u81f4\u7684ID\u6a21\u5f0f\uff1a\u65e9\u5c42\u5728\u4f4e\u7ef4\u6d41\u5f62\u4e0a\u5de5\u4f5c\uff0c\u4e2d\u5c42\u6269\u5c55\u5176\u8868\u5f81\u7a7a\u95f4\uff0c\u540e\u5c42\u518d\u5ea6\u538b\u7f29\u5e76\u6536\u655b\u81f3\u4e0e\u51b3\u7b56\u76f8\u5173\u7684\u8868\u793a\uff0c\u6307\u793a\u8bed\u8a00\u8f93\u5165\u88ab\u6295\u5f71\u5230\u7ed3\u6784\u5316\u4f4e\u7ef4\u6d41\u5f62\u4ee5\u652f\u6491\u51b3\u7b56\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5728LLMs\u4e2d\u6cdb\u5316\u4e0e\u63a8\u7406\u7684\u51e0\u4f55\u5b9e\u73b0\uff1a\u6a21\u578b\u901a\u8fc7\u5206\u5c42\u7684\u7ef4\u5ea6\u8d70\u5411\uff0c\u5c06\u8f93\u5165\u6620\u5c04\u5230\u4efb\u52a1\u5bf9\u9f50\u7684\u4f4e\u7ef4\u6d41\u5f62\uff0c\u4ece\u800c\u5728MCQA\u7b49\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6709\u6548\u63a8\u7406\u3002"}}
{"id": "2511.20327", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20327", "abs": "https://arxiv.org/abs/2511.20327", "authors": ["Michael Kilgour", "Mark E. Tuckerman", "Jutta Rogal"], "title": "MXtalTools: A Toolkit for Machine Learning on Molecular Crystals", "comment": "16 pages, 11 figures", "summary": "We present MXtalTools, a flexible Python package for the data-driven modelling of molecular crystals, facilitating machine learning studies of the molecular solid state. MXtalTools comprises several classes of utilities: (1) synthesis, collation, and curation of molecule and crystal datasets, (2) integrated workflows for model training and inference, (3) crystal parameterization and representation, (4) crystal structure sampling and optimization, (5) end-to-end differentiable crystal sampling, construction and analysis. Our modular functions can be integrated into existing workflows or combined and used to build novel modelling pipelines. MXtalTools leverages CUDA acceleration to enable high-throughput crystal modelling. The Python code is available open-source on our GitHub page, with detailed documentation on ReadTheDocs.", "AI": {"tldr": "MXtalTools \u662f\u4e00\u4e2a\u6a21\u5757\u5316\u3001CUDA \u52a0\u901f\u7684 Python \u5de5\u5177\u5305\uff0c\u7528\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u5206\u5b50\u6676\u4f53\u5efa\u6a21\u548c\u673a\u5668\u5b66\u4e60\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u5206\u5b50\u6676\u4f53\u5efa\u6a21\u7f3a\u4e4f\u4e00\u4e2a\u7edf\u4e00\u7684\u3001\u53ef\u6269\u5c55\u7684\u6570\u636e\u6574\u7406\u3001\u53c2\u6570\u5316\u3001\u91c7\u6837\u3001\u8bad\u7ec3\u548c\u63a8\u65ad\u7684\u5de5\u4f5c\u6d41\uff0cMXtalTools \u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4fc3\u8fdb\u9ad8\u901a\u91cf\u3001\u7aef\u5230\u7aef\u7684\u6676\u4f53\u7ed3\u6784\u5206\u6790\u4e0e\u5efa\u6a21\u3002", "method": "\u63d0\u4f9b\u6570\u636e\u6536\u96c6\u3001\u6574\u7406\u548c\u53bb\u91cd\u7b49\u6570\u636e\u96c6\u5de5\u4f5c\u6d41\uff1b\u6676\u4f53\u53c2\u6570\u5316\u548c\u8868\u793a\uff1b\u6676\u4f53\u7ed3\u6784\u91c7\u6837\u4e0e\u4f18\u5316\uff1b\u7aef\u5230\u7aef\u53ef\u5fae\u5206\u7684\u6676\u4f53\u91c7\u6837\u3001\u6784\u5efa\u4e0e\u5206\u6790\uff1b\u6a21\u5757\u5316\u51fd\u6570\u53ef\u4e0e\u73b0\u6709\u5de5\u4f5c\u6d41\u96c6\u6210\uff0c\u652f\u6301\u5728 CUDA \u4e0a\u52a0\u901f\u3002", "result": "\u652f\u6301\u9ad8\u541e\u5410\u6676\u4f53\u5efa\u6a21\u3001\u6613\u4e8e\u96c6\u6210\u7684\u65b0\u5efa\u6a21\u7ba1\u7ebf\u3001\u4ee5\u53ca\u53ef\u6269\u5c55\u7684\u673a\u5668\u5b66\u4e60\u7814\u7a76\uff1b\u5f00\u6e90\u4ee3\u7801\u5728 GitHub\uff0c\u6587\u6863\u8be6\u5c3d\u3002", "conclusion": "MXtalTools \u63d0\u4f9b\u4e00\u4e2a\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u4fbf\u4e8e\u7814\u7a76\u8005\u5728\u5206\u5b50\u6676\u4f53\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e2d\u642d\u5efa\u7aef\u5230\u7aef\u5de5\u4f5c\u6d41\uff0c\u4fc3\u8fdb\u6570\u636e\u9a71\u52a8\u7684\u6676\u4f53\u7814\u7a76\u3002"}}
{"id": "2511.20347", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20347", "abs": "https://arxiv.org/abs/2511.20347", "authors": ["Chang Gao", "Chujie Zheng", "Xiong-Hui Chen", "Kai Dang", "Shixuan Liu", "Bowen Yu", "An Yang", "Shuai Bai", "Jingren Zhou", "Junyang Lin"], "title": "Soft Adaptive Policy Optimization", "comment": null, "summary": "Reinforcement learning (RL) plays an increasingly important role in enhancing the reasoning capabilities of large language models (LLMs), yet stable and performant policy optimization remains challenging. Token-level importance ratios often exhibit high variance-a phenomenon exacerbated in Mixture-of-Experts models-leading to unstable updates. Existing group-based policy optimization methods, such as GSPO and GRPO, alleviate this problem via hard clipping, making it difficult to maintain both stability and effective learning. We propose Soft Adaptive Policy Optimization (SAPO), which replaces hard clipping with a smooth, temperature-controlled gate that adaptively attenuates off-policy updates while preserving useful learning signals. Compared with GSPO and GRPO, SAPO is both sequence-coherent and token-adaptive. Like GSPO, SAPO maintains sequence-level coherence, but its soft gating forms a continuous trust region that avoids the brittle hard clipping band used in GSPO. When a sequence contains a few highly off-policy tokens, GSPO suppresses all gradients for that sequence, whereas SAPO selectively down-weights only the offending tokens and preserves the learning signal from the near-on-policy ones, improving sample efficiency. Relative to GRPO, SAPO replaces hard token-level clipping with smooth, temperature-controlled scaling, enabling more informative and stable updates. Empirical results on mathematical reasoning benchmarks indicate that SAPO exhibits improved training stability and higher Pass@1 performance under comparable training budgets. Moreover, we employ SAPO to train the Qwen3-VL model series, demonstrating that SAPO yields consistent performance gains across diverse tasks and different model sizes. Overall, SAPO provides a more reliable, scalable, and effective optimization strategy for RL training of LLMs.", "AI": {"tldr": "Soft Adaptive Policy Optimization (SAPO) replaces hard clipping in group-based policy optimization for RL in LLMs with a temperature-controlled soft gate, improving stability and sample efficiency; it achieves better Pass@1 on math benchmarks and shows gains across Qwen3-VL models.", "motivation": "RL-based training of LLMs suffers from high variance in token-level importance ratios, especially in Mixture-of-Experts models. Hard clipping in GSPO/GRPO discards useful learning signals and hampers stability and sample efficiency.", "method": "Introduce SAPO with a smooth, temperature-controlled gate that adaptively attenuates off-policy updates. SAPO is sequence-coherent and token-adaptive, maintaining a continuous trust region instead of brittle hard clipping. It down-weights offending tokens rather than suppressing entire sequences, preserving learning signals from near on-policy tokens.", "result": "Empirical results on mathematical reasoning benchmarks show improved training stability and higher Pass@1 under similar training budgets. SAPO also yields consistent performance gains across the Qwen3-VL model series for diverse tasks and model sizes.", "conclusion": "SAPO provides a more reliable, scalable, and effective RL optimization strategy for training LLMs."}}
{"id": "2511.20349", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20349", "abs": "https://arxiv.org/abs/2511.20349", "authors": ["M. E. A. Kherchouche", "F. Galpin", "T. Dumas", "F. Schnitzler", "D. Menard", "L. Zhang"], "title": "Complexity Reduction Study Based on RD Costs Approximation for VVC Intra Partitioning", "comment": "2025 Data Compression Conference (DCC)", "summary": "In this paper, a complexity study is conducted for Versatile Video Codec (VVC) intra partitioning to accelerate the exhaustive search involved in Rate-Distortion Optimization (RDO) process. To address this problem, two main machine learning techniques are proposed and compared. Unlike existing methods, the proposed approaches are size independent and incorporate the Rate-Distortion (RD) costs of neighboring blocks as input features. The first method is a regression based technique that predicts normalized RD costs of a given Coding Unit (CU). As partitioning possesses the Markov property, the associated decision-making problem can be modeled as a Markov Decision Process (MDP) and solved by Reinforcement Learning (RL). The second approach is a RL agent learned from trajectories of CU decision across two depths with Deep Q-Network (DQN) algorithm. Then a pre-determined thresholds are applied for both methods to select a suitable split for the current CU.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u9762\u5411VVC intra\u5206\u5272\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4ee5\u52a0\u901fRDO\u641c\u7d22\uff1a\u57fa\u4e8e\u56de\u5f52\u7684RD\u6210\u672c\u9884\u6d4b\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5206\u5272\u51b3\u7b56\uff0c\u5177\u6709\u5c3a\u5bf8\u65e0\u5173\u6027\u5e76\u5229\u7528\u76f8\u90bb\u5757RD\u6210\u672c\u4fe1\u606f\uff0c\u5747\u901a\u8fc7\u9608\u503c\u5b9e\u73b0\u5206\u5272\u9009\u62e9\u3002", "motivation": "\u65e8\u5728\u964d\u4f4eVVC\u4e2dRDO\u7684\u7a77\u4e3e\u641c\u7d22\u8ba1\u7b97\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9CU\u5206\u5272\u7684\u9c81\u68d2\u6027\uff1b\u5e0c\u671b\u65b9\u6cd5\u4e0eCU\u5c3a\u5bf8\u65e0\u5173\u5e76\u5145\u5206\u5229\u7528\u90bb\u8fd1\u5757\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "method": "\u7b2c\u4e00\u79cd\u65b9\u6cd5\uff1a\u56de\u5f52\u9884\u6d4bCU\u7684\u5f52\u4e00\u5316RD\u6210\u672c\uff1b\u7b2c\u4e8c\u79cd\u65b9\u6cd5\uff1a\u5c06\u5206\u5272\u51b3\u7b56\u5efa\u6a21\u4e3aMDP\u5e76\u4f7f\u7528DQN\u8fdb\u884c\u8f68\u8ff9\u5b66\u4e60\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff1b\u4e24\u8005\u5747\u8bbe\u7f6e\u9884\u5b9a\u9608\u503c\u4ee5\u51b3\u5b9a\u5f53\u524dCU\u7684\u5206\u5272\u3002", "result": "\u6458\u8981\u6307\u51fa\u4e24\u79cd\u65b9\u6cd5\u5df2\u88ab\u63d0\u51fa\u5e76\u8fdb\u884c\u6bd4\u8f83\uff0c\u4e14\u5177\u5907\u5c3a\u5bf8\u65e0\u5173\u6027\u548c\u4f7f\u7528\u90bb\u57dfRD\u6210\u672c\u7684\u8f93\u5165\u7279\u5f81\uff0c\u4f46\u672a\u7ed9\u51fa\u5177\u4f53\u7684\u5b9e\u9a8c\u6570\u5b57\u6216\u7ed3\u8bba\u3002", "conclusion": "\u4ece\u6458\u8981\u53ef\u63a8\u65ad\uff0c\u8fd9\u4e24\u79cd\u65b9\u6cd5\u53ef\u7528\u4e8e\u51cf\u5c11RDO\u641c\u7d22\u7684\u8ba1\u7b97\u91cf\u5e76\u4ee5\u9608\u503c\u5b9e\u73b0\u5206\u5272\u9009\u62e9\uff0c\u4f46\u5177\u4f53RD\u6027\u80fd\u5f71\u54cd\u5728\u6458\u8981\u4e2d\u672a\u7ed9\u51fa\u5b9a\u91cf\u7ed3\u8bba\u3002"}}
{"id": "2511.20382", "categories": ["cs.LG", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2511.20382", "abs": "https://arxiv.org/abs/2511.20382", "authors": ["Audrey Pei-Hsuan Chen"], "title": "MoRE: Batch-Robust Multi-Omics Representations from Frozen Pre-trained Transformers", "comment": null, "summary": "Representation learning on multi-omics data is challenging due to extreme dimensionality, modality heterogeneity, and cohort-specific batch effects. While pre-trained transformer backbones have shown broad generalization capabilities in biological sequence modeling, their application to multi-omics integration remains underexplored. We present MoRE (Multi-Omics Representation Embedding), a framework that repurposes frozen pre-trained transformers to align heterogeneous assays into a shared latent space. Unlike purely generative approaches, MoRE employs a parameter-efficient fine-tuning (PEFT) strategy, prioritizing cross-sample and cross-modality alignment over simple sequence reconstruction. Specifically, MoRE attaches lightweight, modality-specific adapters and a task-adaptive fusion layer to the frozen backbone. It optimizes a masked modeling objective jointly with supervised contrastive and batch-invariant alignment losses, yielding structure-preserving embeddings that generalize across unseen cell types and platforms. We benchmark MoRE against established baselines, including scGPT, scVI, and Harmony with scArches, evaluating integration fidelity, rare population detection, and modality transfer. Our results demonstrate that MoRE achieves competitive batch robustness and biological conservation while significantly reducing trainable parameters compared to fully fine-tuned models. This work positions MoRE as a practical step toward general-purpose omics foundation models.", "AI": {"tldr": "MoRE uses PEFT with frozen transformers and lightweight adapters to align heterogeneous omics into a shared latent space, achieving competitive integration with far fewer trainable parameters.", "motivation": "Multi-omics data present extreme dimensionality, modality heterogeneity, and cohort-specific batch effects; there is a need for general-purpose, efficient omics foundation models.", "method": "Freeze pre-trained transformer backbones, attach modality-specific adapters and a task-adaptive fusion layer; train with a masked modeling objective plus supervised contrastive and batch-invariant alignment losses to produce cross-sample, cross-modality embeddings; compare against scGPT, scVI, and Harmony with scArches.", "result": "MoRE yields structure-preserving embeddings with competitive batch robustness and biological conservation; generalizes to unseen cell types and platforms; substantially reduces trainable parameters relative to fully fine-tuned models.", "conclusion": "MoRE demonstrates the practicality of a general-purpose omics foundation model via parameter-efficient fine-tuning, enabling robust cross-modality integration across diverse conditions."}}
{"id": "2511.20395", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20395", "abs": "https://arxiv.org/abs/2511.20395", "authors": ["M. C. Schoppema", "B. H. M. van der Velden", "A. H\u00fcrriyeto\u011flu", "M. D. Klijnstra", "E. J. Faassen", "A. Gerssen", "H. J. van der Fels-Klerx"], "title": "Identifying environmental factors associated with tetrodotoxin contamination in bivalve mollusks using eXplainable AI", "comment": "18 pages, 6 figures, submitted to Nature Food", "summary": "Since 2012, tetrodotoxin (TTX) has been found in seafoods such as bivalve mollusks in temperate European waters. TTX contamination leads to food safety risks and economic losses, making early prediction of TTX contamination vital to the food industry and competent authorities. Recent studies have pointed to shallow habitats and water temperature as main drivers to TTX contamination in bivalve mollusks. However, the temporal relationships between abiotic factors, biotic factors, and TTX contamination remain unexplored.\n  We have developed an explainable, deep learning-based model to predict TTX contamination in the Dutch Zeeland estuary. Inputs for the model were meteorological and hydrological features; output was the presence or absence of TTX contamination.\n  Results showed that the time of sunrise, time of sunset, global radiation, water temperature, and chloride concentration contributed most to TTX contamination. Thus, the effective number of sun hours, represented by day length and global radiation, was an important driver for tetrodotoxin contamination in bivalve mollusks.\n  To conclude, our explainable deep learning model identified the aforementioned environmental factors (number of sun hours, global radiation, water temperature, and water chloride concentration) to be associated with tetrodotoxin contamination in bivalve mollusks; making our approach a valuable tool to mitigate marine toxin risks for food industry and competent authorities.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4ee5\u9884\u6d4b\u8377\u5170\u6cfd\u5170\u6cb3\u53e3TTX\u6c61\u67d3\uff0c\u57fa\u4e8e\u6c14\u8c61\u548c\u6c34\u6587\u7279\u5f81\uff1b\u65e5\u7167\u65f6\u957f\u3001\u5168\u7403\u8f90\u5c04\u3001\u6c34\u6e29\u548c\u6c2f\u79bb\u5b50\u6d53\u5ea6\u4e3a\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff1b\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u98df\u54c1\u884c\u4e1a\u4e0e\u76d1\u7ba1\u90e8\u95e8\u8fdb\u884c\u65e9\u671f\u98ce\u9669\u9884\u6d4b\u4e0e\u76d1\u63a7\u3002", "motivation": "TTX\u5728\u6e29\u5e26\u6d77\u57df\u8d1d\u7c7b\u4e2d\u6c61\u67d3\uff0c\u7ed9\u98df\u54c1\u5b89\u5168\u548c\u7ecf\u6d4e\u5e26\u6765\u98ce\u9669\uff0c\u9700\u65e9\u671f\u9884\u6d4b\u5e76\u660e\u786e\u9a71\u52a8\u56e0\u5b50\u4ee5\u4fbf\u76d1\u63a7\u4e0e\u6cbb\u7406\u3002", "method": "\u5efa\u7acb\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u8f93\u5165\u4e3a meteorological \u4e0e hydrological \u7279\u5f81\uff0c\u8f93\u51fa\u4e3aTTX\u6c61\u67d3\u7684\u6709\u65e0\uff1b\u901a\u8fc7\u53ef\u89e3\u91ca\u6027\u5206\u6790\u8bc6\u522b\u5173\u952e\u53d8\u91cf\uff0c\u5982\u65e5\u51fa/\u65e5\u843d\u65f6\u95f4\u3001\u5168\u7403\u8f90\u5c04\u3001\u6c34\u6e29\u3001\u6c2f\u79bb\u5b50\u6d53\u5ea6\u7b49\u3002", "result": "\u7ed3\u679c\u663e\u793a\u65e5\u51fa/\u65e5\u843d\u65f6\u95f4\u3001\u5168\u7403\u8f90\u5c04\u3001\u6c34\u6e29\u548c\u6c2f\u79bb\u5b50\u6d53\u5ea6\u5bf9TTX\u6c61\u67d3\u8d21\u732e\u6700\u5927\uff1b\u201c\u65e5\u7167\u65f6\u957f\u201d\u8fd9\u4e00\u7efc\u5408\u53d8\u91cf\uff08\u7531\u65e5\u957f\u4e0e\u5168\u7403\u8f90\u5c04\u7ec4\u6210\uff09\u88ab\u89c6\u4e3a\u91cd\u8981\u9a71\u52a8\u56e0\u7d20\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u89e3\u91ca\u6027\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u53ef\u4f5c\u4e3a\u98df\u54c1\u884c\u4e1a\u4e0e\u76d1\u7ba1\u673a\u6784\u7684\u5b9e\u7528\u5de5\u5177\uff0c\u7528\u4ee5\u76d1\u6d4b\u548c\u964d\u4f4e\u8d1d\u7c7b\u4e2dTTX\u7b49\u6d77\u6d0b\u6bd2\u7d20\u7684\u98ce\u9669\u3002"}}
{"id": "2511.20397", "categories": ["cs.LG", "cs.DS", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.20397", "abs": "https://arxiv.org/abs/2511.20397", "authors": ["Jo\u00ebl Charles-Rebuff\u00e9", "Nicolas Gast", "Bruno Gaujal"], "title": "Model-Based Learning of Whittle indices", "comment": "31 pages, 8 figures, submitted to TOMPECS", "summary": "We present BLINQ, a new model-based algorithm that learns the Whittle indices of an indexable, communicating and unichain Markov Decision Process (MDP). Our approach relies on building an empirical estimate of the MDP and then computing its Whittle indices using an extended version of a state-of-the-art existing algorithm. We provide a proof of convergence to the Whittle indices we want to learn as well as a bound on the time needed to learn them with arbitrary precision. Moreover, we investigate its computational complexity. Our numerical experiments suggest that BLINQ significantly outperforms existing Q-learning approaches in terms of the number of samples needed to get an accurate approximation. In addition, it has a total computational cost even lower than Q-learning for any reasonably high number of samples. These observations persist even when the Q-learning algorithms are speeded up using pre-trained neural networks to predict Q-values.", "AI": {"tldr": "BLINQ is a model-based algorithm that learns the Whittle indices of an indexable, communicating and unichain MDP by building an empirical MDP and applying an extended Whittle-index algorithm; it is provably convergent with finite-sample bounds and demonstrates superior sample efficiency and lower computational cost compared to Q-learning in experiments.", "motivation": "To efficiently learn Whittle indices for complex indexable MDPs, reducing sample and computational requirements relative to standard Q-learning, and enabling practical deployment.", "method": "Construct an empirical MDP from data, compute Whittle indices via an extended algorithm, prove convergence to the true indices and provide finite-time learning bounds; analyze computational complexity; compare with Q-learning empirically.", "result": "BLINQ achieves significantly better sample efficiency than Q-learning and incurs lower total computational cost for a reasonable number of samples; results hold even when Q-learning is accelerated with pre-trained networks.", "conclusion": "BLINQ offers a provably convergent, sample-efficient, and computationally efficient approach to learning Whittle indices for indexable MDPs, outperforming conventional Q-learning in empirical evaluations."}}
{"id": "2511.20407", "categories": ["cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.20407", "abs": "https://arxiv.org/abs/2511.20407", "authors": ["Kasper Green Larsen", "Natascha Schalburg"], "title": "Tight Margin-Based Generalization Bounds for Voting Classifiers over Finite Hypothesis Sets", "comment": null, "summary": "We prove the first margin-based generalization bound for voting classifiers, that is asymptotically tight in the tradeoff between the size of the hypothesis set, the margin, the fraction of training points with the given margin, the number of training samples and the failure probability.", "AI": {"tldr": "\u9996\u6b21\u7ed9\u51fa\u6295\u7968\u5206\u7c7b\u5668\u7684\u8fb9\u8ddd\u6cdb\u5316\u754c\u9650\uff0c\u4e14\u5728\u5019\u9009\u96c6\u89c4\u6a21\u3001\u8fb9\u8ddd\u3001\u5177\u6709\u8be5\u8fb9\u8ddd\u7684\u8bad\u7ec3\u70b9\u6bd4\u4f8b\u3001\u8bad\u7ec3\u6837\u672c\u91cf\u53ca\u5931\u6548\u6982\u7387\u4e4b\u95f4\u5b9e\u73b0\u6e10\u8fd1\u7d27\u81f4\u7684\u6743\u8861\u3002", "motivation": "\u89e3\u51b3\u5bf9\u6295\u7968\u578b\u5206\u7c7b\u5668\u7684\u6cdb\u5316\u5206\u6790\u7f3a\u4e4f\u7406\u8bba\u754c\u9650\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u79cd\u4e0e\u8fb9\u8ddd\u76f8\u5173\u7684\u901a\u7528\u4e0a\u754c\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5047\u8bbe\u96c6\u5408\u4e0b\u7684\u5b66\u4e60\u60c5\u666f\u3002", "method": "\u901a\u8fc7\u628a\u6295\u7968\u5206\u7c7b\u5668\u7684\u51b3\u7b56\u89c4\u5219\u4e0e\u8fb9\u8ddd\u5206\u5e03\u7ed3\u5408\uff0c\u6784\u5efa\u5305\u542b\u5047\u8bbe\u96c6\u5c3a\u5bf8\u3001\u8fb9\u8ddd\u9608\u503c\u3001\u6837\u672c\u5206\u5e03\u548c\u5931\u8d25\u6982\u7387\u7684\u6cdb\u5316\u754c\u9650\uff0c\u5e76\u8bc1\u660e\u8be5\u754c\u9650\u5728\u6e10\u8fd1\u6781\u9650\u4e0b\u662f\u7d27\u81f4\u7684\u3002", "result": "\u63d0\u51fa\u5e76\u8bc1\u660e\u4e00\u4e2a\u6e10\u8fd1\u7d27\u81f4\u7684\u8fb9\u8ddd\u6cdb\u5316\u754c\u9650\uff0c\u5b9a\u91cf\u63cf\u8ff0\u6cdb\u5316\u8bef\u5dee\u4e0a\u754c\u5982\u4f55\u968f\u6295\u7968\u96c6\u5408\u5c3a\u5bf8\u3001\u8fb9\u8ddd\u5927\u5c0f\u3001\u8fbe\u5230\u8fb9\u8ddd\u7684\u8bad\u7ec3\u70b9\u6bd4\u4f8b\u3001\u8bad\u7ec3\u6837\u672c\u6570\u4ee5\u53ca\u5931\u8d25\u6982\u7387\u7684\u53d8\u5316\u800c\u53d8\u5316\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u6295\u7968\u5206\u7c7b\u5668\u7684\u8fb9\u8ddd\u7406\u8bba\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4efd\u7d27\u81f4\u5316\u7684\u754c\u9650\uff0c\u63ed\u793a\u4e86\u8fb9\u8ddd\u5206\u6790\u5728\u590d\u5408\u5047\u8bbe\u7a7a\u95f4\u4e2d\u7684\u9002\u7528\u6027\u4e0e\u6781\u9650\uff0c\u5177\u6709\u7406\u8bba\u4e0e\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.20445", "categories": ["cs.LG", "physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2511.20445", "abs": "https://arxiv.org/abs/2511.20445", "authors": ["Misha Padidar", "Teresa Huang", "Andrew Giuliani", "Marina Spivak"], "title": "Diffusion for Fusion: Designing Stellarators with Generative AI", "comment": null, "summary": "Stellarators are a prospective class of fusion-based power plants that confine a hot plasma with three-dimensional magnetic fields. Typically framed as a PDE-constrained optimization problem, stellarator design is a time-consuming process that can take hours to solve on a computing cluster. Developing fast methods for designing stellarators is crucial for advancing fusion research. Given the recent development of large datasets of optimized stellarators, machine learning approaches have emerged as a potential candidate. Motivated by this, we present an open inverse problem to the machine learning community: to rapidly generate high-quality stellarator designs which have a set of desirable characteristics. As a case study in the problem space, we train a conditional diffusion model on data from the QUASR database to generate quasisymmetric stellarator designs with desirable characteristics (aspect ratio and mean rotational transform). The diffusion model is applied to design stellarators with characteristics not seen during training. We provide evaluation protocols and show that many of the generated stellarators exhibit solid performance: less than 5% deviation from quasisymmetry and the target characteristics. The modest deviation from quasisymmetry highlights an opportunity to reach the sub 1% target. Beyond the case study, we share multiple promising avenues for generative modeling to advance stellarator design.", "AI": {"tldr": "\u4f7f\u7528\u6269\u6563\u6a21\u578b\u5728 QUASR \u6570\u636e\u96c6\u4e0a\u751f\u6210\u5177\u5907\u51c6\u5bf9\u79f0\u6027\u7684\u626d\u8f6c\u661f\u5f62\u8bbe\u8ba1\uff0c\u5e76\u63a2\u7d22\u5728\u672a\u89c1\u7279\u5f81\u4e0b\u7684\u5feb\u901f\u8bbe\u8ba1\u80fd\u529b\u3002", "motivation": "\u5728\u53d7\u63a7\u6838\u805a\u53d8\u7814\u7a76\u4e2d\uff0c\u8bbe\u8ba1\u661f\u5f62\u88c5\u7f6e\u9700\u8981\u5927\u91cf\u8ba1\u7b97\uff0c\u4e14\u6570\u636e\u96c6\u89c4\u6a21\u6269\u5c55\u540e\uff0c\u6025\u9700\u9ad8\u6548\u7684\u751f\u6210\u6a21\u578b\u6765\u5feb\u901f\u7ed9\u51fa\u9ad8\u8d28\u91cf\u8bbe\u8ba1\uff0c\u4ee5\u7f29\u77ed\u8bbe\u8ba1\u5468\u671f\u3002", "method": "\u5229\u7528\u6761\u4ef6\u6269\u6563\u6a21\u578b\u5bf9 QUASR \u6570\u636e\u5e93\u7684\u661f\u5f62\u8bbe\u8ba1\u8fdb\u884c\u5b66\u4e60\uff0c\u8bbe\u5b9a\u76ee\u6807\u7279\u5f81\uff08\u6a2a\u622a\u6bd4\u3001\u5e73\u5747\u8f6c\u52a8\u53d8\u6362\uff09\u3002\u5728\u8bad\u7ec3\u540e\uff0c\u5c06\u6a21\u578b\u5e94\u7528\u4e8e\u8bad\u7ec3\u4e2d\u672a\u51fa\u73b0\u7684\u76ee\u6807\u7279\u5f81\uff0c\u8bc4\u4f30\u8bbe\u8ba1\u5bf9\u51c6\u5bf9\u79f0\u6027\u548c\u76ee\u6807\u7279\u5f81\u7684\u504f\u5dee\uff0c\u5e76\u63d0\u51fa\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u751f\u6210\u7684\u661f\u5f62\u88c5\u7f6e\u8bbe\u8ba1\u5bf9\u51c6\u51c6\u5bf9\u79f0\u6027\u548c\u76ee\u6807\u7279\u5f81\u7684\u504f\u5dee\u5c0f\u4e8e5%\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u63a5\u8fd1\u5b501%\u7ea7\u522b\u7684\u6f5c\u529b\uff0c\u663e\u793a\u8be5\u751f\u6210\u6a21\u578b\u5177\u5907\u5bf9\u672a\u89c1\u7279\u5f81\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u751f\u6210\u5efa\u6a21\u4e3a\u661f\u5f62\u88c5\u7f6e\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u884c\u7684\u5feb\u901f\u9ad8\u6548\u8def\u5f84\uff1b\u672c\u7814\u7a76\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u5f00\u653e\u95ee\u9898\u548c\u8bc4\u4f30\u534f\u8bae\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u964d\u4f4e\u504f\u5dee\u5e76\u63a2\u7d22\u66f4\u591a\u7279\u5f81\u4e0e\u76ee\u6807\u3002"}}
{"id": "2511.20456", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20456", "abs": "https://arxiv.org/abs/2511.20456", "authors": ["Shreevanth Krishnaa Gopalakrishnan", "Stephen Hailes"], "title": "Towards Trustworthy Wi-Fi Sensing: Systematic Evaluation of Deep Learning Model Robustness to Adversarial Attacks", "comment": "19 pages, 8 figures, 7 tables", "summary": "Machine learning has become integral to Channel State Information (CSI)-based human sensing systems and is expected to power applications such as device-free activity recognition and identity detection in future cellular and Wi-Fi generations. However, these systems rely on models whose decisions can be subtly perturbed, raising concerns for security and reliability in ubiquitous sensing. Quantifying and understanding the robustness of such models, defined as their ability to maintain accurate predictions under adversarial perturbations, is therefore critical before wireless sensing can be safely deployed in real-world environments.\n  This work presents a systematic evaluation of the robustness of CSI deep learning models under diverse threat models (white-box, black-box/transfer, and universal perturbations) and varying degrees of attack realism. We establish a framework to compare compact temporal autoencoder models with larger deep architectures across three public datasets, quantifying how model scale, training regime, and physical constraints influence robustness. Our experiments show that smaller models, while efficient and equally performant on clean data, are markedly less robust. We further confirm that physically realizable signal-space perturbations, designed to be feasible in real wireless channels, significantly reduce attack success compared to unconstrained feature-space attacks. Adversarial training mitigates these vulnerabilities, improving mean robust accuracy with only moderate degradation in clean performance across both model classes. As wireless sensing advances towards reliable, cross-domain operation, these findings provide quantitative baselines for robustness estimation and inform design principles for secure and trustworthy human-centered sensing systems.", "AI": {"tldr": "\u7cfb\u7edf\u6027\u8bc4\u4f30CSI\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5bf9\u767d\u76d2\u3001\u9ed1\u76d2/\u8fc1\u79fb\u4e0e\u901a\u7528\u5bf9\u6297\u6270\u52a8\u7b49\u5a01\u80c1\u6a21\u578b\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u5c0f\u6a21\u578b\u5728\u6e05\u6d01\u6570\u636e\u4e0a\u8868\u73b0\u76f8\u8fd1\u4f46\u9c81\u68d2\u6027\u663e\u8457\u4e0d\u8db3\uff1b\u7269\u7406\u53ef\u5b9e\u73b0\u7684\u4fe1\u53f7\u7a7a\u95f4\u6270\u52a8\u6bd4\u672a\u7ea6\u675f\u7684\u7279\u5f81\u7a7a\u95f4\u653b\u51fb\u66f4\u96be\u4ee5\u5b9e\u73b0\u653b\u51fb\u6210\u529f\uff1b\u5bf9\u6297\u8bad\u7ec3\u53ef\u63d0\u5347\u9c81\u68d2\u6027\u4f46\u5bf9\u6e05\u6d01\u51c6\u786e\u7387\u6709\u4e2d\u7b49\u6298\u8877\u3002", "motivation": "CSI\u57fa\u4e8e\u4eba\u4f53\u611f\u77e5\u7684\u7cfb\u7edf\u6613\u53d7\u5bf9\u6297\u6270\u52a8\u5f71\u54cd\uff0c\u9700\u5efa\u7acb\u5728\u771f\u5b9e\u65e0\u7ebf\u4fe1\u9053\u4e2d\u7684\u9c81\u68d2\u6027\u57fa\u7ebf\uff0c\u4e3a\u5728\u65e0\u7ebf\u611f\u77e5\u4e2d\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u5b9a\u91cf\u8bc4\u4f30\u548c\u8bbe\u8ba1\u6307\u5f15\u3002", "method": "\u5728\u4e09\u4efd\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0c\u6bd4\u8f83\u7d27\u51d1\u7684\u65f6\u5e8f\u81ea\u7f16\u7801\u5668\u6a21\u578b\u4e0e\u66f4\u5927\u89c4\u6a21\u7684\u6df1\u5ea6\u67b6\u6784\uff1b\u9488\u5bf9\u767d\u76d2\u3001\u9ed1\u76d2/\u8fc1\u79fb\u4e0e\u901a\u7528\u6270\u52a8\u7b49\u591a\u79cd\u5a01\u80c1\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5e76\u5f15\u5165\u5bf9\u7269\u7406\u4fe1\u9053\u53ef\u5b9e\u73b0\u6027\u7684\u7ea6\u675f\uff0c\u8bc4\u4f30\u4e24\u7c7b\u6a21\u578b\u5728\u4e0d\u540c\u8bad\u7ec3\u8bbe\u7f6e\u4e0b\u7684\u9c81\u68d2\u6027\uff1b\u5e76\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u8bc4\u4f30\u9c81\u68d2\u6027\u63d0\u5347\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a1) \u5c0f\u6a21\u578b\u5728\u6e05\u6d01\u6570\u636e\u4e0a\u4e0e\u5927\u6a21\u578b\u7b49\u6548\uff0c\u4f46\u9c81\u68d2\u6027\u663e\u8457\u8f83\u5dee\uff1b2) \u53d7\u7269\u7406\u4fe1\u9053\u7ea6\u675f\u7684\u6270\u52a8\u663e\u8457\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u65e0\u7ea6\u675f\u7684\u7279\u5f81\u7a7a\u95f4\u653b\u51fb\uff1b3) \u5bf9\u6297\u8bad\u7ec3\u63d0\u5347\u5e73\u5747\u9c81\u68d2\u6027\uff0c\u4f46\u5bf9\u6e05\u6d01\u6027\u80fd\u6709\u4e2d\u7b49\u7a0b\u5ea6\u7684\u964d\u4f4e\uff1b4) \u7814\u7a76\u63d0\u4f9b\u9c81\u68d2\u6027\u4f30\u7b97\u7684\u57fa\u7ebf\u4e0e\u8bbe\u8ba1\u539f\u5219\uff0c\u5229\u4e8e\u8de8\u9886\u57df\u53ef\u9760\u7684\u4eba\u7c7b\u611f\u77e5\u7cfb\u7edf\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u6a21\u578b\u89c4\u6a21\u548c\u8bad\u7ec3\u7b56\u7565\u5bf9\u9c81\u68d2\u6027\u7684\u51b3\u5b9a\u6027\u5f71\u54cd\uff0c\u5efa\u8bae\u5728CSI\u57fa\u4e8e\u611f\u77e5\u7684\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7efc\u5408\u8003\u8651\u7269\u7406\u7ea6\u675f\u3001\u5a01\u80c1\u6a21\u578b\u548c\u5bf9\u6297\u8bad\u7ec3\u4ee5\u5b9e\u73b0\u66f4\u5b89\u5168\u3001\u53ef\u4fe1\u7684\u65e0\u7ebf\u611f\u77e5\u3002"}}
{"id": "2511.20478", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20478", "abs": "https://arxiv.org/abs/2511.20478", "authors": ["Kateryna Chumachenko", "Amala Sanjay Deshmukh", "Jarno Seppanen", "Ilia Karmanov", "Chia-Chih Chen", "Lukas Voegtle", "Philipp Fischer", "Marek Wawrzos", "Saeid Motiian", "Roman Ageev", "Kedi Wu", "Alexandre Milesi", "Maryam Moosaei", "Krzysztof Pawelec", "Padmavathy Subramanian", "Mehrzad Samadi", "Xin Yu", "Celina Dear", "Sarah Stoddard", "Jenna Diamond", "Jesse Oliver", "Leanna Chraghchian", "Patrick Skelly", "Tom Balough", "Yao Xu", "Jane Polak Scowcroft", "Daniel Korzekwa", "Darragh Hanley", "Sandip Bhaskar", "Timo Roman", "Karan Sapra", "Andrew Tao", "Bryan Catanzaro"], "title": "NVIDIA Nemotron Parse 1.1", "comment": null, "summary": "We introduce Nemotron-Parse-1.1, a lightweight document parsing and OCR model that advances the capabilities of its predecessor, Nemoretriever-Parse-1.0. Nemotron-Parse-1.1 delivers improved capabilities across general OCR, markdown formatting, structured table parsing, and text extraction from pictures, charts, and diagrams. It also supports a longer output sequence length for visually dense documents. As with its predecessor, it extracts bounding boxes of text segments, as well as corresponding semantic classes. Nemotron-Parse-1.1 follows an encoder-decoder architecture with 885M parameters, including a compact 256M-parameter language decoder. It achieves competitive accuracy on public benchmarks making it a strong lightweight OCR solution. We release the model weights publicly on Huggingface, as well as an optimized NIM container, along with a subset of the training data as part of the broader Nemotron-VLM-v2 dataset. Additionally, we release Nemotron-Parse-1.1-TC which operates on a reduced vision token length, offering a 20% speed improvement with minimal quality degradation.", "AI": {"tldr": "Nemotron-Parse-1.1 \u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u6587\u6863\u89e3\u6790\u4e0e OCR \u6a21\u578b\uff0c\u57fa\u4e8e Nemoretriever-Parse-1.0 \u7684\u6539\u8fdb\uff0c\u8986\u76d6\u901a\u7528 OCR\u3001Markdown\u3001\u8868\u683c\u89e3\u6790\u4ee5\u53ca\u56fe\u7247/\u56fe\u8868\u6587\u672c\u63d0\u53d6\uff0c\u652f\u6301\u66f4\u957f\u8f93\u51fa\u5e8f\u5217\uff0c\u53c2\u6570\u91cf 885M\uff08\u542b 256M \u8bed\u8a00\u89e3\u7801\u5668\uff09\uff0c\u516c\u5f00\u6743\u91cd\u4e0e\u4f18\u5316\u5bb9\u5668\uff0c\u53e6\u6709 Nemotron-Parse-1.1-TC \u63d0\u4f9b 20% \u7684\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u63d0\u5347\u5bf9\u591a\u6837\u5316\u6587\u6863\u7684\u9ad8\u6548\u7406\u89e3\u4e0e\u89e3\u6790\u80fd\u529b\uff0c\u63d0\u4f9b\u4e00\u4e2a\u53ef\u90e8\u7f72\u3001\u8d44\u6e90\u53cb\u597d\u7684 OCR \u89e3\u51b3\u65b9\u6848\uff0c\u8986\u76d6\u6587\u672c\u5757\u5b9a\u4f4d\u3001\u8bed\u4e49\u5206\u7c7b\u4e0e\u7ed3\u6784\u5316\u4fe1\u606f\u62bd\u53d6\u7b49\u9700\u6c42\u3002", "method": "\u91c7\u7528\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u603b\u4f53 885M \u53c2\u6570\uff0c\u5176\u4e2d\u5305\u542b\u4e00\u4e2a 256M \u7684\u8bed\u8a00\u89e3\u7801\u5668\uff0c\u6269\u5c55\u8f93\u51fa\u5e8f\u5217\u957f\u5ea6\uff0c\u8f93\u51fa\u6587\u672c\u7684\u8fb9\u754c\u6846\u4e0e\u8bed\u4e49\u7c7b\u522b\uff1b\u652f\u6301\u4e00\u822c OCR\u3001Markdown \u89e3\u6790\u3001\u8868\u683c\u89e3\u6790\u4ee5\u53ca\u56fe\u7247/\u56fe\u8868\u6587\u672c\u63d0\u53d6\uff1b\u516c\u5f00\u6a21\u578b\u6743\u91cd\u3001\u4f18\u5316 NIM \u5bb9\u5668\u548c\u6570\u636e\u5b50\u96c6\uff0c\u9644\u5e26 Nemotron-VLM-v2 \u6570\u636e\u96c6\u6269\u5c55\uff1b\u53e6\u63d0\u4f9b Nemotron-Parse-1.1-TC\uff0c\u5728\u964d\u4f4e\u89c6\u89c9 token \u957f\u5ea6\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u7ea6 20% \u7684\u63a8\u7406\u52a0\u901f\uff0c\u8d28\u91cf\u4e0b\u964d\u6781\u5c0f\u3002", "result": "\u5728\u516c\u5f00\u57fa\u51c6\u4e0a\u5177\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\uff0c\u8bc1\u660e\u5176\u4f5c\u4e3a\u8f7b\u91cf\u7ea7 OCR \u89e3\u51b3\u65b9\u6848\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u591a\u7c7b\u6587\u6863\u573a\u666f\uff08\u5305\u62ec\u8868\u683c\u548c\u56fe\u50cf\u6587\u672c\uff09\u8868\u73b0\u51fa\u6539\u8fdb\u3002", "conclusion": "Nemotron-Parse-1.1 \u63d0\u4f9b\u4e00\u4e2a\u53ef\u516c\u5f00\u83b7\u53d6\u3001\u8f7b\u91cf\u4e14\u9ad8\u6548\u7684\u6587\u6863\u89e3\u6790\u6846\u67b6\uff0c\u9002\u5408\u90e8\u7f72\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\uff0c\u5e76\u901a\u8fc7 Huggingface \u6743\u91cd\u548c\u6570\u636e\u5b50\u96c6\u4fc3\u8fdb\u7814\u7a76\u4e0e\u5e94\u7528\uff1b1.1-TC \u7248\u672c\u5219\u5728\u901f\u5ea6\u65b9\u9762\u63d0\u4f9b\u989d\u5916\u7684\u63d0\u5347\u3002"}}
{"id": "2511.20490", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20490", "abs": "https://arxiv.org/abs/2511.20490", "authors": ["Kiril Vasilev", "Alexandre Misrahi", "Eeshaan Jain", "Phil F Cheng", "Petros Liakopoulos", "Olivier Michielin", "Michael Moor", "Charlotte Bunne"], "title": "MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology", "comment": "Accepted to NeurIPS 2025", "summary": "Multimodal Large Language Models (LLMs) hold promise for biomedical reasoning, but current benchmarks fail to capture the complexity of real-world clinical workflows. Existing evaluations primarily assess unimodal, decontextualized question-answering, overlooking multi-agent decision-making environments such as Molecular Tumor Boards (MTBs). MTBs bring together diverse experts in oncology, where diagnostic and prognostic tasks require integrating heterogeneous data and evolving insights over time. Current benchmarks lack this longitudinal and multimodal complexity. We introduce MTBBench, an agentic benchmark simulating MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations are validated by clinicians via a co-developed app, ensuring clinical relevance. We benchmark multiple open and closed-source LLMs and show that, even at scale, they lack reliability -- frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence or different modalities. To address these limitations, MTBBench goes beyond benchmarking by providing an agentic framework with foundation model-based tools that enhance multi-modal and longitudinal reasoning, leading to task-level performance gains of up to 9.0% and 11.2%, respectively. Overall, MTBBench offers a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use with a focus on MTB environments in precision oncology.", "AI": {"tldr": "MTBBench is a multimodal, longitudinal MTB-style benchmark for oncology LLMs that uses clinician-validated ground truth to test how LLMs handle complex, real-world decision-making; results show current models struggle with reliability and time-resolved data, while an agentic framework with foundation-model tools yields notable task gains.", "motivation": "Existing benchmarks are largely unimodal and decontextualized, failing to capture the multi-agent, longitudinal, multimodal nature of Molecular Tumor Boards and precision oncology decision-making.", "method": "Introduce MTBBench, simulating MTB-style decisions with challenging multimodal and longitudinal oncology questions; clinician-validated ground truth via a co-developed app; benchmark multiple LLMs; provide an agentic framework with tool-use capabilities to enhance reasoning.", "result": "LLMs frequently hallucinate and struggle with time-resolved, multimodal reasoning and reconciling conflicting evidence; agentic tooling yields task-level gains of up to 9.0% (multimodal) and 11.2% (longitudinal).", "conclusion": "MTBBench provides a realistic, challenging testbed for advancing multimodal LLM reasoning, reliability, and tool-use in MTB-based precision oncology workflows."}}
{"id": "2511.20509", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20509", "abs": "https://arxiv.org/abs/2511.20509", "authors": ["Mihaela Hudi\u015fteanu", "Edwige Cyffers", "Nikita P. Kalinin"], "title": "DP-MicroAdam: Private and Frugal Algorithm for Training and Fine-tuning", "comment": null, "summary": "Adaptive optimizers are the de facto standard in non-private training as they often enable faster convergence and improved performance. In contrast, differentially private (DP) training is still predominantly performed with DP-SGD, typically requiring extensive compute and hyperparameter tuning. We propose DP-MicroAdam, a memory-efficient and sparsity-aware adaptive DP optimizer. We prove that DP-MicroAdam converges in stochastic non-convex optimization at the optimal $\\mathcal{O}(1/\\sqrt{T})$ rate, up to privacy-dependent constants. Empirically, DP-MicroAdam outperforms existing adaptive DP optimizers and achieves competitive or superior accuracy compared to DP-SGD across a range of benchmarks, including CIFAR-10, large-scale ImageNet training, and private fine-tuning of pretrained transformers. These results demonstrate that adaptive optimization can improve both performance and stability under differential privacy.", "AI": {"tldr": "\u63d0\u51fa\u4e86 DP-MicroAdam\uff0c\u4e00\u79cd\u5185\u5b58\u9ad8\u6548\u4e14\u5177\u7a00\u758f\u652f\u6301\u7684\u81ea\u9002\u5e94\u5dee\u5206\u9690\u79c1\u4f18\u5316\u5668\uff0c\u7ed9\u51fa\u6536\u655b\u6027\u8bc1\u660e\u5e76\u5728\u4e00\u7cfb\u5217\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u8d8a\u4e8e\u73b0\u6709\u81ea\u9002\u5e94DP\u4f18\u5316\u5668\u7684\u8868\u73b0\uff0c\u4e14\u4e0e DP-SGD \u76f8\u5f53\u751a\u81f3\u8d85\u8d8a\u3002", "motivation": "\u5728\u975e\u79c1\u6709\u8bad\u7ec3\u4e2d\u81ea\u9002\u5e94\u4f18\u5316\u5668\u901a\u5e38\u5e26\u6765\u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u597d\u6027\u80fd\uff1b\u7136\u800c\u5728\u5dee\u5206\u9690\u79c1\u8bad\u7ec3\u4e2d\uff0cDP-SGD \u4e3b\u5bfc\u4e14\u9700\u8981\u9ad8\u8ba1\u7b97\u4e0e\u5927\u91cf\u8d85\u53c2\u6570\u8c03\u4f18\u3002\u9700\u8981\u4e00\u79cd\u517c\u5177\u81ea\u9002\u5e94\u6027\u3001\u5185\u5b58\u53cb\u597d\u6027\u4e0e\u5dee\u5206\u9690\u79c1\u4fdd\u62a4\u7684\u4f18\u5316\u5668\u3002", "method": "\u63d0\u51fa DP-MicroAdam\uff0c\u8bc1\u660e\u5728\u968f\u673a\u975e\u51f8\u95ee\u9898\u4e0b\u5177\u6709\u6536\u655b\u6027\uff0c\u8fbe\u5230 O(1/\u221aT) \u7684\u901f\u7387\uff08\u5e26\u9690\u79c1\u76f8\u5173\u5e38\u6570\uff09\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4 CIFAR-10\u3001ImageNet \u7b49\u6570\u636e\u96c6\u53ca\u79c1\u6709\u5fae\u8c03\u7684\u5b9e\u9a8c\uff0c\u5c55\u793a\u5728\u4e0e\u5dee\u5206\u9690\u79c1\u76f8\u5173\u7684\u7ea6\u675f\u4e0b\u7684\u6027\u80fd\u63d0\u5347\u4e0e\u7a33\u5b9a\u6027\u6539\u5584\u3002", "result": "\u7406\u8bba\u4e0a\uff0cDP-MicroAdam \u5728\u968f\u673a\u975e\u51f8\u4f18\u5316\u4e0b\u8fbe\u5230\u6700\u4f18\u7684 O(1/\u221aT) \u6536\u655b\u901f\u7387\uff08\u5728\u9690\u79c1\u5e38\u6570\u4e0b\uff09\u3002\u5728\u5b9e\u9645\u5b9e\u9a8c\u4e2d\uff0cDP-MicroAdam \u8d85\u8d8a\u4e86\u73b0\u6709\u81ea\u9002\u5e94DP\u4f18\u5316\u5668\uff0c\u5e76\u5728 CIFAR-10\u3001ImageNet \u4ee5\u53ca\u79c1\u6709\u5fae\u8c03\u7684\u9884\u8bad\u7ec3 Transformer \u4e0a\uff0c\u4e0e DP-SGD \u76f8\u6bd4\u8868\u73b0\u4e0d\u52a3\u751a\u81f3\u4f18\u4e8e\u5b83\u3002", "conclusion": "\u8868\u660e\u5728\u5dee\u5206\u9690\u79c1\u8bbe\u7f6e\u4e0b\uff0c\u81ea\u9002\u5e94\u4f18\u5316\u5177\u6709\u63d0\u5347\u6027\u80fd\u4e0e\u7a33\u5b9a\u6027\u7684\u6f5c\u529b\uff0cDP-MicroAdam \u4e3a\u79c1\u6709\u8bad\u7ec3\u63d0\u4f9b\u4e00\u4e2a\u6709\u6548\u7684\u81ea\u9002\u5e94\u4f18\u5316\u89e3\u3002"}}
{"id": "2511.20516", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20516", "abs": "https://arxiv.org/abs/2511.20516", "authors": ["Sam Laing", "Antonio Orvieto"], "title": "Adam Simplified: Bias Correction Simplified", "comment": null, "summary": "The Adam optimizer is a cornerstone of modern deep learning, yet the empirical necessity of each of its individual components is often taken for granted. This paper presents a focused investigation into the role of bias-correction, a feature whose contribution remains poorly understood. Through a series of systematic ablations on vision and language modelling tasks, we demonstrate that the conventional wisdom surrounding bias correction is misleading. In particular, we demonstrate that in the optimal hyper-parameter configuration, the inclusion of bias correction leads to no improvement in final test performance. Moreover, unless appropriate learning rate scheduling is implemented, the inclusion of bias correction can sometimes be detrimental to performance. We further reinterpret bias correction as a form of implicit learning rate scheduling whose behaviour is strongly dependent on the choice of smoothing hyper-parameters $\u03b2_1, \u03b2_2 \\in [0,1)$. Our findings challenge the universal inclusion of this component.", "AI": {"tldr": "Bias-correction in Adam may be unnecessary for optimal performance; it can hurt without proper learning rate scheduling; acts as a form of implicit LR scheduling dependent on beta1, beta2; universal inclusion is not warranted.", "motivation": "Investigate the empirical necessity of Adam's bias-correction, which is often assumed to help but lacks rigorous understanding.", "method": "Systematic ablations on vision and language modeling tasks; compare Adam with and without bias-correction across hyperparameters; reinterpret bias correction as implicit LR scheduling; analyze effect of smoothing parameters beta1, beta2.", "result": "Under optimal hyperparameters, bias correction yields no improvement; without LR scheduling, it can be detrimental; bias correction behaves as an implicit, smoothing-parameter dependent LR scheduler.", "conclusion": "Bias-correction should not be universally applied; decisions should depend on hyperparameter configuration and learning-rate schedule."}}
{"id": "2511.20543", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20543", "abs": "https://arxiv.org/abs/2511.20543", "authors": ["Alhasan Abdellatif", "Hannah P. Menke", "Ahmed H. Elsheikh", "Florian Doster", "Kamaljit Singh"], "title": "Feature-Modulated UFNO for Improved Prediction of Multiphase Flow in Porous Media", "comment": null, "summary": "The UNet-enhanced Fourier Neural Operator (UFNO) extends the Fourier Neural Operator (FNO) by incorporating a parallel UNet pathway, enabling the retention of both high- and low-frequency components. While UFNO improves predictive accuracy over FNO, it inefficiently treats scalar inputs (e.g., temperature, injection rate) as spatially distributed fields by duplicating their values across the domain. This forces the model to process redundant constant signals within the frequency domain. Additionally, its standard loss function does not account for spatial variations in error sensitivity, limiting performance in regions of high physical importance. We introduce UFNO-FiLM, an enhanced architecture that incorporates two key innovations. First, we decouple scalar inputs from spatial features using a Feature-wise Linear Modulation (FiLM) layer, allowing the model to modulate spatial feature maps without introducing constant signals into the Fourier transform. Second, we employ a spatially weighted loss function that prioritizes learning in critical regions. Our experiments on subsurface multiphase flow demonstrate a 21\\% reduction in gas saturation Mean Absolute Error (MAE) compared to UFNO, highlighting the effectiveness of our approach in improving predictive accuracy.", "AI": {"tldr": "UFNO-FiLM \u901a\u8fc7 FiLM \u89e3\u8026\u6807\u91cf\u8f93\u5165\u5e76\u91c7\u7528\u7a7a\u95f4\u52a0\u6743\u635f\u5931\uff0c\u5728 UFNO \u57fa\u7840\u4e0a\u663e\u8457\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5728\u5730\u4e0b\u591a\u76f8\u6e17\u6d41\u573a\u666f\u5b9e\u73b0 21% MAE \u964d\u4f4e", "motivation": "\u89e3\u51b3 UFNO \u5c06\u6807\u91cf\u8f93\u5165\u5f53\u4f5c\u7a7a\u95f4\u573a\u5904\u7406\u5bfc\u81f4\u4fe1\u606f\u5197\u4f59\u4e0e\u5e38\u91cf\u4fe1\u53f7\u8fdb\u5165\u5085\u91cc\u53f6\u57df\u7684\u95ee\u9898\uff0c\u540c\u65f6\u901a\u8fc7\u52a0\u6743\u635f\u5931\u63d0\u5347\u5728\u7269\u7406\u91cd\u8981\u533a\u57df\u7684\u5b66\u4e60\u6548\u679c\u3002", "method": "\u5728 UFNO \u6846\u67b6\u4e2d\u5f15\u5165 FiLM \u5c42\u4ee5\u89e3\u8026\u6807\u91cf\u8f93\u5165\u4e0e\u7a7a\u95f4\u7279\u5f81\uff0c\u5e76\u5bf9\u7279\u5f81\u8fdb\u884c\u6761\u4ef6\u8c03\u5236\uff1b\u5f15\u5165\u7a7a\u95f4\u52a0\u6743\u635f\u5931\u4ee5\u4f18\u5148\u5173\u6ce8\u5173\u952e\u533a\u57df\uff1b\u5728\u5730\u4e0b\u591a\u76f8\u6e17\u6d41\u7684\u4eff\u771f\u573a\u666f\u4e2d\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u4e0e\u539f UFNO \u76f8\u6bd4\uff0c\u6c14\u4f53\u9971\u548c\u5ea6\u7684 MAE \u964d\u4f4e\u7ea6 21%\u3002", "conclusion": "UFNO\u2011FiLM \u901a\u8fc7\u89e3\u8026\u6807\u91cf\u8f93\u5165\u5e76\u805a\u7126\u5173\u952e\u533a\u57df\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u5730\u4e0b\u6e17\u6d41\u573a\u666f\u4e2d\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8bc1\u660e\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.20584", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20584", "abs": "https://arxiv.org/abs/2511.20584", "authors": ["Shuo Xie", "Tianhao Wang", "Beining Wu", "Zhiyuan Li"], "title": "A Tale of Two Geometries: Adaptive Optimizers and Non-Euclidean Descent", "comment": null, "summary": "Adaptive optimizers can reduce to normalized steepest descent (NSD) when only adapting to the current gradient, suggesting a close connection between the two algorithmic families. A key distinction between their analyses, however, lies in the geometries, e.g., smoothness notions, they rely on. In the convex setting, adaptive optimizers are governed by a stronger adaptive smoothness condition, while NSD relies on the standard notion of smoothness. We extend the theory of adaptive smoothness to the nonconvex setting and show that it precisely characterizes the convergence of adaptive optimizers. Moreover, we establish that adaptive smoothness enables acceleration of adaptive optimizers with Nesterov momentum in the convex setting, a guarantee unattainable under standard smoothness for certain non-Euclidean geometry. We further develop an analogous comparison for stochastic optimization by introducing adaptive gradient variance, which parallels adaptive smoothness and leads to dimension-free convergence guarantees that cannot be achieved under standard gradient variance for certain non-Euclidean geometry.", "AI": {"tldr": "\u5c06\u81ea\u9002\u5e94\u4f18\u5316\u5668\u4e0e\u5f52\u4e00\u5316\u6700\u901f\u4e0b\u964d\uff08NSD\uff09\u4e4b\u95f4\u7684\u5173\u7cfb\u5f62\u5f0f\u5316\uff1a\u5728\u975e\u51f8\u548c\u968f\u673a\u8bbe\u7f6e\u4e2d\uff0c\u63d0\u51fa\u81ea\u9002\u5e94\u5149\u6ed1\u6027\u548c\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u5dee\u7684\u6982\u5ff5\uff0c\u4f5c\u4e3a\u6536\u655b\u6027\u548c\u52a0\u901f\u6027\u7684\u6838\u5fc3\u6d4b\u5ea6\uff0c\u5e76\u7ed9\u51fa\u5728\u975e\u6b27\u51e0\u91cc\u5f97\u51e0\u4f55\u4e0b\u7684\u7ef4\u5ea6\u65e0\u5173\u6536\u655b\u6027\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u4e2d\u81ea\u9002\u5e94\u4f18\u5316\u5bb6\u65cf\u548cNSD\u4e4b\u95f4\u5b58\u5728\u5bc6\u5207\u8054\u7cfb\uff0c\u4f46\u4e24\u8005\u7684\u51e0\u4f55\u5047\u8bbe\uff08\u5149\u6ed1\u6027\u5b9a\u4e49\uff09\u4e0d\u540c\u3002\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u3001\u51e0\u4f55\u611f\u77e5\u7684\u6846\u67b6\uff0c\u4ee5\u5728\u975e\u51f8\u4e0e\u968f\u673a\u60c5\u5f62\u4e0b\u89e3\u91ca\u6536\u655b\u6027\u5e76\u63a2\u8ba8\u52a0\u901f\u53ef\u80fd\u6027\u3002", "method": "\u5c06\u81ea\u9002\u5e94\u5149\u6ed1\u6027\u63a8\u5e7f\u5230\u975e\u51f8\u8bbe\u5b9a\uff0c\u5e76\u8bc1\u660e\u5b83\u80fd\u7cbe\u786e\u8868\u5f81\u81ea\u9002\u5e94\u4f18\u5316\u5668\u7684\u6536\u655b\u6027\uff1b\u5728\u51f8\u8bbe\u5b9a\u4e2d\uff0c\u8bc1\u660e\u7ed3\u5408Nesterov\u52a8\u91cf\u65f6\uff0c\u81ea\u9002\u5e94\u5149\u6ed1\u6027\u53ef\u5b9e\u73b0\u52a0\u901f\uff1b\u63d0\u51fa\u4e0e\u81ea\u9002\u5e94\u5149\u6ed1\u6027\u5e76\u5217\u7684\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u5dee\u6982\u5ff5\uff0c\u7528\u4e8e\u968f\u673a\u4f18\u5316\uff0c\u5e76\u7ed9\u51fa\u5728\u67d0\u4e9b\u975e\u6b27\u51e0\u91cc\u5f97\u51e0\u4f55\u4e0b\u7684\u7ef4\u5ea6\u65e0\u5173\u6536\u655b\u6027\u3002", "result": "\u81ea\u9002\u5e94\u5149\u6ed1\u6027\u5168\u9762\u523b\u753b\u81ea\u9002\u5e94\u4f18\u5316\u5668\u7684\u6536\u655b\u6027\u5e76\u53ef\u5728\u51f8\u60c5\u5f62\u4e0b\u5b9e\u73b0\u5e26Nesterov\u52a8\u91cf\u7684\u52a0\u901f\uff1b\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u5dee\u4e0e\u81ea\u9002\u5e94\u5149\u6ed1\u6027\u5e76\u884c\uff0c\u5bfc\u51fa\u5728\u975e\u6b27\u51e0\u91cc\u5f97\u51e0\u4f55\u4e0b\u7684\u7ef4\u5ea6\u65e0\u5173\u7684\u968f\u673a\u4f18\u5316\u6536\u655b\u6027\uff0c\u4f18\u4e8e\u4ee5\u5f80\u5728\u6807\u51c6\u5149\u6ed1\u6027\u4e0e\u68af\u5ea6\u65b9\u5dee\u6846\u67b6\u4e0b\u7684\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u5149\u6ed1\u6027\u4e0e\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u5dee\u6784\u6210\u4e86\u89e3\u91ca\u81ea\u9002\u5e94\u4f18\u5316\u4e0eNSD\u4e4b\u95f4\u5173\u7cfb\u7684\u6838\u5fc3\u51e0\u4f55\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u975e\u51f8\u4e0e\u968f\u673a\u4f18\u5316\u7684\u7406\u8bba\u8fb9\u754c\uff0c\u5e76\u63ed\u793a\u4e86\u5728\u7279\u5b9a\u51e0\u4f55\u7ed3\u6784\u4e0b\u7684\u52a0\u901f\u4e0e\u7ef4\u5ea6\u65e0\u5173\u6027\u7684\u65b0\u53ef\u80fd\u3002"}}
{"id": "2511.20587", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20587", "abs": "https://arxiv.org/abs/2511.20587", "authors": ["Karim Kadry", "Abdallah Abdelwahed", "Shoaib Goraya", "Ajay Manicka", "Naravich Chutisilp", "Farhad Nezami", "Elazer Edelman"], "title": "Anatomica: Localized Control over Geometric and Topological Properties for Anatomical Diffusion Models", "comment": "8 pages, 10 figures", "summary": "We present Anatomica: an inference-time framework for generating multi-class anatomical voxel maps with localized geo-topological control. During generation, we use cuboidal control domains of varying dimensionality, location, and shape to slice out relevant substructures. These local substructures are used to compute differentiable penalty functions that steer the sample towards target constraints. We control geometric features such as size, shape, and position through voxel-wise moments, while topological features such as connected components, loops, and voids are enforced through persistent homology. Lastly, we implement Anatomica for latent diffusion models, where neural field decoders partially extract substructures, enabling the efficient control of anatomical properties. Anatomica applies flexibly across diverse anatomical systems, composing constraints to control complex structures over arbitrary dimensions and coordinate systems, thereby enabling the rational design of synthetic datasets for virtual trials or machine learning workflows.", "AI": {"tldr": "Anatomica \u662f\u4e00\u4e2a\u63a8\u7406\u65f6\u6846\u67b6\uff0c\u7ed3\u5408\u5c40\u90e8\u5750\u6807\u57df\u4e0e\u53ef\u5fae\u60e9\u7f5a\uff0c\u4ee5\u53ca\u6301\u4e45\u540c\u8c03\uff0c\u6765\u5f15\u5bfc\u6f5c\u5728\u6269\u6563\u6a21\u578b\u751f\u6210\u5177\u6709\u591a\u7c7b\u89e3\u5256\u5b66\u7684\u4f53\u7d20\u6620\u5c04\uff0c\u5b9e\u73b0\u51e0\u4f55\u4e0e\u62d3\u6251\u7684\u53ef\u63a7\u6027\u3002", "motivation": "\u5b9e\u73b0\u5bf9\u590d\u6742\u89e3\u5256\u7ed3\u6784\u7684\u53ef\u89e3\u91ca\u3001\u53ef\u63a7\u751f\u6210\uff0c\u4ee5\u4fbf\u4e3a\u865a\u62df\u8bd5\u9a8c\u548c\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u5408\u6210\u6570\u636e\u3002", "method": "\u4f7f\u7528\u4e0d\u540c\u7ef4\u5ea6\u7684\u7acb\u65b9\u63a7\u5236\u57df\u6765\u5207\u51fa\u76f8\u5173\u5b50\u7ed3\u6784\uff0c\u57fa\u4e8e\u8fd9\u4e9b\u5b50\u7ed3\u6784\u8ba1\u7b97\u53ef\u5fae\u60e9\u7f5a\u4ee5\u7ea6\u675f\u91c7\u6837\uff1b\u901a\u8fc7\u4f53\u7d20\u7ea7\u77e9\u548c\u5927\u5c0f\u3001\u5f62\u72b6\u3001\u4f4d\u7f6e\u7b49\u51e0\u4f55\u7279\u5f81\uff1b\u901a\u8fc7\u6301\u4e45\u540c\u8c03\u5f3a\u5236\u5b9e\u73b0\u8fde\u901a\u5206\u652f\u3001\u73af\u548c\u7a7a\u8154\u7b49\u62d3\u6251\u7279\u5f81\uff1b\u5728\u6f5c\u5728\u6269\u6563\u6a21\u578b\u4e2d\u7ed3\u5408\u795e\u7ecf\u573a\u89e3\u7801\u5668\u63d0\u53d6\u5b50\u7ed3\u6784\u4ee5\u9ad8\u6548\u63a7\u5236\u89e3\u5256\u5c5e\u6027\u3002", "result": "\u8bc1\u660e\u901a\u8fc7\u5c40\u90e8\u7ea6\u675f\u548c\u62d3\u6251\u7ea6\u675f\u5728\u63a8\u7406\u9636\u6bb5\u5bf9\u89e3\u5256\u7ed3\u6784\u8fdb\u884c\u51e0\u4f55\u4e0e\u62d3\u6251\u63a7\u5236\u7684\u53ef\u884c\u6027\uff1b\u6846\u67b6\u53ef\u7075\u6d3b\u5e94\u7528\u4e8e\u591a\u79cd\u89e3\u5256\u7cfb\u7edf\u3001\u8de8\u7ef4\u5ea6\u4e0e\u5750\u6807\u7cfb\uff0c\u4fbf\u4e8e\u4e3a\u865a\u62df\u8bd5\u9a8c\u548cML\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u5408\u6210\u6570\u636e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e00\u4e2a\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c40\u90e8\u63a7\u5236\u57df\u4e0e\u6301\u4e45\u540c\u8c03\u5b9e\u73b0\u5bf9\u89e3\u5256\u56fe\u7684\u51e0\u4f55\u4e0e\u62d3\u6251\u7684\u53ef\u63a7\u751f\u6210\uff0c\u4fc3\u8fdb\u89e3\u5256\u6570\u636e\u7684\u7406\u6027\u8bbe\u8ba1\u4e0e\u5e94\u7528\u3002"}}
{"id": "2511.20592", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.20592", "abs": "https://arxiv.org/abs/2511.20592", "authors": ["Mingxing Rao", "Bowen Qu", "Daniel Moyer"], "title": "Latent Diffusion Inversion Requires Understanding the Latent Space", "comment": "14 pages, 4 figures, 4 tables", "summary": "The recovery of training data from generative models (``model inversion'') has been extensively studied for diffusion models in the data domain. The encoder/decoder pair and corresponding latent codes have largely been ignored by inversion techniques applied to latent space generative models, e.g., Latent Diffusion models (LDMs). In this work we describe two key findings: (1) The diffusion model exhibits non-uniform memorization across latent codes, tending to overfit samples located in high-distortion regions of the decoder pullback metric. (2) Even within a single latent code, different dimensions contribute unequally to memorization. We introduce a principled method to rank latent dimensions by their per-dimensional contribution to the decoder pullback metric, identifying those most responsible for memorization. Empirically, removing less-memorizing dimensions when computing attack statistics for score-based membership inference attacker significantly improves performance, with average AUROC gains of 2.7\\% and substantial increases in TPR@1\\%FPR (6.42\\%) across diverse datasets including CIFAR-10, CelebA, ImageNet-1K, Pok\u00e9mon, MS-COCO, and Flickr. This indicates stronger confidence in identifying members under extremely low false-positive tolerance. Our results highlight the overlooked influence of the auto-encoder geometry on LDM memorization and provide a new perspective for analyzing privacy risks in diffusion-based generative models.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u6f5c\u5728\u7a7a\u95f4\u6269\u6563\u6a21\u578b\u7684\u8bb0\u5fc6\u6027\u5206\u6790\u4e0e\u7ef4\u5ea6\u6392\u5e8f\uff0c\u6539\u8fdb\u6210\u5458\u8eab\u4efd\u63a8\u65ad\u653b\u51fb\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u6269\u6563\u6a21\u578b\u7684\u8bb0\u5fc6\u6027\u7814\u7a76\u4e2d\uff0c\u5ffd\u7565\u4e86\u81ea\u7f16\u7801\u5668\u51e0\u4f55\u5bf9\u6f5c\u5728\u7f16\u7801\u7684\u5f71\u54cd\uff1b\u672c\u6587\u63ed\u793a\u6f5c\u5728\u7f16\u7801\u7684\u975e\u5747\u5300\u8bb0\u5fc6\u6027\u53ca\u5355\u4e2a\u7ef4\u5ea6\u7684\u8d21\u732e\u5dee\u5f02\uff0c\u5e76\u63a2\u8ba8\u5176\u5bf9\u9690\u79c1\u653b\u51fb\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u89e3\u7801\u56de\u62c9\uff08pullback\uff09\u7684\u5bf9\u6f5c\u5728\u7ef4\u5ea6\u8d21\u732e\u6392\u5e8f\u7684\u65b9\u6cd5\uff0c\u8bc6\u522b\u5bf9\u8bb0\u5fc6\u6027\u8d21\u732e\u6700\u5927\u7684\u7ef4\u5ea6\uff1b\u5728score-based\u6210\u5458\u8eab\u4efd\u63a8\u65ad\u653b\u51fb\u4e2d\u79fb\u9664\u8bb0\u5fc6\u6027\u8f83\u4f4e\u7684\u7ef4\u5ea6\u4ee5\u63d0\u9ad8\u653b\u51fb\u6027\u80fd\uff1b\u5728CIFAR-10\u3001CelebA\u3001ImageNet-1K\u3001 Pok\u00e9mon\u3001MS-COCO\u3001Flickr\u7b49\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u7ed9\u51faAUROC\u53caTPR@FPR\u7b49\u6307\u6807\u3002", "result": "\u79fb\u9664\u4f4e\u8bb0\u5fc6\u6027\u7ef4\u5ea6\u540e\uff0c\u5e73\u5747AUROC\u63d0\u5347\u7ea62.7%\uff0cTPR@1%FPR\u63d0\u5347\u7ea66.42%\uff0c\u5728\u591a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "\u5f3a\u8c03\u81ea\u7f16\u7801\u5668\u51e0\u4f55\u5728LDM\u8bb0\u5fc6\u6027\u4e2d\u7684\u4f5c\u7528\uff0c\u63d0\u4f9b\u5206\u6790 diffusion-based \u751f\u6210\u6a21\u578b\u9690\u79c1\u98ce\u9669\u7684\u65b0\u89c6\u89d2\uff0c\u5e76\u4e3a\u9690\u79c1\u9632\u62a4\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2511.20601", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20601", "abs": "https://arxiv.org/abs/2511.20601", "authors": ["Heman Shakeri"], "title": "The Driver-Blindness Phenomenon: Why Deep Sequence Models Default to Autocorrelation in Blood Glucose Forecasting", "comment": "7 pages, 1 figure", "summary": "Deep sequence models for blood glucose forecasting consistently fail to leverage clinically informative drivers--insulin, meals, and activity--despite well-understood physiological mechanisms. We term this Driver-Blindness and formalize it via $\u0394_{\\text{drivers}}$, the performance gain of multivariate models over matched univariate baselines. Across the literature, $\u0394_{\\text{drivers}}$ is typically near zero. We attribute this to three interacting factors: architectural biases favoring autocorrelation (C1), data fidelity gaps that render drivers noisy and confounded (C2), and physiological heterogeneity that undermines population-level models (C3). We synthesize strategies that partially mitigate Driver-Blindness--including physiological feature encoders, causal regularization, and personalization--and recommend that future work routinely report $\u0394_{\\text{drivers}}$ to prevent driver-blind models from being considered state-of-the-art.", "AI": {"tldr": "\u63d0\u51fa\u201cDriver-Blindness\u201d\u6982\u5ff5\uff1a\u5728\u8840\u7cd6\u9884\u6d4b\u4e2d\uff0c\u6df1\u5ea6\u5e8f\u5217\u6a21\u578b\u5f80\u5f80\u672a\u80fd\u6709\u6548\u5229\u7528\u4e34\u5e8a\u9a71\u52a8\u56e0\u5b50\uff08\u80f0\u5c9b\u7d20\u3001\u9910 meal\u3001\u6d3b\u52a8\u7b49\uff09\uff0c\u5bfc\u81f4\u591a\u53d8\u91cf\u6a21\u578b\u5bf9\u6bd4\u5355\u53d8\u91cf\u57fa\u7ebf\u7684\u6027\u80fd\u63d0\u5347\u4e0d\u8db3\u3002\u4f5c\u8005\u5c06\u0394_drivers\u5b9a\u4e49\u4e3a\u591a\u53d8\u91cf\u6a21\u578b\u76f8\u5bf9\u4e8e\u5339\u914d\u7684\u5355\u53d8\u91cf\u57fa\u7ebf\u7684\u6027\u80fd\u589e\u76ca\uff0c\u6587\u732e\u4e2d\u0394_drivers\u901a\u5e38\u63a5\u8fd1\u96f6\u3002", "motivation": "\u63ed\u793a\u4e3a\u4f55\u73b0\u6709\u6df1\u5ea6\u6a21\u578b\u672a\u80fd\u5145\u5206\u5229\u7528\u751f\u7406\u5b66\u4e0a\u91cd\u8981\u7684\u9a71\u52a8\u56e0\u5b50\uff0c\u91cf\u5316\u9a71\u52a8\u56e0\u7d20\u5bf9\u9884\u6d4b\u6027\u80fd\u7684\u8d21\u732e\uff0c\u63a8\u52a8\u6a21\u578b\u8bbe\u8ba1\u548c\u8bc4\u4f30\u7684\u6539\u8fdb\uff0c\u4f7f\u9884\u6d4b\u66f4\u5177\u4e34\u5e8a\u610f\u4e49\u3002", "method": " formalize \u0394_drivers \u7684\u6846\u67b6\u5e76\u5bf9\u76f8\u5173\u6587\u732e\u8fdb\u884c\u7efc\u5408\u5206\u6790\uff0c\u63d0\u51fa\u5bfc\u81f4\u9a71\u52a8\u5229\u7528\u4e0d\u8db3\u7684\u4e09\u5927\u56e0\u7d20C1-C3\uff1a\u67b6\u6784\u504f\u597d\u81ea\u76f8\u5173\u6027\u3001\u6570\u636e\u8d28\u91cf\u504f\u5dee\u53ca\u751f\u7406\u5f02\u8d28\u6027\u3002\u57fa\u4e8e\u6b64 synthesis \u51fa\u7f13\u89e3\u7b56\u7565\uff08\u5982\u751f\u7406\u7279\u5f81\u7f16\u7801\u5668\u3001\u56e0\u679c\u6b63\u5219\u5316\u3001\u4e2a\u6027\u5316\uff09\uff0c\u5e76\u5efa\u8bae\u672a\u6765\u5de5\u4f5c\u5728\u62a5\u544a\u4e2d\u7cfb\u7edf\u5448\u73b0 \u0394_drivers \u4ee5\u907f\u514d\u9a71\u52a8\u76f2\u6a21\u578b\u7ee7\u7eed\u88ab\u8bef\u8ba4\u4e3a\u662f\u6700\u5148\u8fdb\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8de8\u6587\u732e\u7684\u0394_drivers\u63a5\u8fd1\u96f6\uff0c\u539f\u56e0\u5728\u4e8eC1-C3\u7684\u76f8\u4e92\u4f5c\u7528\uff1a\u6a21\u578b\u67b6\u6784\u504f\u597d\u5bf9\u81ea\u76f8\u5173\u7684\u504f\u91cd\u3001\u6570\u636e\u9a71\u52a8\u56e0\u7d20\u7684\u566a\u58f0\u4e0e\u6df7\u6dc6\u4ee5\u53ca\u4eba\u7fa4\u5c42\u9762\u7684\u751f\u7406\u5f02\u8d28\u6027\u3002\u63d0\u51fa\u7684\u7f13\u89e3\u7b56\u7565\u80fd\u90e8\u5206\u7f13\u89e3\u9a71\u52a8\u76f2\uff0c\u4f46\u4ecd\u9700\u5728\u5b9e\u8df5\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u548c\u666e\u9002\u6027\u3002", "conclusion": "\u5e94\u5728\u672a\u6765\u5de5\u4f5c\u4e2d\u5f3a\u5236\u62a5\u544a \u0394_drivers\uff0c\u5e76\u7ed3\u5408\u751f\u7406\u7279\u5f81\u7f16\u7801\u3001\u56e0\u679c\u6b63\u5219\u5316\u4e0e\u4e2a\u6027\u5316\u7b49\u7b56\u7565\uff0c\u4ee5\u63d0\u5347\u591a\u53d8\u91cf\u6a21\u578b\u5bf9\u5173\u952e\u751f\u7406\u9a71\u52a8\u56e0\u5b50\u7684\u5229\u7528\u7387\uff0c\u4ece\u800c\u63d0\u5347\u4e34\u5e8a\u53ef\u7528\u6027\u548c\u7814\u7a76\u900f\u660e\u5ea6\u3002"}}
{"id": "2511.20621", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20621", "abs": "https://arxiv.org/abs/2511.20621", "authors": ["Adam Karvonen", "Daniel Reuter", "Roy Rinberg", "Luke Marks", "Adri\u00e0 Garriga-Alonso", "Keri Warr"], "title": "DiFR: Inference Verification Despite Nondeterminism", "comment": null, "summary": "As demand for LLM inference grows, it is becoming increasingly important that providers and their customers can verify that inference processes are performed correctly, without errors or tampering. However, re-running the same inference process twice often leads to different results due to benign numerical noise, making it difficult to distinguish legitimate variation from actual problems. To address this problem, we introduce Token-DiFR (Token-Divergence-From-Reference), a method for verifying inference outputs by comparing generated tokens against predictions made by a trusted reference implementation conditioned on the same random seed. Sampling seed synchronization tightly constrains valid outputs, leaving providers minimal room to deviate from correct inference, which allows output tokens themselves to serve as auditable evidence of correctness at zero additional cost to the provider. Token-DiFR reliably identifies sampling errors, simulated bugs, and model quantization, detecting 4-bit quantization with AUC $>$ 0.999 within 300 output tokens. For applications requiring sample-efficient forward-pass verification, we additionally introduce Activation-DiFR, a scheme that uses random orthogonal projections to compress activations into compact fingerprints for subsequent verification. Activation-DiFR detects 4-bit quantization with AUC $>$ 0.999 using just 2 output tokens, while reducing communication overhead by 25-75% relative to existing methods. We release an open-source integration with vLLM to accelerate practical deployment of verifiable inference.", "AI": {"tldr": "\u63d0\u51fa Token-DiFR \u548c Activation-DiFR\uff0c\u901a\u8fc7\u5bf9\u6bd4\u53d7\u4fe1\u4efb\u53c2\u8003\u5b9e\u73b0\u7684\u8f93\u51fa\u53ca\u6fc0\u6d3b\u6307\u7eb9\u6765\u9a8c\u8bc1\u5927\u6a21\u578b\u63a8\u7406\u7684\u6b63\u786e\u6027\uff0c\u80fd\u591f\u5728\u8f83\u5c11\u6837\u672c\u7684\u60c5\u51b5\u4e0b\u68c0\u6d4b\u91cf\u5316\u548c\u5b9e\u73b0\u9519\u8bef\uff0c\u5e76\u63d0\u4f9b\u5f00\u6e90\u96c6\u6210\u3002", "motivation": "\u968f\u7740\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u9700\u6c42\u7684\u589e\u957f\uff0c\u63d0\u4f9b\u8005\u4e0e\u7528\u6237\u9700\u8981\u53ef\u9760\u5730\u9a8c\u8bc1\u63a8\u7406\u8f93\u51fa\u662f\u5426\u6b63\u786e\u4e14\u672a\u88ab\u7be1\u6539\u3002\u4f46\u540c\u4e00\u63a8\u7406\u8fc7\u7a0b\u7684\u91cd\u590d\u6267\u884c\u5e38\u56e0\u6570\u503c\u566a\u58f0\u4ea7\u751f\u5dee\u5f02\uff0c\u96be\u4ee5\u533a\u5206\u5408\u7406\u6ce2\u52a8\u548c\u5b9e\u9645\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u53ef\u8bc1\u5b9e\u7684\u3001\u96f6\u9644\u52a0\u6210\u672c\u7684\u8f93\u51fa\u8bc1\u636e\u3002", "method": "Token-DiFR \u901a\u8fc7\u5c06\u751f\u6210 token \u4e0e\u4f7f\u7528\u76f8\u540c\u968f\u673a\u79cd\u5b50\u3001\u7ecf\u8fc7\u4fe1\u4efb\u53c2\u8003\u5b9e\u73b0\u7684\u9884\u6d4b\u8fdb\u884c\u5bf9\u6bd4\u6765\u9a8c\u8bc1\u63a8\u7406\u8f93\u51fa\uff1b\u91c7\u6837\u79cd\u5b50\u540c\u6b65\u4f7f\u6709\u6548\u8f93\u51fa\u53d7\u9650\uff0c\u8f93\u51fa token \u672c\u8eab\u53ef\u4f5c\u4e3a\u6b63\u786e\u6027\u7684\u53ef\u5ba1\u8ba1\u8bc1\u636e\u3002Activation-DiFR \u4f7f\u7528\u968f\u673a\u6b63\u4ea4\u6295\u5f71\u5c06\u6fc0\u6d3b\u538b\u7f29\u4e3a\u6307\u7eb9\u4ee5\u4fbf\u540e\u7eed\u9a8c\u8bc1\uff0c\u9002\u7528\u4e8e\u9700\u8981\u6837\u672c\u9ad8\u6548\u7684\u524d\u5411\u9a8c\u8bc1\u3002", "result": "Token-DiFR \u53ef\u5728\u524d 300 \u4e2a\u8f93\u51fa token \u5185\u5bf9 4-bit \u91cf\u5316\u5b9e\u73b0\u68c0\u6d4b\uff0cAUC > 0.999\uff1bActivation-DiFR \u4ec5\u7528 2 \u4e2a\u8f93\u51fa token \u5c31\u5b9e\u73b0 AUC > 0.999\uff0c\u4e14\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u901a\u4fe1\u5f00\u9500\u964d\u4f4e 25-75%\u3002\u5e76\u63d0\u4f9b\u4e0e vLLM \u7684\u5f00\u6e90\u96c6\u6210\u4ee5\u4fc3\u8fdb\u5b9e\u9645\u90e8\u7f72\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u63a8\u7406\u7ed3\u679c\u9a8c\u8bc1\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u540c\u5b9e\u73b0\u548c\u91cf\u5316\u60c5\u666f\u4e0b\u63d0\u5347\u63a8\u7406\u8fc7\u7a0b\u7684\u53ef\u9a8c\u8bc1\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u4e14\u6709\u5b9e\u9645\u90e8\u7f72\u7684\u843d\u5730\u652f\u6301\u3002"}}
{"id": "2511.20626", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20626", "abs": "https://arxiv.org/abs/2511.20626", "authors": ["Wei He", "Kai Han", "Hang Zhou", "Hanting Chen", "Zhicheng Liu", "Xinghao Chen", "Yunhe Wang"], "title": "ROOT: Robust Orthogonalized Optimizer for Neural Network Training", "comment": null, "summary": "The optimization of large language models (LLMs) remains a critical challenge, particularly as model scaling exacerbates sensitivity to algorithmic imprecision and training instability. Recent advances in optimizers have improved convergence efficiency through momentum orthogonalization, but suffer from two key robustness limitations: dimensional fragility in orthogonalization precision and vulnerability to outlier-induced noise. To address these robustness challenges, we introduce ROOT, a Robust Orthogonalized Optimizer that enhances training stability through dual robustness mechanisms. First, we develop a dimension-robust orthogonalization scheme using adaptive Newton iterations with fine-grained coefficients tailored to specific matrix sizes, ensuring consistent precision across diverse architectural configurations. Second, we introduce an optimization-robust framework via proximal optimization that suppresses outlier noise while preserving meaningful gradient directions. Extensive experiments demonstrate that ROOT achieves significantly improved robustness, with faster convergence and superior final performance compared to both Muon and Adam-based optimizers, particularly in noisy and non-convex scenarios. Our work establishes a new paradigm for developing robust and precise optimizers capable of handling the complexities of modern large-scale model training. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/ROOT.", "AI": {"tldr": "ROOT\u63d0\u51fa\u9c81\u68d2\u6b63\u4ea4\u5316\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u725b\u987f\u8fed\u4ee3\u5b9e\u73b0\u7ef4\u5ea6\u9c81\u68d2\u7684\u6b63\u4ea4\u5316\uff0c\u5e76\u7ed3\u5408\u8fd1\u7aef\u4f18\u5316\u6846\u67b6\u6291\u5236\u5f02\u5e38\u70b9\u566a\u58f0\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u4e0e\u6536\u655b\u901f\u5ea6\uff0c\u5728\u566a\u58f0\u548c\u975e\u51f8\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8eMuon\u4e0eAdam\u7b49\u4f18\u5316\u5668\u3002", "motivation": "\u5728\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\uff0c\u968f\u7740\u6a21\u578b\u89c4\u6a21\u589e\u52a0\uff0c\u5bf9\u6570\u503c\u7cbe\u5ea6\u7684\u654f\u611f\u6027\u4e0e\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u65e5\u76ca\u7a81\u51fa\u3002\u57fa\u4e8e\u52a8\u91cf\u7684\u6b63\u4ea4\u5316\u4f18\u5316\u5668\u5728\u9c81\u68d2\u6027\u65b9\u9762\u5b58\u5728\u7ef4\u5ea6\u8106\u5f31\u6027\u4e0e\u5bf9\u79bb\u7fa4\u566a\u58f0\u7684\u6613\u611f\u6027\u3002\u9700\u8981\u4e00\u79cd\u5728\u4e0d\u540c\u4f53\u7cfb\u7ed3\u6784\u4e0b\u90fd\u5177\u5907\u7ef4\u5ea6\u9c81\u68d2\u6027\u5e76\u5bf9\u5f02\u5e38\u70b9\u566a\u58f0\u5177\u5907\u9c81\u68d2\u6027\u7684\u4f18\u5316\u5668\u3002", "method": "\u63d0\u51fa\u4e24\u5927\u9c81\u68d2\u673a\u5236\uff1a1) \u7ef4\u5ea6\u9c81\u68d2\u6b63\u4ea4\u5316\uff1a\u4f7f\u7528\u81ea\u9002\u5e94\u725b\u987f\u8fed\u4ee3\uff0c\u7ed3\u5408\u5bf9\u77e9\u9635\u89c4\u6a21\u7684\u7ec6\u7c92\u5ea6\u7cfb\u6570\uff0c\u786e\u4fdd\u5728\u4e0d\u540c\u77e9\u9635\u5c3a\u5bf8\u4e0b\u4fdd\u6301\u7a33\u5b9a\u7684\u6b63\u4ea4\u5316\u7cbe\u5ea6\uff1b2) \u8fd1\u7aef\u4f18\u5316\u6846\u67b6\uff1a\u901a\u8fc7\u8fd1\u7aef\u4f18\u5316\u6291\u5236\u79bb\u7fa4\u566a\u58f0\uff0c\u540c\u65f6\u5c3d\u91cf\u4fdd\u7559\u6709\u610f\u4e49\u7684\u68af\u5ea6\u65b9\u5411\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0eMuon\u53ca\u57fa\u4e8eAdam\u7684\u4f18\u5316\u5668\u76f8\u6bd4\uff0cROOT\u5728\u9c81\u68d2\u6027\u3001\u6536\u655b\u901f\u5ea6\u548c\u6700\u7ec8\u6027\u80fd\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u5728\u5608\u6742\u548c\u975e\u51f8\u573a\u666f\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u4e3a\u73b0\u4ee3\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u5f00\u53d1\u9c81\u68d2\u4e14\u7cbe\u786e\u7684\u4f18\u5316\u5668\u6811\u7acb\u4e86\u65b0\u8303\u5f0f\uff0c\u4ee3\u7801\u5c06\u5728GitHub\u4e0a\u5f00\u6e90\u3002"}}
{"id": "2511.20636", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20636", "abs": "https://arxiv.org/abs/2511.20636", "authors": ["Ziyue Wang", "Yayati Jadhav", "Peter Pak", "Amir Barati Farimani"], "title": "Image2Gcode: Image-to-G-code Generation for Additive Manufacturing Using Diffusion-Transformer Model", "comment": null, "summary": "Mechanical design and manufacturing workflows conventionally begin with conceptual design, followed by the creation of a computer-aided design (CAD) model and fabrication through material-extrusion (MEX) printing. This process requires converting CAD geometry into machine-readable G-code through slicing and path planning. While each step is well established, dependence on CAD modeling remains a major bottleneck: constructing object-specific 3D geometry is slow and poorly suited to rapid prototyping. Even minor design variations typically necessitate manual updates in CAD software, making iteration time-consuming and difficult to scale. To address this limitation, we introduce Image2Gcode, an end-to-end data-driven framework that bypasses the CAD stage and generates printer-ready G-code directly from images and part drawings. Instead of relying on an explicit 3D model, a hand-drawn or captured 2D image serves as the sole input. The framework first extracts slice-wise structural cues from the image and then employs a denoising diffusion probabilistic model (DDPM) over G-code sequences. Through iterative denoising, the model transforms Gaussian noise into executable print-move trajectories with corresponding extrusion parameters, establishing a direct mapping from visual input to native toolpaths. By producing structured G-code directly from 2D imagery, Image2Gcode eliminates the need for CAD or STL intermediates, lowering the entry barrier for additive manufacturing and accelerating the design-to-fabrication cycle. This approach supports on-demand prototyping from simple sketches or visual references and integrates with upstream 2D-to-3D reconstruction modules to enable an automated pipeline from concept to physical artifact. The result is a flexible, computationally efficient framework that advances accessibility in design iteration, repair workflows, and distributed manufacturing.", "AI": {"tldr": "\u4ece\u56fe\u50cf\u76f4\u63a5\u751f\u6210 G-code\uff0c\u8df3\u8fc7 CAD/3D \u6a21\u578b\uff0c\u5f00\u542f\u7aef\u5230\u7aef\u7684\u6570\u636e\u9a71\u52a8\u539f\u578b\u5316\u3002", "motivation": "CAD \u5efa\u6a21\u5728\u8bbe\u8ba1\u8fed\u4ee3\u4e2d\u662f\u4e3b\u8981\u74f6\u9888\uff0c\u4fee\u6539 CAD \u4ee5\u9002\u914d\u5feb\u901f\u539f\u578b\u5316\u6210\u672c\u9ad8\u3001\u5468\u671f\u957f\u3002\u76f4\u63a5\u4ece\u56fe\u50cf\u5230\u53ef\u6267\u884c G-code \u7684\u65b9\u6cd5\u53ef\u964d\u4f4e\u95e8\u69db\u3001\u52a0\u901f\u8bbe\u8ba1\u5230\u6210\u54c1\u7684\u5faa\u73af\u3002", "method": "\u63d0\u51fa Image2Gcode\uff1a\u4ee5\u56fe\u50cf\u4e3a\u8f93\u5165\uff0c\u63d0\u53d6\u5207\u7247\u7ea7\u7ed3\u6784\u7ebf\u7d22\uff1b\u4f7f\u7528\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\uff08DDPM\uff09\u5bf9 G-code \u5e8f\u5217\u8fdb\u884c\u9010\u6b65\u53bb\u566a\uff0c\u5c06\u9ad8\u65af\u566a\u58f0\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u6253\u5370\u8f68\u8ff9\u548c\u6324\u51fa\u53c2\u6570\uff0c\u76f4\u63a5\u4ece\u89c6\u89c9\u8f93\u5165\u6620\u5c04\u5230\u672c\u5730\u5de5\u5177\u8def\u5f84\uff0c\u65e0\u9700\u663e\u5f0f 3D \u6a21\u578b\u3002\u5e76\u53ef\u4e0e 2D\u20133D \u91cd\u5efa\u6a21\u5757\u8026\u5408\uff0c\u5f62\u6210\u4ece\u6982\u5ff5\u5230\u7269\u4f53\u7684\u7aef\u5230\u7aef\u6d41\u6c34\u7ebf\u3002", "result": "\u76f4\u63a5\u7531\u4e8c\u7ef4\u56fe\u50cf\u751f\u6210 G-code\uff0c\u7701\u7565 CAD/STL \u7b49\u4e2d\u95f4\u73af\u8282\uff0c\u964d\u4f4e\u8fdb\u5165\u95e8\u69db\uff0c\u63d0\u5347\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u4e0e\u5206\u5e03\u5f0f\u5236\u9020\u7684\u6548\u7387\uff1b\u652f\u6301\u6309\u9700\u539f\u578b\u3001\u8fdc\u7a0b\u5236\u9020\uff0c\u4e14\u5177\u6709\u4e00\u5b9a\u7684\u8ba1\u7b97\u6548\u7387\uff1b\u53ef\u4e0e\u4e0a\u6e38\u7684 2D\u20133D \u91cd\u5efa\u6d41\u7a0b\u534f\u540c\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u8bbe\u8ba1\u8fed\u4ee3\u3001\u4fee\u590d\u5de5\u4f5c\u6d41\u4e0e\u5206\u5e03\u5f0f\u5236\u9020\u65b9\u9762\u63d0\u5347\u53ef\u53ca\u6027\uff0c\u5c55\u793a\u4e86\u4ece\u89c6\u89c9\u8f93\u5165\u76f4\u63a5\u6620\u5c04\u5230\u539f\u751f\u5de5\u5177\u8def\u5f84\u7684\u53ef\u884c\u6027\uff0c\u63a8\u52a8\u7aef\u5230\u7aef\u5236\u9020\u6d41\u7a0b\u7684\u53d1\u5c55\u3002"}}
