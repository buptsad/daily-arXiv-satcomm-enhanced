<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 1]
- [eess.SP](#eess.SP) [Total: 8]
- [eess.SY](#eess.SY) [Total: 18]
- [cs.LG](#cs.LG) [Total: 54]
- [cs.CR](#cs.CR) [Total: 8]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [LatencyScope: A System-Level Mathematical Framework for 5G RAN Latency](https://arxiv.org/abs/2511.21277)
*Arman Maghsoudnia,Aoyu Gong,Raphael Cannatà,Dan Mihai Dumitriu,Haitham Hassanieh*

Main category: cs.NI

TL;DR: LatencyScope提出一个对5G RAN单向时延的完整数学框架，结合层级建模和全局配置优化，在多个开源RAN测试床上验证，能贴近实测分布并超越现有分析模型与仿真工具，且可用于URRLC目标的配置搜索。


<details>
  <summary>Details</summary>
Motivation: 在复杂多变的5G RAN配置中，单向时延的来源跨越多个层次且具有随机性，现有分析和仿真工具往往难以同时准确建模各层耦合关系与巨大参数空间，亟需一个能够（i）从全栈角度量化时延来源和瓶颈，（ii）在数十亿级配置空间中高效寻优以满足URLCC目标的框架。

Method: 建立覆盖RAN各层的时延源模型，涵盖射频接口、调度策略、硬件/软件约束及其依赖与随机性；并设计一个配置优化器，能在极大配置空间中高效搜索，找出满足时延-可靠性目标的设置。

Result: 在两个开源5G RAN测试床srsRAN与OAI上进行验证，LatencScope的预测分布与实测分布高度吻合；相较于先前的分析模型与主流仿真工具（如MATLAB 5G Toolbox、5G-LENA）有显著性能提升；并且能够发现满足URLLC目标的系统配置，帮助运营商在系统层面做出更优配置决策。

Conclusion: LatencScope提供了一个可在多种系统配置下准确计算和优化5G RAN单向时延的工具化框架，提升对时延瓶颈的可解释性与可操作性，并能高效地为URLLC场景挑选合适的系统设置。

Abstract: This paper presents LatencyScope, a mathematical framework for accurately computing one-way latency (for uplink and downlink) in the 5G RAN across diverse system configurations. LatencyScope models latency sources at every layer of the Radio Access Network (RAN), pinpointing system-level bottlenecks--such as radio interfaces, scheduling policies, and hardware/software constraints--while capturing their intricate dependencies and their stochastic nature. LatencyScope also includes a configuration optimizer that uses its mathematical models to search through hundreds of billions of configurations and find settings that meet latency-reliability targets under user constraints. We validate LatencyScope on two open-sourced 5G RAN testbeds (srsRAN and OAI), demonstrating that it can closely match empirical latency distributions and significantly outperform prior analytical models and widely used simulators (MATLAB 5G Toolbox, 5G-LENA). It can also find system configurations that meet Ultra-Reliable Low-Latency Communications (URLLC) targets and enable network operators to efficiently identify the best setup for their systems.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [2] [WiRainbow: Single-Antenna Direction-Aware Wi-Fi Sensing via Dispersion Effect](https://arxiv.org/abs/2511.20671)
*Zhaoxin Chang,Shuguang Xiao,Fusang Zhang,Xujun Ma,Badii Jouaber,Qingfeng Zhang,Daqing Zhang*

Main category: eess.SP

TL;DR: WiRainbow通过单天线Wi-Fi感知实现方向感知，利用频率扫描天线的色散效应及耦合谐振结构扩展视场，并辅以基于信噪比的信号处理，在多径环境中实现高精度、鲁棒且成本低的定向估计。


<details>
  <summary>Details</summary>
Motivation: 现有定向感知多依赖天线阵列，成本高、部署复杂。需要一种低成本、易部署的单天线方案来实现Wi-Fi sensing中的目标方向信息。

Method: 利用频率扫描天线的色散效应将Wi-Fi子载波定向到不同角度；提出耦合谐振器天线结构以扩展FSAs的窄视场；开发基于 sensing SNR 的信号处理框架，在多径环境中可靠估计目标方向。

Result: 原型系统WiRainbow已实现，并通过基准实验与真实场景案例验证，显示在成本效益与鲁棒性方面具有良好表现，能够实现准确的方向感知。

Conclusion: 提供一种可扩展的单天线定向感知方案，降低部署成本、简化系统复杂度，并扩大Wi-Fi感知的实际应用场景。

Abstract: Recently, Wi-Fi signals have emerged as a powerful tool for contactless sensing. During the sensing process, obtaining target direction information can provide valuable contextual insights for various applications. Existing direction estimation methods typically rely on antenna arrays, which are costly and complex to deploy in real-world scenarios. In this paper, we present WiRainbow, a novel approach that enables single-antenna-based direction awareness for Wi-Fi sensing by leveraging the dispersion effect of frequency-scanning antennas (FSAs), which can naturally steer Wi-Fi subcarriers toward distinct angles during signal transmission. To address key challenges in antenna design and signal processing, we propose a coupled-resonator-based antenna architecture that significantly expands the narrow Field-of-View inherent in conventional FSAs, improving sensing coverage. Additionally, we develop a sensing signal-to-noise-ratio-based signal processing framework that reliably estimates target direction in multipath-rich environments. We prototype WiRainbow and evaluate its performance through benchmark experiments and real-world case studies, demonstrating its ability to achieve accurate, robust, and cost-effective direction awareness for diverse Wi-Fi sensing applications.

</details>


### [3] [A Fully Multivariate Multifractal Detrended Fluctuation Analysis Method for Fault Diagnosis](https://arxiv.org/abs/2511.20831)
*Khuram Naveed,Naveed ur Rehman*

Main category: eess.SP

TL;DR: 提出了一个全变量的多元MFDFA扩展 FM-MFDFA，并结合MVMD实现故障诊断，适用于多通道振动数据的跨通道相关性建模，效果优于传统MFDFA。


<details>
  <summary>Details</summary>
Motivation: 在多通道振动信号中，跨通道相关性和方差偏置对故障诊断的影响未被充分捕获；需要一种能同时处理多尺度结构与通道相关性的分析框架。

Method: 引入基于马氏距离的协方差加权 L_pq 矩阵范数来定义全变量的波动函数，形成 FM-MFDFA；结合 MVMD 分解以提取与故障相关分量，再应用 FM-MFDFA；在风电齿轮箱数据上验证。

Result: 在噪声条件下，FM-MFDFA 能更有效区分健康与故障状态，优于传统MFDFA。

Conclusion: 通过把多变量符号的跨通道相关性和方差偏置纳入波动分析，提供更准确的多尺度表征与故障诊断能力；MVMD 的事前分离增强了特征相关性提取。

Abstract: We propose a fully multivariate generalization of multifractal detrended fluctuation analysis (MFDFA) and leverage it to develop a fault diagnosis framework for multichannel machine vibration data. We introduce a novel covariance-weighted $L_{pq}$ matrix norm based on Mahalanobis distance to define a fully multivariate fluctuation function that uniquely captures cross-channel dependencies and variance biases in multichannel vibration data. This formulation, termed FM-MFDFA, allows for a more accurate characterization of the multiscale structure of multivariate signals. To enhance feature relevance, the proposed framework integrates multivariate variational mode decomposition (MVMD) to isolate fault-relevant components before applying FM-MFDFA. Results on wind turbine gearbox data demonstrate that the proposed method outperforms conventional MFDFA approaches by effectively distinguishing between healthy and faulty machine states, even under noisy conditions.

</details>


### [4] [Blind Turbo Demodulation for Differentially Encoded OFDM with 2D Trellis Decomposition](https://arxiv.org/abs/2511.21345)
*Chin-Hung Chen,Yan Wu,Wim van Houtum,Alex Alvarado*

Main category: eess.SP

TL;DR: 提出了一种完全盲的2D turbo-DE-PSK解调方案，通过2D树等级结构进行盲相位估计，并用基于功率的估计量估计信道增益和噪声方差，能在无导频条件下接近有完美信道知识时的性能。


<details>
  <summary>Details</summary>
Motivation: 在DAB类系统中，DE-PSK的迭代解调在不使用导频的情况下对信道估计敏感，亟需一种完全盲的解调方案以降低对导频的依赖并提高鲁棒性。

Method: 提出一个完全盲的turbo-DE-PSK结构，利用二维（2D）trellis分解进行盲相位估计，并辅以基于功率的估计量来估计信道增益和噪声方差。系统在多种实际参数设置下进行评估（内码长度、相位量化、2D块大小等），并将其嵌入到turbo解调框架中。

Result: 仿真结果表明，该盲2D turbo解调器的性能接近具有完美信道知识的接收机，且在现实传输条件下保持鲁棒性。

Conclusion: 所提出的盲2D turbo-DE-PSK方案在无需导频的情况下实现接近最优信道知识的性能，是DAB类系统中对导频依赖较大场景的一种有前景的解决方案。

Abstract: Digital Audio Broadcasting (DAB)-like systems employ differentially encoded (DE) phase-shift keying (PSK) for transmission. While turbo-DE-PSK receivers offer substantial performance gains through iterative decoding by making the DE-PSK an inner code, they rely on accurate channel estimation without pilots, which is a key challenge in DAB-like scenarios. This paper develops a fully blind turbo-DE-PSK scheme that jointly estimates channel phase, channel gain, and noise variance directly from the received signal. The design leverages a two-dimensional (2D) trellis decomposition for blind phase estimation, complemented by power-based estimators for channel gain and noise variance. We provide a comprehensive system assessment across practical system parameters, including inner code length, phase quantization, and 2D block size. Simulation results show that the blind 2D turbo demodulator approaches the performance of receivers with perfect channel knowledge and remains robust under realistic transmission conditions.

</details>


### [5] [Data-Driven Assessment of Concrete Slab Integrity via Impact-Echo Signals and Neural Networks](https://arxiv.org/abs/2511.21080)
*Yeswanth Ravichandran,Duoduo Liao,Charan Teja Kurakula*

Main category: eess.SP

TL;DR: ML-based Impact Echo framework for automated defect localization and multi-class classification of concrete defects using FFT-derived peak-frequency features, k-means clustering, GTMs for labels, and a stacked LSTM, achieving 73% accuracy; validated on lab and field data for scalable NDE of bridge decks.


<details>
  <summary>Details</summary>
Motivation: Subsurface defects (delamination, voids, honeycombing) critically affect concrete bridge deck durability and are hard to detect reliably by visual methods. A data-driven, scalable, and objective NDE approach is needed for bridge health monitoring.

Method: Transform IE signals via FFT to dominant peak-frequency features; interpolate into spatial maps for defect visualization. Use unsupervised k-means to identify defect-prone regions. Generate training labels with Ground Truth Masks (GTMs) derived from seeded lab defects. Construct spatially ordered peak-frequency sequences and feed into a stacked LSTM to classify four defect types: shallow delamination, deep delamination, voids, honeycombing.

Result: Achieves 73% overall accuracy in defect classification. Field validation shows models trained on laboratory data generalize under realistic coupling, noise, and environmental variability.

Conclusion: The framework improves objectivity, scalability, and repeatability of NDE and supports data-driven bridge health monitoring at a network scale.

Abstract: Subsurface defects such as delamination, voids, and honeycombing critically affect the durability of concrete bridge decks but are difficult to detect reliably using visual inspection or manual sounding. This paper presents a machine learning based Impact Echo (IE) framework that automates both defect localization and multi-class classification of common concrete defects. Raw IE signals from Federal Highway Administration (FHWA) laboratory slabs and in-service bridge decks are transformed via Fast Fourier Transform (FFT) into dominant peak-frequency features and interpolated into spatial maps for defect zone visualization. Unsupervised k-means clustering highlights low-frequency, defect-prone regions, while Ground Truth Masks (GTMs) derived from seeded lab defects are used to validate spatial accuracy and generate high-confidence training labels. From these validated regions, spatially ordered peak-frequency sequences are constructed and fed into a stacked Long Short-Term Memory (LSTM) network that classifies four defect types shallow delamination, deep delamination, voids, and honeycombing with 73% overall accuracy. Field validation on the bridge deck demonstrates that models trained on laboratory data generalize under realistic coupling, noise, and environmental variability. The proposed framework enhances the objectivity, scalability, and repeatability of Non-Destructive Evaluation (NDE), supporting intelligent, data-driven bridge health monitoring at a network scale.

</details>


### [6] [2D Sparse Array Design via Reweighted L1 Second Order Cone Programming for 3D Ultrasound Imaging](https://arxiv.org/abs/2511.21133)
*Xi Zhang,Miguel Bernal,Wei-Ning Lee*

Main category: eess.SP

TL;DR: 提出基于SOCP的重加权L1稀疏阵列优化方法，用于二维全定向超声阵列的3D成像，在256通道约束下设计出252个激活元件的Q-Flats稀疏阵列，实现分辨率与对比度的有效折衷。


<details>
  <summary>Details</summary>
Motivation: 解决二维全定向阵列在实现3D成像时对通道数需求过高的问题，同时缓解基于随机化稀疏化方法造成的结果不稳定性；需要鲁棒且可控的设计框架。

Method: 将稀疏阵列综合问题建模为二阶锥规划（SOCP），并结合重加权L1策略进行迭代优化。设计出_on-grid_的Q-Flats稀疏阵列，SLL≤-21.26 dB，252个活跃元素，且受256通道上限约束；通过Field II在多角度扇形发射场景中，与Dense、Spiral、Spiral-Taper进行对比。

Result: Dense在分辨率和对比度方面最佳；Spiral-Taper最差。Q-Flats在分辨率上优于Spiral约3%，对比度略差于Spiral，但在256通道约束内实现了较好的折衷。重加权L1 SOCP方法对分辨率、对比度与活跃元素数之间的权衡具有良好灵活性。

Conclusion: 所提出的重加权L1 SOCP稀疏设计方法是实现稀疏阵列MIMO成像的有前景的、灵活的工具，可在分辨率、对比度与通道数之间取得有效折衷。

Abstract: Two-dimensional (2D) fully-addressed arrays can conveniently realize three-dimensional (3D) ultrasound imaging while fully controlled such arrays usually demands thousands of independent channels, which is costly. Sparse array technique using stochastic optimization methods is one of promising techniques to reduce channel counts while due to the stochastic nature of these methods, the optimized results are usually unstable. In this work, we introduce a sparse array design approach that formulates the synthesis problem of sparse arrays as second-order cone programming (SOCP) and a re-weighted L1 technique is implemented to sequentially optimize the SOCP. Based on this method, an on-grid quasi-flatten side-lobe (Q-Flats) 2D sparse array with side-lobe level (SLL) no more than -21.26 dB and 252 activated elements is designed, which aims to achieve as high contrast performance as possible under the limits of resolution and maximum number of independent channels (i.e., 256). The imaging performance of the Q-Flats array was compared with those of a corresponding dense array (Dense), a Fermat spiral array (Spiral) and a spatially 50%-Tukey tapered spiral array (Spiral-Taper) using Field II simulations in a multi-angle steered diverging wave transmission scheme. It was demonstrated that the Dense achieved the best resolution and contrast and the Spiral-Taper the worst. The Q-Flats showed better resolution (about 3%) but slightly worse contrast than the Spiral. All the results indicate the re-weighted L1 SOCP method is a promising and flexible method for seeking trade-offs among resolution, contrast, and number of activated elements.

</details>


### [7] [Multiport Analytical Pixel Electromagnetic Simulator (MAPES) for AI-assisted RFIC and Microwave Circuit Design](https://arxiv.org/abs/2511.21274)
*Junhui Rao,Yi Liu,Jichen Zhang,Zhaoyang Ming,Tianrui Qiao,Yujie Zhang,Chi Yuk Chiu,Hua Wang,Ross Murch*

Main category: eess.SP

TL;DR: MAPES is a physics-based analytical framework that predicts EM performance of pixel-based MW/RFIC structures with high accuracy and huge speed gains by constructing a single multiport impedance matrix from a small set of full-wave simulations and then evaluating any pixel configuration analytically.


<details>
  <summary>Details</summary>
Motivation: There is a need for fast, accurate, and generalizable EM prediction for pixel-based designs in AI-assisted EM design, where data-driven methods suffer from overfitting and computational cost is high.

Method: MAPES extends the Integrated Internal Multiport Method (IMPM) to the pixel presence/absence domain by introducing virtual pixels and diagonal virtual pixels and inserting virtual ports at critical locations. This creates a single multiport impedance matrix that captures horizontal, vertical, and diagonal couplings. Only a small set of full-wave simulations (about 1% of what typical AI-assisted EM simulators require) are required to populate the matrix. Any arbitrary pixel configuration can then be evaluated analytically via a closed-form multiport relation without further full-wave computations.

Result: MAPES delivers high prediction accuracy with 600–2000× speed-up compared to CST simulations, validated on single- and double-layer CMOS processes (180 nm and 65 nm) and PCBs, demonstrating efficiency, scalability, and reliability for AI-assisted MW circuit and RFIC design across technologies.

Conclusion: MAPES provides a practical and versatile tool for AI-assisted microwave and RFIC design, offering fast, accurate EM predictions across diverse fabrication technologies while avoiding data-driven overfitting.

Abstract: This paper proposes a novel analytical framework, termed the Multiport Analytical Pixel Electromagnetic Simulator (MAPES). MAPES enables efficient and accurate prediction of the electromagnetic (EM) performance of arbitrary pixel-based microwave (MW) and RFIC structures. Inspired by the Integrated Internal Multiport Method (IMPM), MAPES extends the concept to the pixel presence/absence domain used in AI-assisted EM design. By introducing virtual pixels and diagonal virtual pixels and inserting virtual ports at critical positions, MAPES captures all horizontal, vertical, and diagonal electromagnetic couplings within a single multiport impedance matrix. Only a small set of full-wave simulations (typically about 1% of the datasets required by AI-assisted EM simulators) is needed to construct this matrix. Subsequently, any arbitrary pixel configuration can be evaluated analytically using a closed-form multiport relation without additional full-wave calculations. The proposed approach eliminates data-driven overfitting and ensures accurate results across all design variations. Comprehensive examples for single- and double-layer CMOS processes (180 nm and 65 nm) and PCBs confirm that MAPES achieves high prediction accuracy with 600- 2000x speed improvement compared to CST simulations. Owing to its efficiency, scalability and reliability, MAPES provides a practical and versatile tool for AI-assisted MW circuit and RFIC design across diverse fabrication technologies.

</details>


### [8] [Phase-Aware Code-Aided EM Algorithm for Blind Channel Estimation in PSK-Modulated OFDM](https://arxiv.org/abs/2511.21340)
*Chin-Hung Chen,Ivana Nikoloska,Wim van Houtum,Yan Wu,Alex Alvarado*

Main category: eess.SP

TL;DR: 提出了一种全盲的相位感知EM算法用于PSK调制的OFDM系统，通过利用解码器的外部信息作为模型证据，并基于PSK对称性构建有限候选模型集合，选择最可能的模型来解决相位模糊问题，且初始化阶段仅调用一次，后续 turbo 迭代的额外复杂度很小。


<details>
  <summary>Details</summary>
Motivation: 盲信道估计中的相位模糊导致局部极大值问题，传统盲EM难以消除相位歧义，从而影响收敛性和估计质量。需要一种机制在初始化阶段以及后续迭代中有效解除相位歧义并保持较低复杂度。

Method: 在EM框架中引入来自解码器的外部信息，将PSK调制的对称性转化为有限的候选模型集合；通过解码器对这些候选模型进行比较，选取最可能的模型以消除相位歧义，并在EM初始化后进行一次性调用，后续 turbo 迭代的额外复杂度基本可忽略。

Result: 仿真结果表明：结合简单卷积码时，该相位感知EM算法在初始化阶段就能稳定解决相位歧义，局部收敛失败率由80%降至接近0%；在具有频率选择性的信道且相位恒定的情况下表现良好，后续 turbo 迭代中的额外复杂度几乎可以忽略。

Conclusion: 通过基于PSK对称性的候选模型以及解码器证据的结合，该方法有效消除了盲信道估计中的相位模糊问题，提升了OFDM的盲信道估计鲁棒性，同时保持低额外计算开销。

Abstract: This paper presents a fully blind phase-aware expectation-maximization (EM) algorithm for OFDM systems with the phase-shift keying (PSK) modulation. We address the well-known local maximum problem of the EM algorithm for blind channel estimation. This is primarily caused by the unknown phase ambiguity in the channel estimates, which conventional blind EM estimators cannot resolve. To overcome this limitation, we propose to exploit the extrinsic information from the decoder as model evidence metrics. A finite set of candidate models is generated based on the inherent symmetries of PSK modulation, and the decoder selects the most likely candidate model. Simulation results demonstrate that, when combined with a simple convolutional code, the phase-aware EM algorithm reliably resolves phase ambiguity during the initialization stage and reduces the local convergence rate from 80% to nearly 0% in frequency-selective channels with a constant phase ambiguity. The algorithm is invoked only once after the EM initialization stage, resulting in negligible additional complexity during subsequent turbo iterations.

</details>


### [9] [Design Of A Communication System To Send Text Using Lora At 400 MHz](https://arxiv.org/abs/2511.21434)
*Fabrizio André Farfán Prado,William César Pérez Campos,Steisy Anahi Carreño Tacuri,Favio David Cabrera Alva,Harold Jacobed Carhuas Lizarbe*

Main category: eess.SP

TL;DR: Design and implementation of a low-power text transmission system using ESP32 + LoRa (DXLR01) at 433 MHz, leveraging CSS modulation; data displayed on LCD and uploaded to ThingSpeak; demonstrates feasibility in rural/limited networks with latency ~3.2 s.


<details>
  <summary>Details</summary>
Motivation: Address connectivity and energy-efficiency gaps in areas with no reliable Wi‑Fi/mobile coverage; long-range, low-power wireless communication is needed.

Method: Hardware: ESP32 with LoRa DXLR01 (433 MHz); configure parameters to maximize range and energy efficiency; use Chirp Spread Spectrum modulation; capture, process, and transmit messages; LCD display; forward received data to ThingSpeak for remote storage/visualization.

Result: Controlled-environment tests show average transmission latency of 3.2 seconds; successful reception and display; data also pushed to ThingSpeak enabling remote monitoring.

Conclusion: Demonstrates feasibility of low-power, long-range text transmission for remote monitoring and control; CSS-based LoRa with ESP32 can operate in infrastructure-limited environments; potential for further optimization and real-world deployment.

Abstract: This work describes the design and implementation of a low-power wireless communication system for transmitting text using ESP32 modules and the LoRa DXLR01. The proposal arises as a solution to connectivity and energy-efficiency problems commonly found in rural areas and certain urban environments where Wi-Fi or mobile networks are unavailable or operate with limitations. To address this, LoRa technology known for its long-range capability and low power consumption is integrated with an ESP32 responsible for capturing, processing, and sending messages.
  The LoRa DXLR01 module, which operates in the 433 MHz band, is configured with parameters aimed at maximising both transmission range and efficient energy usage. Messages are sent using Chirp Spread Spectrum (CSS) modulation, improving signal penetration in obstructed areas and reducing the likelihood of errors. On the receiving end, the ESP32 interprets the data and displays it on an LCD screen. Additionally, the received information is sent to the ThingSpeak platform, allowing remote storage and visualisation without relying on conventional network infrastructure.
  Tests conducted in a controlled environment show an average latency of 3.2 seconds for text transmission. It was also verified that the system can be used in applications such as remote monitoring, infrastructure management, and access control.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [10] [Dynamic Modeling of Load Demand in Electrified Highways Based on the EV Composition](https://arxiv.org/abs/2511.20874)
*Ashutossh Gupta,Vassilis Kekatos,Dionysios Aliprantis,Steve Pekarek*

Main category: eess.SY

TL;DR: 本文提出在固定速度下，将电动汽车(EV)在充电道路(ER)上的动态无线电力传输(DWPT)负载进行时域与频域建模，比较非线性与线性控制对谐波的影响，研究不同Rx线圈长度与EV组成对总负载频谱的影响，并以交通仿真数据进行验证，为电网运营和ER设计提供见解。


<details>
  <summary>Details</summary>
Motivation: 随着ER配备DWPT，EV对路面耦合的可变负载成为电力系统动态研究的关键因素。需要对单个EV和汇总层面的DWPT负载在时域和频域的特性进行建模，以评估对电网稳定性和谐波影响。

Method: 在恒速条件下，对单个EV在ER上的DWPT负载进行时域与频域建模；比较在DWPT-enabled EV中，非线性控制与线性控制对负载谐波的影响，推导Rx线圈长度对谐波幅值的影响规律；提出并分析ER段总DWPT负载的随机模型，研究EV组成对总负载频谱的影响；利用交通仿真器的真实流量数据对理论结果进行验证。

Result: 关键发现包括：1) 非线性控制能使负载谐波幅值较线性控制更低，谐波对稳定性有积极意义；2) 根据模型，EV的Rx线圈长度越长，谐波幅值呈下降趋势；3) ER段的总负载频谱受到EV组成的影响，更多带有较长Rx线圈的车辆（如货车）并不一定降低谐波。研究结果在基于现实交通流的仿真中得到验证。

Conclusion: 研究揭示了DWPT负载的时频行为及其对ER设计和电网运营的影响，为ER设计者和电网运营者提供了评估负载谐波的重要工具，并指出了不同EV组成在减小/控制谐波方面并非简单线性关系，便于在实际部署中进行负载谱优化。

Abstract: Electrified roadways (ERs) equipped with the dynamic wireless power transfer (DWPT) technology can achieve longer driving range and reduce on-board battery requirements for electric vehicles (EVs). Due to the spatial arrangement of transmitter (Tx) coils embedded into the ER pavement, the power drawn by the EV's receiver (Rx) coil is oscillatory in nature. Therefore, understanding the dynamic behavior of the total DWPT load is important for power system dynamic studies. To this end, we model the load of individual EVs in the time and frequency domains for constant EV speed. We establish that a nonlinear control scheme implemented in existing DWPT-enabled EVs exhibits milder frequency harmonics compared to its linear alternative. According to this model, the harmonics of an EV load decrease in amplitude with the Rx coil length. We further propose and analyze stochastic models for the total DWPT load served by an ER segment. Our models explain how the EV composition on the ER affects its frequency spectrum. Interestingly, we show that serving more EVs with longer Rx coils (trucks) does not necessarily entail milder harmonics. Our analytical findings are corroborated using realistic flows from a traffic simulator and offer valuable insights to grid operators and ER designers.

</details>


### [11] [Adaptive Lighting Control in Visible Light Systems: An Integrated Sensing, Communication, and Illumination Framework](https://arxiv.org/abs/2511.21271)
*Xinyan Xie,Xuesong Wang,Xin Lai,Yongheng Wen,Fengrui Yang,Haoyang He,Lai Zhang,Dong Zhao*

Main category: eess.SY

TL;DR: Adaptive ISCI framework for indoor VLC that uses a geometric partition of the receiving plane and NLOS-based localization to switch optimization objectives, achieving energy savings and improved SNR uniformity while meeting illumination constraints and maintaining high localization accuracy.


<details>
  <summary>Details</summary>
Motivation: To resolve the conflict among high data-rate/sensing performance, energy consumption, and user visual comfort in indoor VLCISAC systems by prioritizing energy efficiency and making objective functions adaptive to user position.

Method: Partition the receiving plane into an activity area and a surrounding non-activity area using a geometric approach. Use NLOS sensing to determine user location, which acts as a dynamic switch for the optimization objective. When the user is in the activity area, the system minimizes total transmit power while ensuring communications and illumination; when in the non-activity area, it maximizes SNR uniformity. The framework adapts in real time to user position.

Result: The adaptive ISCI approach achieves 53.59% energy savings compared with a non-adaptive system, and improves SNR uniformity by 57.79%. It also satisfies all illumination constraints and achieves a mean localization error of 0.071 m.

Conclusion: An adaptive, location-aware ISCI framework can efficiently balance energy efficiency, communication/illumination performance, and visual comfort in indoor VLC, providing significant energy savings and uniform sensing performance with precise localization.

Abstract: Indoor visible light communication (VLC) is a promising sixth-generation (6G) technology, as its directional and sensitive optical signals are naturally suited for integrated sensing and communication (ISAC). However, current research mainly focuses on maximizing data rates and sensing accuracy, creating a conflict between high performance, high energy consumption, and user visual comfort. This paper proposes an adaptive integrated sensing, communication, and illumination (ISCI) framework that resolves this conflict by treating energy savings as a primary objective. The framework's mechanism first partitions the receiving plane using a geometric methodology, defining an activity area and a surrounding non-activity area to match distinct user requirements. User location, determined using non-line-of-sight (NLOS) sensing, then acts as a dynamic switch for the system's optimization objective. The system adaptively shifts between minimizing total transmit power while guaranteeing communication and illumination performance in the activity area and maximizing signal-to-noise ratio (SNR) uniformity in the non-activity area. Numerical results confirm that this adaptive ISCI approach achieves 53.59% energy savings over a non-adaptive system and improves SNR uniformity by 57.79%, while satisfying all illumination constraints and maintaining a mean localization error of 0.071 m.

</details>


### [12] [Adaptive Gradient Descent MPPT Algorithm With Complexity-Aware Benchmarking for Low-Power PV Systems](https://arxiv.org/abs/2511.20895)
*Kimia Ahmadi,Wouter A. Serdijn*

Main category: eess.SY

TL;DR: 提出一种针对低功耗光伏系统的实时MPPT算法，结合自适应梯度下降的步进调节来改进经典扰动观察法（P&O），并可选地在偏光和快速光照变化条件下进行全局最大功率点追踪（GMPP）初始化。与多种拓扑、温度条件及实际数据集对比，算法在STC和PSC下均显示高效能与低复杂度，且优于35个同类P&O MPPT算法，适合集成到低功耗PMIC中。


<details>
  <summary>Details</summary>
Motivation: 在快速变化的光照和部分遮挡条件下实现低功耗、实时且鲁棒的MPPT，以减少追踪时间和稳态振荡，同时降低实现复杂度以便集成到PMIC中。

Method: 在经典P&O的基础上引入自适应梯度下降机制，根据瞬时功率-电压斜率动态缩放扰动步长；提供可选的GMPP初始化以提升PSC下的全局搜索能力；通过对不同变换器拓扑、温度和基于实际 irradiance 记录的仿真/测试进行评估，并进行门级复杂度归一化分析与统一FoM评估。

Result: MPPT效率在STC达到99.94%，对实验数据为99.21%，各温度情形>99.6%；在PSC条件下，GMPP初始化可提升追踪效率最高7.8%；FoM分析显示在35个P&O-based算法中具有领先地位，门级复杂度低，拓扑无关。

Conclusion: 所提出的自适应P&O-梯度下降MPPT在动态、资源受限的环境中表现鲁棒且高效，适合在低功耗PMIC中实现，与多种拓扑和温度条件相容。

Abstract: This paper proposes a computationally efficient, real-time maximum power point tracking (MPPT) algorithm tailored for low-power photovoltaic (PV) systems operating under fast-changing irradiance and partial shading conditions (PSC). The proposed method augments the classical perturb and observe (P&O) algorithm with an adaptive gradient descent mechanism that dynamically scales the perturbation step size based on the instantaneous power-voltage slope, thereby minimizing tracking time and steady-state oscillations. An optional initialization routine enhances global MPP (GMPP) tracking under PSC. Extensive simulations, including irradiance recordings from freely moving rodent subjects relevant to the targeted application, and tests across varying converter topologies and temperatures, demonstrate its robust, topology-independent performance. The proposed algorithm achieves 99.94 percent MPPT efficiency under standard test conditions (STC), 99.21 percent when applied to experimental data, and more than 99.6 percent for the tested temperature profiles. Under PSC, the initialization routine improves tracking efficiency by up to 7.8 percent. A normalized gate-level complexity analysis and a unified figure-of-merit (FoM) incorporating efficiency, tracking time, and computational cost demonstrate that the proposed algorithm outperforms 35 state-of-the-art P&O-based MPPT algorithms. These results underscore its suitability for integration in low-power power management integrated circuits (PMICs) operating under dynamic and resource-constrained conditions.

</details>


### [13] [Data-Driven Post-Event Analysis with Real-World Oscillation Data from Denmark](https://arxiv.org/abs/2511.20939)
*Youhong Chen,Debraj Bhattacharjee,Balarko Chaudhuri,Mark O Malley,Nan Qin,Adrian Pilkaer Expethit*

Main category: eess.SY

TL;DR: 使用扩展动态模态分解（EDMD）基于Koopman理论，从19个PMU数据中识别导致0.2 Hz振荡的主要源头，在丹麦真实事件中与 Energinet 的确认一致，优于常规的能量流耗散法（DEF）。


<details>
  <summary>Details</summary>
Motivation: 解决在缺乏详尽系统模型信息时，快速、无模型依赖地定位电网振荡源，以便进行针对性稳定性改进和减震措施。

Method: 对丹麦0.15 Hz 实际事件的PMU数据（不同电压等级、19个PMU，电压与电流相量）应用EDMD；在盲测试设置下不使用额外系统信息，定位主要源头并与 Energinet 的事后确认进行比对，同时与 DEF 法等传统方法进行对照。

Result: EDMD 能准确定位引发0.2 Hz振荡的主源，此源点与 Energinet 后续确认的问题 IBR 电厂一致；DEF 方法未能清晰识别该厂；研究与 Energinet 的验证以及先前的模拟ISO-NE研究结果一致，显示 EDMD 在事后分析中的有效性。

Conclusion: 基于EDMD的事后分析在识别电网主要振荡源并实现定向减振方面具有潜力，有望作为无模型数据驱动的有力工具用于SSO（稳态安全性优化）中的目标定位。

Abstract: This paper demonstrates how Extended Dynamic Mode Decomposition (EDMD), grounded in Koopman operator theory, can effectively identify the main contributor(s) to oscillations in power grids. We use PMU data recorded from a real 0.15 Hz oscillation event in Denmark for post-event analysis. To this end, the EDMD algorithm processed only voltage and current phasors from nineteen PMUs at different voltage levels across the Danish grid. In such a blind-test setting with no supplementary system information, EDMD accurately pinpointed the location of the main contributor to the 0.2 Hz oscillation, consistent with the location of the problematic IBR plant later confirmed by Energinet, where the underlying cause was a control system issue. Conventional approaches, such as the dissipating energy flow (DEF) method used in the ISO-NE OSL tool did not clearly identify this plant. This joint validation with Energinet, reinforcing earlier studies using simulated IBR-dominated systems and real PMU data from ISO-NE, highlights the potential of EDMD-based post-event analysis for identifying major oscillation contributors and enabling targeted SSO mitigation.

</details>


### [14] [Independent policy gradient-based reinforcement learning for economic and reliable energy management of multi-microgrid systems](https://arxiv.org/abs/2511.20977)
*Junkai Hu,Li Xia*

Main category: eess.SY

TL;DR: 提出一种基于均值-方差的多微网能量管理博弈，并给出分布式独立策略梯度方案及其深度强化学习扩展，兼顾经济性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 在含分布式可再生能源的多微网系统中，需同时提升经济性与系统可靠性；仅优化期望奖励往往忽略风险/方差。

Method: 将问题建模为均值-方差团队随机博弈(MV-TSG)，提出在已知模型参数下的分布式独立策略梯度算法；在未知参数时，提出基于独立策略梯度的深度强化学习算法以实现数据驱动的策略优化。

Result: 给出收敛性分析；通过两种场景的数值实验验证所提出方法在分布式计算环境下有效，达成经济性与可靠性之间的折中。

Conclusion: 方法充分利用MMS的分布式计算能力，提供经济性与运行可靠性之间的平衡解，具备在大规模场景中的适用性。

Abstract: Efficiency and reliability are both crucial for energy management, especially in multi-microgrid systems (MMSs) integrating intermittent and distributed renewable energy sources. This study investigates an economic and reliable energy management problem in MMSs under a distributed scheme, where each microgrid independently updates its energy management policy in a decentralized manner to optimize the long-term system performance collaboratively. We introduce the mean and variance of the exchange power between the MMS and the main grid as indicators for the economic performance and reliability of the system. Accordingly, we formulate the energy management problem as a mean-variance team stochastic game (MV-TSG), where conventional methods based on the maximization of expected cumulative rewards are unsuitable for variance metrics. To solve MV-TSGs, we propose a fully distributed independent policy gradient algorithm, with rigorous convergence analysis, for scenarios with known model parameters. For large-scale scenarios with unknown model parameters, we further develop a deep reinforcement learning algorithm based on independent policy gradients, enabling data-driven policy optimization. Numerical experiments in two scenarios validate the effectiveness of the proposed methods. Our approaches fully leverage the distributed computational capabilities of MMSs and achieve a well-balanced trade-off between economic performance and operational reliability.

</details>


### [15] [An Exact, Finite Dimensional Representation for Full-Block, Circle Criterion Multipliers](https://arxiv.org/abs/2511.20995)
*Felix Biertümpfel,Bin Hu,Geir Dullerud,Peter Seiler*

Main category: eess.SY

TL;DR: 提出一种有限维描述集合的方法，用于完整的全块圆判别乘子，解决全集合需无穷多约束的问题。


<details>
  <summary>Details</summary>
Motivation: 在离散时间线性系统与相分段非线性反馈中，圆判别乘子提供的稳定性/性能条件通常受限于全集合的不可计算性；完整集合理论上最少保守，但实现困难。

Method: 将全块圆判别乘子与非重复的 sector-bounded 非线性输入输出对的集合等价为一个增量对集合，并引入一个针对分段线性函数的构造以实现有限维描述；通过有限个矩阵共正性约束来刻画该集合。

Result: 给出可计算的判据，当非线性输入输出维度较小时（≤4）可实现精确描述；提供一个简单示例验证。

Conclusion: 该工作提供无损且可实现的有限维描述，降低全块圆判别乘子在实际问题中的保守性与计算复杂度，适用于小维非线性输入输出场景。

Abstract: This paper provides the first finite-dimensional characterization for the complete set of full-block, circle criterion multipliers. We consider the interconnection of a discrete-time, linear time-invariant system in feedback with a non-repeated, sector-bounded nonlinearity. Sufficient conditions for stability and performance can be derived using: (i) dissipation inequalities, and (ii) Quadratic Constraints (QCs) that bound the input/output pairs of the nonlinearity. Larger classes of QCs (or multipliers) reduce the conservatism of the conditions. Full-block, circle criterion multipliers define the complete set of all possible QCs for non-repeated, sector-bounded nonlinearities. These provide the least conservative conditions. However, full-block multipliers are defined by an uncountably infinite number of constraints and hence do not lead to computationally tractable solutions if left in this raw form. This paper provides a new finite-dimensional characterization for the set of full-block, circle criterion multipliers. The key theoretical insight is: the set of all input/output pairs of non-repeated sector-bounded nonlinearities is equal to the set of all incremental pairs for an appropriately constructed piecewise linear function. Our new description for the complete set of multipliers only requires a finite number of matrix copositivity constraints. These conditions have an exact, computationally tractable implementation for problems where the nonlinearity has small input/output dimensions $(\le 4)$. We illustrate the use of our new characterization via a simple example.

</details>


### [16] [Design and Measurements of mmWave FMCW Radar Based Non-Contact Multi-Patient Heart Rate and Breath Rate Monitoring System](https://arxiv.org/abs/2511.21255)
*Jewel Benny,Pranjal Mahajan,Srayan Sankar Chatterjee,Mohd Wajid,Abhishek Srivastava*

Main category: eess.SY

TL;DR: 基于FMCW毫米波雷达的多人员非接触心率/呼吸率监测，结合最小二乘融合以提升精度和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 在无接触、可用于大规模监测场景的需求背景下，发展能够同时对多名患者测量HR和BR的快速、鲁棒系统

Method: 采用Texas Instruments的FMCW毫米波雷达，提出将多种处理方法通过最小二乘解组合以提高测量准确性与泛化能力，并实现多患者并行监测

Result: 在实验中，BR测量准确度>97%，HR测量准确度>93%，并给出对精度、鲁棒性和泛化的提升描述

Conclusion: 所提出的系统在多患者非接触监测方面具有可行性和高准确性，且最小二乘融合提升了精度和鲁棒性，适用于大规模监测场景

Abstract: Recent developments in mmWave radar technologies have enabled the truly non-contact heart-rate (HR) and breath-rate (BR) measurement approaches, which provides a great ease in patient monitoring. Additionally, these technologies also provide opportunities to simultaneously detect HR and BR of multiple patients, which has become increasingly important for efficient mass monitoring scenarios. In this work, a frequency modulated continuous wave (FMCW) mmWave radar based truly non-contact multiple patient HR and BR monitoring system has been presented. Furthermore, a novel approach is also proposed, which combines multiple processing methods using a least squares solution to improve measurement accuracy, generalization, and handle measurement error. The proposed system has been developed using Texas Instruments' FMCW radar and experimental results with multiple subjects are also presented, which show >97% and >93% accuracy in the measured BR and HR values, respectively.

</details>


### [17] [Response-Based Frequency Stability Assessment under Multi-Scale Disturbances in High-Renewable Power Systems](https://arxiv.org/abs/2511.21269)
*Jinhui Chen,Huadong Sun,Ping Wu,Baocai Wang,Bing Zhao*

Main category: eess.SY

TL;DR: 提出一种基于扰动功率的响应型频率稳定性评估方法，能将多尺度扰动统一处理，通过基于发电机组响应推断的扰动功率在线识别扰动类型并量化强度，针对不同扰动类别给出解析频率响应模型，提供稳态/瞬态约束下的容忍界限与安全裕度，并在高比例可再生能源系统的基准系统上验证其有效性与准确性。


<details>
  <summary>Details</summary>
Motivation: 高比例可再生能源的发电系统中，活跃功率扰动规模增大且具有多尺度特性，常规的频率稳定性评估难以应对未预期事件。需要一种能够在线识别扰动类型、统一处理多尺度扰动并给出可量化的稳定性指标的方法。

Method: 基于发电机组的响应功率构建统一扰动功率模型，通过观测功率响应实现扰动类型在线识别与扰动强度及其变化率的量化。将扰动分为短时和永久扰动，永久扰动再分为阶跃、二级斜率和分级斜率扰动。针对各扰动类别推导解析的频率响应模型：对阶跃扰动给出在稳态与瞬态约束下的最大可承受扰动功率及安全裕度；对斜率扰动使用改进的系统频率响应模型及主要频率制动耗尽后的转子运动方程，计算频率超限的持续时间。

Result: 在CSEE-FS基准系统上验证了所提方法，结果显示其在高可再生能源系统中的频率稳定性定量评估方面具有较高的有效性和准确性。

Conclusion: 所提出的响应型评估方法实现了对多尺度扰动的在线识别与统一处理，提供可量化的安全裕度和超限时间等指标，便于在高比例可再生系统中进行频率稳定性评估与决策。

Abstract: In high-renewable power systems, active-power disturbances are becoming larger and exhibit increasingly diverse time scales, which complicates frequency stability assessment under unanticipated events. This paper presents a response-based frequency stability assessment method that uses disturbance power, inferred from generator electrical responses, to provide a unified treatment of multi-scale disturbances. Unanticipated disturbances are first classified into short-term and permanent events; permanent disturbances are further divided into step, second-level slope and minute-level slope disturbances. Based on the measured power responses of generator groups, a unified disturbance-power model is constructed to identify the disturbance type online and to quantify disturbance intensity through the disturbance power and its rate of change. Analytical frequency-response models are then derived for each disturbance class. For step disturbances, the maximum tolerable disturbance power is obtained under steady-state and transient frequency deviation constraints, and a safety-margin index is defined. For slope-type disturbances, an improved system frequency response (SFR) model and the rotor motion equation after exhaustion of primary frequency regulation are used to compute the over-limit time of frequency deviation. The proposed response-based assessment method is validated on the CSEE-FS frequency-stability benchmark system, demonstrating its effectiveness and accuracy for quantitative frequency stability assessment in high-renewable power systems.

</details>


### [18] [Respiratory Motion Compensation and Haptic Feedback for X-ray-Guided Teleoperated Robotic Needle Insertion](https://arxiv.org/abs/2511.21273)
*Ana Cordon-Avila,Mostafa Selim,Momen Abayazid*

Main category: eess.SY

TL;DR: 通过呼吸运动估算与远程触觉引导实现无放射遥控肝脏插入，机器人模型验证下毫米级运动补偿和3D插入误差，提升治疗/诊断准确性并降低辐射暴露。


<details>
  <summary>Details</summary>
Motivation: 呼吸引起的腹部器官运动显著降低腹部经皮治疗的定位准确性，需在非放射性环境下实现高精度定位与安全的远程操作。

Method: 利用呼吸运动估算模型进行运动补偿，并通过基于距离的触觉反馈实现远程插入的引导与控制；在机器人肝脏仿真模型上进行验证，完成5次插入以评估定位与插入误差。

Result: 运动估计误差在所有运动方向均小于3 mm；3D插入误差在S-I方向为2.60 mm，Lateral方向为7.75 mm，A-P方向为2.86 mm。

Conclusion: 所提出的方法有望减少因呼吸引起的定位不准确性并降低放射暴露，从而提升腹部经皮治疗的安全性和可及性。

Abstract: Respiratory motion limits the accuracy and precision of abdominal percutaneous procedures. In this paper, respiratory motion is compensated robotically using motion estimation models. Additionally, a teleoperated insertion is performed using proximity-based haptic feedback to guide physicians during insertion, enabling a radiation-free remote insertion for the end-user. The study has been validated using a robotic liver phantom, and five insertions were performed. The resulting motion estimation errors were below 3 mm for all directions of motion, and the overall resulting 3D insertion errors were 2.60, 7.75, and 2.86 mm for the superior-inferior, lateral, and anterior-posterior directions of motion, respectively. The proposed approach is expected to minimize the chances of inaccurate treatment or diagnosis due to respiratory-induced motion and reduce radiation exposure.

</details>


### [19] [Scalable Multisubject Vital Sign Monitoring With mmWave FMCW Radar and FPGA Prototyping](https://arxiv.org/abs/2511.21314)
*Jewel Benny,Narahari N. Moudhgalya,Mujeev Khan,Hemant Kumar Meena,Mohd Wajid,Abhishek Srivastava*

Main category: eess.SY

TL;DR: 提出基于 FMCW 雷达的非接触多人体生命体征估计系统，并给出用于现场部署的 FPGA 实现，显著提升速度与资源利用效率。


<details>
  <summary>Details</summary>
Motivation: 解决可穿戴设备带来的不适、校准困难以及感染传播风险等问题，提出可扩展的非接触式生命体征监测方案，并探讨扩展到任意数量受试者的硬件与理论限制。

Method: 采用 FMCW 雷达进行多目标生命体征估计，分析在可扩展性方面的挑战，并给出一个 FPGA 基础的实现作为硬件原型以实现便携性与高效性。

Result: 与软件实现相比，FPGA 方案实现约 2.7 倍执行加速，LUT 使用率下降约 18.4%，并相对于软件达到超过 7400 倍的加速，同时讨论了扩展到更多受试者的可行性与限制。

Conclusion: 该工作展示了非接触式生命体征监测的可行性与潜力，尤其在高效、便携的硬件实现方面具有显著优势，并为未来多人体监测的发展提供方向。

Abstract: In this work, we introduce an innovative approach to estimate the vital signs of multiple human subjects simultaneously in a non-contact way using a Frequency Modulated Continuous Wave (FMCW) radar-based system. Traditional vital sign monitoring methods often face significant limitations, including subject discomfort with wearable devices, challenges in calibration, and the risk of infection transmission through contact measurement devices. To address these issues, this research is motivated by the need for versatile, non-contact vital monitoring solutions applicable in various critical scenarios. This work also explores the challenges of extending this capability to an arbitrary number of subjects, including hardware and theoretical limitations. Supported by rigorous experimental results and discussions, the paper illustrates the system's potential to redefine vital sign monitoring. An FPGA-based implementation is also presented as proof of concept for a hardware-based and portable solution, improving upon previous works by offering 2.7x faster execution and 18.4% less Look-Up Table (LUT) utilization, as well as providing over 7400x acceleration compared to its software counterpart.

</details>


### [20] [Analytical Phasor-Based Fault Location Enhancement for Wind Farm Collector Networks](https://arxiv.org/abs/2511.21319)
*Alailton J. Alves Junior,Daniel Barbosa,Ricardo A. S. Fernandes,Denis V. Coury*

Main category: eess.SY

TL;DR: 提出一种通用的补偿框架，通过在经典环路公式中加入与距离相关的电压修正项来改进风电场集流母线在含IBR的情景下的故障定位准确性；该方法以序域分析推导，可用于多种故障，并仅需局部量测。


<details>
  <summary>Details</summary>
Motivation: 随着并网的逆变型资源(IBRs)比例持续上升，故障电流及电压分布发生显著变化，传统的一端端子相量法在IBR位于故障下游时产生系统性距离过估，导致故障定位不准确；需要一个简单、基于局部量测、并对多种故障类型统一处理的修正机制。

Method: 在经典环路方程中引入距离相关的电压修正项，并以序域表示进行分析推导；将其推广到多种故障情形，保持方法的直观性和易实现性；仅依赖局部测量实现。

Result: 在PSCAD的EMT仿真中，基于真实风电场模型进行评估，定位误差显著降低，平均和最大误差均有明显改善，尤其是对接地故障误差下降超过90%；修正项对风速/渗透水平不敏感，且在各馈线上的性能趋于一致。

Conclusion: 该补偿框架为现代以可再生能源为主的电网提供了一种简洁、可实现的局部量测解决方案，有效缓解IBR引入的故障定位偏差，提升故障定位的鲁棒性和适用性。

Abstract: The increasing integration of Inverter-Based Resources (IBRs) is reshaping fault current characteristics, presenting significant challenges to traditional protection and fault location methods. This paper addresses a key limitation in fault location within wind farm collector networks, i.e., one-terminal phasor-based methods become inaccurate when IBRs are electrically located downstream from the fault. In such cases, the voltage drop caused by IBR fault current injections is not captured by the Intelligent Electronic Device, resulting in a systematic overestimation of fault distance. To mitigate this issue, a general compensation framework was proposed by augmenting classical loop formulations with a distance-dependent voltage correction term. The methodology was derived analytically using a sequence-domain representation and generalized to multiple fault types through a unified notation. It maintains the simplicity and interpretability of conventional approaches and can be implemented using only local measurements. The method was evaluated through EMT simulations in PSCAD using a realistic wind farm model. Results show significant improvements in location accuracy, with average and maximum errors notably reduced, especially for ground-involved faults where reductions exceed 90\%. Furthermore, the compensation eliminates sensitivity to wind penetration levels and ensures uniform performance across feeders, positioning the method as a practical solution for modern renewable-dominated grids.

</details>


### [21] [Model Predictive Control and Moving Horizon Estimation using Statistically Weighted Data-Based Ensemble Models](https://arxiv.org/abs/2511.21343)
*Laura Boca de Giuli,Samuel Mallick,Alessio La Bella,Azita Dabiri,Bart De Schutter,Riccardo Scattolini*

Main category: eess.SY

TL;DR: 提出一个基于MPC的框架，使用基于数据的模型集合，通过基于马氏距离的组合规则实现跨预测窗的加权，并引入基于移动视窗估计的集合模型状态观测器，在多工况能量系统基准上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 在复杂系统的多工况下，模型不确定性和工况切换会削弱MPC表现。采用模型集合可覆盖多种行为模式；结合数据驱动模型与自适应权重以提高鲁棒性与泛化能力；同时需可靠的状态估计以支撑观测与控制。

Method: 构建一个数据驱动模型集合用于MPC；提出以统计马氏距离为基础的组合规则，使集合权重在预测窗内随系统输入而动态变化；开发用于集合模型的基于移动视窗估计的状态观测器；在一个多工况的基准能量系统上进行实验验证。

Result: 在基准能量系统及多工况情形下证明了所提框架的有效性，表现出对工况变化的鲁棒性和控制性能的改善（abstract未给出具体数值）。

Conclusion: 给出了一种将数据驱动模型集合与MPC结合的新途径，并通过MHE提升集合模型的状态估计，为复杂系统的鲁棒控制提供了有意义的研究方向，未来可在更多系统和实时实现方面进行扩展与评估。

Abstract: This paper presents a model predictive control (MPC) framework leveraging an ensemble of data-based models to optimally control complex systems under multiple operating conditions. A novel combination rule for ensemble models is proposed, based on the statistical Mahalanobis distance, enabling the ensemble weights to suitably vary across the prediction window based on the system input. In addition, a novel state observer for ensemble models is developed using moving horizon estimation (MHE). The effectiveness of the proposed methodology is demonstrated on a benchmark energy system operating under multiple conditions.

</details>


### [22] [Evaluation of Large Language Models for Numeric Anomaly Detection in Power Systems](https://arxiv.org/abs/2511.21371)
*Yichen Liu,Hongyu Wu,Bo Liu*

Main category: eess.SY

TL;DR: 将大语言模型用于电网数值异常检测的系统性评估，基于GPT-OSS-20B，在IEEE 14-bus上比较多种学习/微调策略并引入三西格玛规则，揭示潜力与局限，为与经典探测器的集成奠定基础。


<details>
  <summary>Details</summary>
Motivation: 高压电网的多变量遥测数据需要高准确性与可解释性，现有的异常检测方法往往难以兼顾大规模数值数据的鲁棒性与推理透明性；尽管LLMs在自然语言任务中表现出强大能力，但其在大规模数值异常检测上的应用研究尚不充分。

Method: 采用标准化提示框架，在零-shot、少-shot、就地学习、低秩适配（LoRA）、微调、以及混合LLM与传统检测的情境下进行评估；设计基于三西格玛的规则感知检测策略；以IEEE 14-bus系统为评估对象，比较不同训练/推理策略下的检测性能与推理质量（ rationale quality ）。

Result: 报告检测性能与推理质量，未给出具体数值，但验证了LLMs在数值异常检测中的潜力，并展示了在不同学习范式下的表现和推理能力，为后续与经典探测器融合的研究提供基线与方向。

Conclusion: LLM为数值异常检测提供了新的研究路径，具有潜力与局限并存；本文 establisher 基线，指明未来在与传统探测器结合、提高可解释性与鲁棒性方面的研究方向。

Abstract: Large language models (LLMs) have gained increasing attention in power grids for their general-purpose capabilities. Meanwhile, anomaly detection (AD) remains critical for grid resilience, requiring accurate and interpretable decisions based on multivariate telemetry. Yet the performance of LLMs on large-scale numeric data for AD remains largely unexplored. This paper presents a comprehensive evaluation of LLMs for numeric AD in power systems. We use GPT-OSS-20B as a representative model and evaluate it on the IEEE 14-bus system. A standardized prompt framework is applied across zero-shot, few-shot, in-context learning, low rank adaptation (LoRA), fine-tuning, and a hybrid LLM-traditional approach. We adopt a rule-aware design based on the three-sigma criterion, and report detection performance and rationale quality. This study lays the groundwork for further investigation into the limitations and capabilities of LLM-based AD and its integration with classical detectors in cyber-physical power grid applications.

</details>


### [23] [Influence of converter current limiting and prioritization on protection of highly IBR-penetrated networks](https://arxiv.org/abs/2511.21385)
*Andrés E. Quintero,Vinícius A. Lacerda,Oriol Gomis-Bellmunt,Moisés J. B. B. Davi,Mario Oleskovicz*

Main category: eess.SY

TL;DR: 现代变流器控制（GFM/GFL）对距离保护和分布保护的可靠性与安全性有显著影响，可能导致故障定位误差与误动作风险，需改进保护策略。


<details>
  <summary>Details</summary>
Motivation: 在 converter-dominated 传输系统中，了解网格-forming 与网格-following 控制对传统保护（距离保护、线差保护）的影响，以提升保护的可靠性与安全性；并评估低压穿越、限流以及序分优先级的影响。

Method: 在改进的IEEE 39-bus 系统中，部署带 LVRT、限流与正/负序优先级的 GFM 与 GFL 单元；距离保护采用 mho 特性，线差保护采用 alpha-plane 方法，评估在不同工况下的保护行为。

Result: 距离保护中相对地环路会显著高估 Zone-1 覆盖区内近端故障位置；线差保护方面，外部故障可能使工作点短时进入 alpha-plane 的跳闸区，甚至在 ABG 故障的健康相上也如此，且发生在故障初期，需强外部安全措施。总体而言，现代变流器控制结合限流与序分优先级会削弱传统保护的可靠性与安全性。

Conclusion: 现代变流器控制策略若与限流、序分优先协同作用，会对距离保护与线差保护形成挑战，需要对保护算法和保护区设置进行再设计与增强。

Abstract: This paper investigates how grid-forming (GFM) and grid-following (GFL) control strategies in inverter-based resources (IBRs) influence line distance and differential protection in converter-dominated transmission systems. A modified IEEE 39-bus system is evaluated with GFM and GFL units equipped with low-voltage ride-through logic, current limiting, and positive- or negative-sequence prioritization. Distance protection is implemented with a mho characteristic, while line differential protection uses an alpha-plane approach. Results show that phase-to-ground loops in distance protection can substantially overestimate the fault location near the Zone-1 reach. For line differential protection, external faults may cause the operating point to briefly enter the trip region of the alpha-plane, even for the healthy-phase in ABG faults under GFL control and during the initial moments of the fault, demanding strong external security measures. These findings highlight that modern converter controls, together with current limitation and sequence-current prioritization, can compromise the reliability and security of traditional protection schemes.

</details>


### [24] [Understanding Regional Inertia Dynamics in CAISO from Real Grid Disturbances](https://arxiv.org/abs/2511.21387)
*Saurav Dulal,Mohammed M. Olama,Ali R. Ekti,Nils M. Stenvig,Yilu Liu*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The shift from synchronous generators to inverter-based resources has caused power system inertia to be unevenly distributed across power grids. As a result, certain grid regions are more vulnerable to high rate-of-change of frequency (RoCoF) during disturbances. This paper presents a measurement-based framework for estimating grid inertia in CAISO (California Independent System Operator) region using real disturbance-driven frequency data from the Frequency Monitoring Network (FNET/GridEye). By analyzing confirmed disturbances from 2013 to 2024, we identify trends in regional inertia and frequency dynamics, highlighting their relationship with renewable generation and the evolving duck curve. Regional RoCoF values were up to six times higher than interconnection-wide values, coinciding with declining inertia. Recent recovery in inertia is attributed to the increased deployment of battery energy storage systems with synthetic inertia capabilities. These findings underscore the importance of regional inertia monitoring, strategic resource planning, and adaptive operational practices to ensure grid reliability amid growing renewable integration.

</details>


### [25] [Robust Rule-Based Sizing and Control of Batteries for Peak Shaving Applications](https://arxiv.org/abs/2511.21619)
*Lorenzo Nespoli,Vasco Medici*

Main category: eess.SY

TL;DR: 本文提出在电池系统中使用随机调谐的基于规则的控制器（RBC），相较于确定性MPC，能够更快地实现容量与控制目标、提供更现实的LCOE估算并提升运行性能；在真实年度用电曲线的峰值削减任务中得到有力证据。


<details>
  <summary>Details</summary>
Motivation: 随着电池成本下降，对既快又能在实际部署中实现承诺性能的容量分配和控制方法的需求日益增强。相较于确定性模型预测控制（MPC），现有方法可能在现实场景下未能给出真实的LCOE或性能评估。本文旨在展示随机调谐的RBC在这两方面的潜力。

Method: 提出并测试随机调谐的基于规则的控制器（RBCs），并与确定性MPC进行对比；基于真实表计的年度数据用于峰值削减场景进行评估；重点比较LCOE的现实性和运行阶段的性能表现。

Result: 与MPC相比，RBC在提供更现实的LCOE估算和更优的运行性能方面表现更好；基于真实用电数据的实验给出有力证据支持。

Conclusion: 随机调谐的RBCs是实现快速求解与可靠部署性能的可行替代方案，尤其在峰值削减等应用中，能提供比确定性MPC更现实的成本估算与更优的运营表现。

Abstract: As the cost of batteries lowers, sizing and control methods that are both fast and can achieve their promised performances when deployed are becoming more important. In this paper, we show how stochastically tuned rule based controllers (RBCs) can be effectively used to achieve both these goals, providing more realistic estimates in terms of achievable levelised cost of energy (LCOE), and better performances while in operation when compared to deterministic model predictive control (MPC). We test the proposed methodology on yearly profiles from real meters for peak shaving applications and provide strong evidence about these claims.

</details>


### [26] [Bang-Bang Evasion: Its Stochastic Optimality and a Terminal-Set-Based Implementation](https://arxiv.org/abs/2511.21633)
*Liraz Mudrik,Yaakov Oshman*

Main category: eess.SY

TL;DR: 在带后验信息的随机环境下，提出一类最优规避策略并给出一个基于闭环终端集合的 TSE 策略，其存在性与 bang-bang 最优性得到证明且在仿真中优于传统随机模型。


<details>
  <summary>Details</summary>
Motivation: 在现实场景中，拦截系统通常基于不完美信息和有界控制的条件，传统方法多依赖完美信息或启发式随机模型。需要一个理论上存在且可实现的最优规避框架，以提高在随机环境下的生存概率和鲁棒性。

Method: 把问题建模为带后验状态分布的随机最优控制问题，符合广义分离定理，控制律依赖状态的后验分布。证明在确定性情形下的 bang-bang 最优性延拓至随机情形，存在一个最优解族且至少包含 bang-bang 策略；据此提出闭环终端集合基的规避(TSE)策略，并通过对比比例导航追击模型进行蒙特卡洛仿真。

Result: 数学上证明了存在最优解且包含至少一个 bang-bang 策略，使得问题成为一个有限维的问题。仿真表明 TSE 在对抗比例导航的追击中优于基于随机 telegraph、Singer 与 weaving 等随机化策略。

Conclusion: 在带不完美信息和有界控制的现实性随机对抗中，bang-bang 最优性依然成立且可实现；TSE 策略提供了稳定而优越的闭环规避解，对现实中的端目集合控制具有潜在应用前景。

Abstract: We address the problem of optimal evasion in a planar endgame engagement, where a target with bounded lateral acceleration seeks to avoid interception by a missile guided by a linear feedback law. Contrary to existing approaches, that assume perfect information or use heuristic maneuver models in stochastic settings, we formulate the problem in an inherently stochastic framework involving imperfect information and bounded controls. Complying with the generalized separation theorem, the control law factors in the posterior distribution of the state. Extending the well-known optimality of bang-bang evasion maneuvers in deterministic settings to the realm of realistic, stochastic evasion scenarios, we firstly prove that an optimal evasion strategy always exists, and that the set of optimal solutions includes at least one bang-bang policy, rendering the resulting optimal control problem finite-dimensional. Leveraging this structure, we secondly propose the closed-loop terminal-set-based evasion (TSE) strategy, and demonstrate its effectiveness in simulation against a proportional navigation pursuer. Monte Carlo simulations show that the TSE strategy outperforms traditional stochastic evasion strategies based on random telegraph, Singer, and weaving models.

</details>


### [27] [Model-free practical PI-Lead control design by ultimate sensitivity principle](https://arxiv.org/abs/2511.21641)
*Michael Ruderman*

Main category: eess.SY

TL;DR: 在无精确模型的前提下提出一个鲁棒的PI-Lead控制设计方法，通过基于极限灵敏度的理论和环路整形的通用特征，给出一个三步式的实验观测驱动定标流程，用以确定积分时间常数、控制增益和Lead元件，确保足够的相位裕量，并在带噪声的执行器上进行实验验证。


<details>
  <summary>Details</summary>
Motivation: 工程领域常遇到无法获得准确系统模型的情况，需提供简单、鲁棒且易实现的控制设计方法，尤其在运动控制场景中。研究旨在在无模型条件下实现鲁棒的PI-Lead控制并保证相位裕量。

Method: 基于极限灵敏度原则，结合经验Ziegler–Nichols对PID整定的思路及环路整形的一般特征，提出一个三步法来确定积分时间常数、控制增益与Lead元件。每一步仅依赖通过输出观测获得的实验数据，以确保达到所需的相位裕量。

Result: 将所提方法在一个噪声干扰的电机械执行器系统（平移运动）上进行实验评估，验证其可行性与鲁棒性。

Conclusion: 方法提供了一种简洁且可落地的无模型PI-Lead设计流程，在缺乏精确系统建模的情形下仍能获得稳定性裕量与鲁棒性。

Abstract: Practical design and tuning of feedback controllers has to do often without any model of the given dynamic process. Only some general assumptions about the process, in this work type-one stable behavior, can be available for engineers, in particular in motion control systems. This paper proposes a practical and simple in realization procedure for designing a robust PI-Lead control without modeling. The developed method derives from the ultimate sensitivity principles, known in the empirical Ziegler-Nichols tuning of PID control, and makes use of some general characteristics of loop shaping. A three-steps procedure is proposed to determine the integration time constant, control gain, and Lead-element in a way to guarantee a sufficient phase margin, while all steps are served by only experimental observations of the output value. The proposed method is also evaluated with experiments on a noise-perturbed electro-mechanical actuator system with translational motion.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [28] [Prototype-Guided Non-Exemplar Continual Learning for Cross-subject EEG Decoding](https://arxiv.org/abs/2511.20696)
*Dan Li,Hye-Bin Shin,Yeon-Woo Choi*

Main category: cs.LG

TL;DR: ProNECL提出一种原型引导的非样本型持续学习框架，用于跨受试者的持续脑电解码，避免回放历史数据，通过构建类别原型并与全局原型记忆对齐实现知识迁移，实现在BCI 2a/2b数据集上的优越绩效。


<details>
  <summary>Details</summary>
Motivation: EEG信号在个体间存在显著变异，随着新受试者加入，先前知识易被覆盖；传统回放缓冲区在隐私与内存方面存在限制，需开发不访问历史样本的持续学习方法。

Method: 构建类别级原型以概括各受试者的判别表示；通过跨受试者特征对齐和知识蒸馏，将新特征空间渐进地与全局原型记忆对齐；不访问历史EEG样本，原型记忆用于维持先验知识；在每个新受试者加入时增量更新原型与对齐策略。

Result: 在BCI Competition IV 2a/2b数据集上验证，该方法在知识保留与适应性之间取得良好平衡，并在跨受试者持续EEG解码任务中表现优于对比基线。

Conclusion: ProNECL无需历史样本即可有效保留先前知识，且通过原型引导的非样本持续学习提升了跨受试者的EEG解码性能，证明了原型记忆 + 跨受试者对齐在隐私友好场景中的有效性。

Abstract: Due to the significant variability in electroencephalogram (EEG) signals across individuals, knowledge acquired from previous subjects is often overwritten as new subjects are introduced in continual EEG decoding task. Current works mainly rely on storing the historical data of seen subjects as a replay buffer to prevent forgetting. However, privacy concerns or memory constraints make keeping such data impractical. Instead, we propose a Prototype-guided Non-Exemplar Continual Learning (ProNECL)framework that preserves prior knowledge without accessing any historical EEG samples. ProNECL constructs class-level prototypes to summarize discriminative representations from each subject and incrementally aligns new feature spaces with the global prototype memory through cross-subject feature alignment and knowledge distillation. Validated on the BCI Competition IV 2a and 2b datasets, our framework effectively balances knowledge retention and adaptability, achieving superior performance in cross-subject continual EEG decoding tasks.

</details>


### [29] [Post-Pruning Accuracy Recovery via Data-Free Knowledge Distillation](https://arxiv.org/abs/2511.20702)
*Chinmay Tripurwar,Utkarsh Maurya,Dishant*

Main category: cs.LG

TL;DR: Data-free knowledge distillation for model pruning: synthesize privacy-preserving data from a pre-trained teacher using DeepInversion (BN stats) as a transfer set to recover pruning accuracy without real data.


<details>
  <summary>Details</summary>
Motivation: In privacy-sensitive domains, access to original training data is restricted (GDPR/HIPAA). Global unstructured pruning often hurts accuracy; need a data-free approach to recover performance after compression.

Method: Inverting BN statistics via DeepInversion to generate synthetic images (dream images) from the teacher model, using these images as a transfer set to distill knowledge from the teacher to a pruned student network.

Result: Experiments on CIFAR-10 across architectures (ResNet, MobileNet, VGG) show substantial recovery of pruning-induced accuracy loss without using any real data.

Conclusion: A data-free KD framework can effectively combine model compression and data privacy; synthetic data from BN inversion enables effective distillation to recover performance after pruning.

Abstract: Model pruning is a widely adopted technique to reduce the computational complexity and memory footprint of Deep Neural Networks (DNNs). However, global unstructured pruning often leads to significant degradation in accuracy, typically necessitating fine-tuning on the original training dataset to recover performance. In privacy-sensitive domains such as healthcare or finance, access to the original training data is often restricted post-deployment due to regulations (e.g., GDPR, HIPAA). This paper proposes a Data-Free Knowledge Distillation framework to bridge the gap between model compression and data privacy. We utilize DeepInversion to synthesize privacy-preserving ``dream'' images from the pre-trained teacher model by inverting Batch Normalization (BN) statistics. These synthetic images serve as a transfer set to distill knowledge from the original teacher to the pruned student network. Experimental results on CIFAR-10 across various architectures (ResNet, MobileNet, VGG) demonstrate that our method significantly recovers accuracy lost during pruning without accessing a single real data point.

</details>


### [30] [Pretraining Transformer-Based Models on Diffusion-Generated Synthetic Graphs for Alzheimer's Disease Prediction](https://arxiv.org/abs/2511.20704)
*Abolfazl Moslemi,Hossein Peyvandi*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Early and accurate detection of Alzheimer's disease (AD) is crucial for enabling timely intervention and improving outcomes. However, developing reliable machine learning (ML) models for AD diagnosis is challenging due to limited labeled data, multi-site heterogeneity, and class imbalance. We propose a Transformer-based diagnostic framework that combines diffusion-based synthetic data generation with graph representation learning and transfer learning. A class-conditional denoising diffusion probabilistic model (DDPM) is trained on the real-world NACC dataset to generate a large synthetic cohort that mirrors multimodal clinical and neuroimaging feature distributions while balancing diagnostic classes. Modality-specific Graph Transformer encoders are first pretrained on this synthetic data to learn robust, class-discriminative representations and are then frozen while a neural classifier is trained on embeddings from the original NACC data. We quantify distributional alignment between real and synthetic cohorts using metrics such as Maximum Mean Discrepancy (MMD), Frechet distance, and energy distance, and complement discrimination metrics with calibration and fixed-specificity sensitivity analyses. Empirically, our framework outperforms standard baselines, including early and late fusion deep neural networks and the multimodal graph-based model MaGNet, yielding higher AUC, accuracy, sensitivity, and specificity under subject-wise cross-validation on NACC. These results show that diffusion-based synthetic pretraining with Graph Transformers can improve generalization in low-sample, imbalanced clinical prediction settings.

</details>


### [31] [Active Slice Discovery in Large Language Models](https://arxiv.org/abs/2511.20713)
*Minhui Zhang,Prahar Ijner,Yoav Wald,Elliot Creager*

Main category: cs.LG

TL;DR: 提出主动切片发现（Active Slice Discovery）来高效地发现并验证大语言模型在特定错误切片上的模式，降低手动标注成本。


<details>
  <summary>Details</summary>
Motivation: LLMs在某些子集上存在系统性错误（如对特定人群的毒性评论识别差），识别这些错误切片对理解与改进模型至关重要，但逐条标注成本高昂，因此需要高效的分组与有限标注验证的方法。

Method: 将错误样本基于特征表示进行分组/聚类，并通过不确定性为主的主动学习策略挑选样本，由标注者验证所选样本是否共享相同的错误模式，从而在有限的信息下发现同一切片。对毒性分类中的人定义切片进行实验，比较不同表示与主动学习算法的效果。

Result: 在若干切片上，基于不确定性的主动学习算法最有效，使用仅2-10%的切片成员信息即可获得具有竞争力的准确性，并显著优于基线方法。

Conclusion: 主动切片发现提供了一种高效且低标注成本的诊断工具，能在较少标签信息下识别并描述模型的错误切片，便于针对性改进模型。

Abstract: Large Language Models (LLMs) often exhibit systematic errors on specific subsets of data, known as error slices. For instance, a slice can correspond to a certain demographic, where a model does poorly in identifying toxic comments regarding that demographic. Identifying error slices is crucial to understanding and improving models, but it is also challenging. An appealing approach to reduce the amount of manual annotation required is to actively group errors that are likely to belong to the same slice, while using limited access to an annotator to verify whether the chosen samples share the same pattern of model mistake. In this paper, we formalize this approach as Active Slice Discovery and explore it empirically on a problem of discovering human-defined slices in toxicity classification. We examine the efficacy of active slice discovery under different choices of feature representations and active learning algorithms. On several slices, we find that uncertainty-based active learning algorithms are most effective, achieving competitive accuracy using 2-10% of the available slice membership information, while significantly outperforming baselines.

</details>


### [32] [Gradient Descent Algorithm Survey](https://arxiv.org/abs/2511.20725)
*Deng Fucheng,Wang Wanjie,Gong Ao,Wang Xiaoqi,Wang Fan*

Main category: cs.LG

TL;DR: 本文对五种主流深度学习优化算法（SGD、Mini-batch SGD、Momentum、Adam、Lion）进行系统分析，揭示其核心优点、局限与可操作的实用建议，旨在为学术研究与工程实践提供统一的参数调优与算法选择参考。


<details>
  <summary>Details</summary>
Motivation: 在深度学习训练中，如何在不同规模的模型和多样化训练场景中选择合适的优化算法并进行有效调参，是提高训练效率与模型性能的关键难题。本文通过对常用优化算法的系统梳理，提供可操作的指南与对比分析。

Method: 通过对五种优化算法的核心特性、优缺点和实际应用要点进行系统分析，结合理论回顾与实证观察，提出针对不同场景的参数调优策略与使用建议。

Result: 给出五种算法的优缺点清单、重要超参数的调优要点、常见陷阱及在不同模型规模与训练场景中的推荐使用策略，形成可供参考的标准化框架。

Conclusion: 希望为研究者和工程师在模型规模与训练场景多样化的情况下，做出更合理的算法选择与参数设置，从而提升优化效率和模型性能。

Abstract: Focusing on the practical configuration needs of optimization algorithms in deep learning, this article concentrates on five major algorithms: SGD, Mini-batch SGD, Momentum, Adam, and Lion. It systematically analyzes the core advantages, limitations, and key practical recommendations of each algorithm. The research aims to gain an in-depth understanding of these algorithms and provide a standardized reference for the reasonable selection, parameter tuning, and performance improvement of optimization algorithms in both academic research and engineering practice, helping to solve optimization challenges in different scales of models and various training scenarios.

</details>


### [33] [Spatio-Temporal Trajectory Foundation Model - Recent Advances and Future Directions](https://arxiv.org/abs/2511.20729)
*Sean Bin Yang,Ying Sun,Yunyao Cheng,Yan Lin,Kristian Torp,Jilin Hu*

Main category: cs.LG

TL;DR: 本研究/教程对轨迹基础模型（TFMs）在时空基础模型（STFMs）框架内进行系统性综述，给出方法学的分类、优缺点的批判性分析，并提出面向鲁棒、可迁移的未来研究方向，以推动时空通用智能的发展。


<details>
  <summary>Details</summary>
Motivation: 尽管STFMs研究快速发展，但针对TFMs这一重要子类的系统性研究仍然缺乏。需要对现有方法进行分类梳理、优缺点评估，并揭示关键挑战与研究机会，以提高TFMs在广域时空任务中的适应性和迁移性。

Method: 提供对现有TFMs的分류（taxonomy），对其优缺点进行批判性分析，并在此基础上总结开放性挑战，提出未来研究方向的路线图与研究议题。

Result: 给出对TFMs领域的全面综述与分类框架，明确各方法的优点与局限性，识别尚待解决的挑战，勾勒推动鲁棒、可转移的时空通用智能的发展路径。

Conclusion: TFMs是推动时空通用智能的重要工具，需进一步完善鲁棒性、可解释性、责任性与可迁移性，同时加强对数据伦理与风险的考量，才能在广泛的时空任务中实现有效应用。

Abstract: Foundation models (FMs) have emerged as a powerful paradigm, enabling a diverse range of data analytics and knowledge discovery tasks across scientific fields. Inspired by the success of FMs, particularly large language models, researchers have recently begun to explore spatio-temporal foundation models (STFMs) to improve adaptability and generalization across a wide spectrum of spatio-temporal (ST) tasks. Despite rapid progress, a systematic investigation of trajectory foundation models (TFMs), a crucial subclass of STFMs, is largely lacking. This tutorial addresses this gap by offering a comprehensive overview of recent advances in TFMs, including a taxonomy of existing methodologies and a critical analysis of their strengths and limitations. In addition, the tutorial highlights open challenges and outlines promising research directions to advance spatio-temporal general intelligence through the development of robust, responsible, and transferable TFMs.

</details>


### [34] [CHiQPM: Calibrated Hierarchical Interpretable Image Classification](https://arxiv.org/abs/2511.20779)
*Thomas Norrenbrock,Timo Kaiser,Sovan Biswas,Neslihan Kose,Ramesh Manuvinakurike,Bodo Rosenhahn*

Main category: cs.LG

TL;DR: 提出 Calibrated Hierarchical QPM (CHiQPM)，在全球与局部可解释性之间取得良好平衡，并通过层级解释与可校准的预测集合实现人机互补。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域，信任的前提是模型的可解释性。本文提出的 CHiQPM 同时提供全面的全局解释与细粒度的局部解释，并通过分层结构使解释更贴近人类推理，同时与可校准预测（Conformal Prediction）结合，提高预测的可信度。

Method: 提出 CHiQPM 框架，通过对多数类别进行对比性全局解释、构建层级化的解释路径，并结合可校准的 Conformal Prediction 以实现点预测与集合预测的互补，且其层级解释能沿路径遍历，便于人-机协作。

Result: 在点预测方面达到最先进水平且保持对非解释模型的 99% 精度，表明在提升可解释性的同时未显著牺牲准确性。其校准集合预测与其他 CP 方法相当或具竞争力，并提供与分层解释相一致的可解释集合预测。

Conclusion: CHiQPM 显示出在保持高准确性的前提下显著提升全球与局部可解释性的潜力，推动在人机互补的安全关键领域应用。

Abstract: Globally interpretable models are a promising approach for trustworthy AI in safety-critical domains. Alongside global explanations, detailed local explanations are a crucial complement to effectively support human experts during inference. This work proposes the Calibrated Hierarchical QPM (CHiQPM) which offers uniquely comprehensive global and local interpretability, paving the way for human-AI complementarity. CHiQPM achieves superior global interpretability by contrastively explaining the majority of classes and offers novel hierarchical explanations that are more similar to how humans reason and can be traversed to offer a built-in interpretable Conformal prediction (CP) method. Our comprehensive evaluation shows that CHiQPM achieves state-of-the-art accuracy as a point predictor, maintaining 99% accuracy of non-interpretable models. This demonstrates a substantial improvement, where interpretability is incorporated without sacrificing overall accuracy. Furthermore, its calibrated set prediction is competitively efficient to other CP methods, while providing interpretable predictions of coherent sets along its hierarchical explanation.

</details>


### [35] [Physics Steering: Causal Control of Cross-Domain Concepts in a Physics Foundation Model](https://arxiv.org/abs/2511.20798)
*Rio Alexa Fear,Payel Mukhopadhyay,Michael McCabe,Alberto Bietti,Miles Cranmer*

Main category: cs.LG

TL;DR: 本研究探索物理专注型基础模型是否具备可提取与操控的“隐性概念”方向，并尝试通过在激活空间中计算两个物理 regime 的 delta 表达式来实现对模型输出的因果控制，从而推动对科学基础模型的理解与应用。


<details>
  <summary>Details</summary>
Motivation: 验证科学基础模型是否能像在语言与视觉模型中观察到的那样学习通用、可解读的抽象概念及其操控性，进而扩展到受物理规律驱动的推理与发现领域。

Method: 从物理仿真数据集中提取模型前向传播时的激活向量，比较不同物理 regime 之间的差异，得到 delta 张量作为概念方向；将这些概念方向注入模型以影响推理过程，检验能否因果地控制仿真中的物理特征。

Result: 揭示了物理专注型基础模型在内部表示中包含可解释的物理原理方向，且通过注入概念方向可以改变模型的预测行为，体现了对物理特征的因果控制。

Conclusion: 科学基础模型具备对物理规律的泛化表示能力，不仅仅依赖表面相关性；该发现为AI 支持的科学发现提供新路径，促使对复杂科学系统的理解与操控能力提升。

Abstract: Recent advances in mechanistic interpretability have revealed that large language models (LLMs) develop internal representations corresponding not only to concrete entities but also distinct, human-understandable abstract concepts and behaviour. Moreover, these hidden features can be directly manipulated to steer model behaviour. However, it remains an open question whether this phenomenon is unique to models trained on inherently structured data (ie. language, images) or if it is a general property of foundation models. In this work, we investigate the internal representations of a large physics-focused foundation model. Inspired by recent work identifying single directions in activation space for complex behaviours in LLMs, we extract activation vectors from the model during forward passes over simulation datasets for different physical regimes. We then compute "delta" representations between the two regimes. These delta tensors act as concept directions in activation space, encoding specific physical features. By injecting these concept directions back into the model during inference, we can steer its predictions, demonstrating causal control over physical behaviours, such as inducing or removing some particular physical feature from a simulation. These results suggest that scientific foundation models learn generalised representations of physical principles. They do not merely rely on superficial correlations and patterns in the simulations. Our findings open new avenues for understanding and controlling scientific foundation models and has implications for AI-enabled scientific discovery.

</details>


### [36] [Conformal Safety Monitoring for Flight Testing: A Case Study in Data-Driven Safety Learning](https://arxiv.org/abs/2511.20811)
*Aaron O. Feldman,D. Isaiah Harp,Joseph Duncan,Mac Schwager*

Main category: cs.LG

TL;DR: 提出一种数据驱动的飞行测试运行时安全监测框架，通过离线随机轨迹仿真学习已校准的短期安全风险模型；包含未来状态预测、最近邻安全分类与基于保形预测的分类器校准；在含不确定参数的飞行动力学模型上评估，能可靠识别不安全情形、具备理论保证并优于基线方法的预防性风险分类。


<details>
  <summary>Details</summary>
Motivation: 在飞行测试中，参数不确定性与人机交互导致安全违规可能在未预期时发生，需要在违规前就给出清晰、可操作的中止标准。该研究通过数据驱动学习和监测，将安全监测从事后分析转向可预防性决策，并具有广泛的适用性。

Method: 离线的随机轨迹仿真用于学习一个对短期安全风险进行校准的统计模型；框架包含三大组件：1) 基于最近观测预测未来状态的模型；2) 最近邻模型对预测状态的安全性进行分类；3) 通过保形预测对分类器进行校准以提供可靠的置信度。研究在含参数不确定的飞行动力学模型上进行评估，验证能可靠识别不安全情景、达到理论保证并在预防性风险分类方面优于基线方法。

Result: 方法能够在安全边界附近的短期时间窗内识别潜在不安全情景，提供与理论保证一致的置信校准，并在与基线相比的尝试中实现更早的预防性风险分类。

Conclusion: 提出的框架将数据驱动的安全监测与保形预测校准结合，适用于飞行测试及其他高风险、人机协作场景，具备良好的可解释性与可扩展性，能够在未发生安全违规前提供可操作的决策依据。

Abstract: We develop a data-driven approach for runtime safety monitoring in flight testing, where pilots perform maneuvers on aircraft with uncertain parameters. Because safety violations can arise unexpectedly as a result of these uncertainties, pilots need clear, preemptive criteria to abort the maneuver in advance of safety violation. To solve this problem, we use offline stochastic trajectory simulation to learn a calibrated statistical model of the short-term safety risk facing pilots. We use flight testing as a motivating example for data-driven learning/monitoring of safety due to its inherent safety risk, uncertainty, and human-interaction. However, our approach consists of three broadly-applicable components: a model to predict future state from recent observations, a nearest neighbor model to classify the safety of the predicted state, and classifier calibration via conformal prediction. We evaluate our method on a flight dynamics model with uncertain parameters, demonstrating its ability to reliably identify unsafe scenarios, match theoretical guarantees, and outperform baseline approaches in preemptive classification of risk.

</details>


### [37] [Semantic Superiority vs. Forensic Efficiency: A Comparative Analysis of Deep Learning and Psycholinguistics for Business Email Compromise Detection](https://arxiv.org/abs/2511.20944)
*Yaw Osei Adjei*

Main category: cs.LG

TL;DR: 提出了两种BEC检测范式：Forensic Psycholinguistic Stream（CatBoost，解释性强、低时延）与Semantic Stream（DistilBERT，深度学习、上下文理解，精度高但成本也高）在对抗性污染数据集上评估。DistilBERT在GPU上表现最好，但CatBoost在边缘设备和成本敏感场景更具优势；两者在成本敏感学习下的投资回报率高于99.96%。


<details>
  <summary>Details</summary>
Motivation: BEC带来巨大经济损失，现有检测需兼顾准确性、延迟和成本，需比较可解释性与性能之间的权衡，帮助组织在不同硬件条件下选择合适的检测范式。

Method: 比较两种检测流：Forensic Psycholinguistic Stream使用CatBoost提取心理语言线索，具解释性与低延迟；Semantic Stream使用DistilBERT进行上下文语言理解，希望提高检测准确性。对含有对抗污染的数据集N=7,990进行评估，在Tesla T4 GPU上运行，测量AUC与F1，评估延迟。

Result: DistilBERT在对抗性污染数据集上的AUC达到1.0000、F1为0.9981，延迟约7.403毫秒；CatBoost的AUC为0.9905、F1为0.9486，延迟约0.885毫秒，资源占用极低；GPU环境下DistilBERT在准确性方面占优；CatBoost在边缘部署或成本敏感场景具有优势；两者成本敏感学习下的ROI均超过99.96%。

Conclusion: 对于具备GPU基础设施的组织，DistilBERT提供更高的检测准确性；对于边缘部署或低成本场景，CatBoost仍然是一种可行且高效的替代方案。

Abstract: Business Email Compromise (BEC) is a sophisticated social engineering threat that manipulates organizational hierarchies and exploits psychological vulnerabilities, leading to significant financial damage. According to the 2024 FBI Internet Crime Report, BEC accounts for over $2.9 billion in annual adjusted losses, presenting significant economic asymmetry: the cost of a False Negative (fraud loss) exceeds the cost of a False Positive (manual review) by orders of magnitude (approximately 1 to 5,480).
  This paper examines two detection paradigms for BEC: the Forensic Psycholinguistic Stream, which utilizes CatBoost to analyze psycholinguistic cues with high interpretability and low latency, and the Semantic Stream, which employs DistilBERT for deep learning-based contextual language understanding, offering superior accuracy at higher computational cost. We evaluated DistilBERT on an adversarially poisoned dataset (N = 7,990) generated via our Black Hole protocol, benchmarked on Tesla T4 GPU infrastructure, achieving superior detection (AUC = 1.0000, F1 = 0.9981) with acceptable real-time latency (7.403 milliseconds). CatBoost achieves competitive detection (AUC = 0.9905, F1 = 0.9486) at 8.4x lower latency (0.885 milliseconds), consuming negligible computational resources. For organizations with GPU infrastructure, DistilBERT offers superior accuracy. CatBoost is preferable for edge deployments or cost-sensitive environments due to comparable security and lower operational costs. Both approaches demonstrate return on investment exceeding 99.96% when optimized through cost-sensitive learning, by significantly reducing false negatives and associated financial losses.

</details>


### [38] [Primal: A Unified Deterministic Framework for Quasi-Orthogonal Hashing and Manifold Learning](https://arxiv.org/abs/2511.20839)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: Primal提出一种确定性特征映射框架，利用质数平方根的数论独立性构建可控特征向量，与随机特征投影形成对比。包含StaticPrime与DynamicPrime两种变体，在低频实现等距核映射并线性化非凸几何，在高频实现相位混沌包装以实现最大熵哈希，性能上优于归一化高斯基线，代码开源。


<details>
  <summary>Details</summary>
Motivation: 克服随机特征投影的随机性与不可控性，追求确定性、可控的高维特征映射。利用Besicovitch性质引入不可重复的相位轨迹，并通过质数平方根的独立性增强正交性与分布稳定性；目标是在不同频段实现不同的几何与隐私属性。

Method: 提出两个变体：StaticPrime和DynamicPrime。StaticPrime通过确定性序列生成实现接近Welch界的准正交性的序列化位置信编码；DynamicPrime提供一个输入相关的可伸缩投影层，通过统一的单参数σ将两大数学效用类合一。在低频段，映射成为等距核映射，线性化非凸几何并支持高保真重建与压缩感知；在高频段，产生相位包装的混沌行为，转化为最大熵的单向哈希，且适用于超维计算与隐私保护的分布式学习。

Result: 与归一化高斯基线相比， Primal在正交性保持与分布紧凑度方面表现更优，提供一种计算效率高、数学基础扎实的替代随机矩阵投影的方法。公开实现代码：GitHub。

Conclusion: Primal提供一种确定性、可控的特征映射框架，通过数论与相位动态特性在低频和高频下实现不同的几何与隐私属性，实验结果显示其优于随机投影的分布特性和正交性，并具备开源实现，适用于高效计算与隐私保护场景。

Abstract: We present Primal, a deterministic feature mapping framework that harnesses the number-theoretic independence of prime square roots to construct robust, tunable vector representations. Diverging from standard stochastic projections (e.g., Random Fourier Features), our method exploits the Besicovitch property to create irrational frequency modulations that guarantee infinite non-repeating phase trajectories. We formalize two distinct algorithmic variants: (1) StaticPrime, a sequence generation method that produces temporal position encodings empirically approaching the theoretical Welch bound for quasi-orthogonality; and (2) DynamicPrime, a tunable projection layer for input-dependent feature mapping. A central novelty of the dynamic framework is its ability to unify two disparate mathematical utility classes through a single scaling parameter σ. In the low-frequency regime, the method acts as an isometric kernel map, effectively linearizing non-convex geometries (e.g., spirals) to enable high-fidelity signal reconstruction and compressive sensing. Conversely, the high-frequency regime induces chaotic phase wrapping, transforming the projection into a maximum-entropy one-way hash suitable for Hyperdimensional Computing and privacy-preserving Split Learning. Empirical evaluations demonstrate that our framework yields superior orthogonality retention and distribution tightness compared to normalized Gaussian baselines, establishing it as a computationally efficient, mathematically rigorous alternative to random matrix projections. The code is available at https://github.com/VladimerKhasia/primal

</details>


### [39] [Selecting Belief-State Approximations in Simulators with Latent States](https://arxiv.org/abs/2511.20870)
*Nan Jiang*

Main category: cs.LG

TL;DR: 将状态重置与信念状态采样问题统一为条件分布选择问题，提出在仅能采样的设定下的算法与理论分析，区分潜在状态基拣选与观测基拣选，以及两种回滚/展开策略对保证的影响。


<details>
  <summary>Details</summary>
Motivation: 在复杂仿真器中，重置到历史状态对样本规划和与真实数据的校准至关重要；若存在潜在变量，需从观测历史的后验中抽样信念状态，直接采样往往不可行，因此需要在仅有采样能力的条件下选择合适的信念状态采样器。

Method: 将信念状态选择问题归结为条件分布选择任务，提出新算法并给出在仅能采样的访问条件下的分析。提出两种形式：潜在状态基拣选（直接针对潜在状态的条件分布）与观测基拣选（针对观测分布）。分析它们与下游回滚展开方法的关系，特别对单次重置（Single-Reset）与重复重置（Repeated-Reset）的影响。

Result: 理论上提出并分析了算法及其在两种选择范式下的 guarantees；发现观测基拣选在最自然的回滚策略下可能失效，但在另一种回滚策略下具备保证。

Conclusion: 对信念状态选择问题的算法选项、理论细节与开放问题给出清晰的全景，强调分布变换与采样策略的关键影响，揭示该看似简单问题中的丰富景观。

Abstract: State resetting is a fundamental but often overlooked capability of simulators. It supports sample-based planning by allowing resets to previously encountered simulation states, and enables calibration of simulators using real data by resetting to states observed in real-system traces. While often taken for granted, state resetting in complex simulators can be nontrivial: when the simulator comes with latent variables (states), state resetting requires sampling from the posterior over the latent state given the observable history, a.k.a. the belief state (Silver and Veness, 2010). While exact sampling is often infeasible, many approximate belief-state samplers can be constructed, raising the question of how to select among them using only sampling access to the simulator.
  In this paper, we show that this problem reduces to a general conditional distribution-selection task and develop a new algorithm and analysis under sampling-only access. Building on this reduction, the belief-state selection problem admits two different formulations: latent state-based selection, which directly targets the conditional distribution of the latent state, and observation-based selection, which targets the induced distribution over the observation. Interestingly, these formulations differ in how their guarantees interact with the downstream roll-out methods: perhaps surprisingly, observation-based selection may fail under the most natural roll-out method (which we call Single-Reset) but enjoys guarantees under the less conventional alternative (which we call Repeated-Reset). Together with discussion on issues such as distribution shift and the choice of sampling policies, our paper reveals a rich landscape of algorithmic choices, theoretical nuances, and open questions, in this seemingly simple problem.

</details>


### [40] [Probabilistic Hash Embeddings for Online Learning of Categorical Features](https://arxiv.org/abs/2511.20893)
*Aodong Li,Abishek Sankararaman,Balakrishnan Narayanaswamy*

Main category: cs.LG

TL;DR: 提出一种概率哈希嵌入（PHE）用于在线学习的分类特征，解决在流数据中类别词汇不断扩增时的确定性哈希嵌入易受到到达顺序影响和遗忘的问题。通过贝叶斯在线学习对哈希嵌入及相关潜变量进行增量推断，构建一个可扩展、对新项自适应且参数量界限固定、对项到达顺序不敏感的嵌入模型，在分类、序列建模和推荐等在线任务上显示出更优的性能和更高的内存效率。


<details>
  <summary>Details</summary>
Motivation: 在线设置下，类别特征的词汇表会不断演化，传统的确定性哈希嵌入易受到达顺序影响并产生遗忘，需要一个能够增量、对新项友好且记忆开销受控的嵌入方法。

Method: 提出概率哈希嵌入（PHE），将哈希嵌入视为随机变量，结合贝叶斯在线学习进行增量推断。基于PHE构建可扩展的推断算法，学习模型参数并推断/更新哈希嵌入及其他潜在变量的后验。算法具备：处理演化词汇表、对新项自适应且不忘记旧项、参数量界限且不随观测值数目增长、对项到达顺序不敏感。

Result: 在在线学习设定下进行分类、序列建模和推荐任务的实验，显示PHE在性能上优于传统哈希嵌入，且内存开销极低（仅为单热嵌入表的约2–4%）。 supplementary materials在GitHub提供。

Conclusion: PHE提供了一种鲁棒、可扩展且对词汇动态演化具有容错性的在线嵌入解决方案，确保不随项到达顺序而遗忘，适用于流数据场景的分类、序列建模与推荐等任务。

Abstract: We study streaming data with categorical features where the vocabulary of categorical feature values is changing and can even grow unboundedly over time. Feature hashing is commonly used as a pre-processing step to map these categorical values into a feature space of fixed size before learning their embeddings. While these methods have been developed and evaluated for offline or batch settings, in this paper we consider online settings. We show that deterministic embeddings are sensitive to the arrival order of categories and suffer from forgetting in online learning, leading to performance deterioration. To mitigate this issue, we propose a probabilistic hash embedding (PHE) model that treats hash embeddings as stochastic and applies Bayesian online learning to learn incrementally from data. Based on the structure of PHE, we derive a scalable inference algorithm to learn model parameters and infer/update the posteriors of hash embeddings and other latent variables. Our algorithm (i) can handle an evolving vocabulary of categorical items, (ii) is adaptive to new items without forgetting old items, (iii) is implementable with a bounded set of parameters that does not grow with the number of distinct observed values on the stream, and (iv) is invariant to the item arrival order. Experiments in classification, sequence modeling, and recommendation systems in online learning setups demonstrate the superior performance of PHE while maintaining high memory efficiency (consumes as low as 2~4 memory of a one-hot embedding table). Supplementary materials are at https://github.com/aodongli/probabilistic-hash-embeddings

</details>


### [41] [Evolved SampleWeights for Bias Mitigation: Effectiveness Depends on Optimization Objectives](https://arxiv.org/abs/2511.20909)
*Anil K. Saini,Jose Guadalupe Hernandez,Emily F. Wong,Debanshi Misra,Jason H. Moore*

Main category: cs.LG

TL;DR: 通过比较三种数据点加权生成方法，研究遗传算法演化权重在公平性与预测性能权衡中的表现，发现目标函数的选择对收益影响显著，且以准确性+人口统计平等差异为目标时收益最显著。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据中的机器学习模型可能对边缘群体产生偏见。通过对训练数据点赋予权重来缓解偏见是一个常用策略。本文比较三种权重生成方法，并在多目标优化框架下评估它们在预测性能与公平性之间的折衷能力。

Method: 提出三种权重生成策略：①用遗传算法(EA)演化样本权重；②仅基于数据集特征计算权重；③将所有样本设为等权重。GA在进化过程中以成对的预测性指标和公平性指标作为多目标优化目标，评估指标包括两大预测指标(准确率、AUC)及两大公平性指标(人口统计学平等差异、子群假阴性公平性)。在11个公开数据集(含2个医学数据集)上进行实验，并以这些指标衡量模型性能与公平性的权衡。

Result: 演化得到的样本权重在多数数据集上能实现比其他加权方法更优的公平性与预测性能之间的折衷，但这种优势强烈依赖于所选的优化目标。实验指出，以准确率和人口统计平等差异作为优化目标时，能使显著多的数据集在两者之间取得更优的折衷，且获得的数据集数量为最高。

Conclusion: 优化目标的选择对结果影响显著。用遗传算法生成的权重确实能提升公平性与预测性能的权衡，尤其在将准确率与人口统计平等差异作为优化目标时，收益最为明显。

Abstract: Machine learning models trained on real-world data may inadvertently make biased predictions that negatively impact marginalized communities. Reweighting is a method that can mitigate such bias in model predictions by assigning a weight to each data point used during model training. In this paper, we compare three methods for generating these weights: (1) evolving them using a Genetic Algorithm (GA), (2) computing them using only dataset characteristics, and (3) assigning equal weights to all data points. Model performance under each strategy was evaluated using paired predictive and fairness metrics, which also served as optimization objectives for the GA during evolution. Specifically, we used two predictive metrics (accuracy and area under the Receiver Operating Characteristic curve) and two fairness metrics (demographic parity difference and subgroup false negative fairness). Using experiments on eleven publicly available datasets (including two medical datasets), we show that evolved sample weights can produce models that achieve better trade-offs between fairness and predictive performance than alternative weighting methods. However, the magnitude of these benefits depends strongly on the choice of optimization objectives. Our experiments reveal that optimizing with accuracy and demographic parity difference metrics yields the largest number of datasets for which evolved weights are significantly better than other weighting strategies in optimizing both objectives.

</details>


### [42] [Exploring Time-Step Size in Reinforcement Learning for Sepsis Treatment](https://arxiv.org/abs/2511.20913)
*Yingchuan Sun,Shengpu Tang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Existing studies on reinforcement learning (RL) for sepsis management have mostly followed an established problem setup, in which patient data are aggregated into 4-hour time steps. Although concerns have been raised regarding the coarseness of this time-step size, which might distort patient dynamics and lead to suboptimal treatment policies, the extent to which this is a problem in practice remains unexplored. In this work, we conducted empirical experiments for a controlled comparison of four time-step sizes ($Δt\!=\!1,2,4,8$ h) on this domain, following an identical offline RL pipeline. To enable a fair comparison across time-step sizes, we designed action re-mapping methods that allow for evaluation of policies on datasets with different time-step sizes, and conducted cross-$Δt$ model selections under two policy learning setups. Our goal was to quantify how time-step size influences state representation learning, behavior cloning, policy training, and off-policy evaluation. Our results show that performance trends across $Δt$ vary as learning setups change, while policies learned at finer time-step sizes ($Δt = 1$ h and $2$ h) using a static behavior policy achieve the overall best performance and stability. Our work highlights time-step size as a core design choice in offline RL for healthcare and provides evidence supporting alternatives beyond the conventional 4-hour setup.

</details>


### [43] [Operationalizing Quantized Disentanglement](https://arxiv.org/abs/2511.20927)
*Vitoria Barin-Pacela,Kartik Ahuja,Simon Lacoste-Julien,Pascal Vincent*

Main category: cs.LG

TL;DR: 提出 Cliff 准则，通过鼓励因子分布在轴对齐的断点处出现尖锐跳变来实现无监督解耦的识别与学习，在非线性映射下也有效，且在解耦基准上超越基线。


<details>
  <summary>Details</summary>
Motivation: 在无监督情形下实现因子解耦一直是挑战，理论表明 quantized factors 的阈值应导致概率密度的轴对齐不连续。本文将这一高层原理转化为可操作的正则化目标。

Method: 在学习映射的条件密度估计中，鼓励轴对齐的不连续性（称为 cliffs），并使这些不连续点在某个因子上的位置独立于其他因子取值，从而实现无监督的因子解耦，方法命名为 Cliff。

Result: 在解耦基准数据集上，Cliff 相较多基线表现更好，显示了在无监督解耦方面的有效性。

Conclusion: 通过对密度的轴对齐不连续性进行正则化，提供了一种适用于非线性映射的无监督解耦新策略。

Abstract: Recent theoretical work established the unsupervised identifiability of quantized factors under any diffeomorphism. The theory assumes that quantization thresholds correspond to axis-aligned discontinuities in the probability density of the latent factors. By constraining a learned map to have a density with axis-aligned discontinuities, we can recover the quantization of the factors. However, translating this high-level principle into an effective practical criterion remains challenging, especially under nonlinear maps. Here, we develop a criterion for unsupervised disentanglement by encouraging axis-aligned discontinuities. Discontinuities manifest as sharp changes in the estimated density of factors and form what we call cliffs. Following the definition of independent discontinuities from the theory, we encourage the location of the cliffs along a factor to be independent of the values of the other factors. We show that our method, Cliff, outperforms the baselines on all disentanglement benchmarks, demonstrating its effectiveness in unsupervised disentanglement.

</details>


### [44] [Subgoal Graph-Augmented Planning for LLM-Guided Open-World Reinforcement Learning](https://arxiv.org/abs/2511.20993)
*Shanwei Fan*

Main category: cs.LG

TL;DR: 提出 Subgoal Graph-Augmented Actor-Critic-Refiner (SGA-ACR) 框架，通过结合环境特定的子目标图和结构化实体知识，以及一个分离的多-LLM 规划流程（生成/批评/ refined），实现可执行且可验证的子目标生成，提升计划与执行的对齐。通过子目标追踪器在 Crafter 的 22 个任务中验证有效性。


<details>
  <summary>Details</summary>
Motivation: LLMs 在高层次规划中能分解任务为子目标，但缺乏针对具体环境的 grounding，导致子目标在目标环境中不可行或无关紧要。此外，单一模型的规划常将生成与自我验证混为一体，产生自信但不可靠的子目标。需要一个可将生成、评估、 refinement 解耦并结合环境知识的框架。

Method: 提出 SGA-ACR：1) 引入环境特定的子目标图与结构化实体知识作为环境约束；2) 使用多-LLM 规划流水线，将生成、批评与 refinement 分离，确保子目标的可执行性与可验证性；3) 引入子目标追踪器，监控执行进度、提供辅助奖励，并动态更新子目标图以维持计划与行动的一致性。

Result: 在开放世界游戏 Crafter 的 22 个多样任务上进行评估，结果显示所提出的方法能够显著改善规划与执行之间的对齐，提升任务完成的可靠性与效率（与基线相比具有统计显著的改善）。

Conclusion: 通过将环境特定的子目标图、结构化知识与分离式的多-LLM 规划流程结合，SGA-ACR 能实现可执行且可验证的子目标生成，并通过子目标追踪器实现持续对齐与自适应更新，为开放世界和复杂环境中的规划-执行耦合提供一个可扩展的解决方案。

Abstract: Large language models (LLMs) offer strong high-level planning capabilities for reinforcement learning (RL) by decomposing tasks into subgoals. However, their practical utility is limited by poor planning-execution alignment, which reflects a critical gap between abstract plans and actionable, environment-compatible behaviors. This misalignment arises from two interrelated limitations: (1) LLMs often produce subgoals that are semantically plausible but infeasible or irrelevant in the target environment due to insufficient grounding in environment-specific knowledge, and (2) single-LLM planning conflates generation with self-verification, resulting in overconfident yet unreliable subgoals that frequently fail during execution. To address these challenges, we propose Subgoal Graph-Augmented Actor-Critic-Refiner (SGA-ACR), a framework that integrates an environment-specific subgoal graph and structured entity knowledge with a multi-LLM planning pipeline that explicitly separates generation, critique, and refinement to produce executable and verifiable subgoals. A subgoal tracker further monitors execution progress, provides auxiliary rewards, and adaptively updates the subgoal graph to maintain alignment between plans and actions. Experimental results on 22 diverse tasks in the open-world game "Crafter" demonstrate the effectiveness of our proposed method.

</details>


### [45] [FANoise: Singular Value-Adaptive Noise Modulation for Robust Multimodal Representation Learning](https://arxiv.org/abs/2511.20997)
*Jiaoyang Li,Jun Fang,Tianhao Gao,Xiaohui Zhang,Zhiyuan Liu,Chao Liu,Pengzhang Liu,Qixia Jiang*

Main category: cs.LG

TL;DR: 提出 FANoise：一种基于特征的自适应噪声注入策略，用于对比学习中的跨模态表征学习，结合 InfoNCE 目标，在训练动态下抑制噪声负效应、保留其正效应，提升多模态任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据增强中的噪声注入多数为静态或启发式，未充分考虑训练过程中的特征分布和梯度信号的动态变化，导致鲁棒性和泛化性受限。需要一个能动态适应训练状态的噪声注入机制，以提升对比学习中的表征质量。

Method: 提出 FANoise，一种面向多模态对比学习的特征自适应噪声注入策略。基于对比学习的动态特性，结合 InfoNCE 损失的理论框架，设计能在训练过程中自适应调整注入噪声的强度和形式的机制，以减轻噪声的负面影响并保留其潜在正向作用，并在多模态基线模型上进行系统评估。

Result: 实验结果表明，FANoise 在多模态任务上对多种基础视觉-语言模型（VLM）均有持续且显著的性能提升，且能在不同任务和模型设定下保持鲁棒性。理论分析与实验相结合，证明该方法在噪声动态平衡方面具有优势。

Conclusion: 动态、特征自适应的噪声注入策略能有效提升跨模态对比学习中的表征质量，FANoise 提供了一个基于训练动态的理论-实验框架，具有良好的通用性和实用性。

Abstract: Representation learning is fundamental to modern machine learning, powering applications such as text retrieval and multimodal understanding. However, learning robust and generalizable representations remains challenging. While prior work has demonstrated that active noise injection, a form of data augmentation, can enhance encoding performance, most existing methods rely on heuristic or static noise, overlooking the dynamic nature of feature distributions during training. In this work, we systematically study the role of noise in representation learning from both gradient-based and feature distribution perspectives, using InfoNCE loss as a representative example. Focusing on multimodal representation learning, we propose FANoise, a novel feature-adaptive noise injection strategy. By leveraging the dynamics of contrastive learning, FANoise effectively mitigates the negative impacts of noise while preserving its benefits. Under this theoretically grounded framework, comprehensive experiments demonstrate that FANoise consistently improves overall performance on multimodal tasks across various base VLM models.

</details>


### [46] [Estimating Ising Models in Total Variation Distance](https://arxiv.org/abs/2511.21008)
*Constantinos Daskalakis,Vardis Kandiros,Rui Yao*

Main category: cs.LG

TL;DR: 提出对两大类Ising模型的MPLE分析，给出在总变差距离下的统一框架，结合两类模型条件（有界算子范数并满足MLSI；以及有界无穷范数/宽度），实现多项式时间估计以及最优或近似最优的样本复杂性。适用于广泛设置，辅以张量化不等式、度量分解与分布式一致性工具。


<details>
  <summary>Details</summary>
Motivation: 在TV距离下估计Ising模型的统计复杂度清楚，但缺乏统一的、在多种模型假设下的高效算法框架。本文力求通过对MPLE的统一分析，构建两类通用条件下的多项式时间估计器，达到接近最优的样本效率。

Method: 对最大伪似然估计（MPLE）进行统一分析，覆盖两大类模型：1) 满足MLSI且具有有界算子范数的Ising模型；2) 互作用矩阵具有有界无穷范数（宽度有界）的模型。通过张量化、不等式分解、以及分布集中性等工具，推导出在TV距离下的误差界与样本复杂性，并给出多项式时间实现的估计算法。

Result: 在两类模型下均给出多项式时间的估计算法，并给出最优或接近最优的样本复杂性界；结论涵盖对广义Ising模型估计的统一框架及其在不同结构假设下的适用性。

Conclusion: 本文提供了一个统一的MPLE分析框架，连接统计复杂性与计算效率，在两类常见结构假设下实现高效估计，为Ising模型在TV距离的估计提供了广泛的理论支撑与方法论基础。

Abstract: We consider the problem of estimating Ising models over $n$ variables in Total Variation (TV) distance, given $l$ independent samples from the model. While the statistical complexity of the problem is well-understood [DMR20], identifying computationally and statistically efficient algorithms has been challenging. In particular, remarkable progress has occurred in several settings, such as when the underlying graph is a tree [DP21, BGPV21], when the entries of the interaction matrix follow a Gaussian distribution [GM24, CK24], or when the bulk of its eigenvalues lie in a small interval [AJK+24, KLV24], but no unified framework for polynomial-time estimation in TV exists so far. Our main contribution is a unified analysis of the Maximum Pseudo-Likelihood Estimator (MPLE) for two general classes of Ising models. The first class includes models that have bounded operator norm and satisfy the Modified Log-Sobolev Inequality (MLSI), a functional inequality that was introduced to study the convergence of the associated Glauber dynamics to stationarity. In the second class of models, the interaction matrix has bounded infinity norm (or bounded width), which is the most common assumption in the literature for structure learning of Ising models. We show how our general results for these classes yield polynomial-time algorithms and optimal or near-optimal sample complexity guarantees in a variety of settings. Our proofs employ a variety of tools from tensorization inequalities to measure decompositions and concentration bounds.

</details>


### [47] [ChatGpt Content detection: A new approach using xlm-roberta alignment](https://arxiv.org/abs/2511.21009)
*Md Tasnin Tanvir,Dr Santanu Kumar Dash,Ishan Shahnan,Nafis Fuad,Tanvir Rahman,Abdullah Al Faisal,Asadullah Al Mamun*

Main category: cs.LG

TL;DR: 提出一个基于多语言Transformer（XLM-RoBERTa）的AI文本检测框架，结合吞吐前处理、困惑度、语义和可读性特征，通过平衡数据集微调模型，在多种文本领域实现高准确性，并分析特征对决策的贡献。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI（如ChatGPT）日益普及，区分AI生成文本与人类文本的需求日益紧迫，涉及学术诚信、透明度与AI伦理。

Method: 1) 采用严格的预处理和多特征提取（困惑度、语义、可读性等） 2) 在人工与AI文本平衡的数据集上对XLM-RoBERTa进行微调 3) 评估模型在不同文本体裁上的鲁棒性 4) 进行特征分析，揭示困惑度与基于注意力的特征在区分中的关键作用。

Result: 模型显示高准确性和对多领域文本的鲁棒性；困惑度与注意力等特征被确认为区分AI文本与人类文本的关键因素。

Conclusion: 为维护学术诚信提供有价值的检测工具，并为AI伦理领域的透明度与问责制贡献力量。未来工作包括探索其他先进模型及扩大数据集以提升泛化能力。

Abstract: The challenge of separating AI-generated text from human-authored content is becoming more urgent as generative AI technologies like ChatGPT become more widely available. In this work, we address this issue by looking at both the detection of content that has been entirely generated by AI and the identification of human text that has been reworded by AI. In our work, a comprehensive methodology to detect AI- generated text using XLM-RoBERTa, a state-of-the-art multilingual transformer model. Our approach includes rigorous preprocessing, and feature extraction involving perplexity, semantic, and readability features. We fine-tuned the XLM-RoBERTa model on a balanced dataset of human and AI-generated texts and evaluated its performance. The model demonstrated high accuracy and robust performance across various text genres. Additionally, we conducted feature analysis to understand the model's decision-making process, revealing that perplexity and attention-based features are critical in differentiating between human and AI-generated texts. Our findings offer a valuable tool for maintaining academic integrity and contribute to the broader field of AI ethics by promoting transparency and accountability in AI systems. Future research directions include exploring other advanced models and expanding the dataset to enhance the model's generalizability.

</details>


### [48] [Predictive Safety Shield for Dyna-Q Reinforcement Learning](https://arxiv.org/abs/2511.21531)
*Jin Pin,Krasowski Hanna,Vanneaux Elena*

Main category: cs.LG

TL;DR: 提出一种离散空间的模型基预测安全盾牌，基于安全预测在局部更新Q函数，兼顾硬性安全与性能；网格世界实验显示短时预测即可识别最优路径，对仿真-现实分布漂移鲁棒且无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习的安全性难以保障，现有安全盾牌多使用随机抽样或固定后备控制，忽略不同安全行动的未来性能影响，因此需要在保证安全的前提下提升长期回报。

Method: 提出预测安全盾牌，通过对环境模型进行安全仿真，得到安全预测；在该预测基础上对Q函数进行局部更新，以约束策略选择，以实现硬安全与改进的性能。

Result: 在网格世界的实验中，短预测 horizon 即能识别最优路径；方法对分布漂移鲁棒（如仿真到现实），且无需额外训练。

Conclusion: 该盾牌在保留硬安全保证的同时提升了性能，且对模型不确定性和域偏移具有鲁棒性，具备实用性。

Abstract: Obtaining safety guarantees for reinforcement learning is a major challenge to achieve applicability for real-world tasks. Safety shields extend standard reinforcement learning and achieve hard safety guarantees. However, existing safety shields commonly use random sampling of safe actions or a fixed fallback controller, therefore disregarding future performance implications of different safe actions. In this work, we propose a predictive safety shield for model-based reinforcement learning agents in discrete space. Our safety shield updates the Q-function locally based on safe predictions, which originate from a safe simulation of the environment model. This shielding approach improves performance while maintaining hard safety guarantees. Our experiments on gridworld environments demonstrate that even short prediction horizons can be sufficient to identify the optimal path. We observe that our approach is robust to distribution shifts, e.g., between simulation and reality, without requiring additional training.

</details>


### [49] [Staggered Environment Resets Improve Massively Parallel On-Policy Reinforcement Learning](https://arxiv.org/abs/2511.21011)
*Sid Bharthulwar,Stone Tao,Hao Su*

Main category: cs.LG

TL;DR: 通过引入 staggered resets 来降低大规模并行环境中的非平稳性，提高 PPO 等 on-policy RL 在短 rollout 设置下的样本效率和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 在 GPU 加速的并行环境中，为提高吞吐量，通常采用短 rollout 和高更新/数据比率，但同步重置造成非平稳性，影响学习信号，降低训练稳定性。

Method: 提出 staggered resets：在任务 horizon 内的不同点初始化和重置环境，以增加训练批次的时间多样性，降低同步 rollout 带来的非平稳性。用 toy 环境刻画在各种维度的收益，并在高维机器人环境中验证，比较同步重置。

Result: 在 toy 环境中展示了维度上的收益，在高维机器人任务中实现显著的样本效率提升、墙钟时间收敛更快、最终性能更强，并且随着并行环境增多，staggered resets 的效果优于简单同步 rollout。

Conclusion: staggered resets 可以有效缓解并行 RL 的非平稳性，提升吞吐与学习稳定性，且随着并行规模增大，其优势更明显，适合提升 on-policy RL 的数据效率与训练稳定性。

Abstract: Massively parallel GPU simulation environments have accelerated reinforcement learning (RL) research by enabling fast data collection for on-policy RL algorithms like Proximal Policy Optimization (PPO). To maximize throughput, it is common to use short rollouts per policy update, increasing the update-to-data (UTD) ra- tio. However, we find that, in this setting, standard synchronous resets introduce harmful nonstationarity, skewing the learning signal and destabilizing training. We introduce staggered resets, a simple yet effective technique where environments are initialized and reset at varied points within the task horizon. This yields training batches with greater temporal diversity, reducing the nonstationarity induced by synchronized rollouts. We characterize dimensions along which RL environments can benefit significantly from staggered resets through illustrative toy environ- ments. We then apply this technique to challenging high-dimensional robotics environments, achieving significantly higher sample efficiency, faster wall-clock convergence, and stronger final performance. Finally, this technique scales better with more parallel environments compared to naive synchronized rollouts.

</details>


### [50] [A Probabilistic Framework for Temporal Distribution Generalization in Industry-Scale Recommender Systems](https://arxiv.org/abs/2511.21032)
*Yuxuan Zhu,Cong Fu,Yabo Ni,Anxiang Zeng,Yuan Fang*

Main category: cs.LG

TL;DR: 提出 ELBO_TDS，一个结合因果图和自监督变分推断的时序分布偏移鲁棒推荐框架，通过数据增强扩展训练分布，提升长期泛化，已在 Shopee 部署，GMV 提升约2.33%。


<details>
  <summary>Details</summary>
Motivation: Temporal distribution shift（TDS）会侵蚀推荐系统的长期准确性，现有的周期性增量训练难以同时捕捉稳定模式和瞬时模式；现有的对比方法如不变量学习和自监督学习在泛化、表示塌缩或数据利用效率方面存在局限性，需要一种在工业场景可落地且能充分利用扩展分布的方案。

Method: 识别现实生产数据中的关键时移因素并设计简洁有效的数据增强策略，对这些时变因素进行重采样以扩展训练样本分布；在因果图框架下建模时序推荐场景，推导自监督的变分目标 ELBO_TDS，使对扩展分布的利用与因果结构保持一致，以避免表示塌缩。

Result: 理论和经验分析均表明方法具备更强的时序泛化能力，实验显示对用户GMV的提升为2.33%，并已在 Shopee Product Search 中成功部署，同时提供了开源代码。

Conclusion: ELBO_TDS 可以无缝集成到工业规模的增量学习流水线中，提升对时序变化的鲁棒性和长期性能，具有较好的实际落地性和可重复性。

Abstract: Temporal distribution shift (TDS) erodes the long-term accuracy of recommender systems, yet industrial practice still relies on periodic incremental training, which struggles to capture both stable and transient patterns. Existing approaches such as invariant learning and self-supervised learning offer partial solutions but often suffer from unstable temporal generalization, representation collapse, or inefficient data utilization. To address these limitations, we propose ELBO$_\text{TDS}$, a probabilistic framework that integrates seamlessly into industry-scale incremental learning pipelines. First, we identify key shifting factors through statistical analysis of real-world production data and design a simple yet effective data augmentation strategy that resamples these time-varying factors to extend the training support. Second, to harness the benefits of this extended distribution while preventing representation collapse, we model the temporal recommendation scenario using a causal graph and derive a self-supervised variational objective, ELBO$_\text{TDS}$, grounded in the causal structure. Extensive experiments supported by both theoretical and empirical analysis demonstrate that our method achieves superior temporal generalization, yielding a 2.33\% uplift in GMV per user and has been successfully deployed in Shopee Product Search. Code is available at https://github.com/FuCongResearchSquad/ELBO4TDS.

</details>


### [51] [Prediction of Herd Life in Dairy Cows Using Multi-Head Attention Transformers](https://arxiv.org/abs/2511.21034)
*Mahdi Saki,Justin Lipman*

Main category: cs.LG

TL;DR: 利用多头注意力变换器的AI模型，在出生时的多变量时间序列数据上预测奶牛的长期存活，跨7个农场、19,000头牛与约780,000条记录，R^2约83%，具实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 奶农需要对奶牛的长期性能进行客观评估，以识别更具韧性的奶牛，从而提升产奶期和经济效益；决策涉及环境和经济影响，需要开发能在实际养殖场中落地的预测工具。

Method: 采用多头注意力Transformer对出生开始就的历史多变量时间序列数据进行建模，分析约780,000条记录，覆盖19,000头牛在7个澳大利亚农场的数据，并评估跨农场的泛化能力。

Result: 模型在预测群体寿命（herd life）方面的决定系数达到83%，在所研究的农场中表现出较强的预测能力。

Conclusion: 显示该AI驱动方法在奶牛群管理中的潜在实际应用价值，有助于识别具备更高长期产奶潜力的个体，并为淘汰决策提供更科学的依据；跨多农场的良好表现支持其在真实养殖环境中的可行性。

Abstract: Dairy farmers should decide to keep or cull a cow based on an objective assessment of her likely performance in the herd. For this purpose, farmers need to identify more resilient cows, which can cope better with farm conditions and complete more lactations. This decision-making process is inherently complex, with significant environmental and economic implications. In this study, we develop an AI-driven model to predict cow longevity using historical multivariate time-series data recorded from birth. Leveraging advanced AI techniques, specifically Multi-Head Attention Transformers, we analysed approximately 780,000 records from 19,000 unique cows across 7 farms in Australia. The results demonstrate that our model achieves an overall determination coefficient of 83% in predicting herd life across the studied farms, highlighting its potential for practical application in dairy herd management.

</details>


### [52] [FedAPA: Federated Learning with Adaptive Prototype Aggregation Toward Heterogeneous Wi-Fi CSI-based Crowd Counting](https://arxiv.org/abs/2511.21048)
*Jingtao Guo,Yuyi Mao,Ivan Wang-Hei Ho*

Main category: cs.LG

TL;DR: FedAPA 提出一种自适应原型聚合的联邦学习框架，用于Wi-Fi CSI 基于 sensing。通过对同伴原型的相似性进行加权，实现在每个客户端的个性化全局原型，并在本地训练阶段引入分类与表示对比学习的混合目标，理论上给出收敛性分析，在真实场景下显著优于基线，显著降低通信开销。


<details>
  <summary>Details</summary>
Motivation: 大规模部署中需要大量站点特定的训练数据；联邦学习能避免 raw data 共享，但异质性数据和设备资源受限使得 global 模型难以泛化。需对客户端贡献进行自适应加权以实现个性化且高效的全局表示。

Method: 提出 FedAPA：使用自适应原型聚合（APA）策略，为同伴原型分配基于相似性的权重，从而实现对每个客户端的个性化全局原型；在本地训练中采用混合目标，结合分类学习和表示对比学习以对齐局部与全局知识；给出收敛性分析，并在包含六个环境、最多20人分布式 Wi-Fi 场景中进行实际评估。

Result: 相对于多项基线，FedAPA 在准确率、F1、MAE 以及通信开销方面均有提升：准确率至少提升 9.65%，F1 提升约 9%，MAE 降低约 0.29，通信开销降低约 95.94%。

Conclusion: FedAPA 有效缓解了异质性数据和资源约束带来的挑战，通过对每个客户端的个性化全局原型实现更精准的 CSI 基于感知，且在理论收敛性与实证评估上均表现良好，显示在现实分布式环境中的应用潜力。

Abstract: Wi-Fi channel state information (CSI)-based sensing provides a non-invasive, device-free approach for tasks such as human activity recognition and crowd counting, but large-scale deployment is hindered by the need for extensive site-specific training data. Federated learning (FL) offers a way to avoid raw data sharing but is challenged by heterogeneous sensing data and device resources. This paper proposes FedAPA, a collaborative Wi-Fi CSI-based sensing algorithm that uses adaptive prototype aggregation (APA) strategy to assign similarity-based weights to peer prototypes, enabling adaptive client contributions and yielding a personalized global prototype for each client instead of a fixed-weight aggregation. During local training, we adopt a hybrid objective that combines classification learning with representation contrastive learning to align local and global knowledge. We provide a convergence analysis of FedAPA and evaluate it in a real-world distributed Wi-Fi crowd counting scenario with six environments and up to 20 people. The results show that our method outperform multiple baselines in terms of accuracy, F1 score, mean absolute error (MAE), and communication overhead, with FedAPA achieving at least a 9.65% increase in accuracy, a 9% gain in F1 score, a 0.29 reduction in MAE, and a 95.94% reduction in communication overhead.

</details>


### [53] [Breaking the Safety-Capability Tradeoff: Reinforcement Learning with Verifiable Rewards Maintains Safety Guardrails in LLMs](https://arxiv.org/abs/2511.21050)
*Dongkyu Derek Cho,Huan Song,Arijit Ghosh Chowdhury,Haotian An,Yawei Wang,Rohit Thekkanal,Negin Sokhandan,Sharlina Keshava,Hannah Marlowe*

Main category: cs.LG

TL;DR: RLVR在理论和实证分析中显示，在KL约束下可以同时提高推理能力与安全性，挑战了普遍的安全-能力权衡假设。


<details>
  <summary>Details</summary>
Motivation: 现有微调策略（SFT、RLHF）在提升任务性能时常伴随安全性下降，存在安全与能力的固有权衡。尽管RLVR引入可验证的奖励以解决可测任务，但其安全性影响尚未系统研究。

Method: 理论分析：在KL约束优化下推导安全漂移的上界，并给出在何种条件下可消除安全退化的充要条件；实证分析：在五个对抗性安全基准上进行广泛实验，比较优化算法、模型规模与任务领域的影响，辅以消融研究。

Result: 理论上给出安全漂移上界，并在特定条件下可消除安全退化；实证上，RLVR在多项基准上同时提升推理能力与保持或改善安全护栏，且对优化算法、模型规模和任务域的敏感性得到系统分析。

Conclusion: 研究结果挑战了安全-能力必然权衡的普遍认知，表明通过合适的训练范式（如带KL约束的RLVR）可实现两者共赢，为安全可控的推理能力提升提供新路径。

Abstract: Fine-tuning large language models (LLMs) for downstream tasks typically exhibit a fundamental safety-capability tradeoff, where improving task performance degrades safety alignment even on benign datasets. This degradation persists across standard approaches including supervised finetuning (SFT) and reinforcement learning from human feedback (RLHF). While reinforcement learning with verifiable rewards (RLVR) has emerged as a promising alternative that optimizes models on objectively measurable tasks, its safety implications remain unexplored. We present the first comprehensive theoretical and empirical analysis of safety properties in RLVR. Theoretically, we derive upper bounds on safety drift under KL-constrained optimization and prove conditions under which safety degradation is eliminated. Empirically, we conduct extensive experiments across five adversarial safety benchmarks, demonstrating that RLVR can simultaneously enhance reasoning capabilities while maintaining or improving safety guardrails. Our comprehensive ablation studies examine the effects of optimization algorithms, model scale, and task domains. Our findings challenge the prevailing assumption of an inevitable safety capability trade-off, and establish that a specific training methodology can achieve both objectives simultaneously, providing insights for the safe deployment of reasoning-capable LLMs.

</details>


### [54] [Efficient Diffusion Planning with Temporal Diffusion](https://arxiv.org/abs/2511.21054)
*Jiaming Guo,Rui Zhang,Zerun Li,Yunkai Gao,Shaohui Peng,Siming Lan,Xing Hu,Zidong Du,Xishan Zhang,Ling Li*

Main category: cs.LG

TL;DR: Temporal Diffusion Planner (TDP) 将扩散计划中的去噪步骤分散到时间维度，通过生成初始计划并使其随时间逐渐变得模糊，在后续时间步仅对前一计划进行少量去噪更新，从而降低计算量并提高决策频率，同时引入自动再规划以避免与现实偏差过大。实验证明在 D4RL 上相比逐步重新生成计划的方法，决策频率提升约 11-24.8 倍，且性能相同或更好。


<details>
  <summary>Details</summary>
Motivation: 离线数据上学习高性能策略的扩散规划在每个时间步生成新计划会带来显著的计算开销并降低决策频率，且频繁切换计划可能影响性能。受人类“短期具体、长期概括”的规划方式启发，提出一种在时间维度上分配去噪步骤的策略以提高决策效率并保持对现实环境的适应性。

Method: 提出 Temporal Diffusion Planner (TDP)：先生成初始计划，让其随时间逐步变得模糊；在每个后续时间步对前一计划做少量的去噪更新，而非重新生成一个新计划；通过这种跨时间的去噪分布实现更高效的决策，并引入自动再规划机制以防止计划与现实之间出现过大偏差。实验在 D4RL 数据集上评估，与逐步生成新计划的方法相比，决策频率显著提高且性能等价或提升。

Result: 与逐步生成新计划的方法相比，TDP 将决策频率提高了约 11-24.8 倍，同时在多数设置下实现了相同或更好的性能。

Conclusion: 通过将去噪步骤分散到时间维度，TDP 显著提升决策效率并维持或提升性能；自动再规划机制有效减少计划与现实之间的偏差，证明了在离线学习场景中，分时的扩散规划是可行且高效的方法。

Abstract: Diffusion planning is a promising method for learning high-performance policies from offline data. To avoid the impact of discrepancies between planning and reality on performance, previous works generate new plans at each time step. However, this incurs significant computational overhead and leads to lower decision frequencies, and frequent plan switching may also affect performance. In contrast, humans might create detailed short-term plans and more general, sometimes vague, long-term plans, and adjust them over time. Inspired by this, we propose the Temporal Diffusion Planner (TDP) which improves decision efficiency by distributing the denoising steps across the time dimension. TDP begins by generating an initial plan that becomes progressively more vague over time. At each subsequent time step, rather than generating an entirely new plan, TDP updates the previous one with a small number of denoising steps. This reduces the average number of denoising steps, improving decision efficiency. Additionally, we introduce an automated replanning mechanism to prevent significant deviations between the plan and reality. Experiments on D4RL show that, compared to previous works that generate new plans every time step, TDP improves the decision-making frequency by 11-24.8 times while achieving higher or comparable performance.

</details>


### [55] [A Unified Understanding of Offline Data Selection and Online Self-refining Generation for Post-training LLMs](https://arxiv.org/abs/2511.21056)
*Quan Xiao,Tianyi Chen*

Main category: cs.LG

TL;DR: 提出一种将离线数据选择和在线自我精炼生成统一视角的框架，用以适配大型语言模型在下游任务，采用双层数据选择并对每个问题/响应分配可学习的权重，理论上证明其有效性并在质量提升与安全对齐任务上优于未筛选基线。


<details>
  <summary>Details</summary>
Motivation: LLM在下游任务中的数据质量直接决定性能；离线数据选择和在线自我精炼生成是提升数据质量的关键步骤，但缺乏统一的优化框架。文中通过优化视角，将离线选择与在线自我改进结合，利用验证集权重来指导数据与模型的适配。

Method: 提出双层(bilevel)数据选择用于离线数据对验证集的选择，并将在线自我精炼生成视为对当前回答序列的模型适配（选择在当前响应上训练得到的模型以更好拟合验证数据），对每个问题与回答分配学习得到的数据权重，这些权重可显式或隐式地体现。首次从理论上证明双层数据选择框架的有效性，并在离线数据与基于验证数据权重的在线生成相结合时提升性能。

Result: 理论层面证明了该框架的有效性，并展示相对于未筛选直接混合基线的性能提升；在质量提升和安全友好/安全意识的LLM微调任务上实验结果支持其有效性。

Conclusion: 该框架提供了离线数据选择与自我精炼生成的统一理解，结合离线数据与以验证数据为权重的在线生成可提升微调性能。

Abstract: Offline data selection and online self-refining generation, which enhance the data quality, are crucial steps in adapting large language models (LLMs) to specific downstream tasks. We tackle offline data selection and online self-refining generations through an optimization perspective. Specifically, bilevel data selection is used for offline data selection with respect to the validation dataset, and we treat online self-refining generation as a model adaptation step of selecting the model trained on current responses that best fits the validation data. Our framework offers a unified understanding of offline data selection and self-refining generation by assigning a learned data weight to each question and response, either explicitly or implicitly. For the first time, we theoretically demonstrate the effectiveness of the bilevel data selection framework and demonstrate its performance gains over unfiltered direct mixing baselines. By combining offline data with validation-weighted online generations, our method enhances fine-tuning performance. Experiments on quality enhancement and safety-aware LLM fine-tuning validate its effectiveness.

</details>


### [56] [Aligning LLMs with Biomedical Knowledge using Balanced Fine-Tuning](https://arxiv.org/abs/2511.21075)
*Zhenchao Tang,Fang Wang,Haohuai He,Jiale Zhou,Tianxu Lv,Jun Zhu,Shouzhi Chen,Minghao Yang,Yu Wang,Jiayang Wu,Yidong Song,Jianhua Yao*

Main category: cs.LG

TL;DR: 提出一种名为 Balanced Fine-Tuning (BFT) 的后训练方法，通过两层权重机制在缺乏外部奖励的情况下从稀疏生物医学数据中学习复杂推理，显著优于 SFT，并提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 SFT 容易对表层指令模式过拟合，且生物医学推理依赖稀疏文本数据；RL 需要无法实现的外部奖励和验证，难以在该领域实际应用。需要一种高效的后训练方法来增强对生物医学知识的内在化推理能力。

Method: 引入两层权重：1) 令牌级损失通过预测概率放缩以稳定梯度、防止过拟合；2) 样本级通过“最小组置信度”（minimum group confidence）自适应提升对难样本的学习；无需外部奖励信号；对比实验显示对 SFT 更优。

Result: BFT 在医疗任务中使模型获得 SFT 未能获得的知识；在生物任务中，BFT 的模型在生物过程推理方面优于 GeneAgent；文本嵌入可直接用于下游任务，如基因相互作用预测和单细胞扰动反应预测；总体上显著提升了生物医学领域的 LLMS 能力。

Conclusion: BFT 提供了一种高效、无奖励信号的后训练策略，能从稀疏数据中学习复杂推理，具有广泛的生物医药研究应用潜力。

Abstract: Effective post-training is essential to align Large Language Models (LLMs) with specialized biomedical knowledge to accelerate life science research. However, current approaches face significant limitations. First, biomedical reasoning involves intricate mechanisms often represented by sparse textual data. Standard Supervised Fine-Tuning (SFT) tends to overfit to surface-level instruction patterns without effectively internalizing this fragmented scientific knowledge. Second, Reinforcement Learning (RL) is impractical for this domain, as defining meaningful rewards often necessitates prohibitive experimental validation (e.g., wet-lab verification of drug responses), rendering real-time feedback unfeasible. We propose Balanced Fine-Tuning (BFT), an efficient post-training method designed to learn complex reasoning from sparse data without external reward signals. BFT operates through a two-layer weighting mechanism: 1. At the token level, it scales loss via prediction probabilities to stabilize gradients and prevent overfitting; 2. At the sample level, it uses "minimum group confidence" to adaptively enhance the learning of hard samples. Experiments demonstrate that BFT significantly outperforms SFT. In medical tasks, it enables LLMs to acquire knowledge that SFT misses. In biological tasks, BFT-based LLMs surpass GeneAgent (an accurate agent for biology analysis) in biological process reasoning. Moreover, the text embeddings generated by BFT can be directly applied to downstream tasks, such as gene interaction and single-cell perturbation response prediction. These results indicate that BFT facilitates broad applications of LLMs in biomedical research.

</details>


### [57] [MLPMoE: Zero-Shot Architectural Metamorphosis of Dense LLM MLPs into Static Mixture-of-Experts](https://arxiv.org/abs/2511.21089)
*Ivan Novikov*

Main category: cs.LG

TL;DR: A training-free, deterministic method (MLPMoE) converts dense MLPs in transformers into a static, high-cardinality mixture of experts via tensor slicing, enabling structured sparsity with minimal accuracy loss; augmented by Fractal Fade and Compensated Pruning, it works post hoc on checkpoints without training data or routers, and achieves substantial parameter reduction (≈20%) with small perplexity changes on large models.


<details>
  <summary>Details</summary>
Motivation: Inference cost in dense LLMs scales linearly with parameter count; prior sparse MoE methods require calibration data, clustering, or training. A training-free, deterministic transformation to a fixed mixture of experts promises efficiency without additional data or gradient steps.

Method: Apply MLPMoE: reinterpret tensor parallelism as a topological conversion and restructure dense MLPs into a static, high-cardinality mixture of experts using simple tensor slicing and summation. Introduce Fractal Fade (differential branch sparsity) and Compensated Pruning (variance-preserving branch reduction) to induce structured sparsity. The process is post hoc, code-based, and does not require gradients or router training.

Result: Zero-shot MLPMoE on Qwen2.5-0.5B-Instruct and DeepSeek-R1-Distill-Llama-8B changes proxy perplexity by <0.05% with essentially unchanged parameter count. On an 8B model, differential sparsity removes ~20% of MLP parameters while keeping perplexity within ~2% of the dense baseline.

Conclusion: A training-free, gradient-free post hoc transformation can induce structured sparsity in dense transformers with minimal impact on perplexity, enabling more efficient inference without extra calibration data or training; accompanying code is available.

Abstract: Large Language Models (LLMs) are predominantly deployed as dense transformers, where every parameter in every feed-forward block is activated for every token. While architecturally simple, this is computationally inefficient, since inference costs scale linearly with parameter count. Recent upcycling methods such as MoEfication, CMoE, ToMoE, and MoORE reveal that much of the useful computation lives in sparse, semi-modular substructures inside dense feed-forward networks, but these approaches typically rely on clustering, activation profiling, singular value decomposition, or custom routing that requires calibration data. This paper introduces MLPMoE (MLP Mixture-of-Experts), a training-free, deterministic transformation that restructures the dense MLP in transformer blocks into a static, high-cardinality mixture of experts. The transformation uses simple tensor slicing and summation, reinterpreting the algebra of tensor parallelism as a topological conversion rather than a distributed training pattern. We further introduce Fractal Fade (differential branch sparsity) and Compensated Pruning (variance-preserving branch reduction) as lightweight mechanisms for structured sparsity. On Qwen2.5-0.5B-Instruct and DeepSeek-R1-Distill-Llama-8B, the zero-shot MLPMoE transform changes a proxy perplexity metric by less than 0.05 percent while keeping the parameter count effectively constant. On the 8B model, differential sparsity removes about 20 percent of MLP parameters while keeping perplexity within about 2 percent of the dense baseline. The method operates entirely post hoc on existing checkpoints and does not require gradients, calibration sets, or router training. Code is available at https://gist.github.com/iwallarm/fc2ef1eddf226ca7814f9e5e2ae9bad1

</details>


### [58] [MNM : Multi-level Neuroimaging Meta-analysis with Hyperbolic Brain-Text Representations](https://arxiv.org/abs/2511.21092)
*Seunghun Baek,Jaejin Lee,Jaeyoon Sim,Minjae Jeong,Won Hwa Kim*

Main category: cs.LG

TL;DR: 将文本与脑激活图在洛伦兹超曲率空间中嵌入，实现跨层级的神经影像元分析；通过超曲率几何同时捕获语义相似性与层级结构，显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 神经影像研究常因样本量小而可重复性差；传统方法忽略脑的层级组织结构，难以统一处理文本与脑激活数据。超曲率几何能天然建模分层关系，便于跨模态的语义与脑激活对齐。

Method: 在同一超曲线空间（洛伦兹模型）中，将研究文章的文本与相应的脑图像进行嵌入与对齐；通过该嵌入实现文本-脑激活的语义对应、文本与脑激活之间的层级引导，以及对脑激活模式内部层级关系的保持，完成多层次神经影像元分析（MNM）。

Result: 实验表明该方法在与多项基线的对比中表现更优，具备更好的鲁棒性与可解释性。

Conclusion: 提出的超曲线脑-文本表示框架为多层次神经影像元分析提供新范式，能够同时捕获语义和层级信息，提升分析的解释性与可靠性。

Abstract: Various neuroimaging studies suffer from small sample size problem which often limit their reliability. Meta-analysis addresses this challenge by aggregating findings from different studies to identify consistent patterns of brain activity. However, traditional approaches based on keyword retrieval or linear mappings often overlook the rich hierarchical structure in the brain. In this work, we propose a novel framework that leverages hyperbolic geometry to bridge the gap between neuroscience literature and brain activation maps. By embedding text from research articles and corresponding brain images into a shared hyperbolic space via the Lorentz model, our method captures both semantic similarity and hierarchical organization inherent in neuroimaging data. In the hyperbolic space, our method performs multi-level neuroimaging meta-analysis (MNM) by 1) aligning brain and text embeddings for semantic correspondence, 2) guiding hierarchy between text and brain activations, and 3) preserving the hierarchical relationships within brain activation patterns. Experimental results demonstrate that our model outperforms baselines, offering a robust and interpretable paradigm of multi-level neuroimaging meta-analysis via hyperbolic brain-text representation.

</details>


### [59] [Generative Early Stage Ranking](https://arxiv.org/abs/2511.21095)
*Juhee Hong,Meng Liu,Shengzhi Wang,Xiaoheng Mao,Huihui Cheng,Leon Gao,Christopher Leung,Jin Zhou,Chandra Mouli Sekar,Zhao Zhu,Ruochen Liu,Tuan Trieu,Dawei Sun,Jeet Kanjani,Rui Li,Jing Qian,Xuan Cao,Minjie Fan,Mingze Gao*

Main category: cs.LG

TL;DR: 提出一种在ESR阶段引入混合注意力的G在 Generative Early Stage Ranking (GESR) 框架，通过 Mixture of Attention (MoA) 将多种注意力机制结合（硬匹配注意力 HMA、目标感知自注意力、跨注意力），并在最终层通过多对数门控 MLPG 融合新嵌入，提升效果与效率，同时引入高性能硬件内核与缓存等优化，实现在线/离线实验的 topline 指标提升，是在 ESR 规模部署目标感知序列建模的首次尝试。


<details>
  <summary>Details</summary>
Motivation: 传统的 ESR 采用用户和物品表示分离、在最终层才合并，效率高但难以捕捉细粒度的用户-物品亲和力与跨信号；需要在保持效率的同时提升准确性，尤其是针对跨特征的早期交互。

Method: 提出 Mixture of Attention (MoA) 作为核心框架，包含以下模块：1) Hard Matching Attention (HMA)：通过计算用户与物品特征之间的原始匹配计数来显式编码跨信号；2) Target-Aware Self Attention：在给定物品的条件下生成目标感知的用户表示，使学习更具个性化；3) Cross Attention：实现更早期的用户-物品特征交互；4) 终端层的 MLPG（Multi-Logit Parameterized Gating）：利用新得到的表示通过门控整合并生成次级 logits，与主 logits 进行融合；5) 实时和离线的高效实现包括自定义内核与缓存驱动的服务部署等优化以降低延迟。

Result: 在离线和在线实验中，GESR 显著提升 topline 指标、参与度和消费任务表现，验证了方法的有效性与鲁棒性。

Conclusion: 该工作在 ESR 阶段首次规模化部署了端到端目标感知注意力序列建模，证明了混合注意力对提升 ESR 效果与效率的潜力。

Abstract: Large-scale recommendations commonly adopt a multi-stage cascading ranking system paradigm to balance effectiveness and efficiency. Early Stage Ranking (ESR) systems utilize the "user-item decoupling" approach, where independently learned user and item representations are only combined at the final layer. While efficient, this design is limited in effectiveness, as it struggles to capture fine-grained user-item affinities and cross-signals. To address these, we propose the Generative Early Stage Ranking (GESR) paradigm, introducing the Mixture of Attention (MoA) module which leverages diverse attention mechanisms to bridge the effectiveness gap: the Hard Matching Attention (HMA) module encodes explicit cross-signals by computing raw match counts between user and item features; the Target-Aware Self Attention module generates target-aware user representations conditioned on the item, enabling more personalized learning; and the Cross Attention modules facilitate early and more enriched interactions between user-item features. MoA's specialized attention encodings are further refined in the final layer through a Multi-Logit Parameterized Gating (MLPG) module, which integrates the newly learned embeddings via gating and produces secondary logits that are fused with the primary logit. To address the efficiency and latency challenges, we have introduced a comprehensive suite of optimization techniques. These span from custom kernels that maximize the capabilities of the latest hardware to efficient serving solutions powered by caching mechanisms. The proposed GESR paradigm has shown substantial improvements in topline metrics, engagement, and consumption tasks, as validated by both offline and online experiments. To the best of our knowledge, this marks the first successful deployment of full target-aware attention sequence modeling within an ESR stage at such a scale.

</details>


### [60] [From Bits to Rounds: Parallel Decoding with Exploration for Diffusion Language Models](https://arxiv.org/abs/2511.21103)
*Hengyu Fu,Baihe Huang,Virginia Adams,Charles Wang,Venkat Srinivasan,Jiantao Jiao*

Main category: cs.LG

TL;DR: Diffusion Language Models（DLMs）在解码阶段存在将高置信度 token 作为信息增量的固有信息瓶颈，导致解码进展缓慢。理论与实验表明，优先选择高置信度 token 信息量有限且效率低下。本论文给出一个比特—轮次的原则：解码轮次随总信息量线性增加、随每轮信息预算成反比。为提高解码吞吐量，提出无需额外训练的解码策略 Explore-Then-Exploit（ETE），通过跨区块解码与高不确定性 token 的定向探索来重塑条件分布，触发自信预测级联。实验验证理论界限并表明 ETE 在不降低生成质量的前提下，显著降低所需解码轮次。


<details>
  <summary>Details</summary>
Motivation: 现有的 DLM 解码策略依赖高置信度 token，导致信息增量不足且解码轮次随负对数似然的总信息量线性上涨，难以实现高效的并行解码。需要一个不依赖额外训练的解码策略来提升信息吞吐量与解码效率。

Method: 理论上推导每轮可获取信息以及总信息量与轮次之间的关系，提出位数到轮次的原则；提出 Explore-Then-Exploit（ETE）解码策略，结合跨区块解码与对高不确定性 token 的探索，以重塑条件分布并触发连续的自信预测。

Result: 理论界限得到验证，且实验结果显示相较于仅依赖置信度的基线，ETE 能显著减少所需解码轮次，同时保持生成质量。

Conclusion: ETE 提供了一个训练无关的解码策略，通过优化信息吞吐量和探索不确定性，提升 DLM 的解码效率与生成速度，并在理论与实验上得到支持。

Abstract: Diffusion Language Models (DLMs) have recently emerged as a strong alternative to autoregressive language models (LMs). DLMs offer comparable accuracy with faster inference speed via parallel decoding. However, standard DLM decoding strategies relying on high-confidence tokens encounter an inherent information-theoretic bottleneck that restricts decoding progress and ultimately slows generation. We demonstrate both theoretically and empirically that prioritizing high-confidence tokens is inherently inefficient. High-probability tokens carry negligible information and strictly relying on them limits the effective progress made in each decoding round. We prove that the number of decoding rounds must grow linearly with the sample's total information (negative log-likelihood) and inversely with the per-round information budget, establishing a bits-to-rounds principle. We also propose Explore-Then-Exploit (ETE), a training-free decoding strategy that maximizes information throughput and decoding efficiency. ETE combines cross-block decoding with targeted exploration of high-uncertainty tokens to reshape the conditional distribution and trigger cascades of confident predictions. Experiments verify our theoretical bounds and demonstrate that ETE consistently reduces the required number of decoding rounds compared to confidence-only baselines without compromising generation quality.

</details>


### [61] [BRIDGE: Building Representations In Domain Guided Program Verification](https://arxiv.org/abs/2511.21104)
*Robert Joseph George,Carson Eisenach,Udaya Ghai,Dominique Perrault-Joncas,Anima Anandkumar,Dean Foster*

Main category: cs.LG

TL;DR: BRIDGE提出通过结构化提示将验证分解为代码、规范、证明三个领域，并通过独立的推理行为来连接它们，显著提升可验证程序生成的准确性与效率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在代码生成后往往难以完成可验证性要求，尤其在交互式证明框架（如 Lean4）中，需要同时具备可执行实现、形式规格与正确性证明三者，但现有方法很少覆盖三者的全过程，存在可扩展性瓶颈。

Method: 提出一个系统化的结构化提示框架 BRIDGE，将验证分解为 Code、Specifications、Proofs 三个域，并通过显式的中间表示激发三种不同的推理行为（functional、specification-driven、proof-oriented），以保持语义结构并连接三个域。通过系统消融实验验证这一推理分解对准确性与效率的提升。

Result: 相对于直接基线和常见错误反馈方法，BRIDGE显著提升了可验证合成的性能。以 Lean4 为例，functional reasoning 将正确性在 pass@5 上提升约 1.5 倍；推理时的推理计算成本也提升了约 2 倍的效率（更少的生成与更低的采样预算）。在 Python 领域，specification-driven prompting 将通过率提升至多 17.5%。

Conclusion: 结构化领域对齐是可验证合成的有前景方向，BRIDGE 为通过专家迭代或 RLVR 进行训练奠定基础，促使模型在代码、规格与证明三域内内化这些推理策略。

Abstract: Large language models (LLMs) have achieved impressive results in code generation, yet struggle with program verification, especially in interactive proof frameworks such as Lean4. A central challenge is scalability: verified synthesis requires not just code, but also precise specifications and correctness proofs, and existing approaches rarely span all three domains. We present BRIDGE, the first systematic study of structured prompting for scalable verified program generation. BRIDGE decomposes verification into three interconnected domains: Code (executable implementations), Specifications (formal intent statements), and Proofs (constructive correctness arguments). Our key idea is to elicit distinct reasoning behaviors functional, specification-driven, and proof-oriented as intermediate representations that preserve semantic structure and connect these domains. Through systematic ablations, we show that this approach substantially improves both accuracy and efficiency beyond standard error feedback methods. For example, functional reasoning improves correctness of code in formal languages (Lean4) by nearly 1.5x (pass@5) over direct baselines. In inference-time compute, functional reasoning is also 2x more efficient, achieving higher pass rates with fewer generations and lower total sampling budgets. Similarly, we find that specification-driven prompting boosts Python coding pass rates by up to 17.5%. These findings suggest that structured domain alignment is a promising direction for advancing verified synthesis. BRIDGE establishes a foundation for training via expert iteration or RLVR, enabling models to internalize these reasoning strategies across code, specifications, and proofs.

</details>


### [62] [Interpretable Fair Clustering](https://arxiv.org/abs/2511.21109)
*Mudi Jiang,Jiahui Zhou,Xinying Liu,Zengyou He,Zhikui Chen*

Main category: cs.LG

TL;DR: 提出一个可解释且公平的聚类框架，将公平约束嵌入决策树结构，并提供无公平超参数的后剪枝变体，实验表明在公平性、性能和可解释性方面具有竞争力，且能处理多敏感属性。


<details>
  <summary>Details</summary>
Motivation: 在高风险场景中，现有公平聚类往往缺乏可解释性，难以理解聚类决策背后的公平与否原因，因此需要兼具可解释性与公平性的聚类方法。

Method: 通过将公平约束嵌入决策树的结构，构造可解释的聚类树；并提出一种无需公平超参数的变体，通过对不包含公平约束的树进行后剪枝实现公平化。

Result: 在真实数据和合成数据集上，方法在聚类性能与公平性方面具竞争力，且具有良好可解释性，能处理多敏感属性，适应复杂公平约束。

Conclusion: 该框架将公平性与可解释性结合，为公平透明的聚类提供新的路径，扩展了在多敏感属性场景中的应用潜力。

Abstract: Fair clustering has gained increasing attention in recent years, especially in applications involving socially sensitive attributes. However, existing fair clustering methods often lack interpretability, limiting their applicability in high-stakes scenarios where understanding the rationale behind clustering decisions is essential. In this work, we address this limitation by proposing an interpretable and fair clustering framework, which integrates fairness constraints into the structure of decision trees. Our approach constructs interpretable decision trees that partition the data while ensuring fair treatment across protected groups. To further enhance the practicality of our framework, we also introduce a variant that requires no fairness hyperparameter tuning, achieved through post-pruning a tree constructed without fairness constraints. Extensive experiments on both real-world and synthetic datasets demonstrate that our method not only delivers competitive clustering performance and improved fairness, but also offers additional advantages such as interpretability and the ability to handle multiple sensitive attributes. These strengths enable our method to perform robustly under complex fairness constraints, opening new possibilities for equitable and transparent clustering.

</details>


### [63] [Trustless Federated Learning at Edge-Scale: A Compositional Architecture for Decentralized, Verifiable, and Incentive-Aligned Coordination](https://arxiv.org/abs/2511.21118)
*Pius Onobhayedo,Paul Osemudiame Oamen*

Main category: cs.LG

TL;DR: 提出通过密码学凭证、几何新颖性度量、并行对象所有权和时间锁策略等机制，解决联邦学习中的可扩展性、激励、治理等痛点，构建可审计、无原始数据泄露的分布式AI框架。


<details>
  <summary>Details</summary>
Motivation: 将AI计算从中心化提供者向分布式边缘设备转移，利用分布式数据提升模型，同时保护隐私与数据所有权，追求可扩展且可治理的民主化AI。

Method: 提出四个机制：1) 使用密码学凭证证明聚合正确性；2) 使用几何新颖性度量防止激励操纵；3) 通过并行对象所有权实现线性可扩展性；4) 采用时间锁策略防止事后操控。

Result: 给出一个理论框架与架构蓝图，逐一给出各机制的安全性、可扩展性及治理特性，提供形式化的正确性与性能讨论，但尚缺乏实证评估。

Conclusion: 该工作将分布式、隐私保护的联邦学习拉近现实，通过整合密码学、激励设计与治理机制来填补现有的组成漏洞，指明进一步验证与实现路径。

Abstract: Artificial intelligence is retracing the Internet's path from centralized provision to distributed creation. Initially, resource-intensive computation concentrates within institutions capable of training and serving large models.Eventually, as federated learning matures, billions of edge devices holding sensitive data will be able to collectively improve models without surrendering raw information, enabling both contribution and consumption at scale. This democratic vision remains unrealized due to certain compositional gaps; aggregators handle updates without accountability, economic mechanisms are lacking and even when present remain vulnerable to gaming, coordination serializes state modifications limiting scalability, and governance permits retroactive manipulation. This work addresses these gaps by leveraging cryptographic receipts to prove aggregation correctness, geometric novelty measurement to prevent incentive gaming, parallel object ownership to achieve linear scalability, and time-locked policies to check retroactive manipulation.

</details>


### [64] [Learning Cell-Aware Hierarchical Multi-Modal Representations for Robust Molecular Modeling](https://arxiv.org/abs/2511.21120)
*Mengran Li,Zelin Zang,Wenbin Xing,Junzhou Chen,Ronghui Zhang,Jiebo Luo,Stan Z. Li*

Main category: cs.LG

TL;DR: CHMR 提出一个面向细胞的层级多模态表示框架，将分子与细胞反应进行局部-全局建模，并通过树结构向量量化捕捉潜在生物层级，在九个公开基准的分类与回归任务上实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法多关注化学结构，忽略细胞表型与基因表达等响应信息；并且存在模态不完整性和未充分建模分子-细胞-基因层级依赖的问题。

Method: 提出 CHMR，通过联合建模分子与细胞响应的局部与全局依赖，同时引入树结构向量量化模块来捕捉隐含的生物层级，实现多模态层级表示学习。

Result: 在九个公开基准、共728个任务上评估，CHMR 相比基线在分类任务平均提升 3.6%，在回归任务平均提升 17.2%。

Conclusion: 实验结果表明层级感知的多模态学习能够获得更生物学合理的分子表征，CHMR提供一个可泛化的生物医学整合建模框架。

Abstract: Understanding how chemical perturbations propagate through biological systems is essential for robust molecular property prediction. While most existing methods focus on chemical structures alone, recent advances highlight the crucial role of cellular responses such as morphology and gene expression in shaping drug effects. However, current cell-aware approaches face two key limitations: (1) modality incompleteness in external biological data, and (2) insufficient modeling of hierarchical dependencies across molecular, cellular, and genomic levels. We propose CHMR (Cell-aware Hierarchical Multi-modal Representations), a robust framework that jointly models local-global dependencies between molecules and cellular responses and captures latent biological hierarchies via a novel tree-structured vector quantization module. Evaluated on nine public benchmarks spanning 728 tasks, CHMR outperforms state-of-the-art baselines, yielding average improvements of 3.6% on classification and 17.2% on regression tasks. These results demonstrate the advantage of hierarchy-aware, multimodal learning for reliable and biologically grounded molecular representations, offering a generalizable framework for integrative biomedical modeling. The code is in https://github.com/limengran98/CHMR.

</details>


### [65] [How to Correctly Report LLM-as-a-Judge Evaluations](https://arxiv.org/abs/2511.21140)
*Chungpa Lee,Thomas Zeng,Jongwon Jeong,Jy-yong Sohn,Kangwook Lee*

Main category: cs.LG

TL;DR: 提出一个插入式（plug-in）框架，用以校正LLM评估中的偏差并基于测试集与校准集的不确定性构造置信区间，同时通过自适应方法分配校准样本量以降低方差。


<details>
  <summary>Details</summary>
Motivation: LLMs作为评估者可扩展，但由于特异性和敏感性不稳定，导致评估结果偏倚且置信区间不可靠；现有偏差校正多假设知道模型的特异性/敏感性，实际只得估计值，需要在仅有估计值的情况下构造含不确定性的置信区间。

Method: 提出一个简单的plug-in框架，使用测试数据和校准数据的观察结果来估计和校正模型的偏差，构造反映来自测试集和校准集的不确定性的置信区间；并提出自适应算法，在给定预算下高效分配校准样本量以降低估计方差。

Result: 框架实现后，得到更无偏的准确率估计并提供更可靠的置信区间，且自适应分配方法在节省样本的同时提高估计效率。

Conclusion: 该工作使LLM-based评估更实用且统计学意义更强，因为它同时处理来自测试与校准数据的不确定性并优化样本分配。

Abstract: Large language models (LLMs) are increasingly used as evaluators in lieu of humans. While scalable, their judgments are noisy due to imperfect specificity and sensitivity of LLMs, leading to biased accuracy estimates. Although bias-correction methods exist, they are underutilized in LLM research and typically assume exact knowledge of the model's specificity and sensitivity. Furthermore, in general we only have estimates of these values and it is not well known how to properly construct confidence intervals using only estimates. This work presents a simple plug-in framework that corrects such bias and constructs confidence intervals reflecting uncertainty from both test and calibration dataset, enabling practical and statistically sound LLM-based evaluation. Additionally, to reduce uncertainty in the accuracy estimate, we introduce an adaptive algorithm that efficiently allocates calibration sample sizes.

</details>


### [66] [I-GLIDE: Input Groups for Latent Health Indicators in Degradation Estimation](https://arxiv.org/abs/2511.21208)
*Lucas Thil,Jesse Read,Rim Kaddah,Guillaume Doquet*

Main category: cs.LG

TL;DR: 将 RaPP 作为健康指标用于剩余使用寿命（RUL）预测，结合不确定性评估与指示器组（I-GLIDE）实现可解释、机制特异的诊断，在航空与制造数据上显著提升准确性与泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多传感系统中难以分离复杂的退化机制且难以量化健康指标的可靠性不确定性，亟需一个鲁棒且具解释性的 HI 构建框架来提升 RUL 预测及故障路径洞察。

Method: 1) 将 Reconstruction along Projected Pathways (RaPP) 作为 RUL 预测的健康指标；2) 使用蒙特卡洛 dropout 与概率潜变量空间对 RaPP 产生的 HI 进行 aleatoric 与 epistemic 不确定性量化；3) 提出 indicator groups， isolating 不同传感子集以建模系统特定的退化，进而提出 I-GLIDE 的可解释、机制特异诊断。

Result: 在航空航天与制造领域的数据上，相较于最先进的 HI 方法，提升了准确性与泛化性，并给出系统故障路径的可操作洞察，提出了从异常检测到预测性维护的统一框架。

Conclusion: 本文提供一个不确定性感知的复杂系统降解建模框架，弥合异常检测与 prognostics 的差距，提升对多传感系统的机制级诊断能力。

Abstract: Accurate remaining useful life (RUL) prediction hinges on the quality of health indicators (HIs), yet existing methods often fail to disentangle complex degradation mechanisms in multi-sensor systems or quantify uncertainty in HI reliability. This paper introduces a novel framework for HI construction, advancing three key contributions. First, we adapt Reconstruction along Projected Pathways (RaPP) as a health indicator (HI) for RUL prediction for the first time, showing that it outperforms traditional reconstruction error metrics. Second, we show that augmenting RaPP-derived HIs with aleatoric and epistemic uncertainty quantification (UQ) via Monte Carlo dropout and probabilistic latent spaces- significantly improves RUL-prediction robustness. Third, and most critically, we propose indicator groups, a paradigm that isolates sensor subsets to model system-specific degradations, giving rise to our novel method, I-GLIDE which enables interpretable, mechanism-specific diagnostics. Evaluated on data sourced from aerospace and manufacturing systems, our approach achieves marked improvements in accuracy and generalizability compared to state-of-the-art HI methods while providing actionable insights into system failure pathways. This work bridges the gap between anomaly detection and prognostics, offering a principled framework for uncertainty-aware degradation modeling in complex systems.

</details>


### [67] [Robust Gene Prioritization via Fast-mRMR Feature Selection in high-dimensional omics data](https://arxiv.org/abs/2511.21211)
*Rubén Fernández-Farelo,Jorge Paz-Ruza,Bertha Guijarro-Berdiñas,Amparo Alonso-Betanzos,Alex A. Freitas*

Main category: cs.LG

TL;DR: 利用 Fast-mRMR 的特征选择来处理高维、标注不足的生物数据，从而构建更简化、有效的基因优先排序分类模型，并能整合多源特征集。


<details>
  <summary>Details</summary>
Motivation: Biological数据通常高维且标注稀缺，现有方法易受冗余特征和缺失标签的影响，亟需更鲁棒的特征选择来提升基因优先排序的稳定性与性能。

Method: 提出一个鲁棒高效的工作流，将 Fast-mRMR 特征选择应用于基因优先排序任务，仅保留相关且非冗余的特征以供分类器使用，并支持整合不同生物特征集以提升模型表现。

Result: 在饮食限制（Dietary Restriction）数据集上，所提方法显著优于现有方法，表明特征选择对实现可靠的基因优先排序具有关键作用。

Conclusion: 特征选择是实现简化、可解释且更可靠的基因优先排序的关键步骤，所提出的管线还能有效融合多源生物特征以提升泛化能力。

Abstract: Gene prioritization (identifying genes potentially associated with a biological process) is increasingly tackled with Artificial Intelligence. However, existing methods struggle with the high dimensionality and incomplete labelling of biomedical data. This work proposes a more robust and efficient pipeline that leverages Fast-mRMR feature selection to retain only relevant, non-redundant features for classifiers. This enables us to build simpler and more effective models, as well as to combine different biological feature sets. Experiments on Dietary Restriction datasets show significant improvements over existing methods, proving that feature selection can be critical for reliable gene prioritization.

</details>


### [68] [A Physics-Informed U-net-LSTM Network for Data-Driven Seismic Response Modeling of Structures](https://arxiv.org/abs/2511.21276)
*Sutirtha Biswas,Kshitij Kumar Yadav*

Main category: cs.LG

TL;DR: 提出了一种物理信息约束的 U-Net-LSTM 混合框架，用于地震响应预测，显著在精度与计算效率之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: FEM 虽然准确但计算成本高，纯数据驱动模型在物理一致性与泛化能力方面存在局限，需要一种将物理规律融入深度学习的混合方法。

Method: 将物理约束嵌入到 U-Net 与 LSTM 的联合框架中，通过物理信息耦合的损失、硬约束或正则化，实现对结构非线性地震响应的预测，训练数据可能来自数值仿真并辅以物理损失。

Result: 相较于传统机器学习模型，所提出的方法在预测精度与泛化性方面有所提高，同时保持比纯数值 FEM 更低的计算成本，具备潜在的实时应用能力。

Conclusion: 物理信息驱动的 U-Net-LSTM 框架填补了数据驱动与基于物理建模之间的空白，提供了一个鲁棒、高效的地震响应预测方案，未来可扩展到更复杂的非线性行为与不确定性分析。

Abstract: Accurate and efficient seismic response prediction is essential for the design of resilient structures. While the Finite Element Method (FEM) remains the standard for nonlinear seismic analysis, its high computational demands limit its scalability and real time applicability. Recent developments in deep learning, particularly Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Long Short Term Memory (LSTM) models, have shown promise in reducing the computational cost of nonlinear seismic analysis of structures. However, these data driven models often struggle to generalize and capture the underlying physics, leading to reduced reliability. We propose a novel Physics Informed U Net LSTM framework that integrates physical laws with deep learning to enhance both accuracy and efficiency. By embedding domain specific constraints into the learning process, the proposed model achieves improved predictive performance over conventional Machine Learning architectures. This hybrid approach bridges the gap between purely data driven methods and physics based modeling, offering a robust and computationally efficient alternative for seismic response prediction of structures.

</details>


### [69] [Sawtooth Sampling for Time Series Denoising Diffusion Implicit Models](https://arxiv.org/abs/2511.21320)
*Heiko Oppel,Andreas Spilz,Michael Munz*

Main category: cs.LG

TL;DR: 结合隐式扩散模型与锯齿采样器以加速 DDPM 的逆扩散过程，同时提升生成序列的分类性能，达到约 30 倍提速并提升质量。


<details>
  <summary>Details</summary>
Motivation: DDPM 的采样过程计算成本高，迫切需要更快、维持或提升生成质量的采样方法以用于提升分类器性能。

Method: 将隐式扩散模型与新颖的 Sawtooth Sampler 结合，可应用于任何预训练扩散模型，快速近似逆过程。

Result: 实现相较标准基线约 30×的加速，同时提高生成序列在分类任务中的质量。

Conclusion: 该方法为扩散模型的高效应用提供了实用的加速器，帮助在分类场景中更有效地利用合成数据。

Abstract: Denoising Diffusion Probabilistic Models (DDPMs) can generate synthetic timeseries data to help improve the performance of a classifier, but their sampling process is computationally expensive. We address this by combining implicit diffusion models with a novel Sawtooth Sampler that accelerates the reverse process and can be applied to any pretrained diffusion model. Our approach achieves a 30 times speed-up over the standard baseline while also enhancing the quality of the generated sequences for classification tasks.

</details>


### [70] [Masks Can Be Distracting: On Context Comprehension in Diffusion Language Models](https://arxiv.org/abs/2511.21338)
*Julianna Piskorz,Cristina Pinneri,Alvaro Correia,Motasem Alfarra,Risheek Garrepalli,Christos Louizos*

Main category: cs.LG

TL;DR: MDLMs show strong locality bias and mask-induced distractor effects that harm context understanding; a mask-agnostic loss with fine-tuning considerably improves robustness.


<details>
  <summary>Details</summary>
Motivation: To systematically evaluate the context comprehension of MDLMs and identify fundamental limitations in their ability to utilize distant information, as well as the adverse impact of appended mask tokens during generation.

Method: Perform ablation studies varying the position of relevant information, test generation with many appended masks, and introduce a mask-agnostic loss; fine-tune MDLMs with this objective to assess robustness.

Result: Mask-agnostic fine-tuning reduces the disruptive effect of masks and enhances context comprehension, yielding more robust MDLM performance.

Conclusion: Current MDLM training paradigms have critical limitations; incorporating mask-insensitive objectives is a practical way to strengthen diffusion-based language models' context understanding.

Abstract: Masked Diffusion Language Models (MDLMs) have recently emerged as a promising alternative to Autoregressive Language Models (ARLMs), leveraging a denoising objective that, in principle, should enable more uniform context utilisation. In this work, we examine the context comprehension abilities of MDLMs and uncover two key limitations. First, despite their more global training objective and bidirectional attention mechanism, similarly to ARLMS, MDLMs exhibit a strong locality bias: performance is highly sensitive to the position of relevant information within the input, favouring local over distant context. Second, we show that appending a large number of mask tokens--required for generation--can significantly degrade context comprehension. Through systematic ablations, we find that these masks act as distractors, reducing the model's ability to process relevant information. To address this, we introduce a mask-agnostic loss function that encourages predictions to remain invariant to the number of appended masks. Fine-tuning with this objective substantially mitigates the distracting effect of masks, improving robustness of MDLMs. Overall, our findings reveal critical limitations of the current MDLM training paradigm and provide actionable insights for building diffusion-based language models with stronger context comprehension.

</details>


### [71] [Best Practices for Machine Learning Experimentation in Scientific Applications](https://arxiv.org/abs/2511.21354)
*Umberto Michelucci,Francesca Venturini*

Main category: cs.LG

TL;DR: 提供一个面向科学应用的实用ML实验指南，强调可重复性、公平比较与透明报告；提出LOR和COS等新度量，用以评估跨验证折的过拟合与不稳定性。


<details>
  <summary>Details</summary>
Motivation: 为解决科学研究中ML结果的质量与可靠性问题（如基线薄弱、预处理不一致、验证不足等），通过结构化工作流和新评估指标提升证据的可信度。

Method: 提出从数据集准备到模型选择和评估的逐步工作流，结合可重复的基线、实验记录、以及对过拟合/不稳定性进行衡量的新度量（LOR、COS），并提供示例报告格式和实践建议。

Result: 给出一个可操作的研究框架与指标集合，帮助研究者建立稳健基线并产生可再现且可比较的结论；未给出具体实验结果，而是提供指南与格式。

Conclusion: 若采用该指南，可以提升科学ML研究的可重复性、公平性和透明度，增强对模型在科学问题上的证据性结论。

Abstract: Machine learning (ML) is increasingly adopted in scientific research, yet the quality and reliability of results often depend on how experiments are designed and documented. Poor baselines, inconsistent preprocessing, or insufficient validation can lead to misleading conclusions about model performance. This paper presents a practical and structured guide for conducting ML experiments in scientific applications, focussing on reproducibility, fair comparison, and transparent reporting. We outline a step-by-step workflow, from dataset preparation to model selection and evaluation, and propose metrics that account for overfitting and instability across validation folds, including the Logarithmic Overfitting Ratio (LOR) and the Composite Overfitting Score (COS). Through recommended practices and example reporting formats, this work aims to support researchers in establishing robust baselines and drawing valid evidence-based insights from ML models applied to scientific problems.

</details>


### [72] [Hybrid-AIRL: Enhancing Inverse Reinforcement Learning with Supervised Expert Guidance](https://arxiv.org/abs/2511.21356)
*Bram Silue,Santiago Amaya-Corredor,Patrick Mannion,Lander Willem,Pieter Libin*

Main category: cs.LG

TL;DR: 提出了一种混合逆强化学习框架H-AIRL，通过加入来自专家数据的监督损失与随机正则化，提升在稀疏奖励和复杂不完备信息环境中的奖励推断与策略学习；在Gymnasium基准和HULHE扑克上优于原始AIRL。


<details>
  <summary>Details</summary>
Motivation: 解决AIRL在高度复杂、不完美信息的任务中难以学习有效奖励函数的问题，尤其在稀疏、延迟奖励场景如扑克领域。

Method: 在AIRL基础上引入监督损失和随机正则化，形成Hybrid-AIRL；对Gymnasium基准与HULHE进行评估，并通过奖励函数可视化分析学习过程。

Result: H-AIRL在样本效率和稳定性方面优于AIRL，实验结果支持将监督信号融入逆强化学习的有效性。

Conclusion: 将监督信号融入逆强化学习可提升在现实挑战性任务中的性能，H-AIRL为此类问题提供了有效框架。

Abstract: Adversarial Inverse Reinforcement Learning (AIRL) has shown promise in addressing the sparse reward problem in reinforcement learning (RL) by inferring dense reward functions from expert demonstrations. However, its performance in highly complex, imperfect-information settings remains largely unexplored. To explore this gap, we evaluate AIRL in the context of Heads-Up Limit Hold'em (HULHE) poker, a domain characterized by sparse, delayed rewards and significant uncertainty. In this setting, we find that AIRL struggles to infer a sufficiently informative reward function. To overcome this limitation, we contribute Hybrid-AIRL (H-AIRL), an extension that enhances reward inference and policy learning by incorporating a supervised loss derived from expert data and a stochastic regularization mechanism. We evaluate H-AIRL on a carefully selected set of Gymnasium benchmarks and the HULHE poker setting. Additionally, we analyze the learned reward function through visualization to gain deeper insights into the learning process. Our experimental results show that H-AIRL achieves higher sample efficiency and more stable learning compared to AIRL. This highlights the benefits of incorporating supervised signals into inverse RL and establishes H-AIRL as a promising framework for tackling challenging, real-world settings.

</details>


### [73] [The Directed Prediction Change - Efficient and Trustworthy Fidelity Assessment for Local Feature Attribution Methods](https://arxiv.org/abs/2511.21363)
*Kevin Iselborn,David Dembinsky,Adriano Lucieri,Andreas Dengel*

Main category: cs.LG

TL;DR: 提出了 Directed Prediction Change (DPC) 指标，用以评估局部特征属性方法的保真度。通过在 Guided Perturbation Experiment 中结合扰动方向和属性方向，实现大约十倍加速且判定性，避免随机性；在皮肤病变图像、金融表格数据的两类黑箱模型、七种解释算法、4,744 条解释等广泛设置下，展示 DPC 与 PC 共同提供高效、可重复的保真度评估。


<details>
  <summary>Details</summary>
Motivation: 在高风险医疗场景中，解释方法的保真度直接影响临床和监管信任。现有的保真度度量（如 Infidelity）依赖蒙特卡罗采样，需大量模型评估且引入随机性，不利于可重复、确定性的评估。需要一种与局部 Infidelity 同等测量目标、且更高效、无随机性的评估方法。

Method: 在 Guided Perturbation Experiment 的基础上，改进 Prediction Change (PC) 指标，加入扰动方向与属性方向的一致性，提出 Directed Prediction Change (DPC) 指标，使评估过程具确定性并提升速度。该方法通过方向一致性消除随机性，减少计算开销。

Result: 在两类数据集（皮肤病变图像与金融表格数据）、两种黑箱模型、七种解释算法、以及大量超参数设置下进行评估，共覆盖4,744条解释。结果显示，DPC 与 PC 结合提供对基线导向与局部特征属性方法的全面且计算高效的保真度评估，且输出具有确定性、可重复性。大约实现了十倍的加速并消除了随机性。

Conclusion: DPC 可作为局部解释保真度评估的高效、确定性替代或补充，与 PC 一同推动对解释方法的全面评估，特别是在需要高可重复性的场景中，对多算法和多超参数设置具有稳健性。

Abstract: The utility of an explanation method critically depends on its fidelity to the underlying machine learning model. Especially in high-stakes medical settings, clinicians and regulators require explanations that faithfully reflect the model's decision process. Existing fidelity metrics such as Infidelity rely on Monte Carlo approximation, which demands numerous model evaluations and introduces uncertainty due to random sampling. This work proposes a novel metric for evaluating the fidelity of local feature attribution methods by modifying the existing Prediction Change (PC) metric within the Guided Perturbation Experiment. By incorporating the direction of both perturbation and attribution, the proposed Directed Prediction Change (DPC) metric achieves an almost tenfold speedup and eliminates randomness, resulting in a deterministic and trustworthy evaluation procedure that measures the same property as local Infidelity. DPC is evaluated on two datasets (skin lesion images and financial tabular data), two black-box models, seven explanation algorithms, and a wide range of hyperparameters. Across $4\,744$ distinct explanations, the results demonstrate that DPC, together with PC, enables a holistic and computationally efficient evaluation of both baseline-oriented and local feature attribution methods, while providing deterministic and reproducible outcomes.

</details>


### [74] [Anomaly Detection with Adaptive and Aggressive Rejection for Contaminated Training Data](https://arxiv.org/abs/2511.21378)
*Jungi Lee,Jungkwon Kim,Chi Zhang,Kwangsun Yoo,Seok-Joo Byun*

Main category: cs.LG

TL;DR: AAR: 自适应强/软拒绝，基于修正z-score和高斯混合模型阈值，在污染数据下鲁棒地排除异常，平衡保留正常数据与剔除异常；在两类数据集上相比现有方法提升0.041 AUROC。


<details>
  <summary>Details</summary>
Motivation: 训练数据被污染，误差比率假设不准确，正常和异常分布在嘈杂环境中重叠，需自适应去除异常的方法。

Method: 引入 Adaptive and Aggressive Rejection，结合修正z-score与基于GMM的阈值，硬/软拒绝相结合实现动态排除异常。

Result: 在两类数据集（两张图片数据集与30个表格数据集？原文说两 image datasets and thirty tabular datasets）上，AAR相较SOTA提升0.041 AUROC。

Conclusion: AAR提供可扩展且鲁棒的解决方案，改善污染数据下的异常检测，适用于安全、医疗等实际领域。

Abstract: Handling contaminated data poses a critical challenge in anomaly detection, as traditional models assume training on purely normal data. Conventional methods mitigate contamination by relying on fixed contamination ratios, but discrepancies between assumed and actual ratios can severely degrade performance, especially in noisy environments where normal and abnormal data distributions overlap. To address these limitations, we propose Adaptive and Aggressive Rejection (AAR), a novel method that dynamically excludes anomalies using a modified z-score and Gaussian mixture model-based thresholds. AAR effectively balances the trade-off between preserving normal data and excluding anomalies by integrating hard and soft rejection strategies. Extensive experiments on two image datasets and thirty tabular datasets demonstrate that AAR outperforms the state-of-the-art method by 0.041 AUROC. By providing a scalable and reliable solution, AAR enhances robustness against contaminated datasets, paving the way for broader real-world applications in domains such as security and healthcare.

</details>


### [75] [BanglaASTE: A Novel Framework for Aspect-Sentiment-Opinion Extraction in Bangla E-commerce Reviews Using Ensemble Deep Learning](https://arxiv.org/abs/2511.21381)
*Ariful Islam,Md Rifat Hossen,Abir Ahmed,B M Taslimul Haque*

Main category: cs.LG

TL;DR:  BanglaASTE：首个 Bangla ASTE 框架，包含数据集和混合模型，达到高于基线的 Triplet 提取性能。


<details>
  <summary>Details</summary>
Motivation: 弥补 Bangla 语言下 ABSA/ASTE 的研究空白，缺乏数据集和专门的三元组提取框架，限制了 Bangla 电商情感分析的发展。

Method: 构建包含 3,345 条 Bangla 产品评价的数据集；提出基于图的方面-意见匹配及语义相似性的混合分类框架；结合 BanglaBERT 表征与 XGBoost 的集成模型来提升 triplet 提取性能。

Result: 实验结果显示，该集成方法达到 89.9% 的准确率与 89.1% 的 F1 分数，在所有评测指标上显著优于基线模型。

Conclusion: 推动低资源语言情感分析的研究前沿，为 Bangla 电商分析提供可扩展的解决方案，同时有效应对 Bangla 文本的非规范表达、拼写变体与数据稀疏等挑战。

Abstract: Aspect-Based Sentiment Analysis (ABSA) has emerged as a critical tool for extracting fine-grained sentiment insights from user-generated content, particularly in e-commerce and social media domains. However, research on Bangla ABSA remains significantly underexplored due to the absence of comprehensive datasets and specialized frameworks for triplet extraction in this language. This paper introduces BanglaASTE, a novel framework for Aspect Sentiment Triplet Extraction (ASTE) that simultaneously identifies aspect terms, opinion expressions, and sentiment polarities from Bangla product reviews. Our contributions include: (1) creation of the first annotated Bangla ASTE dataset containing 3,345 product reviews collected from major e-commerce platforms including Daraz, Facebook, and Rokomari; (2) development of a hybrid classification framework that employs graph-based aspect-opinion matching with semantic similarity techniques; and (3) implementation of an ensemble model combining BanglaBERT contextual embeddings with XGBoost boosting algorithms for enhanced triplet extraction performance. Experimental results demonstrate that our ensemble approach achieves superior performance with 89.9% accuracy and 89.1% F1-score, significantly outperforming baseline models across all evaluation metrics. The framework effectively addresses key challenges in Bangla text processing including informal expressions, spelling variations, and data sparsity. This research advances the state-of-the-art in low-resource language sentiment analysis and provides a scalable solution for Bangla e-commerce analytics applications.

</details>


### [76] [Ensemble Performance Through the Lens of Linear Independence of Classifier Votes in Data Streams](https://arxiv.org/abs/2511.21465)
*Enes Bektas,Fazli Can*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Ensemble learning improves classification performance by combining multiple base classifiers. While increasing the number of classifiers generally enhances accuracy, excessively large ensembles can lead to computational inefficiency and diminishing returns. This paper investigates the relationship between ensemble size and performance through the lens of linear independence among classifier votes in data streams. We propose that ensembles composed of linearly independent classifiers maximize representational capacity, particularly under a geometric model. We then generalize the importance of linear independence to the weighted majority voting problem. By modeling the probability of achieving linear independence among classifier outputs, we derive a theoretical framework that explains the trade-off between ensemble size and accuracy. Our analysis leads to a theoretical estimate of the ensemble size required to achieve a user-specified probability of linear independence. We validate our theory through experiments on both real-world and synthetic datasets using two ensemble methods, OzaBagging and GOOWE. Our results confirm that this theoretical estimate effectively identifies the point of performance saturation for robust ensembles like OzaBagging. Conversely, for complex weighting schemes like GOOWE, our framework reveals that high theoretical diversity can trigger algorithmic instability. Our implementation is publicly available to support reproducibility and future research.

</details>


### [77] [Mean-Field Limits for Two-Layer Neural Networks Trained with Consensus-Based Optimization](https://arxiv.org/abs/2511.21466)
*William De Deyn,Michael Herty,Giovanni Samaey*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study two-layer neural networks and train these with a particle-based method called consensus-based optimization (CBO). We compare the performance of CBO against Adam on two test cases and demonstrate how a hybrid approach, combining CBO with Adam, provides faster convergence than CBO. In the context of multi-task learning, we recast CBO into a formulation that offers less memory overhead. The CBO method allows for a mean-field limit formulation, which we couple with the mean-field limit of the neural network. To this end, we first reformulate CBO within the optimal transport framework. Finally, in the limit of infinitely many particles, we define the corresponding dynamics on the Wasserstein-over-Wasserstein space and show that the variance decreases monotonically.

</details>


### [78] [IntAttention: A Fully Integer Attention Pipeline for Efficient Edge Inference](https://arxiv.org/abs/2511.21513)
*Wanli Zhong,Haibo Feng,Zirui Zhou,Hanyang Peng,Shiqi Yu*

Main category: cs.LG

TL;DR: 提出IntAttention：第一款完全面整数量化的注意力管线，解决INT8注意力中softmax的瓶颈，利用IndexSoftmax等在整数域内替代指数运算，达到显著加速与能耗下降且无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署Transformer时，延迟和能耗成为瓶颈。尽管INT8能加速主矩阵乘法，但softmax阶段引入去量化-软化/再量化的开销，且会破坏端到端整数数据流的效率，因此需要在整数域内实现全流程注意力，以降低数据转换成本并提升硬件友好性。

Method: 提出IntAttention，这是一种完全整数、即插即用的注意力流水线，无需重新训练。核心是IndexSoftmax这一硬件友好算子，完全在整数域内替代浮点指数运算；并结合稀疏性裁剪、32条查找表近似和直接整数归一化，以消除所有数据类型转换开销。

Result: 在与FP16基线的对比中，IntAttention实现最高3.7x加速、61%能耗下降；相较传统INT8注意力管线，在Armv8 CPU上速度提升约2倍；在多领域语言与视觉模型上保持高保真度。

Conclusion: IntAttention使在普通边缘设备上实现高效、无再训练需求的Transformer推理成为可能，完全消除了softmax中的浮点运算及去/Requantize的成本，未来版本将发布代码。

Abstract: Deploying Transformer models on edge devices is limited by latency and energy budgets. While INT8 quantization effectively accelerates the primary matrix multiplications, it exposes the softmax as the dominant bottleneck. This stage incurs a costly dequantize-softmax-requantize detour, which can account for up to 65% of total attention latency and disrupts the end-to-end integer dataflow critical for edge hardware efficiency. To address this limitation, we present IntAttention, the first fully integer, plug-and-play attention pipeline without retraining. At the core of our approach lies IndexSoftmax, a hardware-friendly operator that replaces floating-point exponentials entirely within the integer domain. IntAttention integrates sparsity-aware clipping, a 32-entry lookup-table approximation, and direct integer normalization, thereby eliminating all datatype conversion overhead. We evaluate IntAttention and demonstrate consistent and substantial gains. Our method achieves up to 3.7x speedup and 61% energy reduction over FP16 baselines and 2.0x faster than conventional INT8 attention pipelines on Armv8 CPUs. These gains are achieved with high-fidelity accuracy comparable to baselines across diverse language and vision models, enabling practical and efficient Transformer inference on commodity edge devices. Code will be released in later version of this work.

</details>


### [79] [Mechanistic Interpretability for Transformer-based Time Series Classification](https://arxiv.org/abs/2511.21514)
*Matīss Kalnāre,Sofoklis Kitharidis,Thomas Bäck,Niki van Stein*

Main category: cs.LG

TL;DR: 将 NLP 中的机制可解释性技术迁移到专为时间序列设计的变换器，并揭示内部因果结构与可解释的潜在特征。


<details>
  <summary>Details</summary>
Motivation: 尽管变换器在时间序列分类上取得了高性能，但其内部决策过程缺乏清晰理解，现有解释多聚焦输入-输出属性，忽略模型内部机制。

Method: 将激活补丁、注意力显著性以及稀疏自编码器等机制解释技术应用于时间序列 Transformer；系统性地探查单个注意头和时间步的因果作用，构建内部信息传播的因果图，并展示稀疏自编码器用于发现可解释的潜在特征。

Result: 在基准时间序列数据集上揭示影响正确分类的关键注意头与时间位置，形成可解释的因果图；稀疏自编码器能够提取可解释的潜在特征，显示方法学上的可行性。

Conclusion: 本研究在 Transformer 可解释性方面提供新方法学贡献，并为时间序列分类任务中的变换器工作机制提供深入洞察。

Abstract: Transformer-based models have become state-of-the-art tools in various machine learning tasks, including time series classification, yet their complexity makes understanding their internal decision-making challenging. Existing explainability methods often focus on input-output attributions, leaving the internal mechanisms largely opaque. This paper addresses this gap by adapting various Mechanistic Interpretability techniques; activation patching, attention saliency, and sparse autoencoders, from NLP to transformer architectures designed explicitly for time series classification. We systematically probe the internal causal roles of individual attention heads and timesteps, revealing causal structures within these models. Through experimentation on a benchmark time series dataset, we construct causal graphs illustrating how information propagates internally, highlighting key attention heads and temporal positions driving correct classifications. Additionally, we demonstrate the potential of sparse autoencoders for uncovering interpretable latent features. Our findings provide both methodological contributions to transformer interpretability and novel insights into the functional mechanics underlying transformer performance in time series classification tasks.

</details>


### [80] [Context-Specific Causal Graph Discovery with Unobserved Contexts: Non-Stationarity, Regimes and Spatio-Temporal Patterns](https://arxiv.org/abs/2511.21537)
*Martin Rabel,Jakob Runge*

Main category: cs.LG

TL;DR: 提出一个模块化框架，通过修改独立性检验层面的约束基因因果发现，处理跨时空非平稳性对因果图推断的影响，并能无缝对接现有方法（如PC、FCI、PCMCI等）。


<details>
  <summary>Details</summary>
Motivation: 现实世界的时空数据往往违背平稳性和空间平移不变性，而这些变化既包含重要信息，也可能削弱传统因果发现方法的稳定性和可靠性。研究聚焦于对因果图变化的信息进行分析与稳健性提升。

Method: 在独立性检验层面修改约束基因发现框架，形成高度模块化的框架，能够与现有的IID和时序因果发现算法（如PC、PC-stable、FCI、PCMCI、PCMCI+、LPCMCI）无缝对接，並引入与变点检测、聚类、独立性检验等相关的子问题解决思路。

Result: 框架具有极高的模块性、可扩展性和广泛适用性，能够系统地理解并改进一系列子问题；便于结合变点检测、聚类等方法提升非平稳场景下的因果发现效果；还为超参数与统计解释提供清晰的框架。

Conclusion: 该工作为在非平稳时空数据背景下的因果发现提供了一个可扩展的研究路线图，厘清了基本限制与 trade-off 的统计含义，未来将以开源实现进一步落地。

Abstract: Real-world data, for example in climate applications, often consists of spatially gridded time series data or data with comparable structure. While the underlying system is often believed to behave similar at different points in space and time, those variations that do exist are twofold relevant: They often encode important information in and of themselves. And they may negatively affect the stability / convergence and reliability\Slash{}validity of results of algorithms assuming stationarity or space-translation invariance. We study the information encoded in changes of the causal graph, with stability in mind. An analysis of this general task identifies two core challenges. We develop guiding principles to overcome these challenges, and provide a framework realizing these principles by modifying constraint-based causal discovery approaches on the level of independence testing. This leads to an extremely modular, easily extensible and widely applicable framework. It can leverage existing constraint-based causal discovery methods (demonstrated on IID-algorithms PC, PC-stable, FCI and time series algorithms PCMCI, PCMCI+, LPCMCI) with little to no modification. The built-in modularity allows to systematically understand and improve upon an entire array of subproblems. By design, it can be extended by leveraging insights from change-point-detection, clustering, independence-testing and other well-studied related problems. The division into more accessible sub-problems also simplifies the understanding of fundamental limitations, hyperparameters controlling trade-offs and the statistical interpretation of results. An open-source implementation will be available soon.

</details>


### [81] [A decoupled alignment kernel for peptide membrane permeability predictions](https://arxiv.org/abs/2511.21566)
*Ali Amirahmadi,Gökçe Geylan,Leonardo De Maria,Farzaneh Etminani,Mattias Ohlsson,Alessandro Tibo*

Main category: cs.LG

TL;DR: 提出了基于单体感知的全局比对核 MD-GAK 及其带三角位置先验的 PMD-GAK，用于循环肽的性质预测，强调不依赖复杂深度学习、而是结合化学相似性与序列对齐的简单核方法，并在高斯过程框架中实现不确定性估计，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 循环肽要穿透细胞膜、数据有限且需要可校准的不确定性；希望在不依赖大规模数据的前提下获得可靠预测并提供不确定性估计。

Method: 提出 MD-GAK，耦合残基-残基相似性与序列对齐，同时解耦局部匹配与缺口惩罚；另有带三角位置先验的 PMD-GAK；在高斯过程框架中应用这两个核。

Result: 在大量实验中，与最先进模型相比，所提方法在所有指标上均表现优于对比方法；PMD-GAK 在校准误差方面具有额外优势。

Conclusion: 简单但具化学意义的核方法可在有限数据场景下实现出色的预测与不确定性估计，MD-GAK 与 PMD-GAK 为循环肽性质预测提供有效工具。

Abstract: Cyclic peptides are promising modalities for targeting intracellular sites; however, cell-membrane permeability remains a key bottleneck, exacerbated by limited public data and the need for well-calibrated uncertainty. Instead of relying on data-eager complex deep learning architecture, we propose a monomer-aware decoupled global alignment kernel (MD-GAK), which couples chemically meaningful residue-residue similarity with sequence alignment while decoupling local matches from gap penalties. MD-GAK is a relatively simple kernel. To further demonstrate the robustness of our framework, we also introduce a variant, PMD-GAK, which incorporates a triangular positional prior. As we will show in the experimental section, PMD-GAK can offer additional advantages over MD-GAK, particularly in reducing calibration errors. Since our focus is on uncertainty estimation, we use Gaussian Processes as the predictive model, as both MD-GAK and PMD-GAK can be directly applied within this framework. We demonstrate the effectiveness of our methods through an extensive set of experiments, comparing our fully reproducible approach against state-of-the-art models, and show that it outperforms them across all metrics.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [82] [Supporting Students in Navigating LLM-Generated Insecure Code](https://arxiv.org/abs/2511.20878)
*Jaehwan Park,Kyungchan Lim,Seonhye Park,Doowon Kim*

Main category: cs.CR

TL;DR: 提出 Bifröst 框架，通过对抗性 LLM、VS Code 扩展与漏洞反馈培养 AI 辅助开发中的安全意识，初步证据显示提升对 LLM 输出的怀疑性并暴露学生对不安全代码的易感性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在软件开发中的广泛应用，开发者可以用自然语言描述任务并获得代码，但这也带来新的安全风险；现有教育往往强调效率而忽视安全培训，导致学生缺乏识别与缓解 AI 参与工作流中安全问题的能力。

Method: 提出 Bifröst 教育框架，包三部分：1) Visual Studio Code 扩展，用以模拟现实开发环境；2) 对抗性配置的 LLMs，生成不安全代码以暴露安全缺陷；3) 一个漏洞反馈系统，突出并引导分析这些安全问题。通过让学生在受控情境中处理受不安全 LLM 影响的代码并进行安全分析来培养批判性评估能力。

Result: 课堂部署样本量为 61，揭示学生对不安全代码的易感性；干预后的调查样本量为 21，显示学生对 LLM 输出的怀疑性增强，表明安全分析能力有初步提升的迹象。

Conclusion: 该框架为 AI 辅助开发的安全教育提供了一个有前景的路径，通过沉浸式任务与针对性反馈提升学生的安全审查能力；但需要在更大样本、不同场景中进行长期效果验证与扩展。

Abstract: The advent of Artificial Intelligence (AI), particularly large language models (LLMs), has revolutionized software development by enabling developers to specify tasks in natural language and receive corresponding code, boosting productivity. However, this shift also introduces security risks, as LLMs may generate insecure code that can be exploited by adversaries. Current educational approaches emphasize efficiency while overlooking these risks, leaving students underprepared to identify and mitigate security issues in AI-assisted workflows.
  To address this gap, we present Bifröst, an educational framework that cultivates security awareness in AI-augmented development. Bifröst integrates (1) a Visual Studio Code extension simulating realistic environments, (2) adversarially configured LLMs that generate insecure code, and (3) a feedback system highlighting vulnerabilities. By immersing students in tasks with compromised LLMs and providing targeted security analysis, Bifröst cultivates critical evaluation skills; classroom deployments (n=61) show vulnerability to insecure code, while a post-intervention survey (n=21) indicates increased skepticism toward LLM outputs.

</details>


### [83] [A Taxonomy of Pix Fraud in Brazil: Attack Methodologies, AI-Driven Amplification, and Defensive Strategies](https://arxiv.org/abs/2511.20902)
*Glener Lanes Pizzolato,Brenda Medeiros Lopes,Claudio Schepke,Diego Kreutz*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work presents a review of attack methodologies targeting Pix, the instant payment system launched by the Central Bank of Brazil in 2020. The study aims to identify and classify the main types of fraud affecting users and financial institutions, highlighting the evolution and increasing sophistication of these techniques. The methodology combines a structured literature review with exploratory interviews conducted with professionals from the banking sector. The results show that fraud schemes have evolved from purely social engineering approaches to hybrid strategies that integrate human manipulation with technical exploitation. The study concludes that security measures must advance at the same pace as the growing complexity of attack methodologies, with particular emphasis on adaptive defenses and continuous user awareness.

</details>


### [84] [Readout-Side Bypass for Residual Hybrid Quantum-Classical Models](https://arxiv.org/abs/2511.20922)
*Guilin Zhang,Wulan Guo,Ziqi Tan,Hongyang He,Hailong Jiang*

Main category: cs.CR

TL;DR: 提出了一种轻量级的残差混合架构，将量子特征与原始输入拼接后用于分类，以绕过量子测量瓶颈，同时不增加量子复杂度。实验显示该模型在集中式和联邦学习设置中均优于纯量子与先前混合模型，提升可达约55%的准确率，且通信成本较低且隐私鲁棒性增强。消融实验验证了量子-经典接口处残差连接的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决量子机器学习中的测量瓶颈及由此带来的隐私风险；在隐私敏感、资源受限的环境（如联邦边缘学习）实现近端可行的量子模型集成。

Method: 提出一种残差混合架构，在量子特征与原始输入之间进行拼接后进行分类，从而绕过测量瓶颈且不增加量子比特的复杂度。通过消融研究验证残差连接在量子-经典界面的作用，并在集中和联邦学习场景进行实验评估。

Result: 相较于量子基线，准确率提升高达约55%；优于纯量子模型和早期混合模型；具有低通信成本与增强的隐私鲁棒性。消融研究证实量子-经典接口处的残差连接有效。

Conclusion: 为在隐私敏感、资源受限的场景（如联邦边缘学习）中将量子模型落地提供了现实可行路径，具有中期可行性。

Abstract: Quantum machine learning (QML) promises compact and expressive representations, but suffers from the measurement bottleneck - a narrow quantum-to-classical readout that limits performance and amplifies privacy risk. We propose a lightweight residual hybrid architecture that concatenates quantum features with raw inputs before classification, bypassing the bottleneck without increasing quantum complexity. Experiments show our model outperforms pure quantum and prior hybrid models in both centralized and federated settings. It achieves up to +55% accuracy improvement over quantum baselines, while retaining low communication cost and enhanced privacy robustness. Ablation studies confirm the effectiveness of the residual connection at the quantum-classical interface. Our method offers a practical, near-term pathway for integrating quantum models into privacy-sensitive, resource-constrained settings like federated edge learning.

</details>


### [85] [CAHS-Attack: CLIP-Aware Heuristic Search Attack Method for Stable Diffusion](https://arxiv.org/abs/2511.21180)
*Shuhan Xia,Jing Dai,Hui Ouyang,Yadong Shang,Dongxiao Zhao,Peipei Li*

Main category: cs.CR

TL;DR: 提出 CAHS-Attack，一种结合 MCTS 的 CLIP 驱动启发式搜索对抗攻击方法，通过基因算法预选根节点并在 rollout 过程保留语义破坏性最强的结果，以实现对扩散模型的高效攻击，达到新高的攻击效果。


<details>
  <summary>Details</summary>
Motivation: 扩散模型对对抗提示的易脆弱性，现有黑白盒攻击在现实场景受限，迫切需要更强的、可扩展的无遮挡攻击方法；同时揭示 CLIP 文本编码器在文本-图像对齐中的安全隐患。

Method: 将蒙特卡洛树搜索用于对抗提示的细粒度后缀优化，利用受限的遗传算法在根节点上进行初选，且在每次仿真 rollout 中选取语义破坏性最强的结果用于局部搜索。

Result: 在短长提示、不同语义层级的设定下，达到或超过现有方法的攻击性能，显示出 state-of-the-art 的攻击效果。

Conclusion: SD 模型的脆弱性可归因于其 CLIP 基文本编码的固有脆弱性，揭示当前 text-to-image 流程中的根本安全风险。

Abstract: Diffusion models exhibit notable fragility when faced with adversarial prompts, and strengthening attack capabilities is crucial for uncovering such vulnerabilities and building more robust generative systems. Existing works often rely on white-box access to model gradients or hand-crafted prompt engineering, which is infeasible in real-world deployments due to restricted access or poor attack effect. In this paper, we propose CAHS-Attack , a CLIP-Aware Heuristic Search attack method. CAHS-Attack integrates Monte Carlo Tree Search (MCTS) to perform fine-grained suffix optimization, leveraging a constrained genetic algorithm to preselect high-potential adversarial prompts as root nodes, and retaining the most semantically disruptive outcome at each simulation rollout for efficient local search. Extensive experiments demonstrate that our method achieves state-of-the-art attack performance across both short and long prompts of varying semantics. Furthermore, we find that the fragility of SD models can be attributed to the inherent vulnerability of their CLIP-based text encoders, suggesting a fundamental security risk in current text-to-image pipelines.

</details>


### [86] [AuthenLoRA: Entangling Stylization with Imperceptible Watermarks for Copyright-Secure LoRA Adapters](https://arxiv.org/abs/2511.21216)
*Fangming Shi,Li Li,Kejiang Chen,Guorui Feng,Xinpeng Zhang*

Main category: cs.CR

TL;DR: 在 LoRA 微调的扩散模型中，提出 AuthenLoRA，将水印嵌入训练阶段，确保生成图像携带可追溯水印，同时保持高保真风格化和低误检率。


<details>
  <summary>Details</summary>
Motivation: 解决 LoRA 水印的传播与追溯缺陷：现有水印要么嵌入基模型、要么仅验证 LoRA 模块，未能与生成图像持续耦合，且基于风格化的水印易引入视觉损伤或高假阳性，需要在保持 stylization 的前提下实现可靠溯源。

Method: 提出双目标优化，联合学习目标风格分布与水印诱导的分布漂移；扩展 LoRA 架构以实现多尺度自适应；引入零信息正则化以显著降低水印验证的误报；在 LoRA 的训练流程中嵌入水印机制并实现对生成图像的水印传播。

Result: 实验表明在保持高保真风格化的同时，水印传播鲁棒、验证误报率显著低于现有方法，并具备良好的可溯性。

Conclusion: AuthenLoRA 提供一个统一且可开源的水印框架，能在 LoRA 微调的扩散模型中实现可追溯的水印传播，并兼顾风格化质量与误检控制。

Abstract: Low-Rank Adaptation (LoRA) offers an efficient paradigm for customizing diffusion models, but its ease of redistribution raises concerns over unauthorized use and the generation of untraceable content. Existing watermarking techniques either target base models or verify LoRA modules themselves, yet they fail to propagate watermarks to generated images, leaving a critical gap in traceability. Moreover, traceability watermarking designed for base models is not tightly coupled with stylization and often introduces visual degradation or high false-positive detection rates. To address these limitations, we propose AuthenLoRA, a unified watermarking framework that embeds imperceptible, traceable watermarks directly into the LoRA training process while preserving stylization quality. AuthenLoRA employs a dual-objective optimization strategy that jointly learns the target style distribution and the watermark-induced distribution shift, ensuring that any image generated with the watermarked LoRA reliably carries the watermark. We further design an expanded LoRA architecture for enhanced multi-scale adaptation and introduce a zero-message regularization mechanism that substantially reduces false positives during watermark verification. Extensive experiments demonstrate that AuthenLoRA achieves high-fidelity stylization, robust watermark propagation, and significantly lower false-positive rates compared with existing approaches. Open-source implementation is available at: https://github.com/ShiFangming0823/AuthenLoRA

</details>


### [87] [Illuminating the Black Box: Real-Time Monitoring of Backdoor Unlearning in CNNs via Explainable AI](https://arxiv.org/abs/2511.21291)
*Tien Dat Hoang*

Main category: cs.CR

TL;DR: 提出一种将 Grad-CAM 融入后门去除（unlearning）的框架，并引入 Trigger Attention Ratio (TAR) 以实现可解释、实时监控的后门移除。


<details>
  <summary>Details</summary>
Motivation: 现有的后门去除方法缺乏透明性与实时解释能力，难以提供可观测、可验证的移除过程，因此需要兼具解释性与高效性的新框架。

Method: 将 Grad-CAM 纳入 unlearning 过程，提出 Trigger Attention Ratio (TAR) 以量化模型对触发模式与合法对象特征的注意力迁移。提出一个平衡的去学习策略：对后门样本进行梯度上升以强化对后门的干扰，结合 Elastic Weight Consolidation (EWC) 避免灾难性遗忘，并设置一个恢复阶段以提升清洁准确率。

Result: 在 CIFAR-10/BadNets 实验中，后门攻击成功率（ASR）从 96.51% 降至 5.52%，清洁准确率提升或保持在 82.06%（占原始水平的 99.48%），实现了约 94.28% 的 ASR 降低。

Conclusion: 将可解释性 AI 融入后门移除流程，提供透明、可观察、可验证的后门去除机制。

Abstract: Backdoor attacks pose severe security threats to deep neural networks by embedding malicious triggers that force misclassification. While machine unlearning techniques can remove backdoor behaviors, current methods lack transparency and real-time interpretability. This paper introduces a novel framework that integrates Gradient-weighted Class Activation Mapping (Grad-CAM) into the unlearning process to provide real-time monitoring and explainability. We propose the Trigger Attention Ratio (TAR) metric to quantitatively measure the model's attention shift from trigger patterns to legitimate object features. Our balanced unlearning strategy combines gradient ascent on backdoor samples, Elastic Weight Consolidation (EWC) for catastrophic forgetting prevention, and a recovery phase for clean accuracy restoration. Experiments on CIFAR-10 with BadNets attacks demonstrate that our approach reduces Attack Success Rate (ASR) from 96.51% to 5.52% while retaining 99.48% of clean accuracy (82.06%), achieving a 94.28% ASR reduction. The integration of explainable AI enables transparent, observable, and verifiable backdoor removal.

</details>


### [88] [Empirical Assessment of the Code Comprehension Effort Needed to Attack Programs Protected with Obfuscation](https://arxiv.org/abs/2511.21301)
*Leonardo Regano,Daniele Canavese,Cataldo Basile,Marco Torchiano*

Main category: cs.CR

TL;DR: 本研究通过一个受控实验评估对代码混淆的有效性，重点在于衡量对攻击者理解代码的延迟效果，并考察复杂性度量是否能预测成功率和任务时长；首次评估对同一代码分层多重混淆的效果，提供客观指标与攻击成功概率之间的相关证据，并指明未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 保护软件资产的有效性需要实证数据；尽管混淆广泛使用，但其效果尚未被充分评估；通过将多层混淆和客观指标结合，填补理论与经验之间的空白。

Method: 在受试者为硕士生的控制实验中，比较被混淆和未混淆代码的代码理解任务；引入多层混淆的组合；测量任务成功率与完成时长，并收集代码复杂性等客观指标，分析其与攻击成功的相关性。

Result: 实验表明混淆能在一定程度上延缓代码理解；代码复杂性指标与攻击成功率和耗时存在相关性；首次提供对分层混淆的实验证据；弥合客观指标与主观评估之间的联系；指出需要进一步分析的方面。

Conclusion: 混淆在延缓攻击者理解方面具有可观的效果；客观复杂性指标可预测攻击成功概率与耗时，但需要在更广泛场景和参与者群体中验证；未来工作应深入研究分层混淆的影响、指标的鲁棒性，以及扩展到实际应用情境。

Abstract: Evaluating the effectiveness of software protection is crucial for selecting the most effective methods to safeguard assets within software applications. Obfuscation involves techniques that deliberately modify software to make it more challenging to understand and reverse-engineer, while maintaining its original functionality. Although obfuscation is widely adopted, its effectiveness remains largely unexplored and unthoroughly evaluated. This paper presents a controlled experiment involving Master's students performing code comprehension tasks on applications hardened with obfuscation. The experiment's goals are to assess the effectiveness of obfuscation in delaying code comprehension by attackers and to determine whether complexity metrics can accurately predict the impact of these protections on success rates and durations of code comprehension tasks. The study is the first to evaluate the effect of layering multiple obfuscation techniques on a single piece of protected code. It also provides experimental evidence of the correlation between objective metrics of the attacked code and the likelihood of a successful attack, bridging the gap between objective and subjective approaches to estimating potency. Finally, the paper highlights significant aspects that warrant additional analysis and opens new avenues for further experiments.

</details>


### [89] [Constructing and Benchmarking: a Labeled Email Dataset for Text-Based Phishing and Spam Detection Framework](https://arxiv.org/abs/2511.21448)
*Rebeka Toth,Tamas Bisztray,Richard Dubniczky*

Main category: cs.CR

TL;DR: 提出一个包含钓鱼、垃圾邮件及合法邮件的标注数据集，区分人工与LLM生成内容，并标注情感诉求与动机；通过多模型评估识别情感/动机线索的能力，并评估对原始与改写邮件的一致性与鲁棒性；在强力的钓鱼检测同时，垃圾邮件与合法邮件区分仍具挑战性；并提供开源资源与评估框架。


<details>
  <summary>Details</summary>
Motivation: 应对LLM在邮件欺诈生成中的日益普及，亟需高质量标注数据集与评估框架，以提升AI辅助邮件安全系统的检测能力与鲁棒性，并促进开源研究。

Method: 构建包含类别、情感诉求（如紧迫感、恐惧、权威）与动机（链接跟随、凭据盗取、金融欺诈）的邮件数据集，并对多种LLM在识别情感/动机线索上的能力进行基线评估；选取最可靠的模型对整组数据进行注释；通过对邮件进行多轮LLM改写以保持语义与意图，评估分类鲁棒性；以专家标注的真值对一流LLM在原始与改写邮件上的表现进行评估；

Result: 结果显示在钓鱼检测方面表现强劲，但在将垃圾邮件与合法邮件区分开方面仍存在明显挑战；数据集与评估框架有助于改进AI辅助的邮件安全系统；开源资源、代码与模板对研究社区开放，促进再现性和扩展性。

Conclusion: 该研究提供了一个全面且可复现的评估平台，强调通过情感与动机线索来提升邮件安全检测的能力，同时揭示了垃圾邮件与合法邮件区分的难点，支持开源科学生态。

Abstract: Phishing and spam emails remain a major cybersecurity threat, with attackers increasingly leveraging Large Language Models (LLMs) to craft highly deceptive content. This study presents a comprehensive email dataset containing phishing, spam, and legitimate messages, explicitly distinguishing between human- and LLM-generated content. Each email is annotated with its category, emotional appeal (e.g., urgency, fear, authority), and underlying motivation (e.g., link-following, credential theft, financial fraud). We benchmark multiple LLMs on their ability to identify these emotional and motivational cues and select the most reliable model to annotate the full dataset. To evaluate classification robustness, emails were also rephrased using several LLMs while preserving meaning and intent. A state-of-the-art LLM was then assessed on its performance across both original and rephrased emails using expert-labeled ground truth. The results highlight strong phishing detection capabilities but reveal persistent challenges in distinguishing spam from legitimate emails. Our dataset and evaluation framework contribute to improving AI-assisted email security systems. To support open science, all code, templates, and resources are available on our project site.

</details>
