<div id=toc></div>

# Table of Contents

- [eess.SY](#eess.SY) [Total: 6]
- [cs.CR](#cs.CR) [Total: 11]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.IT](#cs.IT) [Total: 5]
- [eess.SP](#eess.SP) [Total: 11]
- [cs.LG](#cs.LG) [Total: 44]


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [1] [Perception-Limited Smooth Safety Filtering](https://arxiv.org/abs/2512.17057)
*Lyes Smaili,Soulaimane Berkane*

Main category: eess.SY

TL;DR: 提出两种感知感知友好、平滑的安全过滤器，用于在感知有限的非线性控制系统，解决传统CBF在感知受限下的切换不平滑问题，并以闭式解和可微惩罚形式实现安全控制，理论与数值均表明优于传统CBF。


<details>
  <summary>Details</summary>
Motivation: 由于感知受限导致全局可用的安全函数不可行，传统CBF在感知边界处会产生不平滑切换，亟需在保证安全与可实现性前提下实现平滑过滤。

Method: 提出两种互补的感知感知安全过滤器：第一种是平滑感知门，基于感知距离调整CBF约束，给出闭式的Lipschitz安全控制律并保证前向不变性；第二种用可微惩罚项替代硬CBF约束，得到一个与CBF原理一致的平滑无约束优化安全滤波器。对两种设计给出存在性、唯一性和闭环轨迹的前向不变性证明。

Result: 数值结果显示所提平滑滤波器能为无人机和二阶地面机器人等系统合成更高阶的跟踪控制器，并显著提升安全性能的平滑性和鲁棒性，相较于经典CBF滤波器。

Conclusion: 该框架提供了感知感知的安全过滤策略，确保在感知受限场景中的平滑安全行为，并在理论和数值上优于传统CBF滤波器，推动高阶控制在感知受限下的安全性实现。

Abstract: This paper develops a smooth safety-filtering framework for nonlinear control-affine systems under limited perception. Classical Control Barrier Function (CBF) filters assume global availability of the safety function - its value and gradient must be known everywhere - an assumption incompatible with sensing-limited settings, and the resulting filters often exhibit nonsmooth switching when constraints activate. We propose two complementary perception-aware safety filters applicable to general control-invariant safety sets. The first introduces a smooth perception gate that modulates barrier constraints based on sensing range, yielding a closed-form Lipschitz-safe controller with forward-invariance guarantees. The second replaces the hard CBF constraint with a differentiable penalty term, leading to a smooth unconstrained optimization-based safety filter consistent with CBF principles. For both designs, we establish existence, uniqueness, and forward invariance of the closed-loop trajectories. Numerical results demonstrate that the proposed smooth filters enable the synthesis of higher-order tracking controllers for systems such as drones and second-order ground robots, offering substantially smoother and more robust safety-critical behaviors than classical CBF-based filters.

</details>


### [2] [Uncertainty-Aware 3D UAV Tracking Using Single-Anchor UWB Measurements](https://arxiv.org/abs/2512.17249)
*Yuqi Ping,Junwei Wu,Bofeng Zheng,Fan Liu,Tianhao Liang,Tingting Zhang*

Main category: eess.SY

TL;DR: 提出一种基于单锚UWB的3D跟踪框架，结合鲁棒因子图定位与协方差感知的CLF-CBF跟踪控制器，以在测量降级和运动不确定性下提升稳定性与安全性。


<details>
  <summary>Details</summary>
Motivation: 在仅依赖单锚UWB的情况下实现对移动目标的可靠3D跟踪，需将不确定性引入的定位与控制耦合，提升系统在现实场景（如室内狭窄走廊）中的鲁棒性与安全性。

Method: 在UAV上安装单锚UWB，通过距离与三维方位角等观测构建鲁棒因子图实现目标定位，并利用其后验协方差来驱动协方差感知的CLF-CBF控制器，动态调整目标距离约束与安全裕度。

Result: 通过数值仿真与真实室内走廊实验验证，所提出的方法在测量下降级条件下仍能保持较好跟踪性与安全性。

Conclusion: 将观测不确定性映射到控制约束的自适应耦合，提供一种在复杂室内环境中可行的3D跟踪解决方案。

Abstract: In this letter, we present an uncertainty-aware single-anchor Ultra-Wideband (UWB)-based 3D tracking framework. Specifically, a mobile Unmanned Aerial Vehicle (UAV) maintains a desired standoff distance to a moving target using range and 3D bearing measurements from a multi-antenna UWB anchor rigidly mounted on the UAV. To enhance the stability and safety under measurement degradation and motion uncertainty, we jointly design a robust factor-graph-based target localization method and a covariance-aware control Lyapunov function--control barrier function (CLF--CBF) tracking controller. This controller adaptively adjusts distance bounds and safety margins based on the posterior target covariance provided by the factor graph. The proposed system is evaluated through numerical simulations and real-world experiments carried out in a narrow indoor corridor environment.

</details>


### [3] [Grey graphs and its application](https://arxiv.org/abs/2512.17360)
*Wanli Xie,Jiale Zhang,Ruiqing Cao*

Main category: eess.SY

TL;DR: 提出基于灰色图理论的多属性决策方法，利用区间灰数、核与灰度度，结合模糊图与灰色图运算规则，通过数值例子验证可行性。


<details>
  <summary>Details</summary>
Motivation: 解决多属性决策问题中属性值为区间灰数时的决策难题，利用灰色图和核/灰度度改善决策过程的可行性与鲁棒性。

Method: 将模糊图理论与区间灰数结合，提出基于灰色图的多属性决策方法；给出灰色图及其运算规程，并在决策分析中使用核和灰度度来表征属性值与关系；通过一个数值实例演示方法步骤。

Result: 给出一种简化的形式、灰色图的操作规则、及对备选方案的分析与评估，证明该方法在该问题上的有效性与可行性。

Conclusion: 该方法可为区间灰数的多属性决策提供可行的框架，具有理论与应用价值；未来工作可能包括扩展、鲁棒性分析、对比研究等。

Abstract: In multi-attribute decision-making problems where the attribute values are interval grey numbers, a simplified form based on kernels and the degree of greyness is presented. Combining fuzzy graph theory with the kernel and the degree of greyness of interval grey numbers, grey graphs and their corresponding operation rules are presented. This paper presents a new multi-attribute decision-making method based on grey graph theory. We analyzed and evaluated the alternative schemes using grey graph. Lastly, a numerical example was conducted in order to demonstrate the effectiveness and feasibility of the proposed method.

</details>


### [4] [Layer-to-layer Closed-loop Switched Heating and Cooling Control of the Laser Powder Bed Fusion Process](https://arxiv.org/abs/2512.17518)
*Barış Kavas,Efe C. Balta,Lars Witte,Michael R. Tucker,John Lygeros,Markus Bambach*

Main category: eess.SY

TL;DR: A switched layer-to-layer closed-loop feedback controller stabilizes interlayer temperature in laser powder bed fusion using a lateral thermal camera, switching between heating via laser power and cooling via interlayer dwell time, with evaluation on supported vs. unsupported overhangs and trade-offs between efficiency, energy, and build time.


<details>
  <summary>Details</summary>
Motivation: Thermal management is critical in laser powder bed fusion to prevent overheating and thermal stresses; maintaining a stable interlayer temperature across varying geometries is essential for part quality, especially in complex or overhanging features.

Method: A novel switched layer-to-layer closed-loop controller measures interlayer temperature with a lateral thermal camera, and maintains a reference temperature by: (1) heating mode using a feedback optimization algorithm to adjust laser power; (2) cooling mode by increasing interlayer dwell time to allow cooling until the target is reached. The controller is evaluated on both supported and unsupported overhangs to assess the influence of support structures on thermal behavior and controller performance.

Result: The controller stabilizes interlayer temperature across varying cross-sectional areas within the material's stable processing zone. Heating mode achieves temperature stabilization even with significant cross-section variation. Trade-offs identified among process efficiency, energy consumption, and build time: supported parts reduce overheating but use more energy/material; unsupported parts stabilize faster but require longer dwell times and build times. The approach improves thermal stability for geometries prone to excessive thermal stresses and introduces interlayer dwell time as a practical tool for complex geometries.

Conclusion: Interlayer dwell time coupled with a switched heating/cooling controller provides effective thermal stabilization in L-PBF across diverse geometries, with notable improvements for high-thermal-stress regions. However, users must consider trade-offs in energy use and build time, and the presence of supports alters thermal dynamics and controller efficiency.

Abstract: This study investigates the stabilization of interlayer temperature in the laser powder bed fusion process through a novel switched layer-to-layer closed-loop feedback controller. The controller architecture aims to measure the interlayer temperature by a laterally positioned thermal camera and maintain a preset reference temperature by switching between the heating mode through dynamic laser power adjustment and the cooling mode by assigning interlayer dwell time to allow cooling between layers. The switching controller employs a feedback optimization control algorithm for the heating mode to adjust the laser power, and a triggering algorithm that increases the interlayer dwell time until the interlayer temperature reaches the reference value. Additionally, the study compares the performance of the proposed controller in both supported and unsupported overhanging parts to evaluate the effect of support structures on the controller performance as well as the thermal behavior of overhanging parts. Results demonstrate the controller's effectiveness in stabilizing interlayer temperature across varying cross-sectional areas while remaining within the material's stable processing zone. In the heating mode, the controller efficiently stabilizes temperature, even in geometries with significant cross-section variation. The study also identifies trade-offs among process efficiency, energy consumption, and build time. Supported parts exhibit reduced overheating but consume more energy and material, while unsupported parts stabilize interlayer temperature faster but with longer build times due to increased dwell time assignments. The research highlights notable improvements in interlayer temperature control for geometries prone to excessive thermal stresses. Moreover, the introduction of interlayer dwell time offers a practical solution to maintaining thermal stability in complex geometries.

</details>


### [5] [Techno-Economic Case Study of a Rural Local Electricity Community in Switzerland](https://arxiv.org/abs/2512.17803)
*Gerard Marias Gonzalez,Alejandro Pena-Bello,Jérémy Dumoulin,Nicolas Wyrsch*

Main category: eess.SY

TL;DR: 瑞士农村地区的本地电力社区（CEL）将于2026年投入运行，研究评估其对参与者与本地分布式系统运营商（DSO）的技术-经济影响。结果显示，CEL可提升本地可再生能源利用（特别是光伏）且带来有限的财政收益，效果高度受社区规模、构成与关税设计影响。内部交易在光伏产出约为社区负荷1–2倍时最优化；对DSO而言，CELs将降低网内进口27–46%，导致分布式电价收入下降约17–36%，需监管调整。集中式储能对成员有经济价值但对电网的技术影响有限；若容量较大则可降低变压器峰值，但可能增加线路载荷，需谨慎选型与布局。


<details>
  <summary>Details</summary>
Motivation: 评估本地电力社区（CEL）在瑞士的经济与技术影响，以及对参与者、DGOs与监管框架的含义，以辅助政策制定与投资决策。

Method: 以瑞士农村案例为基础，分析CEL内成员之间的电力交换、tariff设计、以及集中/分布式储能对交易经济性与电网负荷的影响，采用定量模型评估成本、收益及网负荷变化，并探讨对DSO收入与监管的含义。

Result: CEL提升本地可再生能源利用，尤其是光伏，且带来有限的财政收益，且高度受社区规模、构成和关税设计影响。内部交易的最大化出现在本地PV产出约等于1–2倍社区负荷时。对DSO而言，CELs使进口电量减少约27–46%，从而分布式关税收入下降约17–36%，需要监管适应。集中式储能为成员带来经济价值，但对电网的技术影响有限；若容量较大可降低变压器峰值，但可能增加线路载荷，需谨慎容量配置与布局。

Conclusion: 需监管层面做出调整以应对DSO收入下降等财政影响；CELs可促进本地能源自给，但实际效应取决于设计和规模；储能策略需与地区网路规模匹配，避免造成新的负荷错配。

Abstract: Local Electricity Communities (communautés électriques locales, CEL) will become operational in Switzerland in 2026, allowing prosumers, consumers, and storage operators within the same municipality and distribution system operator (DSO) area to exchange electricity over the public grid with reduced distribution tariffs. This report examines a rural Swiss case study to explore the techno-economic implications of CELs for both participants and the local DSO. The findings indicate that CELs can enhance the local use of renewable generation, particularly photovoltaics, and offer modest financial gains, with outcomes strongly shaped by community size, composition, and tariff design. Larger and more heterogeneous communities achieve better internal matching of supply and demand, though the overall incentive remains limited because the tariff reduction applies only to distribution charges. The study further shows that internal energy exchange is maximized when local PV generation covers roughly 1-2 times the community load. For DSOs, CELs reduce grid imports (27-46%), resulting in a substantial reduction in distribution tariff revenues (17-36%), necessitating regulatory adaptation. While centralized batteries provide economic value to members, their technical impact on the grid remains modest due to their small, economically optimized capacity. Larger centralized storage is shown to reduce transformer peak power, but risks increasing line loading, suggesting a need for careful sizing and placement.

</details>


### [6] [Distributionally Robust Imitation Learning: Layered Control Architecture for Certifiable Autonomy](https://arxiv.org/abs/2512.17899)
*Aditya Gahlawat,Ahmed Aboudonia,Sandeep Banik,Naira Hovakimyan,Nikolai Matni,Aaron D. Ames,Gioele Zardini,Alberto Speranzon*

Main category: eess.SY

TL;DR: DRIP：通过分层控制架构将 TaSIL 和 L1-DRAC 整合在一起，实现可证可控的模仿学习框架，针对策略误差和外部扰动导致的分布偏移，提供对整个控制管线的证书能力。


<details>
  <summary>Details</summary>
Motivation: 在模仿学习中，分布偏移来自策略误差和外部扰动/模型不确定性，导致自我驱动控制的鲁棒性降低。需要一个可证可控的体系，将学习组件（如感知）与基于模型的决策结合起来。

Method: 提出 DRIP 架构（一个层级控制架构，结合 TaSIL 的对策略误差的鲁棒性和 L1-DRAC 的对不确定性的鲁棒性），通过层级输入输出约束实现对整个控制流水线的可证性，设计 layer-centric 输入输出以实现系统各层的证书。

Result: 提供一个理论框架，能为整条控制流水线提供证书，指向可证可控的自主系统路径，并展现将学习组件与证认的决策制定耦合的潜力。

Conclusion: DRIP 为实现完全可证可控的自主管线铺平道路，通过将学习组件（感知）与可证可控的决策机制结合，促进面向实际部署的可验证性。

Abstract: Imitation learning (IL) enables autonomous behavior by learning from expert demonstrations. While more sample-efficient than comparative alternatives like reinforcement learning, IL is sensitive to compounding errors induced by distribution shifts. There are two significant sources of distribution shifts when using IL-based feedback laws on systems: distribution shifts caused by policy error and distribution shifts due to exogenous disturbances and endogenous model errors due to lack of learning. Our previously developed approaches, Taylor Series Imitation Learning (TaSIL) and $\mathcal{L}_1$ -Distributionally Robust Adaptive Control (\ellonedrac), address the challenge of distribution shifts in complementary ways. While TaSIL offers robustness against policy error-induced distribution shifts, \ellonedrac offers robustness against distribution shifts due to aleatoric and epistemic uncertainties. To enable certifiable IL for learned and/or uncertain dynamical systems, we formulate \textit{Distributionally Robust Imitation Policy (DRIP)} architecture, a Layered Control Architecture (LCA) that integrates TaSIL and~\ellonedrac. By judiciously designing individual layer-centric input and output requirements, we show how we can guarantee certificates for the entire control pipeline. Our solution paves the path for designing fully certifiable autonomy pipelines, by integrating learning-based components, such as perception, with certifiable model-based decision-making through the proposed LCA approach.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [7] [CAPIO: Safe Kernel-Bypass of Commodity Devices using Capabilities](https://arxiv.org/abs/2512.16957)
*Friedrich Doku,Jonathan Laughton,Nick Wanninger,Peter Dinda*

Main category: cs.CR

TL;DR: CAPIO 以能力机理实现对内存映射I/O的细粒度访问控制，通过子页切片来实现对设备内存的精确授权，与内核绕行相比保留字节级访问控制与低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有内核依赖的高开销中介接口与按页粒度的寻址模型导致了低延迟I/O的安全与性能矛盾；必须在不暴露完整的控制寄存器的前提下，避免子页级别的资源暴露。

Method: 在 CHERI 的 ARM Morello 平台上实现 CAPIO，利用不可伪造的能力创建设备内存的子页“切片”，并将延迟敏感的硬件访问下放给用户态，同时严格隔离同页上共存的特权寄存器；实现一个面向商用网卡的安全访问驱动作为原型，验证在内核绕行下的延迟改善与字节级访问控制。

Result: CAPIO 实现了内核绕行的低延迟优势，并在字节级别上对特权资源进行访问控制的证明原型，展示了细粒度I/O权限控制的可行性与效能提升。

Conclusion: 通过硬件能力提供的不可伪造的能力，CAPIO 证明了细粒度的 I/O 访问策略在商业设备上的可行性，为在不暴露完整设备寄存器的前提下实现低延迟 I/O 提供了一条切实路径。

Abstract: Securing low-latency I/O in commodity systems forces a fundamental trade-off: rely on the kernel's high overhead mediated interface, or bypass it entirely, exposing sensitive hardware resources to userspace and creating new vulnerabilities. This dilemma stems from a hardware granularity mismatch: standard MMUs operate at page boundaries, making it impossible to selectively expose safe device registers without also exposing the sensitive control registers colocated on the same page. Existing solutions to driver isolation enforce an isolation model that cannot protect sub-page device resources.
  This paper presents CAPIO, the first architecture to leverage hardware capabilities to enforce fine-grained access control on memory-mapped I/O. Unlike prior page-based protections, CAPIO utilizes unforgeable capabilities to create precise, sub-page "slices" of device memory. This mechanism enables the kernel to delegate latency-critical hardware access to userspace applications while strictly preventing interaction with co-located privileged registers.
  We implement CAPIO based on CHERI on the ARM Morello platform and demonstrate a proof-of-concept safe-access driver for a commodity network card which was not originally designed for kernel bypass. We demonstrate that CAPIO achieves the latency improvements of kernel bypass while enforcing byte-level access control of privileged resources.

</details>


### [8] [MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval](https://arxiv.org/abs/2512.16962)
*Saksham Sahai Srivastava,Haoyu He*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Model (LLM) agents increasingly rely on long-term memory and Retrieval-Augmented Generation (RAG) to persist experiences and refine future performance. While this experience learning capability enhances agentic autonomy, it introduces a critical, unexplored attack surface, i.e., the trust boundary between an agent's reasoning core and its own past. In this paper, we introduce MemoryGraft. It is a novel indirect injection attack that compromises agent behavior not through immediate jailbreaks, but by implanting malicious successful experiences into the agent's long-term memory. Unlike traditional prompt injections that are transient, or standard RAG poisoning that targets factual knowledge, MemoryGraft exploits the agent's semantic imitation heuristic which is the tendency to replicate patterns from retrieved successful tasks. We demonstrate that an attacker who can supply benign ingestion-level artifacts that the agent reads during execution can induce it to construct a poisoned RAG store where a small set of malicious procedure templates is persisted alongside benign experiences. When the agent later encounters semantically similar tasks, union retrieval over lexical and embedding similarity reliably surfaces these grafted memories, and the agent adopts the embedded unsafe patterns, leading to persistent behavioral drift across sessions. We validate MemoryGraft on MetaGPT's DataInterpreter agent with GPT-4o and find that a small number of poisoned records can account for a large fraction of retrieved experiences on benign workloads, turning experience-based self-improvement into a vector for stealthy and durable compromise. To facilitate reproducibility and future research, our code and evaluation data are available at https://github.com/Jacobhhy/Agent-Memory-Poisoning.

</details>


### [9] [Sedna: Sharding transactions in multiple concurrent proposer blockchains](https://arxiv.org/abs/2512.17045)
*Alejandro Ranchal-Pedrosa,Benjamin Marsh,Lefteris Kokoris-Kogias,Alberto Sonnino*

Main category: cs.CR

TL;DR: Sedna uses verifiable rateless coding for transaction dissemination in multi-proposer blockchains, enabling private delivery to subsystems of proposers and deterministic decoding that preserves liveness and until-decode privacy, with 2-3x bandwidth efficiency over naive replication and no consensus changes.


<details>
  <summary>Details</summary>
Motivation: Address the practical trilemma in MCP blockchains: censorship resistance, low latency, and cost. Current replication strategies either expose payloads to MEV or suffer from inefficiency and weak censorship guarantees. Sedna aims to reduce MEV exposure and improve efficiency without modifying the consensus protocol.

Method: Users privately deliver addressed symbol bundles to subsets of proposers using verifiable rateless coding. Once enough symbols are finalized to decode, execution proceeds in a deterministic order. The approach provides liveness and until-decode privacy, with analytics showing near information-theoretic lower bounds on bandwidth; no changes to the underlying consensus are required.

Result: Sedna achieves a 2-3x improvement in bandwidth efficiency compared to naive replication, approaches the information-theoretic lower bound for bandwidth, and preserves liveness and until-decode privacy. It enables incremental deployment without consensus modifications.

Conclusion: Sedna offers a practical and deployable solution to the transaction dissemination problem in MCP blockchains, improving efficiency and privacy while maintaining compatibility with existing consensus, thus mitigating the censorship-latency-cost trilemma.

Abstract: Modern blockchains increasingly adopt multi-proposer (MCP) consensus to remove single-leader bottlenecks and improve censorship resistance. However, MCP alone does not resolve how users should disseminate transactions to proposers. Today, users either naively replicate full transactions to many proposers, sacrificing goodput and exposing payloads to MEV, or target few proposers and accept weak censorship and latency guarantees. This yields a practical trilemma among censorship resistance, low latency, and reasonable cost (in fees or system goodput).
  We present Sedna, a user-facing protocol that replaces naive transaction replication with verifiable, rateless coding. Users privately deliver addressed symbol bundles to subsets of proposers; execution follows a deterministic order once enough symbols are finalized to decode. We prove Sedna guarantees liveness and \emph{until-decode privacy}, significantly reducing MEV exposure. Analytically, the protocol approaches the information-theoretic lower bound for bandwidth overhead, yielding a 2-3x efficiency improvement over naive replication. Sedna requires no consensus modifications, enabling incremental deployment.

</details>


### [10] [AlignDP: Hybrid Differential Privacy with Rarity-Aware Protection for LLMs](https://arxiv.org/abs/2512.17251)
*Madhava Gaikwad*

Main category: cs.CR

TL;DR: AlignDP: a two-tier privacy mechanism that blocks knowledge transfer at the data interface by separating rare and non-rare fields; rare fields use PAC indistinguishability for zero-epsilon local DP, non-rare fields use RAPPOR for unbiased local DP estimates; a global aggregator enforces composition and budget; theoretical bounds and a toy simulation show rare events are hidden while frequent categories are recoverable with small error.


<details>
  <summary>Details</summary>
Motivation: Mitigate pre-leak privacy risks where language models can extract, distill, or be fine-tuned using leaked data. Existing defenses act post-leak; AlignDP aims to neutralize transfer preemptively at the data interface.

Method: Partition data into rare and non-rare fields. Apply PAC indistinguishability shielding to rare fields (effectively zero-epsilon local DP) and privatize non-rare fields with RAPPOR (unbiased frequency estimates under local DP). Use a global aggregator to enforce privacy budget and composition across fields. The paper analyzes limits of extending PAC to global aggregation, derives bounds for RAPPOR estimates, and conducts a toy simulation to validate feasibility.

Result: The work provides theoretical bounds for both components and demonstrates in a toy simulation that rare categories remain hidden while frequent categories can be recovered with small error.

Conclusion: A two-tier AlignDP design can suppress leakage by protecting rare events and perturbing frequent events, with a global budget mechanism; results show potential utility preservation for common categories while maintaining strong protection for rare ones, though there are theoretical and practical trade-offs to explore.

Abstract: Large language models are exposed to risks of extraction, distillation, and unauthorized fine-tuning. Existing defenses use watermarking or monitoring, but these act after leakage. We design AlignDP, a hybrid privacy lock that blocks knowledge transfer at the data interface. The key idea is to separate rare and non-rare fields. Rare fields are shielded by PAC indistinguishability, giving effective zero-epsilon local DP. Non-rare fields are privatized with RAPPOR, giving unbiased frequency estimates under local DP. A global aggregator enforces composition and budget. This two-tier design hides rare events and adds controlled noise to frequent events. We prove limits of PAC extension to global aggregation, give bounds for RAPPOR estimates, and analyze utility trade-off. A toy simulation confirms feasibility: rare categories remain hidden, frequent categories are recovered with small error.

</details>


### [11] [Practical Framework for Privacy-Preserving and Byzantine-robust Federated Learning](https://arxiv.org/abs/2512.17254)
*Baolei Zhang,Minghong Fang,Zhuqing Liu,Biao Yi,Peizhao Zhou,Yuan Wang,Tong Li,Zheli Liu*

Main category: cs.CR

TL;DR: ABBR is a practical framework for Byzantine-robust and privacy-preserving federated learning that uses dimensionality reduction to accelerate private filtering, analyzes accuracy loss in low-dimensional vector-wise filtering, and includes an adaptive tuning strategy. It achieves faster runtimes and lower communication overhead while maintaining comparable Byzantine resilience to state-of-the-art baselines.


<details>
  <summary>Details</summary>
Motivation: Existing defenses against backdoor and privacy inference attacks incur high computational and communication overhead, creating a gap between theory and practice; a practical, efficient solution is needed.

Method: Introduce ABBR framework; apply dimensionality reduction to speed up private computation of complex filtering rules; analyze accuracy loss of vector-wise filtering in low-dimensional space; propose adaptive tuning strategy to mitigate impact of bypassed filtering; implement with state-of-the-art Byzantine-robust aggregation rules; evaluate on public datasets.

Result: ABBR runs significantly faster with minimal communication overhead and retains nearly the same Byzantine resilience as baseline methods.

Conclusion: ABBR provides a practical, efficient solution that balances privacy and robustness in federated learning, narrowing the gap between theory and practice.

Abstract: Federated Learning (FL) allows multiple clients to collaboratively train a model without sharing their private data. However, FL is vulnerable to Byzantine attacks, where adversaries manipulate client models to compromise the federated model, and privacy inference attacks, where adversaries exploit client models to infer private data. Existing defenses against both backdoor and privacy inference attacks introduce significant computational and communication overhead, creating a gap between theory and practice. To address this, we propose ABBR, a practical framework for Byzantine-robust and privacy-preserving FL. We are the first to utilize dimensionality reduction to speed up the private computation of complex filtering rules in privacy-preserving FL. Additionally, we analyze the accuracy loss of vector-wise filtering in low-dimensional space and introduce an adaptive tuning strategy to minimize the impact of malicious models that bypass filtering on the global model. We implement ABBR with state-of-the-art Byzantine-robust aggregation rules and evaluate it on public datasets, showing that it runs significantly faster, has minimal communication overhead, and maintains nearly the same Byzantine-resilience as the baselines.

</details>


### [12] [An Iconic Heavy Hitter Algorithm Made Private](https://arxiv.org/abs/2512.17295)
*Rayne Holland*

Main category: cs.CR

TL;DR: 提出了差分隐私版本的 SpaceSaving 算法，以及一种从任何差分隐私频率 Oracle 中提取重头项的通用方法，并给出实验证明在严格隐私下仍具备优越的实用性。


<details>
  <summary>Details</summary>
Motivation: 在数据流场景中，对用户行为的更新级隐私保护（update-level DP）日益重要；现有工作多将 Misra-Gries 改造以实现 DP，但对性能更好的 SpaceSaving 的私有化研究尚缺乏，且缺少通用的私有重头项提取机制。

Method: 对非私有 SpaceSaving 摘要进行后处理，通过注入渐近最优的噪声并应用稳健的标签抑制选择规则来实现私有化；同时提出一个从任意 DP 频率预言器中提取重头项的通用方法，需额外仅 O(k) 内存，并安全地从带噪的频率估计中释放项目身份。

Result: 在多组隐私参数和空间预算下，方法显示出优于现有的私有 Misra-Gries 算法的实用性，实验表明 SpaceSaving 的经验优势在私有化后仍然存在，且实现高效、实用的重头项识别。

Conclusion: 本文提供了在强 DP 保证下的实用重头项识别方法：通过对 SpaceSaving 私有化保持其实用性，并给出一个可插拔式的私有重头项回收框架，便于在线性草图上进行私有化的重头项提取。

Abstract: Identifying heavy hitters in data streams is a fundamental problem with widespread applications in modern analytics systems. These streams are often derived from sensitive user activity, making update-level privacy guarantees necessary. While recent work has adapted the classical heavy hitter algorithm Misra-Gries to satisfy differential privacy in the streaming model, the privatization of other heavy hitter algorithms with better empirical utility is absent.
  Under this observation, we present the first differentially private variant of the SpaceSaving algorithm, which, in the non-private setting, is regarded as the state-of-the-art in practice. Our construction post-processes a non-private SpaceSaving summary by injecting asymptotically optimal noise and applying a carefully calibrated selection rule that suppresses unstable labels. This yields strong privacy guarantees while preserving the empirical advantages of SpaceSaving.
  Second, we introduce a generic method for extracting heavy hitters from any differentially private frequency oracle in the data stream model. The method requires only O(k) additional memory, where k is the number of heavy items, and provides a mechanism for safely releasing item identities from noisy frequency estimates. This yields an efficient, plug-and-play approach for private heavy hitter recovery from linear sketches.
  Finally, we conduct an experimental evaluation on synthetic and real-world datasets. Across a wide range of privacy parameters and space budgets, our method provides superior utility to the existing differentially private Misra-Gries algorithm. Our results demonstrate that the empirical superiority of SpaceSaving survives privatization and that efficient, practical heavy hitter identification is achievable under strong differential privacy guarantees.

</details>


### [13] [Cryptanalysis of Pseudorandom Error-Correcting Codes](https://arxiv.org/abs/2512.17310)
*Tianrui Wang,Anyu Wang,Tianshuo Cong,Delong Ran,Jinyuan Liu,Xiaoyun Wang*

Main category: cs.CR

TL;DR: 首次对伪随机错误纠正码（PRC）进行系统密码分析，提出三种攻击以挑战其不可检测性与鲁棒性假设，并对真实大模型水印进行验证。攻击在多参数配置下有效，能在约2^22次运算量内检测水印。提出三种防御与改进的密钥生成算法，但在当前参数下仍难以达到128位安全，受大模型输出长度约束影响。


<details>
  <summary>Details</summary>
Motivation: 填补对PRC安全性分析的空白，评估在具体参数及现实攻击场景中的鲁棒性、不可检测性及水印安全性，以提升水印方案的安全性与实用性。

Method: 提出三种攻击：两种用于区分PRC码字与普通向量、一次用于破坏解码过程；在真实的生成模型（如 DeepSeek、Stable Diffusion）上验证攻击有效性；提出三项防御措施，包括参数优化、实现细节改进及重新设计的密钥生成算法。

Result: 攻击在所有参数配置下削弱或破坏了PRC的安全性；能以约2^22次运算检测水印的存在；改进的密钥生成函数有效防止了弱密钥，但总体仍未达到128-bit 安全，由于大模型的输出长度等固有限制。

Conclusion: PRC 方案在当前设计下存在显著安全隐患，需要更强的防御和更严格的参数选择；未来工作可聚焦于提升关键安全性、改进水印嵌入与密钥生成以实现更高的安全等级。

Abstract: Pseudorandom error-correcting codes (PRC) is a novel cryptographic primitive proposed at CRYPTO 2024. Due to the dual capability of pseudorandomness and error correction, PRC has been recognized as a promising foundational component for watermarking AI-generated content. However, the security of PRC has not been thoroughly analyzed, especially with concrete parameters or even in the face of cryptographic attacks. To fill this gap, we present the first cryptanalysis of PRC. We first propose three attacks to challenge the undetectability and robustness assumptions of PRC. Among them, two attacks aim to distinguish PRC-based codewords from plain vectors, and one attack aims to compromise the decoding process of PRC. Our attacks successfully undermine the claimed security guarantees across all parameter configurations. Notably, our attack can detect the presence of a watermark with overwhelming probability at a cost of $2^{22}$ operations. We also validate our approach by attacking real-world large generative models such as DeepSeek and Stable Diffusion. To mitigate our attacks, we further propose three defenses to enhance the security of PRC, including parameter suggestions, implementation suggestions, and constructing a revised key generation algorithm. Our proposed revised key generation function effectively prevents the occurrence of weak keys. However, we highlight that the current PRC-based watermarking scheme still cannot achieve a 128-bit security under our parameter suggestions due to the inherent configurations of large generative models, such as the maximum output length of large language models.

</details>


### [14] [Sandwiched and Silent: Behavioral Adaptation and Private Channel Exploitation in Ethereum MEV](https://arxiv.org/abs/2512.17602)
*Davide Mancino,Davide Rezzoli*

Main category: cs.CR

TL;DR: 本研究基于交易级数据，量化用户在多次公开对手攻击后的适应行为：约40%在60天内转向私有路由，重复攻击情形下增至54%；首次攻击后弃用率峰值7.5%，生存偏差导致1–2%逐步下降；2024年11–12月发生2932起私有对牌攻击，影响3126笔私有受害交易，造成损失约$409,236，攻击者利润$293,786；单一机器人账户约占私有前端攻击的三分之二；私有攻击集中在少数DEX池；私有路由并不能完全防护MEV，仍具可利用性，需持续监控与协议层防御。


<details>
  <summary>Details</summary>
Motivation: 理解用户对MEV攻击的反应及私有路由的有效性，量化行为适应与经济影响。

Method: 使用2024年11月至2025年2月的交易级数据，结合mempool可见性与ZeroMEV标签，跟踪n次公开对牌攻击后的用户结果，定义再激活、弃用、首次采用私有路由等

Result: 量化结果：约40%的受害者60天内转向私有路由，重复暴露情形下增至54%；首次攻击后弃用率峰值7.5%，在幸存者偏误的影响下降至1–2%；2024年11–12月报告2,932起私有 sandwich 攻击，影响3,126笔私有受害交易，损失$409,236，攻击者利润$293,786；一个机器人账户几乎占私有前端攻击的三分之二；私有攻击高度集中在少数DEX池。

Conclusion: 私有路由并不能完全保护，尽管执行失败促使用户转向私有通道，私有攻击仍具可利用性且高度集中，需要持续监控与协议层防护。

Abstract: How users adapt after being sandwiched remains unclear; this paper provides an empirical quantification. Using transaction level data from November 2024 to February 2025, enriched with mempool visibility and ZeroMEV labels, we track user outcomes after their n-th public sandwich: (i) reactivation, i.e., the resumption of on-chain activity within a 60-day window, and (ii) first-time adoption of private routing. We refer to users who do not reactivate within this window as churned, and to users experiencing multiple attacks (n>1) as undergoing repeated exposure. Our analysis reveals measurable behavioral adaptation: around 40% of victims migrate to private routing within 60 days, rising to 54% with repeated exposures. Churn peaks at 7.5% after the first sandwich but declines to 1-2%, consistent with survivor bias. In Nov-Dec 2024 we confirm 2,932 private sandwich attacks affecting 3,126 private victim transactions, producing \$409,236 in losses and \$293,786 in attacker profits. A single bot accounts for nearly two-thirds of private frontruns, and private sandwich activity is heavily concentrated on a small set of DEX pools. These results highlight that private routing does not guarantee protection from MEV extraction: while execution failures push users toward private channels, these remain exploitable and highly concentrated, demanding continuous monitoring and protocol-level defenses.

</details>


### [15] [A Post-Quantum Secure End-to-End Verifiable E-Voting Protocol Based on Multivariate Polynomials](https://arxiv.org/abs/2512.17613)
*Vikas Srivastava,Debasish Roy,Sihem Mesnager,Nibedita Kundu,Sumit Kumar Debnath,Sourav Mukhopadhyay*

Main category: cs.CR

TL;DR: 提出基于多元多项式的后量子安全端到端可验证电子投票协议，依赖MQ问题的NP-hard性，采用标准密码学原语，设计简单高效。


<details>
  <summary>Details</summary>
Motivation: 传统纸质投票和现有设计在量子威胁下可能不再安全，需要一种后量子、端到端可验证且实现友好的电子投票方案。

Method: 提出基于多元多项式的端到端可验证E-Voting协议，安全性基于MQ问题的困难性，使用标准密码构件，强调实现简洁和效率。

Result: 给出一个简单且高效的设计，并给出基于MQ难度的安全性分析，满足端到端可验证性。

Conclusion: 基于MQ的后量子E-Voting可行，提供对量子攻击的防护，同时保持实现简便性。

Abstract: Voting is a primary democratic activity through which voters select representatives or approve policies. Conventional paper ballot elections have several drawbacks that might compromise the fairness, effectiveness, and accessibility of the voting process. Therefore, there is an increasing need to design safer, effective, and easily accessible alternatives. E-Voting is one such solution that uses digital tools to simplify voting. Existing state-of-the-art designs for secure E-Voting are based on number-theoretic hardness assumptions. These designs are no longer secure due to quantum algorithms such as Shor's algorithm. We present the design and analysis of \textit{first} post-quantum secure end-to-end verifiable E-Voting protocol based on multivariate polynomials to address this issue. The security of our proposed design depends on the hardness of the MQ problem, which is an NP-hard problem. We present a simple yet efficient design involving only standard cryptographic primitives as building blocks.

</details>


### [16] [Digital and Web Forensics Model Cards, V1](https://arxiv.org/abs/2512.17722)
*Paola Di Maio*

Main category: cs.CR

TL;DR: A standardized model-card framework for digital and web forensics, featuring a web-based generator and controlled vocabularies for classification, reasoning, bias, and error categorization; introduces a beta tool and invites community feedback; notes systemic risk due to potential mob influence.


<details>
  <summary>Details</summary>
Motivation: To adapt model-card methodologies for the digital forensics domain, enabling transparent, consistent representation of forensic knowledge and processes, and facilitating evaluation, reuse, and adoption.

Method: Proposes a web-based framework with defined model-card structure and controlled vocabularies, including classification, types of reasoning, bias identification, and error categorization; provides a beta generator tool and seeks community feedback to refine the standard.

Result: Description of a beta version of the generator tool, along with the model-card structure and controlled vocabularies; a foundation for systematic representation of forensic knowledge and processes.

Conclusion: A standardized model-card framework for digital and web forensics can enhance transparency and comparability; iterative refinement via community feedback is planned; the abstract also flags systemic risk from external pressures (mob influence) affecting anti-fraud and forensic processes.

Abstract: This paper introduces a standardized model card framework specifically designed for digital and web forensics. Building upon established model card methodologies and recent work on abstract models for digital forensic analysis, this paper presents a web based framework that generates model cards specifically designed to represent knowledge in the forensic domain. The framework includes controlled vocabularies for classification, reasoning types, bias identification, and error categorization, along with a web-based generator tool to facilitate adoption. The paper describes the model card structure, presents the controlled vocabularies, and introduces the beta version of the generator tool, inviting community feedback to refine this emerging standard. Ultimately, the systemic risk is that that the anti fraud and digital and web forensics processes are controlled by the mobs.

</details>


### [17] [Methods and Tools for Secure Quantum Clouds with a specific Case Study on Homomorphic Encryption](https://arxiv.org/abs/2512.17748)
*Aurelia Kusumastuti,Nikolay Tcholtchev,Philipp Lämmel,Sebastian Bock,Manfred Hauswirth*

Main category: cs.CR

TL;DR: 将量子云安全性作为核心，研究将同态加密（HE）与 Eclipse Qrisp 集成以保护量子云平台，评估三种后量子密码学算法的可行性与性能，给出未来量子云的安全要点与标准化建议。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的普及，传统加密面临潜在威胁，亟需量子抗性加密和对量子云基础设施的保护机制；将 HE 融入量子计算框架可以在数据存储与处理阶段提供更强的隐私保护与安全性。

Method: 评估 HE 与 Eclipse Qrisp 的技术可行性，分析三种 PQC 算法在该集成中的实现、运行时与内存开销的权衡，并提出针对量子云体系架构的影响评估与安全策略建议。

Result: 实现并将 HE 与 Eclipse Qrisp 集成的三个 PQC 算法可行，QOTP 具备简单性与低开销；Chen 与 GSW 在运行时和内存消耗方面存在性能权衡。研究给出对量子云安全的综合建议，如在数据存储与处理层实现 HE、发展量子密钥分发（QKD）、加强访问控制/认证，以及参与 PQC 标准化工作。

Conclusion: 将 HE 融入量子云平台是可行且具有实际价值的方向，未来量子云架构应将数据层的加密、密钥管理和访问控制等与 PQC 标准化协同推进，以提升整体安全性与隐私保护水平。

Abstract: The rise of quantum computing/technology potentially introduces significant security challenges to cloud computing, necessitating quantum-resistant encryption strategies as well as protection schemes and methods for cloud infrastructures offering quantum computing time and services (i.e. quantum clouds). This research explores various options for securing quantum clouds and ensuring privacy, especially focussing on the integration of homomorphic encryption (HE) into Eclipse Qrisp, a high-level quantum computing framework, to enhance the security of quantum cloud platforms. The study addresses the technical feasibility of integrating HE with Qrisp, evaluates performance trade-offs, and assesses the potential impact on future quantum cloud architectures.The successful implementation and Qrisp integration of three post-quantum cryptographic (PQC) algorithms demonstrates the feasibility of integrating HE with quantum computing frameworks. The findings indicate that while the Quantum One-Time Pad (QOTP) offers simplicity and low overhead, other algorithms like Chen and Gentry-Sahai-Waters (GSW) present performance trade-offs in terms of runtime and memory consumption. The study results in an overall set of recommendations for securing quantum clouds, e.g. implementing HE at data storage and processing levels, developing Quantum Key Distribution (QKD), and enforcing stringent access control and authentication mechanisms as well as participating in PQC standardization efforts.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [18] [Timely Information Updating for Mobile Devices Without and With ML Advice](https://arxiv.org/abs/2512.17381)
*Yu-Pin Hsu,Yi-Hsuan Tseng*

Main category: cs.NI

TL;DR: 本论文提出一种信息更新系统中的在线更新调度算法，在仅基于可获得观测的前提下实现对时效性与更新成本的最优权衡，且在对手可同时操控多种不确定性（操作时长、信息陈旧性、更新成本、更新机会可用性）的对抗性环境中实现最优竞争比。通过将机器学习（ML）建议引入设计，提出ML增强算法，在对手可额外污染ML建议的情况下仍能实现一致性-鲁棒性权衡的最优解。竞争比随更新成本区间线性增长，但对其他不确定性不受影响。最终更新策略对ML建议呈现阈值型：要么完全信任要么完全忽略，部分信任無法在不严重削弱鲁棒性的前提下提升一致性。大量随机环境的仿真验证了理论结论。


<details>
  <summary>Details</summary>
Motivation: 在移动设备对物理过程进行状态更新并传输给接入点的场景中，需在信息的时效性（新鲜度）和设备更新成本之间权衡，并面对多源不确定性与潜在对手的攻击性建模。

Method: 构建基于可观测信息的在线更新触发策略，并在对手可同时控制更新时长、信息陈旧性、更新成本和更新机会的恶意环境中进行竞争分析，设计算法以实现对比 adversary 的最优竞争比；引入对ML建议的鲁棒处理，设计ML增强的在线算法，探索对ML建议的使用阈值性策略（信任/不信任）。

Result: 所提出的在线算法在对手 adversary 的情形下达到理论上的最优竞争比；ML增强算法实现一致性-鲁棒性权衡的最优解，并且该竞争比随更新成本范围线性增长且不受其他不确定性影响；在仿真中，阈值型对ML建议的使用被证明能在提高一致性的同时保持鲁棒性，且在随机设定中验证了理论结论。

Conclusion: 给出在高不确定性对抗环境下的在线更新调度框架，证明对ML建议的阈值性信任机制与成本-时效权衡的最优性，以及在实际系统中对抗鲁棒的实现路径与应用前景。

Abstract: This paper investigates an information update system in which a mobile device monitors a physical process and sends status updates to an access point (AP). A fundamental trade-off arises between the timeliness of the information maintained at the AP and the update cost incurred at the device. To address this trade-off, we propose an online algorithm that determines when to transmit updates using only available observations. The proposed algorithm asymptotically achieves the optimal competitive ratio against an adversary that can simultaneously manipulate multiple sources of uncertainty, including the operation duration, the information staleness, the update cost, and the availability of update opportunities. Furthermore, by incorporating machine learning (ML) advice of unknown reliability into the design, we develop an ML-augmented algorithm that asymptotically attains the optimal consistency-robustness trade-off, even when the adversary can additionally corrupt the ML advice. The optimal competitive ratio scales linearly with the range of update costs, but is unaffected by other uncertainties. Moreover, an optimal competitive online algorithm exhibits a threshold-like response to the ML advice: it either fully trusts or completely ignores the ML advice, as partially trusting the advice cannot improve the consistency without severely degrading the robustness. Extensive simulations in stochastic settings further validate the theoretical findings in the adversarial environment.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [19] [Hermitian Hulls of Rational Algebraic Geometry Codes and Applications in Quantum Codes](https://arxiv.org/abs/2512.17128)
*Lin Sok,Martianus Frederic Ezerman,Ling San*

Main category: cs.IT

TL;DR: 通过代数几何码和希尔曼对称内积的船尾部结构，给出可设计的 Hermitian 船头维数下界，并据此构造新参数的 MDS 量子纠错码（EAQECCs）。


<details>
  <summary>Details</summary>
Motivation: 在线性码的 Hull 维数研究中，Hermitian 内积下的结构比 Euclidean 更具挑战性。本文旨在利用一变量代数函数场工具，系统地估计一般化有理代数几何码的 Hermitian hull 维数，并据此为设计 EAQECC 提供新的可行参数。

Method: 利用一变量代数函数场的技巧，对一般化有理代数几何码的 Hermitian hull 维数给出下界；通过选择评价点使与 Hermitian 对偶码相关的 Weil 微分的留数具有易于验证的性质，来估计 hull；基于已知的 Reed-Solomon 及其广义扩展的结果，构造具有设计 hull 维数的码；在这些带设计 hull 的最大距离可并的码（MDS）上应用 Hermitian 方法，得到两族新的 MDS EAQECC。

Result: 给出两族新的参数优秀的 MDS EAQECC，它们来自对带设计 hull 维数的 AG 码的 Hermitian 构造，且这些量子码的参数在已知文献中是新的。

Conclusion: 所提出的方法为利用 AG 码在 Hermitian 情况下的 hull 维数进行设计，并通过对 Weil 微分留数的控制实现可验证的 hull 下界，进而得到参数新颖的 MDS EAQECC。

Abstract: Interest in the hulls of linear codes has been growing rapidly. More is known when the inner product is Euclidean than Hermitian. A shift to the latter is gaining traction. The focus is on a code whose Hermitian hull dimension and dual distance can be systematically determined. Such a code can serve as an ingredient in designing the parameters of entanglement-assisted quantum error-correcting codes (EAQECCs).
  We use tools from algebraic function fields of one variable to efficiently determine a good lower bound on the Hermitian hull dimensions of generalized rational algebraic geometry (AG) codes. We identify families of AG codes whose hull dimensions can be well estimated by a lower bound. Given such a code, the idea is to select a set of evaluation points for which the residues of the Weil differential associated with the Hermitian dual code has an easily verifiable property.
  The approach allows us to construct codes with designed Hermitian hull dimensions based on known results on Reed-Solomon codes and their generalization. Using the Hermitian method on these maximum distance separable (MDS) codes with designed hull dimensions yields two families of MDS EAQECCs. We confirm that the excellent parameters of the quantum codes from these families are new.

</details>


### [20] [Quasi-recursive MDS Matrices over Galois Rings](https://arxiv.org/abs/2512.17256)
*Shakir Ali,Atif Ahmad Khan,Abhishek Kesarwani,Susanta Samanta*

Main category: cs.IT

TL;DR: 提出一种基于伽罗斯环和斜多项式环的新直接构造方法，用以生成准递归的MDS矩阵，并给出多项式判定准则及其右根相关的Wedderburn条件；在非交换设定下显著扩展矩阵族，适用于密码学扩散层应用，特别是s=1、p=2时的实现。


<details>
  <summary>Details</summary>
Motivation: 扩展现有递归MDS矩阵的构造至非交换的Galois环，增加矩阵族规模并提升在密码学扩散层中的应用潜力。

Method: 利用 GR(p^s, p^{sm})[X;σ] 的斜多项式环及其丰富的分解性质，构造伴随矩阵生成准递归MDS矩阵；提出两条用于判定能产生递归MDS矩阵的准则，并给出一个基于相关 Wedderburn 多项式右根的附加准则；据此设计斜多项式以生成目标矩阵，拓展到非交换设定。

Result: 给出判定多项式的两个准则及一个关于Wedderburn多项式右根的附加准则；建立从斜多项式到准递归MDS矩阵的直接构造框架；在非交换设置下显著扩展可用矩阵族，提升实际实现潜力。

Conclusion: 该框架对 s=1 且 p=2（即有限域 F_{2^m}）的实用实现尤为相关，并对现实世界的密码学应用具有潜在意义。

Abstract: Let $p$ be a prime and $s,m,n$ be positive integers. This paper studies quasi-recursive MDS matrices over Galois rings $GR(p^{s}, p^{sm})$ and proposes various direct construction methods for such matrices. The construction is based on skew polynomial rings $GR(p^{s}, p^{sm})[X;σ]$, whose rich factorization properties and enlarged class of polynomials are used to define companion matrices generating quasi-recursive MDS matrices. First, two criteria are established for characterizing polynomials that yield recursive MDS matrices, generalizing existing results, and then an additional criterion is derived in terms of the right roots of the associated Wedderburn polynomial. Using these criteria, methods are developed to construct skew polynomials that give rise to quasi-recursive MDS matrices over Galois rings. This framework extends known constructions to the non-commutative setting and significantly enlarges the family of available matrices, with potential applications to efficient diffusion layers in cryptographic primitives. The results are particularly relevant for practical implementations when $s = 1$ and $p = 2$, i.e., over the finite field $\mathbb{F}_{2^m}$, which is of central interest in real-world cryptographic applications.

</details>


### [21] [A distance-free approach to generalized weights](https://arxiv.org/abs/2512.17542)
*Andrea Di Giusto,Elisa Gorla,Alberto Ravagnani*

Main category: cs.IT

TL;DR: 提出了一个统一的广义权重框架：通过一个测试族将线性码与若干子空间的交集定义权重，能够从中导出广义汉明、秩度、sum-rank等的性质，并给出对偶性及单调性等结果。


<details>
  <summary>Details</summary>
Motivation: 解决在不同距离下对线性码的广义权重的统一定义与性质问题，避免仅依赖支持集或反码，提出一个可通过选择测试族来揭示权重性质的通用框架。

Method: 定义测试族并通过码与该族的交集来定义权重；在一般框架下证明广义权重的弱单调性，以及部分子序列的严格递增；给出类似 Wei 对偶定理的对偶性结论；通过选取最佳反码、以及针对 sum-rank、MDS/MRD 的特殊测试族，将通用结果退化为已知的广义权重情形或近似情形，并扩展对包含非零汉明分量的和秩码的对偶性。

Result: 给出一个统一的理论框架及其性质：广义权重在一般测试族下具备弱单调性，某些子序列严格递增；存在与 Wei 类似的对偶性；不同测试族可还原为广义汉明、秩权重及 sum-rank 权重的结果，并在特定情形（如 MDS/MRD、非零汉明分量的和秩码）获得扩展性的对偶结论。

Conclusion: 该框架提供了一种统一视角来理解不同距离下的广义权重，通过选择不同测试族可以得到具体情形的权重及对偶性质，拓展了对 sum-rank 等新情形的理解，并与现有结构（如最佳反码、MDS/MRD）相吻合或扩展。

Abstract: We propose a unified theory of generalized weights for linear codes endowed with an arbitrary distance. Instead of relying on supports or anticodes, the weights of a code are defined via the intersections of the code with a chosen family of spaces, which we call a test family. The choice of test family determines the properties of the corresponding generalized weights and the characteristics of the code that they capture. In this general framework, we prove that generalized weights are weakly increasing and that certain subsequences are strictly increasing. We also prove a duality result reminiscent of Wei's Duality Theorem. The corresponding properties of generalized Hamming and rank-metric weights follow from our general results by selecting optimal anticodes as a test family. For sum-rank metric codes, we propose a test family that results in generalized weights that are closely connected to -- but not always the same as -- the usual generalized weights. This choice allows us to extend the known duality results for generalized sum-rank weights to some sum-rank-metric codes with a nonzero Hamming component. Finally, we explore a family of generalized weights obtained by intersecting the underlying code with MDS or MRD codes.

</details>


### [22] [Locally-APN Binomials with Low Boomerang Uniformity in Odd Characteristic](https://arxiv.org/abs/2512.17603)
*Namhun Koo,Soonhak Kwon,Minwoo Ko,Byunguk Kim*

Main category: cs.IT

TL;DR: 在特定条件下，F_r(x)=x^r+x^{r+(q-1)/2}在有限域F_q上局部APN且boomerang谱不超过2；并研究F_3、F_{(2q-1)/3}的微分谱，以及F_2在p=3时的boomerang谱。


<details>
  <summary>Details</summary>
Motivation: 扩展已有关于q ≡ 3 mod 4 下对幂多项的局部-APN性和boomerang谱的认识，给出更宽的参数条件下的鲁棒性界限，并分析具体幂的微分谱与boomerang谱以深化对这类函数在有限域中的差分性质与安全性评估。

Method: 通过对χ符号条件（高斯符号）与幂多项差分方程的解计数分析，结合 gcd(r,q-1) | 2 的约束，扩展前人工作得到局部APN性与boomerang谱界；随后计算并给出F_3、F_{(2q-1)/3} 的微分谱，以及在 p=3 时 F_2 的 boomerang谱。

Result: 若存在至多一个x∈F_q，使 χ(x)=χ(x+1)=1 且 (x+1)^r - x^r = b 对所有 b∈F_q^* 成立，且 gcd(r,q-1) | 2，则 F_r 在 F_q 上局部APN，boomerang谱不超过 2；并给出 F_3、F_{(2q-1)/3} 的微分谱，以及 F_2 在 p=3 时的 boomerang谱的具体分析结果。

Conclusion: 本文将前人结果进一步推广至更广的参数范围，揭示在特定高斯符号条件与阶的约束下，代数幂多项在有限域的差分与boomerang性质具有稳定界限，为设计具鲁棒差分特性的新型的有限域函数提供条件性证据。

Abstract: Recently, several studies have shown that when $q\equiv3\pmod{4}$, the function $F_r(x)=x^r+x^{r+\frac{q-1}{2}}$ defined over $\mathbb{F}_q$ is locally-APN and has boomerang uniformity at most~$2$. In this paper, we extend these results by showing that if there is at most one $x\in \mathbb{F}_q$ with $χ(x)=χ(x+1)=1$ satisfying $(x+1)^r - x^r = b$ for all $b\in \mathbb{F}_q^*$ and $\gcd(r,q-1)\mid 2$, then $F_r$ is locally-APN with boomerang uniformity at most $2$. Moreover, we study the differential spectra of $F_3$ and $F_{\frac{2q-1}{3}}$, and the boomerang spectrum of $F_2$ when $p=3$.

</details>


### [23] [Iterative Gaussian Approximation for Random Spreading Unsourced Random Access](https://arxiv.org/abs/2512.17628)
*Liandong Hu,Jian Dang,Zaichen Zhang*

Main category: cs.IT

TL;DR: 提出一种通用于 RS-URA 类别的迭代高斯近似解码器，适用于 RS-URA 的随机扩频结构，能在少数活动用户场景下接近理论极限，且迭代次数少、收敛快。


<details>
  <summary>Details</summary>
Motivation: 面向大规模机器类型通信(mMTC)对广泛连接的鲁棒和高效需求，URA 尤其是随机扩频的 RS-URA 作为降低干扰、提高频谱与能量效率的关键技术，需接近高斯多址信道极限的解码方案。

Method: 提出一个通用于 RS-URA 类别的迭代高斯近似解码器。所述解码器通过迭代外信息与内信息（extrinsic/intrinsic soft information）实现 soft-output 解码，且收敛只需少量迭代。

Result: 数值结果表明该解码器在性能与鲁棒性方面有效，能在不同 RS-URA 场景中提升解码性能并保持鲁棒性。

Conclusion: 提出的通用迭代高斯近似解码框架在 RS-URA 中具有良好的性能、快速收敛性和广泛适用性，能够有效提升低活动用户数情形下的解码能力。

Abstract: Massive machine-type communications (mMTC) demand robust solutions to support extensive connectivity efficiently. Unsourced random access (URA) has emerged as a promising approach, delivering high spectral and energy efficiency. Among URA code structures, the random spreading (RS) category is a key enabler, providing strong anti-interference capabilities through spectrum spreading gain. Notably, RS-URA approaches theoretical performance limits over the Gaussian multiple access channel in scenarios with few active users. In this paper, we propose an iterative Gaussian approximation decoder designed universally for RS-URA categories. The proposed receiver iterates extrinsic and intrinsic soft information to enhance decoding performance, requiring only a few iterations to converge. Numerical results validate the decoder's effectiveness in terms of performance and robustness.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [24] [Packet Detection in a Filter Bank-Based Ultra-Wideband Communication System](https://arxiv.org/abs/2512.17055)
*Brian Nelson,Behrouz Farhang-Boroujeny*

Main category: eess.SP

TL;DR: 提出基于FBMC-SS的SRB/MRB探测器用于UWB系统，通过Rao score test设计分级通道器，以在中等采样率实现性能与高采样率方案相当的检测，并在1.28 GHz带宽的OTA实验中实现极低SNR下可靠检测（-40 dB，预置半长IEEE802.15.4预码）。


<details>
  <summary>Details</summary>
Motivation: 在超宽带系统中需要极宽带宽的信号处理，但高采样率ADC/DAC成本高、实现困难。FBMC-SS的谱分割特性允许使用并行处理的中速采样率来合成/处理UWB信号，因此有机会在降低采样率的同时保持检测性能。

Method: 从单信号处理器出发，设计基于Rao score检验的分组检测器；利用FBMC-SS结构提出级联通道分析器(Model Cascade Channelizer)来实现探测，命名为单射频带(SRB)探测器。考虑到500 MHz及以上带宽要求，SRB需>500 MHz采样率，因而扩展为多射频带(MRB)探测器，使用并行处理器在中等采样率下实现。通过数值仿真比较SRB与MRB在典型UWB信道中的性能；并给出1.28 GHz带宽的OTA实测结果。

Result: SRB与MRB探测器在典型UWB信道中具有相同的检测性能；OTA实验表明在恶劣环境下也能实现可靠检测，-40 dB SNR，半长度的预码（≈IEEE802.15.4标准最长预码的一半）即可达到可靠检测。

Conclusion: 基于FBMC-SS的SRB/MRB探测框架在降低ADE/ADC/DAC采样率要求的同时保持检测性能，具备在实际UWB系统中的应用潜力，并在OTA中验证了在宽带条件下的可行性。

Abstract: Recently, filter bank multi-carrier spread spectrum (FBMC-SS) technology has been proposed for use in ultra-wideband (UWB) communication systems. It has been noted that, due to the spectral partitioning properties of the filter banks, a UWB signal can be synthesized and processed using a parallel set of signal processors operating at a moderate rate. This transceiver architecture can be used to generate UWB signals, without requiring a high-rate analog-to-digital and/or digital-to-analog converter. In this paper, beginning with a design operating on a single signal processor, we explore the development of a packet detector using the Rao score test. Taking advantage of the FBMC-SS signal structure, an effective detector design based on a cascade channelizer is proposed. We refer to this design as singe-radio band (SRB) detector. Given the typical bandwidth of UWB systems ($\bf 500$~MHz or wider), the SRB detector has to operate at a fast sampling rate of greater than $\bf 500$~MHz. This may be undesirable, as low cost analog-to-digital (ADC) and digital-to-analog (DAC) converters are often limited to a sampling rate of $\bf 200$~MHz or lower. Taking note of this point, the proposed SRB detector is extended to a multi-radio band (MRB) detector, where a set of parallel signal processors operating at a moderate sampling rate are used for a more practical implementation of the detector. Through computer simulations, we show that SRB and MRB detectors have the same performance in typical UWB channels. Finally, we provide results from an over-the-air demonstration of a UWB design occupying $\bf 1.28$~GHz of bandwidth. We find that reliable detection performance is possible in the harshest environments, at signal-to-noise ratios as low as $\bf -40$~dB with a preamble length of approximately half the duration of longest preamble length recommended in the IEEE802.15.4 standard.

</details>


### [25] [Deep Reinforcement Learning-Aided Strategies for Big Data Offloading in Vehicular Networks](https://arxiv.org/abs/2512.17133)
*Talha Akyildiz,Hessam Mahdavifar*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider vehicular networking scenarios where existing vehicle-to-vehicle (V2V) links can be leveraged for an effective uploading of large-size data to the network. In particular, we consider a group of vehicles where one vehicle can be designated as the \textit{leader} and other \textit{follower} vehicles can offload their data to the leader vehicle or directly upload it to the base station (or a combination of the two). In our proposed framework, the leader vehicle is responsible for receiving the data from other vehicles and processing it in order to remove the redundancy (deduplication) before uploading it to the base station. We present a mathematical framework of the considered network and formulate two separate optimization problems for minimizing (i) total time and (ii) total energy consumption by vehicles for uploading their data to the base station. We employ deep reinforcement learning (DRL) tools to obtain solutions in a dynamic vehicular network where network parameters (e.g., vehicle locations and channel coefficients) vary over time. Our results demonstrate that the application of DRL is highly beneficial, and data offloading with deduplication can significantly reduce the time and energy consumption. Furthermore, we present comprehensive numerical results to validate our findings and compare them with alternative approaches to show the benefits of the proposed DRL methods.

</details>


### [26] [Active RIS-Aided Anti-Jamming Wireless Communications: A Stackelberg Game Perspective](https://arxiv.org/abs/2512.17335)
*Xiao Tang,Zhen Ma,Bin Li,Cong Li,Qinghe Du,Dusit Niyato,Zhu Han*

Main category: eess.SP

TL;DR: 提出了基于主动可重构智能表面的 anti-jamming 通信方案，采用 Stackelberg 博弈模型，领导者为合法用户，预测并嵌入干扰者的最优策略；通过双层优化和分块坐标下降求解，证明存在 Stackelberg 均衡，算法在多场景下优于基线方案。


<details>
  <summary>Details</summary>
Motivation: 对抗自适应干扰（jammer）对无线通信的威胁日益严重，需新型抗干扰技术。主动 RIS 可提供可控信道改造，结合博弈论可在不完全信息或对抗环境下优化资源配置，提升合法传输质量并削弱干扰。

Method: 将合法系统与自适应干扰者的互动建模为 Stackelberg 博弈，领导者（合法用户）先设计传输策略并预期干扰者的最优响应；干扰者最优策略被嵌入领导者问题，形成双层优化，联合优化合法的发射功率、发射/接收波束、以及主动反射参数；通过分块坐标下降求解，子问题采用凸松弛与序列凸近似逐步收敛。

Result: 证明存在 Stackelberg 均衡；给出可实现的求解流程（BCD+凸松弛/近似），并通过仿真验证主动 RIS 助力的方案在提升合法传输和降低干扰方面显著优于基线，在多种场景下均具优势。

Conclusion: 主动 RIS 与博弈论框架的结合在抗干扰通信中有效，通过策略性的资源分配和信道控制实现对自适应干扰的鲁棒性提升。

Abstract: The pervasive threat of jamming attacks, particularly from adaptive jammers capable of optimizing their strategies, poses a significant challenge to the security and reliability of wireless communications. This paper addresses this issue by investigating anti-jamming communications empowered by an active reconfigurable intelligent surface. The strategic interaction between the legitimate system and the adaptive jammer is modeled as a Stackelberg game, where the legitimate user, acting as the leader, proactively designs its strategy while anticipating the jammer's optimal response. We prove the existence of the Stackelberg equilibrium and derive it using a backward induction method. Particularly, the jammer's optimal strategy is embedded into the leader's problem, resulting in a bi-level optimization that jointly considers legitimate transmit power, transmit/receive beamformers, and active reflection. We tackle this complex, non-convex problem by using a block coordinate descent framework, wherein subproblems are iteratively solved via convex relaxation and successive convex approximation techniques. Simulation results demonstrate the significant superiority of the proposed active RIS-assisted scheme in enhancing legitimate transmissions and degrading jamming effects compared to baseline schemes across various scenarios. These findings highlight the effectiveness of combining active RIS technology with a strategic game-theoretic framework for anti-jamming communications.

</details>


### [27] [BM4D-PC: nonlocal volumetric denoising of principal components of diffusion-weighted MR images](https://arxiv.org/abs/2512.17138)
*Vinicius P. Campos,Diego Szczupak,Tales Santini,Afonso C. Silva,Alessandro Foi,Marcelo A. C. Vieira,Corey A. Baron*

Main category: eess.SP

TL;DR: 提出 BM4D-PC 的 dMRI 去噪新方法。通过在 PCA 分解后的 diffusion 权重图像的主成分上应用 BM4D，结合完整噪声统计（PSD），实现对空间相关噪声的有效建模，并可直接估计噪声图和 PSD；在合成和真实数据上均展现出优于四种对比方法的性能。


<details>
  <summary>Details</summary>
Motivation: dMRI 的噪声由于采集与重建策略的不同而呈现空间相关性，现有去噪方法未充分建模噪声特性，亟需一种能够利用完整噪声统计信息的去噪框架；以提升去噪效果、保留细节并改善扩散指标为目标。

Method: 提出以 BM4D 为核心的去噪策略，利用噪声功率谱密度（PSD）等完整噪声统计信息；将 BM4D 应用于通过对整个 DWI 数据集进行 PCA 分解得到的主成分，从而挖掘跨扩散方向的 Redundancy（BM4D-PC）。方法还可直接估计噪声映射及 PSD。对比研究包括在体外仿真与体内高分辨率人类和卷尾猴数据，和四种现有方法的对比评估。

Result: 在合成数据中，BM4D-PC 在 PSNR、SSIM、RMSE 三项指标上均表现最好；在体内数据中，BM4D-PC 显著提升原始 DWI 的图像质量，在噪声抑制和细节保留方面优于对比方法，并改善了扩散指标的质量。

Conclusion: BM4D-PC 能在多种采集策略与分辨率下实现前沿的 dMRI 去噪效果，为神经科学研究中的扩散分析提供更高质量的数据支撑。

Abstract: Purpose: Noise in diffusion-weighted MRI (dMRI) is often spatially correlated due to different acquisition and reconstruction strategies, which is not fully accounted for in current denoising strategies. Thus, we propose a novel model-based denoising method for dMRI that effectively accounts for the different noise characteristics of data. Methods: We propose a denoising strategy that incorporates full noise statistics, including the noise power spectral density (PSD), by leveraging the BM4D algorithm. Furthermore, to exploit redundancy across the diffusion MRI dataset, BM4D is applied to principal components (PC) of diffusion-weighted images (DWI) obtained through principal component analysis (PCA) decomposition of the entire DWI dataset, an approach we refer to as BM4D-PC. Importantly, our method also allows for direct estimation of both the noise map and PSD. We evaluated BM4D-PC against four existing state-of-the-art methods using in-silico and in vivo datasets, including high-resolution human and marmoset acquisitions. Results: Overall, BM4D-PC presented the best results for the metrics PSNR, SSIM and RMSE on the in-silico experiments. The in-vivo studies also showed that BM4D-PC dramatically enhanced the image quality of raw DWIs, outperforming existing denoising methods in terms of noise suppression and detail preservation, leading to improved quality of diffusion metrics. Conclusion: The proposed BM4D-PC method demonstrated state-of-the-art denoising results for dMRI using datasets from various acquisition strategies and image resolutions, potentially supporting future advances in neuroscience research.

</details>


### [28] [Near-Field Position and Orientation Tracking With Hybrid ELAA Architecture](https://arxiv.org/abs/2512.17274)
*Lin Chen,Xiaojun Yuan,Ying-Jun Angela Zhang*

Main category: eess.SP

TL;DR: Proposes predictive analog combining with an extended Kalman filter (PAC-EKF) for near-field pose tracking using ELAA at the base station under limited RF chains; analyzes fundamental limits with Bayesian CRB; develops two low-complexity analog combiner designs; shows improved tracking with fewer RF chains and lower transmit power.


<details>
  <summary>Details</summary>
Motivation: Enable accurate near-field position and orientation tracking in ELAA-based systems under hardware constraints (limited RF chains and analog compression) by preserving pose-relevant signal components and leveraging temporal pose correlation.

Method: Introduce PAC-EKF that uses an analog combiner to form informative low-dimensional observations, model temporal pose dynamics, analyze Fisher information and Bayesian CRB to quantify pose information under unit-modulus analog hardware, and design two low-complexity analog combiners.

Result: Analytical bounds quantify the impact of analog combiner, array size, SNR, and pose on achievable information; numerical experiments show substantial tracking accuracy gains with predictive analog combining even with few RF chains and reduced transmit power.

Conclusion: Predictive analog combining with EKF enhances NF pose tracking in ELAA systems under hardware constraints; the proposed designs provide practical, low-complexity solutions that improve information capture and tracking performance.

Abstract: This paper investigates near-field (NF) position and orientation tracking of a multi-antenna mobile station (MS) using an extremely large antenna array (ELAA)-equipped base station (BS) with a limited number of radio frequency (RF) chains. Under this hybrid array architecture, the received uplink pilot signal at the BS is first combined by analog phase shifters, producing a low-dimensional observation before digital processing. Such analog compression provides only partial access to the ELAA measurement, making it essential to design an analog combiner that can preserve pose-relevant signal components despite channel uncertainty and unit-modulus hardware constraints. To address this, we propose a predictive analog combining-assisted extended Kalman filter (PAC-EKF) framework, where the analog combiner can leverage the temporal correlation in the MS pose variation to capture the most informative signal components predictively. We then analyze fundamental performance limits via Bayesian Cramér-Rao bound and Fisher information matrix, explicitly quantifying how the analog combiner, array size, signal-to-noise ratio, and MS pose influence the pose information contained in the uplink observation. Building on these insights, we develop two methods for designing a low-complexity analog combiner. Numerical results show that the proposed predictive analog combining approach significantly improves tracking accuracy, even with fewer RF chains and lower transmit power.

</details>


### [29] [Near-Field Multi-User Communications via Polar-Domain Beamfocusing: Analytical Framework and Performance Analysis](https://arxiv.org/abs/2512.17283)
*Lin Chen,Ahmed Elzanaty,Mustafa A. Kishk,Ying-Jun Angela Zhang*

Main category: eess.SP

TL;DR: 提出了一种近场多级天线模式（NF-MLAP）的近场分析框架，结合极域波前与随机几何，用以分析极大尺度阵列下的近场多用户系统。通过可计算的上界和表达式，展示覆盖、频谱效率和区域频谱效率的性能，并揭示天线数量与射频链路数等硬件配置与系统性能之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 随着频率升高和天线阵列规模增大，近场传播成为主导特性。近场允许在角度和距离上进行波束聚焦（极域），带来新的空间多址机会，但角-距离耦合使干扰分析复杂。需要一个既能反映近场传播特性又具备数值可分析性的框架。

Method: 建立一个分析性随机几何框架，结合近场传播的角–距离耦合；提出近场多级天线模式（NF-MLAP）近似以简化耦合并得到可计算的覆盖概率、频谱效率和区域频谱效率的表达及上界；通过理论分析与仿真验证分析框架的准确性与趋势。

Result: 框架能够准确捕捉性能趋势，给出硬件配置（天线数、射频链路数）与系统性能（空间资源重用、干扰抑制）之间的关键权衡，并给出紧贴实际性能的上界。

Conclusion: NF-MLAP与SG框架为近场大规模天线系统的性能分析提供了一个可行且计算友好的工具，便于硬件设计和系统优化，强调近场效应在多用户空间资源管理中的重要性。

Abstract: As wireless systems evolve toward higher frequencies and extremely large antenna arrays, near-field (NF) propagation becomes increasingly dominant. Unlike far-field (FF) communication, which relies on a planar-wavefront model and is limited to angular-domain beamsteering, NF propagation exhibits spherical wavefronts that enable beamfocusing in both angle and distance, i.e., the polar domain, offering new opportunities for spatial multiple access. This paper develops an analytical stochastic geometry (SG) framework for a multi-user system assisted by polar-domain beamfocusing, which jointly captures NF propagation characteristics and the spatial randomness of user locations. The intrinsic coupling between angle and distance in the NF antenna pattern renders inter-user interference analysis intractable. To address this challenge, we propose a tractable near-field multi-level antenna pattern (NF-MLAP) approximation, which enables computationally efficient expressions and tight upper bounds for key performance metrics, including coverage probability, spectrum efficiency, and area spectrum efficiency. Analytical and simulation results demonstrate that the proposed framework accurately captures performance trends and reveals fundamental trade-offs between hardware configuration (including the number of antennas and radio frequency chains) and system performance (in terms of spatial resource reuse and interference mitigation).

</details>


### [30] [OpenPathNet: An Open-Source RF Multipath Data Generator for AI-Driven Wireless Systems](https://arxiv.org/abs/2512.17286)
*Lizhou Liu,Xiaohui Chen,Wenyi Zhang*

Main category: eess.SP

TL;DR: OpenPathNet: 一个开源的射频多径数据生成器及数据集，提供逐路径参数（增益、到达时间、空间角度）及高精度射线追踪，支持再现性、可扩展性，促进AI驱动的6G无线研究。


<details>
  <summary>Details</summary>
Motivation: 在AI与6G无线融合背景下，迫切需要大规模、高保真、可重复的射频数据集。现有资源（如CKMImageNet）多为预处理的图像化信道表示，未能保留信号传播的物理细节，制约AI建模与泛化。

Method: 采用模块化、参数化的数据生成流水线，基于现实世界环境地图进行高精度射线追踪，得到逐路径的增益、到达时间和空间角等物理一致的多径参数；可扩展至新的环境与配置，具备可重复性。

Result: 提供开源的数据生成器与数据集，构成一个可扩展的测试平台；有望在信道建模、波束预测、环境感知通信和AI驱动的6G系统的感知与综合应用方面推进研究。

Conclusion: OpenPathNet通过提供物理一致、可扩展且透明的多径数据，推动AI驱动无线研究的发展，并促进实验的可重复性与可比性。

Abstract: The convergence of artificial intelligence (AI) and sixth-generation (6G) wireless technologies is driving an urgent need for large-scale, high-fidelity, and reproducible radio frequency (RF) datasets. Existing resources, such as CKMImageNet, primarily provide preprocessed and image-based channel representations, which conceal the fine-grained physical characteristics of signal propagation that are essential for effective AI modeling. To bridge this gap, we present OpenPathNet, an open-source RF multipath data generator accompanied by a publicly released dataset for AI-driven wireless research. Distinct from prior datasets, OpenPathNet offers disaggregated and physically consistent multipath parameters, including per-path gain, time of arrival (ToA), and spatial angles, derived from high-precision ray tracing simulations constructed on real-world environment maps. By adopting a modular, parameterized pipeline, OpenPathNet enables reproducible generation of multipath data and can be readily extended to new environments and configurations, improving scalability and transparency. The released generator and accompanying dataset provide an extensible testbed that holds promise for advancing studies on channel modeling, beam prediction, environment-aware communication, and integrated sensing in AI-enabled 6G systems. The source code and dataset are publicly available at https://github.com/liu-lz/OpenPathNet.

</details>


### [31] [SCAR: Semantic Cardiac Adversarial Representation via Spatiotemporal Manifold Optimization in ECG](https://arxiv.org/abs/2512.17423)
*Shunbo Jia,Caizhi Liao*

Main category: eess.SP

TL;DR: SCAR is a novel universal adversarial perturbation (UAP) framework for ECG analysis that incorporates clinical realism via spatiotemporal smoothing (W=25 ~50ms), spectral consistency (<15 Hz), and anatomical amplitude constraints (<0.2 mV). It achieves strong transferability (58.09% on ResNet) and high source-model success (82.46%), and reveals an emergent targeted misdiagnosis by reconstructing ST-segment elevations. It also serves as a dual-use tool for data augmentation in adversarial training and as educational material for clinicians to recognize AI-targeted semantic forgeries.


<details>
  <summary>Details</summary>
Motivation: Deep ECG models are vulnerable to adversarial perturbations. Standard imperceptible noise constraints fail to generate effective universal attacks due to high inter-subject variability and lack clinical plausibility. There is a need for attacks that are both effective and believable to clinicians to assess human-in-the-loop defense.

Method: SCAR integrates spatiotemporal smoothing (W=25, ~50 ms), spectral consistency (<15 Hz), and anatomical amplitude constraints (<0.2 mV) directly into the gradient optimization. It is compared against a Standard Universal DeepFool with post-hoc physiological filtering.

Result: SCAR attains 82.46% success on the source model and 58.09% transferability on ResNet. Baseline universal DeepFool with filtering collapses to ~16% on transfer tasks. Clinically, SCAR converges to forging Myocardial Infarction features with 90.2% misdiagnosis by reconstructing ST-segment elevations. Additionally, SCAR is proposed as a data augmentation method for Hybrid Adversarial Training and as educational samples for clinicians.

Conclusion: SCAR demonstrates that physiologically constrained UAPs can robustly attack ECG classifiers and reveal clinically plausible adversarial features. It offers dual use for defense via robust training and for clinician education, but raises concerns about clinical safety and the need for robust, detection-aware defenses.

Abstract: Deep learning models for Electrocardiogram (ECG) analysis have achieved expert-level performance but remain vulnerable to adversarial attacks. However, applying Universal Adversarial Perturbations (UAP) to ECG signals presents a unique challenge: standard imperceptible noise constraints (e.g., 10 uV) fail to generate effective universal attacks due to the high inter-subject variability of cardiac waveforms. Furthermore, traditional "invisible" attacks are easily dismissed by clinicians as technical artifacts, failing to compromise the human-in-the-loop diagnostic pipeline. In this study, we propose SCAR (Semantic Cardiac Adversarial Representation), a novel UAP framework tailored to bypass the clinical "Human Firewall." Unlike traditional approaches, SCAR integrates spatiotemporal smoothing (W=25, approx. 50ms), spectral consistency (<15 Hz), and anatomical amplitude constraints (<0.2 mV) directly into the gradient optimization manifold.
  Results: We benchmarked SCAR against a rigorous baseline (Standard Universal DeepFool with post-hoc physiological filtering). While the baseline suffers a performance collapse (~16% success rate on transfer tasks), SCAR maintains robust transferability (58.09% on ResNet) and achieves 82.46% success on the source model. Crucially, clinical analysis reveals an emergent targeted behavior: SCAR specifically converges to forging Myocardial Infarction features (90.2% misdiagnosis) by mathematically reconstructing pathological ST-segment elevations. Finally, we demonstrate that SCAR serves a dual purpose: it not only functions as a robust data augmentation strategy for Hybrid Adversarial Training, offering optimal clinical defense, but also provides effective educational samples for training clinicians to recognize low-cost, AI-targeted semantic forgeries.

</details>


### [32] [Sub-6 GHz Beam-Reconfigurable Microfluidic Antenna Using Graphene Liquid for 5G Network](https://arxiv.org/abs/2512.17434)
*Sasmita Dash,Constantinos Psomas,Ioannis Krikidis*

Main category: eess.SP

TL;DR: 本工作提出一种基于石墨烯液体的可重构天线，在5.5 GHz的子6 GHz段实现360°全方位波束重构，增益6 dBi，阻抗带宽约24%，且在六种重构情形下保持稳定的反射系数。


<details>
  <summary>Details</summary>
Motivation: 为提升未来无线系统的覆盖、容量与传输质量，需要高性能且可重构的天线。液态天线具有小型化、柔性、可重构和透明等优点；石墨烯液体在导电性、成本和加工性方面具有潜在优势，且在天线应用中优于传统液态金属。

Method: 通过在微流控通道中实现石墨烯液体的定向移动来实现天线的波束重构。以5.5 GHz为工作点，天线实现360°方向的波束重构，提供六个目标方向（0°,45°,135°,180°,225°,315°），在所有方向下获得稳定的反射系数和6 dBi的增益。带宽约24%。

Result: 在5.5 GHz下实现六个重新配置场景中均具稳定的回波损耗/反射系数，且主瓣实现六个方向波束重构，最大增益为6 dBi，带宽约24%。

Conclusion: 石墨烯液体基可重构Sub-6 GHz天线具有良好前景，可为下一代无线系统提供灵活的波束控制能力和宽带特性。

Abstract: As wireless communication systems continue to grow rapidly, high-performance antennas become increasingly crucial for expanding coverage, improving capacity, and enhancing transmission quality. In light of this, research has focused considerable attention on liquid antennas due to their unique characteristics, which include small size, flexibility, reconfigurability and transparency. Recently, graphene liquid has been explored for numerous applications due to its low cost, high conductivity, flexibility, and ease of processing. Specifically for antenna applications, graphene liquid performs better than conventional liquid metal. This paper presents a graphene-liquid antenna with beam reconfiguration ability for sub-6 GHz communication system. The graphene-liquid movement within the microfluidic channel is taken into consideration by the reconfiguration mechanism. The antenna achieves beam reconfiguration in 360° directions with 6 dBi of gain at 5.5 GHz, featuring a wideband impedance bandwidth of 24%. The antenna main beam is specifically reconfigured into six directions (0°, 45°, 135°, 180°, 225° and 315°) at 5.5 GHz. Additionally, in all six reconfigurable scenarios at 5.5 GHz, the antenna provides a stable reflection coefficient. Therefore, for the next generation of wireless communication systems, this novel design of graphene-liquid-based reconfigurable sub-6 GHz antennas holds promise.

</details>


### [33] [Alternating Direction Method of Multipliers for Nonlinear Matrix Decompositions](https://arxiv.org/abs/2512.17473)
*Atharva Awari,Nicolas Gillis,Arnaud Vandaele*

Main category: eess.SP

TL;DR: 基于 ADMM 的非线性矩阵分解（NMD）方法综述与分析


<details>
  <summary>Details</summary>
Motivation: 解决在输入矩阵 X 和低秩因子 W, H 的情况下，通过对元素级非线性变换 f(·) 的处理，实现对广义非线性数据的高效近似，并在多种非线性模型与损失函数下保持灵活性和可扩展性.

Method: 将交替方向乘子法（ADMM）用于优化问题，分解为对 W、H 及相关拉格朗日对偶变量的迭代更新，处理 X ≈ f(WH) 的非线性映射。支持多种非线性函数 f（如 ReLU、平方、MinMax）及多种损失度量（最小二乘、L1、KL 散度），框架可扩展到其他非线性和指标，适合大规模稀疏或概率性数据场景。

Result: 在若干代表性非线性模型上验证了方法的可行性与高效性，展示了对不同非线性变换和损失函数的适用性，并在真实数据集上体现出良好的适配性、灵活性与潜在广泛应用前景。

Conclusion: 该框架具有较高的通用性、灵活性和扩展性，能够处理广义的非线性矩阵分解问题，未来工作可能集中在收敛性分析、对比研究、以及对更多非线性变换与损失函数的整合与优化来提升效率和鲁棒性。

Abstract: We present an algorithm based on the alternating direction method of multipliers (ADMM) for solving nonlinear matrix decompositions (NMD). Given an input matrix $X \in \mathbb{R}^{m \times n}$ and a factorization rank $r \ll \min(m, n)$, NMD seeks matrices $W \in \mathbb{R}^{m \times r}$ and $H \in \mathbb{R}^{r \times n}$ such that $X \approx f(WH)$, where $f$ is an element-wise nonlinear function. We evaluate our method on several representative nonlinear models: the rectified linear unit activation $f(x) = \max(0, x)$, suitable for nonnegative sparse data approximation, the component-wise square $f(x) = x^2$, applicable to probabilistic circuit representation, and the MinMax transform $f(x) = \min(b, \max(a, x))$, relevant for recommender systems. The proposed framework flexibly supports diverse loss functions, including least squares, $\ell_1$ norm, and the Kullback-Leibler divergence, and can be readily extended to other nonlinearities and metrics. We illustrate the applicability, efficiency, and adaptability of the approach on real-world datasets, highlighting its potential for a broad range of applications.

</details>


### [34] [Augmented Affine Frequency Division Multiplexing for Both Low PAPR Signaling and Diversity Gain Protection](https://arxiv.org/abs/2512.17679)
*Zhou Lu,Mohammed El-Hajjar,Lie-liang Yang*

Main category: eess.SP

TL;DR: 提出A2FDM以解决AFDM的PAPR问题，并通过替换c2矩阵为一个单位矩阵，同时实现子块DFT与符号映射，提出两种映射方案（交错映射和局部映射），并对复杂度、参数与性能进行分析与仿真比较。结论是A2FDM在抑制PAPR的同时可在AFDM不利条件下恢复多样性增益。


<details>
  <summary>Details</summary>
Motivation: AFDM存在PAPR问题，与OFDM类似的特性，以及AFDM中基于c2的冗余信号矩阵导致效率下降，需在降低PAPR的同时保持或恢复系统增益。

Method: 提出增广AFDM(A2FDM)，用一个新单位矩阵代替AFDM中的c2矩阵，单位矩阵实现子块DFT和符号映射；设计两种映射：Interleaved与Localized；推导输入输出关系；分析实现复杂度及系统参数对性能的影响；给出仿真以对比AFDM与A2FDM在不同设定下的表现。

Result: A2FDM能够缓解AFDM的PAPR问题，并在AFDM处于不利条件导致丧失多样性增益时，仍能获得可观的多样性增益；两种映射方案在性能与复杂度上存在权衡，仿真覆盖了多种系统设置与运行条件。

Conclusion: A2FDM为AFDM的PAPR问题提供有效缓解，同时在特定条件下可维持或恢复多样性增益；映射策略及参数选择对最终性能有显著影响，需在具体场景中做出权衡。

Abstract: Research results on Affine Frequency Division Multiplexing (AFDM) reveal that it experiences the same Peak-to-Average Power Ratio (PAPR) problem as conventional Orthogonal Frequency-Division Multiplexing (OFDM). On the other side, some references and also our studies demonstrate that AFDM involves an unneeded matrix, which is based on a parameter typically represented by $c_2$, for signalling. Hence, in this paper, an augmented AFDM scheme, referred to as A$^2$FDM, is proposed to mitigate the PAPR problem of AFDM, which is achieved by replacing the $c_2$ matrix in AFDM by a new unitary matrix that performs both sub-block-based Discrete Fourier Transform (DFT) and symbol mapping. Two symbol mapping schemes, namely interleaved mapping and localized mapping, are proposed for implementing A$^2$FDM, yielding the Interleaved A$^2$FDM and Localized A$^2$FDM. The input-output relationships of these schemes are derived and the complexity and the effects of system parameters on the performance of A$^2$FDM along with AFDM systems are analyzed. Furthermore, simulation results are provided to demonstrate and compare comprehensively the performance of the considered schemes in conjunction with different system settings and various operational conditions. Our studies and results demonstrate that, while A$^2$FDM is capable of circumventing the PAPR problem faced by AFDM, it is capable of attaining the achievable diversity gain, when AFDM is operated in its undesirable conditions resulting in the loss of the diversity gain available.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [35] [Dion2: A Simple Method to Shrink Matrix in Muon](https://arxiv.org/abs/2512.16928)
*Kwangjun Ahn,Noah Amsel,John Langford*

Main category: cs.LG

TL;DR: Dion2通过稀疏更新策略在Muon优化器中显著降低正交化成本并提升可扩展性。


<details>
  <summary>Details</summary>
Motivation: Muon优化器在正交化阶段呈现超线性成本，随着规模增长代价上升。尽管有研究试图通过缩小进入正交化的矩阵来缓解，但仍需要更简洁有效的方案。

Method: Dion2在每次迭代中选择一定比例的行或列，只有选中的子集被进行正交化，更新变得稀疏，因而降低计算和通信成本。

Result: 稀疏更新降低了总成本，提升了Muon的横向扩展性和性能。

Conclusion: Dion2提供了一种比前期工作更简单且高效的矩阵缩小策略，适用于大规模分布式环境中的Muon优化器。

Abstract: The Muon optimizer enjoys strong empirical performance and theoretical grounding. However, the super-linear cost of its orthonormalization step introduces increasing overhead with scale. To alleviate this cost, several works have attempted to reduce the size of the matrix entering the orthonormalization step. We introduce Dion2, a much simpler method for shrinking the matrix involved in Muon's computation compared to prior approaches. At a high level, Dion2 selects a fraction of rows or columns at each iteration and orthonormalizes only those. This sampling procedure makes the update sparse, reducing both computation and communication costs which in turn improves the scalability of Muon.

</details>


### [36] [BIONIX: A Wireless, Low-Cost Prosthetic Arm with Dual-Signal EEG and EMG Control](https://arxiv.org/abs/2512.16929)
*Pranesh Sathish Kumar*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Affordable upper-limb prostheses often lack intuitive control systems, limiting functionality and accessibility for amputees in low-resource settings. This project presents a low-cost, dual-mode neuro-muscular control system integrating electroencephalography (EEG) and electromyography (EMG) to enable real-time, multi-degree-of-freedom control of a prosthetic arm. EEG signals are acquired using the NeuroSky MindWave Mobile 2 and transmitted via ThinkGear Bluetooth packets to an ESP32 microcontroller running a lightweight classification model. The model was trained on 1500 seconds of recorded EEG data using a 6-frame sliding window with low-pass filtering, excluding poor-signal samples and using a 70/20/10 training--validation--test split. The classifier detects strong blink events, which toggle the hand between open and closed states. EMG signals are acquired using a MyoWare 2.0 sensor and SparkFun wireless shield and transmitted to a second ESP32, which performs threshold-based detection. Three activation bands (rest: 0--T1; extension: T1--T2; contraction: greater than T2) enable intuitive elbow control, with movement triggered only after eight consecutive frames in a movement class to improve stability. The EEG-controlled ESP32 actuates four finger servos, while the EMG-controlled ESP32 drives two elbow servos. A functional prototype was constructed using low-cost materials (total cost approximately 240 dollars), with most expense attributed to the commercial EEG headset. Future work includes transitioning to a 3D-printed chassis, integrating auto-regressive models to reduce EMG latency, and upgrading servo torque for improved load capacity and grip strength. This system demonstrates a feasible pathway to low-cost, biologically intuitive prosthetic control suitable for underserved and global health applications.

</details>


### [37] [Physics-Informed Lightweight Machine Learning for Aviation Visibility Nowcasting Across Multiple Climatic Regimes](https://arxiv.org/abs/2512.16967)
*Marcelo Cerda Castillo*

Main category: cs.LG

TL;DR: 基于 METAR 的轻量级 XGBoost 模型在11个机场的短时天气预测中优于现有 TAF，并具可解释性，适合边缘计算。


<details>
  <summary>Details</summary>
Motivation: 提升低能见度与降水等短时预报（nowcasting）的准确性与时效性，解决现有数值天气预报与 TAF 的计算成本、偏好保守性及时间分辨率不足等问题。

Method: 采用仅以 METAR 为输入的 XGBoost 轻量框架，辅以基于热力学原理的物理引导特征工程；在11个机场、覆盖2000–2024年的历史数据上评估；与运营 TAF 进行盲评估比较；通过 SHAP 进行可解释性分析。

Result: 模型在3小时战术窗口内对低能见度与降水事件的检测率显著提升，召回率提升约为2.5–4.0倍，虚警显著下降；SHAP 表明模型对平流、辐射与辈降等局部物理驱动进行了隐式重建，提供可操作的解释。

Conclusion: 该框架实现了一个轻量、可解释、跨气候区的 nowcasting 方案，仅依赖地面观测数据，具备边缘计算友好性并能提升运营态势感知。

Abstract: Short-term prediction (nowcasting) of low-visibility and precipitation events is critical for aviation safety and operational efficiency. Current operational approaches rely on computationally intensive numerical weather prediction guidance and human-issued TAF products, which often exhibit conservative biases and limited temporal resolution. This study presents a lightweight gradient boosting framework (XGBoost) trained exclusively on surface observation data (METAR) and enhanced through physics-guided feature engineering based on thermodynamic principles. The framework is evaluated across 11 international airports representing distinct climatic regimes (including SCEL, KJFK, KORD, KDEN, SBGR, and VIDP) using historical data from 2000 to 2024. Results suggest that the model successfully captures underlying local physical processes without manual configuration. In a blind comparative evaluation against operational TAF forecasts, the automated model achieved substantially higher detection rates at tactical horizons (3 hours), with a 2.5 to 4.0 times improvement in recall while reducing false alarms. Furthermore, SHAP analysis reveals that the model performs an implicit reconstruction of local physical drivers (advection, radiation, and subsidence), providing actionable explainability for operational situational awareness.
  Keywords: aviation meteorology; physics-guided machine learning; explainable artificial intelligence; lightweight machine learning; nowcasting; METAR; TAF verification; edge computing

</details>


### [38] [GB-DQN: Gradient Boosted DQN Models for Non-stationary Reinforcement Learning](https://arxiv.org/abs/2512.17034)
*Chang-Hwan Lee,Chanseung Lee*

Main category: cs.LG

TL;DR: Gradient-Boosted Deep Q-Networks (GB-DQN): an adaptive additive ensemble that incrementally learns residuals to counteract non-stationarity, with theoretical convergence guarantees and empirical robustness improvements over DQN.


<details>
  <summary>Details</summary>
Motivation: Non-stationary environments cause model drift and catastrophic forgetting in deep reinforcement learning. A principled, online adaptation mechanism is needed to maintain performance when dynamics or rewards change.

Method: GB-DQN constructs an additive ensemble of Q-networks. Each new learner is trained to approximate the Bellman residual of the current ensemble after observed drift, implementing gradient-boosted residual learning in reinforcement learning. Theoretical results show monotonic reduction of the empirical Bellman residual and convergence to the post-drift optimal value function under standard assumptions.

Result: The approach provably reduces the Bellman residual at each boosting step and converges to the post-drift optimal value function. Empirical experiments across diverse control tasks with controlled dynamics shifts demonstrate faster recovery, improved stability, and greater robustness relative to DQN and common non-stationary baselines.

Conclusion: GB-DQN provides a principled, scalable method for adapting to non-stationarity in RL by incremental residual learning, yielding increased robustness and quicker recovery after dynamics changes.

Abstract: Non-stationary environments pose a fundamental challenge for deep reinforcement learning, as changes in dynamics or rewards invalidate learned value functions and cause catastrophic forgetting. We propose \emph{Gradient-Boosted Deep Q-Networks (GB-DQN)}, an adaptive ensemble method that addresses model drift through incremental residual learning. Instead of retraining a single Q-network, GB-DQN constructs an additive ensemble in which each new learner is trained to approximate the Bellman residual of the current ensemble after drift. We provide theoretical results showing that each boosting step reduces the empirical Bellman residual and that the ensemble converges to the post-drift optimal value function under standard assumptions. Experiments across a diverse set of control tasks with controlled dynamics changes demonstrate faster recovery, improved stability, and greater robustness compared to DQN and common non-stationary baselines.

</details>


### [39] [SFBD-OMNI: Bridge models for lossy measurement restoration with limited clean samples](https://arxiv.org/abs/2512.17051)
*Haoye Lu,Yaoliang Yu,Darren Ho*

Main category: cs.LG

TL;DR: 提出了一种在有黑箱腐蚀生成器的噪声观测下进行分布恢复的方法。将问题建模为单边信息熵最优传输，并通过一个 EM 风格算法求解；提出可判定在信息丢失下是否可恢复的测试准则；在少量干净样本存在时，说明分布仍可恢复的情形；并引入 SFBD-OMNI 框架，将腐蚀样本分布映射到真实分布；推广 SFBD 至任意测量模型；实验显示显著提升。


<details>
  <summary>Details</summary>
Motivation: 现实中获取完全观测样本成本高昂，且往往存在腐蚀/噪声观测；需要在黑箱腐蚀条件下重建真实分布，提升鲁棒性和可恢复性。

Method: 把问题转化为单边熵最优传输，使用 EM 风格算法求解；提出判断是否可 recover 的理论准则；给出在信息损失下的可恢复性分析；在此基础上提出 SFBD-OMNI 桥接框架，将腐蚀样本分布映射到真实分布，推广 SFBD 至任意测量模型。

Result: 在基准数据集和多种测量设定下，方法在定性和定量指标上都表现出显著提升。

Conclusion: 该框架提供一种通用、可扩展的分布恢复方案，能够处理任意测量模型并提升性能，且具有理论判定可恢复性的工具；未来可结合更多测量模型和更大规模数据。

Abstract: In many real-world scenarios, obtaining fully observed samples is prohibitively expensive or even infeasible, while partial and noisy observations are comparatively easy to collect. In this work, we study distribution restoration with abundant noisy samples, assuming the corruption process is available as a black-box generator. We show that this task can be framed as a one-sided entropic optimal transport problem and solved via an EM-like algorithm. We further provide a test criterion to determine whether the true underlying distribution is recoverable under per-sample information loss, and show that in otherwise unrecoverable cases, a small number of clean samples can render the distribution largely recoverable. Building on these insights, we introduce SFBD-OMNI, a bridge model-based framework that maps corrupted sample distributions to the ground-truth distribution. Our method generalizes Stochastic Forward-Backward Deconvolution (SFBD; Lu et al., 2025) to handle arbitrary measurement models beyond Gaussian corruption. Experiments across benchmark datasets and diverse measurement settings demonstrate significant improvements in both qualitative and quantitative performance.

</details>


### [40] [Universal consistency of the $k$-NN rule in metric spaces and Nagata dimension. III](https://arxiv.org/abs/2512.17058)
*Vladimir G. Pestov*

Main category: cs.LG

TL;DR: 在完整可分的度量空间 X 上，k最近邻分类器的（弱）普遍一致性等价于对任意局部有限测度的强 Lebesgue–Besicovitch 微分性质，以及 X 的 Nagata 维度的 sigma-有限性；本文证明从 (1) 推出 (3)，完成三者的等价性并纠正系列论文中的错误陈述。


<details>
  <summary>Details</summary>
Motivation: 将统计学习理论中的一致性问题与几何测度性质相联系，给出在一般度量空间中对 k-NN 全局一致性的完整刻画，回应系列论文的猜想。

Method: 基于已知 (2)⇔(3) 与 (2)⇒(1) 的结果，发展新的分析与构造性证明，推导 (1)⇒(3)，并纠正此前论文中的错误断言，整合差分性质与几何维度条件的证明框架。

Result: 证明了 (1)→(3) 的蕴含以及在已知结论下三者的等价性；完成对该系列研究中未决命题的解决。

Conclusion: 使三者条件在适用的度量空间中完全等价，回应了早期猜想并修正了相关文献中的错误陈述，巩固了 k-NN 全局一致性与空间几何维度之间的联系。

Abstract: We prove the last remaining implication allowing to claim the equivalence of the following conditions for a complete separable metric space $X$:
  (1) The $k$-nearest neighbour classifier is (weakly) universally consistent in $X$, (2) The strong Lebesgue--Besicovitch differentiation property holds in $X$ for every locally finite Borel measure, (3) $X$ is sigma-finite dimensional in the sense of Nagata.
  The equivalence (2)$\iff$(3) was announced by Preiss (1983), while a detailed proof of the implication (3)$\Rightarrow$(2) has appeared in Assouad and Quentin de Gromard (2006). The implication (2)$\Rightarrow$(1) was established by Cérou and Guyader (2006). We prove the implication (1)$\Rightarrow$(3). The result was conjectured in the first article in the series (Collins, Kumari, Pestov 2020), and here we also correct a wrong claim made in the second article (Kumari and Pestov 2024).

</details>


### [41] [Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation](https://arxiv.org/abs/2512.17073)
*Zhenyu Liu,Yunzhen Liu,Zehao Fan,Garrett Gagnon,Yayue Hou,Nan Wu,Yangwook Kang,Liu Liu*

Main category: cs.LG

TL;DR: 提出一种带宽高效的自适应MoE推理方法，通过低秩补偿实现路由引导的精度恢复，在每个 token 仅传输 Top-n（n<k）个专家的低秩因子并对其应用补偿，其他专家保持低位宽，从而提升带宽与准确性/吞吐的折衷。


<details>
  <summary>Details</summary>
Motivation: MoE 模型通过稀疏激活扩展容量，但对显存和带宽造成压力；按 token 路由的离线/在线传输导致 I/O 限制；静态量化虽然降低带宽，但容易在专家异质性存在时显著损失精度。

Method: 提出 Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation，利用预计算的低秩补偿器对路由引导阶段实现精度恢复。在推理阶段，对每个 token 仅传输 Top-n（n<k）个专家的低秩因子，并对传输的因子应用补偿，其他专家保持低位宽表示。该方案与 GPU 与 GPU-NDP 系统上的 offloading 相结合以实现高效带宽利用。

Result: 在带宽-精度之间实现更优折衷，并提升推理吞吐量。

Conclusion: 该方法为大规模 MoE 推理提供了一种带宽友好且可扩展的解决方案，充分利用低秩补偿与按需专家传输的结合以提高吞吐与精度表现。

Abstract: Mixture-of-Experts (MoE) models scale capacity via sparse activation but stress memory and bandwidth. Offloading alleviates GPU memory by fetching experts on demand, yet token-level routing causes irregular transfers that make inference I/O-bound. Static uniform quantization reduces traffic but degrades accuracy under aggressive compression by ignoring expert heterogeneity. We present Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation, which performs router-guided precision restoration using precomputed low-rank compensators. At inference time, our method transfers compact low-rank factors with Top-n (n<k) experts per token and applies compensation to them, keeping others low-bit. Integrated with offloading on GPU and GPU-NDP systems, our method delivers a superior bandwidth-accuracy trade-off and improved throughput.

</details>


### [42] [Can Large Reasoning Models Improve Accuracy on Mathematical Tasks Using Flawed Thinking?](https://arxiv.org/abs/2512.17079)
*Saraswathy Amjith,Mihika Dusad,Neha Muramalla,Shweta Shah*

Main category: cs.LG

TL;DR: Mixed-CoT-RL: 通过在训练中引入受控的错误推理痕迹，提升大语言模型在遇到错误前提下的错位恢复能力，同时保持在干净题目上的表现。相比标准强化学习，混合训练在带错误前提的问题上表现更好；且对推理错误的暴露比计算错误带来更大收益。


<details>
  <summary>Details</summary>
Motivation: 解决链式推理（CoT）在早期错误出现时容易放大并导致错误答案的问题。提出在训练阶段引入带单一控制错误的推理痕迹，以教会模型检测并从错误中恢复，同时不牺牲普通问题的解决能力。

Method: 在 MATH-lighteval 的竞赛级问题上，生成带有且仅带一个受控错误的 CoT 前缀（计算错误如符号翻转、缺失项；推理错误如错误规则应用、无根据的推理步骤），并用二元最终答案奖励对 Qwen3-4B 进行 GRPO 微调。比较混合-CoT-RL、标准 RL（干净题目）以及未调优基线在有无错误前提下的表现。

Result: 在干净题目上，混合-CoT-RL 与标准 RL 表现相当（41%）。在带错误前提的题目上，混合-CoT-RL 显著优于标准 RL（24% 对 19%）。单纯针对干净题目的 RL 微调反而降低鲁棒性（19% 对 20% 的未调优基线）。在错误类型间，暴露于推理错误比暴露于计算错误带来更大鲁棒性提升，且混合训练效果最佳。

Conclusion: 暴露于带错误的推理痕迹的训练可以提升错误恢复能力而不牺牲准确性，为大语言模型的数学推理提供更鲁棒的路径。

Abstract: Chain-of-thought (CoT) prompting has become central to mathematical reasoning in large language models, yet models remain brittle to early errors: a single arithmetic slip or unjustified inference typically propagates uncorrected to an incorrect final answer. We investigate whether training on intentionally flawed reasoning traces can teach models to detect and recover from such errors without degrading standard problem-solving ability. Using competition-level problems from MATH-lighteval, we generate CoT prefixes containing exactly one controlled error, either a calculation error (sign flips, dropped terms) or a reasoning error (misapplied rules, unjustified logical steps), and fine-tune Qwen3-4B with GRPO using a binary final-answer reward. Our Mixed-CoT-RL model matches standard RL on clean problems (41% vs 41%) while substantially outperforming it on problems prefilled with flawed reasoning (24% vs 19%). Notably, clean-only RL fine-tuning degrades robustness below the untuned baseline 19% vs. 20%), indicating that conventional training increases susceptibility to misleading prefills. Among error types, training on reasoning errors yields greater robustness gains than calculation errors alone, with mixed training performing best. These findings demonstrate that exposure to flawed traces during training can improve error-recovery behavior without sacrificing accuracy, suggesting a path toward more robust mathematical reasoning in LLMs.

</details>


### [43] [Learning to Plan, Planning to Learn: Adaptive Hierarchical RL-MPC for Sample-Efficient Decision Making](https://arxiv.org/abs/2512.17091)
*Toshiaki Hori,Jonathan DeCastro,Deepak Gopinath,Avinash Balachandran,Guy Rosman*

Main category: cs.LG

TL;DR: 提出一个将强化学习与模型预测控制（MPC）结合的分层规划框架，通过用RL行动指导MPPI采样并自适应聚合采样来改进值函数估计，从而提升在多领域的数据效率与任务成功率。


<details>
  <summary>Details</summary>
Motivation: 在复杂分层规划问题中，现有方法在鲁棒性、数据效率和探索-估计稳定性之间存在权衡，亟需一个能在不确定性环境中动态平衡探索与学习的框架。

Method: 将强化学习动作用于指导MPPI采样，利用自适应聚合的MPPI样本来 Inform 值函数估计；在价值不确定时增加MPPI探索，形成耦合的自适应规划循环，从而提升鲁棒性与训练稳定性。

Result: 在多领域（包括赛车驱动、改装的Acrobot、带障碍的月球着陆器）中显示出更高的数据效率与总体表现，任务成功率提升可达约72%，相较非自适应采样的收敛速度提升约2.1倍。

Conclusion: 提出的耦合RL-MPC框架通过将RL行动融入采样并以自适应方式整合样本来提升规划鲁棒性与数据效率，适用于复杂分层规划任务，并在多个领域表现出显著改进。

Abstract: We propose a new approach for solving planning problems with a hierarchical structure, fusing reinforcement learning and MPC planning. Our formulation tightly and elegantly couples the two planning paradigms. It leverages reinforcement learning actions to inform the MPPI sampler, and adaptively aggregates MPPI samples to inform the value estimation. The resulting adaptive process leverages further MPPI exploration where value estimates are uncertain, and improves training robustness and the overall resulting policies. This results in a robust planning approach that can handle complex planning problems and easily adapts to different applications, as demonstrated over several domains, including race driving, modified Acrobot, and Lunar Lander with added obstacles. Our results in these domains show better data efficiency and overall performance in terms of both rewards and task success, with up to a 72% increase in success rate compared to existing approaches, as well as accelerated convergence (x2.1) compared to non-adaptive sampling.

</details>


### [44] [UniCoMTE: A Universal Counterfactual Framework for Explaining Time-Series Classifiers on ECG Data](https://arxiv.org/abs/2512.17100)
*Justin Li,Efe Sencan,Jasper Zheng Duan,Vitus J. Leung,Stephan Tsaur,Ayse K. Coskun*

Main category: cs.LG

TL;DR: 提出一个模型无关的对比性解释框架 UniCoMTE，用于多变量时间序列分类器的对比类解释，并在ECG任务上评估，与LIME/SHAP等方法比较。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在时间序列任务中的黑箱性问题，提升在高风险领域（如医疗）中的信任与可解释性；需要兼容多种模型架构，并且直接在原始输入上工作。

Method: 提出 UniCoMTE 框架，通过修改输入样本并评估对模型预测的影响来识别最具影响的时间特征，属于模型无关的方法，直接作用于原始时间序列输入。对ECG分类器进行评估，比较解释质量与LIME、SHAP在可理解性方面的表现，并通过对相似样本的泛化性测试以及医生评审的临床有用性问卷来评估应用性。

Result: 该框架能生成简洁、稳定且贴合人类理解的解释，在清晰度和适用性方面优于现有方法，能够将模型预测与有意义的信号模式联系起来，提升时间序列应用的可解释性。

Conclusion:  UniCoMTE 为深度学习在时间序列任务中的可解释性和信任度提升提供了普适的解决方案，具有广泛的潜在应用和临床价值。

Abstract: Machine learning models, particularly deep neural networks, have demonstrated strong performance in classifying complex time series data. However, their black-box nature limits trust and adoption, especially in high-stakes domains such as healthcare. To address this challenge, we introduce UniCoMTE, a model-agnostic framework for generating counterfactual explanations for multivariate time series classifiers. The framework identifies temporal features that most heavily influence a model's prediction by modifying the input sample and assessing its impact on the model's prediction. UniCoMTE is compatible with a wide range of model architectures and operates directly on raw time series inputs. In this study, we evaluate UniCoMTE's explanations on a time series ECG classifier. We quantify explanation quality by comparing our explanations' comprehensibility to comprehensibility of established techniques (LIME and SHAP) and assessing their generalizability to similar samples. Furthermore, clinical utility is assessed through a questionnaire completed by medical experts who review counterfactual explanations presented alongside original ECG samples. Results show that our approach produces concise, stable, and human-aligned explanations that outperform existing methods in both clarity and applicability. By linking model predictions to meaningful signal patterns, the framework advances the interpretability of deep learning models for real-world time series applications.

</details>


### [45] [Atom: Efficient On-Device Video-Language Pipelines Through Modular Reuse](https://arxiv.org/abs/2512.17108)
*Kunjal Panchal,Saayan Mitra,Somdeb Sarkhel,Haoliang Wang,Ishita Dasgupta,Gang Wu,Hui Guan*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in video-language models have enabled powerful applications like video retrieval, captioning, and assembly. However, executing such multi-stage pipelines efficiently on mobile devices remains challenging due to redundant model loads and fragmented execution. We introduce Atom, an on-device system that restructures video-language pipelines for fast and efficient execution. Atom decomposes a billion-parameter model into reusable modules, such as the visual encoder and language decoder, and reuses them across subtasks like captioning, reasoning, and indexing. This reuse-centric design eliminates repeated model loading and enables parallel execution, reducing end-to-end latency without sacrificing performance. On commodity smartphones, Atom achieves 27--33% faster execution compared to non-reuse baselines, with only marginal performance drop ($\leq$ 2.3 Recall@1 in retrieval, $\leq$ 1.5 CIDEr in captioning). These results position Atom as a practical, scalable approach for efficient video-language understanding on edge devices.

</details>


### [46] [Bridging Training and Merging Through Momentum-Aware Optimization](https://arxiv.org/abs/2512.17109)
*Alireza Moayedikia,Alicia Troncoso*

Main category: cs.LG

TL;DR: 提出一个统一框架，在训练阶段就持续维护分解的动量和曲率统计，并用来进行几何感知的模型合并，达到与最新低秩方法相当的内存效率，同时获得任务重要性评分以实现更优秀的合并，并给出非凸目标下的收敛保证。


<details>
  <summary>Details</summary>
Motivation: 现有工作将曲率信息在训练中产生后丢弃，随后在模型合并时重新计算，造成重复计算并浪费资源；需要一种能在训练中就积累并重复使用的曲率-动量统计的统一框架。

Method: 在训练过程中维持因子化的动量和曲率统计，并用于几何感知的模型合并；累积任务显著性得分，支持曲率感知的参数选择；在不需要后处理Fisher的情况下完成；提出针对非凸目标的收敛性分析，误差界限由梯度奇异值衰减界定；在自然语言理解基准上进行评估。

Result: 在自然语言理解基准上，曲率感知的参数选择在所有稀疏程度下均优于仅基于幅度选择的基线；多任务合并优于强基线；内存效率与最先进方法相当；提供收敛保证、对超参数鲁棒性更好。

Conclusion: 将优化轨迹视为可重复使用的资产，避免重复计算，使模型合并更加有据可循且成本更低；为低秩优化与模型合并提供一个更具原则性、鲁棒性和高效性的框架。

Abstract: Training large neural networks and merging task-specific models both exploit low-rank structure and require parameter importance estimation, yet these challenges have been pursued in isolation. Current workflows compute curvature information during training, discard it, then recompute similar information for merging -- wasting computation and discarding valuable trajectory data. We introduce a unified framework that maintains factorized momentum and curvature statistics during training, then reuses this information for geometry-aware model composition. The proposed method achieves memory efficiency comparable to state-of-the-art approaches while accumulating task saliency scores that enable curvature-aware merging without post-hoc Fisher computation. We establish convergence guarantees for non-convex objectives with approximation error bounded by gradient singular value decay. On natural language understanding benchmarks, curvature-aware parameter selection outperforms magnitude-only baselines across all sparsity levels, with multi-task merging improving over strong baselines. The proposed framework exhibits rank-invariant convergence and superior hyperparameter robustness compared to existing low-rank optimizers. By treating the optimization trajectory as a reusable asset rather than discarding it, our approach eliminates redundant computation while enabling more principled model composition.

</details>


### [47] [Digitizing Nepal's Written Heritage: A Comprehensive HTR Pipeline for Old Nepali Manuscripts](https://arxiv.org/abs/2512.17111)
*Anjali Sarawgi,Esteban Garces Arias,Christof Zotter*

Main category: cs.LG

TL;DR: 首次为旧尼泊尔语开发端到端手写文本识别流水线，采用行级转录，系统评估编码器-解码器架构与数据驱动策略，最佳CER为4.9%，并分析解码策略与 token-level 混淆；数据集保密但公开训练代码、模型配置与评估脚本以促进低资源历史脚本的研究。


<details>
  <summary>Details</summary>
Motivation: 历史上重要且资源稀缺的旧尼泊尔语手写文本的自动识别需求；提升数字化及研究可复现性；填补低资源语言的HTR研究空白。

Method: 端到端流水线，基于行级转录；比较不同编码器-解码器架构；引入数据驱动的技术（如数据增强、数据清洗、数据采样等数据中心化方法）以改进识别；实现并评估解码策略；进行 token-level 混淆分析。

Result: 最佳模型CER 4.9%；对解码策略和 token-level 混淆有系统分析；评估脚本公布以促进复现。

Conclusion: 首次实现 Old Nepali 的端到端 HTR，促进低资源历史脚本领域研究；尽管评估数据集保密，但公开代码与配置提升透明度；未来可扩展到更多历史语言与更大规模数据集。

Abstract: This paper presents the first end-to-end pipeline for Handwritten Text Recognition (HTR) for Old Nepali, a historically significant but low-resource language. We adopt a line-level transcription approach and systematically explore encoder-decoder architectures and data-centric techniques to improve recognition accuracy. Our best model achieves a Character Error Rate (CER) of 4.9\%. In addition, we implement and evaluate decoding strategies and analyze token-level confusions to better understand model behaviour and error patterns. While the dataset we used for evaluation is confidential, we release our training code, model configurations, and evaluation scripts to support further research in HTR for low-resource historical scripts.

</details>


### [48] [AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens](https://arxiv.org/abs/2512.17375)
*Tung-Ling Li,Yuhao Wu,Hongliang Liu*

Main category: cs.LG

TL;DR: 本文揭示 reward 模型/评判系统在大语言模型中易被短序列低困惑度控制令牌所欺骗，通过影响末层对数差来把正确的“No”判为“Yes”；提出 AdvJudge-Zero 从零开始利用下一时序分布和束搜索发现多样化控制令牌序列，并发现扰动集中在一个低秩软模式，与评判拒绝方向不对齐；实验证明在大规模开源权重和专业化评估模型上，控制令牌会产生高假阳性率；通过以 LoRA 为基础的小样本对抗训练可显著降低假阳性，同时尽量保持评估质量。


<details>
  <summary>Details</summary>
Motivation: 提升后训练管线如 RLHF、DPO、RLAIF 中奖励模型的鲁棒性，防止现实世界策略输出通过控制令牌干扰二分类评估，确保评估过程的可靠性。

Method: AdvJudge-Zero 通过利用模型的下一时序分布和束搜索从零开始探索多样化的控制令牌序列；对诱导的隐藏状态扰动进行分析，发现扰动集中在一个低秩的“软模式”，并且该模式与评判器的拒绝方向不对齐；在大规模开源权重和专业化 judge 模型上评估其对数学和推理基准的影响。

Result: 控制令牌导致很高的假阳性率，尤其是在数学与推理基准上对错误答案的评估中；采用 LoRA 基础的对抗性训练对少量带控制令牌的增强样本进行训练后，显著降低假阳性，同时尽量保持评估质量。

Conclusion: 揭示评估系统的潜在脆弱性及其现实攻击面，提出基于对抗性训练的防御策略，需在不同模型规模和任务下进一步评估与扩展。

Abstract: Reward models and LLM-as-a-Judge systems are central to modern post-training pipelines such as RLHF, DPO, and RLAIF, where they provide scalar feedback and binary decisions that guide model selection and RL-based fine-tuning. We show that these judge systems exhibit a recurring vulnerability: short sequences of low-perplexity control tokens can flip many binary evaluations from correct ``No'' judgments to incorrect ``Yes'' judgments by steering the last-layer logit gap. These control tokens are patterns that a policy model could plausibly generate during post-training, and thus represent realistic reward-hacking risks rather than worst-case adversarial strings. Our method, AdvJudge-Zero, uses the model's next-token distribution and beam-search exploration to discover diverse control-token sequences from scratch, and our analysis shows that the induced hidden-state perturbations concentrate in a low-rank ``soft mode'' that is anti-aligned with the judge's refusal direction. Empirically, these tokens cause very high false positive rates when large open-weight and specialized judge models score incorrect answers on math and reasoning benchmarks. Finally, we show that LoRA-based adversarial training on small sets of control-token-augmented examples can markedly reduce these false positives while preserving evaluation quality.

</details>


### [49] [The Effect of Negation on CLIP in Medical Imaging: Limitations of Contrastive Language-Image Pretraining](https://arxiv.org/abs/2512.17121)
*Jasmine Vu,Shivanand Sheshappanavar*

Main category: cs.LG

TL;DR: 对基于 CLIP 的胸部 X 线检索在含否定词与不含否定词的提示下进行评估与微调。结果显示在处理否定表达方面有所提升，但正向提示的准确度略有下降；并通过 token attribution、t-SNE 投影和注意力头消融等分析研究微调对文本编码器在否定性临床语言上的内部表示影响。


<details>
  <summary>Details</summary>
Motivation: 解决 CLIP 在医学语言中的否定表达理解不足的问题，提升在医疗影像检索、报告生成与诊断相关任务中的可靠性与鲁棒性。

Method: 在 Stanford AIMI CheXagent 模型上评估胸部 X 线图像检索，使用包含与不包含否定的提示；应用基于以往工作的方法进行微调；结合 token attribution、t-SNE 投影和注意力头消融等分析，研究微调如何改变文本编码器对否定临床语言的表征。

Result: 在处理否定提示方面实现改进；正向提示评估的准确度略有下降；并对模型内部行为进行了分析，揭示微调如何重塑否定性表达的表示及其对检索任务的影响。

Conclusion: 对 CLIP 在医学场景中的否定处理有更清晰的认识，基于临床语言的微调有望提升其在医疗 AI 设备中的可靠性，但需在否定与肯定提示的性能权衡中进行优化。

Abstract: Large vision-language models like CLIP are increasingly used in medical imaging tasks due to their ability to align images and text without the need for extensive labeled data. This makes them particularly useful for applications like image retrieval, report generation, and classification in clinical settings. A potential issue to this approach is that CLIP-based models often under perform when interpreting negated phrases, which is especially problematic in the context of medical diagnosing. In this study, we evaluate the Stanford AIMI CheXagent model on its ability to correctly retrieve chest X-ray images using prompts with and without negation. The goal of this project is to understand where this model fails and then use it as a base model to improve its retrieval accuracy by fine tuning methods outlined in previous work. Results from this study show improvement in handling of negation in the CLIP model with a slight decrease in accuracy of positive prompt evaluation. Alongside retrieval accuracy, we examined internal model behavior through token attribution, t-SNE projection, and attention-head ablation to better characterize how each fine tuning approach reshaped the text encoders representation of negated clinical language. Through this work, we hope to better understand the internal behavior of CLIP and improve its handling of negation using clinically relevant language for improving its reliability in medical AI devices.

</details>


### [50] [DiffeoMorph: Learning to Morph 3D Shapes Using Differentiable Agent-Based Simulations](https://arxiv.org/abs/2512.17129)
*Seong Ho Pahng,Guoye Guan,Benjamin Fefferman,Sahand Hormoz*

Main category: cs.LG

TL;DR: DiffeoMorph learns a morphogenesis protocol for multi-agent systems to morph into a target 3D shape using an SE(3)-equivariant GNN and a Zernike-based, rotation-aligned shape-matching loss; it employs a bilevel optimization with implicit differentiation to align predicted and target shapes, enabling formation of simple to complex morphologies from minimal cues.


<details>
  <summary>Details</summary>
Motivation: Understand how local, distributed agent interactions can yield precise global morphologies and provide a differentiable framework for programmable morphogenesis applicable to biology-inspired systems, robotics, and multi-agent learning.

Method: Agents update positions and internal states via an attention-based SE(3)-equivariant graph neural network. A new continuous shape-matching loss based on 3D Zernike polynomials compares the predicted shape to the target as a spatial distribution, invariant to agent ordering, number, and rigid transforms. An alignment step rotates the predicted Zernike spectrum to best match the target, enforcing full SO(3) invariance. This creates a bilevel optimization: inner loop optimizes the best-in-class unit quaternion for alignment; outer loop updates the agent model. Gradients are computed through the alignment via implicit differentiation. The approach is benchmarked against standard shape metrics.

Result: The framework can morph populations into shapes ranging from ellipsoids to more complex morphologies using minimal spatial cues, with empirical evidence that the Zernike-based loss offers advantages over conventional distance metrics for shape comparison.

Conclusion: DiffeoMorph provides a differentiable, rotation-aware pathway to programmable morphogenesis in distributed agent systems, enabling robust formation of diverse 3D shapes and offering a competitive loss for shape matching over existing metrics.

Abstract: Biological systems can form complex three-dimensional structures through the collective behavior of identical agents -- cells that follow the same internal rules and communicate without central control. How such distributed control gives rise to precise global patterns remains a central question not only in developmental biology but also in distributed robotics, programmable matter, and multi-agent learning. Here, we introduce DiffeoMorph, an end-to-end differentiable framework for learning a morphogenesis protocol that guides a population of agents to morph into a target 3D shape. Each agent updates its position and internal state using an attention-based SE(3)-equivariant graph neural network, based on its own internal state and signals received from other agents. To train this system, we introduce a new shape-matching loss based on the 3D Zernike polynomials, which compares the predicted and target shapes as continuous spatial distributions, not as discrete point clouds, and is invariant to agent ordering, number of agents, and rigid-body transformations. To enforce full SO(3) invariance -- invariant to rotations yet sensitive to reflections, we include an alignment step that optimally rotates the predicted Zernike spectrum to match the target before computing the loss. This results in a bilevel problem, with the inner loop optimizing a unit quaternion for the best alignment and the outer loop updating the agent model. We compute gradients through the alignment step using implicit differentiation. We perform systematic benchmarking to establish the advantages of our shape-matching loss over other standard distance metrics for shape comparison tasks. We then demonstrate that DiffeoMorph can form a range of shapes -- from simple ellipsoids to complex morphologies -- using only minimal spatial cues.

</details>


### [51] [SafeBench-Seq: A Homology-Clustered, CPU-Only Baseline for Protein Hazard Screening with Physicochemical/Composition Features and Cluster-Aware Confidence Intervals](https://arxiv.org/abs/2512.17527)
*Muhammad Haris Khan*

Main category: cs.LG

TL;DR: SafeBench-Seq：一个基于元数据、可复现的蛋白质序列级风险筛查基准，使用<=40%同源性聚类分割，CPU 上可运行，提供可校准的概率输出和多种评估指标。


<details>
  <summary>Details</summary>
Motivation: 蛋白质设计的基础模型带来生物安全风险，但缺乏简单、可复现、在同源控制下的序列级基线筛查工具。

Method: 构建 SafeBench-Seq：来自公开数据 SafeProtein hazards 与 UniProt benigns；特征选取全局物理化学描述子和氨基酸组成；对联合数据集进行 <=40% 相似性聚类以实现簇级 Holdout；训练并比较线性模型（逻辑回归、线性 SVM）和树模型（随机森林等）在校准概率（CalibratedClassifierCV）下的表现；评估指标包括 AUROC、AUPRC、TPR@1%FPR、FPR@95%TPR，以及 Brier、ECE、可靠性图；还通过成分保持置换、长度/组成消融等方法探究易受捷径影响；输出为元数据（聚类 ID、分割标签等），CPU-only，且不分发有害序列。

Result: 随机划分高估鲁棒性，聚类分割更接近“从未见过威胁”的情形；线性模型较有良好校准，树模型的 Brier 和 ECE 略高；提供了概率校准的基线，方便复现实验。

Conclusion: SafeBench-Seq 提供一个可复现、元数据仅依赖的序列级基准，为同源控制的风险筛查提供基线，并强调在蛋白质设计的安全评估中需要考虑聚类分割和概率校准等因素。

Abstract: Foundation models for protein design raise concrete biosecurity risks, yet the community lacks a simple, reproducible baseline for sequence-level hazard screening that is explicitly evaluated under homology control and runs on commodity CPUs. We introduce SafeBench-Seq, a metadata-only, reproducible benchmark and baseline classifier built entirely from public data (SafeProtein hazards and UniProt benigns) and interpretable features (global physicochemical descriptors and amino-acid composition). To approximate "never-before-seen" threats, we homology-cluster the combined dataset at <=40% identity and perform cluster-level holdouts (no cluster overlap between train/test). We report discrimination (AUROC/AUPRC) and screening-operating points (TPR@1% FPR; FPR@95% TPR) with 95% bootstrap confidence intervals (n=200), and we provide calibrated probabilities via CalibratedClassifierCV (isotonic for Logistic Regression / Random Forest; Platt sigmoid for Linear SVM). We quantify probability quality using Brier score, Expected Calibration Error (ECE; 15 bins), and reliability diagrams. Shortcut susceptibility is probed via composition-preserving residue shuffles and length-/composition-only ablations. Empirically, random splits substantially overestimate robustness relative to homology-clustered evaluation; calibrated linear models exhibit comparatively good calibration, while tree ensembles retain slightly higher Brier/ECE. SafeBench-Seq is CPU-only, reproducible, and releases metadata only (accessions, cluster IDs, split labels), enabling rigorous evaluation without distributing hazardous sequences.

</details>


### [52] [Smoothing DiLoCo with Primal Averaging for Faster Training of LLMs](https://arxiv.org/abs/2512.17131)
*Aaron Defazio,Konstantin Mishchenko,Parameswaran Raman,Hao-Jun Michael Shi,Lin Xiao*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose Generalized Primal Averaging (GPA), an extension of Nesterov's method in its primal averaging formulation that addresses key limitations of recent averaging-based optimizers such as single-worker DiLoCo and Schedule-Free (SF) in the non-distributed setting. These two recent algorithmic approaches improve the performance of base optimizers, such as AdamW, through different iterate averaging strategies. Schedule-Free explicitly maintains a uniform average of past weights, while single-worker DiLoCo performs implicit averaging by periodically aggregating trajectories, called pseudo-gradients, to update the model parameters. However, single-worker DiLoCo's periodic averaging introduces a two-loop structure, increasing its memory requirements and number of hyperparameters. GPA overcomes these limitations by decoupling the interpolation constant in the primal averaging formulation of Nesterov. This decoupling enables GPA to smoothly average iterates at every step, generalizing and improving upon single-worker DiLoCo. Empirically, GPA consistently outperforms single-worker DiLoCo while removing the two-loop structure, simplifying hyperparameter tuning, and reducing its memory overhead to a single additional buffer. On the Llama-160M model, GPA provides a 24.22% speedup in terms of steps to reach the baseline (AdamW's) validation loss. Likewise, GPA achieves speedups of 12% and 27% on small and large batch setups, respectively, to attain AdamW's validation accuracy on the ImageNet ViT workload. Furthermore, we prove that for any base optimizer with regret bounded by $O(\sqrt{T})$, where $T$ is the number of iterations, GPA can match or exceed the convergence guarantee of the original optimizer, depending on the choice of interpolation constants.

</details>


### [53] [BumpNet: A Sparse Neural Network Framework for Learning PDE Solutions](https://arxiv.org/abs/2512.17198)
*Shao-Ting Chiu,Ioannis G. Kevrekidis,Ulisses Braga-Neto*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce BumpNet, a sparse neural network framework for PDE numerical solution and operator learning. BumpNet is based on meshless basis function expansion, in a similar fashion to radial-basis function (RBF) networks. Unlike RBF networks, the basis functions in BumpNet are constructed from ordinary sigmoid activation functions. This enables the efficient use of modern training techniques optimized for such networks. All parameters of the basis functions, including shape, location, and amplitude, are fully trainable. Model parsimony and h-adaptivity are effectively achieved through dynamically pruning basis functions during training. BumpNet is a general framework that can be combined with existing neural architectures for learning PDE solutions: here, we propose Bump-PINNs (BumpNet with physics-informed neural networks) for solving general PDEs; Bump-EDNN (BumpNet with evolutionary deep neural networks) to solve time-evolution PDEs; and Bump-DeepONet (BumpNet with deep operator networks) for PDE operator learning. Bump-PINNs are trained using the same collocation-based approach used by PINNs, Bump-EDNN uses a BumpNet only in the spatial domain and uses EDNNs to advance the solution in time, while Bump-DeepONets employ a BumpNet regression network as the trunk network of a DeepONet. Extensive numerical experiments demonstrate the efficiency and accuracy of the proposed architecture.

</details>


### [54] [Learning solution operator of dynamical systems with diffusion maps kernel ridge regression](https://arxiv.org/abs/2512.17203)
*Jiwoo Song,Daning Huang,John Harlim*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Many scientific and engineering systems exhibit complex nonlinear dynamics that are difficult to predict accurately over long time horizons. Although data-driven models have shown promise, their performance often deteriorates when the geometric structures governing long-term behavior are unknown or poorly represented. We demonstrate that a simple kernel ridge regression (KRR) framework, when combined with a dynamics-aware validation strategy, provides a strong baseline for long-term prediction of complex dynamical systems. By employing a data-driven kernel derived from diffusion maps, the proposed Diffusion Maps Kernel Ridge Regression (DM-KRR) method implicitly adapts to the intrinsic geometry of the system's invariant set, without requiring explicit manifold reconstruction or attractor modeling, procedures that often limit predictive performance. Across a broad range of systems, including smooth manifolds, chaotic attractors, and high-dimensional spatiotemporal flows, DM-KRR consistently outperforms state-of-the-art random feature, neural-network and operator-learning methods in both accuracy and data efficiency. These findings underscore that long-term predictive skill depends not only on model expressiveness, but critically on respecting the geometric constraints encoded in the data through dynamically consistent model selection. Together, simplicity, geometry awareness, and strong empirical performance point to a promising path for reliable and efficient learning of complex dynamical systems.

</details>


### [55] [Electric Vehicle Charging Load Forecasting: An Experimental Comparison of Machine Learning Methods](https://arxiv.org/abs/2512.17257)
*Iason Kyriakopoulos,Yannis Theodoridis*

Main category: cs.LG

TL;DR: 系统性比较5种时间序列预测模型在不同时间尺度和空间聚合层级上的EV充电需求预测，基于4个公开数据集的实证分析。


<details>
  <summary>Details</summary>
Motivation: 解决电动车充电需求对电网管理的挑战，弥补在多时空尺度和多数据集上的比较研究不足。

Method: 评估五种时间序列模型（涵盖传统统计、机器学习、深度学习）在短/中/长期预测任务，以及从单一充电站到区域和城市级别的不同空间聚合。数据来自四个公开的真实世界数据集，每个数据集逐一报告结果。

Result: 各模型在不同时空条件下的预测性能存在差异，强调需要对时空尺度进行模型选择和混合方法的考虑；在四数据集上的一致性增强了结论的稳健性。

Conclusion: 首次在如此广泛的时空粒度和多数据集范围内系统评估EV充电需求预测，提供对研究与应用的全面见解。

Abstract: With the growing popularity of electric vehicles as a means of addressing climate change, concerns have emerged regarding their impact on electric grid management. As a result, predicting EV charging demand has become a timely and important research problem. While substantial research has addressed energy load forecasting in transportation, relatively few studies systematically compare multiple forecasting methods across different temporal horizons and spatial aggregation levels in diverse urban settings. This work investigates the effectiveness of five time series forecasting models, ranging from traditional statistical approaches to machine learning and deep learning methods. Forecasting performance is evaluated for short-, mid-, and long-term horizons (on the order of minutes, hours, and days, respectively), and across spatial scales ranging from individual charging stations to regional and city-level aggregations. The analysis is conducted on four publicly available real-world datasets, with results reported independently for each dataset. To the best of our knowledge, this is the first work to systematically evaluate EV charging demand forecasting across such a wide range of temporal horizons and spatial aggregation levels using multiple real-world datasets.

</details>


### [56] [Understanding Generalization in Role-Playing Models via Information Theory](https://arxiv.org/abs/2512.17270)
*Yongqi Li,Hao Lang,Fei Huang,Tieyun Qian,Yongbin Li*

Main category: cs.LG

TL;DR: 提出了一个信息理论度量R-EMID来评估角色扮演模型（RPM）在分布漂移下的泛化退化，并给出上界预测最坏情形；同时通过一个共进化强化学习框架来改进对话生成概率的估算以计算R-EMID，并在实证中发现用户漂移风险最高，RL是提升泛化的最有效方法。


<details>
  <summary>Details</summary>
Motivation: RPM在实际部署中因用户、角色与对话等分布漂移而退化，现有方法（如LLM作为评判者）无法对这种退化给出细粒度、可解释的诊断与框架，因此需要可解释的度量与去耦合的理论分析来理解各类漂移对泛化的影响。

Method: 提出R-EMID作为信息论角度的度量，并推导出其上界以预测最坏-case泛化；建立一个共进化强化学习框架来建模用户、角色、对话上下文之间的耦合关系，从而提升对话生成概率的估计以便计算R-EMID。

Result: 在多个RPMs的泛化评估中，R-EMID揭示用户漂移风险最大；使用RL框架能显著提升RPM的泛化表现。

Conclusion: R-EMID提供可解释的性能退化度量和上界，揭示不同漂移贡献；共进化RL框架有效提升对话生成概率估计和RPM泛化表现，特别是在用户漂移条件下。

Abstract: Role-playing models (RPMs) are widely used in real-world applications but underperform when deployed in the wild. This degradation can be attributed to distribution shifts, including user, character, and dialogue compositional shifts. Existing methods like LLM-as-a-judge fall short in providing a fine-grained diagnosis of how these shifts affect RPM generalization, and thus there lack formal frameworks to characterize RPM generalization behaviors. To bridge these gaps, we introduce an information-theoretic metric, named reasoning-based effective mutual information difference (R-EMID), to measure RPM performance degradation in an interpretable way. We also derive an upper bound on R-EMID to predict the worst-case generalization performance of RPMs and theoretically reveal how various shifts contribute to the RPM performance degradation. Moreover, we propose a co-evolving reinforcement learning framework to adaptively model the connection among user, character, and dialogue context and thus enhance the estimation of dialogue response generation probability, which is critical for calculating R-EMID. Finally, we evaluate the generalization performance of various RPMs using R-EMID, finding that user shift poses the highest risk among all shifts and reinforcement learning is the most effective approach for enhancing RPM generalization.

</details>


### [57] [MINPO: Memory-Informed Neural Pseudo-Operator to Resolve Nonlocal Spatiotemporal Dynamics](https://arxiv.org/abs/2512.17273)
*Farinaz Mostajeran,Aruzhan Tleubek,Salah A Faroughi*

Main category: cs.LG

TL;DR: MINPO 是一种统一的神经算子框架，用于学习非局部算子及其逆算子，使用记忆感知编码器（KAN 或 MLP）并通过非局部一致性损失实现解场重构，适用于各种非局部 IDEs（包括分数阶 PDEs），在准确性和鲁棒性方面优于传统方法和现有神经方法。


<details>
  <summary>Details</summary>
Motivation: 许多物理系统由非局部时空行为驱动，需求解积分-微分方程（IDEs）。传统方法在卷积积分计算上成本高，且现有神经求解器难以跨越多样的非局部结构实现泛化，因此需要一个能够涵盖长程空间相互作用和长期记忆的统一框架。

Method: 提出 Memory-Informed Neural Pseudo-Operator (MINPO)。MINPO 可选择使用 Kolmogorov-Arnold Networks (KANs) 或多层感知机（MLPs）作为编码器，直接学习非局部算子及其逆算子，并显式重构未知解场。为确保一致性，引入轻量级的非局部一致性损失，增强学习的算子与重构解的一致性。MINPO 能自然捕捉并高效求解由长程非局部依赖驱动的广谱 IDEs 及其子集（含分数阶 PDEs）。

Result: 与经典方法和最先进的神经基方法（如 A-PINN、fPINN，以及相应的 A-PIKAN、fPIKAN）对比，MINPO 在多样化核类型、核维度以及重复计算核积分的高计算成本情形下仍展现出高精度与鲁棒性；能够处理不同核结构和高维度情形，具有较强的泛化能力和计算效率优势。

Conclusion: MINPO 提供了一个超越特定问题设定的统一框架，适用于由非局部算子支配的系统，能够泛化到更广泛的 IDEs 与子类，显著提升对长程相互作用与记忆效应的建模与求解能力。

Abstract: Many physical systems exhibit nonlocal spatiotemporal behaviors described by integro-differential equations (IDEs). Classical methods for solving IDEs require repeatedly evaluating convolution integrals, whose cost increases quickly with kernel complexity and dimensionality. Existing neural solvers can accelerate selected instances of these computations, yet they do not generalize across diverse nonlocal structures. In this work, we introduce the Memory-Informed Neural Pseudo-Operator (MINPO), a unified framework for modeling nonlocal dynamics arising from long-range spatial interactions and/or long-term temporal memory. MINPO, employing either Kolmogorov-Arnold Networks (KANs) or multilayer perceptron networks (MLPs) as encoders, learns the nonlocal operator and its inverse directly through neural representations, and then explicitly reconstruct the unknown solution fields. The learning is guarded by a lightweight nonlocal consistency loss term to enforce coherence between the learned operator and reconstructed solution. The MINPO formulation allows to naturally capture and efficiently resolve nonlocal spatiotemporal dependencies governed by a wide spectrum of IDEs and their subsets, including fractional PDEs. We evaluate the efficacy of MINPO in comparison with classical techniques and state-of-the-art neural-based strategies based on MLPs, such as A-PINN and fPINN, along with their newly-developed KAN variants, A-PIKAN and fPIKAN, designed to facilitate a fair comparison. Our study offers compelling evidence of the accuracy of MINPO and demonstrates its robustness in handling (i) diverse kernel types, (ii) different kernel dimensionalities, and (iii) the substantial computational demands arising from repeated evaluations of kernel integrals. MINPO, thus, generalizes beyond problem-specific formulations, providing a unified framework for systems governed by nonlocal operators.

</details>


### [58] [Alzheimer's Disease Brain Network Mining](https://arxiv.org/abs/2512.17276)
*Alireza Moayedikia,Sara Fin*

Main category: cs.LG

TL;DR: A semi-supervised, multi-view learning framework MATCH-AD combines deep representations, graph-based label propagation, and optimal transport to diagnose Alzheimer’s disease with scarce labels across multimodal neuroimaging data, achieving near-perfect accuracy on ~5k subjects and providing convergence guarantees.


<details>
  <summary>Details</summary>
Motivation: Clinical assessment for AD is expensive and invasive, leading to labels available for only a fraction of neuroimaging data; leverage unlabeled data and multiple modalities to improve diagnosis.

Method: MATCH-AD integrates deep representation learning, graph-based label propagation, and Wasserstein (optimal transport) distances within a semi-supervised, multi-view framework to propagate diagnostic information and model disease progression across cognitive states.

Result: On ~5000 subjects from NACC with structural MRI, CSF biomarkers, and clinical variables, MATCH-AD achieves near-perfect diagnostic accuracy with <1/3 labeled, outperforms baselines, kappa indicating almost perfect agreement, and provides theoretical bounds on label propagation error and transport stability.

Conclusion: Principled semi-supervised learning can unlock diagnostic potential of large partially annotated neuroimaging datasets, reducing annotation burden while maintaining clinical accuracy for deployment.

Abstract: Machine learning approaches for Alzheimer's disease (AD) diagnosis face a fundamental challenges. Clinical assessments are expensive and invasive, leaving ground truth labels available for only a fraction of neuroimaging datasets. We introduce Multi view Adaptive Transport Clustering for Heterogeneous Alzheimer's Disease (MATCH-AD), a semi supervised framework that integrates deep representation learning, graph-based label propagation, and optimal transport theory to address this limitation. The framework leverages manifold structure in neuroimaging data to propagate diagnostic information from limited labeled samples to larger unlabeled populations, while using Wasserstein distances to quantify disease progression between cognitive states. Evaluated on nearly five thousand subjects from the National Alzheimer's Coordinating Center, encompassing structural MRI measurements from hundreds of brain regions, cerebrospinal fluid biomarkers, and clinical variables MATCHAD achieves near-perfect diagnostic accuracy despite ground truth labels for less than one-third of subjects. The framework substantially outperforms all baseline methods, achieving kappa indicating almost perfect agreement compared to weak agreement for the best baseline, a qualitative transformation in diagnostic reliability. Performance remains clinically useful even under severe label scarcity, and we provide theoretical convergence guarantees with proven bounds on label propagation error and transport stability. These results demonstrate that principled semi-supervised learning can unlock the diagnostic potential of the vast repositories of partially annotated neuroimaging data accumulating worldwide, substantially reducing annotation burden while maintaining accuracy suitable for clinical deployment.

</details>


### [59] [M2RU: Memristive Minion Recurrent Unit for Continual Learning at the Edge](https://arxiv.org/abs/2512.17299)
*Abdullah M. Zyarah,Dhireesha Kudithipudi*

Main category: cs.LG

TL;DR: M2RU是一种混合信号递归单元加速器，支持片上持续学习，面向边缘时间处理，具高能效。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上进行持续学习面临高能耗和频繁数据移动的问题，需高效的时间序列处理解决方案。

Method: 提出M2RU混合信号架构，采用minion递归单元，整合weighted-bit streaming、跨矩阵处理多比特输入，以及经验回放以在域漂移下稳定学习；实现片上持续学习。

Result: 实现15 GOPS、48.62 mW、312 GOPS/W；在顺序MNIST和 CIFAR-10任务上精度与软件基线相差不超过5%；与CMOS数字设计相比能源效率提升约29X；在持续学习负载下设备可用寿命约12.2年。

Conclusion: M2RU为边缘端时间智能提供可扩展且高能效的实时自适应平台。

Abstract: Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.

</details>


### [60] [Task Schema and Binding: A Double Dissociation Study of In-Context Learning](https://arxiv.org/abs/2512.17325)
*Chaeha Kim*

Main category: cs.LG

TL;DR: ICL由两大分离机制组成：任务模式识别（Task Schema）与具体输入输出绑定（Binding），并在跨模型补丁实验中证实其可分离性以及跨架构的一般性，并解释了先验知识对模式依赖的影响及对提示设计的启示。


<details>
  <summary>Details</summary>
Motivation: 挑战把ICL视为单一机制的观点，提供双过程理论的实证证据，解释ICL现象背后的因果机制。

Method: 在9个模型、7个Transformer家族以及Mamba（370M-13B参数）中，进行激活patching实验；通过对late MLP层补丁传递Task Schema，以及对残差流补丁传递Binding，来检验两种机制的可传递性与耦合性。

Result: 得到三点发现：1) 双重解耦证据：Task Schema通过晚期MLP补丁传递达到100%，Binding通过残差流补丁传递约62%；2) Prior-Schema权衡：当存在先验知识时，Schema依赖与先验知识呈负相关（Spearman rho=-0.596，p<0.001，N=28个任务-模型对）；3) 架构普适性：该机制在所有测试架构上成立，包括非Transformer的Mamba。并给出对ICL之“单一机制”的反驳，提出两种机制在神经层面的因果分离。

Conclusion: ICL具有双过程性质，Task Schema在缺乏先验时发挥作用，Binding在高先验时易受注意力错 routing的干扰而非直接输出竞争；这一发现为提示工程提供方向：通过提升模式转移效率可减少示例需求，同时在高先验情境下通过设计来降低绑定失败率（约38%），提升生产中的ICL可靠性。最终，解释了ICL难题的原因，并为未来在跨架构、跨任务的通用ICL研究和应用提供了理论与方法论基础。

Abstract: We provide causal mechanistic validation that in-context learning (ICL) decomposes into two separable mechanisms: Task Schema (abstract task type recognition) and Binding (specific input-output associations). Through activation patching experiments across 9 models from 7 Transformer families plus Mamba (370M-13B parameters), we establish three key findings:
  1. Double dissociation: Task Schema transfers at 100% via late MLP patching; Binding transfers at 62% via residual stream patching -- proving separable mechanisms
  2. Prior-Schema trade-off: Schema reliance inversely correlates with prior knowledge (Spearman rho = -0.596, p < 0.001, N=28 task-model pairs)
  3. Architecture generality: The mechanism operates across all tested architectures including the non-Transformer Mamba
  These findings offer a mechanistic account of the ICL puzzle that contrasts with prior views treating ICL as a monolithic mechanism (whether retrieval-based, gradient descent-like, or purely Bayesian). By establishing that Schema and Binding are neurally dissociable -- not merely behavioral modes -- we provide causal evidence for dual-process theories of ICL. Models rely on Task Schema when prior knowledge is absent, but prior knowledge interferes through attentional mis-routing (72.7% recency bias) rather than direct output competition (0%). This explains why arbitrary mappings succeed (zero prior leads to full Schema reliance) while factual overrides fail -- and reveals that the true bottleneck is attentional, not output-level. Practical implications: Understanding these dual mechanisms enables more efficient prompt engineering -- reliable schema transfer reduces required demonstrations for novel tasks, while prior-aware design can mitigate the 38% binding failure rate in high-prior scenarios, improving ICL system reliability in production deployments.

</details>


### [61] [Adversarially Robust Detection of Harmful Online Content: A Computational Design Science Approach](https://arxiv.org/abs/2512.17367)
*Yidong Chai,Yi Liu,Mohammadreza Ebrahimi,Weifeng Li,Balaji Padmanabhan*

Main category: cs.LG

TL;DR: 提出基于大语言模型生成与聚合的对抗鲁棒检测框架（LLM-SGA）及其实现的 ARHOCD 检测器，通过多检测器集成、基于贝叶斯推断的权重分配与对抗训练，在 hate speech、rumor、extremist content 三类数据集上实现对文本对抗攻击的鲁棒性与泛化能力的提升。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中的有害内容检测模型易受对抗性文本攻击影响，若要提升对多样化攻击的泛化能力又不牺牲总体准确性，需设计可泛化且高效的检测框架；现有方法难以同时兼顾泛化与准确性。

Method: 1) 提出 LLM-SGA 框架，识别文本对抗攻击的关键不变量以提升泛化；2) 在该框架内实现 ARHOCD，包含： (a) 基 detector 的集合并策略； (b) 动态权重分配方法，基于样本可预测性与各检测器能力，权重初始由领域知识设定并通过贝叶斯推断更新；(c) 对抗训练策略，迭代优化基检测器与权重分配器。

Result: 在 hate speech、rumor、extremist content 三个数据集上评估，ARHOCD 展现出较强的泛化能力并在对抗条件下提升检测准确率。

Conclusion: 提出的框架与检测器在兼顾对抗鲁棒性与泛化性能方面取得进展，缓解了现有方法的局限性，具有在更广泛在线内容检测任务中的潜在应用价值。

Abstract: Social media platforms are plagued by harmful content such as hate speech, misinformation, and extremist rhetoric. Machine learning (ML) models are widely adopted to detect such content; however, they remain highly vulnerable to adversarial attacks, wherein malicious users subtly modify text to evade detection. Enhancing adversarial robustness is therefore essential, requiring detectors that can defend against diverse attacks (generalizability) while maintaining high overall accuracy. However, simultaneously achieving both optimal generalizability and accuracy is challenging. Following the computational design science paradigm, this study takes a sequential approach that first proposes a novel framework (Large Language Model-based Sample Generation and Aggregation, LLM-SGA) by identifying the key invariances of textual adversarial attacks and leveraging them to ensure that a detector instantiated within the framework has strong generalizability. Second, we instantiate our detector (Adversarially Robust Harmful Online Content Detector, ARHOCD) with three novel design components to improve detection accuracy: (1) an ensemble of multiple base detectors that exploits their complementary strengths; (2) a novel weight assignment method that dynamically adjusts weights based on each sample's predictability and each base detector's capability, with weights initialized using domain knowledge and updated via Bayesian inference; and (3) a novel adversarial training strategy that iteratively optimizes both the base detectors and the weight assignor. We addressed several limitations of existing adversarial robustness enhancement research and empirically evaluated ARHOCD across three datasets spanning hate speech, rumor, and extremist content. Results show that ARHOCD offers strong generalizability and improves detection accuracy under adversarial conditions.

</details>


### [62] [meval: A Statistical Toolbox for Fine-Grained Model Performance Analysis](https://arxiv.org/abs/2512.17409)
*Dishantkumar Sutariya,Eike Petersen*

Main category: cs.LG

TL;DR: 提出一个统计工具箱，用于在医疗影像模型中对按患者与记录属性分层的模型性能进行严格的统计分析，包括指标选择、不确定度估计、多重比较校正，以及对交叉子组的识别；并通过 ISIC2020 和 MIMIC-CXR 两个案例进行演示。


<details>
  <summary>Details</summary>
Motivation: 在分析按患者和记录属性分层的模型性能时，尽管能揭示关键失败模式，但要做到统计学上的严格比较并非易事。需要在不同样本量和基线发生率下选择合适的性能指标、估计指标不确定性、对多重比较进行校正，以及在组合丰富的子组中发现最具“趣味性”的子组。

Method: 提出一个面向医疗影像的统计工具箱，提供适用于跨子组比较的指标、置信区间、多重比较校正和交叉子组挖掘机制；通过两个案例进行方法示范。

Result: 该工具箱使研究者能够更严格地评估潜在的子组性能差异，并在 ISIC2020 和 MIMIC-CXR 数据集上进行了示例分析。

Conclusion: 该工具箱具普遍适用性，尤其适用于医疗影像领域，提供了一套易于使用、可用于发现和评估子组性能差异的统计分析框架。

Abstract: Analyzing machine learning model performance stratified by patient and recording properties is becoming the accepted norm and often yields crucial insights about important model failure modes. Performing such analyses in a statistically rigorous manner is non-trivial, however. Appropriate performance metrics must be selected that allow for valid comparisons between groups of different sample sizes and base rates; metric uncertainty must be determined and multiple comparisons be corrected for, in order to assess whether any observed differences may be purely due to chance; and in the case of intersectional analyses, mechanisms must be implemented to find the most `interesting' subgroups within combinatorially many subgroup combinations. We here present a statistical toolbox that addresses these challenges and enables practitioners to easily yet rigorously assess their models for potential subgroup performance disparities. While broadly applicable, the toolbox is specifically designed for medical imaging applications. The analyses provided by the toolbox are illustrated in two case studies, one in skin lesion malignancy classification on the ISIC2020 dataset and one in chest X-ray-based disease classification on the MIMIC-CXR dataset.

</details>


### [63] [Learning What to Write: Write-Gated KV for Efficient Long-Context Inference](https://arxiv.org/abs/2512.17452)
*Yen-Chieh Huang,Rui Fang,Ming-Syan Chen,Pi-Cheng Hsiu*

Main category: cs.LG

TL;DR: 通过写入门控的 KV 缓存管理实现长上下文推理的高效化，提出 KV Admission/Selection/Eviction 三原语，并在 Llama 上实现显著的内存和速度提升，兼容 FlashAttention 与 paged-KV。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理受二次注意力和 KV 缓存增长的瓶颈，现有方法多聚焦后续选择或驱逐，未解决根本的写入低效问题。

Method: 将 KV 缓存管理形式化为 Admission、Selection、Eviction 三个原语。通过 Write-Gated KV 在进入缓存前预测 token 的效用，仅写入高效用状态，保持全局缓存紧凑并使用滑动本地缓存；与 FlashAttention 与 paged-KV 兼容。

Result: 在 Llama 上实现后，内存使用降低约 46-57%，预热（prefill）提速约 3.03–3.45x，解码提速约 1.89–2.56x，精度损失极小；代码开放。

Conclusion: 通过学习何时写入缓存，是实现高效长上下文推理的一个原理性且实用的办法，具备与现有缓存与注意力实现协同的潜力。

Abstract: Long-context LLM inference is bottlenecked by the quadratic attention complexity and linear KV cache growth. Prior approaches mitigate this via post-hoc selection or eviction but overlook the root inefficiency: indiscriminate writing to persistent memory. In this paper, we formalize KV cache management as a causal system of three primitives: KV Admission, Selection, and Eviction. We instantiate KV Admission via Write-Gated KV, a lightweight mechanism that learns to predict token utility before it enters the cache. By filtering out low-utility states early to maintain a compact global cache alongside a sliding local cache, Write-Gated KV reduces memory usage by 46-57% and delivers 3.03-3.45$\times$ prefill and 1.89-2.56$\times$ decode speedups on Llama model with negligible accuracy loss, all while remaining compatible with FlashAttention and paged-KV systems. These results demonstrate that learning what to write, is a principled and practical recipe for efficient long-context inference. Code is available at https://github.com/EMCLab-Sinica/WG-KV .

</details>


### [64] [Bayesian Optimisation: Which Constraints Matter?](https://arxiv.org/abs/2512.17569)
*Xietao Wang Lin,Juan Ungredda,Max Butler,James Town,Alma Rahat,Hemant Singh,Juergen Branke*

Main category: cs.LG

TL;DR: 提出针对解耦约束的 Knowledge Gradient 贝叶斯优化变体，能够只评估与最优解相关的约束以提升样本效率，实验表明优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在昂贵的全局黑箱优化中，目标与约束往往可解耦评估；通常只有少数约束在最优解附近起作用，因此需要设计能专注于绑定约束的获取函数以提高优化效率。

Method: 提出新的贝叶斯优化中的 Knowledge Gradient 获取函数变体，适用于带解耦约束的问题，其中目标函数和约束的子集可独立进行评估。方法包括识别并聚焦于可能绑定的约束，从而仅评估相关约束以最大化信息增益，并与现有约束获取函数进行对比。

Result: 通过对比基准实验，所提方法在与现有方法的基准中表现出显著的性能提升，证实其在实际场景中的有效性。

Conclusion: 解耦约束的 KG 变体能提高昂贵全局优化的样本效率，当只有少数约束绑定时，能显著优于状态-of-the-art。

Abstract: Bayesian optimisation has proven to be a powerful tool for expensive global black-box optimisation problems. In this paper, we propose new Bayesian optimisation variants of the popular Knowledge Gradient acquisition functions for problems with \emph{decoupled} black-box constraints, in which subsets of the objective and constraint functions may be evaluated independently. In particular, our methods aim to take into account that often only a handful of the constraints may be binding at the optimum, and hence we should evaluate only relevant constraints when trying to optimise a function. We empirically benchmark these methods against existing methods and demonstrate their superiority over the state-of-the-art.

</details>


### [65] [GreedySnake: Accelerating SSD-Offloaded LLM Training with Efficient Scheduling and Optimizer Step Overlapping](https://arxiv.org/abs/2512.17570)
*Yikang Yue,Yishu Yin,Xuehai Qian*

Main category: cs.LG

TL;DR: GreedySnake is an SSD-offloaded training system that uses vertical scheduling to improve LLM training throughput by finishing all micro-batches for a layer before moving to the next, overlapping part of the optimization with the next forward pass to mitigate I/O bottlenecks; it outperforms horizontal scheduling and ZeRO-Infinity, achieving up to ~2x throughput gains on GPT-65B/175B models, with code released.


<details>
  <summary>Details</summary>
Motivation: 降低大规模LLM训练成本并提高吞吐，通过将数据存储卸载到SSD并优化微批次调度来缓解I/O瓶颈。

Method: 基于梯度累积的微批次训练，采用垂直调度（同层内完成所有微批次后再进入下一层），并在一定阶段将优化步骤与下一轮前向传播重叠；利用SSD卸载来减轻显存压力。

Result: 在A100 GPU上，相比ZeRO-Infinity，GPT-65B在1卡上提升约1.96x，4卡上约1.93x；GPT-175B在1卡上提升约2.53x。代码开源，地址提供。

Conclusion: 垂直调度与部分优化重叠显著缓解SSD卸载训练的I/O瓶颈，使训练吞吐量更接近理论Roofline极限，提升大模型训练的成本效率。

Abstract: SSD-offloaded training offers a practical and promising approach to making LLM training cost-effective. Building on gradient accumulation with micro-batches, this paper introduces GreedySnake, a new SSD-offloaded training system that employs vertical scheduling, which executes all microbatches of a layer before proceeding to the next. Compared to existing systems that use horizontal scheduling (i.e., executing micro-batches sequentially), GreedySnake achieves higher training throughput with smaller batch sizes, bringing the system much closer to the ideal scenario predicted by the roofline model. To further mitigate the I/O bottleneck, GreedySnake overlaps part of the optimization step with the forward pass of the next iteration. Experimental results on A100 GPUs show that GreedySnake achieves saturated training throughput improvements over ZeRO-Infinity: 1.96x on 1 GPU and 1.93x on 4 GPUs for GPT-65B, and 2.53x on 1 GPU for GPT-175B. The code is open-sourced at https://github.com/npz7yyk/GreedySnake

</details>


### [66] [Learning Safe Autonomous Driving Policies Using Predictive Safety Representations](https://arxiv.org/abs/2512.17586)
*Mahesh Keswani,Raunak Bhattacharyya*

Main category: cs.LG

TL;DR: SRPL extends SafeRL for autonomous driving by using predictive safety representations to balance reward and safety, showing improved performance on WOMD and NuPlan with robustness gains, though effectiveness depends on policy optimizer and dataset.


<details>
  <summary>Details</summary>
Motivation: In autonomous driving, optimizing performance under strict safety constraints is crucial; traditional methods face a tension between conservatism and exploration. Predictive safety representations aim to forecast future constraint violations to enable safer learning.

Method: Apply the Safety Representations for Safer Policy Learning (SRPL) framework with a predictive model of future constraint violations; evaluate on Waymo Open Motion Dataset (WOMD) and NuPlan; assess reward-safety tradeoff, robustness to observation noise, and zero-shot cross-dataset generalization; report effect sizes and statistical significance.

Result: SRPL improves the reward-safety tradeoff, with statistically significant improvements in success rate (effect sizes r=0.65–0.86) and cost reduction (r=0.70–0.83; p<0.05). Its effectiveness depends on the underlying policy optimizer and dataset distribution. Predictive safety representations enhance robustness to observation noise and improve zero-shot cross-dataset generalization.

Conclusion: Predictive safety representations are a promising direction to strengthen SafeRL for real-world autonomous driving, offering improved safety-performance tradeoffs and generalization, though their benefits hinge on policy choice and data distribution.

Abstract: Safe reinforcement learning (SafeRL) is a prominent paradigm for autonomous driving, where agents are required to optimize performance under strict safety requirements. This dual objective creates a fundamental tension, as overly conservative policies limit driving efficiency while aggressive exploration risks safety violations. The Safety Representations for Safer Policy Learning (SRPL) framework addresses this challenge by equipping agents with a predictive model of future constraint violations and has shown promise in controlled environments. This paper investigates whether SRPL extends to real-world autonomous driving scenarios. Systematic experiments on the Waymo Open Motion Dataset (WOMD) and NuPlan demonstrate that SRPL can improve the reward-safety tradeoff, achieving statistically significant improvements in success rate (effect sizes r = 0.65-0.86) and cost reduction (effect sizes r = 0.70-0.83), with p < 0.05 for observed improvements. However, its effectiveness depends on the underlying policy optimizer and the dataset distribution. The results further show that predictive safety representations play a critical role in improving robustness to observation noise. Additionally, in zero-shot cross-dataset evaluation, SRPL-augmented agents demonstrate improved generalization compared to non-SRPL methods. These findings collectively demonstrate the potential of predictive safety representations to strengthen SafeRL for autonomous driving.

</details>


### [67] [Sharing Knowledge without Sharing Data: Stitches can improve ensembles of disjointly trained models](https://arxiv.org/abs/2512.17592)
*Arthur Guijt,Dirk Thierens,Ellen Kerkhof,Jan Wiersma,Tanja Alderliesten,Peter A. N. Bosman*

Main category: cs.LG

TL;DR: 在不共享权重的异步协作中，通过引入拼接层将独立训练的模型整合，达到对多方数据的竞争性性能；多目标视角揭示单方数据训练的局部优势与跨方性能损失的权衡，拼接策略提升泛化并恢复性能。


<details>
  <summary>Details</summary>
Motivation: 动机是医疗等领域的数据分散导致难以直接共享；联邦学习虽能解决数据分布问题，但需要参与方同步训练和交换模型权重，存在延时和隐私/安全挑战。本研究探讨在非同步、异步协作条件下，通过中间表示拼接实现跨方模型组合的可行性与效果。

Method: 方法包括：1) 采用多目标视角对每个参与方的数据性能进行独立评估；2) 在每个方独立训练模型；3) 设计并插入一对拼接层，将各自的中间表示进行融合，形成可在异步场景下使用的组合模型；4) 与仅在单方数据上训练、以及把数据在方之间简单合并等基线方法进行对比；5) 评估拼接层对保持良好泛化与恢复跨方性能的影响。

Result: 研究发现：仅在单方数据上训练的模型，与将其与另一方数据合并后在该单方数据上评估的性能相近，但在其他方数据上的性能明显下降；使用独立训练的模型的集成可以实现更好的泛化，但对各方自身数据的性能会下降；通过在独立模型的中间表示上添加恰当的两层拼接结构，能够在保持改进泛化的同时，显著提升或恢复对多方数据的竞争性性能，表明异步协作是可行且具潜力的。

Conclusion: 结论是，在不需要共享权重的异步协作场景中，利用中间表示拼接层可有效整合独立训练的模型，获得接近或可与同步方法相竞争的性能，同时提升泛化能力，为隐私保护下的跨方协作提供了一条有前景的途径。

Abstract: Deep learning has been shown to be very capable at performing many real-world tasks. However, this performance is often dependent on the presence of large and varied datasets. In some settings, like in the medical domain, data is often fragmented across parties, and cannot be readily shared. While federated learning addresses this situation, it is a solution that requires synchronicity of parties training a single model together, exchanging information about model weights. We investigate how asynchronous collaboration, where only already trained models are shared (e.g. as part of a publication), affects performance, and propose to use stitching as a method for combining models.
  Through taking a multi-objective perspective, where performance on each parties' data is viewed independently, we find that training solely on a single parties' data results in similar performance when merging with another parties' data, when considering performance on that single parties' data, while performance on other parties' data is notably worse. Moreover, while an ensemble of such individually trained networks generalizes better, performance on each parties' own dataset suffers. We find that combining intermediate representations in individually trained models with a well placed pair of stitching layers allows this performance to recover to a competitive degree while maintaining improved generalization, showing that asynchronous collaboration can yield competitive results.

</details>


### [68] [A Systems-Theoretic View on the Convergence of Algorithms under Disturbances](https://arxiv.org/abs/2512.17598)
*Guner Dilsad Er,Sebastian Trimpe,Michael Muehlebach*

Main category: cs.LG

TL;DR: 在存在扰动、噪声和系统耦合的情况下，推导算法收敛与稳定性界限，并给出基于对偶Lyapunov定理的扰动影响量化，提供一个在噪声环境下分析算法行为的统一工具。


<details>
  <summary>Details</summary>
Motivation: 在实际系统中，算法往往暴露于扰动和与其他动力系统耦合，需从理论上扩展孤立情形的收敛性到有扰动情形。

Method: 利用对偶Lyapunov定理推导关键不等式，量化扰动对收敛率和稳定性的影响，并将结果应用于分布式学习通信约束、机器学习泛化的敏感性、以及隐私噪声注入等场景。

Result: 给出稳定界和收敛速率的上/下界，作为评估算法在噪声与耦合环境中的性能的统一工具。

Conclusion: 该框架可作为分析在噪声、干扰及与其他动力系统耦合的算法时的统一分析工具，帮助理解和设计鲁棒算法。

Abstract: Algorithms increasingly operate within complex physical, social, and engineering systems where they are exposed to disturbances, noise, and interconnections with other dynamical systems. This article extends known convergence guarantees of an algorithm operating in isolation (i.e., without disturbances) and systematically derives stability bounds and convergence rates in the presence of such disturbances. By leveraging converse Lyapunov theorems, we derive key inequalities that quantify the impact of disturbances. We further demonstrate how our result can be utilized to assess the effects of disturbances on algorithmic performance in a wide variety of applications, including communication constraints in distributed learning, sensitivity in machine learning generalization, and intentional noise injection for privacy. This underpins the role of our result as a unifying tool for algorithm analysis in the presence of noise, disturbances, and interconnections with other dynamical systems.

</details>


### [69] [More Consistent Accuracy PINN via Alternating Easy-Hard Training](https://arxiv.org/abs/2512.17607)
*Zhaoqian Gao,Min Yanga*

Main category: cs.LG

TL;DR: 提出一种将硬性与易于训练的优先化策略交替结合的混合训练方法，用于 PINN 的 PDE 求解，在具有梯度陡峭、非线性和高维度的方程上实现高精度和鲁棒性；相对于基线方法，相对 L2 误差达到 1e-5~1e-6。


<details>
  <summary>Details</summary>
Motivation: 现有的硬优先化与易优先化在 PINN 的训练中各有优劣，但对不同 PDE 的表现不一致，亟需一种在多类问题上兼具高效与稳定的训练策略。

Method: 提出一种交替训练算法，将硬优先化与易优先化结合，通过交替的训练阶段来融合两者的优势，形成混合型的权重/采样策略以提升对尖锐梯度、非线性和高维问题的拟合能力。

Result: 在梯度陡峭、非线性强和高维度的 PDE 上，该方法实现相对 L2 误差在 1e-5–1e-6 的水平，显著优于基线方法，并表现出对多类问题的更高鲁棒性和一致性。

Conclusion: 混合训练策略可提升 PINNs 的性能与鲁棒性，为设计更稳健的 PINN 训练框架提供新的思路。

Abstract: Physics-informed neural networks (PINNs) have recently emerged as a prominent paradigm for solving partial differential equations (PDEs), yet their training strategies remain underexplored. While hard prioritization methods inspired by finite element methods are widely adopted, recent research suggests that easy prioritization can also be effective. Nevertheless, we find that both approaches exhibit notable trade-offs and inconsistent performance across PDE types. To address this issue, we develop a hybrid strategy that combines the strengths of hard and easy prioritization through an alternating training algorithm. On PDEs with steep gradients, nonlinearity, and high dimensionality, the proposed method achieves consistently high accuracy, with relative L2 errors mostly in the range of O(10^-5) to O(10^-6), significantly surpassing baseline methods. Moreover, it offers greater reliability across diverse problems, whereas compared approaches often suffer from variable accuracy depending on the PDE. This work provides new insights into designing hybrid training strategies to enhance the performance and robustness of PINNs.

</details>


### [70] [SCOPE: Sequential Causal Optimization of Process Interventions](https://arxiv.org/abs/2512.17629)
*Jakob De Moor,Hans Weytjens,Johannes De Smedt,Jochen De Weerdt*

Main category: cs.LG

TL;DR: 提出SCOPE，一种基于因果学习的PresPM序列干预方法，通过向后推导实现逐步干预对最终KPI的影响，能直接使用观测数据并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实场景中干预并非孤立；需对多次干预序列进行对齐以共同优化结果。现有PresPM多聚焦单次干预，或将多次干预独立处理，忽视时间依赖；而将其建模为RL往往需模拟或数据增强，导致现实差距和偏差。

Method: SCOPE通过向后推导(backward induction)估计每个候选干预动作的效果，将其影响从最终决策点向前传播到初始点；利用因果学习器，使得可直接利用观测数据而不需要为RL构建过程近似。

Result: 在一个现有的合成数据集和一个基于现实事件日志的新半合成数据集上实验，SCOPE在优化KPI方面持续优于最先进的PresPM方法；新引入的半合成基准基于真实事件日志，具备可复用性。

Conclusion: SCOPE实现了对序列干预的对齐建议，解决干预之间的相互影响问题，并可直接利用观测数据；同时提供可复用的半合成基准，促进后续对序列PresPM的研究。

Abstract: Prescriptive Process Monitoring (PresPM) recommends interventions during business processes to optimize key performance indicators (KPIs). In realistic settings, interventions are rarely isolated: organizations need to align sequences of interventions to jointly steer the outcome of a case. Existing PresPM approaches fall short in this respect. Many focus on a single intervention decision, while others treat multiple interventions independently, ignoring how they interact over time. Methods that do address these dependencies depend either on simulation or data augmentation to approximate the process to train a Reinforcement Learning (RL) agent, which can create a reality gap and introduce bias. We introduce SCOPE, a PresPM approach that learns aligned sequential intervention recommendations. SCOPE employs backward induction to estimate the effect of each candidate intervention action, propagating its impact from the final decision point back to the first. By leveraging causal learners, our method can utilize observational data directly, unlike methods that require constructing process approximations for reinforcement learning. Experiments on both an existing synthetic dataset and a new semi-synthetic dataset show that SCOPE consistently outperforms state-of-the-art PresPM techniques in optimizing the KPI. The novel semi-synthetic setup, based on a real-life event log, is provided as a reusable benchmark for future work on sequential PresPM.

</details>


### [71] [Trust-Region Adaptive Policy Optimization](https://arxiv.org/abs/2512.17636)
*Mingyu Su,Jian Guan,Yuxian Gu,Minlie Huang,Hongning Wang*

Main category: cs.LG

TL;DR: TRAPO是一种在每个训练实例中交替进行SFT与RL的混合训练框架，通过在专家前缀上优化SFT损失、在模型自我完成上优化RL损失来统一外部监督与自我探索；并引入TrSFT与自适应前缀选择机制以提升稳定性和效率，在五个数学推理基准上优于传统SFT、RL及SFT-RL等方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有两阶段管线（先SFT后RL）中存在的刚性模仿导致的探索受限与遗忘问题，推动RL在推理能力提升中的潜力发挥。

Method: TRAPO在每个训练样本中交替优化：对专家前缀应用SFT损失，对模型自我完成应用RL损失；引入Trust-Region SFT（TrSFT）在前向KL约束的可信域内最小化，超出部分降低优化强度，从而实现向逆KL的偏好，获得对RL友好的模式聚焦更新；同时设计自适应前缀选择机制，基于测量的效用分配专家指导。

Result: 在五个数学推理基准上，TRAPO对比标准SFT、RL及SFT-then-RL管线以及最新方法，表现出一致的性能提升，确立了一个新的推理增强型LLM训练范式。

Conclusion: TRAPO通过将信任域约束的SFT和自我探索的RL有机结合，并辅以自适应前缀分配，稳定且有效地提升推理能力，，为推理增强型大语言模型提供了强有力的新范式。

Abstract: Post-training methods, especially Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), play an important role in improving large language models' (LLMs) complex reasoning abilities. However, the dominant two-stage pipeline (SFT then RL) suffers from a key inconsistency: SFT enforces rigid imitation that suppresses exploration and induces forgetting, limiting RL's potential for improvements. We address this inefficiency with TRAPO (\textbf{T}rust-\textbf{R}egion \textbf{A}daptive \textbf{P}olicy \textbf{O}ptimization), a hybrid framework that interleaves SFT and RL within each training instance by optimizing SFT loss on expert prefixes and RL loss on the model's own completions, unifying external supervision and self-exploration. To stabilize training, we introduce Trust-Region SFT (TrSFT), which minimizes forward KL divergence inside a trust region but attenuates optimization outside, effectively shifting toward reverse KL and yielding stable, mode-seeking updates favorable for RL. An adaptive prefix-selection mechanism further allocates expert guidance based on measured utility. Experiments on five mathematical reasoning benchmarks show that TRAPO consistently surpasses standard SFT, RL, and SFT-then-RL pipelines, as well as recent state-of-the-art approaches, establishing a strong new paradigm for reasoning-enhanced LLMs.

</details>


### [72] [You Only Train Once: Differentiable Subset Selection for Omics Data](https://arxiv.org/abs/2512.17678)
*Daphné Chopard,Jorge da Silva Gonçalves,Irene Cannistraci,Thomas M. Sutter,Julia E. Vogt*

Main category: cs.LG

TL;DR: YOTO proposes an end-to-end, differentiable framework that jointly selects discrete gene subsets and performs prediction on single-cell RNA-seq data, using a closed feedback loop with sparsity constraints and multi-task learning, achieving superior performance and compact gene subsets.


<details>
  <summary>Details</summary>
Motivation: The goal is to obtain compact, informative gene subsets for biomarker discovery, interpretability, and cost-effective profiling. Existing methods are often multi-stage or rely on post hoc feature attribution, leading to weak coupling between selection and prediction.

Method: An end-to-end differentiable architecture that jointly selects discrete gene subsets and predicts outcomes. Sparsity is enforced so only selected genes contribute at inference. A closed feedback loop lets prediction guide gene selection and vice versa. Multi-task learning enables shared representations and leveraging partially labeled data, promoting cross-task generalization.

Result: Evaluated on two representative single-cell RNA-seq datasets, YOTO consistently outperforms state-of-the-art baselines, yielding sparse, meaningful gene subsets and improved predictive performance that generalizes across tasks without extra training steps.

Conclusion: Sparse, end-to-end, multi-task gene subset selection enhances predictive accuracy and interpretability, reduces reliance on downstream classifiers, and facilitates biomarker discovery in single-cell analysis.

Abstract: Selecting compact and informative gene subsets from single-cell transcriptomic data is essential for biomarker discovery, improving interpretability, and cost-effective profiling. However, most existing feature selection approaches either operate as multi-stage pipelines or rely on post hoc feature attribution, making selection and prediction weakly coupled. In this work, we present YOTO (you only train once), an end-to-end framework that jointly identifies discrete gene subsets and performs prediction within a single differentiable architecture. In our model, the prediction task directly guides which genes are selected, while the learned subsets, in turn, shape the predictive representation. This closed feedback loop enables the model to iteratively refine both what it selects and how it predicts during training. Unlike existing approaches, YOTO enforces sparsity so that only the selected genes contribute to inference, eliminating the need to train additional downstream classifiers. Through a multi-task learning design, the model learns shared representations across related objectives, allowing partially labeled datasets to inform one another, and discovering gene subsets that generalize across tasks without additional training steps. We evaluate YOTO on two representative single-cell RNA-seq datasets, showing that it consistently outperforms state-of-the-art baselines. These results demonstrate that sparse, end-to-end, multi-task gene subset selection improves predictive performance and yields compact and meaningful gene subsets, advancing biomarker discovery and single-cell analysis.

</details>


### [73] [Mitigating Forgetting in Low Rank Adaptation](https://arxiv.org/abs/2512.17720)
*Joanna Sliwa,Frank Schneider,Philipp Hennig,Jose Miguel Hernandez-Lobato*

Main category: cs.LG

TL;DR: LaLoRA: 在LoRA权重上应用拉普拉斯近似的权重空间正则化，以抑制在高曲率方向上的更新，从而在参数高效微调中减少遗忘，并通过正则化强度直接控制学习-遗忘权衡。


<details>
  <summary>Details</summary>
Motivation: 解决在使用参数高效微调方法（如LoRA）时，模型在新领域上快速适应的同时易发生对原有知识的灾难性遗忘的问题。

Method: 对LoRA权重仅应用拉普拉斯近似，估计每个参数的重要性/置信度，并在高曲率方向对更新进行约束，从而在保持LoRA轻量化的前提下保护原有知识。还比较了不同的曲率近似、分析用于近似的训练数据对结果的影响，并考察超参数鲁棒性。

Result: 在对Llama模型进行数学推理微调时，显示出更好的学习-遗忘权衡，且该平衡能通过正则化强度直接控制。对参数置信度估计、曲率近似以及数据选择的分析显示该方法具有鲁棒性并维持了轻量化特性。

Conclusion: 把拉普拉斯近似应用到LoRA权重上是一种高效且有效的权重空间正则化思路，能够在保持LoRA轻量级的同时提高保留先验知识的能力，并且提供了对曲率近似和数据选择的进一步研究方向以提升性能与鲁棒性。

Abstract: Parameter-efficient fine-tuning methods, such as Low-Rank Adaptation (LoRA), enable fast specialization of large pre-trained models to different downstream applications. However, this process often leads to catastrophic forgetting of the model's prior domain knowledge. We address this issue with LaLoRA, a weight-space regularization technique that applies a Laplace approximation to Low-Rank Adaptation. Our approach estimates the model's confidence in each parameter and constrains updates in high-curvature directions, preserving prior knowledge while enabling efficient target-domain learning. By applying the Laplace approximation only to the LoRA weights, the method remains lightweight. We evaluate LaLoRA by fine-tuning a Llama model for mathematical reasoning and demonstrate an improved learning-forgetting trade-off, which can be directly controlled via the method's regularization strength. We further explore different loss landscape curvature approximations for estimating parameter confidence, analyze the effect of the data used for the Laplace approximation, and study robustness across hyperparameters.

</details>


### [74] [Can You Hear Me Now? A Benchmark for Long-Range Graph Propagation](https://arxiv.org/abs/2512.17762)
*Luca Miglior,Matteo Tolloso,Alessio Gravina,Davide Bacciu*

Main category: cs.LG

TL;DR: 提出了 ECHO 基准，用于系统性评估 GNN 在极长距离传播中的能力，包含三项合成任务与两组化学数据集，揭示现有GNN在长程信息传递上的不足并给出潜在的设计方向。


<details>
  <summary>Details</summary>
Motivation: 长期以来，捕捉图结构中远距离信息传播是 GNN 研究的核心挑战之一，现有基准难以严格测试模型在极长信息传递中的表现。需要一个专门针对长程传播的综合评估框架和数据集来推动方法改进。

Method: 设计并实现 ECHO 基准：(1) 三个合成图任务（单源最短路径、节点离心性、图直径），在结构复杂、信息 bottleneck 明显的拓扑上构造任务；(2) 两组真实世界数据集（ECHO-Charge、ECHO-Energy），基于化学领域，标签来自密度泛函理论（DFT），天然依赖长程分子相互作用；(3) 对流行的 GNN 架构进行广泛基准评测。

Result: 基准测试显示现有 GNN 在处理极长程传播时存在显著性能差距，说明“真正的”长程传播能力尚未被充分实现；某些设计选择可以在一定程度上缓解瓶颈，指向改进方向。

Conclusion: ECHO 为评估长程信息传播建立了新的标准，并且可推动 AI for science 领域在长距离图信息传递方面的研究和应用。

Abstract: Effectively capturing long-range interactions remains a fundamental yet unresolved challenge in graph neural network (GNN) research, critical for applications across diverse fields of science. To systematically address this, we introduce ECHO (Evaluating Communication over long HOps), a novel benchmark specifically designed to rigorously assess the capabilities of GNNs in handling very long-range graph propagation. ECHO includes three synthetic graph tasks, namely single-source shortest paths, node eccentricity, and graph diameter, each constructed over diverse and structurally challenging topologies intentionally designed to introduce significant information bottlenecks. ECHO also includes two real-world datasets, ECHO-Charge and ECHO-Energy, which define chemically grounded benchmarks for predicting atomic partial charges and molecular total energies, respectively, with reference computations obtained at the density functional theory (DFT) level. Both tasks inherently depend on capturing complex long-range molecular interactions. Our extensive benchmarking of popular GNN architectures reveals clear performance gaps, emphasizing the difficulty of true long-range propagation and highlighting design choices capable of overcoming inherent limitations. ECHO thereby sets a new standard for evaluating long-range information propagation, also providing a compelling example for its need in AI for science.

</details>


### [75] [Calibratable Disambiguation Loss for Multi-Instance Partial-Label Learning](https://arxiv.org/abs/2512.17788)
*Wei Tang,Yin-Fang Yang,Weijia Zhang,Min-Ling Zhang*

Main category: cs.LG

TL;DR: 提出可插拔的可校准消解损失 (CDL)，用于多实例部分标签学习（MIPL）和部分标签学习（PLL），通过两种实例化方式实现对候选标签集及候选+非候选标签集的概率校准，理论分析支持其下界与正则化性质，实验显示在分类与校准性能上显著优于传统消解损失，且可无缝插入现有框架。


<details>
  <summary>Details</summary>
Motivation: 现有的 MIPL 在标签和实例空间中均处于弱监督状态，往往导致预测的校准性不足，影响可靠性。需在不显著增加计算复杂度的前提下提升分类准确性与概率校准。

Method: 提出 CDL，具有两种 instantiations：1) 基于候选标签集概率进行校准；2) 同时整合候选与非候选标签集的概率进行校准。CDL 可作为“plug-and-play”组件嵌入现有的 MIPL/PLL 框架，理论上给出 CDL 的下界与正则化性质，证明其优于传统消解损失。

Result: 在基准数据集和真实数据集上，CDL 显著提升分类性能与概率校准能力，相较传统方法表现更优。

Conclusion: CDL 能同时提升分类准确性与校准性，具备理论支撑与良好实证效果，且具备良好的可嵌入性，适用于现有 MIPL/PLL 框架。

Abstract: Multi-instance partial-label learning (MIPL) is a weakly supervised framework that extends the principles of multi-instance learning (MIL) and partial-label learning (PLL) to address the challenges of inexact supervision in both instance and label spaces. However, existing MIPL approaches often suffer from poor calibration, undermining classifier reliability. In this work, we propose a plug-and-play calibratable disambiguation loss (CDL) that simultaneously improves classification accuracy and calibration performance. The loss has two instantiations: the first one calibrates predictions based on probabilities from the candidate label set, while the second one integrates probabilities from both candidate and non-candidate label sets. The proposed CDL can be seamlessly incorporated into existing MIPL and PLL frameworks. We provide a theoretical analysis that establishes the lower bound and regularization properties of CDL, demonstrating its superiority over conventional disambiguation losses. Experimental results on benchmark and real-world datasets confirm that our CDL significantly enhances both classification and calibration performance.

</details>


### [76] [Exploiting ID-Text Complementarity via Ensembling for Sequential Recommendation](https://arxiv.org/abs/2512.17820)
*Liam Collins,Bhuvesh Kumar,Clark Mingxuan Ju,Tong Zhao,Donald Loveland,Leonardo Neves,Neil Shah*

Main category: cs.LG

TL;DR: 研究ID嵌入与文本模态在序列推荐中的互补性。发现两种特征存在互补信号，单独使用任一特征都能提升时也能受益于另一个特征的加入。提出通过独立模型训练以保持互补性，并通过简单的集成策略利用互补性，效果优于若干基线，表明同时使用ID和文本特征且不需要复杂的融合架构即可达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 当前SR领域要么用文本/模态嵌入完全替代ID嵌入，要么与ID+模态特征共存但使用复杂的多阶段训练与对齐结构，缺乏对ID与模态特征互补性的理解。本研究旨在揭示两类特征的互补性及其在实际系统中的利用方法。

Method: 首先分析ID-文本SR模型之间的信号互补性；在此基础上提出一个简单的SR方案：分别训练独立的ID模型与文本模型以保持互补性，再通过简单的集成策略融合两者的输出。

Result: 实证结果显示，该简单的独立训练+集成方法在多组基线中表现领先，验证了ID与文本特征的互补性，同时表明要达到SOTA并非必须采取复杂的融合架构。

Conclusion: ID与文本特征对序列推荐具有互补性，且通过独立训练并简单集成即可充分利用这一互补性，从而实现更好的推荐性能，挑战了需要复杂融合架构的观点。

Abstract: Modern Sequential Recommendation (SR) models commonly utilize modality features to represent items, motivated in large part by recent advancements in language and vision modeling. To do so, several works completely replace ID embeddings with modality embeddings, claiming that modality embeddings render ID embeddings unnecessary because they can match or even exceed ID embedding performance. On the other hand, many works jointly utilize ID and modality features, but posit that complex fusion strategies, such as multi-stage training and/or intricate alignment architectures, are necessary for this joint utilization. However, underlying both these lines of work is a lack of understanding of the complementarity of ID and modality features. In this work, we address this gap by studying the complementarity of ID- and text-based SR models. We show that these models do learn complementary signals, meaning that either should provide performance gain when used properly alongside the other. Motivated by this, we propose a new SR method that preserves ID-text complementarity through independent model training, then harnesses it through a simple ensembling strategy. Despite this method's simplicity, we show it outperforms several competitive SR baselines, implying that both ID and text features are necessary to achieve state-of-the-art SR performance but complex fusion architectures are not.

</details>


### [77] [Weighted Stochastic Differential Equation to Implement Wasserstein-Fisher-Rao Gradient Flow](https://arxiv.org/abs/2512.17878)
*Herlock Rahimi*

Main category: cs.LG

TL;DR: WFR-based diffusion samplers augment traditional diffusion with mass reweighting via Wasserstein–Fisher–Rao geometry, implemented through weighted SDEs and Feynman–Kac corrections; aims to improve exploration in nonconvex/multimodal targets.


<details>
  <summary>Details</summary>
Motivation: Overdamped/underdamped diffusion samplers mix poorly for nonconvex or multimodal targets, limiting sampling efficiency in high-dimensional generative modeling. The work investigates WFR geometry to better explore such landscapes by coupling transport with reaction dynamics and mass reweighting.

Method: Introduce explicit correction terms to reweight mass in diffusion samplers under Wasserstein–Fisher–Rao framework; implement via weighted stochastic differential equations and Feynman–Kac representation; analyze geometric and operator-theoretic structure.

Result: Preliminary, rigorous characterization of WFR-based sampling dynamics; derives formulation and properties linking reweighting to diffusion in WFR geometry; sets groundwork for theoretical/algorithmic development.

Conclusion: WFR-based reweighting provides a principled extension to diffusion samplers, aligning transport and reaction dynamics; further work needed to develop concrete algorithms and to quantify gains in sampling efficiency for nonconvex targets.

Abstract: Score-based diffusion models currently constitute the state of the art in continuous generative modeling. These methods are typically formulated via overdamped or underdamped Ornstein--Uhlenbeck-type stochastic differential equations, in which sampling is driven by a combination of deterministic drift and Brownian diffusion, resulting in continuous particle trajectories in the ambient space. While such dynamics enjoy exponential convergence guarantees for strongly log-concave target distributions, it is well known that their mixing rates deteriorate exponentially in the presence of nonconvex or multimodal landscapes, such as double-well potentials. Since many practical generative modeling tasks involve highly non-log-concave target distributions, considerable recent effort has been devoted to developing sampling schemes that improve exploration beyond classical diffusion dynamics.
  A promising line of work leverages tools from information geometry to augment diffusion-based samplers with controlled mass reweighting mechanisms. This perspective leads naturally to Wasserstein--Fisher--Rao (WFR) geometries, which couple transport in the sample space with vertical (reaction) dynamics on the space of probability measures. In this work, we formulate such reweighting mechanisms through the introduction of explicit correction terms and show how they can be implemented via weighted stochastic differential equations using the Feynman--Kac representation. Our study provides a preliminary but rigorous investigation of WFR-based sampling dynamics, and aims to clarify their geometric and operator-theoretic structure as a foundation for future theoretical and algorithmic developments.

</details>


### [78] [Regularized Random Fourier Features and Finite Element Reconstruction for Operator Learning in Sobolev Space](https://arxiv.org/abs/2512.17884)
*Xinyue Yu,Hayden Schaeffer*

Main category: cs.LG

TL;DR: 提出了一种正则化的随机傅里叶特征-有限元重建映射（RRFF-FEM）的算子学习框架，用来自多变量学生分布的随机特征和带有频率加权的Tikhonov正则化来抑制高频噪声，在训练样本量m与特征数N满足N≈m log m时，系统条件良好，理论上给出误差与泛化保证。实验表明该方法对噪声鲁棒、训练时间更短，与未正则化的随机特征、核方法和神经算子在准确性上竞争。


<details>
  <summary>Details</summary>
Motivation: 在无限维函数空间上的算子学习需要高效、可解释且对噪声鲁棒的近似。核方法虽理论可控但计算成本高且对大规模训练敏感。需要一种在噪声环境下也能提供理论保证、且训练高效的算子学习方法。

Method: 采用多元Student分布的随机特征，以及带有频率权重的Tikhonov正则化以抑制高频噪声，结合有限元重建映射（FEM）来获取算子输出。理论上给出随机特征矩阵的极端奇异值的高概率界定；若特征数N与训练样本数m之比满足N≈m log m，则系统条件良好，进而给出估计与泛化保证。通过对一系列PDE基准问题（对流、 Burgers、 Darcy、 Helmholtz、 Navier–Stokes、结构力学）进行数值实验，验证鲁棒性、训练时间的改进以及与核/神经算子方法的竞争力。

Result: 给出了在高概率意义下随机特征矩阵的极值奇异值界限，并证明在N≈m log m下系统可良好条件化，从而获得误差和泛化界面的理论保障。大量数值实验证明：RRFF及RRFF-FEM对噪声具有鲁棒性，训练时间相较未正则化方法显著降低，且在与核方法和神经算子测试的准确性上保持竞争力。

Conclusion: RRFF-FEM提供了一种在噪声环境下也具备理论保证且计算高效的算子学习框架，是核方法与神经算子在PDE算子学习领域的有力竞争者，尤其在需要处理大型训练集时表现突出。

Abstract: Operator learning is a data-driven approximation of mappings between infinite-dimensional function spaces, such as the solution operators of partial differential equations. Kernel-based operator learning can offer accurate, theoretically justified approximations that require less training than standard methods. However, they can become computationally prohibitive for large training sets and can be sensitive to noise. We propose a regularized random Fourier feature (RRFF) approach, coupled with a finite element reconstruction map (RRFF-FEM), for learning operators from noisy data. The method uses random features drawn from multivariate Student's $t$ distributions, together with frequency-weighted Tikhonov regularization that suppresses high-frequency noise. We establish high-probability bounds on the extreme singular values of the associated random feature matrix and show that when the number of features $N$ scales like $m \log m$ with the number of training samples $m$, the system is well-conditioned, which yields estimation and generalization guarantees. Detailed numerical experiments on benchmark PDE problems, including advection, Burgers', Darcy flow, Helmholtz, Navier-Stokes, and structural mechanics, demonstrate that RRFF and RRFF-FEM are robust to noise and achieve improved performance with reduced training time compared to the unregularized random feature model, while maintaining competitive accuracy relative to kernel and neural operator tests.

</details>
