<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 24]
- [cs.IT](#cs.IT) [Total: 16]
- [eess.SP](#eess.SP) [Total: 25]
- [eess.SY](#eess.SY) [Total: 17]
- [cs.LG](#cs.LG) [Total: 12]
- [cs.NI](#cs.NI) [Total: 7]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Trojans in Artificial Intelligence (TrojAI) Final Report](https://arxiv.org/abs/2602.07152)
*Kristopher W. Reese,Taylor Kulp-McDowall,Michael Majurski,Tim Blattner,Derek Juba,Peter Bajcsy,Antonio Cardone,Philippe Dessauw,Alden Dima,Anthony J. Kearsley,Melinda Kleczynski,Joel Vasanth,Walid Keyrouz,Chace Ashcraft,Neil Fendley,Ted Staley,Trevor Stout,Josh Carney,Greg Canal,Will Redman,Aurora Schmidt,Cameron Hickert,William Paul,Jared Markowitz,Nathan Drenkow,David Shriver,Marissa Connor,Keltin Grimes,Marco Christiani,Hayden Moore,Jordan Widjaja,Kasimir Gabert,Uma Balakrishnan,Satyanadh Gundimada,John Jacobellis,Sandya Lakkur,Vitus Leung,Jon Roose,Casey Battaglino,Farinaz Koushanfar,Greg Fields,Xihe Gu,Yaman Jandali,Xinqiao Zhang,Akash Vartak,Tim Oates,Ben Erichson,Michael Mahoney,Rauf Izmailov,Xiangyu Zhang,Guangyu Shen,Siyuan Cheng,Shiqing Ma,XiaoFeng Wang,Haixu Tang,Di Tang,Xiaoyi Chen,Zihao Wang,Rui Zhu,Susmit Jha,Xiao Lin,Manoj Acharya,Wenchao Li,Chao Chen*

Main category: cs.CR

TL;DR: IARPA TrojAI项目针对AI模型中的后门威胁进行了深入研究，提出基于权重分析和触发器逆向的检测方法，评估其效果，并给出未来改进AI安全的建议。


<details>
  <summary>Details</summary>
Motivation: 解决现代AI模型中隐藏的恶意后门——AI Trojan，这些后门可能导致系统失效或被恶意攻击。

Method: 通过权重分析和触发器逆向的方法检测AI后门，并评估其在已部署模型中的风险。

Result: 实验评估显示检测器性能、灵敏度及“天然”后门的普遍性，并揭示了尚未解决的挑战。

Conclusion: 报告总结了IARPA TrojAI计划对AI后门威胁的研究成果，并提出了改进AI安全的建议。

Abstract: The Intelligence Advanced Research Projects Activity (IARPA) launched the TrojAI program to confront an emerging vulnerability in modern artificial intelligence: the threat of AI Trojans. These AI trojans are malicious, hidden backdoors intentionally embedded within an AI model that can cause a system to fail in unexpected ways, or allow a malicious actor to hijack the AI model at will. This multi-year initiative helped to map out the complex nature of the threat, pioneered foundational detection methods, and identified unsolved challenges that require ongoing attention by the burgeoning AI security field. This report synthesizes the program's key findings, including methodologies for detection through weight analysis and trigger inversion, as well as approaches for mitigating Trojan risks in deployed models. Comprehensive test and evaluation results highlight detector performance, sensitivity, and the prevalence of "natural" Trojans. The report concludes with lessons learned and recommendations for advancing AI security research.

</details>


### [2] [Lite-BD: A Lightweight Black-box Backdoor Defense via Reviving Multi-Stage Image Transformations](https://arxiv.org/abs/2602.07197)
*Abdullah Arafat Miah,Yu Bi*

Main category: cs.CR

TL;DR: Lite-BD 采用先下采样后上采样消除空间触发器，再用频带滤波去除隐藏触发器，证明在黑盒场景下既高效又鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有黑盒净化技术缺乏变换合理性说明、对数据集敏感、计算开销大、忽略频域处理。

Method: 1) 超分辨率下-上采样消除空间触发器；2) 基于查询的带频率滤波去除特定频带的触发器。

Result: 在多种先进攻击下实验表明 Lite-BD 在保护准确率与计算效率上均优于现有方案。

Conclusion: Lite-BD 通过双阶段轻量化黑盒防御有效消除基于图像下-上采样的搏击触发器，具备高鲁棒性与高效性。

Abstract: Deep Neural Networks (DNNs) are vulnerable to backdoor attacks. Due to the nature of Machine Learning as a Service (MLaaS) applications, black-box defenses are more practical than white-box methods, yet existing purification techniques suffer from key limitations: a lack of justification for specific transformations, dataset dependency, high computational overhead, and a neglect of frequency-domain transformations. This paper conducts a preliminary study on various image transformations, identifying down-upscaling as the most effective backdoor trigger disruption technique. We subsequently propose \texttt{Lite-BD}, a lightweight two-stage blackbox backdoor defense. \texttt{Lite-BD} first employs a super-resolution-based down-upscaling stage to neutralize spatial triggers. A secondary stage utilizes query-based band-by-band frequency filtering to remove triggers hidden in specific bands. Extensive experiments against state-of-the-art attacks demonstrate that \texttt{Lite-BD} provides robust and efficient protection. Codes can be found at https://github.com/SiSL-URI/Lite-BD.

</details>


### [3] [Hydra: Robust Hardware-Assisted Malware Detection](https://arxiv.org/abs/2602.07240)
*Eli Propp,Seyed Majid Zahedi*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Malware detection using Hardware Performance Counters (HPCs) offers a promising, low-overhead approach for monitoring program behavior. However, a fundamental architectural constraint, that only a limited number of hardware events can be monitored concurrently, creates a significant bottleneck, leading to detection blind spots. Prior work has primarily focused on optimizing machine learning models for a single, statically chosen event set, or on ensembling models over the same feature set. We argue that robustness requires diversifying not only the models, but also the underlying feature sets (i.e., the monitored hardware events) in order to capture a broader spectrum of program behavior. This observation motivates the following research question: Can detection performance be improved by trading temporal granularity for broader coverage, via the strategic scheduling of different feature sets over time? To answer this question, we propose Hydra, a novel detection mechanism that partitions execution traces into time slices and learns an effective schedule of feature sets and corresponding classifiers for deployment. By cycling through complementary feature sets, Hydra mitigates the limitations of a fixed monitoring perspective. Our experimental evaluation shows that Hydra significantly outperforms state-of-the-art single-feature-set baselines, achieving a 19.32% improvement in F1 score and a 60.23% reduction in false positive rate. These results underscore the importance of feature-set diversity and establish strategic multi-feature-set scheduling as an effective principle for robust, hardware-assisted malware detection.

</details>


### [4] [Beyond Crash: Hijacking Your Autonomous Vehicle for Fun and Profit](https://arxiv.org/abs/2602.07249)
*Qi Sun,Ahmed Abdo,Luis Burbano,Ziyang Li,Yaxing Yao,Alvaro Cardenas,Yinzhi Cao*

Main category: cs.CR

TL;DR: JackZebra通过可视化补丁与闭环控制实现对视觉自驾车的路线劫持。


<details>
  <summary>Details</summary>
Motivation: 传统对抗攻击往往关注即时安全失败，缺乏对长期路线完整性威胁的研究。需要理解在不触发明显错误的情况下，攻击者如何对视觉自驾车实施渐进式路由劫持。

Method: JackZebra将路由劫持视为闭环控制问题，通过将对抗补丁转换为在线可选的转向原语，并在光照、天气、交通等变化下保持有效。采用可重构后置显示装置投射专门设计的补丁，利用实时交互循环对车辆轨迹进行调整。

Result: 实验表明，JackZebra在多种环境下实现了高成功率的路由劫持，可使受害车辆偏离原始路线并停在攻击者指定的目标位置。

Conclusion: 本文展示了JackZebra框架能够在视觉端到端驾驶系统中实现路由级劫持，成功将受害车辆引离原始路线并驶向攻击者设定的目的地。

Abstract: Autonomous Vehicles (AVs), especially vision-based AVs, are rapidly being deployed without human operators. As AVs operate in safety-critical environments, understanding their robustness in an adversarial environment is an important research problem. Prior physical adversarial attacks on vision-based autonomous vehicles predominantly target immediate safety failures (e.g., a crash, a traffic-rule violation, or a transient lane departure) by inducing a short-lived perception or control error. This paper shows a qualitatively different risk: a long-horizon route integrity compromise, where an attacker gradually steers a victim AV away from its intended route and into an attacker-chosen destination while the victim continues to drive "normally." This will not pose a danger to the victim vehicle itself, but also to potential passengers sitting inside the vehicle.
  In this paper, we design and implement the first adversarial framework, called JackZebra, that performs route-level hijacking of a vision-based end-to-end driving stack using a physically plausible attacker vehicle with a reconfigurable display mounted on the rear. The central challenge is temporal persistence: adversarial influence must remain effective in changing viewpoints, lighting, weather, traffic, and the victim's continual replanning -- without triggering conspicuous failures. Our key insight is to treat route hijacking as a closed-loop control problem and to convert adversarial patches into steering primitives that can be selected online via an interactive adjustment loop. Our adversarial patches are also carefully designed against worst-case background and sensor variations so that the adversarial impacts on the victim. Our evaluation shows that JackZebra can successfully hijack victim vehicles to deviate from original routes and stop at adversarial destinations with a high success rate.

</details>


### [5] [Patch-to-PoC: A Systematic Study of Agentic LLM Systems for Linux Kernel N-Day Reproduction](https://arxiv.org/abs/2602.07287)
*Juefei Pu,Xingyu Li,Haonan Li,Zhengchuan Liang,Jonathan Cox,Yifan Wu,Kareem Shehada,Arrdya Srivastav,Zhiyun Qian*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Autonomous large language model (LLM) based systems have recently shown promising results across a range of cybersecurity tasks. However, there is no systematic study on their effectiveness in autonomously reproducing Linux kernel vulnerabilities with concrete proofs-of-concept (PoCs). Owing to the size, complexity, and low-level nature of the Linux kernel, such tasks are widely regarded as particularly challenging for current LLM-based approaches.
  In this paper, we present the first large-scale study of LLM-based Linux kernel vulnerability reproduction. For this purpose, we develop K-Repro, an LLM-based agentic system equipped with controlled code-browsing, virtual machine management, interaction, and debugging capabilities. Using kernel security patches as input, K-Repro automates end-to-end bug reproduction of N-day vulnerabilities in the Linux kernel. On a dataset of 100 real-world exploitable Linux kernel vulnerabilities collected from KernelCTF, our results show that K-Repro can generate PoCs that reproduce over 50\% of the cases with practical time and monetary cost.
  Beyond aggregate success rates, we perform an extensive study of effectiveness, efficiency, stability, and impact factors to explain when agentic reproduction succeeds, where it fails, and which components drive performance. These findings provide actionable guidance for building more reliable autonomous security agents and for assessing real-world N-day risk from both offensive and defensive perspectives.

</details>


### [6] [ACORN-IDS: Adaptive Continual Novelty Detection for Intrusion Detection Systems](https://arxiv.org/abs/2602.07291)
*Sean Fuhrman,Onat Gungor,Tajana Rosing*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Intrusion Detection Systems (IDS) must maintain reliable detection performance under rapidly evolving benign traffic patterns and the continual emergence of cyberattacks, including zero-day threats with no labeled data available. However, most machine learning-based IDS approaches either assume static data distributions or rely on labeled attack samples, substantially limiting their applicability in real-world deployments. This setting naturally motivates continual novelty detection, which enables IDS models to incrementally adapt to non-stationary data streams without labeled attack data. In this work, we introduce ACORN-IDS, an adaptive continual novelty detection framework that learns exclusively from normal data while exploiting the inherent structure of an evolving unlabeled data stream. ACORN-IDS integrates a continual feature extractor, trained using reconstruction and metric learning objectives with clustering-based pseudo-labels, alongside a PCA-based reconstruction module for anomaly scoring. This design allows ACORN-IDS to continuously adapt to distributional shifts in both benign and malicious traffic. We conduct an extensive evaluation of ACORN-IDS on five realistic intrusion datasets under two continual learning scenarios: (i) Evolving Attacks and (ii) Evolving Normal and Attack Distributions. ACORN-IDS achieves, on average, a 62% improvement in F1-score and a 58% improvement in zero-day attack detection over the state-of-the-art unsupervised continual learning baseline. It also outperforms existing state-of-the-art novelty detection approaches while exhibiting near-zero forgetting and imposing minimal inference overhead. These results demonstrate that ACORN-IDS offers a practical, label-efficient solution for building adaptive and robust IDS in dynamic, real-world environments. We plan to release the code upon acceptance.

</details>


### [7] [Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model](https://arxiv.org/abs/2602.07422)
*Tianyi Wu,Mingzhe Du,Yue Liu,Chengran Yang,Terry Yue Zhuo,Jiaheng Zhang,See-Kiong Ng*

Main category: cs.CR

TL;DR: SecCoderX 结合漏洞检测与奖励建模的在线 RL，使得代码 LLM 在保持功能的同时，显著提升安全性，提升ESR约10%。


<details>
  <summary>Details</summary>
Motivation: LLM 在软件开发中的安全风险高，现有安全编码对齐方法往往以牺牲功能为代价；迫切需要在保持功能的同时显著提升代码安全性。

Method: 采用在线强化学习框架：①利用成熟漏洞检测资源合成真实场景下的漏洞诱发任务；②训练基于推理的漏洞奖励模型为 RL 提供规模化、可靠的安全监督；三者在在线 RL 循环中统一，指导模型生成安全且功能完好的代码。

Result: 在大规模实验中，SecCoderX 的有效安全率（ESR）比未对齐模型提升约10%，而传统方法往往导致ESR下降14-54%。

Conclusion: SecCoderX 将代码 LLM 对齐至既安全又保持功能强大的输出来，成功解决了“功能―安全”矛盾。

Abstract: Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains a major barrier to real-world deployment. Existing secure code alignment methods often suffer from a functionality--security paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionality-preserving secure code generation. SecCoderX first bridges vulnerability detection and secure code generation by repurposing mature detection resources in two ways: (i) synthesizing diverse, reality-grounded vulnerability-inducing coding tasks for online RL rollouts, and (ii) training a reasoning-based vulnerability reward model that provides scalable and reliable security supervision. Together, these components are unified in an online RL loop to align code LLMs to generate secure and functional code. Extensive experiments demonstrate that SecCoderX achieves state-of-the-art performance, improving Effective Safety Rate (ESR) by approximately 10% over unaligned models, whereas prior methods often degrade ESR by 14-54%. We release our code, dataset and model checkpoints at https://github.com/AndrewWTY/SecCoderX.

</details>


### [8] [SoK: Credential-Based Trust Management in Decentralized Ledger Systems](https://arxiv.org/abs/2602.07572)
*Yanna Jiang,Haiyu Deng,Qin Wang,Guangsheng Yu,Xu Wang,Yilin Sai,Shiping Chen,Wei Ni,Ren Ping Liu*

Main category: cs.CR

TL;DR: 本文对凭证式分布式信任管理系统进行系统综述，提供分类与评估框架，发现挑战并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着去中心化系统和区块链的发展，对基于凭证的DTMS需求日益突出，但理论与实践之间存在鸿沟，需要系统化的研究。

Method: 综述法：对现有DTMS进行多维度分析，包括体系结构、凭证机制和信任评估模型，并基于此构建了评价准则与分类体系。

Result: 识别了当前DTMS中的关键挑战与研究方向，确定了体系结构、凭证策略、信任评估等方面的差距，并为访问控制、声誉系统及区块链信任框架等应用提供了洞见。

Conclusion: 本文通过系统综述，梳理并评估了以凭证为核心的分布式信任管理系统（DTMS），提出了详细的分类学和评估标准，为未来研究和实践提供了指导。

Abstract: Trust management systems (TMS) are crucial for managing trust in distributed environments. The rise of decentralized systems and blockchain has sparked interest in credential-based decentralized trust management systems (DTMS). This paper bridges the gap between theory and practice through a systematic review of credential-based DTMS. We analyze existing DTMS solutions through multiple dimensions, including their architectural designs, credential mechanisms, and trust evaluation models. Our survey provides a detailed taxonomy of credential-based DTMS approaches and establishes comprehensive evaluation criteria for assessing DTMS implementations. Through extensive analysis of current systems and implementations, we identify critical challenges and promising research directions in the field. Our examination offers valuable insights for researchers and practitioners working on DTMS, particularly in areas such as access control, reputation systems, and blockchain-based trust frameworks.

</details>


### [9] [AirCatch: Effectively tracing advanced tag-based trackers](https://arxiv.org/abs/2602.07656)
*Abhishek Kumar Mishra,Swadeep,Guevara Noubir,Mathieu Cunche*

Main category: cs.CR

TL;DR: AirCatch用CFO指纹和高密度检测算法对抗快速识别符旋转的追踪器，在资源受限部署可行，实验显示无误报，早期检测效果好。


<details>
  <summary>Details</summary>
Motivation: 传统的基于协议的防护在面对高速识别符旋转的恶意追踪器时失效，需寻找更稳健的物理层防御方案；

Method: 利用调制感知的载波频率偏移（CFO）指纹，基于高核心密度与持久性检测算法，并通过约10美元的BlePhasyr SDR实现低成本部署；

Result: 在多品牌标签、多小时捕获、模拟攻击生成器及真实移动场景中，AirCatch在无误报的前提下实现了早期检测，并仅在极低率时退化；

Conclusion: AirCatch提供了一种基于物理层的被动检测系统，能够在标签识别符快速旋转的情况下识别并阻止非法跟踪，且在各种环境下无误报；

Abstract: Tag-based tracking ecosystems help users locate lost items, but can be leveraged for unwanted tracking and stalking. Existing protocol-driven defenses and prior academic solutions largely assume stable identifiers or predictable beaconing. However, identifier-based defenses fundamentally break down against advanced rogue trackers that aggressively rotate identifiers. We present AirCatch, a passive detection system that exploits a physical-layer constraint: while logical identifiers can change arbitrarily fast, the transmitter's analog imprint remains stable and reappears as a compact and persistently occupied region in Carrier Frequency Offset (CFO) feature space. AirCatch advances the state of the art along three axes: (i) a novel, modulation-aware CFO fingerprint that augments packet-level CFO with content-independent CFO components that amplify device distinctiveness; (ii) a new tracking detection algorithm based on high core density and persistence that is robust to contamination and evasion through per-identifier segmentation; and (iii) an ultra-low-cost receiver, an approximately 10 dollar BLE SDR named BlePhasyr, built from commodity components, that makes RF fingerprinting based detection practical in resource-constrained deployments. We evaluate AirCatch across Apple, Google, Tile, and Samsung tag families in multi-hour captures, systematically stress-test evasion using a scenario generator over a grid of transmission and rotation periods, and validate in diverse real-world mobility traces including home and office commutes, public transport, car travel, and airport journeys while sweeping background tag density. Across these stress tests, AirCatch achieves no false positives and early detection over a wide range of adversarial configurations and environments, degrading gracefully only in extreme low-rate regimes that also reduce attacker utility.

</details>


### [10] [IPBAC: Interaction Provenance-Based Access Control for Secure and Privacy-Aware Systems](https://arxiv.org/abs/2602.07722)
*Sharif Noor Zisad,Ragib Hasan*

Main category: cs.CR

TL;DR: 引入交互来源记录到访问控制，弥补RBAC灵活性和追溯性不足，提升安全合规管理。


<details>
  <summary>Details</summary>
Motivation: RBAC等传统模型在角色定义僵化、动态环境适配不足以及追溯性差方面存在缺陷，亟需更灵活、可追踪的控制方法。

Method: 将交互来源数据（行动者身份、时间、上下文等元数据）采集并嵌入到访问控制决策流程中，形成基于交互用途的访问策略。

Result: 实现了更强的未授权访问防护、显著提升审计追溯的准确性与完整性，并支持自适应安全策略。

Conclusion: IPBAC通过结合交互来源数据提升了对未经授权访问的防护、审计和合规性追踪能力，形成更灵活、可适应动态环境的访问控制框架。

Abstract: Traditional access control systems, including RBAC, face significant limitations such as inflexible role definitions, difficulty handling dynamic scenarios, and lack of detailed accountability and traceability. To this end, we introduce the Interaction Provenance-based Access Control (IPBAC) model. In this paper, we explore the integration of interaction provenance with access control to overcome these limitations. Interaction provenance refers to the detailed recording of actions and interactions within a system, capturing comprehensive metadata such as the identity of the actor, the time of an action, and the context. IPBAC ensures stronger protection against unauthorized access, enhances traceability for auditing and compliance, and supports adaptive security policies. This provenance-based access control not only strengthens security, but also provides a robust framework for auditing and compliance.

</details>


### [11] [Leveraging the Power of Ensemble Learning for Secure Low Altitude Economy](https://arxiv.org/abs/2602.07725)
*Yaoqi Yang,Yong Chen,Jiacheng Wang,Geng Sun,Dusit Niyato,Zhu Han*

Main category: cs.CR

TL;DR: 利用多模型集成提升低空经济恶意飞机入侵检测准确率与效率，案例证明其可行性，建议进一步探索模型组合与自适应方法


<details>
  <summary>Details</summary>
Motivation: 提升低空经济安全，防御恶意飞机入侵，满足多变环境与资源受限设备的需求

Method: 采用集成学习框架，融合多模型优点，提出恶意飞机跟踪的IDS方案，并通过案例研究评估其可行性与效果

Result: 展示了集成学习相较单模型能显著提升检测准确率、适应性与资源利用率，并在案例中验证了其可行性与有效性

Conclusion: 集成学习在低空经济安全检测中具有显著优势，未来研究可聚焦于模型选择、资源节约与在线自适应改进

Abstract: Low Altitude Economy (LAE) holds immense promise for enhancing societal well-being and driving economic growth. However, this burgeoning field is vulnerable to security threats, particularly malicious aircraft intrusion attacks. To address the above concerns, intrusion detection systems (IDS) can be used to defend against malicious aircraft intrusions in LAE. Whereas, due to the heterogeneous data, dynamic environment, and resource-constrained devices within LAE, current IDS face challenges in detection accuracy, adaptability, and resource utilization ratio. In this regard, due to the inherent ability to combine the strengths of multiple models, ensemble learning can realize more robust and diverse anomaly detection further enhance IDS accuracy, thereby improving robustness and efficiency of the secure LAE. Unlike single-model approaches, ensemble learning can leverage the collective knowledge of its constituent models to effectively defend the malicious aircraft intrusion attacks. Specifically, this paper investigates ensemble learning for secure LAE, covering research focuses, solutions, and a case study. We first establish the rationale for ensemble learning and then review research areas and potential solutions, demonstrating the necessities and benefits of applying ensemble learning to secure LAE. Subsequently, we propose a framework of ensemble learning-enabled malicious aircrafts tracking in the secure LAE, where its feasibility and effectiveness are evaluated by the designed case study. Finally, we conclude by outlining promising future research directions for further advancing the ensemble learning-enabled secure LAE.

</details>


### [12] [Rethinking Latency Denial-of-Service: Attacking the LLM Serving Framework, Not the Model](https://arxiv.org/abs/2602.07878)
*Tianyi Wang,Huawei Fan,Yuanchao Shu,Peng Cheng,Cong Wang*

Main category: cs.CR

TL;DR: LLM服务对算法延迟攻击具备抵抗力，但易受Fill+Squeeze系统层攻击影响，实验证明在黑盒环境下能以更低成本实现显著性能压制。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）推理成本高昂，即使是轻微的延迟也会导致显著的运营费用和可用性风险，目前的研究多聚焦于通过构造输入触发最坏情况输出长度的算法复杂度攻击，但发现这些算法层面攻击在现代LLM服务中效果有限。

Method: 提出新的系统层级攻击策略——Fill与Squeeze。Fill阶段耗尽全局kv缓存以引发Head-of-Line阻塞；Squeeze阶段强制系统进入重复抢占周期。攻击使用从简单纯文本提示到复杂提示工程的输入长度操控，辅以内存状态的侧信道探测，实现在黑盒场景中的低成本实施。

Result: 实验显示相较于已有攻击，Fill＆Squeeze在Time to First Token上平均产生20–280×的延迟降低，Time Per Output Token上平均降低1.5–4×，同时攻击成本降低30–40%。该攻击利用系统级优化的薄弱点，能够显著削弱LLM服务的性能。

Conclusion: 算法层面的延迟攻击在现代LLM服务中多被连续批处理等优化屏蔽，系统层面的fill‑squeeze攻击通过操控调度状态实现更高效延迟控制。因此，LLM安全应关注系统调度与缓存管理，而非仅依赖算法改进。

Abstract: Large Language Models face an emerging and critical threat known as latency attacks. Because LLM inference is inherently expensive, even modest slowdowns can translate into substantial operating costs and severe availability risks. Recently, a growing body of research has focused on algorithmic complexity attacks by crafting inputs to trigger worst-case output lengths. However, we report a counter-intuitive finding that these algorithmic latency attacks are largely ineffective against modern LLM serving systems. We reveal that system-level optimization such as continuous batching provides a logical isolation to mitigate contagious latency impact on co-located users. To this end, in this paper, we shift the focus from the algorithm to the system layer, and introduce a new Fill and Squeeze attack strategy targeting the state transition of the scheduler. "Fill" first exhausts the global KV cache to induce Head-of-Line blocking, while "Squeeze" forces the system into repetitive preemption. By manipulating output lengths using methods from simple plain-text prompts to more complex prompt engineering, and leveraging side-channel probing of memory status, we demonstrate that the attack can be orchestrated in a black-box setting with much less cost. Extensive evaluations indicate by up to 20-280x average slowdown on Time to First Token and 1.5-4x average slowdown on Time Per Output Token compared to existing attacks with 30-40% lower attack cost.

</details>


### [13] [Privacy-Preserving Covert Communication Using Encrypted Wearable Gesture Recognition](https://arxiv.org/abs/2602.07936)
*Tasnia Ashrafi Heya,Sayed Erfan Arefin*

Main category: cs.CR

TL;DR: 通过同态加密实现可穿戴设备上的隐蔽手势识别，准确率94.44%，支持从高端到低端设备的部署。


<details>
  <summary>Details</summary>
Motivation: 在隐蔽或防护关键情境下，语音对话易暴露用户意图。传统可穿戴手势通信会泄漏原始传感器数据、中间特征或分类结果，导致意图推断、行为生物识别泄露以及内置信任攻击。

Method: 采用多方同态加密学习管道，直接在加密运动数据上进行手势识别，防止任何第三方获取原始信号、学习特征或语义输出。

Result: 使用600条商用智能手表手势样本评测，分类准确率超过94.44%，并在从高性能系统到资源受限边缘设备的不同硬件上验证部署可行性。

Conclusion: 首次将加密手势识别应用于可穿戴隐蔽通信，构建了既能保护隐私又能实际部署的低功耗系统。

Abstract: Secure communication is essential in covert and safety-critical settings where verbal interactions may expose user intent or operational context. Wearable gesture-based communication enables low-effort, nonverbal interaction, but existing systems leak motion data, intermediate representations, or inference outputs to untrusted infrastructure, enabling intent inference, behavioral biometric leakage, and insider attacks. This work proposes a privacy-preserving gesture-based covert communication system that ensures, no raw sensor signals, learned features, or classification outputs are exposed to any third-party. The system employs a multi-party homomorphic learning pipeline for gesture recognition directly over encrypted motion data, preventing adversaries from inferring gesture semantics, replaying sensor traces, or accessing intermediate representations. To our knowledge, this work is the first to apply encrypted gesture recognition in a wearable-based covert communication setting. We design and evaluate haptic and visual feedback mechanisms for covert signal delivery and evaluate the system using 600 gesture samples from a commodity smartwatch, achieving over 94.44% classification accuracy and demonstrating the feasibility of the proposed system with practical deployability from high-performance systems to resource-constrained edge devices.

</details>


### [14] [IssueGuard: Real-Time Secret Leak Prevention Tool for GitHub Issue Reports](https://arxiv.org/abs/2602.08072)
*Md Nafiu Rahman,Sadif Ahmed,Zahin Wahab,Gias Uddin,Rifat Shahriyar*

Main category: cs.CR

TL;DR: IssueGuard是一款Chrome扩展，通过正则+CodeBERT实时检测issue文本中的密钥，F1达92.7%，可防止秘密泄露


<details>
  <summary>Details</summary>
Motivation: 解决GitHub和GitLab issue跟踪系统中因未加密文本导致的API密钥等秘密信息泄露问题

Method: Chrome扩展实时检测输入文本，使用正则提取候选密钥，再利用Fine-tuned CodeBERT进行上下文分类，过滤误报

Result: 在基准数据集上F1分数92.70%，显著优于传统纯正则扫描器

Conclusion: IssueGuard在Web界面中无缝集成，能够实时提示并防止敏感数据提交，提升开发协作安全性

Abstract: GitHub and GitLab are widely used collaborative platforms whose issue-tracking systems contain large volumes of unstructured text, including logs, code snippets, and configuration examples. This creates a significant risk of accidental secret exposure, such as API keys and credentials, yet these platforms provide no mechanism to warn users before submission. We present \textsc{IssueGuard}, a tool for real-time detection and prevention of secret leaks in issue reports. Implemented as a Chrome extension, \textsc{IssueGuard} analyzes text as users type and combines regex-based candidate extraction with a fine-tuned CodeBERT model for contextual classification. This approach effectively separates real secrets from false positives and achieves an F1-score of 92.70\% on a benchmark dataset, outperforming traditional regex-based scanners. \textsc{IssueGuard} integrates directly into the web interface and continuously analyzes the issue editor, presenting clear visual warnings to help users avoid submitting sensitive data. The source code is publicly available at \href{https://github.com/nafiurahman00/IssueGuard}{https://github.com/nafiurahman00/IssueGuard}, and a demonstration video is available at \href{https://youtu.be/kvbWA8rr9cU}{https://youtu.be/kvbWA8rr9cU}.

</details>


### [15] [A Transfer Learning Approach to Unveil the Role of Windows Common Configuration Enumerations in IEC 62443 Compliance](https://arxiv.org/abs/2602.08165)
*Miguel Bicudo,Estevão Rabello,Daniel Menasché,Paulo Segal,Claudio Segal,Anton Kocheturov,Priyanjan Sharma*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Industrial control systems (ICS) depend on highly heterogeneous environments where Linux, proprietary real-time operating systems, and Windows coexist. Although the IEC 62443-3-3 standard provides a comprehensive framework for securing such systems, translating its requirements into concrete configuration checks remains challenging, especially for Windows platforms. In this paper, we propose a transfer learning methodology that maps Windows Common Configuration Enumerations (CCEs) to IEC 62443-3-3 System Security Requirements by leveraging labeled Linux datasets. The resulting labeled dataset enables automated compliance checks, analysis of requirement prevalence, and identification of cross-platform similarities and divergences. Our results highlight the role of CCEs as a bridge between abstract standards and concrete configurations, advancing automation, traceability, and clarity in IEC 62443-3-3 compliance for Windows environments.

</details>


### [16] [Towards Real-World Industrial-Scale Verification: LLM-Driven Theorem Proving on seL4](https://arxiv.org/abs/2602.08384)
*Jianyu Zhang,Fuyuan Zhang,Jiayi Lu,Jilin Hu,Xiaoyi Yin,Long Zhang,Feng Yang,Yongwang Zhao*

Main category: cs.CR

TL;DR: AutoReal 利用链式思维训练与上下文增强，将 7B 规模模型在 seL4 和 AFP 上的证明成功率提升至约 52%，显著优于以往方法，并实现本地可部署。


<details>
  <summary>Details</summary>
Motivation: 传统形式化方法可靠但成本高，主要针对数学基准，工业规模验证缺乏有效支持；大型封闭模型无法本地部署。

Method: 提出AutoReal，通过链式思维训练（CoT）教导LLM推理过程，并利用项目上下文增强推理；在基模型上微调得到7B规模的AutoReal-Prover。

Result: 在seL4重要理论660条中，证明成功率达51.67%，显著高于先前27.06%；在AFP的451条定理也达到53.88%成功率，表明良好泛化能力。

Conclusion: AutoReal实现了轻量级、可本地部署的工业规模定理证明，展示LLM在实际验证任务中的可行性与优势。

Abstract: Formal methods (FM) are reliable but costly to apply, often requiring years of expert effort in industrial-scale projects such as seL4, especially for theorem proving. Recent advances in large language models (LLMs) have made automated theorem proving increasingly feasible. However, most prior work focuses on mathematics-oriented benchmarks such as miniF2F, with limited evaluation on real-world verification projects. The few studies that consider industrial-scale verification mostly rely on closed-source models with hundreds of billions of parameters, which cannot be locally deployed and incur substantial usage costs. In this paper, we propose AutoReal, an LLM-driven theorem proving method for real-world industrial-scale systems with support for lightweight local deployment. We evaluate AutoReal on the seL4-Isabelle verification project as a representative and challenging case study. AutoReal incorporates two key improvements: (1) chain-of-thought (CoT)-based proof training, which teaches the LLM the reasoning behind proof steps and enables step-wise explanations alongside proofs, and (2) context augmentation, which leverages proof context from the project to enhance LLM-driven proving. Based on the AutoReal methodology, we fine-tune a base model to obtain AutoReal-Prover, a compact 7B-scale prover for industrial-scale theorem proving. AutoReal-Prover achieves a 51.67% proof success rate on 660 theorems from seL4-designated Important Theories across all 10 seL4 proof categories, substantially outperforming prior attempts on seL4 (27.06%). To evaluate generalization, we further apply AutoReal-Prover to three security-related projects from the Archive of Formal Proofs (AFP), covering all 451 theorems and achieving a proof success rate of 53.88%. Overall, this work advances the application of LLM-driven theorem proving in real-world industrial-scale verification.

</details>


### [17] [LLMs + Security = Trouble](https://arxiv.org/abs/2602.08422)
*Benjamin Livshits*

Main category: cs.CR

TL;DR: 本文指出现有 AI 代码安全方法缺陷，并建议采用受限解码在代码生成阶段直接嵌入安全约束，以实现更可靠的安全保证。


<details>
  <summary>Details</summary>
Motivation: 传统的“以火攻火”方法——使用概率 AI 检查器或攻击者来保护概率生成的代码——无法解决长期尾部的安全缺陷；神经符号方法难以与 LLM 辅助开发的“气氛编码”工作流程对齐，导致人机交互成为弱点。

Method: 利用扩散式代码模型的受限解码和模块化、层级化的安全约束实现安全可构建代码的生成。

Result: 提出并讨论了在代码生成阶段直接强制执行安全约束的可行性，为实现更安全的 LLM 生成代码奠定理论与技术基础。

Conclusion: 通过在代码生成阶段强制执行安全约束（如受限解码）可以获得更强的安全保证，而不是仅依赖事后检测和修复。

Abstract: We argue that when it comes to producing secure code with AI, the prevailing "fighting fire with fire" approach -- using probabilistic AI-based checkers or attackers to secure probabilistically generated code -- fails to address the long tail of security bugs. As a result, systems may remain exposed to zero-day vulnerabilities that can be discovered by better-resourced or more persistent adversaries.
  While neurosymbolic approaches that combine LLMs with formal methods are attractive in principle, we argue that they are difficult to reconcile with the "vibe coding" workflow common in LLM-assisted development: unless the end-to-end verification pipeline is fully automated, developers are repeatedly asked to validate specifications, resolve ambiguities, and adjudicate failures, making the human-in-the-loop a likely point of weakness, compromising secure-by-construction guarantees.
  In this paper we argue that stronger security guarantees can be obtained by enforcing security constraints during code generation (e.g., via constrained decoding), rather than relying solely on post-hoc detection and repair. This direction is particularly promising for diffusion-style code models, whose approach provides a natural elegant opportunity for modular, hierarchical security enforcement, allowing us to combine lower-latency generation techniques with generating secure-by-construction code.

</details>


### [18] [Retrieval Pivot Attacks in Hybrid RAG: Measuring and Mitigating Amplified Leakage from Vector Seeds to Graph Expansion](https://arxiv.org/abs/2602.08668)
*Scott Thornton*

Main category: cs.CR

TL;DR: Hybrid Retrieval-Augmented Generation管线可能在向量检索到知识图谱的过渡点形成跨租户数据泄漏；此风险可通过在图扩展边界实施单点授权检查消除，无需复杂防御。


<details>
  <summary>Details</summary>
Motivation: Hybrid RAG管线结合向量检索与知识图谱扩展，可用于多跳推理，但此组合会在向量-图界面产生向量检索到图的“枢轴”风险，导致敏感信息跨租户泄漏。

Method: 对多租户企业语料库和Enron邮件数据集进行实验，设计七种检索枢轴攻击，量化Leakage@k、Amplification Factor和Pivot Depth指标；随后在图扩展边界处强制执行授权，评估其对泄漏的抑制效果。

Result: 在未防护的Hybrid RAG中，检索枢轴风险RPR最高达0.95，且多次未授权项目被返回；Leakage统一出现在PD=2；在图扩展边界强制授权后，RPR降至近0，且对所有攻击变体及10%标签伪造率均有效，且开销极低。

Conclusion: 通过在向量检索与图扩展的转换点实施授权检查，可有效消除检索增强生成（RAG）管线中的跨租户数据泄漏风险（RPR接近0），证明单点边界授权比复杂防御更为关键。

Abstract: Hybrid Retrieval-Augmented Generation (RAG) pipelines combine vector similarity search with knowledge graph expansion for multi-hop reasoning. We show that this composition introduces a distinct security failure mode: a vector-retrieved "seed" chunk can pivot via entity links into sensitive graph neighborhoods, causing cross-tenant data leakage that does not occur in vector-only retrieval. We formalize this risk as Retrieval Pivot Risk (RPR) and introduce companion metrics Leakage@k, Amplification Factor, and Pivot Depth (PD) to quantify leakage magnitude and traversal structure.
  We present seven Retrieval Pivot Attacks that exploit the vector-to-graph boundary and show that adversarial injection is not required: naturally shared entities create cross-tenant pivot paths organically. Across a synthetic multi-tenant enterprise corpus and the Enron email corpus, the undefended hybrid pipeline exhibits high pivot risk (RPR up to 0.95) with multiple unauthorized items returned per query. Leakage consistently appears at PD=2, which we attribute to the bipartite chunk-entity topology and formalize as a proposition.
  We then show that enforcing authorization at a single location, the graph expansion boundary, eliminates measured leakage (RPR near 0) across both corpora, all attack variants, and label forgery rates up to 10 percent, with minimal overhead. Our results indicate the root cause is boundary enforcement, not inherently complex defenses: two individually secure retrieval components can compose into an insecure system unless authorization is re-checked at the transition point.

</details>


### [19] [Large Language Lobotomy: Jailbreaking Mixture-of-Experts via Expert Silencing](https://arxiv.org/abs/2602.08741)
*Jona te Lintelo,Lichao Wu,Stjepan Picek*

Main category: cs.CR

TL;DR: L\$^3\$ 是一种无需训练的攻击，通过学习专家路由并沉默关键安全专家，能大幅提升对 MoE LLM 的安全攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 揭示在效率为驱动的 Mixture-of-Experts (MoE) 大语言模型中，安全对齐与路由结构之间的潜在矛盾；

Method: 提出零训练、架构无关的攻击方法 L\$^3\$，通过学习路由模式并动态沉默与安全相关的专家，以突破安全屏障；

Result: 在 8 个顶级开源 MoE LLM 上测试，攻击成功率从 7.3% 提升至 70.4%，最高 86.3%，且仅需沉默 20% 以下的专家即可绕过安全防护，整体语言功能保持；

Conclusion: MoE 设计的效率优势与安全对齐存在根本冲突，暗示未来需采用更稳健的安全机制，结合架构与路由特性；

Abstract: The rapid adoption of Mixture-of-Experts (MoE) architectures marks a major shift in the deployment of Large Language Models (LLMs). MoE LLMs improve scaling efficiency by activating only a small subset of parameters per token, but their routing structure introduces new safety attack surfaces. We find that safety-critical behaviors in MoE LLMs (e.g., refusal) are concentrated in a small set of experts rather than being uniformly distributed. Building on this, we propose Large Language Lobotomy (L$^3$), a training-free, architecture-agnostic attack that compromises safety alignment by exploiting expert routing dynamics. L$^3$ learns routing patterns that correlate with refusal, attributes safety behavior to specific experts, and adaptively silences the most safety-relevant experts until harmful outputs are produced. We evaluate L$^3$ on eight state-of-the-art open-source MoE LLMs and show that our adaptive expert silencing increases average attack success from 7.3% to 70.4%, reaching up to 86.3%, outperforming prior training-free MoE jailbreak methods. Moreover, bypassing guardrails typically requires silencing fewer than 20% of layer-wise experts while largely preserving general language utility. These results reveal a fundamental tension between efficiency-driven MoE design and robust safety alignment and motivate distributing safety mechanisms more robustly in future MoE LLMs with architecture- and routing-aware methods.

</details>


### [20] [DyMA-Fuzz: Dynamic Direct Memory Access Abstraction for Re-hosted Monolithic Firmware Fuzzing](https://arxiv.org/abs/2602.08750)
*Guy Farrelly,Michael Chesser,Seyit Camtepe,Damith C. Ranasinghe*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rise of smart devices in critical domains--including automotive, medical, industrial--demands robust firmware testing. Fuzzing firmware in re-hosted environments is a promising method for automated testing at scale, but remains difficult due to the tight coupling of code with a microcontroller's peripherals. Existing fuzzing frameworks primarily address input challenges in providing inputs for Memory-Mapped I/O or interrupts, but largely overlook Direct Memory Access (DMA), a key high-throughput interface used that bypasses the CPU. We introduce DyMA-Fuzz to extend recent advances in stream-based fuzz input injection to DMA-driven interfaces in re-hosted environments. It tackles key challenges--vendor-specific descriptors, heterogeneous DMA designs, and varying descriptor locations--using runtime analysis techniques to infer DMA memory access patterns and automatically inject fuzzing data into target buffers, without manual configuration or datasheets. Evaluated on 94 firmware samples and 8 DMA-guarded CVE benchmarks, DyMA-Fuzz reveals vulnerabilities and execution paths missed by state-of-the-art tools and achieves up to 122% higher code coverage. These results highlight DyMA-Fuzz as a practical and effective advancement in automated firmware testing and a scalable solution for fuzzing complex embedded systems.

</details>


### [21] [CryptoGen: Secure Transformer Generation with Encrypted KV-Cache Reuse](https://arxiv.org/abs/2602.08798)
*Hedong Zhang,Neusha Javidnia,Shweta Pardeshi,Qian Lou,Farinaz Koushanfar*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The widespread deployment of cloud-hosted generative models raises a fundamental challenge: enabling efficient autoregressive generation while preserving the privacy of both user prompts and model parameters in untrusted environments. We address this challenge in a client-server setting where an untrusted server hosts an autoregressive Transformer and the client requires cryptographic protection for both inputs and inference. We present CryptoGen, the first system to enable scalable privacy-preserving neural generation with persistent encrypted key-value (KV) cache reuse. Discriminative-task secure inference systems incur quadratic latency and memory growth when adapted to autoregressive decoding due to the lack of native encrypted KV-cache support. In contrast, CryptoGen achieves near-linear scaling by securely reusing and updating encrypted KV caches throughout generation. CryptoGen integrates homomorphic encryption and secret sharing to support both prefilling and generation. Key techniques include a unified encrypted KV-cache framework, heterogeneous SIMD encodings for different phases, optimized cipher-cipher matrix-matrix and matrix-vector operations, and efficient noise refresh and ciphertext concatenation mechanisms. Evaluation on generative Transformer models trained on WikiText-2, PTB, and LAMBADA shows that for input lengths of 128-512 tokens, CryptoGen achieves 4.4x-7.6x lower per-token latency than state-of-the-art discriminative secure inference systems, while maintaining near-linear latency and memory scaling, with advantages increasing for longer sequences. CryptoGen is released as an open-source library.

</details>


### [22] [ZK-Rollup for Hyperledger Fabric: Architecture and Performance Evaluation](https://arxiv.org/abs/2602.08870)
*Sania Siddiqui,Neha,Hari Babu K*

Main category: cs.CR

TL;DR: 本文在Fabric上部署ZK Rollup Layer‑2方案，增加交易吞吐量10倍、延迟降低80%，保留权限链安全性。


<details>
  <summary>Details</summary>
Motivation: 在区块链平台，如何在提升可扩展性的同时保持用户隐私安全是长期难题。

Method: 在Hyperledger Fabric上实现了基于Zero Knowledge Rollups的Layer‑2扩容方案，采用离链排序器将交易即时收集，并通过Merkle树批量打包，生成ZK证明供链上验证。

Result: 通过拆分交易接收与链上清算过程，吞吐量从原来的5~7 TPS提升至70~100 TPS；客户端感知延迟从4秒降至700~1000毫秒，吞吐提升近十倍，延迟降低近八成。

Conclusion: 整合ZK Rollups后，Hyperledger Fabric既实现了显著的可扩展性提升，又未牺牲其本身的安全与权限机制。

Abstract: A big challenge posed in blockchain centric platforms is achieving scalability while also preserving user privacy. This report details the design, implementation and evaluation of a Layer-2 scaling solution for Hyperledger Fabric using Zero Knowledge Rollups (ZK Rollups). The proposed architecture introduces an off chain sequencer that accepts transactions immediately and sends them for batching into a Merkle tree based rollup, using ZK proofs to attest to the correctness and verifiability of the entire batch.
  The design aims to decouple transaction ingestion from actual on chain settlements to address Fabric scalability limitations and increase throughput under high load conditions. The baseline architecture in Hyperledger Fabric constrains transaction requests due to endorsement, ordering and validation phases, leading to a throughput of 5 to 7 TPS with an average latency of 4 seconds. Our Layer-2 solution achieves an ingestion throughput of 70 to 100 TPS, leading to an increase of nearly ten times due to the sequencer immediate acceptance of each transaction and reducing client perceived latency by nearly eighty percent to 700 to 1000 milliseconds. This work demonstrates that integrating ZK Rollups in Hyperledger Fabric enhances scalability while not compromising the security guarantees of a permissioned blockchain network.

</details>


### [23] [Reverse Online Guessing Attacks on PAKE Protocols](https://arxiv.org/abs/2602.08993)
*Eloise Christian,Tejas Gadwalkar,Arthur Azevedo de Amorim,Edward V. Zieglar*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Though not yet widely deployed, password-authenticated key exchange (PAKE) protocols have been the subject of several recent standardization efforts, partly because of their resistance against various guessing attacks, but also because they do not require a public-key infrastructure (PKI), making them naturally resistant against PKI failures. The goal of this paper is to reevaluate the PAKE model by noting that the absence of a PKI -- or, more generally, of a mechanism aside from the password for authenticating the server -- makes such protocols vulnerable to reverse online guessing attacks, in which an adversary attempts to validate password guesses by impersonating a server. While their logic is similar to traditional guessing, where the attacker impersonates a client, reverse guessing poses a unique risk because the burden of detection is shifted to the clients, rendering existing defenses against traditional guessing moot. Our results demonstrate that reverse guessing is particularly effective when an adversary attacks clients indiscriminately, such as in phishing or password-spraying attacks, or for applications with automated login processes or a universal password, such as WPA3-SAE. Our analysis suggests that stakeholders should, by default, authenticate the server using more stringent measures than just the user's password, and that a password-only mode of operation should be a last resort against catastrophic security failures when other authentication mechanisms are not available.

</details>


### [24] [CIC-Trap4Phish: A Unified Multi-Format Dataset for Phishing and Quishing Attachment Detection](https://arxiv.org/abs/2602.09015)
*Fatemeh Nejati,Mahdi Rabbani,Mansur Mirani,Gunjan Piya,Igor Opushnyev,Ali A. Ghorbani,Sajjad Dadkhah*

Main category: cs.CR

TL;DR: 提出统一多格式钓鱼附件数据集与轻量化检测管道，利用SHAP特征选择，随机森林等模型实现高精度识别，并通过CNN+词法方法双轮检测QR码钓鱼。


<details>
  <summary>Details</summary>
Motivation: 攻击者持续利用附件绕过安全措施，现有数据集不足导致模型训练受限，亟需涵盖多格式并提供简洁高效检测方案。

Method: 构建CIC-Trap4Phish数据集，设计无执行静态特征提取管道，结合SHAP和特征重要性进行特征选择，使用随机森林、XGBoost、决策树等轻量化模型；针对QR码采用CNN与URL词法分析。

Result: 所有模型在各文件格式上均达到较高检测准确率；CNN与词法模型在QR码攻击上亦表现优异。

Conclusion: 该研究通过多格式数据集与轻量化模型实现了对钓鱼邮件附件的高精度检测，尤其对QR码攻击提供了互补的CNN与语言模型方法。

Abstract: Phishing attacks represents one of the primary attack methods which is used by cyber attackers. In many cases, attackers use deceptive emails along with malicious attachments to trick users into giving away sensitive information or installing malware while compromising entire systems. The flexibility of malicious email attachments makes them stand out as a preferred vector for attackers as they can embed harmful content such as malware or malicious URLs inside standard document formats. Although phishing email defenses have improved a lot, attackers continue to abuse attachments, enabling malicious content to bypass security measures. Moreover, another challenge that researches face in training advance models, is lack of an unified and comprehensive dataset that covers the most prevalent data types. To address this gap, we generated CIC-Trap4Phish, a multi-format dataset containing both malicious and benign samples across five categories commonly used in phishing campaigns: Microsoft Word documents, Excel spreadsheets, PDF files, HTML pages, and QR code images. For the first four file types, a set of execution-free static feature pipeline was proposed, designed to capture structural, lexical, and metadata-based indicators without the need to open or execute files. Feature selection was performed using a combination of SHAP analysis and feature importance, yielding compact, discriminative feature subsets for each file type. The selected features were evaluated by using lightweight machine learning models, including Random Forest, XGBoost, and Decision Tree. All models demonstrate high detection accuracy across formats. For QR code-based phishing (quishing), two complementary methods were implemented: image-based detection by employing Convolutional Neural Networks (CNNs) and lexical analysis of decoded URLs using recent lightweight language models.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [25] [Single-shot lossy compression: mutual information bounds](https://arxiv.org/abs/2602.07280)
*Victoria Kostina*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: For several styles of fidelity constraints -- guaranteed distortion, conditional excess distortion, excess distortion -- we show mutual information upper bounds on the minimum expected description length needed to represent a random variable. Coupled with the corresponding converses, these results attest that as long as the information content in the data is not too low, minimizing the mutual information under an appropriate fidelity constraint serves as a reasonable proxy for the minimum description length of the data. We provide alternative characterizations of all three convex proxies, shedding light on the structure of their solutions.

</details>


### [26] [Information Theoretic Modeling of Interspecies Molecular Communication](https://arxiv.org/abs/2602.07474)
*Bitop Maitra,Murat Kuscu,Ozgur B. Akan*

Main category: cs.IT

TL;DR: 构建信息论模型评估植物-昆虫分子通信，发现风速、距离和释放量显著决定通信性能。


<details>
  <summary>Details</summary>
Motivation: 探讨在噪声环境（风、距离、生物反应）下，植物如何利用化学信号与昆虫交流，理解其对生态系统的信息传递机制。

Method: 通过将受体响应建模为多项分布，对化学信号的随机绑定事件进行定量化处理，并以离散持续时间形式构成接收观测，随后利用信息理论指标进行分析。

Result: 数值仿真指出，通信效率随风速、距离以及分子释放量变化显著，表明环境参数是影响VOCs交流的关键因素。

Conclusion: 该论文构建了一个信息论框架，揭示了环境因素（风速、距离、释放分子数）如何影响植物与昆虫之间基于VOCs的分子通信。

Abstract: Plants and insects communicate using chemical signals like volatile organic compounds (VOCs). A plant encodes information using different blends of VOCs, which propagate through the air to represent different symbolic information. This communication occurs in a noisy environment, characterized by wind, distance, and complex biological reactions. At the receiver, cross-reactive olfactory receptors produce stochastic binding events whose discretized durations form the receiver observation. In this paper, an information-theoretic framework is developed to model interspecies molecular communication (MC), where receptor responses are modeled probabilistically using a multinomial distribution. Numerical results show that the communication depends on environmental parameters such as wind speed, distance, and the number of released molecules. The proposed framework provides fundamental insights into the VOC-based interspecies communication under realistic biological and environmental conditions.

</details>


### [27] [Transformer-based Hybrid Beamforming with Dynamic Subarray for Near-Space Airship-Borne Communications](https://arxiv.org/abs/2602.07509)
*Ruiqi Wang,Zhen Gao,Keke Ying,Ziwei Wan,Symeon Chatzinotas,Mohamed-Slim Alouini*

Main category: cs.IT

TL;DR: 提出基于Transformer的DyHBFNet，通过动态子阵和模型驱动算法实现高效波束形成，实现能效与光谱效率双提升。


<details>
  <summary>Details</summary>
Motivation: 低能耗空船平台需要在能量受限条件下实现高能效通信。

Method: 1) 动态子阵连接策略；2) 采用Transformer编码器设计ABFNet、ASNet、DBFNet；3) 在DBFNet中使用模型驱动的加权MSE算法。

Result: 仿真表明该框架相较基线方案显著提升光谱效率与能效，并对CSI误差表现出更好的鲁棒性。

Conclusion: 通过动态子阵和Transformer驱动的混合波束形成框架，大幅提升近地空船基站的光谱效率与能效，并在不完美CSI下保持鲁棒性。

Abstract: This paper proposes a hybrid beamforming framework for massive multiple-input multiple-output (MIMO) in near-space airship-borne communications. To achieve high energy efficiency (EE) in energy-constraint airships, a dynamic subarray structure is introduced, where each radio frequency chain (RFC) is connected to a disjoint subset of the antennas according to channel state information (CSI). The proposed joint dynamic hybrid beamforming network (DyHBFNet) comprises three key components: 1) An analog beamforming network (ABFNet) that optimizes the analog beamforming matrices and provides auxiliary information for the antenna selection network (ASNet) design, 2) an ASNet that dynamically optimizes the connections between antennas and RFCs, and 3) a digital beamforming network (DBFNet) that optimizes digital beamforming matrices by employing a model-driven weighted minimum mean square error algorithm for improving beamforming performance and convergence speed. The proposed ABFNet, ASNet, and DBFNet are all designed based on advanced Transformer encoders. Simulation results demonstrate that the proposed framework significantly enhances spectral efficiency and EE compared to baseline schemes. Additionally, its robust performance under imperfect CSI makes it a scalable solution for practical implementations.

</details>


### [28] [Expected Recovery Time in DNA-based Distributed Storage Systems](https://arxiv.org/abs/2602.07601)
*Adi Levy,Roni Con,Eitan Yaakobi,Han Mao Kiah*

Main category: cs.IT

TL;DR: 在DNA存储中，随机抽样读取导致单容器失效，本文通过多容器分布式编码和推广的Coupon Collector分析，估算期望恢复时间，提出可行的方案与理论基础。


<details>
  <summary>Details</summary>
Motivation: DNA数据存储允许在高密度存储介质中保存大量信息，但受制于测序技术的随机性，单个容器的丢失可能导致数据损失。研究如何通过多容器分布式编码实现对单容器失效的纠正，以提高系统鲁棒性。

Method: 采用多容器分布式编码，利用随机读操作视为随机抽样，构造多基因缠倒的编码方案，并分析其基于Coupon Collector问题的期望恢复时间。通过对经典Coupon Collector问题的推广，解析在不同技术参数下的性能。

Result: 证明在合理参数选择下，采用适当的纠错码可以在可接受的读取次数内恢复失败容器的数据，期望恢复时间与容器数、容器容量和纠错码重度相关。进一步指出该分析框架可推广为相似随机抽样场景的通用方法。

Conclusion: 本文提出并分析了DNA分布式存储系统的容器失效恢复机制，提供了理论依据和性能预估，为后续系统设计提供路径。

Abstract: We initiate the study of DNA-based distributed storage systems, where information is encoded across multiple DNA data storage containers to achieve robustness against container failures. In this setting, data are distributed over $M$ containers, and the objective is to guarantee that the contents of any failed container can be reliably reconstructed from the surviving ones. Unlike classical distributed storage systems, DNA data storage containers are fundamentally constrained by sequencing technology, since each read operation yields the content of a uniformly random sampled strand from the container. Within this framework, we consider several erasure-correcting codes and analyze the expected recovery time of the data stored in a failed container. Our results are obtained by analyzing generalized versions of the classical Coupon Collector's Problem, which may be of independent interest.

</details>


### [29] [Data Compression with Stochastic Codes](https://arxiv.org/abs/2602.07635)
*Gergely Flamich,Deniz Gündüz*

Main category: cs.IT

TL;DR: 本文概述了相对熵编码的概念、方法与实践，指出其在有损数据压缩中的潜在优势和应用前景。


<details>
  <summary>Details</summary>
Motivation: Machine learning对数据压缩产生重要影响，迫切需要一个在有损源编码中替代量化和熵编码的新方法，进一步探索相关熵编码技术的应用和实现空间。

Method: 通过提供相对熵编码的系统概述，重点讨论其构造随机码、计算复杂度与实践实现缺失的细节，旨在让读者更直观地了解该技术。

Result: 文章向不同层次的读者展示了相对熵编码的直观图景、最新应用实例，并阐释其简洁优雅的构造原理。

Conclusion: 相对熵编码是数据压缩研究中新兴而简洁且富有吸引力的领域，为有损压缩提供了实用的替代方案，并为未来研究提供了丰富视角。

Abstract: Machine learning has had a major impact on data compression over the last decade and inspired many new, exciting theoretical and applied questions.
  This paper describes one such direction -- relative entropy coding -- which focuses on constructing stochastic codes, primarily as an alternative to quantisation and entropy coding in lossy source coding. Our primary aim is to provide a broad overview of the topic, with an emphasis on the computational and practical aspects currently missing from the literature.
  Our goal is threefold: for the curious reader, we aim to provide an intuitive picture of the field and convince them that relative entropy coding is a simple yet exciting emerging field in data compression research. For a reader interested in applied research on lossy data compression, we provide an account of the most salient contemporary applications. Finally, for the reader who has heard of relative entropy coding but has never been quite sure what it is or how the algorithms fit together, we hope to illustrate how simple and elegant the underlying constructions are.

</details>


### [30] [Capacity Scaling Laws for Boundary-Induced Drift-Diffusion Noise Channels](https://arxiv.org/abs/2602.07866)
*Yen-Chi Lee*

Main category: cs.IT

TL;DR: NDFHL噪声通道在高SNR下可用等方差正态信号近似，容量只受接收边界维度影响，所有传输参数表现在噪声熵中，容量差随SNR增大趋零。


<details>
  <summary>Details</summary>
Motivation: 研究由多维漂移扩散过程导致的边界诱导噪声通道，探讨其几何驱动下的容量极限及其随传输参数变化的性质。

Method: 通过将吸收超平面上第一着地点的噪声表示为高斯方差混合，构建NDFHL家族；在二阶矩约束下推导精确高SNR容量展开，并计算其导数与熵相关的校正项。

Result: 证明等维度正态符号在所有固定漂移下在高SNR下容量达成；容量的前导因子仅由接收端超平面维度决定；并显示所有物理参数仅通过噪声差分熵影响容量；同时展示NDFHL密度熵连续、有限，连接有限方差与奇异的Cauchy极限。

Conclusion: 在高信噪比条件下，任何固定漂移强度的NDFHL通道的容量近似可由等维度具体公式给出；此时等方差正态信号最优，且容量上界与下界在常数项收敛，容量差随SNR增大趋向零。

Abstract: This paper studies the high-power capacity scaling of additive noise channels whose noise arises from the first-hitting location of a multidimensional drift-diffusion process on an absorbing hyperplane. By identifying the underlying stochastic transport mechanism as a Gaussian variance-mixture, we introduce and analyze the Normally-Drifted First-Hitting Location (NDFHL) family as a geometry-driven model for boundary-induced noise. Under a second-moment constraint, we derive an exact high-SNR capacity expansion and show that the asymptotic upper and lower bounds coincide at the constant level, yielding a vanishing capacity gap. As a consequence, isotropic Gaussian signaling is asymptotically capacity-achieving for all fixed drift strengths, despite the non-Gaussian and semi-heavy-tailed nature of the noise. The pre-log factor is determined solely by the dimension of the receiving boundary, revealing a geometric origin of the channel's degrees of freedom. The refined expansion further uncovers an entropy-dominant universality, whereby all physical parameters of the transport process -- including drift strength, diffusion coefficient, and boundary separation -- affect the capacity only through the differential entropy of the induced noise. Although the NDFHL density does not admit a simple closed form, its entropy is shown to be finite and to vary continuously as the drift vanishes, thereby connecting the finite-variance regime with the singular infinite-variance Cauchy limit. Together, these results provide a unified geometric and information-theoretic characterization of boundary-hitting channels across both regular and singular transport regimes.

</details>


### [31] [Rich-ARQ: From 1-bit Acknowledgment to Rich Neural Coded Feedback](https://arxiv.org/abs/2602.07886)
*Enhao Chen,Yulin Shao*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper reimagines the foundational feedback mechanism in wireless communication, transforming the prevailing 1-bit binary ACK/NACK with a high-dimensional, information-rich vector to transform passive acknowledgment into an active collaboration. We present Rich-ARQ, a paradigm that introduces neural-coded feedback for collaborative physical-layer channel coding between transmitter and receiver. To realize this vision in practice, we develop a novel asynchronous feedback code that eliminates stalling from feedback delays, adapts dynamically to channel fluctuations, and features a lightweight encoder suitable for on-device deployment. We materialize this concept into the first full-stack, standard-compliant software-defined radio prototype, which decouples AI inference from strict radio timing. Comprehensive over-the-air experiments demonstrate that Rich-ARQ achieves significant SNR gains over conventional 1-bit hybrid ARQ and remarkable latency reduction over prior learning-based feedback codes, moving the promise of intelligent feedback from theory to a practical, high-performance reality for next-generation networks.

</details>


### [32] [OFDM Enabled Over-the-Air Computation Systems with Two-Dimensional Fluid Antennas](https://arxiv.org/abs/2602.07953)
*Heyang Xiong,Quanzhong Li,Qi Zhang*

Main category: cs.IT

TL;DR: FAS+OFDM+MM优化实现MSE显著下降


<details>
  <summary>Details</summary>
Motivation: 在频率选择性环境下利用空间自由度提升无线信道性能

Method: 将计算均方误差（MSE）最小化问题转化为发射前置器和天线位置优化，以及接收组合器优化问题，随后采用主化-最小化（MM）加顺序优化方法求解

Result: 数值实验表明该方案相较固定位置天线方案可显著降低MSE

Conclusion: 二维流体天线系统在 OFDM 使能的空时多址计算中能够有效减少误差


Abstract: Fluid antenna system (FAS) is able to exploit spatial degrees of freedom (DoFs) in wireless channels. In this letter, to exploit spatial DoFs in frequency-selective environments, we investigate an orthogonal frequency division multiplexing enabled over-the-air computation system, where the access point is equipped with a two-dimensional FAS to enhance performance. We solve the computation mean square error (MSE) minimization problem by transforming the original problem into transmit precoders optimization problem and antenna positions optimization along with receive combiners optimization problem. The latter is solved via a majorization-minimization approach combined with sequential optimization. Numerical results confirm that the proposed scheme achieves MSE reduction over the scheme with fixed position antennas.

</details>


### [33] [Tighter Information-Theoretic Generalization Bounds via a Novel Class of Change of Measure Inequalities](https://arxiv.org/abs/2602.07999)
*Yanxiao Liu,Yijun Fan an Deniz Gündüz*

Main category: cs.IT

TL;DR: 通过$f$-发散度的处理不等式，构建统一不等式框架，进而获得更紧的泛化误差上界，适用于多种学习与隐私情境。


<details>
  <summary>Details</summary>
Motivation: 在信息论泛化分析中现有的测度不等式已显不足，缺乏统一简洁且更紧的理论工具。

Method: 利用$f$-发散度的典型数学结构，建立一系列变化测度不等式；随后将这些不等式嵌入泛化误差推导，覆盖$ f$-发散度、Renyi发散度以及α互信息等多类信息量。

Result: 得到了一系列新颖且严格的高概率泛化界限，并恢复了若干已知最优结果；框架还可灵活适用于条件互信息、PAC‑贝叶斯与差分隐私三大设定。

Conclusion: 本文通过数据处理不等式构建了一套统一的变化测度不等式，并将其成功应用于随机学习算法的泛化误差分析，得出了更紧凑的高概率信息论泛化界限。

Abstract: In this paper, we propose a novel class of change of measure inequalities via a unified framework based on the data processing inequality for $f$-divergences, which is surprisingly elementary yet powerful enough to yield tighter inequalities. We provide change of measure inequalities in terms of a broad family of information measures, including $f$-divergences (with Kullback-Leibler divergence and $χ^2$-divergence as special cases), Rényi divergence, and $α$-mutual information (with maximal leakage as a special case). We then embed these inequalities into the analysis of generalization error for stochastic learning algorithms, yielding novel and tighter high-probability information-theoretic generalization bounds, while also recovering several best-known results via simplified analyses. A key advantage of our framework is its flexibility: it readily adapts to a range of settings, including the conditional mutual information framework, PAC-Bayesian theory, and differential privacy mechanisms, for which we derive new generalization bounds.

</details>


### [34] [Term Coding and Dispersion: A Perfect-vs-Rate Complexity Dichotomy for Information Flow](https://arxiv.org/abs/2602.08110)
*Søren Riis*

Main category: cs.IT

TL;DR: 提出一个通过最大化符号解释满足性来研究映射像大小的新框架，证明最大像规模与图猜测数相关，并给出算法；若输出维度≥3，则完美分散存在性判定不可行。


<details>
  <summary>Details</summary>
Motivation: 探究信息流与离散结构间的极值分布，尤其在符号解释自由的情况下，最大化满足性与像大小的关联所产生的通信与信息理论意义。

Method: 构造函数符号解释并最大化满足项方程组的赋值数，研究映射Θ的像大小，通过把该问题转化为关联有向图的猜测数，利用多项式时间算法计算D。

Result: 证明最大分散规模为Θ(n^D)，其中D是相关图的猜测数；给出多项式时间算法计算D；展示r≥3时完美分散判定是不可判定的，而对应的渐近率阈值问题可在多项式时间内判定。

Conclusion: 该论文提出了一个新的离散数学前沿问题框架，并针对极值问题提供了可计算的指数上界和不可判定的完美分散判定问题。

Abstract: We introduce a new framework term coding for extremal problems in discrete mathematics and information flow, where one chooses interpretations of function symbols so as to maximise the number of satisfying assignments of a finite system of term equations.
  We then focus on dispersion, the special case in which the system defines a term map $Θ^\mathcal I:\A^k\to\A^r$ and the objective is the size of its image. Writing $n:=|\A|$, we show that the maximum dispersion is $Θ(n^D)$ for an integer exponent $D$ equal to the guessing number of an associated directed graph, and we give a polynomial-time algorithm to compute $D$. In contrast, deciding whether \emph{perfect dispersion} ever occurs (i.e.\ whether $\Disp_n(\mathbf t)=n^r$ for some finite $n\ge 2$) is undecidable once $r\ge 3$, even though the corresponding asymptotic rate-threshold questions are polynomial-time decidable.

</details>


### [35] [Optimal Transmit Beamforming for MIMO ISAC with Unknown Target and User Locations](https://arxiv.org/abs/2602.08255)
*Yizhuo Wang,Shuowen Zhang*

Main category: cs.IT

TL;DR: 仅依据位置概率分布，最佳的ISAC波束设计为静态方案；对应的协方差矩阵秩有限，且目标与用户分布趋向相似可提升性能。


<details>
  <summary>Details</summary>
Motivation: 在MIMO ISAC系统中，目标与用户位置未知且仅知道其概率分布，如何充分利用空间资源并在统计意义下实现感知与通信的满意性能，尤其目标与用户分布相似是否有益，是迫切需要解决的问题。

Method: 基于位置概率分布，构造通信期望速率与后验CRB作为性能指标，提出在期望速率约束下最小化PCRB的波束形成优化问题；通过解析求解得到最优解；随后证明最优协方差矩阵秩上界，并通过对比静态与动态波束设计，证明静态设计已能达到最优性能。

Result: 得到最优的静态波束形成功能，证明最优协方差矩阵秩受所有可能用户位置下通信通道矩阵之和的上界；动态多时隙波束设计不优于静态方案；数值仿真显示，当目标与用户位置分布相似时，ISAC性能提升，并给出基站-用户/目标关联策略的实用见解。

Conclusion: 作者证明在仅有目标与用户位置概率分布信息的情形下，最佳的传输波束形成功能应采用静态策略；最优传输协方差矩阵秩受可用MIMO通道矩阵之和上界；以及当目标与用户位置分布趋近时，ISAC性能得到提升。

Abstract: This paper studies a challenging scenario in a multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system where the locations of the sensing target and the communication user are both unknown and random, while only their probability distribution information is known. In this case, how to fully utilize the spatial resources by designing the transmit beamforming such that both sensing and communication can achieve satisfactory performance statistically is a difficult problem, which motivates the study in this paper. Moreover, we aim to reveal if it is desirable to have similar probability distributions for the target and user locations in terms of the ISAC performance. Firstly, based on only probability distribution information, we establish communication and sensing performance metrics via deriving the expected rate or posterior Cramér-Rao bound (PCRB). Then, we formulate the transmit beamforming optimization problem to minimize the PCRB subject to the expected rate constraint, for which the optimal solution is derived. It is unveiled that the rank of the optimal transmit covariance matrix is upper bounded by the summation of MIMO communication channel matrices for all possible user locations. Furthermore, due to the need to cater to multiple target/user locations, we investigate whether dynamically employing different beamforming designs over different time slots improves the performance. It is proven that using a static beamforming strategy is sufficient for achieving the optimal performance. Numerical results validate our analysis, show that ISAC performance improves as the target/user location distributions become similar, and provide useful insights on the BS-user/-target association strategy.

</details>


### [36] [Hierarchical Subcode Ensemble Decoding of Polar Codes](https://arxiv.org/abs/2602.08391)
*Yubeen Jo,Geon Choi,Chanho Park,Namyoon Lee*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Subcode-ensemble decoders improve iterative decoding by running multiple decoders in parallel over carefully chosen subcodes, increasing the likelihood that at least one decoder avoids the dominant trapping structures. Achieving strong diversity gains, however, requires constructing many subcodes that satisfy a linear covering property-yet existing approaches lack a systematic way to scale the ensemble size while preserving this property. This paper introduces hierarchical subcode ensemble decoding (HSCED), a new ensemble decoding framework that expands the number of constituent decoders while still guaranteeing linear covering. The key idea is to recursively generate subcode parity constraints in a hierarchical structure so that coverage is maintained at every level, enabling large ensembles with controlled complexity. To demonstrate its effectiveness, we apply HSCED to belief propagation (BP) decoding of polar codes, where dense parity-check matrices induce severe stopping-set effects that limit conventional BP. Simulations confirm that HSCED delivers significant block-error-rate improvements over standard BP and conventional subcode-ensemble decoding under the same decoding-latency constraint.

</details>


### [37] [Multipoint Code-Weight Sphere Decoding: Parallel Near-ML Decoding for Short-Blocklength Codes](https://arxiv.org/abs/2602.08501)
*Yubeen Jo,Geon Choi,Yongjune Kim,Namyoon Lee*

Main category: cs.IT

TL;DR: 两阶段近ML解码：低复杂度首选；失败后采用多点码权球解码，聚焦低权扰动，保持低延迟并实现近ML性能。


<details>
  <summary>Details</summary>
Motivation: 短包URLLC场景下有限块长度导致ML解码难以应用，传统解码器要么误码率高，要么计算复杂；因此需要既可靠又低延迟的近ML方案。

Method: 第一阶段使用低复杂度解码器输出候选码字并校验；若失败则第二阶段采用多点码权球解码（MP-WSD），通过预先计算低权码字生成结构化扰动，在欧氏球内逐步搜索，提升解码质量。

Result: 仿真表明，该框架能在短块低码率线路下实现近ML性能，且平均复杂度低，主要在高信噪比下第一阶段成功率高，第二阶段刻意局部搜索。

Conclusion: 提出了两阶段近ML解码框架，能在保持低延迟的同时，达到短块长度线性码的近ML性能。

Abstract: Ultra-reliable low-latency communications (URLLC) operate with short packets, where finite-blocklength effects make near-maximum-likelihood (near-ML) decoding desirable but often too costly. This paper proposes a two-stage near-ML decoding framework that applies to any linear block code. In the first stage, we run a low-complexity decoder to produce a candidate codeword and a cyclic redundancy check. When this stage succeeds, we terminate immediately. When it fails, we invoke a second-stage decoder, termed multipoint code-weight sphere decoding (MP-WSD). The central idea behind {MP-WSD} is to concentrate the ML search where it matters. We pre-compute a set of low-weight codewords and use them to generate structured local perturbations of the current estimate. Starting from the first-stage output, MP-WSD iteratively explores a small Euclidean sphere of candidate codewords formed by adding selected low-weight codewords, tightening the search region as better candidates are found. This design keeps the average complexity low: at high signal-to-noise ratio, the first stage succeeds with high probability and the second stage is rarely activated; when it is activated, the search remains localized. Simulation results show that the proposed decoder attains near-ML performance for short-blocklength, low-rate codes while maintaining low decoding latency.

</details>


### [38] [Reliable one-bit quantization of bandlimited graph data via single-shot noise shaping](https://arxiv.org/abs/2602.08669)
*Johannes Maly,Anna Veselovska*

Main category: cs.IT

TL;DR: 本文提出一种单次噪声塑形量化技术，能将图结构带限数据压缩至单比特，并给出严格误差边界，实验验证优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在自然科学与机器学习中，图数据普遍存在。由于存储与通信成本的限制，需要将图结构数据压缩至极低比特率，同时确保其在低通滤波后的信息完整性。

Method: 采用单次投射（single-shot） noise shaping 技术，对图结构的带限信号进行量化调制，设计了具备严格误差理论支撑的量化器，并在低位数下实现稳定量化。

Result: 实验表明，该方法在多种图数据集上实现了最先进的量化性能，尤其在单比特量化场景下仍保持低误差，并提供了针对任意比特位数的可靠量化方案。

Conclusion: 本研究提出了一种高效的单射噪声塑形量化方法，能够在保持低通滤波下信息完整的前提下，将图结构、带限数据压缩至极低比特位（甚至单比特），并给出严格的误差上界，实验证明其性能优于现有方案。

Abstract: Graph data are ubiquitous in natural sciences and machine learning. In this paper, we consider the problem of quantizing graph structured, bandlimited data to few bits per entry while preserving its information under low-pass filtering. We propose an efficient single-shot noise shaping method that achieves state-of-the-art performance and comes with rigorous error bounds. In contrast to existing methods it allows reliable quantization to arbitrary bit-levels including the extreme case of using a single bit per data coefficient.

</details>


### [39] [Trellis codes with a good distance profile constructed from expander graphs](https://arxiv.org/abs/2602.08718)
*Yubin Zhu,Zitan Chen*

Main category: cs.IT

TL;DR: 该工作给出新的trellis码距离上界，显示其列距离能超过卷积码，并用渐伸图构造了常规模型trellis码，几乎达到卷积码最佳距离谱，但卷积码需要更大字母集。


<details>
  <summary>Details</summary>
Motivation: 提升trellis码相较于卷积码的距离性能，并在常规模型上实现更优的距离结构。

Method: 通过推导Singleton上界以及运用渐伸图构造trellis码。

Result: 证明了列距离上界的提升，构造了常规模型的trellis码实现接近最大距离谱的性能，指出卷积码在此类构造中需指数级字母集。

Conclusion: 作者提出了新的Singleton型上界，并证明在给定时间点，trellis码的最大列距离可超过卷积码；利用渐伸图构造在常规模型上的trellis码，几乎满足最大距离谱的速率-距离权衡。

Abstract: We derive Singleton-type bounds on the free distance and column distances of trellis codes. Our results show that, at a given time instant, the maximum attainable column distance of trellis codes can exceed that of convolutional codes. Moreover, using expander graphs, we construct trellis codes over constant-size alphabets that achieve a rate-distance trade-off arbitrarily close to that of convolutional codes with a maximum distance profile. By comparison, all known constructions of convolutional codes with a maximum distance profile require working over alphabets whose size grows at least exponentially with the number of output symbols per time instant.

</details>


### [40] [Clique-Based Deletion-Correcting Codes via Penalty-Guided Clique Search](https://arxiv.org/abs/2602.08952)
*Aniruddh Pandav,Rajshekhar V Bhat*

Main category: cs.IT

TL;DR: 把删除码构造化为最大团问题，利用 PGCS 产生更大码表，并改进 LCS 解码器速度。


<details>
  <summary>Details</summary>
Motivation: 传统图基启发式（最小度、着色等）生成的删除纠错码限幅较低，需寻找更强的构造方法以提升码长度‑纠错性能。

Method: 将构造问题转化为最大团问题，采用 Penalty‑Guided Clique Search（PGCS）进行随机团搜索；对分段接收使用最优化 LCS 解码器。

Result: PGCS 在 n=8–14，d=1–3 时生成的新码表往往比已知码表更大，部分区间达标最优，优于 Helberg 经典构造；解码器平均复杂度显著降低。

Conclusion: PGCS 在有限长度下可获得最优或更优的 d 删除纠错码；解码器大幅降低平均复杂度。

Abstract: We study the construction of $d$-deletion-correcting binary codes by formulating the problem as a Maximum Clique Problem (MCP). In this formulation, vertices represent candidate codewords and edges connect pairs whose longest common subsequence (LCS) distance guarantees correction of up to $d$ deletions. A valid codebook corresponds to a clique in the resulting graph, and finding the largest codebook is equivalent to identifying a maximum clique. While MCP-based formulations for deletion-correcting codes have previously been explored, we demonstrate that applying Penalty-Guided Clique Search (PGCS), a lightweight stochastic clique-search heuristic inspired by Dynamic Local Search (DLS), consistently yields larger codebooks than existing graph-based heuristics, including minimum-degree and coloring methods, for block lengths $n = 8,9,\dots,14$ and deletion parameters $d = 1,2,3$. In several finite-length regimes, the resulting codebooks match known optimal sizes and outperform classical constructions such as Helberg codes. For decoding under segmented reception, where codeword boundaries are known, we propose an optimized LCS-based decoder that exploits symbol-count filtering and early termination to substantially reduce the number of LCS evaluations while preserving exact decoding guarantees. These optimizations lead to significantly lower average-case decoding complexity than the baseline $O(|C| n^2)$ approach.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [41] [Deep Reinforcement Learning for Interference Suppression in RIS-Aided Space-Air-Ground Integrated Networks](https://arxiv.org/abs/2602.06982)
*Pujitha Mamillapalli,Shikhar Verma,Tiago Koketsu Rodrigues,Abhinav Kumar*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Future 6G networks envision ubiquitous connectivity through space-air-ground integrated networks (SAGINs), where high-altitude platform stations (HAPSs) and satellites complement terrestrial systems to provide wide-area, low-latency coverage. However, the rapid growth of terrestrial devices intensifies spectrum sharing between terrestrial and non-terrestrial segments, resulting in severe cross-tier interference. In particular, frequency sharing between the HAPS satellite uplink and HAPS ground downlink improves spectrum efficiency but suffers from interference caused by the HAPS antenna back-lobe. Existing approaches relying on zero-forcing (ZF) codebooks have limited performance under highly dynamic channel conditions. To overcome this limitation, we employ a reconfigurable intelligent surface (RIS)-aided HAPS-based SAGIN framework with a deep deterministic policy gradient (DDPG) algorithm. The proposed DDPG framework optimizes the HAPS beamforming weights to form spatial nulls toward interference sources while maintaining robust links to the desired signals. Simulation results demonstrate that the DDPG framework consistently outperforms conventional ZF beamforming among different RIS configurations, achieving up to \(11.3\%\) throughput improvement for a \(4\times4\) RIS configuration, validating its adaptive capability to enhance spectral efficiency in dynamic HAPS-based SAGINs.

</details>


### [42] [A Pre-trained EEG-to-MEG Generative Framework for Enhancing BCI Decoding](https://arxiv.org/abs/2602.06990)
*Zhuo Li,Shuqiang Wang*

Main category: eess.SP

TL;DR: 基于EEG的跨模态生成提升了MEG信号的可获取性，并显著提升了BCI系统性能。


<details>
  <summary>Details</summary>
Motivation: MEG因成本高、携带不便，限制了其在BCI中的应用；需一种成本效益高的替代方案以拉近EEG与MEG间的数据鸿沟。

Method: 先使用预训练EEG模型提取通用神经表示；再通过空间焦点映射模块学习MEG的低空间扩散特性；随后使用宽频谱校准模块提升高频灵敏度；最后评估合成MEG在时频与源空间上的一致性及其在BCI解码中的效果。

Result: 合成的MEG与真实MEG在时频特征和源空间激活模式上高度一致；使用合成MEG还在独立的EEG实验中提升了BCI解码性能。

Conclusion: 通过跨模态生成框架，利用EEG提取的神经活动表示，学习MEG的空间聚焦与频谱校准，从而合成逼真的MEG信号，实现低成本MEG数据获取并提升BCI性能。

Abstract: Electroencephalography (EEG) and magnetoencephalography (MEG) play important and complementary roles in non-invasive brain-computer interface (BCI) decoding. However, compared to the low cost and portability of EEG, MEG is more expensive and less portable, which severely limits the practical application of MEG in BCI systems. To overcome this limitation, this study proposes the first cross-modal generation framework based on EEG-MEG spatiotemporal coupled representations to synthesize MEG signals cost-effectively. The framework first extracts general neural activity representations through a pre-trained EEG model. Building upon these representations, the framework effectively learns the lower spatial dispersion and higher high-frequency sensitivity of MEG via the spatial focus mapping module and the broadband spectral calibration module. Experimental results demonstrate that the synthesized MEG signals show high consistency with the real MEG in both time-frequency characteristics and source space activation patterns. More importantly, downstream BCI decoding experiments demonstrate that using synthesized MEG leads to performance enhancements not only on paired EEG-MEG datasets but also on independent EEG-only datasets. Overall, this framework opens a new avenue for overcoming data bottlenecks in BCI.

</details>


### [43] [OTFS-based Integrated Positioning and Communication Systems with Low-Resolution ADCs](https://arxiv.org/abs/2602.07001)
*Yueyi Yang,Zeping Sui,Zilong Liu,Leila Musavian*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper proposes a two-phase orthogonal time frequency space (OTFS)-based integrated positioning and communication (IPAC) framework under realistic low-resolution analog-to-digital converters (ADCs). In the uplink phase, the positioning signal is used to estimate channel parameters, which are subsequently used to determine the user's position. The spatial smoothing-multiple signal classification algorithm is introduced to estimate the angle-of-arrival, whereas an iterative interference cancellation scheme is conceived for the remaining parameters' estimation. The corresponding Cramer-Rao lower bounds of channel parameters and user position are also derived. During the downlink communication phase, the estimated parameters are exploited to improve beamforming at the base station. Simulation results evaluate the impact of ADC quantizer resolutions. Specifically, it is shown that enhanced downlink bit error rate performance can be achieved with improved uplink positioning, while the use of low-resolution ADCs induces noticeable performance degradation in the OTFS-IPAC system.

</details>


### [44] [Behavior Score Prediction in Resting-State Functional MRI by Deep State Space Modeling](https://arxiv.org/abs/2602.07131)
*Javier Salazar Cavazos,Maximillian Egan,Krisanne Litinas,Benjamin Hampstead,Scott Peltier*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Early clinical assessment of Alzheimer's disease relies on behavior scores that measure a subject's language, memory, and cognitive skills. On the medical imaging side, functional magnetic resonance imaging has provided invaluable insights into the neural pathways underlying Alzheimer's disease. While prior studies have used resting-state functional MRI by extracting functional connectivity matrices, these approaches neglect the temporal dynamics inherent in functional data. In this work, we present a deep state space modeling framework that directly leverages the blood-oxygenation-level-dependent time series to learn a sparse collection of brain regions to predict behavior scores. Our model extracts temporal features that encapsulate nuanced patterns of intrinsic brain activity, thereby enhancing predictive performance compared to traditional connectivity methods. We identify specific brain regions that are most predictive of cognitive impairment through experiments on data provided by the Michigan Alzheimer's Disease Research Center, providing new insights into the neural substrates of early Alzheimer's pathology. These findings have important implications for the possible development of risk monitoring and intervention strategies in Alzheimer's disease.

</details>


### [45] [Pulse Shaping Filter Design for Zak-OTFS](https://arxiv.org/abs/2602.07350)
*Kecheng Zhang,Weijie Yuan,Yonghui Li*

Main category: eess.SP

TL;DR: Improved pulse design (PSWF in IOTA) reduces channel spread in Zak‑OTFS, enhancing estimation and BER over standard windows.


<details>
  <summary>Details</summary>
Motivation: High‑mobility communications require robust OTFS; single‑pilot channel estimation is theoretically possible but poor due to pulse‑shaping induced channel spread; need to reduce sidelobes to improve estimation.

Method: Derive the discrete‑time I/O model for oversampled Zak‑OTFS; analyze delay‑Doppler symbols and window ambiguity functions; design PSWF‑based pulse shapes under IOTA; conduct numerical simulations comparing to RRC and rectangular windows.

Result: PSWF‑IOTA pulse shaping yields superior channel estimation and BER in high‑SNR regime compared to classical windows.

Conclusion: The paper demonstrates that designing pulse‑shaping filters based on PSWFs within the IOTA framework significantly improves channel estimation accuracy and BER performance in discrete‑time oversampled Zak‑OTFS systems, especially in high‑SNR, high‑mobility scenarios.

Abstract: The Zak-transform-based Orthogonal Time Frequency Space (Zak-OTFS), offers a robust framework for high-mobility communications by simplifying the input-output (I/O) relation to a twisted convolution. While this structure theoretically enables accurate channel estimation by sampling the response from one pilot symbol, practical implementation is constrained by the spreading of effective channel response induced by pulse shaping filters. To address this, we first derive the I/O relationship for discrete-time oversampled Zak-OTFS, which closely approximates the continuous-time system and facilitates analysis and numerical simulation. We show that every delay-Doppler domain symbol undergoes the same effective channel response under the discrete oversampled Zak-OTFS. We then analyze the impact of window ambiguity functions, and reveal that high sidelobes lead to wide channel spreading and degrade estimation accuracy. Building on this insight, we propose a novel pulse shaping filter design that synthesizes Prolate Spheroidal Wave Functions (PSWFs) within the Isotropic Orthogonal Transform Algorithm (IOTA) framework. Numerical simulations confirm that the proposed design achieves superior channel estimation accuracy and bit error rate (BER) performance compared to conventional root-raised-cosine and rectangular windowing schemes in the high-SNR regime.

</details>


### [46] [Optimal Low-Dimensional Structures of ISAC Beamforming: Theory and Efficient Algorithms](https://arxiv.org/abs/2602.07502)
*Xiaotong Zhao,Mian Li,Ya-Feng Liu,Qingjiang Shi,Anthony Man-Cho So*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Transmit beamforming design is a fundamental problem in integrated sensing and communication (ISAC) systems. Numerous methods have been proposed to jointly optimize key performance metrics such as the signal-to-interference-plus-noise ratio and Cramér-Rao bound. However, the computational complexity of these methods often grows rapidly with the number of transmit antennas at the base station (BS). To tackle this challenge, we prove a fundamental structural property of the ISAC beamforming problem, i.e., there exists an optimal solution exhibiting a low-dimensional structure. This leads to an equivalent reformulation of the problem with dimension related to the number of users rather than the number of BS antennas, thereby enabling the development of low-complexity algorithms. When applying the interior-point method to the reformulated problem, we achieve up to six orders of magnitude in complexity reduction when the number of antennas exceeds the number of users by an order of magnitude. To further reduce the complexity, we develop a balanced augmented Lagrangian method to solve the reformulated problem. The proposed algorithm maintains optimality while achieving a computational complexity that scales quartically with the number of users. Our simulation results demonstrate that the proposed R-BAL method can achieve a speedup of more than 10000$\times$ over the conventional IPM in massive MIMO scenarios.

</details>


### [47] [Beyond $λ/2$: Can Arbitrary EMVS Arrays Achieve Unambiguous NLOS Localization?](https://arxiv.org/abs/2602.07515)
*Hua Chen,Zhenhao Yu,Tuo Wu,Wei Liu,Maged Elkashlan,Hyundong Shin,Matthew C. Valenti,Robert Schober*

Main category: eess.SP

TL;DR: 该研究展示了大间距EMVS阵列结合RIS和PARAFAC求解，可实现无幅度模糊的高精度定位，并显著提升信噪比。


<details>
  <summary>Details</summary>
Motivation: 传统雷达阵列受限于λ/2间距，无法突破孔径和角分辨率；探讨是否通过EMVS与RIS结合，打破该限制实现无模糊定位。

Method: 构建第三阶PARAFAC模型并通过TALS算法分离空间、偏振与传播效应；利用EMVS六个电磁分量的旋转不变性进行相位去缠绕；采用半正定松弛（SDP）优化RIS相位，以最大化接收功率并迭代细化定位。

Result: 实现了对非视距双向MIMO雷达下的二维DOD、DOA及偏振参数的无模糊联合估计，并通过RIS相位优化显著提升了信噪比与定位鲁棒性。

Conclusion: 利用多分量EMVS测量、PARAFAC模型和光学相位重排，可在任意间距大于λ/2的阵列中获得无幅度模糊的RMS辅助定位，且通过RIS相位优化进一步提升信噪比并抑制空间多重性。

Abstract: Conventional radar array design mandates interelement spacing not exceeding half a wavelength ($λ/2$) to avoid spatial ambiguity, fundamentally limiting array aperture and angular resolution. This paper addresses the fundamental question: Can arbitrary electromagnetic vector sensor (EMVS) arrays achieve unambiguous reconfigurable intelligent surface (RIS)-aided localization when element spacing exceeds $λ/2$? We provide an affirmative answer by exploiting the multi-component structure of EMVS measurements and developing a synergistic estimation and optimization framework for non-line-of-sight (NLOS) bistatic multiple input multiple output (MIMO) radar. A third-order parallel factor (PARAFAC) model is constructed from EMVS observations, enabling natural separation of spatial, polarimetric, and propagation effects via the trilinear alternating least squares (TALS) algorithm. A novel phase-disambiguation procedure leverages rotational invariance across the six electromagnetic components of EMVSs to resolve $2π$ phase wrapping in arbitrary array geometries, allowing unambiguous joint estimation of two-dimensional (2-D) direction of departure (DOD), two-dimensional direction of arrival (DOA), and polarization parameters with automatic pairing. To support localization in NLOS environments and enhance estimation robustness, a reconfigurable intelligent surface (RIS) is incorporated and its phase shifts are optimized via semidefinite programming (SDP) relaxation to maximize received signal power, improving signal-to-noise ratio (SNR) and further suppressing spatial ambiguities through iterative refinement.

</details>


### [48] [Fractional Filtering and Anomaly-Guided Diagnostics: The Local Damage Mode Extractor (LDME) for Early Gear Fault Detection](https://arxiv.org/abs/2602.07527)
*Yaakoub Berrouche*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Early and reliable detection of gear faults in complex drivetrain systems is critical for aviation safety and operational availability. We present the Local Damage Mode Extractor (LDME), a structured, physics-informed signal processing framework that combines dual-path denoising, multiscale decomposition, fractional-domain enhancement, and statistically principled anomaly scoring to produce interpretable condition indicators without supervision. LDME is organized in three layers: (i) dual-path denoising (DWT with adaptive Savitzky-Golay smoothing) to suppress broadband noise while preserving transient fault structure; (ii) multi-scale damage enhancement using a Teager-Kaiser pre-amplifier followed by a Hadamard-Caputo fractional operator that accentuates non-sinusoidal, low-frequency fault signatures; and (iii) decision fusion, where harmonics-aware Fourier indicators are combined and scored by an unsupervised anomaly detector. Evaluation using the Case Western Reserve University (CWRU) bearing dataset, the HUMS 2023 planetary gearbox benchmark, and a controlled simulated dataset shows that LDME consistently distinguishes nominal, early-crack, and propagated-crack stages under various operating conditions. LDME identifies the primary detection event earlier (198 cycles) than HT-TSA (284 cycles) and advances maintenance recommendation time from 383 to 365 cycles. We discuss its relation to prior art, limitations, and future theoretical directions. All code and experimental configurations are documented for reproducibility.

</details>


### [49] [A Scalable Cloud-Edge Collaborative CKM Construction Framework Enabled by a Foundation Prior Model](https://arxiv.org/abs/2602.07586)
*Sixu Xiao,Yong Zeng,Haotian Rong,Yanqun Tang*

Main category: eess.SP

TL;DR: 云端训练可泛化CKM先验，边缘节点可本地融合，达成低成本、可扩展的CKM构建方案。


<details>
  <summary>Details</summary>
Motivation: CKM观测噪声与稀疏化问题导致传统端到端算法昂贵且不可扩展，亟需云-边协作与AI-RAN的可扩展框架；

Method: 在云端使用无标签数据训练通用CKM先验的基础模型；边缘节点在推理时将共享先验与本地观测进行融合；

Result: 在CKMImageNet数据集上实验验证，提出方法在构建精度上与现有方法竞争，训练成本更低，能缓解负迁移、提升泛化与部署规模；

Conclusion: 云-边协作框架通过共享可泛化CKM先验显著提升构建效率与泛化性，显著降低训练成本与数据需求；

Abstract: Channel knowledge maps (CKMs) provide a site-specific, location-indexed knowledge base that supports environment-aware communications and sensing in 6G networks. In practical deployments, CKM observations are often noisy and irregular due to coverage-induced sparsity and hardware-induced linear/nonlinear degradations. Conventional end-to-end algorithms couple CKM prior information with task- and device-specific observations, and require labeled data and separate training for each construction configuration, which is expensive and therefore incompatible with scalable edge deployments. Motivated by the trends toward cloud-edge collaboration and the Artificial Intelligence - Radio Access Network (AI-RAN) paradigm, we develop a cloud-edge collaborative framework for scalable CKM construction, which enables knowledge sharing across tasks, devices, and regions by explicitly decoupling a generalizable CKM prior from the information provided by local observations. A foundation model is trained once in the cloud using unlabeled data to learn a generalizable CKM prior. During inference, edge nodes combine the shared prior with local observations. Experiments on the CKMImageNet dataset show that the proposed method achieves competitive construction accuracy while substantially reducing training cost and data requirements, mitigating negative transfer, and offering clear advantages in generalization and deployment scalability.

</details>


### [50] [MI-ISAC: Magneto-Inductive Integrated Sensing and Communication in the Reactive Near-Field for RF-Denied Environments](https://arxiv.org/abs/2602.07714)
*Haofan Dong,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 本文提出利用磁耦合的MI-ISAC解决射频屏蔽环境中的感知与通信问题，提供实现细节、理论证明及性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统射频在地下、海水和人体内被高强度衰减，导致传感与通讯受限，需寻找替代的低介电损耗方法。

Method: 采用三轴线圈实现可辨识的距离角度估计，利用耦合强度梯度替代时差测量，构建MI-MIMO通道模型，并通过理论与实验验证。

Result: 推导三轴线圈的必要性与充分性；耦合强度带来毫米级距离/角度精度；耦合梯度实现六阶微分分辨率；与时分隔线比较提升4–10+ dB；MI-MIMO通道几何不变且条件良好。

Conclusion: MI-ISAC通过外磁耦合实现传感与通讯，在电磁屏蔽环境下提供高效性能，极大提升近场可见度与定位精度。

Abstract: Radio-frequency integrated sensing and communication (RF-ISAC) is ineffective inunderground, underwater, and in-body environments where conductive media attenuate electromagnetic waves by tens of dB per meter. This article presents magneto-inductive ISAC (MI-ISAC), a paradigm that exploits the reactive near-field quasi-static coupling inherent to MI links, enabling a fundamentally different approach to ISAC in these RF-denied environments. Five foundational results are established: (i)~tri-axial coils are necessary and sufficient for identifiable joint range-and-angle estimation; (ii)~coupling strength changes sharply with range, enabling theoretical sub-millimeter accuracy at typical MI distances despite kHz-level bandwidth; (iii)~time-of-flight is ineffective under such narrow bandwidth, but the coupling gradient provides approximately six orders of magnitude finer resolution; (iv)~MI-ISAC can provide 4--10+\,dB sensing gain over time-division baselines; and (v)~the MI-MIMO channel is geometry-invariant and well-conditioned across all orientations. Applications and a research roadmap are discussed.

</details>


### [51] [Code-Weight Sphere Decoding](https://arxiv.org/abs/2508.19631)
*Yubeen Jo,Geon Choi,Yongjune Kim,Namyoon Lee*

Main category: eess.SP

TL;DR: 提出一种低权码球解码结合初始解码的两阶段近ML解码器，能够在URLLC环境中以可接受的复杂度实现高可靠性。


<details>
  <summary>Details</summary>
Motivation: URLLC对低延迟高可靠性要求，需要在有限长度下提供高性能误码校正。

Method: 首先使用低复杂度初始解码，若CRC失效，则使用预先计算的低权码word构造近邻球，在该球内迭代改进估计。

Result: 模拟显示在低速率编码下，该两阶段解码在可靠性和复杂度上取得优异折衷，趋近于ML性能。

Conclusion: 该两阶段解码框架在有限长度码场景下实现了接近ML的可靠性，并通过低权码球解码有效降低复杂度，在高SNR下表现尤佳。

Abstract: Ultra-reliable low-latency communications (URLLC) demand high-performance error-correcting codes and decoders in the finite blocklength regime. This letter introduces a novel two-stage near-maximum likelihood (near-ML) decoding framework applicable to any linear block code. Our approach first employs a low-complexity initial decoder. If this initial stage fails a cyclic redundancy check, it triggers a second stage: the proposed code-weight sphere decoding (WSD). WSD iteratively refines the codeword estimate by exploring a localized sphere of candidates constructed from pre-computed low-weight codewords. This strategy adaptively minimizes computational overhead at high signal-to-noise ratios while achieving near-ML performance, especially for low-rate codes. Extensive simulations demonstrate that our two-stage decoder provides an excellent trade-off between decoding reliability and complexity, establishing it as a promising solution for next-generation URLLC systems.

</details>


### [52] [Adjustment of Cluster-Then-Predict Framework for Multiport Scatterer Load Prediction](https://arxiv.org/abs/2602.08129)
*Hanjun Park,Aleksandr D. Kuznetsov,Ville Viikari*

Main category: eess.SP

TL;DR: 使用聚类-再预测框架和RUI指标，预测多端口散射器的负载阻抗误差降低46%，最佳方案为K-means与KNN组合。


<details>
  <summary>Details</summary>
Motivation: 预测多端口散射器中相互依赖的负载值因维度高和阻抗与散射能力之间复杂依赖而具有挑战性，但对通信和测量系统设计至关重要。

Method: 提出两阶段的聚类-再预测框架：先对S参数进行聚类，再使用回归模型预测对应负载阻抗；同时引入“真实世界统一指数（RUI）”来量化多指标的权衡。

Result: 在梯度提升回归（GB）上应用时，误差（RMSE）显著下降最多达46%；无论采用何种聚类与回归方法，这一提升都稳健出现；基于RUI评估，K-means+KNN 被确定为最优配置。

Conclusion: 聚类-再预测方法有效捕捉S参数与负载阻抗的函数关系，显著提升预测精度，并为多目标评估提供新的统一指标。

Abstract: Predicting interdependent load values in multiport scatterers is challenging due to high dimensionality and complex dependence between impedance and scattering ability, yet this prediction remains crucial for the design of communication and measurement systems. In this paper, we propose a two-stage cluster-then-predict framework for multiple load values prediction task in multiport scatterers. The proposed cluster-then-predict approach effectively captures the underlying functional relation between S-parameters and corresponding load impedances, achieving up to a 46% reduction in Root Mean Square Error (RMSE) compared to the baseline when applied to gradient boosting (GB). This improvement is consistent across various clustering and regression methods. Furthermore, we introduce the Real-world Unified Index (RUI), a metric for quantitative analysis of trade-offs among multiple metrics with conflicting objectives and different scales, suitable for performance assessment in realistic scenarios. Based on RUI, the combination of K-means clustering and k-nearest neighbors (KNN) is identified as the optimal setup for the analyzed multiport scatterer.

</details>


### [53] [AFDM: Evolving OFDM Towards 6G+](https://arxiv.org/abs/2602.08163)
*Hyeon Seok Rou,Vincent Savaux,Zeping Sui,Giuseppe Thadeu Freitas de Abreu,Zilong Liu*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As the standardization of sixth generation (6G) wireless systems accelerates, there is a growing consensus in favor of evolutionary waveforms that offer new features while maximizing compatibility with orthogonal frequency division multiplexing (OFDM), which underpins the 4G and 5G systems. This article presents affine frequency division multiplexing (AFDM) as a premier candidate for 6G, offering intrinsic robustness for both high-mobility communications and integrated sensing and communication (ISAC) in doubly dispersive channels, while maintaining a high degree of synergy with the legacy OFDM. To this end, we provide a comprehensive analysis of AFDM, starting with a generalized fractional-delay-fractional-Doppler (FDFD) channel model that accounts for practical pulse shaping filters and inter-sample coupling. We then detail the AFDM transceiver architecture, demonstrating that it reuses nearly the entire OFDM pipeline and requires only lightweight digital pre- and post-processing. We also analyze the impact of hardware impairments, such as phase noise and carrier frequency offset, and explore advanced functionalities enabled by the chirp-parameter domain, including index modulation and physical-layer security. By evaluating the reusability across the radio-frequency, physical, and higher layers, the article demonstrates that AFDM provides a low-risk, feature-rich, and efficient path toward achieving high-fidelity communications in the later versions of 6G and beyond (6G+).

</details>


### [54] [LocDreamer: World Model-Based Learning for Joint Indoor Tracking and Anchor Scheduling](https://arxiv.org/abs/2602.08204)
*Geng Wang,Zhouyou Gu,Shenghong Li,Peng Cheng,Jihong Park,Branka Vucetic,Yonghui Li*

Main category: eess.SP

TL;DR: LocDreamer 通过世界模型生成合成测量并用RL调度锚点，实现高精度低能耗定位跟踪，实验显示数据效率与精准度大幅提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的方法需大量标注数据且忽视频谱与能效，需一种既高效又节能的定位跟踪解决方案。

Method: 利用世界模型学习目标运动和环境的潜在表示，生成合成测量进行想象驱动的训练；同时使用RL主动激活最有信息的锚点。

Result: 在真实室内数据集上，LocDreamer相较传统贝叶斯滤波随机调度提升了37%的跟踪精度，且仅用合成数据即可达到86%的真实数据训练精度。

Conclusion: LocDreamer通过世界模型与强化学习实现了高精度、低能耗的定位跟踪与锚点调度，显著提升数据效率与泛化能力。

Abstract: Accurate, resource-efficient localization and tracking enables numerous location-aware services in next-generation wireless networks. However, existing machine learning-based methods often require large labeled datasets while overlooking spectrum and energy efficiencies. To fill this gap, we propose LocDreamer, a world model (WM)-based framework for joint target tracking and scheduling of localization anchors. LocDreamer learns a WM that captures the latent representation of the target motion and localization environment, thereby generating synthetic measurements to imagine arbitrary anchor deployments. These measurements enable imagination-driven training of both the tracking model and the reinforcement learning (RL)-based anchor scheduler that activates only the most informative anchors, which significantly reduce energy and signaling costs while preserving high tracking accuracy. Experiments on a real-world indoor dataset demonstrate that LocDreamer substantially improves data efficiency and generalization, outperforming conventional Bayesian filter with random scheduling by 37% in tracking accuracy, and achieving 86% of the accuracy of same model trained directly on real data.

</details>


### [55] [Riemannian Manifold Optimization for Advanced Wireless Communications: Fundamentals and Applications](https://arxiv.org/abs/2602.08225)
*Siwen Li,Jiacheng Chen,Yunting Xu,Shaofeng Li,Le Yao,Jieling Wang,Dusit Niyato*

Main category: eess.SP

TL;DR: 本文阐述RMO在下一代无线通信中的应用，展示其在安全波束成形等非凸问题上优于传统方法的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 随着5G/6G技术的发展，如大规模MIMO、RIS、ISAC、FAS等新型系统出现，部署它们面临大规模非凸优化问题；传统欧氏空间方法需逼近或松弛约束，导致性能下降和计算量大。

Method: 1）系统阐述RMO基本概念与工具；2）给出将无线通信中的约束非凸问题重构为自然流形的策略；3）设计针对每类流形的定制化RMO算法；4）在案例研究中，将FAS‑NOMA安全波束成形问题映射到流形空间并使用RMO求解。

Result: 在FAS‑NOMA安全波束成形案例中，RMO在保持约束完整性的同时，比传统算法取得更优的通信性能，同时显著降低计算开销，验证了RMO的实际效益。

Conclusion: 本文阐明了黎曼流形优化（RMO）在大规模非凸约束问题中的优势，证明其能够直接在约束流形上操作，从而实现约束满足与高效求解；在本文提出的FAS辅助NOMA系统中安全波束成形任务上，RMO相较传统方法在性能和计算效率上均显著优越。

Abstract: Next-generation wireless communications promise transformative technologies such as massive multiple-input multiple-output (MIMO), reconfigurable intelligent surfaces (RIS), integrated sensing and communication (ISAC), and fluid antenna systems (FAS). However, deploying these technologies is hindered by large-scale optimization problems with nonconvex constraints. Conventional Euclidean-space methods rely on approximations or relaxations, which degrade performance and incur substantial computational costs. Riemannian manifold optimization (RMO) offers a powerful alternative that directly operates on the manifold defined by the geometric constraints. This approach inherently satisfies the constraints at every optimization step, thereby avoiding the performance degradation and substantial computational costs. In this paper, we first elaborate on the principles of RMO, including the fundamental concepts, tools, and methods, emphasizing its effectiveness for nonconvex problems. We then introduce its applications in advanced wireless communications, showing how constrained problems are reformulated on their natural manifolds and solved using tailored RMO algorithms. Furthermore, we present a case study on secure beamforming in an FAS-assisted non-orthogonal multiple access (NOMA) system, demonstrating RMO's superiority over conventional methods in terms of both performance and computational efficiency.

</details>


### [56] [Towards Optimal Semantic Communications: Reconsidering the Role of Semantic Feature Channels](https://arxiv.org/abs/2602.08260)
*Yongjeong Oh,Jihong Park,Jinho Choi,Yo-Seb Jeon*

Main category: eess.SP

TL;DR: 探讨并实现SF通道的优化与实现，从而在变动信道中显著提升语义通信效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设SF通道固定，忽视了其可配置性；通过优化可提升在不确定信道条件下的语义通信性能。

Method: 首先将完整通信流程建模为SF通道，随后在互信息约束下针对线性编解码器和高斯源分析推导最优SF通道；进一步提出联合优化框架并实现实时功率控制的物理层校准策略。

Result: 实验验证显示，在各类信道环境下，本方法的任务性能显著优于无优化或传统方案。

Conclusion: 提出了通过优化语义特征传输路径，在多变信道条件下提升语义通信任务性能的方案；实验表明在多种通信环境下，SF通道优化显著优于传统方法。

Abstract: This paper investigates the optimization of transmitting the encoder outputs, termed semantic features (SFs), in semantic communication (SC). We begin by modeling the entire communication process from the encoder output to the decoder input, encompassing the physical channel and all transceiver operations, as the SF channel, thereby establishing an encoder-SF channel-decoder pipeline. In contrast to prior studies that assume a fixed SF channel, we note that the SF channel is configurable, as its characteristics are shaped by various transmission and reception strategies, such as power allocation. Based on this observation, we formulate the SF channel optimization problem under a mutual information constraint between the SFs and their reconstructions, and analytically derive the optimal SF channel under a linear encoder-decoder structure and Gaussian source assumption. Building upon this theoretical foundation, we propose a joint optimization framework for the encoder-decoder and SF channel, applicable to both analog and digital SCs. To realize the optimized SF channel, we also propose a physical-layer calibration strategy that enables real-time power control and adaptation to varying channel conditions. Simulation results demonstrate that the proposed SF channel optimization achieves superior task performance under various communication environments.

</details>


### [57] [Beam Alignment in Multipath Environments for Integrated Sensing and Communication using Bandit Learning](https://arxiv.org/abs/2602.08380)
*Akanksha Sneh,Shobha Sundar Ram,Sumit J Darak,Aakanksha Tewari*

Main category: eess.SP

TL;DR: ISAC + UCB → 35%探索时间下降, 1.4×吞吐率提升。


<details>
  <summary>Details</summary>
Motivation: 在毫米波通信中，传统的多臂赌博机算法在波束数量很大的情况下会导致探索时间过长，进而影响总体吞吐率。

Method: 在UCB基础上加入ISAC，将雷达光视场与通信光视场共享，利用雷达检测的移动目标信息过滤候选波束，并估计准静态场景下的重新对准时间，从而大幅减少探索步数。实现采用SoC硬件-软件协同设计与定点分析，并使用加速器提升执行速度。

Result: 实验表明ISAC‑增强UCB相比仅通信基准的多臂赌博机，整体探索时间减少35%，吞吐率提高1.4倍。

Conclusion: 通过融合雷达与通信信息，能够显著降低毫米波波束搜索耗时，提升系统吞吐率，证明ISAC在频谱共享场景中的有效性。

Abstract: Prior works have explored multi-armed bandit (MAB) algorithms for the selection of optimal beams for millimeter-wave (mmW) communications between base station and mobile users. However, when the number of beams is large, the existing MAB algorithms are characterized by long exploration times, resulting in poor overall communication throughput. In this work, we propose augmenting the upper confidence bound (UCB) based MAB with integrated sensing and communication (ISAC) to address this limitation. The premise of the work is that the radar and communication functionalities share the same field-of-view and that communication mobile users are detected by the radar as mobile targets. The radar information is used for significantly reducing the number of candidate beams for the UCB, resulting in an overall reduction in the exploration time. Further, the radar information is used to estimate the realignment time in quasi-stationary scenarios. We have realized the MAB and radar signal processing algorithms on the system on chip (SoC) via hardware-software co-design (HSCD) and fixed-point analysis. We demonstrate the significant gain in execution time using accelerators. The simulations consider complex propagation channels involving direct and multipath, with simple and extended radar targets in the presence of significant static clutter. The resulting experiments show that the proposed ISAC-based MAB achieves a 35% reduction in the overall exploration time and 1.4 factor higher throughput as compared to the conventional MAB that is based only on communications.

</details>


### [58] [IEEE 802.11ad-Aided 5-D Sensing with a UAV Swarm in Urban Environment](https://arxiv.org/abs/2602.08396)
*Akanksha Sneh,Shobha Sundar Ram,Kumar Vijay Mishra*

Main category: eess.SP

TL;DR: 提议将毫米波802.11ad协议与无人机群结合，实现5D地面目标感知，模拟验证其性能，适用于城市、灾区等场景。


<details>
  <summary>Details</summary>
Motivation: 在城市、灾区和偏远地区等复杂环境中部署空中基站需要依靠无人机（UAV）实现覆盖。单颗无人机受限于续航和运营成本，但群体协同可以克服这一局限。关键挑战在于如何让每架无人机实时跟踪地面移动用户并保持同一时刻的同步。然而，在每架无人机上加装额外的感知硬件会大幅增加体积、成本与功耗。

Method: 基于毫米波IEEE 802.11ad协议，提出一种集成感知与通信的无人机群系统。系统利用该协议的宽带时域/频域特性，实现对地面目标的五维（距离、多普勒速度、方位角、仰角、极化）感知。通过模拟真实城市环境的数值实验，评估其性能。

Result: 仿真结果表明，所提方法在城市环境中能够实现精确的五维目标感知，链路同步和数据传输可以在同一时隙完成，降低硬件负担并保持高效覆盖。

Conclusion: 该集成方案为无人机群在复杂环境中的无线通信与目标跟踪提供了可行且低成本的实现路径。

Abstract: Aerial base stations mounted on unmanned aerial vehicles (UAVs) support next-generation wireless networks in challenging environments such as urban areas, disaster zones, and remote locations. Further, UAV swarms overcome the challenges of limited battery life and other operational constraints of a single UAV. However, tracking mobile users on the ground by each UAV and the corresponding synchronization between the UAVs is a significant issue that must be addressed before this framework can be deployed in reality. Incorporating additional sensing capabilities to facilitate this additional requirement would introduce significant overhead in terms of hardware, cost, and power to each UAV. Instead, we propose an integrated sensing and communications-enabled swarm UAV system, based on the millimeter-wave IEEE 802.11ad protocol. Further, we show that our proposed system is capable of five-dimensional (5-D) ground target sensing (range, Doppler velocity, azimuth, elevation, and polarization) in an urban environment. Numerical experiments using realistic models demonstrate and validate the performance of 5-D sensing using our proposed 802-11ad-aided UAV system.

</details>


### [59] [Movable Antenna Enabled Reconfigurable Array Topologies for Structured Beam Communications](https://arxiv.org/abs/2602.08409)
*Hongyun Jin,Wenchi Cheng,Jingqing Wang*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Spatially structured beams have emerged as a promising technology for enhancing spectrum efficiency (SE) in sixth-generation (6G) networks. However, structured beam schemes based on fixed-position antennas (FPAs) fail to fully exploit the array aperture, thereby limiting their topological reconfigurability and adaptability to diverse communication scenarios. To overcome these limitations, this paper proposes a novel structured beam communication framework exploiting movable antennas (MAs) to achieve reconfigurable array topologies. Specifically, we develop an MA-based geometric modeling framework to construct a variety of practical array topologies, thereby enabling the realization of diverse array configurations utilizing a unified hardware platform. Furthermore, we investigate the joint design of the array topology and the structured beamforming vector to efficiently exploit the array aperture and facilitate the multiplexing of orthogonal spatial modes. Accordingly, we formulate the corresponding beam generation and demodulation schemes and derive the channel gains under varying array topologies. We also propose an alternating optimization algorithm to jointly optimize the array topology configuration, the antenna element positions, and the structured beamforming vector, with the aim of maximizing the system SE. Numerical results demonstrate that the proposed joint design significantly enhances the SE compared to conventional FPA schemes. By synergizing the spatial multiplexing degrees of freedom (DoFs) of structured beams with the mobility DoFs of MAs within 2D planar regions, this work establishes a reconfigurable and practical framework for structured beam-based wireless communications.

</details>


### [60] [Reconfigurable Low-Complexity Architecture for High Resolution Doppler Velocity Estimation in Integrated Sensing and Communication System](https://arxiv.org/abs/2602.08415)
*Aakanksha Tewari,Samarth Sharma Bhardwaj,Sumit J Darak,Shobha Sundar Ram*

Main category: eess.SP

TL;DR: 创建可重构SoC架构，改进ESPRIT实现速度提升6.7倍、资源消耗减至21%/37%，在高SNR下延迟减至一半，确保ISAC系统在毫米波环境中高效多普勒估计。


<details>
  <summary>Details</summary>
Motivation: 在毫米波集成感知与通信（ISAC）系统中，为实现细粒度多普勒分辨率以区分移动目标(MU)混叠，需要长时间的相干处理间隔，但这会削减通信时间与吞吐量。

Method: 提出基于硬件-软件协同设计的可重构SoC架构，允许算法层级切换：低复杂度、高速度FFT粗估与高复杂度ESPRIT细估。对ESPRIT做出改进，实现6.7倍加速，同时内存与乘法器使用分别减少79%和63%。在高SNR下，还可切换至更少慢时包，进一步将延迟缩短一倍。

Result: 改进后的ESPRIT算法保持估计精度，速度提升6.7倍；系统资源占用显著下降；在高SNR条件下，系统可把慢时包数量减半，延迟提升2倍。

Conclusion: 该可重构ISAC架构实现了高效、多比例多普勒估计，兼顾性能与资源约束，为毫米波智能交通应用提供实用解决方案。

Abstract: In millimeter wave integrated sensing and communication (ISAC) systems for intelligent transportation, radar and communication share spectrum and hardware in a time division manner. Radar rapidly detects and localizes mobile users (MUs), after which communication proceeds through narrow beams identified by radar. Achieving fine Doppler resolution for MU clutter discrimination requires long coherent processing intervals, reducing communication time and throughput. To address this, we propose a reconfigurable architecture for Doppler estimation realized on a system on chip using hardware software codesign. The architecture supports algorithm level reconfiguration, dynamically switching between low-complexity, high-speed FFT-based coarse estimation and high complexity ESPRIT based fine estimation. We introduce modifications to ESPRIT that achieve 6.7 times faster execution while reducing memory and multiplier usage by 79% and 63%, respectively, compared to state of the art approaches, without compromising accuracy. Additionally, the reconfigurable architecture can switch to lower slow time packets under high SNR conditions, improving latency further by 2 times with no loss in performance.

</details>


### [61] [Symbol Rate Maximization in Rolling-Shutter OCC: Design and Implementation Considerations](https://arxiv.org/abs/2602.08474)
*Xinyu Zhang,Alexis A. Dowhuszko,Miguel Rêgo,Pedro Fonseca,Luís Nero Alves,Jyri Hämäläinen,Risto Wichman*

Main category: eess.SP

TL;DR: 将滚动快门摄像机建模为矩形匹配滤波器，实验验证三口衰减信道，线性均衡可补偿同步误差，OCC可达像素扫描速率下的Nyquist数据速率。


<details>
  <summary>Details</summary>
Motivation: 研究滚动快门摄像机捕获可见光通信LED发射器的高速光强变化时，能实现的最大数据速率；阐明时间同步误差对干扰的影响。

Method: 将滚动快门摄像机视为矩形匹配滤波器，利用曝光时间模型，并在像素行扫描速率下进行采样；实验测定最大符号速率，建立三端口衰减量的等效信道模型，采用线性均衡补偿 ISI。

Result: 实验与仿真结果高度一致，验证了三口信道模型；线性均衡有效补偿 ISI，使系统可在摄像机像素行扫速率（即Nyquist速率）下工作。

Conclusion: 本文提出了基于滚动快门摄像机的等效数字通信模型，并通过实验验证了三捲道信道模型和线性均衡法能在Nyquist采样率下实现OCC系统的最佳数据速率。

Abstract: Optical Camera Communication (OCC) systems can take advantage of the row-by-row scanning process of rolling-shutter cameras to capture the fast variations of light intensity coming from Visible Light Communication (VLC) LED-based transmitters. In order to study the maximum data rate that is feasible in such kind of OCC systems, this paper presents its equivalent digital communication system model in which the rolling-shutter camera is modeled as a rectangular matched-filter whose time width is equal to the exposure time of the camera, followed by a sampling process at the pixel row sweep rate of the camera. Based on the proposed rolling-shutter camera model, the maximum symbol rate that such OCC systems can support is experimentally demonstrated, and the impact of imperfect time synchronization between the VLC transmitter and the rolling-shutter OCC receiver is characterized in the form of Inter-Symbol Interference (ISI). The equivalent three-tap channel model that results from this process is experimentally validated and the generated ISI is compensated with the use of linear equalization in reception. Simulation and experimental results show a strong correlation between them, demonstrating that the proposed approach can be used to make the OCC system work at the Nyquist sampling rate, which is equivalent to the pixel row sweep rate of the rolling-shutter camera used in reception.

</details>


### [62] [RFSoC-Based Integrated Navigation and Sensing Using NavIC](https://arxiv.org/abs/2602.08596)
*Riya Sachdeva,Aakanksha Tewari,Sumit J. Darak,Shobha Sundar Ram,Sanat K. Biswas*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Prior art has proposed a secondary application for Global Navigation Satellite System (GNSS) infrastructure for remote sensing of ground-based and maritime targets. Here, a passive radar receiver is deployed to detect uncooperative targets on Earth's surface by capturing ground-reflected satellite signals. This work demonstrates a hardware prototype of an L-band Navigation with Indian Constellation (NavIC) satellite-based remote sensing receiver system mounted on an AMD Zynq radio frequency system-on-chip (RFSoC) platform. Two synchronized receiver channels are introduced for capturing the direct signal (DS) from the satellite and ground-reflected signal (GRS) returns from targets. These signals are processed on the ARM processor and field programmable gate array (FPGA) of the RFSoC to generate delay-Doppler maps of the ground-based targets. The performance is first validated in a loop-back configuration of the RFSoC. Next, the DS and GRS signals are emulated by the output from two ports of the Keysight Arbitrary Waveform Generator (AWG) and interfaced with the RFSoC where the signals are subsequently processed to obtain the delay-Doppler maps. The performance is validated for different signal-to-noise ratios (SNR).

</details>


### [63] [Ziv-Zakai Bound for Near-Field Localization and Sensing](https://arxiv.org/abs/2602.08609)
*Nicolò Decarli,Davide Dardari*

Main category: eess.SP

TL;DR: ZZB是近场定位/感知的更准确性能界限，能指导天线阵列设计并发现低信噪比下的精度瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现代无线系统频率升高、天线阵列尺寸增大，导致近场效应显著，传统的 CRB 在低 SNR 区域表现欠佳，亟需更严谨的性能极限分析。

Method: 通过在信号模型中引入球面波前与阵列几何，利用 ZZB 对距离与角度估计误差进行解析评估，并探讨阵列几何、波长及目标位置对精度的影响。

Result: 研究揭示 ZZB 在不同参数下的过渡行为，明确了近场感知的基本限制与提升方向。

Conclusion: 该研究表明在大规模天线阵列下，ZZB 能够比 CRB 更精确地捕捉近场定位与感知的估计误差，尤其在低信噪比或阈值区域。

Abstract: The increasing carrier frequencies and growing physical dimensions of antenna arrays in modern wireless systems are driving renewed interest in localization and sensing under near-field conditions. In this paper, we analyze the Ziv-Zakai Bound (ZZB) for near-field localization and sensing operated with large antenna arrays, which offers a tighter characterization of estimation accuracy compared to traditional bounds such as the Cramér-Rao Bound (CRB), especially in low signal-to-noise ratio or threshold regions. Leveraging spherical wavefront and array geometry in the signal model, we evaluate the ZZB for distance and angle estimation, investigating the dependence of the accuracy on key signal and system parameters such as array geometry, wavelength, and target position. Our analysis highlights the transition behavior of the ZZB and underscores the fundamental limitations and opportunities for accurate near-field sensing.

</details>


### [64] [Joint Channel Sounding and Source-Channel Coding for MIMO-OFDM Systems: Deep Unified Encoding and Parallel Flow-Matching Decoding](https://arxiv.org/abs/2602.08795)
*Hao Jiang,Xiaojun Yuan,Qinghua Guo*

Main category: eess.SP

TL;DR: 提出 DU 编码＋PFM 解码，联合估计信道+源，实验验证效果远超前沿方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法需先进行信道估计后源重构，且往往依赖显式导频；本方法旨在通过联合估计和生成先验提升推断效率。

Method: 使用深度统一（DU）编码器将源信息编码为包含冗余的码字，接收端采用并行流匹配（PFM）解码器，利用基于流的生成模型共同估计信道和源。

Result: 在块衰落MIMO‑OFDM信道上，仿真表明DU‑PFM在信道估计和源重构上均显著优于现有扩散模型方法。

Conclusion: 本研究提出了深度统一编码器与并行流匹配解码器，实现了在无需显式导频与数据分离的情况下，对信道与源的不确定性进行联合估计，显著提升了MIMO‑OFDM系统的信道估计精度与源重构质量。

Abstract: In this work, we propose a deep unified (DU) encoder that embeds source information in a codeword that contains sufficient redundancy to handle both channel and source uncertainties, without enforcing an explicit pilot-data separation. At the receiver, we design a parallel flow-matching (PFM) decoder that leverages flow-based generative priors to jointly estimate the channel and the source, yielding much more efficient inference than the existing diffusion-based approaches. To benchmark performance limits, we derive the Bayesian Cramér-Rao bound (BCRB) for the joint channel and source estimation problem. Extensive simulations over block-fading MIMO-OFDM channels demonstrate that the proposed DU-PFM approach drastically outperforms the state-of-the-art methods in both channel estimation accuracy and source reconstruction quality.

</details>


### [65] [Denoise Stepwise Signals by Diffusion Model Based Approach](https://arxiv.org/abs/2602.08904)
*Xingdi Tong,Chenyu Wen*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Stepwise signals are ubiquitous in single-molecule detections, where abrupt changes in signal levels typically correspond to molecular conformational changes or state transitions. However, these features are inevitably obscured by noise, leading to uncertainty in estimating both signal levels and transition points. Traditional frequency-domain filtering is ineffective for denoising stepwise signals, as edge-related high-frequency components strongly overlap with noise. Although Hidden Markov Model-based approaches are widely used, they rely on stationarity assumptions and are not specifically designed for signal denoising. Here, we propose a diffusion model-based algorithm for stepwise signal denoising, named the Stepwise Signal Diffusion Model (SSDM). During training, SSDM learns the statistical structure of stepwise signals via a forward diffusion process that progressively adds noise. In the following reverse process, the model reconstructs clean signals from noisy observations, integrating a multi-scale convolutional network with an attention mechanism. Training data are generated by simulating stepwise signals through a Markov process with additive Gaussian noise. Across a broad range of signal-to-noise ratios, SSDM consistently outperforms traditional methods in both signal level reconstruction and transition point detection. Its effectiveness is further demonstrated on experimental data from single-molecule Forster Resonance Energy Transfer and nanopore DNA translocation measurements. Overall, SSDM provides a general and robust framework for recovering stepwise signals in various single-molecule detections and other physical systems exhibiting discrete state transitions.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [66] [Meta-Reinforcement Learning for Robust and Non-greedy Control Barrier Functions in Spacecraft Proximity Operations](https://arxiv.org/abs/2602.07335)
*Minduli C. Wijayatunga,Richard Linares,Roberto Armellin*

Main category: eess.SY

TL;DR: 通过学习参数化的 ICCBF 与元强化学习，可在推力约束与不确定条件下实现更安全、低燃料消耗的航天器检查与对接。


<details>
  <summary>Details</summary>
Motivation: 传统 ICCBF 在满足推力约束与不确定性时过于保守且鲁棒性差，导致燃料消耗高、任务可行性低；需要一种能够局部调整安全集并降低保守性的框架。

Method: 通过对 ICCBF 递归中的整个 class-𝒦 函数阶层进行参数化并利用差分代数高效计算控制裕度，将学习得到的连续时间 ICCBF 实现于典型的时采样系统；随后设计了元强化学习方案，使用 MLP 与 RNN 架构在隐藏物理参数及不确定性分布上训练生成 ICCBF 参数的策略。

Result: 仿真验证表明该方法在巡航控制、航天器检查与对接场景中保持安全的同时，燃料消耗减少、任务可行性提升；RNN 架构在复杂检查任务中表现尤为突出。

Conclusion: 在使用学习的全阶 class-𝒦 函数参数化的 ICCBF 框架下，系统能保证在推力约束与不确定性下的安全，同时显著降低燃料消耗并提升任务可行性，尤其在更复杂的检查场景中，RNN 模型表现更佳。

Abstract: Autonomous spacecraft inspection and docking missions require controllers that can guarantee safety under thrust constraints and uncertainty. Input-constrained control barrier functions (ICCBFs) provide a framework for safety certification under bounded actuation; however, conventional ICCBF formulations can be overly conservative and exhibit limited robustness to uncertainty, leading to high fuel consumption and reduced mission feasibility. This paper proposes a framework in which the full hierarchy of class-$\mathcal{K}$ functions defining the ICCBF recursion is parameterized and learned, enabling localized shaping of the safe set and reduced conservatism. A control margin is computed efficiently using differential algebra to enable the learned continuous-time ICCBFs to be implemented on time-sampled dynamical systems typical of spacecraft proximity operations. A meta-reinforcement learning scheme is developed to train a policy that generates ICCBF parameters over a distribution of hidden physical parameters and uncertainties, using both multilayer perceptron (MLP) and recurrent neural network (RNN) architectures. Simulation results on cruise control, spacecraft inspection, and docking scenarios demonstrate that the proposed approach maintains safety while reducing fuel consumption and improving feasibility relative to fixed class-$\mathcal{K}$ ICCBFs, with the RNN showing a particularly strong advantage in the more complex inspection case.

</details>


### [67] [In-Context System Identification for Nonlinear Dynamics Using Large Language Models](https://arxiv.org/abs/2602.07360)
*Linyu Lin*

Main category: eess.SY

TL;DR: 本文提出一种LLM辅助的SINDy管道，通过迭代交互式生成并评估候选方程，在多项动力系统数据上实现了比传统SINDy更高的符号回归精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: SINDy在发现非线性动力学时需要专家手工调参，易导致搜索空间有限且效率低；探索如何利用LLM的领域知识与符号推理来自动化并优化方程搜索，以降低专家干预并提升恢复质量。

Method: 首先使用自适应库拟合基础SINDy模型，随后进入LLM引导的迭代优化循环：在每个迭代中，将当前最佳方程、误差指标及领域约束汇总为提示并交给LLM，通过对话式学习生成新的候选方程结构；对候选方程进行符号解析、训练与测试数据评估，并以模拟误差与结构相似度为指标；若测试误差低于NRMSE 0.1或迭代次数达到10次即停止；最终选取最佳模型。

Result: 在63个ODEBench数据集以及冷却核反应堆模型上进行实验，LLM-aided SINDy相较传统SINDy在所有复杂动力学场景中取得更高的方程相似度与更低的测试RMSE；总体表现出一致的性能提升，验证了LLM能够有效引导符号搜索。

Conclusion: LLM的引入显著提升了SINDy在复杂动力系统中的符号恢复效果，能够在不完全依赖专家手工设计库的前提下，生成更准确、更具可解释性的支配方程。

Abstract: Sparse Identification of Nonlinear Dynamics (SINDy) is a powerful method for discovering parsimonious governing equations from data, but it often requires expert tuning of candidate libraries. We propose an LLM-aided SINDy pipeline that iteratively refines candidate equations using a large language model (LLM) in the loop through in-context learning. The pipeline begins with a baseline SINDy model fit using an adaptive library and then enters a LLM-guided refinement cycle. At each iteration, the current best equations, error metrics, and domain-specific constraints are summarized in a prompt to the LLM, which suggests new equation structures. These candidate equations are parsed against a defined symbolic form and evaluated on training and test data. The pipeline uses simulation-based error as a primary metric, but also assesses structural similarity to ground truth, including matching functional forms, key terms, couplings, qualitative behavior. An iterative stopping criterion ends refinement early if test error falls below a threshold (NRMSE < 0.1) or if a maximum of 10 iterations is reached. Finally, the best model is selected, and we evaluate this LLM-aided SINDy on 63 dynamical system datasets (ODEBench) and march leuba model for boiling nuclear reactor. The results are compared against classical SINDy and show the LLM-loop consistently improves symbolic recovery with higher equation similarity to ground truth and lower test RMSE than baseline SINDy for cases with complex dynamics. This work demonstrates that an LLM can effectively guide SINDy's search through equation space, integrating data-driven error feedback with domain-inspired symbolic reasoning to discover governing equations that are not only accurate but also structurally interpretable.

</details>


### [68] [$\partial$CBDs: Differentiable Causal Block Diagrams](https://arxiv.org/abs/2602.07581)
*Thomas Beckers,Ján Drgoňa,Truong X. Nghiem*

Main category: eess.SY

TL;DR: 提出∂CBDs，融合因果块图、合约验证与可微分编程，实现可组合、可验证且可学习的CPS建模。


<details>
  <summary>Details</summary>
Motivation: 传统CBD、DP 与合约验证各自局限，缺乏统一能同时支持组合性、可学习与可验证的系统。

Method: 在传统因果块图基础上引入 A--G 合约与可微分残差合约，兼顾模块化推理与自动微分优化。

Result: 构造了可结合数据、物理与约束的梯度优化过程，保证模型梯度可导且满足可靠性合约。

Conclusion: 提供了一种可微分、可验证、可学习的CPS建模框架——∂CBDs，实现了模块化、可训练与可验证的统一体系。

Abstract: Modern cyber-physical systems (CPS) integrate physics, computation, and learning, demanding modeling frameworks that are simultaneously composable, learnable, and verifiable. Yet existing approaches treat these goals in isolation: causal block diagrams (CBDs) support modular system interconnections but lack differentiability for learning; differentiable programming (DP) enables end-to-end gradient-based optimization but provides limited correctness guarantees; while contract-based verification frameworks remain largely disconnected from data-driven model refinement. To address these limitations, we introduce differentiable causal block diagrams ($\partial$CBDs), a unifying formalism that integrates these three perspectives. Our approach (i) retains the compositional structure and execution semantics of CBDs, (ii) incorporates assume--guarantee (A--G) contracts for modular correctness reasoning, and (iii) introduces residual-based contracts as differentiable, trajectory-level certificates compatible with automatic differentiation (AD), enabling gradient-based optimization and learning. Together, these elements enable a scalable, verifiable, and trainable modeling pipeline that preserves causality and modularity while supporting data-, physics-, and constraint-informed optimization for CPS.

</details>


### [69] [Quantifying resilience for distribution system customers with SALEDI](https://arxiv.org/abs/2602.07684)
*Arslan Ahmad,Ian Dobson*

Main category: eess.SY

TL;DR: 提出SALEDI，用对数变换降低大停电事件客户时间波动，提升指标稳定性并经过统计检验与实际数据验证。


<details>
  <summary>Details</summary>
Motivation: 传统可靠性指标能跟踪常规小故障，但对于极端大规模停电，客户受影响时间高度变异，难以以单一指标衡量，这限制了对电力系统弹性的量化；因此需要一条能够对极端事件进行有效缩放的指标。

Method: 对客户停电分钟数取对数后计算平均值，形成System Average Large Event Duration Index（SALEDI），并与替代指标进行对比；随后通过统计检验评估其精度，并使用实际停电数据说明其实用性。

Result: SALEDI在对五家公司停电数据的分析中显示：其估计误差低于其他指标，能够稳定、客观地捕捉大幅停电事件对客户的实际影响；并验证了其统计可靠性。

Conclusion: SALEDI有效量化大型停电事件对客户的影响，提供了比传统可靠性指标更精确、更稳定的弹性度量；其对不同风格的供电数据均表现良好，并已在五家电力公司的停电数据中得到验证。

Abstract: The impact of routine smaller outages on distribution system customers in terms of customer minutes interrupted can be tracked using conventional reliability indices. However, the customer minutes interrupted in large blackout events are extremely variable, and this makes it difficult to quantify the customer impact of these extreme events with resilience metrics. We solve this problem with the System Average Large Event Duration Index SALEDI that logarithmically transforms the customer minutes interrupted. We explain how this new resilience metric works, compare it with alternatives, quantify its statistical accuracy, and illustrate its practical use with standard outage data from five utilities.

</details>


### [70] [Convergence Analysis of Continuous-Time Distributed Stochastic Gradient Algorithms](https://arxiv.org/abs/2602.07836)
*Jianhua Sun,Kaihong Lu,Xin Yu*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we propose a new framework to study distributed optimization problems with stochastic gradients by employing a multi-agent system with continuous-time dynamics. Here the goal of the agents is to cooperatively minimize the sum of convex objective functions. When making decisions, each agent only has access to a stochastic gradient of its own objective function rather than the real gradient, and can exchange local state information with its immediate neighbors via a time-varying directed graph. Particularly, the stochasticity is depicted by the Brownian motion. To handle this problem, we propose a continuous-time distributed stochastic gradient algorithm based on the consensus algorithm and the gradient descent strategy. Under mild assumptions on the connectivity of the graph and objective functions, using convex analysis theory, the Lyapunov theory and Ito formula, we prove that the states of the agents asymptotically reach a common minimizer in expectation. Finally, a simulation example is worked out to demonstrate the effectiveness of our theoretical results.

</details>


### [71] [Accuracy-Delay Trade-Off in LLM Offloading via Token-Level Uncertainty](https://arxiv.org/abs/2602.07958)
*Yumin Kim,Hyeonsu Lyu,Minjae Lee,Hyun Jong Yang*

Main category: eess.SY

TL;DR: 提出不确定性感知下发框架与贪婪算法，实验表明在不同用户密度下能同时减少延迟并维持精度，超过传统方法。


<details>
  <summary>Details</summary>
Motivation: 在移动端计算受限的环境下，LLM推理计算量大导致性能瓶颈。

Method: 基于token级不确定性指标的动态推理选择框架，并设计了贪婪下发算法(GOA)

Result: GOA在多用户场景下，既降低延迟又保持/提升精度，优于基线策略

Conclusion: GOA为移动边缘计算中LLM推理提供了可扩展、高效的解决方案

Abstract: Large language models (LLMs) offer significant potential for intelligent mobile services but are computationally intensive for resource-constrained devices. Mobile edge computing (MEC) allows such devices to offload inference tasks to edge servers (ESs), yet introduces latency due to communication and serverside queuing, especially in multi-user environments. In this work, we propose an uncertainty-aware offloading framework that dynamically decides whether to perform inference locally or offload it to the ES, based on token-level uncertainty and resource constraints. We define a margin-based token-level uncertainty metric and demonstrate its correlation with model accuracy. Leveraging this metric, we design a greedy offloading algorithm (GOA) that minimizes delay while maintaining accuracy by prioritizing offloading for highuncertainty queries. Our experiments show that GOA consistently achieves a favorable trade-off, outperforming baseline strategies in both accuracy and latency across varying user densities, and operates with practical computation time. These results establish GOA as a scalable and effective solution for LLM inference in MEC environments.

</details>


### [72] [Trustworthiness Layer for Foundation Models in Power Systems: Application for N-k Contingency Assessment](https://arxiv.org/abs/2602.07995)
*Antonio Alcántara,Spyros Chatzivasileiadis*

Main category: eess.SY

TL;DR: 在电网 N‑k 并发分析中，结合分层覆盖预测提升大模型可靠性、精度与速度，更能泛化到更高阶并发情形！


<details>
  <summary>Details</summary>
Motivation: 提高能源系统中基础模型（Foundation Models）的可靠性与可解释性，解决传统模型缺乏统计显式不确定性估计的问题！

Method: 采用分层逐层覆盖预测构造自适应统计可信度区间，用于回归输出的置信区间与筛选决策的保守阈值！

Result: 将此方法应用于 GridFM，显著提升 N‑k 并发评估的可信度与精度；相较 DC 风险评估提高 2–3 倍精度、相较 AC 求解加速 8–18 倍！并能从 N‑1 / N‑2 训练集合理外推到 N‑5 的未见并发！

Conclusion: 通过可信度层，可让基于大模型的电力系统评估具备可解释、不确定性显式、快速、优于传统 AC/ DC 方法的特性，具有广泛应用前景！

Abstract: This work introduces for the first time, to our knowledge, a trustworthiness layer for foundation models in power systems. Using stratified conformal prediction, we devise adaptive, statistically valid confidence bounds for each output of a foundation model. For regression, this allows users to obtain an uncertainty estimate for each output; for screening, it supports conservative decisions that minimize false negatives. We demonstrate our method by enhancing GridFM, the first open-source Foundation Model for power systems, with statistically valid prediction intervals instead of heuristic error margins. We apply it for N-k contingency assessment, a combinatorial NP-Hard problem. We show that trustworthy GridFM can offer richer and more accurate information than DC Power Flow, having 2x-3x higher precision, while running up to 18x faster than AC Power Flow for systems up to 118 buses. Moving a step further, we also examine the ability of trustworthy GridFM to generalize to unseen high-order contingencies: through a rigorous analysis, we assess how a model trained on N-1 or N-2 outages extrapolates to unseen contingencies up to N-5.

</details>


### [73] [Robust and Gain-Scheduling ${\cal H}_2$ Control Techniques for LFT Uncertain and Parameter-Dependent Systems](https://arxiv.org/abs/2602.08137)
*Fen Wu*

Main category: eess.SY

TL;DR: E用LMI方法取得鲁棒与增益调度的${\cal H}_2$控制，成功降低保守性并提升干扰抑制性能。


<details>
  <summary>Details</summary>
Motivation: 解决受结构不确定性和白噪声扰动影响的LFT系统的鲁棒${\cal H}_2$合成问题。

Method: 引入中间矩阵变量，推导出基于线性矩阵不等式（LMI）的凸合成条件，可用于鲁棒和增益调度控制器设计。

Result: 实验与应用演示该鲁棒${\cal H}_2$控制器显著降低保守性，并相较传统鲁棒${\cal H}_\infty$设计具有更好的干扰抑制。

Conclusion: 在保持经典白噪声和冲激响应解释的前提下，扩展了最优${\cal H}_2$控制到非线性时间不变系统，并提供了鲁棒性保证。

Abstract: This paper addresses the robust ${\cal H}_2$ synthesis problem for linear fractional transformation (LFT) systems subject to structured uncertainty (parameter) and white-noise disturbances. By introducing an intermediate matrix variable, we derive convex synthesis conditions in terms of linear matrix inequalities (LMIs) that enable both robust and gain-scheduled controller design for parameter-dependent systems. The proposed framework preserves the classical white-noise and impulse-response interpretation of the ${\cal H}_2$ criterion while providing certified robustness guarantees, thereby extending optimal ${\cal H}_2$ control beyond the linear time-invariant setting. Numerical and application examples demonstrate that the resulting robust ${\cal H}_2$ controllers achieve significantly reduced conservatism and improved disturbance rejection compared with conventional robust ${\cal H}_\infty$-based designs.

</details>


### [74] [Pitot-Aided Attitude and Air Velocity Estimation with Almost Global Asymptotic Stability Guarantees](https://arxiv.org/abs/2602.08273)
*Melone Nyoba Tchonkeu,Soulaimane Berkane,Tarek Hamel*

Main category: eess.SY

TL;DR: 本文提出一种级联式观测器，用IMU与Pitot测量实现低传感器成本下的姿态与气流速度估计，并在UO条件下给出全局稳定性证明，实验支持其实效。


<details>
  <summary>Details</summary>
Motivation: 在无人机飞行中，传统姿态估计需要多传感器或强激励下才能满足精度，而少量传感器（IMU+Pitot）下的高精度连续估计一直是关键挑战。

Method: 先用Riccati/卡尔曼滤波器估计机体固定坐标系内的气流速度和机体俯仰角；随后将估计的俯仰角与磁力计数据在 SO(3) 上利用非线性观察器融合，获得完整姿态。

Result: 验证实验显示，该观测器在实际飞行数据中实现了有效的速度与姿态估计，并满足既定的几乎全局渐近稳定性。

Conclusion: 本文提出的级联观测器能实现固定翼无人机在IMU和Pitot数据条件下的姿态和气流速度估计，并在统一可观测条件下实现几乎全局渐近稳定。

Abstract: This paper investigates the problem of attitude and air velocity estimation for fixed-wing unmanned aerial vehicles (UAVs) using IMU measurements and at least one Pitot tube measurement, with almost global asymptotic stability (AGAS) guarantees. A cascade observer architecture is developed, in which a Riccati/Kalman-type filter estimates the body-fixed frame air velocity and the vehicle's tilt using IMU data as inputs and Pitot measurements as outputs. Under mild excitation conditions, the resulting air velocity and tilt estimation error dynamics are shown to be uniformly observable. The estimated tilt is then combined with magnetometer measurements in a nonlinear observer on SO(3) to recover the full attitude. Rigorous analysis establishes AGAS of the overall cascade structure under the uniform observability (UO) condition. The effectiveness of the proposed approach is demonstrated through validation on real flight data.

</details>


### [75] [Experimental Realization of Koopman-Model Predictive Control for an AC-DC Converter](https://arxiv.org/abs/2602.08303)
*Shun Hirose,Shiu Mochiyama,Yoshihiko Susuki*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper experimentally demonstrates the Koopman-Model Predictive Control (K-MPC) for a real AC-DC converter. The converter is typically modeled with a nonlinear time-variant plant. We introduce a new dynamical approach to lifting measurable dynamics from the plant and constructing a linear time-invariant model that is consistent with control objectives of the converter. We show that the lifting approach, combined with the K-MPC controller, performs well across the full experimental system and outperforms existing control strategies in terms of both steady-state and transient responses.

</details>


### [76] [An Approach for the Qualitative Graphical Representation of the Describing Function in Nonlinear Systems Stability Analysis](https://arxiv.org/abs/2602.08435)
*Davide Tebaldi,Roberto Zanasi*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The describing function method is a useful tool for the qualitative analysis of limit cycles in the stability analysis of nonlinear systems. This method is inherently approximate; therefore, it should be used for a fast qualitative analysis of the considered systems. However, plotting the exact describing function requires heavy mathematical calculations, reducing interest in this method especially from the point of view of control education. The objective of this paper is to enhance the describing function method by providing a new approach for the qualitative plotting of the describing function for piecewise nonlinearities involving discontinuities. Unlike the standard method, the proposed approach allows for a straightforward, hand-drawn plotting of the describing function using the rules introduced in this paper, simply by analyzing the shape of the nonlinearity. The proposed case studies show that the limit cycles estimation performed using the standard exact plotting of the describing function yields the same qualitative results as those obtained using the proposed qualitative method for plotting the describing function.

</details>


### [77] [A Multi-physics Simulation Framework for High-power Microwave Counter-unmanned Aerial System Design and Performance Evaluation](https://arxiv.org/abs/2602.08477)
*Akbar Anbar Jafari,Gholamreza Anbarjafari*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The proliferation of small unmanned aerial systems (sUAS) operating under autonomous guidance has created an urgent need for non-kinetic neutralization methods that are immune to conventional radio-frequency jamming. This paper presents a comprehensive multi-physics simulation framework for the design and performance evaluation of a high-power microwave (HPM) counter-UAS system operating at 2.45\,GHz. The framework integrates electromagnetic propagation modelling, antenna pattern analysis, electromagnetic coupling to unshielded drone wiring harnesses, and a sigmoid-based semiconductor damage probability model calibrated to published CMOS latchup thresholds. A 10{,}000-trial Monte Carlo analysis incorporating stochastic variations in transmitter power, antenna pointing error, target wire orientation, polarization mismatch, and component damage thresholds yields system-level kill probabilities with 95\% confidence intervals. For a baseline configuration of 25\,kW continuous-wave power and a 60\,cm parabolic reflector (21.2\,dBi gain), the Monte Carlo simulation predicts a kill probability of $51.4\pm1.0$\% at 20\,m, decreasing to $13.1\pm0.7$\% at 40\,m. Pulsed operation at 500\,kW peak power (1\% duty cycle) extends the 90\% kill range from approximately 18\,m to 88\,m. The framework further provides parametric design maps, safety exclusion zone calculations compliant with ICNIRP 2020 guidelines, thermal management requirements, and waveguide mode analysis. All simulation codes and results are provided for full reproducibility.

</details>


### [78] [Residential Peak Load Reduction via Direct Load Control under Limited Information](https://arxiv.org/abs/2602.08598)
*Katharina Kaiser,Gustavo Valverde,Gabriela Hug*

Main category: eess.SY

TL;DR: 开发了一种利用热泵、电热水器及电动车有限信息的优化控制器，成功在夏季提高了峰值削减，且在无完善知识的情况下实现了约一半理想方案的峰值削减效果。


<details>
  <summary>Details</summary>
Motivation: 低压配电网峰值负荷过大，需要利用可控负荷和电动车的可调节性来降低功率峰值，从而提升配电网的可靠性和效率。

Method: 提出基于优化的预测控制方案，利用热泵、电热水器和电动车的有限信息，限制可调节负荷的运行时间以平滑配电变压器前的总负荷曲线，并保持客户舒适。

Result: 改进后控制方案在夏季比原方案获得更大的峰值削减；与理想控制器比较，有限信息的方案可实现其潜在平均峰值削减的约一半。

Conclusion: 改进的控制器在夏季实现了更大的峰值削减，并且在具有限量信息的条件下，能够获得相当于理想控制器（全知情）的约一半的日峰值削减效果。

Abstract: Thermostatically controlled loads and electric vehicles offer flexibility to reduce power peaks in low-voltage distribution networks. This flexibility can be maximized if the devices are coordinated centrally, given some level of information about the controlled devices. In this paper, we propose novel optimization-based control schemes with prediction capabilities that utilize limited information from heat pumps, electric water heaters, and electric vehicles. The objective is to flatten the total load curve seen by the distribution transformer by restricting the times at which the available flexible loads are allowed to operate, subject to the flexibility constraints of the loads to preserve customers' comfort. The original scheme was tested in a real-world setup, considering both winter and summer days. The pilot results confirmed the technical feasibility but also informed the design of an improved version of the controller. Computer simulations using the adjusted controller show that, compared to the original formulation, the improved scheme achieves greater peak reductions in summer. Additionally, comparisons were made with an ideal controller, which assumes perfect knowledge of the inflexible load profile, the models of the controlled devices, the hot water and space heating demand, and future electric vehicle charging sessions. The proposed scheme with limited information achieves almost half of the potential average daily peak reduction that the ideal controller with perfect knowledge would achieve.

</details>


### [79] [Stability and stabilization of semilinear single-track vehicle models with distributed tire friction dynamics via singular perturbation analysis](https://arxiv.org/abs/2602.08757)
*Luigi Romano,Ole Morten Aamo,Miroslav Krstić,Jan Åslund,Erik Frisk*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper investigates the stability and stabilization of semilinear single-track vehicle models with distributed tire friction dynamics, modeled as interconnections of ordinary differential equations (ODEs) and hyperbolic partial differential equations (PDEs). Motivated by the long-standing practice of neglecting transient tire dynamics in vehicle modeling and control, a rigorous justification is provided for such simplifications using singular perturbation theory. A perturbation parameter, defined as the ratio between a characteristic rolling contact length and the vehicle's longitudinal speed, is introduced to formalize the time-scale separation between rigid-body motion and tire dynamics. For sufficiently small values of this parameter, it is demonstrated that standard finite-dimensional techniques can be applied to analyze the local stability of equilibria and to design stabilizing controllers. Both state-feedback and output-feedback designs are considered, under standard stabilizability and detectability assumptions. Whilst the proposed controllers follow classical approaches, the novelty of the work lies in establishing the first mathematical framework that rigorously connects distributed tire models with conventional vehicle dynamics. The results reconcile decades of empirical findings with a formal theoretical foundation and open new perspectives for the analysis and control of ODE-PDE systems with distributed friction in automotive applications.

</details>


### [80] [Passivity-exploiting stabilization of semilinear single-track vehicle models with distributed tire friction dynamics](https://arxiv.org/abs/2602.08767)
*Luigi Romano,Ole Morten Aamo,Miroslav Krstić,Jan Åslund,Erik Frisk*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper addresses the local stabilization problem for semilinear single-track vehicle models with distributed tire friction dynamics, represented as interconnections of ordinary differential equations (ODEs) and hyperbolic partial differential equations (PDEs). A passivity-exploiting backstepping design is presented, which leverages the strict dissipativity properties of the PDE subsystem to achieve exponential stabilization of the considered ODE-PDE interconnection around a prescribed equilibrium. Sufficient conditions for local well-posedness and exponential convergence are derived by constructing a Lyapunov functional combining the lumped and distributed states. Both state-feedback and output-feedback controllers are synthesized, the latter relying on a cascaded observer. The theoretical results are corroborated with numerical simulations, considering non-ideal scenarios and accounting for external disturbances and uncertainties. Simulation results confirm that the proposed control strategy can effectively and robustly stabilize oversteer vehicles at high speeds, demonstrating the relevance of the approach for improving the safety and performance in automotive applications.

</details>


### [81] [Accelerated Stabilization of Switched Linear MIMO Systems using Generalized Homogeneity](https://arxiv.org/abs/2602.08903)
*Moussa Labbadi,Andrey Polyakov,Denis Efimov*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper addresses the problem of exponential and accelerated finite-time, as well as nearly fixed-time, stabilization of switched linear MIMO systems. The proposed approach relies on a generalized homogenization framework for switched linear systems and employs implicit Lyapunov functions for control design, covering both common and multiple Lyapunov function settings. Linear matrix equations and inequalities are derived to characterize the dilation generator and to synthesize the controller gains. Robustness of the resulting control laws with respect to system uncertainties and external disturbances is analyzed. The effectiveness of the proposed approach is illustrated through numerical examples.

</details>


### [82] [Artificial Magnetic Conductor Frame to Improve Impedance Matching and Radiation Symmetry in 2$\times$2 Array for 6G Applications](https://arxiv.org/abs/2602.08943)
*Edoardo Giusti,Krishan Kumar Tiwari,C. J. Reddy,Danilo Brizi,Agostino Monorchio,Giuseppe Caire*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: An Artificial Magnetic Conductor (AMC) frame capable of improving the impedance matching of a 2$\times$2 array for 6G applications without degrading isolation performance is presented. The proposed frame is integrated into the array without modifying the single radiating element design. By relying on accurate full-wave simulations, it results that the addition of the frame restores the impedance matching performance, achieving a bandwidth of 1.5 GHz at 28 GHz. The isolation between each port remains under -15 dB within the operating band, thanks to the vias in the rectangular patch metasurface. Moreover, the overall structure exhibits a gain of 11.81 dBi with an aperture efficiency of 69$\%$, satisfactorily for broadband communication purposes. The proposed AMC frame represents an effective method for improving array performance without the need to alter the shape or dimensions of the single radiating element.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [83] [RIFLE: Robust Distillation-based FL for Deep Model Deployment on Resource-Constrained IoT Networks](https://arxiv.org/abs/2602.08446)
*Pouria Arefijamal,Mahdi Ahmadlou,Bardia Safaei,Jörg Henkel*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Federated learning (FL) is a decentralized learning paradigm widely adopted in resource-constrained Internet of Things (IoT) environments. These devices, typically relying on TinyML models, collaboratively train global models by sharing gradients with a central server while preserving data privacy. However, as data heterogeneity and task complexity increase, TinyML models often become insufficient to capture intricate patterns, especially under extreme non-IID (non-independent and identically distributed) conditions. Moreover, ensuring robustness against malicious clients and poisoned updates remains a major challenge. Accordingly, this paper introduces RIFLE - a Robust, distillation-based Federated Learning framework that replaces gradient sharing with logit-based knowledge transfer. By leveraging a knowledge distillation aggregation scheme, RIFLE enables the training of deep models such as VGG-19 and Resnet18 within constrained IoT systems. Furthermore, a Kullback-Leibler (KL) divergence-based validation mechanism quantifies the reliability of client updates without exposing raw data, achieving high trust and privacy preservation simultaneously. Experiments on three benchmark datasets (MNIST, CIFAR-10, and CIFAR-100) under heterogeneous non-IID conditions demonstrate that RIFLE reduces false-positive detections by up to 87.5%, enhances poisoning attack mitigation by 62.5%, and achieves up to 28.3% higher accuracy compared to conventional federated learning baselines within only 10 rounds. Notably, RIFLE reduces VGG19 training time from over 600 days to just 1.39 hours on typical IoT devices (0.3 GFLOPS), making deep learning practical in resource-constrained networks.

</details>


### [84] [ArcMark: Multi-bit LLM Watermark via Optimal Transport](https://arxiv.org/abs/2602.07235)
*Atefeh Gilani,Carol Xuan Long,Sajani Vithana,Oliver Kosut,Lalitha Sankar,Flavio P. Calmon*

Main category: cs.LG

TL;DR: 本研究首次给出多位水印信息理论容量，并基于此提出ArcMark，显著提升水印位速率与检测准确率，证明水印本质为通道编码问题。


<details>
  <summary>Details</summary>
Motivation: 现有多位水印多采用单位一比特编码，容量上限不明，亟需理论指导以提升水印效能。

Method: 利用信息论与编码理论推导多位水印容量，并基于此设计ArcMark，利用多位编码实现更高位速率与检测准确率。

Result: ArcMark在位速率与检出准确率上优于现有方案，能够在保证不改变平均下一个词预测的前提下接近理论容量。

Conclusion: 多位水印是通道编码问题，本文首次提供信息论容量上界并推导ArcMark，实现了容量接近的水印方案。

Abstract: Watermarking is an important tool for promoting the responsible use of language models (LMs). Existing watermarks insert a signal into generated tokens that either flags LM-generated text (zero-bit watermarking) or encodes more complex messages (multi-bit watermarking). Though a number of recent multi-bit watermarks insert several bits into text without perturbing average next-token predictions, they largely extend design principles from the zero-bit setting, such as encoding a single bit per token. Notably, the information-theoretic capacity of multi-bit watermarking -- the maximum number of bits per token that can be inserted and detected without changing average next-token predictions -- has remained unknown. We address this gap by deriving the first capacity characterization of multi-bit watermarks. Our results inform the design of ArcMark: a new watermark construction based on coding-theoretic principles that, under certain assumptions, achieves the capacity of the multi-bit watermark channel. In practice, ArcMark outperforms competing multi-bit watermarks in terms of bit rate per token and detection accuracy. Our work demonstrates that LM watermarking is fundamentally a channel coding problem, paving the way for principled coding-theoretic approaches to watermark design.

</details>


### [85] [Learning Nonlinear Systems In-Context: From Synthetic Data to Real-World Motor Control](https://arxiv.org/abs/2602.07173)
*Tong Jian,Tianyu Dai,Tao Yu*

Main category: cs.LG

TL;DR: 提出 Transformer‑ICL 电机前馈控制模型，先在合成系统上预训练，再用少量实机样本快速适配，最终性能优于 PI 与物理方法。


<details>
  <summary>Details</summary>
Motivation: 传统的 PI 控制器和基于物理的信号处理方法在面对非线性与复杂负载条件时往往表现不佳。近年来大规模语言模型（LLM）展示了强大的上下文学习（ICL）能力，但尚未将其扩展到信号处理系统。本研究的动因是探索是否能将 LLM 的 ICL 能力迁移到电机前馈控制这一关键但挑战性的问题上，以实现更高效的数据利用和适应性。

Method: 提出一种基于 Transformer 的架构，将信号表示与系统行为相分离，从而支持少样本微调和一次式 ICL。该模型在大规模合成的线性与非线性系统上进行预训练，学习到对未知系统动力学的泛化能力。随后仅需少量真实电机样本即可完成适配，实现一次式前馈预测。

Result: 实验表明，该方法能够跨多种电机负载配置进行泛化，对未调参的数据样本也能产生准确的前馈预测，并在性能上优于传统 PI 控制器及基于物理模型的前馈基线。

Conclusion: 本工作证明了 ICL 可以有效衔接合成预训练与现实环境的适配，开启了利用数据高效控制物理系统的新方向。

Abstract: LLMs have shown strong in-context learning (ICL) abilities, but have not yet been extended to signal processing systems. Inspired by their design, we have proposed for the first time ICL using transformer models applicable to motor feedforward control, a critical task where classical PI and physics-based methods struggle with nonlinearities and complex load conditions. We propose a transformer based model architecture that separates signal representation from system behavior, enabling both few-shot finetuning and one-shot ICL. Pretrained on a large corpus of synthetic linear and nonlinear systems, the model learns to generalize to unseen system dynamics of real-world motors only with a handful of examples. In experiments, our approach generalizes across multiple motor load configurations, transforms untuned examples into accurate feedforward predictions, and outperforms PI controllers and physics-based feedforward baselines. These results demonstrate that ICL can bridge synthetic pretraining and real-world adaptability, opening new directions for data efficient control of physical systems.

</details>


### [86] [Don't Always Pick the Highest-Performing Model: An Information Theoretic View of LLM Ensemble Selection](https://arxiv.org/abs/2602.08003)
*Yigit Turkmen,Baturalp Buyukates,Melih Bastopcu*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) are often ensembled together to improve overall reliability and robustness, but in practice models are strongly correlated. This raises a fundamental question: which models should be selected when forming an LLM ensemble? We formulate budgeted ensemble selection as maximizing the mutual information between the true label and predictions of the selected models. Furthermore, to explain why performance can saturate even with many models, we model the correlated errors of the models using Gaussian-copula and show an information-theoretic error floor for the performance of the ensemble. Motivated by these, we propose a simple greedy mutual-information selection algorithm that estimates the required information terms directly from data and iteratively builds an ensemble under a query budget. We test our approach in two question answering datasets and one binary sentiment classification dataset: MEDMCQA, MMLU, and IMDB movie reviews. Across all datasets, we observe that our method consistently outperforms strong baselines under the same query budget.

</details>


### [87] [Privately Learning Decision Lists and a Differentially Private Winnow](https://arxiv.org/abs/2602.07370)
*Mark Bun,William Fang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We give new differentially private algorithms for the classic problems of learning decision lists and large-margin halfspaces in the PAC and online models. In the PAC model, we give a computationally efficient algorithm for learning decision lists with minimal sample overhead over the best non-private algorithms. In the online model, we give a private analog of the influential Winnow algorithm for learning halfspaces with mistake bound polylogarithmic in the dimension and inverse polynomial in the margin. As an application, we describe how to privately learn decision lists in the online model, qualitatively matching state-of-the art non-private guarantees.

</details>


### [88] [Efficient and Adaptable Detection of Malicious LLM Prompts via Bootstrap Aggregation](https://arxiv.org/abs/2602.08062)
*Shayan Ali Hassan,Tao Ni,Zafar Ayyub Qazi,Marco Canini*

Main category: cs.LG

TL;DR: BAGEL：小模型集成+随机森林路由，轻量且可增量升级，F1 0.92，430M参数，超越千亿参数防护。


<details>
  <summary>Details</summary>
Motivation: 当前黑盒API缺乏透明度且不易跟随威胁演变，白盒大模型评判器成本高昂并需重训练，迫切需要兼顾性能、效率与适应性的防御框架。

Method: BAGEL采用Bootstrap聚合和专家混合的轻量级模型集合，并利用随机森林路由器进行成员选择，结合随机抽样进行预测聚合；新攻击可通过微调86M参数分类器进行增量更新。

Result: 在六个演示数据集上，BAGEL仅使用5个成员（430M参数）即可达到0.92 F1，优于OpenAI Moderation API和ShieldGemma；在9次增量更新后性能仍稳健，且具有路由器可解释性。

Conclusion: BAGEL通过小模型集成实现高效、可增量升级的恶意提示检测，匹配甚至超越千亿参数的防护，保持了高F1分数并提供可解释性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, reasoning, and generation. However, these systems remain susceptible to malicious prompts that induce unsafe or policy-violating behavior through harmful requests, jailbreak techniques, and prompt injection attacks. Existing defenses face fundamental limitations: black-box moderation APIs offer limited transparency and adapt poorly to evolving threats, while white-box approaches using large LLM judges impose prohibitive computational costs and require expensive retraining for new attacks. Current systems force designers to choose between performance, efficiency, and adaptability.
  To address these challenges, we present BAGEL (Bootstrap AGgregated Ensemble Layer), a modular, lightweight, and incrementally updatable framework for malicious prompt detection. BAGEL employs a bootstrap aggregation and mixture of expert inspired ensemble of fine-tuned models, each specialized on a different attack dataset. At inference, BAGEL uses a random forest router to identify the most suitable ensemble member, then applies stochastic selection to sample additional members for prediction aggregation. When new attacks emerge, BAGEL updates incrementally by fine-tuning a small prompt-safety classifier (86M parameters) and adding the resulting model to the ensemble. BAGEL achieves an F1 score of 0.92 by selecting just 5 ensemble members (430M parameters), outperforming OpenAI Moderation API and ShieldGemma which require billions of parameters. Performance remains robust after nine incremental updates, and BAGEL provides interpretability through its router's structural features. Our results show ensembles of small finetuned classifiers can match or exceed billion-parameter guardrails while offering the adaptability and efficiency required for production systems.

</details>


### [89] [Stateless Yet Not Forgetful: Implicit Memory as a Hidden Channel in LLMs](https://arxiv.org/abs/2602.08563)
*Ahmed Salem,Andrew Paverd,Sahar Abdelnabi*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) are commonly treated as stateless: once an interaction ends, no information is assumed to persist unless it is explicitly stored and re-supplied. We challenge this assumption by introducing implicit memory-the ability of a model to carry state across otherwise independent interactions by encoding information in its own outputs and later recovering it when those outputs are reintroduced as input. This mechanism does not require any explicit memory module, yet it creates a persistent information channel across inference requests. As a concrete demonstration, we introduce a new class of temporal backdoors, which we call time bombs. Unlike conventional backdoors that activate on a single trigger input, time bombs activate only after a sequence of interactions satisfies hidden conditions accumulated via implicit memory. We show that such behavior can be induced today through straightforward prompting or fine-tuning. Beyond this case study, we analyze broader implications of implicit memory, including covert inter-agent communication, benchmark contamination, targeted manipulation, and training-data poisoning. Finally, we discuss detection challenges and outline directions for stress-testing and evaluation, with the goal of anticipating and controlling future developments. To promote future research, we release code and data at: https://github.com/microsoft/implicitMemory.

</details>


### [90] [Sparse Models, Sparse Safety: Unsafe Routes in Mixture-of-Experts LLMs](https://arxiv.org/abs/2602.08621)
*Yukun Jiang,Hai Huang,Mingjie Li,Yage Zhang,Michael Backes,Yang Zhang*

Main category: cs.LG

TL;DR: 本文揭示MoE LLMs存在安全漏洞，提出评估与发现unsafe路由的方法，并给出防御建议


<details>
  <summary>Details</summary>
Motivation: 研究混合专家（MoE）架构在大语言模型中对安全性影响的不足

Method: 提出Router Safety importance score (RoSais)评估路由器安全重要性，并使用Fine-grained token-layer-wise Stochastic Optimization (F-SOUR)寻找具体unsafe routes

Result: 通过操纵高RoSais路由器，DeepSeek-V2-Lite的攻击成功率提升4倍至0.79；F-SOUR在四类MoE LLM上平均ASR分别达到0.90和0.98

Conclusion: MoE LLMs的安全风险与其稀疏架构相关，路由器操纵可显著提升恶意输出风险，需要安全意识路由禁用和路由器训练等防御措施

Abstract: By introducing routers to selectively activate experts in Transformer layers, the mixture-of-experts (MoE) architecture significantly reduces computational costs in large language models (LLMs) while maintaining competitive performance, especially for models with massive parameters. However, prior work has largely focused on utility and efficiency, leaving the safety risks associated with this sparse architecture underexplored. In this work, we show that the safety of MoE LLMs is as sparse as their architecture by discovering unsafe routes: routing configurations that, once activated, convert safe outputs into harmful ones. Specifically, we first introduce the Router Safety importance score (RoSais) to quantify the safety criticality of each layer's router. Manipulation of only the high-RoSais router(s) can flip the default route into an unsafe one. For instance, on JailbreakBench, masking 5 routers in DeepSeek-V2-Lite increases attack success rate (ASR) by over 4$\times$ to 0.79, highlighting an inherent risk that router manipulation may naturally occur in MoE LLMs. We further propose a Fine-grained token-layer-wise Stochastic Optimization framework to discover more concrete Unsafe Routes (F-SOUR), which explicitly considers the sequentiality and dynamics of input tokens. Across four representative MoE LLM families, F-SOUR achieves an average ASR of 0.90 and 0.98 on JailbreakBench and AdvBench, respectively. Finally, we outline defensive perspectives, including safety-aware route disabling and router training, as promising directions to safeguard MoE LLMs. We hope our work can inform future red-teaming and safeguarding of MoE LLMs. Our code is provided in https://github.com/TrustAIRLab/UnsafeMoE.

</details>


### [91] [Dashed Line Defense: Plug-And-Play Defense Against Adaptive Score-Based Query Attacks](https://arxiv.org/abs/2602.08679)
*Yanzhang Fu,Zizheng Guo,Jizhou Luo*

Main category: cs.LG

TL;DR: 本文揭示了现有运行时防御在自适应攻击下易被绕过，提出 Dashed Line Defense（DLD）——一种后置处理方法，可在不影响标签的前提下通过损失歧义阻止得分查询攻击，实验证明其在 ImageNet 上对抗自适应攻击时表现优于先前方案。


<details>
  <summary>Details</summary>
Motivation: 本文指出，基于得分的查询攻击通过仅利用模型输出得分进行迭代优化，能够在黑盒情况下制造对抗样本，对深度学习模型构成严重威胁。现有的运行时防御大多需访问模型参数或在攻击者自适应时失效，缺乏可靠性。

Method: 提出可插拔的后置处理方案Dashed Line Defense (DLD)，通过在观察到的损失值与候选样本真实攻击强度之间引入歧义，扰乱攻击者对查询的分析与自适应，从而阻断对抗样本的生成过程。提供理论证明其防御能力，并在 ImageNet 上通过实验验证。

Result: 在一个或多个最坏情况下的自适应攻击下，DLD 的性能始终优于之前的防御方法，并且不会影响模型的原始预测标签。

Conclusion: 现有运行时防御对自适应攻击易被绕过，DLD 通过引入损失歧义实现了对自适应查询攻击的有效抵御，确认了其作为可靠可插拔防御方案的可行性。

Abstract: Score-based query attacks pose a serious threat to deep learning models by crafting adversarial examples (AEs) using only black-box access to model output scores, iteratively optimizing inputs based on observed loss values. While recent runtime defenses attempt to disrupt this process via output perturbation, most either require access to model parameters or fail when attackers adapt their tactics. In this paper, we first reveal that even the state-of-the-art plug-and-play defense can be bypassed by adaptive attacks, exposing a critical limitation of existing runtime defenses. We then propose Dashed Line Defense (DLD), a plug-and-play post-processing method specifically designed to withstand adaptive query strategies. By introducing ambiguity in how the observed loss reflects the true adversarial strength of candidate examples, DLD prevents attackers from reliably analyzing and adapting their queries, effectively disrupting the AE generation process. We provide theoretical guarantees of DLD's defense capability and validate its effectiveness through experiments on ImageNet, demonstrating that DLD consistently outperforms prior defenses--even under worst-case adaptive attacks--while preserving the model's predicted labels.

</details>


### [92] [Spectral Guardrails for Agents in the Wild: Detecting Tool Use Hallucinations via Attention Topology](https://arxiv.org/abs/2602.08082)
*Valentin Noël*

Main category: cs.LG

TL;DR: Spectral attention analysis yields a fast, training‑free hallucination detector with high recall and precision, demonstrating that hallucinations manifest as noisy attention patterns and enabling safer autonomous agent deployment.


<details>
  <summary>Details</summary>
Motivation: Existing supervised guardrails rely on expensive labeled data; reliable, lightweight detection of tool‑use failures (hallucinations) is critical for deploying autonomous agents safely in the wild.

Method: Compute single‑layer spectral features (smoothness, entropy) from attention matrices during inference, and apply simple thresholding to flag hallucinations without labeled data.

Result: On Llama 3.1 8B: 97.7% recall (multi‑feature) and 86.1% recall/81.0% precision (balanced). Llama L26 Smoothness: 98.2% recall; Mistral L3 Entropy: 94.7% recall. Cross‑model evaluation shows Loud Liar effect—Llama’s errors are spectrally catastrophic; Mistral 7B best discrimination (AUC 0.900).

Conclusion: Spectral analysis of attention topology provides an effective, training‑free safeguard for detecting hallucinations in large language models, achieving near‑perfect recall and strong precision across multiple models; this method reveals hallucination as a thermodynamic state change in attention patterns.

Abstract: Deploying autonomous agents in the wild requires reliable safeguards against tool use failures. We propose a training free guardrail based on spectral analysis of attention topology that complements supervised approaches. On Llama 3.1 8B, our method achieves 97.7\% recall with multi-feature detection and 86.1\% recall with 81.0\% precision for balanced deployment, without requiring any labeled training data. Most remarkably, we discover that single layer spectral features act as near-perfect hallucination detectors: Llama L26 Smoothness achieves 98.2\% recall (213/217 hallucinations caught) with a single threshold, and Mistral L3 Entropy achieves 94.7\% recall. This suggests hallucination is not merely a wrong token but a thermodynamic state change: the model's attention becomes noise when it errs. Through controlled cross-model evaluation on matched domains ($N=1000$, $T=0.3$, same General domain, hallucination rates 20--22\%), we reveal the ``Loud Liar'' phenomenon: Llama 3.1 8B's failures are spectrally catastrophic and dramatically easier to detect, while Mistral 7B achieves the best discrimination (AUC 0.900). These findings establish spectral analysis as a principled, efficient framework for agent safety.

</details>


### [93] [StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors](https://arxiv.org/abs/2602.08934)
*Suraj Ranganath,Atharv Ramesh*

Main category: cs.LG

TL;DR: StealthRL通过强化学习生成几乎能规避多分类检测器的改写文本，表明现有模型在语义保持与检测之间易受攻击。


<details>
  <summary>Details</summary>
Motivation: 探讨AI文本检测器在面对保持语义但规避检测的对手式改写攻击时的鲁棒性挑战。

Method: 使用StealthRL——一种基于强化学习的框架，采用Group Relative Policy Optimization (GRPO)与LoRA适配器在Qwen3-4B上训练改写策略，以平衡检测规避与语义保持。

Result: 在1%假阳性阈值下，StealthRL的攻击成功率达99.9%，平均TPR降至0.001，AUROC从0.74降至0.27；攻击对未见过的检测器同样适用，说明存在共享架构缺陷。

Conclusion: 本文展示了当前AI文本检测器在鲁棒性上的重大缺口，并通过StealthRL提供了一套系统的对手式评估协议。

Abstract: AI-text detectors face a critical robustness challenge: adversarial paraphrasing attacks that preserve semantics while evading detection. We introduce StealthRL, a reinforcement learning framework that stress-tests detector robustness under realistic adversarial conditions. StealthRL trains a paraphrase policy against a multi-detector ensemble using Group Relative Policy Optimization (GRPO) with LoRA adapters on Qwen3-4B, optimizing a composite reward that balances detector evasion with semantic preservation. We evaluate six attack settings (M0-M5) against three detector families (RoBERTa, FastDetectGPT, and Binoculars) at the security-relevant 1% false positive rate operating point. StealthRL achieves near-zero detection (0.001 mean TPR@1%FPR), reduces mean AUROC from 0.74 to 0.27, and attains a 99.9% attack success rate. Critically, attacks transfer to a held-out detector family not seen during training, revealing shared architectural vulnerabilities rather than detector-specific brittleness. We additionally conduct LLM-based quality evaluation via Likert scoring, analyze detector score distributions to explain why evasion succeeds, and provide per-detector AUROC with bootstrap confidence intervals. Our results expose significant robustness gaps in current AI-text detection and establish StealthRL as a principled adversarial evaluation protocol. Code and evaluation pipeline are publicly available at https://github.com/suraj-ranganath/StealthRL.

</details>


### [94] [FreqLens: Interpretable Frequency Attribution for Time Series Forecasting](https://arxiv.org/abs/2602.08768)
*Chi-Sheng Chen,Xinyu Zhang,En-Jui Kuo,Guan-Ying Chen,Qiuzhe Xie,Fan Zhang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Time series forecasting models often lack interpretability, limiting their adoption in domains requiring explainable predictions. We propose \textsc{FreqLens}, an interpretable forecasting framework that discovers and attributes predictions to learnable frequency components. \textsc{FreqLens} introduces two key innovations: (1) \emph{learnable frequency discovery} -- frequency bases are parameterized via sigmoid mapping and learned from data with diversity regularization, enabling automatic discovery of dominant periodic patterns without domain knowledge; and (2) \emph{axiomatic frequency attribution} -- a theoretically grounded framework that provably satisfies Completeness, Faithfulness, Null-Frequency, and Symmetry axioms, with per-frequency attributions equivalent to Shapley values. On Traffic and Weather datasets, \textsc{FreqLens} achieves competitive or superior performance while discovering physically meaningful frequencies: all 5 independent runs discover the 24-hour daily cycle ($24.6 \pm 0.1$h, 2.5\% error) and 12-hour half-daily cycle ($11.8 \pm 0.1$h, 1.6\% error) on Traffic, and weekly cycles ($10\times$ longer than the input window) on Weather. These results demonstrate genuine frequency-level knowledge discovery with formal theoretical guarantees on attribution quality.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [95] [Mirage: Transmitting a Video as a Perceptual Illusion for 50,000X Speedup](https://arxiv.org/abs/2602.07396)
*Junjie Wu,Tianrui Li,Yi Zhang,Ziyuan Yang*

Main category: cs.NI

TL;DR: Mirage框架将视频拆分为时序/空间语义表征，仅传递语义数据；接收端用生成模型重建视频，压缩率可达50,000倍，保持隐私并支持自定义设置。


<details>
  <summary>Details</summary>
Motivation: 当前通信框架以信号级重建为目标，导致高通信成本与系统复杂度，尤其是视频传输场景；需要更高效的语义级通信方案。

Method: 提出Mirage框架，将视频拆分为时序信息（通过视频字幕保持）和空间外观（关键帧压缩为语义表征），仅传输语义表征，接收端利用生成式视频模型合成视频。

Result: 实验显示Mirage在视频传输中实现高达50000倍的数据压缩速度提升，且具备隐私保护与可个性化调节。

Conclusion: Mirage通过语义级通信显著降低带宽消耗，同时保持语义信息，提供灵活的效率-隐私-质量权衡。

Abstract: The existing communication framework mainly aims at accurate reconstruction of source signals to ensure reliable transmission. However, this signal-level fidelity-oriented design often incurs high communication overhead and system complexity, particularly in video communication scenarios where mainstream frameworks rely on transmitting visual data itself, resulting in significant bandwidth consumption. To address this issue, we propose a visual data-free communication framework, Mirage, for extremely efficient video transmission while preserving semantic information. Mirage decomposes video content into two complementary components: temporal sequence information capturing motion dynamics and spatial appearance representations describing overall visual structure. Temporal information is preserved through video captioning, while key frames are encoded into compact semantic representations for spatial appearance. These representations are transmitted to the receiver, where videos are synthesized using generative video models. Since no raw visual data is transmitted, Mirage is inherently privacy-preserving. Mirage also supports personalized adaptation across deployment scenarios. The sender, network, and receiver can independently impose constraints on semantic representation, transmission, and generation, enabling flexible trade-offs between efficiency, privacy, control, and perceptual quality. Experimental results in video transmission demonstrate that Mirage achieves up to a 50000X data-level compression speedup over raw video transmission, with gains expected to scale with larger video content sizes.

</details>


### [96] [LEO Topology Design Under Real-World Deployment Constraints](https://arxiv.org/abs/2602.07756)
*Muaz Ali,Beichuan Zhang*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The performance of large-scale Low-Earth-Orbit (LEO) networks, which consist of thousands of satellites interconnected by optical links, is dependent on its network topology. Existing topology designs often assume idealized conditions and do not account for real-world deployment dynamics, such as partial constellation deployment, daily node turnovers, and varying link availability, making them inapplicable to real LEO networks. In this paper, we develop two topology design methods that explicitly operate under real-world deployment constraints: the Long--Short Links (LSL) method, which systematically combines long-distance shortcut links with short-distance local links, and the Simulated Annealing (SA) method, which constructs topologies via stochastic optimization. Evaluated under both full deployment and partial deployment scenarios using 3-months of Starlink data, our methods achieve up to 45% lower average end-to-end delay, 65% fewer hops, and up to $2.3\times$ higher network capacity compared to +Grid. Both methods are designed to handle daily node turnovers by incrementally updating the topology, maintaining good network performance while avoiding costly full reconstruction of the topology.

</details>


### [97] [Trajectory-Aware Multi-RIS Activation and Configuration: A Riemannian Diffusion Method](https://arxiv.org/abs/2602.07937)
*Kaining Wang,Bo Yang,Yusheng Lei,Zhibo Li,Zhiwen Yu,Xuelin Cao,Bin Guo,George C. Alexandropoulos,Dusit Niyato,Mérouane Debbah,Zhu Han*

Main category: cs.NI

TL;DR: 本文提出基于轨迹预测与 Riemannian 扩散的多 RIS 控制框架，显著提升 SINR，在多用户多 RIS 场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 多 RIS 环境中，随时激活容易放大干扰，尤其在大规模、移动密集且 LOS 重叠频繁的情况，需智能调度以维持 SINR。

Method: 1) LSTM 结合速度与航向预测多用户轨迹；2) Riemannian 扩散模型在圆上生成相位配置，并由强化学习动态引导；3) 通过比较激活与未激活下的可实现速率，诱导最优的 RIS 开/关状态。

Result: 仿真表明，本框架在不同发射功率、RIS 配置与干扰密度下，均比学习控制方案提升约 30% SINR，比始终开启方案提升约 44%。

Conclusion: 通过 LSTM 预测轨迹、Riemannian 扩散生成相位以及基于预测速率的 ON/OFF 选择，本框架在多用户多 RIS 场景下显著提升了信干比。

Abstract: Reconfigurable intelligent surfaces (RISs) offer a low-cost, energy-efficient means for enhancing wireless coverage. Yet, their inherently programmable reflections may unintentionally amplify interference, particularly in large-scale, multi-RIS-enabled mobile communication scenarios where dense user mobility and frequent line-of-sight overlaps can severely degrade the signal-to-interference-plus-noise ratio (SINR). To address this challenge, this paper presents a novel generative multi-RIS control framework that jointly optimizes the ON/OFF activation patterns of multiple RISs in the smart wireless environment and the phase configurations of the activated RISs based on predictions of multi-user trajectories and interference patterns. We specially design a long short-term memory (LSTM) artificial neural network, enriched with speed and heading features, to forecast multi-user trajectories, thereby enabling reconstruction of future channel state information. To overcome the highly nonconvex nature of the multi-RIS control problem, we develop a Riemannian diffusion model on the torus to generate geometry-consistent phase-configuration, where the reverse diffusion process is dynamically guided by reinforcement learning. We then rigorously derive the optimal ON/OFF states of the metasurfaces by comparing predicted achievable rates under RIS activation and deactivation conditions. Extensive simulations demonstrate that the proposed framework achieves up to 30\% SINR improvement over learning-based control and up to 44\% gain compared with the RIS always-on scheme, while consistently outperforming state-of-the-art baselines across different transmit powers, RIS configurations, and interference densities.

</details>


### [98] [DHEA-MECD: An Embodied Intelligence-Powered DRL Algorithm for AUV Tracking in Underwater Environments with High-Dimensional Features](https://arxiv.org/abs/2602.07947)
*Kai Tian,Chuan Lin,Guangjie Han,Chen An,Qian Zhu,Shengzhao Zhu,Zhenyu Wang*

Main category: cs.NI

TL;DR: 利用双头编码和注意力机制提取多模特征，结合阶段适应的多专家决策，DHEA‑MECD在水下多目标跟踪上显著优于传统DRL方法。


<details>
  <summary>Details</summary>
Motivation: 在高维特征、耦合运动状态、空间约束和随机扰动的水下环境中，实现有效的多目标跟踪仍是挑战。

Method: 采用双头编码-注意力信息提取+基于阶段的多专家协同决策与Top‑k专家选择的深度强化学习算法，形成DHEA-MECD多目标跟踪模型。

Result: 实验显示，该方法在主流DRL方法之上，在复杂扰动环境下获得更优跟踪成功率、收敛速度和运动最优性。

Conclusion: 提出的DHEA-MECD框架在复杂水下环境中实现了更高的多目标跟踪成功率、收敛速度更快且运动最优性更好。

Abstract: In recent years, autonomous underwater vehicle (AUV) systems have demonstrated significant potential in complex marine exploration. However, effective AUV-based tracking remains challenging in realistic underwater environments characterized by high-dimensional features, including coupled kinematic states, spatial constraints, time-varying environmental disturbances, etc. To address these challenges, this paper proposes a hierarchical embodied-intelligence (EI) architecture for underwater multi-target tracking with AUVs in complex underwater environments. Built upon this architecture, we introduce the Double-Head Encoder-Attention-based Multi-Expert Collaborative Decision (DHEA-MECD), a novel Deep Reinforcement Learning (DRL) algorithm designed to support efficient and robust multi-target tracking. Specifically, in DHEA-MECD, a Double-Head Encoder-Attention-based information extraction framework is designed to semantically decompose raw sensory observations and explicitly model complex dependencies among heterogeneous features, including spatial configurations, kinematic states, structural constraints, and stochastic perturbations. On this basis, a motion-stage-aware multi-expert collaborative decision mechanism with Top-k expert selection strategy is introduced to support stage-adaptive decision-making. Furthermore, we propose the DHEA-MECD-based underwater multitarget tracking algorithm to enable AUV smart, stable, and anti-interference multi-target tracking. Extensive experimental results demonstrate that the proposed approach achieves superior tracking success rates, faster convergence, and improved motion optimality compared with mainstream DRL-based methods, particularly in complex and disturbance-rich marine environments.

</details>


### [99] [From Raw Data to Shared 3D Semantics: Task-Oriented Communication for Multi-Robot Collaboration](https://arxiv.org/abs/2602.08624)
*Ruibo Xue,Jiedan Tan,Fang Liu,Jingwen Tong,Taotao Wang,Shuoyao Wang*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multi-robot systems (MRS) rely on exchanging raw sensory data to cooperate in complex three-dimensional (3D) environments. However, this strategy often leads to severe communication congestion and high transmission latency, significantly degrading collaboration efficiency. This paper proposes a decentralized task-oriented semantic communication framework for multi-robot collaboration in unknown 3D environments. Each robot locally extracts compact, task-relevant semantics using a lightweight Pixel Difference Network (PiDiNet) with geometric processing. It shares only these semantic updates to build a task-sufficient 3D scene representation that supports cooperative perception, navigation, and object transport. Our numerical results show that the proposed method exhibits a dramatic reduction in communication overhead from $858.6$ Mb to $4.0$ Mb (over $200\times$ compression gain) while improving collaboration efficiency by shortening task completion from $1,054$ to $281$ steps.

</details>


### [100] [Rethinking IPv6 Defense: A Unified Edge-Centric Zero-Trust Data-Plane Architecture](https://arxiv.org/abs/2602.08891)
*Walid Aljoby,Mohammed Alzayani,Md. Kamrul Hossain,Khaled A. Harras*

Main category: cs.NI

TL;DR: 基于P4的单流水线零信任边缘架构，通过先验证身份后检测洪水，实现对IPv6伪装与洪水攻击的统一防御，并在软件与硬件上均验证有效。


<details>
  <summary>Details</summary>
Motivation: IPv6安全与可靠性日益紧密关联，Neighbor Discovery、Router Advertisements和ICMPv6虽必要却易受伪造与洪水攻击，而庞大地址空间导致传统基于IP信誉的防御不可扩展；因此亟需一种统一且可扩展的边缘安全架构。

Method: 实现单一可编程数据平面流水线，整合四个模块：外部伪装、内部伪装、外部洪水、内部洪水。在数据平面中先执行身份可信性过滤，随后基于可信身份统计时间窗口进行洪水检测。
- 采用前缀 Hop‑Limit 分段、DAD 锚定地址‑端口绑定
- 采用 Count‑Min Sketch 进行窗口计数
- 用P4实现，在BMv2与Netronome NFP‑4000 SmartNIC 上验证。

Result: 在15种单向、双向、多向组合场景中实验，展示该流水线能够在保持低延迟的同时，显著减少伪造与洪水攻击带来的误报与漏报；在BMv2原型以及硬件 SmartNIC 上均能实现预期性能。

Conclusion: 提供一种零信任边缘架构，可在IPv6环境下有效检测与抑制伪造与洪水攻击，且兼容现有硬件，具备可扩展性与实用性。

Abstract: IPv6 dependability is increasingly inseparable from IPv6 security: Neighbor Discovery (ND), Router Advertisements (RA), and ICMPv6 are essential for correct operation yet expose a broad attack surface for spoofing and flooding. Meanwhile, IPv6's massive address space breaks per-IP reputation and makes many defenses either non-scalable or narrowly scoped (e.g., only internal threats, only RA abuse, or only volumetric floods). We propose a zero-trust edge architecture implemented in a single programmable data-plane pipeline that unifies four modules: external spoofing, internal spoofing, external flooding, and internal flooding. A key design choice is to enforce identity plausibility before rate plausibility: stateless per-packet validation filters spoofed traffic early so that time-window statistics for flooding operate on credible identities. We outline a concrete P4 design (prefix Hop-Limit bands, DAD-anchored address-port bindings, and Count-Min Sketch windowed counting) and evaluate it across a systematic 15-scenario suite spanning single-, dual-, and multi-vector compositions. We report results from a BMv2 prototype and validate the same pipeline on a Netronome NFP-4000 SmartNIC, and we discuss limitations and open directions.

</details>


### [101] [Performance Evaluation of V2X Communication Using Large-Scale Traffic Data](https://arxiv.org/abs/2602.07244)
*John Pravin Arockiasamy,Alexey Vinel*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Vehicular communication (V2X) technologies are widely regarded as a cornerstone for cooperative and automated driving, yet their large-scale real-world deployment remains limited. As a result, understanding V2X performance under realistic, full-scale traffic conditions continues to be relevant. Most existing performance evaluations rely on synthetic traffic scenarios generated by simulators, which, while useful, may not fully capture the features of real-world traffic. In this paper, we present a large-scale, data-driven evaluation of V2X communication performance using real-world traffic datasets. Vehicle trajectories derived from the Highway Drone (HighD) and Intersection Drone (InD) datasets are converted into simulation-ready formats and coupled with a standardized V2X networking stack to enable message-level performance analysis for entire traffic populations comprising over hundred thousands vehicles across multiple locations. We evaluate key V2X performance indicators, including inter-generation gap, inter-packet gap, packet delivery ratio, and channel busy ratio, across both highway and urban intersection environments. Our results show that cooperative awareness services remain feasible at scale under realistic traffic conditions. In addition, the findings highlight how traffic density, mobility patterns, and communication range influence V2X performance and how synthetic traffic assumptions may overestimate channel congestion.

</details>
