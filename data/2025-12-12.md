<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 41]
- [eess.SY](#eess.SY) [Total: 11]
- [cs.IT](#cs.IT) [Total: 2]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.CR](#cs.CR) [Total: 17]
- [eess.SP](#eess.SP) [Total: 11]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [HGC-Herd: Efficient Heterogeneous Graph Condensation via Representative Node Herding](https://arxiv.org/abs/2512.09947)
*Fuyan Ou,Siqi Ai,Yulin Hu*

Main category: cs.LG

TL;DR: 提出一种训练无关的跨异构图压缩方法HGC-Herd，能够在保持语义与结构保真度的前提下，生成紧凑的异构图以供下游任务使用，并显著降低运行时间和内存开销。


<details>
  <summary>Details</summary>
Motivation: - HGNNs在大规模异构图上的扩展性受制于结构冗余和高维特征。现有图压缩方法（如GCond）多用于同构图，基于梯度匹配，计算、内存和优化开销较大。需一种训练无关、适用于异构图的高效压缩方案。

Method: - HGC-Herd通过轻量级特征传播来编码多跳关系上下文，提升语义信息表达；- 采用类别级的驱动机制(类内为代表节点的“herding”)选取每个类别的代表节点，生成平衡且具判别性的子图集合；- 该过程无需模型训练即可完成压缩，所得子图可用于后续学习任务。

Result: 在ACM、DBLP和Freebase数据集上，压缩后图在保持与全图训练相当甚至更优的准确率的同时，大幅降低了运行时和内存消耗。

Conclusion: 结果表明该方法在高效且可扩展的异构图表示学习方面具有实际应用价值。

Abstract: Heterogeneous graph neural networks (HGNNs) have demonstrated strong capability in modeling complex semantics across multi-type nodes and relations. However, their scalability to large-scale graphs remains challenging due to structural redundancy and high-dimensional node features. Existing graph condensation approaches, such as GCond, are primarily developed for homogeneous graphs and rely on gradient matching, resulting in considerable computational, memory, and optimization overhead. We propose HGC-Herd, a training-free condensation framework that generates compact yet informative heterogeneous graphs while maintaining both semantic and structural fidelity. HGC-Herd integrates lightweight feature propagation to encode multi-hop relational context and employs a class-wise herding mechanism to identify representative nodes per class, producing balanced and discriminative subsets for downstream learning tasks. Extensive experiments on ACM, DBLP, and Freebase validate that HGC-Herd attains comparable or superior accuracy to full-graph training while markedly reducing both runtime and memory consumption. These results underscore its practical value for efficient and scalable heterogeneous graph representation learning.

</details>


### [2] [BAMBO: Construct Ability and Efficiency LLM Pareto Set via Bayesian Adaptive Multi-objective Block-wise Optimization](https://arxiv.org/abs/2512.09972)
*Kesheng Chen,Wenjian Luo,Zhenqian Zhu,Yamin Hu,Yiya Xi*

Main category: cs.LG

TL;DR: 提出 BAMBOO：一种基于贝叶斯的自适应多目标分块优化框架，自动构建大语言模型的 Pareto 前沿，通过分块聚类与动态规划降低维度，并在进化循环中用 qEHVI 获取高效解集，优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的 Pareto 前沿构建方法要么是粗粒度的模型级整合，得到稀疏且次优的解集；要么是粒度太细、逐层搜索，面临维数灾难，计算代价高。需在能力-效率之间的折衷上高效、全面地构建 Pareto 集。

Method: 提出 BAMBOO 框架，核心在于混合最优分块分区（Hybrid Optimal Block Partitioning，HOBP）。将搜索问题建模为一维聚类，通过动态规划在块内同质性与块间信息分布之间实现最优平衡，从而在不牺牲颗粒度的前提下显著降低维度。整个过程在以 q-Expected Hypervolume Improvement（qEHVI）为采集函数的进化循环中自动化执行。

Result: 实验显示 BAMBOO 能发现比基线更优且更完整的帕累托前沿，支持针对不同运营约束的灵活模型选择。

Conclusion: 提供了一种自动化且高效的 LLM Pareto 集构建方法，通过分块聚类降维并维持必要的粒度，从而在能力-效率权衡中实现更优的多目标优化。

Abstract: Constructing a Pareto set is pivotal for navigating the capability-efficiency trade-offs in Large Language Models (LLMs); however, existing merging techniques remain inadequate for this task. Coarse-grained, model-level methods yield only a sparse set of suboptimal solutions, while fine-grained, layer-wise approaches suffer from the "curse of dimensionality," rendering the search space computationally intractable. To resolve this dichotomy, we propose BAMBO (Bayesian Adaptive Multi-objective Block-wise Optimization), a novel framework that automatically constructs the LLM Pareto set. BAMBO renders the search tractable by introducing a Hybrid Optimal Block Partitioning strategy. Formulated as a 1D clustering problem, this strategy leverages a dynamic programming approach to optimally balance intra-block homogeneity and inter-block information distribution, thereby dramatically reducing dimensionality without sacrificing critical granularity. The entire process is automated within an evolutionary loop driven by the q-Expected Hypervolume Improvement (qEHVI) acquisition function. Experiments demonstrate that BAMBO discovers a superior and more comprehensive Pareto frontier than baselines, enabling agile model selection tailored to diverse operational constraints. Code is available at: https://github.com/xin8coder/BAMBO.

</details>


### [3] [Latent Action World Models for Control with Unlabeled Trajectories](https://arxiv.org/abs/2512.10016)
*Marvin Alles,Xingyuan Zhang,Patrick van der Smagt,Philip Becker-Ehmck*

Main category: cs.LG

TL;DR: 提出一个潜在行动（latent-action）世界模型，结合行动有条件和无行动数据，通过学习共享的潜在行动表示来对齐观测到的控制信号与从被动观察中推断的行动，使单一动力学模型即可在大规模未标记轨迹和少量带标签的行动数据上训练，并通过离线强化学习实现潜在行动策略。在 DeepMind Control Suite 上，与纯行动有条件基线相比，使用标注行动的数据样本显著减少一个数量级量级且性能良好。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型通常依赖带行动标签的轨迹，行动标签稀缺时效果受限。希望结合大量无行动数据（如被动观测）与少量带标签的数据，提升数据利用率与学习效率，并探索如何将离线RL与无行动训练结合。

Method: 提出一类潜在行动世界模型，学习共享的潜在行动表示，使观测到的控制信号与被动观测中推断的动作对齐；单一动力学模型在未标记轨迹上大规模训练，同时用少量带标签数据微调。随后通过离线RL在潜在行动空间上学习策略，实现从离线数据到行动自由数据的无缝结合。

Result: 在 DeepMind Control Suite 上，该方法在使用远少于纯行动有条件基线的标注数据情况下，仍实现了强劲的性能表现。

Conclusion: 潜在行动使世界模型能够在被动和交互数据上共同训练，从而提高学习效率和数据利用率，推动行动自由训练与离线RL的融合。

Abstract: Inspired by how humans combine direct interaction with action-free experience (e.g., videos), we study world models that learn from heterogeneous data. Standard world models typically rely on action-conditioned trajectories, which limits effectiveness when action labels are scarce. We introduce a family of latent-action world models that jointly use action-conditioned and action-free data by learning a shared latent action representation. This latent space aligns observed control signals with actions inferred from passive observations, enabling a single dynamics model to train on large-scale unlabeled trajectories while requiring only a small set of action-labeled ones. We use the latent-action world model to learn a latent-action policy through offline reinforcement learning (RL), thereby bridging two traditionally separate domains: offline RL, which typically relies on action-conditioned data, and action-free training, which is rarely used with subsequent RL. On the DeepMind Control Suite, our approach achieves strong performance while using about an order of magnitude fewer action-labeled samples than purely action-conditioned baselines. These results show that latent actions enable training on both passive and interactive data, which makes world models learn more efficiently.

</details>


### [4] [Cluster-Dags as Powerful Background Knowledge For Causal Discovery](https://arxiv.org/abs/2512.10032)
*Jan Marco Ruiz de Vargas,Kirtan Padh,Niki Kilbertus*

Main category: cs.LG

TL;DR: Using Cluster-DAGs as a prior knowledge framework to warm-start causal discovery, introducing Cluster-PC and Cluster-FCI for fully and partially observed settings, which outperform their baselines without prior knowledge on simulated data.


<details>
  <summary>Details</summary>
Motivation: To address challenges in causal discovery under high-dimensional data and complex dependencies by leveraging a flexible prior knowledge structure.

Method: Introduce Cluster-DAGs as a prior framework and develop two modified constraint-based algorithms, Cluster-PC (fully observed) and Cluster-FCI (partially observed) for causal discovery.

Result: On simulated data, Cluster-PC and Cluster-FCI outperform their respective baselines without prior knowledge.

Conclusion: Cluster-DAGs offer greater flexibility than existing tiered background knowledge, and the proposed algorithms improve causal discovery when prior knowledge is available.

Abstract: Finding cause-effect relationships is of key importance in science. Causal discovery aims to recover a graph from data that succinctly describes these cause-effect relationships. However, current methods face several challenges, especially when dealing with high-dimensional data and complex dependencies. Incorporating prior knowledge about the system can aid causal discovery. In this work, we leverage Cluster-DAGs as a prior knowledge framework to warm-start causal discovery. We show that Cluster-DAGs offer greater flexibility than existing approaches based on tiered background knowledge and introduce two modified constraint-based algorithms, Cluster-PC and Cluster-FCI, for causal discovery in the fully and partially observed setting, respectively. Empirical evaluation on simulated data demonstrates that Cluster-PC and Cluster-FCI outperform their respective baselines without prior knowledge.

</details>


### [5] [Robust Gradient Descent via Heavy-Ball Momentum with Predictive Extrapolation](https://arxiv.org/abs/2512.10033)
*Sarwan Ali*

Main category: cs.LG

TL;DR: HB-SGE is a robust first-order optimizer that combines heavy-ball momentum with predictive gradient extrapolation, enabling stable acceleration on ill-conditioned and non-convex problems where NAG and standard momentum can diverge.


<details>
  <summary>Details</summary>
Motivation: Nesterov's Accelerated Gradient (NAG) accelerates well-conditioned problems but often diverges on ill-conditioned or non-convex landscapes due to aggressive momentum accumulation; there is a need for a first-order method that maintains acceleration while ensuring stability across diverse landscapes.

Method: HB-SGE uses heavy-ball momentum together with predictive gradient extrapolation via local Taylor approximations to estimate future gradient directions, providing adaptive acceleration with stability. It maintains O(d) memory overhead and uses the same hyperparameters as standard momentum.

Result: Provides convergence guarantees for strongly convex functions. Empirically, HB-SGE converges on ill-conditioned quadratics with condition number κ=50 in 119 iterations where SGD and NAG diverge. On the non-convex Rosenbrock function, HB-SGE converges in 2,718 iterations while classical momentum methods diverge within 10 steps. NAG remains faster on well-conditioned problems, but HB-SGE offers robust acceleration and speedups over SGD across diverse landscapes.

Conclusion: HB-SGE offers a robust alternative to SGD and classical momentum, delivering stable acceleration on ill-conditioned and non-convex problems with modest memory overhead and no extra hyperparameter tuning, while maintaining competitive performance on well-conditioned problems.

Abstract: Accelerated gradient methods like Nesterov's Accelerated Gradient (NAG) achieve faster convergence on well-conditioned problems but often diverge on ill-conditioned or non-convex landscapes due to aggressive momentum accumulation. We propose Heavy-Ball Synthetic Gradient Extrapolation (HB-SGE), a robust first-order method that combines heavy-ball momentum with predictive gradient extrapolation. Unlike classical momentum methods that accumulate historical gradients, HB-SGE estimates future gradient directions using local Taylor approximations, providing adaptive acceleration while maintaining stability. We prove convergence guarantees for strongly convex functions and demonstrate empirically that HB-SGE prevents divergence on problems where NAG and standard momentum fail. On ill-conditioned quadratics (condition number $κ=50$), HB-SGE converges in 119 iterations while both SGD and NAG diverge. On the non-convex Rosenbrock function, HB-SGE achieves convergence in 2,718 iterations where classical momentum methods diverge within 10 steps. While NAG remains faster on well-conditioned problems, HB-SGE provides a robust alternative with speedup over SGD across diverse landscapes, requiring only $O(d)$ memory overhead and the same hyperparameters as standard momentum.

</details>


### [6] [Intelligently Weighting Multiple Reference Models for Direct Preference Optimization of LLMs](https://arxiv.org/abs/2512.10040)
*Skyler Wu,Aymen Echarghaoui*

Main category: cs.LG

TL;DR: 提出四种对参考模型权重进行离线/在线估计的策略以改进 MRPO，但实验显示单参考 DPO 在多数设置优于多参考 MRPO，质疑多参考方法的实际效用。


<details>
  <summary>Details</summary>
Motivation: 在微调大语言模型以对齐人类偏好时，如何为参考模型权重设定一个统计上稳健且有效的策略仍不清晰。现有 MRPO 的权重设定多为 ad-hoc，缺乏稳健性评估，因此亟需更系统的权重策略以提升偏好对齐性能。

Method: 提出四种 weighting 策略：两种离线方法利用保留（held-out）验证信号，另一种在线方法使用滑动窗口估计以降低过拟合，另一个在线方法将参考权重看作一个 K 臂赌博机问题并使用 Thompson Sampling。实验以 Qwen2.5-0.5B 作为策略模型，七个来自 Llama、Mistral、Qwen、Yi、Phi 家族的参考模型（0.5B-14B）进行对比。

Result: 这四种新策略在 UltraFeedback 和 SafeRLHF 的偏好准确性上均优于现有的 MRPO 权重设定方法。更具启发性的是，单参考 DPO 在使用任意 6/7 个参考时几乎始终优于所有测试中的多参考方法。

Conclusion: 多参考 MRPO 的实际效用受到质疑；在当前实验条件下，单参考 DPO 往往更具可行性，需重新评估参考模型的组合与权重策略，未来工作应聚焦于稳健的单一参考或更系统的多参考权重设计。

Abstract: Fine-tuning is integral for aligning large language models (LLMs) with human preferences. Multiple-Reference Preference Optimization (MRPO) builds on Direct Preference Optimization (DPO) by fine-tuning LLMs on preference datasets while regularizing the policy towards a mixture of reference models to leverage their collective desirable properties. However, current methods for setting the reference weights are ad-hoc and statistically unsound, leading to unreliable performance. To address this, we introduce four new weighting strategies: two offline methods that leverage held-out validation signal; one online method that uses a sliding-window estimator to reduce overfitting; and an online method that treats reference weighting as a $K$-armed bandit via Thompson Sampling. Experiments using Qwen2.5-0.5B as the policy model and seven reference models from the Llama, Mistral, Qwen, Yi, and Phi families (0.5B-14B each) show that all 4 of our strategies outperform the current MRPO weighting methods on UltraFeedback and SafeRLHF in preference accuracy. More thought-provokingly, however, we find that single-reference DPO, using any of 6 out of 7 references, consistently outperforms all tested multiple-reference approaches -- calling into question the practical appeal of multiple-reference approaches.

</details>


### [7] [Local LLM Ensembles for Zero-shot Portuguese Named Entity Recognition](https://arxiv.org/abs/2512.10043)
*João Lucas Luz Lima Sarcinelli,Diego Furtado Silva*

Main category: cs.LG

TL;DR: 提出一个三步本地LLM集合方法用于零样本NER，在5个葡语数据集上超过单模型（4/5），并在跨数据情形展现强泛化潜力。


<details>
  <summary>Details</summary>
Motivation: 解决葡萄牙语等低资源语言的NER性能不足问题，利用本地可部署的开源/开权重LLM，通过集成提升NER能力，同时避免对数据进行大规模微调。

Method: 构建三步集合管线：选择相似能力的本地LLMs、基于启发式的模型组合选择、在极少标注数据下进行无微调的零样本NER，且在不同源数据集上训练/评估以实现跨数据泛化。

Result: 在4/5个葡萄牙NER数据集上优于单一LLM；不同源数据集的集成在跨数据设置中通常优于单模型，减少对目标任务标注数据的依赖。

Conclusion: 提出可扩展、低资源、零样本NER的一种有效三步本地LLM集成策略，且代码开源，利于本地部署与无标注数据情形。

Abstract: Large Language Models (LLMs) excel in many Natural Language Processing (NLP) tasks through in-context learning but often under-perform in Named Entity Recognition (NER), especially for lower-resource languages like Portuguese. While open-weight LLMs enable local deployment, no single model dominates all tasks, motivating ensemble approaches. However, existing LLM ensembles focus on text generation or classification, leaving NER under-explored. In this context, this work proposes a novel three-step ensemble pipeline for zero-shot NER using similarly capable, locally run LLMs. Our method outperforms individual LLMs in four out of five Portuguese NER datasets by leveraging a heuristic to select optimal model combinations with minimal annotated data. Moreover, we show that ensembles obtained on different source datasets generally outperform individual LLMs in cross-dataset configurations, potentially eliminating the need for annotated data for the current task. Our work advances scalable, low-resource, and zero-shot NER by effectively combining multiple small LLMs without fine-tuning. Code is available at https://github.com/Joao-Luz/local-llm-ner-ensemble.

</details>


### [8] [DB2-TransF: All You Need Is Learnable Daubechies Wavelets for Time Series Forecasting](https://arxiv.org/abs/2512.10051)
*Moulik Gupta,Achyut Mani Tripathi*

Main category: cs.LG

TL;DR: 引入可学习Daubechies小波系数层的DB2-TransF，替代自注意力以提升大规模时间序列预测的可扩展性与效率；在13个基准上与Transformer相当/更优，且显著降低内存使用。


<details>
  <summary>Details</summary>
Motivation: Transformer在时间序列预测中对自注意力的二次复杂度限制了在大规模和高维场景中的可扩展性；需要一种能有效捕获多尺度模式与跨序列相关性的高效建模方式。

Method: 提出DB2-TransF，这是一种Transformer启发的架构，将自注意力替换为可学习的Daubechies小波系数层，用于高效地捕捉多尺度本地与全局模式及跨时间序列的相关性。

Result: 在13个标准预测基准上，DB2-TransF实现了与常规Transformer相当或更优的预测精度，同时显著降低了时间序列预测任务的内存开销。

Conclusion: DB2-TransF为高级时间序列预测提供了一种可扩展且资源高效的框架，具备与Transformer竞争的准确性与更低的资源需求。代码可在GitHub获取。

Abstract: Time series forecasting requires models that can efficiently capture complex temporal dependencies, especially in large-scale and high-dimensional settings. While Transformer-based architectures excel at modeling long-range dependencies, their quadratic computational complexity poses limitations on scalability and adaptability. To overcome these challenges, we introduce DB2-TransF, a novel Transformer-inspired architecture that replaces the self-attention mechanism with a learnable Daubechies wavelet coefficient layer. This wavelet-based module efficiently captures multi-scale local and global patterns and enhances the modeling of correlations across multiple time series for the time series forecasting task. Extensive experiments on 13 standard forecasting benchmarks demonstrate that DB2-TransF achieves comparable or superior predictive accuracy to conventional Transformers, while substantially reducing memory usage for the time series forecasting task. The obtained experimental results position DB2-TransF as a scalable and resource-efficient framework for advanced time series forecasting. Our code is available at https://github.com/SteadySurfdom/DB2-TransF

</details>


### [9] [Mitigating Exposure Bias in Risk-Aware Time Series Forecasting with Soft Tokens](https://arxiv.org/abs/2512.10056)
*Alireza Namazi,Amirreza Dolatpour Fathkouhi,Heman Shakeri*

Main category: cs.LG

TL;DR: SoTra introduces Soft-Token Trajectory Forecasting to mitigate exposure bias in autoregressive medical forecasting, enabling uncertainty-aware, risk-minimized predictions; demonstrates 18% reduction in zone-based risk for glucose forecasting and ~15% reduction in effective clinical risk for blood pressure forecasting.


<details>
  <summary>Details</summary>
Motivation: Standard teacher-forcing autoregressive models suffer from exposure bias, leading to unstable multi-step forecasts in safety-critical predictive control settings like diabetes and hemodynamic management. There is a need for calibrated uncertainty-aware trajectory forecasting and risk-aware control to minimize clinical harm.

Method: SoTra propagates continuous probability distributions (soft tokens) to mitigate exposure bias and learn calibrated trajectories. A risk-aware decoding module then minimizes expected clinical harm during forecasting.

Result: In glucose forecasting, SoTra reduces average zone-based risk by 18%; in blood-pressure forecasting, it lowers effective clinical risk by ~15%.

Conclusion: SoTra provides calibrated, uncertainty-aware trajectory forecasting with a risk-aware decoding mechanism, improving safety and applicability of autoregressive predictive control in safety-critical medical contexts.

Abstract: Autoregressive forecasting is central to predictive control in diabetes and hemodynamic management, where different operating zones carry different clinical risks. Standard models trained with teacher forcing suffer from exposure bias, yielding unstable multi-step forecasts for closed-loop use. We introduce Soft-Token Trajectory Forecasting (SoTra), which propagates continuous probability distributions (``soft tokens'') to mitigate exposure bias and learn calibrated, uncertainty-aware trajectories. A risk-aware decoding module then minimizes expected clinical harm. In glucose forecasting, SoTra reduces average zone-based risk by 18\%; in blood-pressure forecasting, it lowers effective clinical risk by approximately 15\%. These improvements support its use in safety-critical predictive control.

</details>


### [10] [MedXAI: A Retrieval-Augmented and Self-Verifying Framework for Knowledge-Guided Medical Image Analysis](https://arxiv.org/abs/2512.10098)
*Midhat Urooj,Ayan Banerjee,Farhat Shaikh,Kuntal Thakur,Sandeep Gupta*

Main category: cs.LG

TL;DR: 一个统一的可解释框架 MedXAI，将临床专家知识与深度视觉模型结合，以提升跨域泛化、缓解稀有病种偏差，并提供局部化的诊断特征解释；在多模态任务（静息态fMRI的发作区定位、糖尿病视网膜病变分级）上经过十个多中心数据集验证，提升跨域泛化约3%、稀有类别F1提升约10%，并通过符号组件作为临床先验提升鲁棒性和解释一致性。


<details>
  <summary>Details</summary>
Motivation: 在医学AI中，模型面对域迁移和稀有病种时往往表现下降，且缺乏可解释性，难以在安全关键的临床环境中部署。现有的后验解释方法（如Saliency、LIME）可能不具临床可理解性或不稳定。需要一个将专家知识融入模型且可解释、鲁棒的框架。

Method: 提出 MedXAI，整合深度视觉模型与基于专家知识的符号组件，作为临床先验和正则化项；通过对诊断特征的局部化来提供解释；实现多模态学习，评估在静息态fMRI的Seizure Onset Zone定位和糖尿病视网膜病变分级两个任务上的性能和解释一致性。

Result: 在十个多中心数据集上，跨域泛化提升约3%，稀有类别的F1提升约10%；比强基线模型具有显著优势；消融实验表明符号组件作为临床先验和正则化器提高了分布外鲁棒性。

Conclusion: MedXAI在临床相关性、可解释性和跨域鲁棒性方面表现优越，尤其在多模态医学AI中的稀有疾病场景，提供了与临床需求对齐的解释。

Abstract: Accurate and interpretable image-based diagnosis remains a fundamental challenge in medical AI, particularly un- der domain shifts and rare-class conditions. Deep learning mod- els often struggle with real-world distribution changes, exhibit bias against infrequent pathologies, and lack the transparency required for deployment in safety-critical clinical environments. We introduce MedXAI (An Explainable Framework for Med- ical Imaging Classification), a unified expert knowledge based framework that integrates deep vision models with clinician- derived expert knowledge to improve generalization, reduce rare- class bias, and provide human-understandable explanations by localizing the relevant diagnostic features rather than relying on technical post-hoc methods (e.g., Saliency Maps, LIME). We evaluate MedXAI across heterogeneous modalities on two challenging tasks: (i) Seizure Onset Zone localization from resting-state fMRI, and (ii) Diabetic Retinopathy grading. Ex periments on ten multicenter datasets show consistent gains, including a 3% improvement in cross-domain generalization and a 10% improvmnet in F1 score of rare class, substantially outperforming strong deep learning baselines. Ablations confirm that the symbolic components act as effective clinical priors and regularizers, improving robustness under distribution shift. MedXAI delivers clinically aligned explanations while achieving superior in-domain and cross-domain performance, particularly for rare diseases in multimodal medical AI.

</details>


### [11] [CHyLL: Learning Continuous Neural Representations of Hybrid Systems](https://arxiv.org/abs/2512.10117)
*Sangli Teng,Hang Liu,Jingyu Song,Koushil Sreenath*

Main category: cs.LG

TL;DR: CHyLL learns a continuous neural representation of hybrid systems in latent space without trajectory segmentation or explicit mode switching, by gluing the state space at guard surfaces via the reset map to form a piecewise smooth quotient manifold where the flow is continuous; it jointly learns a higher-dimensional embedding and the continuous flow, enabling accurate prediction, extraction of topological invariants, and application to stochastic optimal control.


<details>
  <summary>Details</summary>
Motivation: Learning the flows of hybrid systems with both continuous and discrete time dynamics is challenging due to mode switching and discontinuities in the flows; existing methods rely on trajectory segmentation by mode, which struggles with switching and discontinuities.

Method: CHyLL constructs a continuous neural embedding in a latent space using the reset map to glue state space at the guard surface, reformulating the state space as a piecewise smooth quotient manifold; based on embedding theorems, it concurrently learns a singularity-free neural embedding and the continuous flow in the embedding space, avoiding segmentation, event functions, and mode switching.

Result: The approach achieves accurate flow prediction and can identify the topological invariants of hybrid systems; it is also extended to stochastic optimal control problems.

Conclusion: CHyLL provides a unified continuous representation for hybrid systems, enabling accurate flow prediction and topological insights while bypassing explicit mode segmentation and event handling; it demonstrates potential for stochastic control applications.

Abstract: Learning the flows of hybrid systems that have both continuous and discrete time dynamics is challenging. The existing method learns the dynamics in each discrete mode, which suffers from the combination of mode switching and discontinuities in the flows. In this work, we propose CHyLL (Continuous Hybrid System Learning in Latent Space), which learns a continuous neural representation of a hybrid system without trajectory segmentation, event functions, or mode switching. The key insight of CHyLL is that the reset map glues the state space at the guard surface, reformulating the state space as a piecewise smooth quotient manifold where the flow becomes spatially continuous. Building upon these insights and the embedding theorems grounded in differential topology, CHyLL concurrently learns a singularity-free neural embedding in a higher-dimensional space and the continuous flow in it. We showcase that CHyLL can accurately predict the flow of hybrid systems with superior accuracy and identify the topological invariants of the hybrid systems. Finally, we apply CHyLL to the stochastic optimal control problem.

</details>


### [12] [Partitioning the Sample Space for a More Precise Shannon Entropy Estimation](https://arxiv.org/abs/2512.10133)
*Gabriel F. A. Bastos,Jugurta Montalvão*

Main category: cs.LG

TL;DR: 提出一种离散香农熵估计器，通过估计缺失质量与未见结果数量来抵消偏差，在样本不足情况下优于经典估计器，并与前沿方法相当。


<details>
  <summary>Details</summary>
Motivation: 在小数据情境下，样本数可能小于可能输出类别数，传统经验估计往往会产生较大偏差，需要更可靠的无偏或低偏倚的熵估计方法。

Method: 结合可分解性(decomposability)属性，并对缺失质量(missing mass)和未见结果数量(unseen outcomes)进行估计，以补偿由未观测事件引起的负偏差。

Result: 实验结果表明，在欠采样（小样本）条件下，该方法优于部分经典 estimators，且与一些公认的状态‑of‑the‑art estimators相当。

Conclusion: 给出了一种在小数据下更可靠的离散香农熵估计策略，能够有效缓解未观测事件带来的偏差。

Abstract: Reliable data-driven estimation of Shannon entropy from small data sets, where the number of examples is potentially smaller than the number of possible outcomes, is a critical matter in several applications. In this paper, we introduce a discrete entropy estimator, where we use the decomposability property in combination with estimations of the missing mass and the number of unseen outcomes to compensate for the negative bias induced by them. Experimental results show that the proposed method outperforms some classical estimators in undersampled regimes, and performs comparably with some well-established state-of-the-art estimators.

</details>


### [13] [Sequence-to-Image Transformation for Sequence Classification Using Rips Complex Construction and Chaos Game Representation](https://arxiv.org/abs/2512.10141)
*Sarwan Ali,Taslim Murad,Imdadullah Khan*

Main category: cs.LG

TL;DR: 通过CGR将分子序列映射为二维坐标，构建Rips复形提取拓扑特征，形成稳定的图像化表示，并在抗癌肽数据集上实现对乳腺癌和肺癌数据的高准确率。


<details>
  <summary>Details</summary>
Motivation: 解决传统特征工程在稀疏性和计算复杂性上的不足，以及深度学习在表格生物数据上的欠佳表现，提供一种保留信息且可与视觉模型结合的新表征。

Method: 将序列元素映射到二维CGR坐标，计算两两距离，构建Rips复形以捕捉局部结构与全局拓扑，给出表示唯一性、拓扑稳定性和信息保留性的形式保证。

Result: 在抗癌肽数据集的广泛实验中，超过向量化、序列语言模型及现有基于图像的方法，乳腺数据集86.8%，肺癌数据集94.5%的准确率。

Conclusion: 拓扑表征兼容视觉深度学习架构，保持关键序列信息，提升分子序列分析的效果。

Abstract: Traditional feature engineering approaches for molecular sequence classification suffer from sparsity issues and computational complexity, while deep learning models often underperform on tabular biological data. This paper introduces a novel topological approach that transforms molecular sequences into images by combining Chaos Game Representation (CGR) with Rips complex construction from algebraic topology. Our method maps sequence elements to 2D coordinates via CGR, computes pairwise distances, and constructs Rips complexes to capture both local structural and global topological features. We provide formal guarantees on representation uniqueness, topological stability, and information preservation. Extensive experiments on anticancer peptide datasets demonstrate superior performance over vector-based, sequence language models, and existing image-based methods, achieving 86.8\% and 94.5\% accuracy on breast and lung cancer datasets, respectively. The topological representation preserves critical sequence information while enabling effective utilization of vision-based deep learning architectures for molecular sequence analysis.

</details>


### [14] [Murmur2Vec: A Hashing Based Solution For Embedding Generation Of COVID-19 Spike Sequences](https://arxiv.org/abs/2512.10147)
*Sarwan Ali,Taslim Murad*

Main category: cs.LG

TL;DR: 提出一种基于哈希的低维嵌入来表示刺突蛋白序列，用于大规模SARS-CoV-2谱系分类，显著提升效率和保持较高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有树状法难以扩展到多百万序列的数据集；现有嵌入法要么需要对齐、要么预测性能和运行成本不足以支撑大规模分析。为实现对 spike 区域的快速、可扩展的谱系分类，需要新的嵌入策略。

Method: 聚焦最常见的几个SARS-CoV-2谱系的 spike 区域，提出基于哈希的紧凑表示，并用多种机器学习模型进行有监督的谱系分类。与基线和前沿嵌入方法在多项指标上进行广泛比较。

Result: 嵌入生成时间可降低多达99.81%，分类准确率最高可达86.4%，在效率和性能之间实现显著折衷。

Conclusion: 该方法为大规模病毒序列分析提供快速、有效、可扩展的解决方案，适合大规模谱系监测与公共卫生应用。

Abstract: Early detection and characterization of coronavirus disease (COVID-19), caused by SARS-CoV-2, remain critical for effective clinical response and public-health planning. The global availability of large-scale viral sequence data presents significant opportunities for computational analysis; however, existing approaches face notable limitations. Phylogenetic tree-based methods are computationally intensive and do not scale efficiently to today's multi-million-sequence datasets. Similarly, current embedding-based techniques often rely on aligned sequences or exhibit suboptimal predictive performance and high runtime costs, creating barriers to practical large-scale analysis. In this study, we focus on the most prevalent SARS-CoV-2 lineages associated with the spike protein region and introduce a scalable embedding method that leverages hashing to generate compact, low-dimensional representations of spike sequences. These embeddings are subsequently used to train a variety of machine learning models for supervised lineage classification. We conduct an extensive evaluation comparing our approach with multiple baseline and state-of-the-art biological sequence embedding methods across diverse metrics. Our results demonstrate that the proposed embeddings offer substantial improvements in efficiency, achieving up to 86.4\% classification accuracy while reducing embedding generation time by as much as 99.81\%. This highlights the method's potential as a fast, effective, and scalable solution for large-scale viral sequence analysis.

</details>


### [15] [CIEGAD: Cluster-Conditioned Interpolative and Extrapolative Framework for Geometry-Aware and Domain-Aligned Data Augmentation](https://arxiv.org/abs/2512.10178)
*Keito Inoshita,Xiaokang Zhou,Akira Kawai,Katsutoshi Yada*

Main category: cs.LG

TL;DR: CIEGAD is a cluster-conditioned interpolative/extrapolative data augmentation framework that uses cluster-based domain profiles, a hierarchical frequency-geometric allocation scheme, and interpolative/extrapolative synthesis with geometry-constrained filtering and an LLM-based judge to expand the peripheral regions of real-world data while maintaining alignment, diversity, and quality, yielding improved F1/recall on long-tailed and multi-class tasks.


<details>
  <summary>Details</summary>
Motivation: In practical deep learning deployment, data scarcity and label imbalance create semantically uncovered regions in real-world distributions, causing misclassification near class boundaries and unstable behavior in peripheral areas. Although LLMs show promise for data augmentation, there is no integrated framework that simultaneously provides directional control of generation, domain alignment, and quality control.

Method: CIEGAD constructs domain profiles via cluster conditioning, employs a hierarchical frequency-geometric allocation that blends class frequency and geometric indicators to allocate generation, enables both interpolative (within-domain) and extrapolative (toward distribution periphery) synthesis for controlled directionality, and applies geometry-constrained filtering together with an LLM-as-a-Judge mechanism for quality control.

Result: Experiments across multiple classification tasks show that CIEGAD expands the semantically uncovered peripheral regions while preserving alignment with real data and maintaining semantic diversity. In long-tailed and multi-class settings, it consistently improves F1 and recall, demonstrating distributional consistency, diversity, and quality.

Conclusion: CIEGAD provides a practically oriented data augmentation framework that complements underrepresented regions in real-world distributions without sacrificing alignment, enabling more robust performance in diverse classification scenarios.

Abstract: In practical deep learning deployment, the scarcity of data and the imbalance of label distributions often lead to semantically uncovered regions within the real-world data distribution, hindering model training and causing misclassification near class boundaries as well as unstable behaviors in peripheral areas. Although recent large language models (LLMs) show promise for data augmentation, an integrated framework that simultaneously achieves directional control of generation, domain alignment, and quality control has not yet been fully established. To address these challenges, we propose a Cluster-conditioned Interpolative and Extrapolative framework for Geometry-Aware and Domain-aligned data augmentation (CIEGAD), which systematically complements both in-distribution and out-of-distribution semantically uncovered regions. CIEGAD constructs domain profiles through cluster conditioning, allocates generation with a hierarchical frequency-geometric allocation integrating class frequency and geometric indicators, and finely controls generation directions via the coexistence of interpolative and extrapolative synthesis. It further performs quality control through geometry-constrained filtering combined with an LLM-as-a-Judge mechanism. Experiments on multiple classification tasks demonstrate that CIEGAD effectively extends the periphery of real-world data distributions while maintaining high alignment between generated and real-world data as well as semantic diversity. In particular, for long-tailed and multi-class classification tasks, CIEGAD consistently improves F1 and recall, validating the triple harmony of distributional consistency, diversity, and quality. These results indicate that CIEGAD serves as a practically oriented data augmentation framework that complements underrepresented regions while preserving alignment with real-world data.

</details>


### [16] [MiniF2F-Dafny: LLM-Guided Mathematical Theorem Proving via Auto-Active Verification](https://arxiv.org/abs/2512.10187)
*Mantas Baksys,Stefan Zetzsche,Olivier Bouissou*

Main category: cs.LG

TL;DR: 首次将 miniF2F 数学推理基准转译为 Dafny 自动定理证明器，展示了自动化与大语言模型的协同潜力。


<details>
  <summary>Details</summary>
Motivation: 探索将数学推理基准从互动定理证明器扩展到自动定理证明器的可行性，以评估 Dafny 的自动化水平及与 LLM 的协同边界。

Method: 将 miniF2F 译本提交给 Dafny 自动证明，统计通过率；对无法用空证明完成的问题，评估12个现成的 LLM 提供证明提示，结合迭代错误纠正提升通过率。

Result: Dafny 自动化在测试集 99/244（40.6%）和验证集 109/244（44.7%）实现空证明通过；对于空证明失败的问题，12 个 LLM 的最佳模型在迭代纠错下实现 55.7% 的 pass@4；报告了人机分工的有效性：LLMs 提供高层次指导，自动化处理低层次细节。

Conclusion: 该基准可为评估自动证明器与提示工程的协同提供基线，GitHub 上的实现可供复现与扩展。

Abstract: We present miniF2F-Dafny, the first translation of the mathematical reasoning benchmark miniF2F to an automated theorem prover: Dafny. Previously, the benchmark existed only in interactive theorem provers (Lean, Isabelle, HOL Light, Metamath). We find that Dafny's automation verifies 99/244 (40.6%) of the test set and 109/244 (44.7%) of the validation set with empty proofs--requiring no manual proof steps. For problems where empty proofs fail, we evaluate 12 off-the-shelf LLMs on providing proof hints. The best model we test achieves 55.7% pass@4 success rate employing iterative error correction. These preliminary results highlight an effective division of labor: LLMs provide high-level guidance while automation handles low-level details. Our benchmark can be found on GitHub at http://github.com/dafny-lang/miniF2F .

</details>


### [17] [Federated Domain Generalization with Latent Space Inversion](https://arxiv.org/abs/2512.10224)
*Ragja Palakkadavath,Hung Le,Thanh Nguyen-Tang,Svetha Venkatesh,Sunil Gupta*

Main category: cs.LG

TL;DR: FedDG framework with privacy-aware training and aggregation: latent space inversion for domain-invariant local learning and important weight aggregation to preserve local adaptation, achieving better generalization to unseen clients with less communication.


<details>
  <summary>Details</summary>
Motivation: Federated domain generalization must handle distribution shifts across clients while preserving data privacy. Existing FedDG methods often share statistics or model updates that can leak information; a privacy-preserving approach with efficient communication is desirable.

Method: Proposes latent space inversion to enforce domain invariance during local training, reducing private information leakage. Introduces important weight aggregation to emphasize parameters that significantly influence local predictions, mitigating loss of local adaptation when client data are non-i.i.d. The framework aggregates locally trained models with privacy-aware techniques to form a global model.

Result: Extensive experiments show superior performance compared to state-of-the-art FedDG methods and lower communication overhead.

Conclusion: The approach improves generalization to unseen clients and preserves privacy while reducing communication, offering a practical and effective FedDG solution.

Abstract: Federated domain generalization (FedDG) addresses distribution shifts among clients in a federated learning framework. FedDG methods aggregate the parameters of locally trained client models to form a global model that generalizes to unseen clients while preserving data privacy. While improving the generalization capability of the global model, many existing approaches in FedDG jeopardize privacy by sharing statistics of client data between themselves. Our solution addresses this problem by contributing new ways to perform local client training and model aggregation. To improve local client training, we enforce (domain) invariance across local models with the help of a novel technique, \textbf{latent space inversion}, which enables better client privacy. When clients are not \emph{i.i.d}, aggregating their local models may discard certain local adaptations. To overcome this, we propose an \textbf{important weight} aggregation strategy to prioritize parameters that significantly influence predictions of local models during aggregation. Our extensive experiments show that our approach achieves superior results over state-of-the-art methods with less communication overhead.

</details>


### [18] [Adaptive Information Routing for Multimodal Time Series Forecasting](https://arxiv.org/abs/2512.10229)
*Jun Seo,Hyeokjun Choe,Seohui Bae,Soyeon Park,Wonbin Ahn,Taeyoon Lim,Junhyuk Kang,Sangjun Han,Jaehoon Lee,Dongwan Kang,Minjae Kim,Sungdong Yoo,Soonyoung Lee*

Main category: cs.LG

TL;DR: 提出 Adaptive Information Routing (AIR) 框架，用文本信息动态引导时序模型在多模态时间序列预测中进行信息路由与融合；并结合文本精炼管线与基准数据集，实证表明在真实市场数据上提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中仅靠历史时间序列信息往往不足以获得高质量预测，需要引入文本等模态信息来增强预测能力；传统多模态方法将文本与时间序列同等对待，缺乏对信息如何被融合和路由的可控性。

Method: 提出 AIR 框架，通过可学习的路由机制基于文本信息动态决定多变量时间序列信息的融合方式与权重；构建文本精炼流水线，利用大语言模型将原始文本转换为适用于多模态预测的表示；提供一个支持多模态 forecasting 研究的基准数据集。

Result: 在真实世界市场数据（如原油价格、汇率）上，AIR 能通过文本信息调控时序模型行为，显著提升多种时间序列预测任务的准确度。

Conclusion: AIR 为多模态时序预测引入可控的信息路由机制，有效利用文本信息的引导作用，提升模型的灵活性和预测性能，并为未来的多模态时间序列研究提供可扩展的框架。

Abstract: Time series forecasting is a critical task for artificial intelligence with numerous real-world applications. Traditional approaches primarily rely on historical time series data to predict the future values. However, in practical scenarios, this is often insufficient for accurate predictions due to the limited information available. To address this challenge, multimodal time series forecasting methods which incorporate additional data modalities, mainly text data, alongside time series data have been explored. In this work, we introduce the Adaptive Information Routing (AIR) framework, a novel approach for multimodal time series forecasting. Unlike existing methods that treat text data on par with time series data as interchangeable auxiliary features for forecasting, AIR leverages text information to dynamically guide the time series model by controlling how and to what extent multivariate time series information should be combined. We also present a text-refinement pipeline that employs a large language model to convert raw text data into a form suitable for multimodal forecasting, and we introduce a benchmark that facilitates multimodal forecasting experiments based on this pipeline. Experiment results with the real world market data such as crude oil price and exchange rates demonstrate that AIR effectively modulates the behavior of the time series model using textual inputs, significantly enhancing forecasting accuracy in various time series forecasting tasks.

</details>


### [19] [R^2-HGP: A Double-Regularized Gaussian Process for Heterogeneous Transfer Learning](https://arxiv.org/abs/2512.10258)
*Duo Wang,Xinming Wang,Chao Wang,Xiaowei Yue,Jianguo Wu*

Main category: cs.LG

TL;DR: 提出一种双正则化异构高斯过程（R^2-HGP）框架，用于多源转移学习。通过可训练的先验映射对异质输入进行对齐，将对齐后的输入作为潜变量，构建多源转移 GP，并在CVAE框架中整合；引入物理知识正则化以约束对齐，并对传输系数进行稀疏惩罚以抑制负迁移。通过大量仿真和工程案例验证其在多源转移学习中的有效性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决源/目标域输入空间异质性、在异构转移中未充分利用先验知识/物理信息、以及信息共享不当导致的负迁移，这是传统多输出高斯过程在迁移学习中的关键挑战。需要一个统一框架来同时解决这三类问题。

Method: 1) 提出可训练的先验概率映射模型以对齐异质输入域；2) 将对齐后的输入视为潜变量，构建多源转移高斯过程；3) 将整个结构集成到基于条件变分自编码器（CVAE）的框架中；4) 将物理洞见作为正则化项纳入，以确保对齐符合物理知识；5) 在多源转移GP模型中对传输系数施加稀疏惩罚，以自适应选择最有信息的源输出并抑制负迁移。

Result: 通过大量仿真和实际工程案例研究，R^2-HGP在多源转移学习场景中表现出对比基准的显著优势，在多种评估指标上实现一致的改进。

Conclusion: R^2-HGP提供了一个统一的框架，能够解决输入异质性、先验/物理信息融入以及负迁移等核心问题。实验结果表明该方法相较于最先进基线具备稳定且显著的性能提升，且具备较好的泛化与可解释性潜力。

Abstract: Multi-output Gaussian process (MGP) models have attracted significant attention for their flexibility and uncertainty-quantification capabilities, and have been widely adopted in multi-source transfer learning scenarios due to their ability to capture inter-task correlations. However, they still face several challenges in transfer learning. First, the input spaces of the source and target domains are often heterogeneous, which makes direct knowledge transfer difficult. Second, potential prior knowledge and physical information are typically ignored during heterogeneous transfer, hampering the utilization of domain-specific insights and leading to unstable mappings. Third, inappropriate information sharing among target and sources can easily lead to negative transfer. Traditional models fail to address these issues in a unified way. To overcome these limitations, this paper proposes a Double-Regularized Heterogeneous Gaussian Process framework (R^2-HGP). Specifically, a trainable prior probability mapping model is first proposed to align the heterogeneous input domains. The resulting aligned inputs are treated as latent variables, upon which a multi-source transfer GP model is constructed and the entire structure is integrated into a novel conditional variational autoencoder (CVAE) based framework. Physical insights is further incorporated as a regularization term to ensure that the alignment results adhere to known physical knowledge. Next, within the multi-source transfer GP model, a sparsity penalty is imposed on the transfer coefficients, enabling the model to adaptively select the most informative source outputs and suppress negative transfer. Extensive simulations and real-world engineering case studies validate the effectiveness of our R^2-HGP, demonstrating consistent superiority over state-of-the-art benchmarks across diverse evaluation metrics.

</details>


### [20] [An Interpretable AI Tool for SAVR vs TAVR in Low to Intermediate Risk Patients with Severe Aortic Stenosis](https://arxiv.org/abs/2512.10308)
*Vasiliki Stoumpou,Maciej Tysarowski,Talhat Azemi,Jawad Haider,Howard L. Haronian,Robert C. Hagberg,Dimitris Bertsimas*

Main category: cs.LG

TL;DR: 提出一个可解释的处方框架，用 prognostic matching、counterfactual 预测与最优策略树（OPT）在 SAVR 与 TAVR 之间为低至中等风险患者给出长期（5 年）结局的个体化治疗建议，评估显示若按 OPT 处方，5 年死亡率相对真实处方下降显著，具跨机构泛化潜力。


<details>
  <summary>Details</summary>
Motivation: 当前仅有预测个体风险的模型，缺乏直接优化长期结局、且具有可解释性的个体化治疗推荐；本研究旨在提供透明且数据驱动的 TAVR/SAVR 选择策略，以实现长期生存获益。

Method: 在 Hartford Hospital 与 St. Vincent's Hospital 的数据上，利用 prognostic matching 和样本加权来近似随机化，并估计在 SAVR 与 TAVR 下的反事实死亡率。随后以反事实预测训练 Optimal Policy Tree，输出将患者分区并给出降低长期死亡风险的治疗选择。

Result: OPT 处方应用后， Hartford 数据集相对真实处方的 5 年死亡率下降约 20.3%； St. Vincent's 数据集下降约 13.8%。结果与外部数据的一致性提示模型具备一定的泛化能力。

Conclusion: 该分析框架首次在 TAVR 与 SAVR 的比较中提供透明、数据驱动的长期结局优化建议，具有跨机构适用性并有助于结构心脏病的精准医疗实践。

Abstract: Background. Treatment selection for low to intermediate risk patients with severe aortic stenosis between surgical (SAVR) and transcatheter (TAVR) aortic valve replacement remains variable in clinical practice, driven by patient heterogeneity and institutional preferences. While existing models predict postprocedural risk, there is a lack of interpretable, individualized treatment recommendations that directly optimize long-term outcomes.
  Methods. We introduce an interpretable prescriptive framework that integrates prognostic matching, counterfactual outcome modeling, and an Optimal Policy Tree (OPT) to recommend the treatment minimizing expected 5-year mortality. Using data from Hartford Hospital and St. Vincent's Hospital, we emulate randomization via prognostic matching and sample weighting and estimate counterfactual mortality under both SAVR and TAVR. The policy model, trained on these counterfactual predictions, partitions patients into clinically coherent subgroups and prescribes the treatment associated with lower estimated risk.
  Findings. If the OPT prescriptions are applied, counterfactual evaluation showed an estimated reduction in 5-year mortality of 20.3\% in Hartford and 13.8\% in St. Vincent's relative to real-life prescriptions, showing promising generalizability to unseen data from a different institution. The learned decision boundaries aligned with real-world outcomes and clinical observations.
  Interpretation. Our interpretable prescriptive framework is, to the best of our knowledge, the first to provide transparent, data-driven recommendations for TAVR versus SAVR that improve estimated long-term outcomes both in an internal and external cohort, while remaining clinically grounded and contributing toward a more systematic and evidence-based approach to precision medicine in structural heart disease.

</details>


### [21] [A Privacy-Preserving Cloud Architecture for Distributed Machine Learning at Scale](https://arxiv.org/abs/2512.10341)
*Vinoth Punniyamoorthy,Ashok Gadi Parthi,Mayilsamy Palanigounder,Ravi Kiran Kodali,Bikesh Kumar,Kabilan Kannan*

Main category: cs.LG

TL;DR: 云原生隐私保护架构，融合联邦学习、差分隐私、零知识合规证明与强化学习驱动的自适应治理，在混合Kubernetes环境下实现安全训练/推理、可验证的策略执行，以及低开销的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在分布式机器学习场景中，需要强隐私保护、可验证的合规性以及跨多云/混合云环境的可扩展部署，避免集中化数据并提升治理能力。

Method: 将联邦学习、差分隐私、零知识证明用于合规性证明，以及基于强化学习的自适应治理结合云原生架构，开发一个可在混合Kubernetes集群中部署的原型，实现安全训练与推理、无需集中数据、并提供可密码学验证的策略强制执行。

Result: 原型展示了对成员身份推断风险的降低、隐私预算的一致强制执行、在差分隐私约束下模型性能的稳定，以及多机构工作负载下的实用性和低开销；实验表明在持续的风险感知治理下，工具具备良好可扩展性与稳定性。

Conclusion: 该框架为在大规模、可信任且合规的分布式机器学习系统部署提供了一个切实可行的基础，促进跨机构与多云环境中的隐私保护与治理能力。

Abstract: Distributed machine learning systems require strong privacy guarantees, verifiable compliance, and scalable deploy- ment across heterogeneous and multi-cloud environments. This work introduces a cloud-native privacy-preserving architecture that integrates federated learning, differential privacy, zero- knowledge compliance proofs, and adaptive governance powered by reinforcement learning. The framework supports secure model training and inference without centralizing sensitive data, while enabling cryptographically verifiable policy enforcement across institutions and cloud platforms. A full prototype deployed across hybrid Kubernetes clusters demonstrates reduced membership- inference risk, consistent enforcement of formal privacy budgets, and stable model performance under differential privacy. Ex- perimental evaluation across multi-institution workloads shows that the architecture maintains utility with minimal overhead while providing continuous, risk-aware governance. The pro- posed framework establishes a practical foundation for deploying trustworthy and compliant distributed machine learning systems at scale.

</details>


### [22] [GPG: Generalized Policy Gradient Theorem for Transformer-based Policies](https://arxiv.org/abs/2512.10365)
*Hangyu Mao,Guangting Dong,Zhicheng Dou*

Main category: cs.LG

TL;DR: Generalized Policy Gradient (GPG) 作为面向 Transformer 策略的统一梯度框架，表明标准 Policy Gradient Theorem 与 GRPO 已作为特例包含其中，并探讨其在训练大型语言模型（LLMs）中的实际应用与效率提升的潜力。


<details>
  <summary>Details</summary>
Motivation: 为 Transformer 基础的策略提供一个统一且可扩展的梯度优化理论框架，将现有的 Policy Gradient 与 GRPO 统一在 GPG 下，并为在 LLM 训练中实现更高效的策略优化提供理论支撑。

Method: 推导并建立 GPG 定理，使其在 Transformer 策略下成立；证明标准 Policy Gradient Theorem 与 GRPO 两者可以从 GPG 推导出成为特例；讨论将 GPG 应用于 LLM 训练中的具体做法与优化路径，强调理论与实践的结合。

Result: 从理论层面实现了对标准 PG 和 GRPO 的统一：两者在 GPG 框架下为同一梯度优化体系的特例；在实践层面揭示了将 GPG 应用于 Transformer/LLM 策略优化的潜在优势与应用场景，提供对高效策略优化的新见解。

Conclusion: GPG 为 Transformer 基础的策略优化提供了一个统一的、可扩展的理论框架，能够将标准策略梯度和 GRPO 以及未来的梯度方法纳入同一体系，推动在 LLM 训练中的更高效、系统化的策略优化与实践。

Abstract: We present the Generalized Policy Gradient (GPG) Theorem, specifically designed for Transformer-based policies. Notably, we demonstrate that both standard Policy Gradient Theorem and GRPO emerge as special cases within our GPG framework. Furthermore, we explore its practical applications in training Large Language Models (LLMs), offering new insights into efficient policy optimization.

</details>


### [23] [Fitting magnetization data using continued fraction of straight lines](https://arxiv.org/abs/2512.10390)
*Vijay Prakash S*

Main category: cs.LG

TL;DR: 用继续分数（continued fraction）近似 ferromagnetic M(H) 的非线性响应，并通过非线性回归估计模型参数；该方法解释域的生长与收缩对磁化曲线的影响。


<details>
  <summary>Details</summary>
Motivation: 磁化强度对外加磁场呈现非线性，传统模型难以灵活拟合实验数据。用直线的继续分数作为代数表达式，提供一种可解析且可用于参数估计的拟合工具。

Method: 将非线性函数近似为直线的继续分数形式，使用非线性回归拟合磁化强度与磁场的关系；通过拟合参数解释磁域的生长与收缩过程。

Result: 所得到的拟合能捕捉非线性特征，并提供可解的参数，便于解释域的演化；继续分数提供了一个代数可用的表达式，便于参数估计。

Conclusion: 直线继续分数是建模铁磁材料非线性磁化响应的可行工具，能够提供域动力学参数并具有计算上的便利。

Abstract: Magnetization of a ferromagnetic substance in response to an externally applied magnetic field increases with the strength of the field. This is because at the microscopic level, magnetic moments in certain regions or domains of the substance increasingly align with the applied field, while the amount of misaligned domains decreases. The alignment of such magnetic domains with an applied magnetic field forms the physical basis for the nonlinearity of magnetization. In this paper, the nonlinear function is approximated as a combination of continued fraction of straight lines. The resulting fit is used to interpret the nonlinear behavior in both growing and shrinking magnetic domains. The continued fraction of straight lines used here is an algebraic expression which can be used to estimate parameters using nonlinear regression.

</details>


### [24] [UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning](https://arxiv.org/abs/2512.10492)
*Jiaxi Wu,Tiantian Zhang,Yuxing Wang,Yongzhe Chang,Xueqian Wang*

Main category: cs.LG

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Robust adversarial reinforcement learning has emerged as an effective paradigm for training agents to handle uncertain disturbance in real environments, with critical applications in sequential decision-making domains such as autonomous driving and robotic control. Within this paradigm, agent training is typically formulated as a zero-sum Markov game between a protagonist and an adversary to enhance policy robustness. However, the trainable nature of the adversary inevitably induces non-stationarity in the learning dynamics, leading to exacerbated training instability and convergence difficulties, particularly in high-dimensional complex environments. In this paper, we propose a novel approach, Uncertainty-Aware Critic Ensemble for robust adversarial Reinforcement learning (UACER), which consists of two strategies: 1) Diversified critic ensemble: a diverse set of K critic networks is exploited in parallel to stabilize Q-value estimation rather than conventional single-critic architectures for both variance reduction and robustness enhancement. 2) Time-varying Decay Uncertainty (TDU) mechanism: advancing beyond simple linear combinations, we develop a variance-derived Q-value aggregation strategy that explicitly incorporates epistemic uncertainty to dynamically regulate the exploration-exploitation trade-off while simultaneously stabilizing the training process. Comprehensive experiments across several MuJoCo control problems validate the superior effectiveness of UACER, outperforming state-of-the-art methods in terms of overall performance, stability, and efficiency.

</details>


### [25] [Adaptive Replay Buffer for Offline-to-Online Reinforcement Learning](https://arxiv.org/abs/2512.10510)
*Chihyeon Song,Jaewoo Lee,Jinkyoo Park*

Main category: cs.LG

TL;DR: 提出了 Adaptive Replay Buffer (ARB)，通过对每条轨迹内的转移赋予基于“on-policyness”的采样权重，实现对离线数据的自适应利用。ARB 是学习无关、实现简单的缓冲区设计，能够无缝嵌入现有的 O2O RL 算法中，以提升早期稳定性并改善最终性能。


<details>
  <summary>Details</summary>
Motivation: 离线数据集固定与在线新经验之间的权衡是 O2O RL 的核心挑战。固定的数据混合比例在早期学习稳定性与渐近性能之间难以兼顾；需要一种无需复杂学习过程、可学习性低且能自适应调整数据利用的策略。

Method: ARB 通过一个轻量度量“on-policyness”来评估 collected trajectories 与当前策略行为的一致性，并据此为轨迹中每个转移分配比例采样权重，从而实现对 offline 和 online 数据的自适应利用。该方法为学习无关、易于实现的缓冲区设计，能够无缝融入现有的 O2O RL 算法。

Result: 在 D4RL 基准实验中，ARB 稳定缓解了早期性能下降，并显著提升了多种 O2O RL 算法的最终性能，表明自适应、基于行为的回放缓冲设计具有重要意义和实用性。

Conclusion: 强调了以行为为导向的自适应回放缓冲在 O2O RL 中的作用，ARB 的学习无关特性使其易于普遍采用，具备提升早期稳定性与最终表现的潜力。

Abstract: Offline-to-Online Reinforcement Learning (O2O RL) faces a critical dilemma in balancing the use of a fixed offline dataset with newly collected online experiences. Standard methods, often relying on a fixed data-mixing ratio, struggle to manage the trade-off between early learning stability and asymptotic performance. To overcome this, we introduce the Adaptive Replay Buffer (ARB), a novel approach that dynamically prioritizes data sampling based on a lightweight metric we call 'on-policyness'. Unlike prior methods that rely on complex learning procedures or fixed ratios, ARB is designed to be learning-free and simple to implement, seamlessly integrating into existing O2O RL algorithms. It assesses how closely collected trajectories align with the current policy's behavior and assigns a proportional sampling weight to each transition within that trajectory. This strategy effectively leverages offline data for initial stability while progressively focusing learning on the most relevant, high-rewarding online experiences. Our extensive experiments on D4RL benchmarks demonstrate that ARB consistently mitigates early performance degradation and significantly improves the final performance of various O2O RL algorithms, highlighting the importance of an adaptive, behavior-aware replay buffer design.

</details>


### [26] [Disentangled and Distilled Encoder for Out-of-Distribution Reasoning with Rademacher Guarantees](https://arxiv.org/abs/2512.10522)
*Zahra Rahiminasab,Michael Yuhas,Arvind Easwaran*

Main category: cs.LG

TL;DR: 提出 disentangled distilled encoder (DDE) 框架，通过学生-教师蒸馏在压缩模型的同时保持潜在空间的解耦性，并给出基于 Rademacher 复杂度的理论保证，用于资源受限设备上的多标签 OOD 推理。


<details>
  <summary>Details</summary>
Motivation: 解决在资源受限设备上对解耦潜在空间进行蒸馏以保持多标签 OOD 推理能力的问题，同时保持潜在因子的可解释性。

Method: 将蒸馏问题建模为带解耦约束的受限优化；结合变分自编码器（VAE）的潜在空间和解耦因子；引入解耦性约束；给出基于 Rademacher 复杂度的理论保证。

Result: 理论上提供对解耦性的保持保证；在实际部署（如在 NVIDIA 端）对压缩模型进行评估，验证压缩后的 DDE 能维持解耦性并保持对多标签 OOD 推理的能力。

Conclusion: DDE 为资源受限设备上的高效、可解释的多标签 OOD 推理提供了一个结合蒸馏与解耦约束的有效框架，相较于传统蒸馏在保持解耦性方面具有优势。

Abstract: Recently, the disentangled latent space of a variational autoencoder (VAE) has been used to reason about multi-label out-of-distribution (OOD) test samples that are derived from different distributions than training samples. Disentangled latent space means having one-to-many maps between latent dimensions and generative factors or important characteristics of an image. This paper proposes a disentangled distilled encoder (DDE) framework to decrease the OOD reasoner size for deployment on resource-constrained devices while preserving disentanglement. DDE formalizes student-teacher distillation for model compression as a constrained optimization problem while preserving disentanglement with disentanglement constraints. Theoretical guarantees for disentanglement during distillation based on Rademacher complexity are established. The approach is evaluated empirically by deploying the compressed model on an NVIDIA

</details>


### [27] [Mode-Seeking for Inverse Problems with Diffusion Models](https://arxiv.org/abs/2512.10524)
*Sai Bharath Chandra Gutha,Ricardo Vinuesa,Hossein Azizpour*

Main category: cs.LG

TL;DR: 引入变分模式搜索损失（VML），在每个去扩散步骤中引导采样向最大后验估计（MAP）收敛。对线性逆问题，VML可解析推导；基于VML，提出VML-MAP算法，在多数据集的图像重建任务中在性能和计算时间上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于扩散模型的逆问题方法在后验采样与MAP估计中对建模近似的依赖以及高计算成本，寻求一个理论上更稳健且高效的优化框架。

Method: 从扩散后验p(x0|xt)与测量后验p(x0|y)之间的KL散度出发，推导出VML并在每一步的逆扩散中最小化，指引样本朝向MAP。对于线性逆问题，VML可解析推导，无需近似。进一步提出VMMAP算法，将VML应用于实际逆问题求解并提高效率。

Result: 通过大量图像去噪/修复等逆问题的实验，VML-VMAP在性能和计算时间上优于现有的后验采样/MAP方法，具有较强的普适性与实用性。

Conclusion: VML为利用无条件扩散模型解决逆问题提供了一个有理论支撑且高效的框架，VML-MAP在多种数据集上展现出良好的实用性。

Abstract: A pre-trained unconditional diffusion model, combined with posterior sampling or maximum a posteriori (MAP) estimation techniques, can solve arbitrary inverse problems without task-specific training or fine-tuning. However, existing posterior sampling and MAP estimation methods often rely on modeling approximations and can be computationally demanding. In this work, we propose the variational mode-seeking loss (VML), which, when minimized during each reverse diffusion step, guides the generated sample towards the MAP estimate. VML arises from a novel perspective of minimizing the Kullback-Leibler (KL) divergence between the diffusion posterior $p(\mathbf{x}_0|\mathbf{x}_t)$ and the measurement posterior $p(\mathbf{x}_0|\mathbf{y})$, where $\mathbf{y}$ denotes the measurement. Importantly, for linear inverse problems, VML can be analytically derived and need not be approximated. Based on further theoretical insights, we propose VML-MAP, an empirically effective algorithm for solving inverse problems, and validate its efficacy over existing methods in both performance and computational time, through extensive experiments on diverse image-restoration tasks across multiple datasets.

</details>


### [28] [Unlocking the Address Book: Dissecting the Sparse Semantic Structure of LLM Key-Value Caches via Sparse Autoencoders](https://arxiv.org/abs/2512.10547)
*Qingsen Ma,Dianyun Wang,Jiaming Lyu,Yaoye Wang,Lechen Ning,Sujie Zhu,Zhenbo Xu,Liuyu Xiang,Huining Li,Huijia Wu,Zhaofeng He*

Main category: cs.LG

TL;DR: 提出 STA-Attention 框架，利用 Top-K 稀疏自编码器将 KV 缓存分解为可解释的“语义原子”，揭示 Key-Value 的不对称性，并提出 Dual-Budget 策略，在多种大模型上实现对原模型困惑度和零-shot 表现的近似保持，同时提升可解释性与注意力建模的精度。


<details>
  <summary>Details</summary>
Motivation: KV 缓存是长上下文大模型的主要内存瓶颈，但通常被视为一个不透明的数值张量，需要机制理解和效率提升。

Method: 采用 Top-K 稀疏自编码器来解耦 KV 缓存，避免 L1 正则化带来的收缩偏差，抽取可解释的语义原子；分析 Key 与 Value 向量的不同分布，发现 Key 向量更稀疏且由“语义肘部”支配，Value 向量密集且承载内容；提出 Dual-Budget 策略，选择性保留最具信息量的语义成分，滤除噪声，避免破坏点积几何关系。

Result: 在 Yi-6B、Mistral-7B、Qwen2.5-32B 等模型上的实验表明，语义重构能维持与原模型相近的 perplexity 和零-shot 能力，达到可解释性和注意力建模之间的桥接。

Conclusion: STA-Attention 为将可解释性与准确的注意力建模结合起来提供了一种新的路径，Key-Value 不对称性与 Dual-Budget 策略是其核心发现，具有潜在减缓内存压力与提升模型理解性的意义。

Abstract: The Key-Value (KV) cache is the primary memory bottleneck in long-context Large Language Models, yet it is typically treated as an opaque numerical tensor. In this work, we propose \textbf{STA-Attention}, a framework that utilizes Top-K Sparse Autoencoders (SAEs) to decompose the KV cache into interpretable ``semantic atoms.'' Unlike standard $L_1$-regularized SAEs, our Top-K approach eliminates shrinkage bias, preserving the precise dot-product geometry required for attention. Our analysis uncovers a fundamental \textbf{Key-Value Asymmetry}: while Key vectors serve as highly sparse routers dominated by a ``Semantic Elbow,'' deep Value vectors carry dense content payloads requiring a larger budget. Based on this structure, we introduce a Dual-Budget Strategy that selectively preserves the most informative semantic components while filtering representational noise. Experiments on Yi-6B, Mistral-7B, Qwen2.5-32B, and others show that our semantic reconstructions maintain perplexity and zero-shot performance comparable to the original models, effectively bridging the gap between mechanistic interpretability and faithful attention modeling.

</details>


### [29] [Is the Information Bottleneck Robust Enough? Towards Label-Noise Resistant Information Bottleneck Learning](https://arxiv.org/abs/2512.10573)
*Yi Huang,Qingyun Sun,Yisen Gao,Haonan Yuan,Xingcheng Fu,Jianxin Li*

Main category: cs.LG

TL;DR: 提出 LaT-IB：一个对标签噪声鲁棒的 Information Bottleneck 框架，通过最小充分清洁 MSC 约束实现对清洁标签的信息保留与噪声信息抑制，并通过噪声感知的潜在解耦和三阶段训练提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: IB 依赖准确标签，易受标签噪声影响而产生过拟合和性能下降。现实场景存在标签噪声，需要在保留任务相关信息与抑制噪声之间建立鲁棒机制。

Method: 引入 MSC 作为互信息正则，分解潜在表示为清洁标签空间与噪声空间，推导预测、压缩、解耦三者的互信息界限；提出噪声感知的潜在解耦策略；设计三阶段训练框架：Warmup、Knowledge Injection、Robust Training。

Result: 理论上给出各组成部分的互信息界限，证明优化可获得对输入噪声不变性及清洁/噪声标签信息的分离；在多数据集/设置下展现对标签噪声的鲁棒性和效率提升。

Conclusion: MSC 约束与三阶段训练共同提升对标签噪声的鲁棒性，提供一种可泛化的噪声鲁棒信息瓶颈框架，适用于现实世界的带噪标签学习。

Abstract: The Information Bottleneck (IB) principle facilitates effective representation learning by preserving label-relevant information while compressing irrelevant information. However, its strong reliance on accurate labels makes it inherently vulnerable to label noise, prevalent in real-world scenarios, resulting in significant performance degradation and overfitting. To address this issue, we propose LaT-IB, a novel Label-Noise ResistanT Information Bottleneck method which introduces a "Minimal-Sufficient-Clean" (MSC) criterion. Instantiated as a mutual information regularizer to retain task-relevant information while discarding noise, MSC addresses standard IB's vulnerability to noisy label supervision. To achieve this, LaT-IB employs a noise-aware latent disentanglement that decomposes the latent representation into components aligned with to the clean label space and the noise space. Theoretically, we first derive mutual information bounds for each component of our objective including prediction, compression, and disentanglement, and moreover prove that optimizing it encourages representations invariant to input noise and separates clean and noisy label information. Furthermore, we design a three-phase training framework: Warmup, Knowledge Injection and Robust Training, to progressively guide the model toward noise-resistant representations. Extensive experiments demonstrate that LaT-IB achieves superior robustness and efficiency under label noise, significantly enhancing robustness and applicability in real-world scenarios with label noise.

</details>


### [30] [Multi-Objective Reward and Preference Optimization: Theory and Algorithms](https://arxiv.org/abs/2512.10601)
*Akhil Agnihotri*

Main category: cs.LG

TL;DR: 提出并验证一组跨约束强化学习与偏好学习算法（ACPO、e-COP、warmPref-PS、PSPL、MOPO），覆盖平均成本、有限时域与偏好驱动场景，並将其应用于大规模语言模型对齐，具备理论保证与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在控制、偏好整合和模型对齐等领域，存在对约束遵循、数据异质性偏好和大模型可扩展性的挑战；需要统一的理论框架与实用算法以确保安全、稳健和高效学习。

Method: - ACPO：在平均成本 CMDP 中结合敏感性分析与信任域更新，实现稳健约束处理并具备理论保证。 
- e-COP：基于 episodic policy difference lemma 的策略优化，适用于 episodic CMDP，具有可证明的性能、易实现、可扩展。 
- warmPref-PS：引入后验采样策略，整合来自异质评者的离线偏好数据、对评者能力建模，从而显著降低后验- regrets 并提升数据收集效率。 
- PSPL：通过从对比轨迹中联合采样奖励模型与转移动力学，给出贝叶斯简单后悔界限，鲁棒识别最优策略。 
- MOPO：在多目标约束优化视角下的迭代算法，具有闭式更新，能扩展到亿级参数的语言模型，鲁棒性强。

Result: 在理论上提供收敛性、稳健性等 guarantees，实验上达到 state-of-the-art，覆盖从平均成本到 episodic 与偏好驱动场景，且实现可扩展性至大规模语言模型；并对安全性和对齐提供实用工具。

Conclusion: 通过统一约束 RL 的平均成本、 episodic、偏好驱动三个范式，论文为安全与对齐的决策提供理论与工具的综合框架。

Abstract: This thesis develops theoretical frameworks and algorithms that advance constrained reinforcement learning (RL) across control, preference learning, and alignment of large language models. The first contribution addresses constrained Markov Decision Processes (CMDPs) under the average-cost criterion through the Average-Constrained Policy Optimization (ACPO) algorithm. ACPO integrates sensitivity analysis with trust-region updates to ensure stable constraint handling, achieving state-of-the-art empirical performance with theoretical guarantees. Constrained RL is then extended to finite-horizon settings via e-COP, the first policy optimization method for episodic CMDPs. Built on an episodic policy difference lemma, e-COP offers provable performance, simplicity, and scalability in safety-critical environments. The thesis then investigates reinforcement learning from human preferences. warmPref-PS introduces a posterior sampling strategy for linear bandits that integrates offline preference data from heterogeneous raters into online learning. Explicit modeling of rater competence yields substantial regret reduction and more efficient data collection for RLHF. The PSPL algorithm further advances preference-based RL by jointly sampling reward models and transition dynamics from pairwise trajectory comparisons, providing Bayesian simple-regret guarantees and robust empirical identification of optimal policies. The final contribution applies these methods to large-scale model alignment. A multi-objective constrained optimization view yields MOPO, an iterative algorithm with closed-form updates that scales to multi-billion-parameter language models and remains robust across alignment settings. Collectively, the thesis unifies constrained RL across average-cost, episodic, and preference-driven paradigms, delivering theoretical advances and practical tools for safe and aligned decision-making.

</details>


### [31] [Supporting Migration Policies with Forecasts: Illegal Border Crossings in Europe through a Mixed Approach](https://arxiv.org/abs/2512.10633)
*C. Bosco,U. Minora,D. de Rigo,J. Pingsdorf,R. Cortinovis*

Main category: cs.LG

TL;DR: 混合方法论：将机器学习与专家定性判断相结合，针对欧洲五条主要迁徙路线，预测一年内非法越境，意在提升数据驱动模型的预测能力。


<details>
  <summary>Details</summary>
Motivation: 应对迁徙模式的突然变化和传统数据集的局限性，提供对EU《移民与庇护框架协定》等政策的前瞻性、政策相关的预测，以支持早期预警和成员国团结。

Method: 将机器学习与迁移专家的定性见解作为协变量整合进模型；覆盖五条路线，时间视窗为一年；并对已知数据进行验证。

Result: 通过与已知数据的耦合验证，展示了方法在迁徙治理背景下的适用性和可靠性，但未在摘要中给出具体指标。

Conclusion: 该方法与现有学术建议保持一致，提供一个面向EU迁徙治理的创新性操作工具，能够提升政策相关的预测与决策支持。

Abstract: This paper presents a mixed-methodology to forecast illegal border crossings in Europe across five key migratory routes, with a one-year time horizon. The methodology integrates machine learning techniques with qualitative insights from migration experts. This approach aims at improving the predictive capacity of data-driven models through the inclusion of a human-assessed covariate, an innovation that addresses challenges posed by sudden shifts in migration patterns and limitations in traditional datasets. The proposed methodology responds directly to the forecasting needs outlined in the EU Pact on Migration and Asylum, supporting the Asylum and Migration Management Regulation (AMMR). It is designed to provide policy-relevant forecasts that inform strategic decisions, early warning systems, and solidarity mechanisms among EU Member States. By joining data-driven modeling with expert judgment, this work aligns with existing academic recommendations and introduces a novel operational tool tailored for EU migration governance. The methodology is tested and validated with known data to demonstrate its applicability and reliability in migration-related policy context.

</details>


### [32] [Token Sample Complexity of Attention](https://arxiv.org/abs/2512.10656)
*Léa Bohbot,Cyril Letrouit,Gabriel Peyré,François-Xavier Vialard*

Main category: cs.LG

TL;DR: 研究在极长的上下文下分析注意力的收敛性，提出两级收敛界：对注意力映射的点态统一收敛在半径R的球内以速率C(R)/sqrt(n)收敛（C(R)随R指数增长），以及对变换后分布的矩的收敛以速率C'(R)/n^β收敛，β<1/2且C'(R)与支撑规模多项式相关；在softmax趋近hardmax的极限下给出对数收敛；并通过高斯数据和BERT在维基百科文本的实验验证。


<details>
  <summary>Details</summary>
Motivation: 随着上下文窗口的扩展，需要定量了解注意力在极长序列上的行为，给出理论收敛界并验证是否随序列长度趋于无限而收敛。

Method: 对注意力映射在两层级进行收敛分析：1) 在紧支撑（或子高斯）分布下，点态统一收敛在半径R球内，速率为C(R)/sqrt(n)，其中C(R)随R指数增长；2) 转换后的分布矩的收敛，速率为C'(R)/n^β，β<1/2，C'(R)与分布支撑大小的多项式关系，β由注意力几何和分布的谱性质决定；另外考察softmax趋向hardmax的极限，给出对数收敛；并给出对合成高斯数据与BERT在维基文本上的实验。

Result: 结论包括：在紧支撑或子高斯分布下，注意力图对n的收敛速率为2的1/2次方，且随R增大收敛界恶化；关于矩的收敛，给出n^β（β<1/2）收敛，系数随R与支撑规模多项式相关；软最大极限下收敛为对数级；实验结果支持理论预测。

Conclusion: 理论揭示极长上下文下注意力的收敛特性及其依赖因素（R、分布支撑、谱性质、注意力几何），并指出在某些场景下收敛可能较慢，需要在模型设计中权衡；实验在合成高斯数据与BERT维基文本上验证了这些收敛趋势。

Abstract: As context windows in large language models continue to expand, it is essential to characterize how attention behaves at extreme sequence lengths. We introduce token-sample complexity: the rate at which attention computed on $n$ tokens converges to its infinite-token limit. We estimate finite-$n$ convergence bounds at two levels: pointwise uniform convergence of the attention map, and convergence of moments for the transformed token distribution. For compactly supported (and more generally sub-Gaussian) distributions, our first result shows that the attention map converges uniformly on a ball of radius $R$ at rate $C(R)/\sqrt{n}$, where $C(R)$ grows exponentially with $R$. For large $R$, this estimate loses practical value, and our second result addresses this issue by establishing convergence rates for the moments of the transformed distribution (the token output of the attention layer). In this case, the rate is $C'(R)/n^β$ with $β<\tfrac{1}{2}$, and $C'(R)$ depends polynomially on the size of the support of the distribution. The exponent $β$ depends on the attention geometry and the spectral properties of the tokens distribution. We also examine the regime in which the attention parameter tends to infinity and the softmax approaches a hardmax, and in this setting, we establish a logarithmic rate of convergence. Experiments on synthetic Gaussian data and real BERT models on Wikipedia text confirm our predictions.

</details>


### [33] [DCFO Additional Material](https://arxiv.org/abs/2512.10659)
*Tommaso Amico,Pernille Matthews,Lena Krieger,Arthur Zimek,Ira Assent*

Main category: cs.LG

TL;DR: 提出基于密度的反事实解释（DCFO）来为局部异常因子 LOF 生成对异常点的反事实解释。通过将数据空间划分为 LOF 行为平滑的区域并进行梯度优化，实验表明 DCFO 在 50 个 OpenML 数据集上优于基线，具有更好的近端性和有效性。


<details>
  <summary>Details</summary>
Motivation: LOF 在实际应用中广泛使用，但缺乏可解释性；现有反事实方法多未针对经典的异常检测算法，难以提供针对性且可操作的解释。需要可用于排除偏差、验证重要性并提供防范措施的解释。

Method: 提出 DCFO，利用密度基础思想将数据空间划分成 LOF 行为平滑的区域，进而在这些区域内应用梯度优化生成反事实解释，以提高解释的可操作性与稳定性。

Result: 在 50 份 OpenML 数据集上的广泛实验显示，DCFO 始终优于基线方法，生成的反事实在距离近似性（proximality）和有效性（validity）方面均有提升。

Conclusion: DCFO 有效填补 LOF 的可解释性空白，提供了面向经典密度型检测器的高效反事实解释方法，具有良好的实用性和潜在的推广性。

Abstract: Outlier detection identifies data points that significantly deviate from the majority of the data distribution. Explaining outliers is crucial for understanding the underlying factors that contribute to their detection, validating their significance, and identifying potential biases or errors. Effective explanations provide actionable insights, facilitating preventive measures to avoid similar outliers in the future. Counterfactual explanations clarify why specific data points are classified as outliers by identifying minimal changes required to alter their prediction. Although valuable, most existing counterfactual explanation methods overlook the unique challenges posed by outlier detection, and fail to target classical, widely adopted outlier detection algorithms. Local Outlier Factor (LOF) is one the most popular unsupervised outlier detection methods, quantifying outlierness through relative local density. Despite LOF's widespread use across diverse applications, it lacks interpretability. To address this limitation, we introduce Density-based Counterfactuals for Outliers (DCFO), a novel method specifically designed to generate counterfactual explanations for LOF. DCFO partitions the data space into regions where LOF behaves smoothly, enabling efficient gradient-based optimisation. Extensive experimental validation on 50 OpenML datasets demonstrates that DCFO consistently outperforms benchmarked competitors, offering superior proximity and validity of generated counterfactuals.

</details>


### [34] [Learning by Analogy: A Causal Framework for Composition Generalization](https://arxiv.org/abs/2512.10669)
*Lingjing Kong,Shaoan Xie,Yang Jiao,Yetian Chen,Yanhui Guo,Simone Shao,Yan Gao,Guangyi Chen,Kun Zhang*

Main category: cs.LG

TL;DR: 提出一个基于因果模块化的层次生成过程模型，能够实现成分式泛化，并且可从可观测数据（文本-图像对）中可识别地恢复潜在层次结构；理论性证明与实证都显示出对复杂关系的泛化能力提升。


<details>
  <summary>Details</summary>
Motivation: 当前的成分式泛化研究对支撑机制的理解不足，缺乏对数据结构和原理的清晰界定。作者主张将高层概念分解为低层概念并在相似情境下重新组合，仿照人类类比的方式来实现泛化；识别性（identifiability）是学习此类生成过程的关键前提。

Method: 提出一个层次化的数据生成过程，编码不同层次的概念及其相互作用机制，并以因果模块化与最小改变原则为核心；理论证明该框架下的潜在层次结构在可观测数据上是可辨识的（identifiable），且能够实现比仅依赖线性、加性假设更丰富的成分间关系的组合泛化；并在文本-图像对等可观测数据上进行可验证性分析。

Result: 从理论上证明了在复杂概念关系下的成分化泛化能力，并给出潜在层次结构的可辨识性证明；在基准数据集上基于理论框架得到显著的性能提升。

Conclusion: 该研究为成分式泛化提供了新的理论与方法路径，展示了可辨识的潜在层次结构如何帮助学习更复杂的概念组合，并在实证评估中取得进展。

Abstract: Compositional generalization -- the ability to understand and generate novel combinations of learned concepts -- enables models to extend their capabilities beyond limited experiences. While effective, the data structures and principles that enable this crucial capability remain poorly understood. We propose that compositional generalization fundamentally requires decomposing high-level concepts into basic, low-level concepts that can be recombined across similar contexts, similar to how humans draw analogies between concepts. For example, someone who has never seen a peacock eating rice can envision this scene by relating it to their previous observations of a chicken eating rice.
  In this work, we formalize these intuitive processes using principles of causal modularity and minimal changes. We introduce a hierarchical data-generating process that naturally encodes different levels of concepts and their interaction mechanisms. Theoretically, we demonstrate that this approach enables compositional generalization supporting complex relations between composed concepts, advancing beyond prior work that assumes simpler interactions like additive effects. Critically, we also prove that this latent hierarchical structure is provably recoverable (identifiable) from observable data like text-image pairs, a necessary step for learning such a generative process. To validate our theory, we apply insights from our theoretical framework and achieve significant improvements on benchmark datasets.

</details>


### [35] [HybridVFL: Disentangled Feature Learning for Edge-Enabled Vertical Federated Multimodal Classification](https://arxiv.org/abs/2512.10701)
*Mostafa Anoosha,Zeinab Dehghani,Kuniko Paxton,Koorosh Aslansefat,Dhavalkumar Thakker*

Main category: cs.LG

TL;DR: HybridVFL 通过在客户端进行特征解耦、在服务器端采用跨模态变换器进行上下文感知融合，显著提升垂直联邦学习在多模态皮肤病变数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有垂直联邦学习（VFL）多采用简单的特征融合，难以充分利用多模态信息且在资源受限设备场景下性能受限，需要更强的上下文感知融合策略以提升效果并保持隐私。

Method: 在客户端执行特征解耦以保护隐私并提升可控信息的利用，在服务器端引入跨模态 Transformer 进行上下文感知的模态融合与分类，通过对 HAM10000 数据集的系统评估验证性能提升。

Result: 相较于标准联邦基线，HybridVFL 在多模态皮肤病变任务上显著提升性能，显示出先进融合机制在鲁棒性与隐私保护系统中的关键性。

Conclusion: 研究表明将特征解耦与跨模态 Transformer 融合应用于VFL能显著提升多模态边缘AI场景的性能与隐私保护，HybridVFL为此类系统提供了一种有效解决方案。

Abstract: Vertical Federated Learning (VFL) offers a privacy-preserving paradigm for Edge AI scenarios like mobile health diagnostics, where sensitive multimodal data reside on distributed, resource-constrained devices. Yet, standard VFL systems often suffer performance limitations due to simplistic feature fusion. This paper introduces HybridVFL, a novel framework designed to overcome this bottleneck by employing client-side feature disentanglement paired with a server-side cross-modal transformer for context-aware fusion. Through systematic evaluation on the multimodal HAM10000 skin lesion dataset, we demonstrate that HybridVFL significantly outperforms standard federated baselines, validating the criticality of advanced fusion mechanisms in robust, privacy-preserving systems.

</details>


### [36] [Beyond the Black Box: Identifiable Interpretation and Control in Generative Models via Causal Minimality](https://arxiv.org/abs/2512.10720)
*Lingjing Kong,Shaoan Xie,Guangyi Chen,Yuewen Sun,Xiangchen Song,Eric P. Xing,Kun Zhang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Deep generative models, while revolutionizing fields like image and text generation, largely operate as opaque black boxes, hindering human understanding, control, and alignment. While methods like sparse autoencoders (SAEs) show remarkable empirical success, they often lack theoretical guarantees, risking subjective insights. Our primary objective is to establish a principled foundation for interpretable generative models. We demonstrate that the principle of causal minimality -- favoring the simplest causal explanation -- can endow the latent representations of diffusion vision and autoregressive language models with clear causal interpretation and robust, component-wise identifiable control. We introduce a novel theoretical framework for hierarchical selection models, where higher-level concepts emerge from the constrained composition of lower-level variables, better capturing the complex dependencies in data generation. Under theoretically derived minimality conditions (manifesting as sparsity or compression constraints), we show that learned representations can be equivalent to the true latent variables of the data-generating process. Empirically, applying these constraints to leading generative models allows us to extract their innate hierarchical concept graphs, offering fresh insights into their internal knowledge organization. Furthermore, these causally grounded concepts serve as levers for fine-grained model steering, paving the way for transparent, reliable systems.

</details>


### [37] [Generalized Spherical Neural Operators: Green's Function Formulation](https://arxiv.org/abs/2512.10723)
*Hao Tang,Hao Chen,Chao Li*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Neural operators offer powerful approaches for solving parametric partial differential equations, but extending them to spherical domains remains challenging due to the need to preserve intrinsic geometry while avoiding distortions that break rotational consistency. Existing spherical operators rely on rotational equivariance but often lack the flexibility for real-world complexity. We propose a general operator-design framework based on the designable spherical Green's function and its harmonic expansion, establishing a solid operator-theoretic foundation for spherical learning. Based on this, we propose an absolute and relative position-dependent Green's function that enables flexible balance of equivariance and invariance for real-world modeling. The resulting operator, Green's-function Spherical Neural Operator (GSNO) with a novel spectral learning method, can adapt to anisotropic, constraint-rich systems while retaining spectral efficiency. To exploit GSNO, we develop GSHNet, a hierarchical architecture that combines multi-scale spectral modeling with spherical up-down sampling, enhancing global feature representation. Evaluations on diffusion MRI, shallow water dynamics, and global weather forecasting, GSNO and GSHNet consistently outperform state-of-the-art methods. Our results position GSNO as a principled and general framework for spherical operator learning, bridging rigorous theory with real-world complexity.

</details>


### [38] [LGAN: An Efficient High-Order Graph Neural Network via the Line Graph Aggregation](https://arxiv.org/abs/2512.10735)
*Lin Du,Lu Bai,Jincheng Li,Lixin Cui,Hangyuan Du,Lichi Zhang,Yuting Chen,Zhao Li*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Graph Neural Networks (GNNs) have emerged as a dominant paradigm for graph classification. Specifically, most existing GNNs mainly rely on the message passing strategy between neighbor nodes, where the expressivity is limited by the 1-dimensional Weisfeiler-Lehman (1-WL) test. Although a number of k-WL-based GNNs have been proposed to overcome this limitation, their computational cost increases rapidly with k, significantly restricting the practical applicability. Moreover, since the k-WL models mainly operate on node tuples, these k-WL-based GNNs cannot retain fine-grained node- or edge-level semantics required by attribution methods (e.g., Integrated Gradients), leading to the less interpretable problem. To overcome the above shortcomings, in this paper, we propose a novel Line Graph Aggregation Network (LGAN), that constructs a line graph from the induced subgraph centered at each node to perform the higher-order aggregation. We theoretically prove that the LGAN not only possesses the greater expressive power than the 2-WL under injective aggregation assumptions, but also has lower time complexity. Empirical evaluations on benchmarks demonstrate that the LGAN outperforms state-of-the-art k-WL-based GNNs, while offering better interpretability.

</details>


### [39] [Interpretable and Steerable Concept Bottleneck Sparse Autoencoders](https://arxiv.org/abs/2512.10805)
*Akshay Kulkarni,Tsui-Wei Weng,Vivek Narayanaswamy,Shusen Liu,Wesam A. Sakla,Kowshik Thopalli*

Main category: cs.LG

TL;DR: 提出了 CB-SAE：通过裁剪低效神经元并引入概念瓶颈，提升 LVLMs 的稀疏自编码器的可解释性和可操控性；在分析中发现多数 SAE 神经元要么可解释性低，要么可控性低，且无监督学习导致用户概念缺失；结果显示可解释性提升32.1%、可操控性提升14.5%；计划公开代码与权重。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器在可解释性和可操控性方面有潜力，但实际表现受限，因为大多数神经元不可解释或不可控，且无监督学习难以覆盖用户希望的概念；需要一个低成本的后处理框架来对齐概念并提升可用性。

Method: 提出两种轻量级可解释性与可操控性度量；对 LVLM 进行系统分析；提出 CB-SAE：后处理裁剪低效神经元，并在潜在空间增加一个轻量级的概念瓶颈，使之与用户定义的概念集对齐。

Result: 在分析中发现多数 SAE 神经元要么可解释性低，要么可操控性低；CB-SAE 能在 LVLMs 和图像生成任务中将可解释性提升约32.1%、可操控性提升约14.5%。

Conclusion: CB-SAE 显著提升可解释性和可操控性，并通过后处理裁剪与概念瓶颈对齐提升实用性；计划公开代码和权重以便复现。

Abstract: Sparse autoencoders (SAEs) promise a unified approach for mechanistic interpretability, concept discovery, and model steering in LLMs and LVLMs. However, realizing this potential requires that the learned features be both interpretable and steerable. To that end, we introduce two new computationally inexpensive interpretability and steerability metrics and conduct a systematic analysis on LVLMs. Our analysis uncovers two observations; (i) a majority of SAE neurons exhibit either low interpretability or low steerability or both, rendering them ineffective for downstream use; and (ii) due to the unsupervised nature of SAEs, user-desired concepts are often absent in the learned dictionary, thus limiting their practical utility. To address these limitations, we propose Concept Bottleneck Sparse Autoencoders (CB-SAE) - a novel post-hoc framework that prunes low-utility neurons and augments the latent space with a lightweight concept bottleneck aligned to a user-defined concept set. The resulting CB-SAE improves interpretability by +32.1% and steerability by +14.5% across LVLMs and image generation tasks. We will make our code and model weights available.

</details>


### [40] [Generative Modeling from Black-box Corruptions via Self-Consistent Stochastic Interpolants](https://arxiv.org/abs/2512.10857)
*Chirag Modi,Jiequn Han,Eric Vanden-Eijnden,Joan Bruna*

Main category: cs.LG

TL;DR: 提出自一致随机插值器（SCSI），通过在受损数据与清洁数据之间迭代更新运输映射，在仅有受损数据和黑箱前向模型的条件下实现对污染通道的反演，提供理论保证并具备较高计算效率。


<details>
  <summary>Details</summary>
Motivation: 在很多科学/工程领域，清洁数据难以获得，只能获取被嘈杂通道污染的观测；需要在分布层面解决逆问题，并构建清洁数据的生成模型。现有方法往往依赖于洁净数据或复杂的变分推理，难以高效或灵活处理强非线性前向模型。

Method: 通过引入基于随机插值的运输更新，迭代地更新受损样本到清洁样本之间的运输映射，且仅需要访问受损数据和对前向通道的黑箱访问。该过程形成自一致的运输映射，收敛后实现对污染通道的反演，形成自一致随机插值器（SCSI）。

Result: 在自然图像处理和科学重建的逆问题中展现出优越性能；相较于变分方法，计算效率更高；对任意非线性前向模型具备良好适应性；在适当假设下给出收敛性保证。

Conclusion: SCSI为在仅有受损观测下的清洁数据生成建模提供一个理论上有保障、计算高效、灵活适应复杂前向模型的解决方案，推动分布层面的逆问题建模。

Abstract: Transport-based methods have emerged as a leading paradigm for building generative models from large, clean datasets. However, in many scientific and engineering domains, clean data are often unavailable: instead, we only observe measurements corrupted through a noisy, ill-conditioned channel. A generative model for the original data thus requires solving an inverse problem at the level of distributions. In this work, we introduce a novel approach to this task based on Stochastic Interpolants: we iteratively update a transport map between corrupted and clean data samples using only access to the corrupted dataset as well as black box access to the corruption channel. Under appropriate conditions, this iterative procedure converges towards a self-consistent transport map that effectively inverts the corruption channel, thus enabling a generative model for the clean data. We refer to the resulting method as the self-consistent stochastic interpolant (SCSI). It (i) is computationally efficient compared to variational alternatives, (ii) highly flexible, handling arbitrary nonlinear forward models with only black-box access, and (iii) enjoys theoretical guarantees. We demonstrate superior performance on inverse problems in natural image processing and scientific reconstruction, and establish convergence guarantees of the scheme under appropriate assumptions.

</details>


### [41] [Scaling Behavior of Discrete Diffusion Language Models](https://arxiv.org/abs/2512.10858)
*Dimitri von Rütte,Janis Fluri,Omead Pooladzandi,Bernhard Schölkopf,Thomas Hofmann,Antonio Orvieto*

Main category: cs.LG

TL;DR: DLMs 的缩放行为强烈依赖噪声类型，与 ALMs 存在显著差异。统一扩散在可计算资源约束下需要更多参数但对数据需求较低，且在数据受限场景中具有潜在优势；在达到 10B 参数、1e22 FLOPs 的规模下，统一扩散模型的 scaling 行为得到了验证，是公开可用的最大的统一扩散模型之一。


<details>
  <summary>Details</summary>
Motivation: 探究离散扩散语言模型在不同噪声类型下的缩放规律，并将其与自回归语言模型的缩放规律进行比较，以判断不同噪声和训练超参数如何影响模型在数据和计算资源上的效率。

Method: 通过在掩码扩散与均匀扩散之间进行平滑插值，研究不同噪声类型对 DLM 缩放行为的影响；关注批量大小、学习率等关键超参数；将模型规模扩展至 10B 参数，并在 10^22 FLOPs 条件下训练，验证预测的缩放规律。

Result: 不同噪声类型导致 DLM 的缩放行为显著不同；在 compute-bound（计算受限）情形下，不同噪声类型的最终损失趋于相近；与掩码扩散相比，均匀扩散需要更多参数、而数据需求较少，因而在数据受限的训练场景中具有优势；已将均匀扩散模型扩展至 100 亿参数，达到 10^22 FLOPs，验证了其缩放规律，且成为公开可用的最大规模均匀扩散模型。

Conclusion: DLM 的缩放规律与 ALM 存在本质差异，噪声类型是决定性因素。均匀扩散在数据不足时更具参数依赖性和数据效率，是数据受限场景的有力候选；该研究提供了对高参数量、/大规模训练的实际证实，促进对离散扩散方法的理解与应用。

Abstract: Modern LLM pre-training consumes vast amounts of compute and training data, making the scaling behavior, or scaling laws, of different models a key distinguishing factor. Discrete diffusion language models (DLMs) have been proposed as an alternative to autoregressive language models (ALMs). However, their scaling behavior has not yet been fully explored, with prior work suggesting that they require more data and compute to match the performance of ALMs.
  We study the scaling behavior of DLMs on different noise types by smoothly interpolating between masked and uniform diffusion while paying close attention to crucial hyperparameters such as batch size and learning rate. Our experiments reveal that the scaling behavior of DLMs strongly depends on the noise type and is considerably different from ALMs. While all noise types converge to similar loss values in compute-bound scaling, we find that uniform diffusion requires more parameters and less data for compute-efficient training compared to masked diffusion, making them a promising candidate in data-bound settings. We scale our uniform diffusion model up to 10B parameters trained for $10^{22}$ FLOPs, confirming the predicted scaling behavior and making it the largest publicly known uniform diffusion model to date.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [42] [QSTAformer: A Quantum-Enhanced Transformer for Robust Short-Term Voltage Stability Assessment against Adversarial Attacks](https://arxiv.org/abs/2512.09936)
*Yang Li,Chong Ma,Yuanzheng Li,Sen Li,Yanbo Chen,Zhaoyang Dong*

Main category: eess.SY

TL;DR: 提出了一种量子增强Transformer（QSTAformer）用于短期电压稳定性评估（STVSA），在注意力机制中嵌入参数化量子电路，结合对抗训练提升鲁棒性，并比较多种PQC架构。


<details>
  <summary>Details</summary>
Motivation: 短期电压稳定性评估对电力系统安全至关重要，传统ML在对抗条件下鲁棒性不足；需要一种高效且鲁棒的量子增强方法。

Method: 设计QSTAformer，将PQCs嵌入注意力机制；开发对抗训练策略以对抗白盒与灰盒攻击；对多种PQC架构进行基准比较；在IEEE 39母线系统上进行案例研究。

Result: 在IEEE 39-bus系统上实现竞争性精度、降低的计算复杂度、以及更强的鲁棒性，证明在对抗条件下的安全可扩展性。

Conclusion: 首次系统性研究量子机器学习在STVSA中的对抗脆弱性，表明该方法在安全可扩展的STVSA方面具有潜力。

Abstract: Short-term voltage stability assessment (STVSA) is critical for secure power system operation. While classical machine learning-based methods have demonstrated strong performance, they still face challenges in robustness under adversarial conditions. This paper proposes QSTAformer-a tailored quantum-enhanced Transformer architecture that embeds parameterized quantum circuits (PQCs) into attention mechanisms-for robust and efficient STVSA. A dedicated adversarial training strategy is developed to defend against both white-box and gray-box attacks. Furthermore, diverse PQC architectures are benchmarked to explore trade-offs between expressiveness, convergence, and efficiency. To the best of our knowledge, this is the first work to systematically investigate the adversarial vulnerability of quantum machine learning-based STVSA. Case studies on the IEEE 39-bus system demonstrate that QSTAformer achieves competitive accuracy, reduced complexity, and stronger robustness, underscoring its potential for secure and scalable STVSA under adversarial conditions.

</details>


### [43] [Explicit Control Barrier Function-based Safety Filters and their Resource-Aware Computation](https://arxiv.org/abs/2512.10118)
*Pol Mestres,Shima Sadat Mousavi,Pio Ong,Lizhi Yang,Ersin Das,Joel W. Burdick,Aaron D. Ames*

Main category: eess.SY

TL;DR: 提出了基于区域分段的闭式解用于CBF安全滤波的高频实现，通过在状态空间划分区域并在每个区域给出闭式控制律，从而实现无需实时求解QP的资源感知安全控制，并在区域变化时更新策略。


<details>
  <summary>Details</summary>
Motivation: CBF安全滤波通常通过在实时求解二次规划(QP)来实现，以保证状态安全；然而在需要极高控制频率的应用中，现成的QP求解器可能成为瓶颈。

Method: 将状态空间划分为若干区域，在每个区域推导一条闭式控制律以实现等效的CBF约束；设计区域变化检测机制，在区域之间时使用该区域的闭式解，在区域未变化时复用；实现资源感知的CBF安全滤波器。

Result: 在一系列示例中展示方法的有效性，覆盖航天控制和安全强化学习等场景，显著降低计算需求并保持安全性。

Conclusion: 区域分段的闭式CBF安全滤波器提供了一种高频控制中的高效实现路径，具有可扩展性，但也需注意区域划分的保守性、边界处理和切换开销等问题。

Abstract: This paper studies the efficient implementation of safety filters that are designed using control barrier functions (CBFs), which minimally modify a nominal controller to render it safe with respect to a prescribed set of states. Although CBF-based safety filters are often implemented by solving a quadratic program (QP) in real time, the use of off-the-shelf solvers for such optimization problems poses a challenge in applications where control actions need to be computed efficiently at very high frequencies. In this paper, we introduce a closed-form expression for controllers obtained through CBF-based safety filters. This expression is obtained by partitioning the state-space into different regions, with a different closed-form solution in each region. We leverage this formula to introduce a resource-aware implementation of CBF-based safety filters that detects changes in the partition region and uses the closed-form expression between changes. We showcase the applicability of our approach in examples ranging from aerospace control to safe reinforcement learning.

</details>


### [44] [Traffic Equilibrium in Mixed-Autonomy Network with Capped Customer Waiting](https://arxiv.org/abs/2512.10194)
*Jiaxin Hou,Kexin Wang,Ruolin Li,Jong-shi Pang*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper develops a unified modeling framework to capture the equilibrium-state interactions among ride-hailing companies, travelers, and traffic of mixed-autonomy transportation networks. Our framework integrates four interrelated sub-modules: (i) the operational behavior of representative ride-hailing Mixed-Fleet Traffic Network Companies (MiFleet TNCs) managing autonomous vehicle (AV) and human-driven vehicle (HV) fleets, (ii) traveler mode-choice decisions taking into account travel costs and waiting time, (iii) capped customer waiting times to reflect the option available to travelers not to wait for TNCs' service beyond his/her patience and to resort to existing travel modes, and (iv) a flow-dependent traffic congestion model for travel times. A key modeling feature distinguishes AVs and HVs across the pickup and service (customer-on-board) stages: AVs follow Wardrop pickup routes but may deviate during service under company coordination, whereas HVs operate in the reverse manner. The overall framework is formulated as a Nonlinear Complementarity Problem (NCP), which is equivalent to a Variational Inequality(VI) formulation based on which the existence of a variational equilibrium solution to the traffic model is established. Numerical experiments examine how AV penetration and Wardrop relaxation factors, which bound route deviation, affect company, traveler, and system performance to various degrees. The results provide actionable insights for policymakers on regulating AV adoption and company vehicle deviation behavior in modern-day traffic systems that are fast changing due to the advances in technology and information accessibility.

</details>


### [45] [Collision-Aware Density-Driven Control of Multi-Agent Systems via Control Barrier Functions](https://arxiv.org/abs/2512.10392)
*Sungjun Seo,Kooktae Lee*

Main category: eess.SY

TL;DR: The paper proposes a Density-Driven Control (D^2C) framework for multi-agent area coverage with obstacle-aware Control Barrier Functions (CBFs). It integrates optimal-transport-based coverage with obstacle-specific, velocity-enhanced CBFs to ensure safety and efficient navigation in cluttered environments.


<details>
  <summary>Details</summary>
Motivation: Efficiently-covered deployment of robot swarms in large, obstacle-rich environments is essential for environmental monitoring and search-and-rescue, balancing coverage performance with safety under resource constraints.

Method: 1) Use D^2C to steer agents to a target distribution encoding spatial coverage priorities via optimal transport. 2) Integrate CBFs for safety; extend CBFs to handle circular and rectangular obstacles with analytic unit normals toward the nearest obstacle face. 3) Introduce a velocity-dependent term in the CBF to improve collision avoidance. 

Result: Simulations show smoother navigation near obstacles and improved area coverage efficiency compared to the existing method, while maintaining collision-free operation.

Conclusion: The proposed framework effectively combines density-driven coverage control with obstacle-aware safety mechanisms, enhancing both coverage efficiency and safety in cluttered environments.

Abstract: This paper tackles the problem of safe and efficient area coverage using a multi-agent system operating in environments with obstacles. Applications such as environmental monitoring and search and rescue require robot swarms to cover large domains under resource constraints, making both coverage efficiency and safety essential. To address the efficiency aspect, we adopt the Density-Driven Control (D$^2$C) framework, which uses optimal transport theory to steer agents according to a reference distribution that encodes spatial coverage priorities. To ensure safety, we incorporate Control Barrier Functions (CBFs) into the framework. While CBFs are commonly used for collision avoidance, we extend their applicability by introducing obstacle-specific formulations for both circular and rectangular shapes. In particular, we analytically derive a unit normal vector based on the agent's position relative to the nearest face of a rectangular obstacle, improving safety enforcement in environments with non-smooth boundaries. Additionally, a velocity-dependent term is incorporated into the CBF to enhance collision avoidance. Simulation results validate the proposed method by demonstrating smoother navigation near obstacles and more efficient area coverage than the existing method, while still ensuring collision-free operation.

</details>


### [46] [Structural Methods for handling mode changes in multimode DAE systems](https://arxiv.org/abs/2512.10580)
*Albert Benveniste,Benoit Caillaud,Yahao Chen,Khalil Ghorbal,Mathias Malandain*

Main category: eess.SY

TL;DR: 提出一种在多模态 DAE 基于模型的语言（如 Modelica）中实现热重启的面向编译的分析方法，结合结构与冲击分析，在存在冲击的情况下也能生成热重启，并能在编译时检测模式切换的定义不充分之处并给出诊断。


<details>
  <summary>Details</summary>
Motivation: 在混合系统的物理-计算模型中，模式切换以及随之产生的冲击行为直接影响仿真与代码生成的正确性。现有的语言对热重启的数学含义缺乏统一定义，导致需要手工平滑模式切换，影响可重复性与自动化。

Method: 提出热重启的数学含义；结合结构分析和冲击分析的混合方法；开发在编译时执行的算法，用于在模式切换不充分时生成诊断信息，并在存在冲击时仍能产生热重启。

Result: 给出一种在编译期可执行的分析与生成机制，能够在存在冲击的情况下构造热重启并输出诊断信息；为 paradigm 如 Modelica 的多模态 DAE 程序提供更可靠的模式切换处理。

Conclusion: 该工作为多模态物理-计算语言中的模式切换提供了统一的热重启语义与可诊断的编译期分析，提升了混合系统建模与代码生成的鲁棒性与自动化程度。

Abstract: Hybrid systems are an important concept in Cyber-Physical Systems modeling, for which multiphysics modeling from first principles and the reuse of models from libraries are key. To achieve this, DAEs must be used to specify the dynamics in each discrete state (or mode in our context). This led to the development of DAE-based equational languages supporting multiple modes, of which Modelica is a popular standard. Mode switching can be time- or state-based. Impulsive behaviors can occur at mode changes. While mode changes are well understood in particular physics (e.g., contact mechanics), this is not the case in physics-agnostic paradigms such as Modelica. This situation causes difficulties for the compilation of programs, often requiring users to manually smooth out mode changes. In this paper, we propose a novel approach for the hot restart at mode changes in such paradigms. We propose a mathematical meaning for hot restarts (such a mathematical meaning does not exist in general), as well as a combined structural and impulse analysis for mode changes, generating the hot restart even in the presence of impulses. Our algorithm detects at compile time if the mode change is insufficiently specified, in which case it returns diagnostics information to the user.

</details>


### [47] [NWP-based Atmospheric Refractivity Modeling and Fast & Stable Non-uniform Plane Wave Ray-Tracing Simulations for LEO Link Analysis](https://arxiv.org/abs/2512.10598)
*Bowoo Jang,Jun Heo,Yong Bae Park,Dong-Yeop Na*

Main category: eess.SY

TL;DR: 本研究提出一种高保真度的三维复介电常数重建与更快更稳的非均匀平面波射线追踪算法，并在双精度下实现稳定性与显著加速


<details>
  <summary>Details</summary>
Motivation: 现有LEO链路分析在两方面受限：一是由稀疏的高空气象观测（ radiosonde）所导致的三维大气折射率重建精度不足；二是以往的非均匀平面波射线追踪在复杂界面处易出现数值下溢，导致数值不稳定，影响研究的可靠性

Method: 使用数值天气预报（NWP）数据重建高分辨率的三维复介电常数场；开发快速且数值稳定的非均匀平面波射线追踪算法，在双精度下保持稳定，并实现对高精度基准的24倍加速

Result: 与严格的非均匀平面波模型相比，导向孔径误差（boresight）和路径损耗在重度降水情形下差异仍然极小；在有损大气中，虽然射线形成非均匀平面波，但沿路径的有效衰减与统一平面波模型预测几乎一致

Conclusion: 研究结果支持在实际LEO链路分析中持续使用统一平面波射线追踪方法，因为它在数值稳定性与计算效率方面取得了与严格方法相近的结果。

Abstract: Existing low-Earth-orbit (LEO) communication link analyses face two main challenges: (1) limited accuracy of 3D atmospheric refractivity reconstructed from sparsely sampled radiosonde data, and (2) numerical instability in previous non-uniform plane-wave ray-tracing algorithms (i.e., underflow under standard double precision), where non-uniform plane waves inevitably arise at complex-valued dielectric interfaces, is caused by extremely small atmospheric loss terms. To address these issues, we reconstruct a high-resolution 3D complex-valued refractivity model using numerical weather prediction data, and develop a fast and numerically stable non-uniform plane-wave ray tracer. The method remains stable in double precision and delivers a 24-fold speedup over high-precision benchmarks. Comparisons show that boresight-error deviations and path-loss differences between the rigorous method and the uniform-plane-wave approximation remain negligible, even under heavy precipitation. Although rays in a lossy atmosphere experience different phase- and attenuation-direction vectors-forming non-uniform plane waves-the resulting effective attenuation along the path is nearly identical to that predicted by the uniform-plane-wave model. These findings justify the continued use of uniform-plane-wave ray tracing in practical LEO link analyses.

</details>


### [48] [Codeshare agreements between airlines: literature review with the aid of artificial intelligence](https://arxiv.org/abs/2512.10639)
*Lucas T. B. Mendes,Alessandro V. M. Oliveira*

Main category: eess.SY

TL;DR: 本文对代码共享协议的文献进行综述，聚焦巴西市场，梳理其对航线供给与价格的潜在影响及监管背景，使用Litmaps等计算工具分析引文关系，旨在揭示长期证据、特定市场特征及未来研究空白。


<details>
  <summary>Details</summary>
Motivation: 理解代码共享在竞争与协同中的作用及其演化，特别是在具有独特监管历史的巴西市场，帮助学术界与监管者把握研究方向与政策含义。

Method: 系统性文献综述，结合理论与案例研究；以Litmaps作为计算工具分析出版物之间的引文关系，并聚焦巴西市场的证据与特征。

Result: 总结了现有研究在供给、价格、竞争效应上的不一致结论；梳理了巴西市场的特殊性与监管背景；识别出研究空白与未来研究方向。

Conclusion: 对代码共享的知识状态进行定性梳理，强调巴西市场的独特性与证据缺口，呼吁未来在监管、市场结构与全球比较方面的进一步研究。

Abstract: Codeshare agreements are contracts that allow two or more airlines to share seats on the same flight. These agreements, which are widespread in commercial aviation as a response to highly competitive environments, have enabled the expansion of airline networks without additional costs or risks for the companies involved. The literature presents ambiguous effects associated with the practice, with evidence of increased supply and reduced prices in situations of route complementarity, while also pointing to anti-competitive impacts in markets where companies act as competitors. A review of scientific production over time, including theoretical contributions and case studies, is essential to understand the evolution of these agreements and their implications, especially in the Brazilian context, marked by its own characteristics and particular regulatory history. Thus, this article reviews the literature on codesharing, with an emphasis on the Brazilian market, and uses the Litmaps computational tool, based on artificial intelligence techniques, to support the contextual analysis of publications through their citation relationships. The ultimate goal is to identify and evaluate the main evidence accumulated over decades on the effects of these agreements in Brazil. The joint analysis of the contributions allows us to outline the current state of knowledge, characterize specificities observed in the Brazilian market, and identify gaps that may guide future studies.

</details>


### [49] [Estimating Hormone Concentrations in the Pituitary-Thyroid Feedback Loop from Irregularly Sampled Measurements](https://arxiv.org/abs/2512.10657)
*Seth Siriya,Tobias M. Wolff,Victor G. Lopez,Matthias A. Müller*

Main category: eess.SY

TL;DR: 在甲状腺疾病药物剂量的模型驱动控制中，研究在不可观测内部激素与不规则采样条件下，基于样本的移动预测估计（MHE）对 pituitary-thyroid 循环模型的鲁棒性与估计误差进行验证，结果表明更高采样频率可在模型不确定性与剂量误报情形下降低估计误差且估计稳定。


<details>
  <summary>Details</summary>
Motivation: 解决内部激素浓度不可直接测量且血样测量的采样时点不规则的问题，从而实现对药物剂量的更精准控制，提升个体化治疗的安全性与有效性。

Method: 构建两种代表性 hypo- 与 hyperthyroidism 的 pituitary-thyroid 循环模型，将内部浓度作为状态变量；提出样本基可检测性概念以适应不规则采样；设计并实现样本基移动预测估计（MHE），对虚拟患者在不同采样方案下进行仿真与评估。

Result: 在所有场景中，估计器表现出鲁棒稳定性；更高的采样频率降低了估计误差，且在存在模型不确定性和剂量误报的条件下仍保持良好性能。

Conclusion: 该工作证明了在不规则抽样与不可直接观测状态下，样本基 MHE 具有良好鲁棒性和可行性，可用于甲状腺疾病的个性化药物剂量控制；未来工作可进一步在真实患者数据上进行验证，增强对模型不确定性的处理，并优化实时实现的计算性能。

Abstract: Model-based control techniques have recently been investigated for the recommendation of medication dosages to address thyroid diseases. These techniques often rely on knowledge of internal hormone concentrations that cannot be measured from blood samples. Moreover, the measurable concentrations are typically only obtainable at irregular sampling times. In this work, we empirically verify a notion of sample-based detectability that accounts for irregular sampling of the measurable concentrations on two pituitary-thyroid loop models representing patients with hypo- and hyperthyroidism, respectively, and include the internal concentrations as states. We then implement sample-based moving horizon estimation for the models, and test its performance on virtual patients across a range of sampling schemes. Our study shows robust stability of the estimator across all scenarios, and that more frequent sampling leads to less estimation error in the presence of model uncertainty and misreported dosages.

</details>


### [50] [Active prognosis and diagnosis of modular discrete-event systems](https://arxiv.org/abs/2512.10684)
*Shaopeng Hu,Shaowen Miao,Jan Komenda,Zhiwu Li*

Main category: eess.SY

TL;DR: 提出在离散事件系统(DES)中对预知性(prognosability)与诊断性(diagnosability)进行验证与强制，建立了与在子集不良语言上的前归一性(pre-normality)等价的关系，证明存在极大可控的、正常的、且具预知性/诊断性的语言子语言，并给出计算极大子语言的算法；还将该框架扩展至模块化DES，借助改进的前归一性实现局部子系统的全局一致性控制与诊断性保证。


<details>
  <summary>Details</summary>
Motivation: 在复杂的离散事件系统中，尽早且可靠地预测和诊断系统故障对保障安全性和性能至关重要。现有工作在模块化系统中难以实现全局性质的预知性/诊断性，因此需要理论等价性、极大子语言的存在性以及可计算算法来实现对单元及模块的可控、正常与预知/诊断子语言的构造与 enforcement。

Method: 建立预知性/诊断性与前归一性之间的等价性（分别在非故障语言子集和故障语言后缀上）；证明存在极大可控、正常且预知性/诊断性的子语言及其存在性；设计算法计算这些极大子语言，并将方法推广到模块化DES，通过改进的前归一性实现局部子系统的全局可控、正常与预知性/诊断性；给出实例以说明方法。

Result: 理论上给出预知性与诊断性的等价性、极大子语言的存在性和可计算性，以及模块化系统中局部控制器在全局层面实现可控、正常和预知/诊断性的结论；提供了用于实现的算法并通过示例验证有效性。

Conclusion: 提出的框架为在单体及模块化DES中强制实现预知性与诊断性提供了系统的理论基础和可执行算法，确保闭环系统在全局层面具备可控、正常以及预知性/诊断性，并对后续在复杂系统中的应用具有潜在现实意义。

Abstract: This paper addresses the verification and enforcement of prognosability and diagnosability for discreteevent systems (DESs) modeled by deterministic finite automata. We establish the equivalence between prognosability (respectively, diagnosability) and pre-normality over a subset of the non-faulty language (respectively, a suffix of the faulty language). We then demonstrate the existence of supremal prognosable (respectively, diagnosable) and normal sublanguages. Furthermore, an algorithm is then designed to compute the supremal controllable, normal, and prognosable (respectively, diagnosable) sublanguages. Since DESs are typically composed of multiple components operating in parallel, pure local supervisors are generally insufficient, as prognosability and diagnosability are global properties of a system. Given the limited work on enforcing prognosability or diagnosability in modular DESs, where these properties are enforced through local supervisors, this paper leverages a refined version of pre-normality to compute modular supervisors for local subsystems. The resulting closed-loop system is shown to be globally controllable, normal, and prognosable/ diagnosable. Examples are provided to illustrate the proposed method.

</details>


### [51] [Distribution-Free Stochastic MPC for Joint-in-Time Chance-Constrained Linear Systems](https://arxiv.org/abs/2512.10738)
*Lukas Vogel,Andrea Carron,Eleftherios E. Vlahakis,Dimos V. Dimarogonas*

Main category: eess.SY

TL;DR: 将 conformal prediction 应用于随机模型预测控制，利用有限样本误差区域来放宽联合时约束并提供形式保证，同时在未知扰动分布和噪声分布下实现递归可行性与闭环约束满足，且可扩展到输出反馈。


<details>
  <summary>Details</summary>
Motivation: 现有随机MPC往往依赖参数化、高斯假设或离线计算，本文提出一种低计算成本、具有形式保障的对未知扰动分布的鲁棒性处理方法，提升对联合时约束的可控性和可信度。

Method: 通过 conformal prediction 构建系统随机误差轨迹的有限样本置信区域，将概率约束转化为以置信集为基础的概率集合优化问题；采用 indirect feedback 与概率集合形成的递归可行性分析；拓展到输出反馈情形，在有噪声样本时仍能保证约束满足和递归可行性。

Result: 证明放宽后的优化问题在闭环下具有递归可行性，并满足联合概率约束；数值示例显示相较现有方法在有效性与计算成本上的优势。

Conclusion: 基于 CP 的框架为未知扰动分布下的线性系统提供一个轻量、带形式保证的联合时约束处理思路，且可扩展至输出反馈场景。

Abstract: This work presents a stochastic model predictive control (MPC) framework for linear systems subject to joint-in-time chance constraints under unknown disturbance distributions. Unlike existing stochastic MPC formulations that rely on parametric or Gaussian assumptions or require expensive offline computations, the proposed method leverages conformal prediction (CP) as a streamlined tool to construct finite-sample confidence regions for the system's stochastic error trajectories with minimal computational effort. These regions enable the relaxation of probabilistic constraints while providing formal guarantees. By employing an indirect feedback mechanism and a probabilistic set-based formulation, we prove recursive feasibility of the relaxed optimization problem and establish chance constraint satisfaction in closed-loop. Furthermore, we extend the approach to the more general output feedback setting with unknown measurement noise distributions. Given available noise samples, we establish satisfaction of the joint chance constraints and recursive feasibility via output measurements alone. Numerical examples demonstrate the effectiveness and advantages of the proposed method compared to existing approaches.

</details>


### [52] [Low-Order $\mathcal{H}_2 / \mathcal{H}_\infty$ Controller Design for Aeroelastic Vibration Suppression](https://arxiv.org/abs/2512.10841)
*Mohammad Mirtaba,Juan Augusto Paredes Salazar,Daning Huang,Ankit Goel*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents an $\mathcal{H}_2 / \mathcal{H}_\infty$ minimization-based output-feedback controller for active aeroelastic vibration suppression in a cantilevered beam. First, a nonlinear structural model incorporating moderate deflection and aerodynamic loading is derived and discretized using the finite element method (FEM). Then, a low-order linear model is identified from random gaussian input response data from the FEM model to synthesize an output-feedback controller using the $\mathcal{H}_2 / \mathcal{H}_\infty$ framework. A frequency-weighted dynamic filter is introduced to emphasize disturbance frequencies of interest, enabling the controller to target dominant vibration modes. Simulation results demonstrate the effectiveness of the proposed technique for vibration suppression and study its robustness to system parameter variations, including actuator placement.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [53] [Fourier Sparsity of Delta Functions and Matching Vector PIRs](https://arxiv.org/abs/2512.09941)
*Fatemeh Ghasemi,Swastik Kopparty*

Main category: cs.IT

TL;DR: 给出 delta 函数在傅里叶基中的稀疏度上下界，并据此限定基于匹配向量的PIR中通过改进 S 解码多项式无法实现常数服务器、polylog 级别通信的可能性。


<details>
  <summary>Details</summary>
Motivation: 将傅里叶分析应用到 {0,1}^r 上的 delta 函数，研究其在 Z_m^r 的傅里叶稀疏度，以揭示对 Matching Vector 基PIR 方案的潜在改进空间。

Method: 给出对 delta 函数的傅里叶稀疏度的非平凡上界和下界，证明其推导过程清晰、简洁；并将结果应用于分析 S 解码多项式在 MV-PIR 的作用与局限性。

Result: 得到关于 delta 函数傅里叶稀疏度的上下界，表明仅通过寻找更稀疏的 S 解码多项式，无法显著提升现有基于已知匹配向量族的 MV-PIR 的通信复杂度（在常数服务器条件下达到 polylog 级别）。

Conclusion: 研究揭示了对 MV-PIR 的一个重要限制，提出了若干未解的有趣问题，指向未来在傅里叶分析与 PIR 设计方面的进一步探索。

Abstract: In this paper we study a basic and natural question about Fourier analysis of Boolean functions, which has applications to the study of Matching Vector based Private Information Retrieval (PIR) schemes. For integers m and r, define a delta function on {0,1}^r to be a function f: Z_m^r -> C with f(0) = 1 and f(x) = 0 for all nonzero Boolean x. The basic question we study is how small the Fourier sparsity of a delta function can be; namely how sparse such an f can be in the Fourier basis?
  In addition to being intrinsically interesting and natural, such questions arise naturally when studying "S-decoding polynomials" for the known matching vector families. Finding S-decoding polynomials of reduced sparsity, which corresponds to finding delta functions with low Fourier sparsity, would improve the current best PIR schemes.
  We show nontrivial upper and lower bounds on the Fourier sparsity of delta functions. Our proofs are elementary and clean. These results imply limitations on improving Matching Vector PIR schemes simply by finding better S-decoding polynomials. In particular, there are no S-decoding polynomials that can make Matching Vector PIRs based on the known matching vector families achieve polylogarithmic communication with a constant number of servers. Many interesting questions remain open.

</details>


### [54] [Improving the decoding performance of CA-polar codes](https://arxiv.org/abs/2512.10223)
*Jiewei Feng,Peihong Yuan,Ken R. Duffy,Muriel Médard*

Main category: cs.IT

TL;DR: 通过使用与编码无关的解码器，将 CA-SCL 从不完整解码转变为完整解码；在 CRC 未通过时仍可找到通过 CRC 的码字，从而提升性能。


<details>
  <summary>Details</summary>
Motivation: 提升 CA-SCL 在 CRC 约束下的解码性能，解决 CRC 未通过时的解码不足，并研究系统化 CA-Polar 编码的潜在收益。

Method: 在 CRC 未通过时，应用与编码无关的解码器寻找满足 CRC 的码字；对 CA-Polar（5G NR 标准）与系统化 CA-Polar 进行对比评估；结合基于块的软输出以控制未检测错误率。

Result: 对于 CA-Polar（5G NR）的无系统编码，BLER 提升可达约 0.2 dB；若改为系统化 CA-Polar，提升范围为约 0.2 dB 至 1 dB；并且通过块式软输出实现对未检测错误率的控制。

Conclusion: 编码无关解码策略在保持 CRC 约束下可提升 CA-Polar 的解码性能，且系统化编码带来更显著的收益，同时能够通过软输出机制对未检测错误率进行控制。

Abstract: We investigate the use of modern code-agnostic decoders to convert CA-SCL from an incomplete decoder to a complete one. When CA-SCL fails to identify a codeword that passes the CRC check, we apply a code-agnostic decoder that identifies a codeword that satisfies the CRC. We establish that this approach gives gains of up to 0.2 dB in block error rate for CA-Polar codes from the 5G New Radio standard. If, instead, the message had been encoded in a systematic CA-polar code, the gain improves to 0.2 ~ 1dB. Leveraging recent developments in blockwise soft output, we additionally establish that it is possible to control the undetected error rate even when using the CRC for error correction.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [55] [L2 Ethernet Switch VLSI Implementation](https://arxiv.org/abs/2512.10318)
*Aniruddh Mishra,Benjamin Oommen,Jimmy Liang*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Ethernet switches are foundational to the global internet infrastructure. These devices route packets of data on a local area network between source addresses to destination media access control addresses. On the L2 layer of the Open Systems Interconnections model, Ethernet switches take in digitized data from a Media Independent Interface and send it to the corresponding output port for the destination address. Switches need to handle parallel input and output streams from each port, prioritizing throughput, efficiency, and packet integrity. Due to the confidential nature of the networking device industry, there do not exist many open source implementations of switching fabrics. We propose an open source design for an L2 Ethernet switch along with the power, performance, and area tradeoffs for architecture decisions.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [56] [Blockchain-Anchored Audit Trail Model for Transparent Inter-Operator Settlement](https://arxiv.org/abs/2512.09938)
*Balakumar Ravindranath Kunthu,Ranganath Nagesh Taware,Sathish Krishna Anumula*

Main category: cs.CR

TL;DR: 提出一个区块链锚定的审计追踪模型，用以实现跨运营商清算的透明、不可篡改和自动化，显著降低成本和时间，具备高吞吐、互操作性和合规性。


<details>
  <summary>Details</summary>
Motivation: 解决传统跨运营商清算中的长周期、高成本与低透明度等痛点；现有系统依赖多中介与人工，难以实现快速对账。

Method: 基于分布式账本、智能合约和加密验证，构建统一的不可篡改交易记录和自动化清算流程，提供跨域审计追踪与合规框架。

Result: 实验/评估显示交易费用下降87%，清算周期从120天缩短到3分钟，审计轨迹完整性达100%；智能合约将人工干预降低92%，清算争议减少88%；市场分析显示机构采用率从2020年的8%增至2024年4月的52%，行业投资预测为9.2十亿美元/年。

Conclusion: 该框架解决可扩展性、互操作性及跨司法辖合规性挑战，具备每秒12,000笔交易的吞吐能力。

Abstract: The telecommunications and financial services industries face substantial challenges in inter-operator settlement processes, characterized by extended reconciliation cycles, high transaction costs, and limited real-time transparency. Traditional settlement mechanisms rely on multiple intermediaries and manual procedures, resulting in settlement periods exceeding 120 days with operational costs consuming approximately 5 percent of total revenue. This research presents a blockchain-anchored audit trail model enabling transparent, immutable, and automated inter-operator settlement. The framework leverages distributed ledger technology, smart contract automation, and cryptographic verification to establish a unified, tamper-proof transaction record. Empirical evaluation demonstrates 87 percent reduction in transaction fees, settlement cycle compression from 120 days to 3 minutes, and 100 percent audit trail integrity. Smart contract automation reduces manual intervention by 92 percent and eliminates 88 percent of settlement disputes. Market analysis indicates institutional adoption accelerated from 8 percent in 2020 to 52 percent by April 2024, with projected industry investment reaching 9.2 billion USD annually. The framework addresses scalability (12,000 transactions per second), interoperability, and regulatory compliance across multiple jurisdictions.

</details>


### [57] [ZK-APEX: Zero-Knowledge Approximate Personalized Unlearning with Executable Proofs](https://arxiv.org/abs/2512.09953)
*Mohammad M Maheri,Sunil Cotterill,Alex Davidson,Hamed Haddadi*

Main category: cs.CR

TL;DR: 提出 ZK APEX，在边缘设备上实现零重训练的个性化去学习，结合提供方的稀疏屏蔽和客户端的小规模 Group OBS 补偿，以及 Halo2 的零知识证明，在不暴露私有数据或个性化参数的前提下实现可验证的去学习。


<details>
  <summary>Details</summary>
Motivation: 在全球模型分发到大量边缘设备、用户使用私有数据进行本地个性化的情境下，删除请求可能被忽略或被伪造，提供方也难以验证每个设备的参数和数据。需要一个低开销且可验证的去学习方法，在尽量保留本地任务性能的同时，确保删除信息被真正忘记，并且验证在边缘设备上保持轻量。

Method: 提出 ZK APEX：直接在个性化模型上实现去学习，无需再训练。通过提供方的稀疏屏蔽与客户端的小型 Group OBS 补偿，以及基于块的经验Fisher矩阵来构造具有曲率感知的更新，以降低开销。再结合 Halo2 零知识证明，证明正确的去学习变换已应用且不暴露私有数据或个性化参数。

Result: 在视觉Transformer分类任务上，几乎恢复所有个性化精度，同时有效去除目标信息；在 OPT125M 的代码数据模型上，恢复约原始精度的70%。证据生成对 ViT 案例约两小时，是基于重新训练的检查速度的十万倍级别提升，内存耗<1GB，证据大小约400MB。则首次呈现了一个在边缘设备上可行的可验证个性化去学习框架。

Conclusion: 本工作首次将 verifiable personalized unlearning 引入到可在边缘设备上运行的实际框架中，结合分布式模型、轻量更新与零知识证明，兼顾隐私、合规与性能，开启了边缘端可验证去学习的新方向。

Abstract: Machine unlearning aims to remove the influence of specific data points from a trained model to satisfy privacy, copyright, and safety requirements. In real deployments, providers distribute a global model to many edge devices, where each client personalizes the model using private data. When a deletion request is issued, clients may ignore it or falsely claim compliance, and providers cannot check their parameters or data. This makes verification difficult, especially because personalized models must forget the targeted samples while preserving local utility, and verification must remain lightweight on edge devices.
  We introduce ZK APEX, a zero-shot personalized unlearning method that operates directly on the personalized model without retraining. ZK APEX combines sparse masking on the provider side with a small Group OBS compensation step on the client side, using a blockwise empirical Fisher matrix to create a curvature-aware update designed for low overhead. Paired with Halo2 zero-knowledge proofs, it enables the provider to verify that the correct unlearning transformation was applied without revealing any private data or personalized parameters.
  On Vision Transformer classification tasks, ZK APEX recovers nearly all personalization accuracy while effectively removing the targeted information. Applied to the OPT125M generative model trained on code data, it recovers around seventy percent of the original accuracy. Proof generation for the ViT case completes in about two hours, more than ten million times faster than retraining-based checks, with less than one gigabyte of memory use and proof sizes around four hundred megabytes. These results show the first practical framework for verifiable personalized unlearning on edge devices.

</details>


### [58] [TRUCE: TRUsted Compliance Enforcement Service for Secure Health Data Exchange](https://arxiv.org/abs/2512.09959)
*Dae-young Kim,Karuna Pande Joshi*

Main category: cs.CR

TL;DR: A novel TRUCE framework automates regulatory-compliant secure data exchange using context-aware trust scoring, validated against HIPAA DUA with up to 1M records; enables real-time, large-volume compliance.


<details>
  <summary>Details</summary>
Motivation: Rising sharing of sensitive PII and regulatory conflicts (e.g., HIPAA vs. Cures Act) create complexity in health data compliance; there is a need for automated, trustworthy data management to protect privacy.

Method: AI/Knowledge representation and Semantic Web techniques for context-aware reasoning. A trust management component combines static ground truth (regulations like HIPAA) with dynamic ground truth (organizational policies) to assess data exchange, user trust, and data veracity.

Result: Validation against HIPAA Data Usage Agreement (DUA) on CDC Contact Tracing patient data, up to one million records. TRUCE enables streamlined compliance for large-velocity data exchanges in real time.

Conclusion: TRUCE can streamline privacy-compliant data exchange, enforce regulatory adherence in real time, and assist organizations in managing compliance for high-volume data sharing.

Abstract: Organizations are increasingly sharing large volumes of sensitive Personally Identifiable Information (PII), like health records, with each other to better manage their services. Protecting PII data has become increasingly important in today's digital age, and several regulations have been formulated to ensure the secure exchange and management of sensitive personal data. However, at times some of these regulations are at loggerheads with each other, like the Health Insurance Portability and Accountability Act (HIPAA) and Cures Act; and this adds complexity to the already challenging task of Health Data compliance. As public concern regarding sensitive data breaches grows, finding solutions that streamline compliance processes and enhance individual privacy is crucial. We have developed a novel TRUsted Compliance Enforcement (TRUCE) framework for secure data exchange which aims to automate compliance procedures and enhance trusted data management within organizations. The TRUCE framework reasons over contexts of data exchange and assesses the trust score of users and the veracity of data based on corresponding regulations. This framework, developed using approaches from AI/Knowledge representation and Semantic Web technologies, includes a trust management method that incorporates static ground truth, represented by regulations such as HIPAA, and dynamic ground truth, defined by an organization's policies. In this paper, we present our framework in detail along with the validation against the Health Insurance Portability and Accountability Act (HIPAA) Data Usage Agreement (DUA) on CDC Contact Tracing patient data, up to one million patient records. TRUCE service will streamline compliance efforts and ensure adherence to privacy regulations and can be used by organizations to manage compliance of large velocity data exchange in real time.

</details>


### [59] [A Comparative Analysis of zk-SNARKs and zk-STARKs: Theory and Practice](https://arxiv.org/abs/2512.10020)
*Ayush Nainwal,Atharva Kamble,Nitin Awathare*

Main category: cs.CR

TL;DR: 对比 zk-SNARK（Groth16）与 zk-STARKs 在实际实现层面的性能：在消费级 ARM 平台上，SNARK 在证明生成速度和证明大小方面显著优于 STARK；而 STARK 在验证速度和透明性/抗量子性方面具有优势，但需要更大的证明。


<details>
  <summary>Details</summary>
Motivation: 在真实世界条件下评估两类主流零知识证明体系的实际性能与权衡，以指导开发者在隐私交易、可验证计算与可扩展性方案中的选型与优化。

Method: 基于公开的参考实现，在消费级 ARM 平台上进行实现级基准测试，比较两者的证明生成时间、验证时延、证明大小，并进行 CPU 配置分析以定位计算瓶颈。

Result: 结果显示：zk-SNARKs（Groth16）在证明生成方面快约 68 倍，证明尺寸小约 123 倍；但验证阶段较慢且需要受信任设置。zk-STARKs 尽管生成慢且证明更大，但验证更快、保持透明性且对量子安全。CPU profiling 发现两者在计算瓶颈上存在显著差异，受执行模型与实现细节影响显著。

Conclusion: 该对比为开发者、协议设计者和研究人员提供了在不同应用场景（隐私交易、可验证计算、可扩展性聚合）中选择与优化证明系统的操作性洞见，强调实现细节和运行环境对实际性能的决定性作用。

Abstract: Zero-knowledge proofs (ZKPs) are central to secure and privacy-preserving computation, with zk-SNARKs and zk-STARKs emerging as leading frameworks offering distinct trade-offs in efficiency, scalability, and trust assumptions. While their theoretical foundations are well studied, practical performance under real-world conditions remains less understood.
  In this work, we present a systematic, implementation-level comparison of zk-SNARKs (Groth16) and zk-STARKs using publicly available reference implementations on a consumer-grade ARM platform. Our empirical evaluation covers proof generation time, verification latency, proof size, and CPU profiling. Results show that zk-SNARKs generate proofs 68x faster with 123x smaller proof size, but verify slower and require trusted setup, whereas zk-STARKs, despite larger proofs and slower generation, verify faster and remain transparent and post-quantum secure. Profiling further identifies distinct computational bottlenecks across the two systems, underscoring how execution models and implementation details significantly affect real-world performance. These findings provide actionable insights for developers, protocol designers, and researchers in selecting and optimizing proof systems for applications such as privacy-preserving transactions, verifiable computation, and scalable rollups.

</details>


### [60] [Malicious GenAI Chrome Extensions: Unpacking Data Exfiltration and Malicious Behaviours](https://arxiv.org/abs/2512.10029)
*Shresta B. Seetharam,Mohamed Nabeel,William Melicher*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid proliferation of AI and GenAI tools has extended to the Chrome Web Store. Cybercriminals are exploiting this trend, deploying malicious Chrome extensions posing as AI tools or impersonating popular GenAI models to target users. These extensions often appear legitimate while secretly exfiltrating sensitive data or redirecting users web traffic to attacker-controlled domains.
  To examine the impact of this trend on the browser extension ecosystem, we curated a dataset of 5,551 AI-themed extensions released over a nine-month period to the Chrome Web Store. Using a multi-signal detection methodology that combines manifest analysis, domain reputation, and runtime network behavior, supplemented with human review, we identified 154 previously undetected malicious Chrome extensions. Together with extensions known from public threat research disclosures, this resulted in a final set of 341 malicious extensions for analysis. Of these, 29 were GenAI-related, forming the focus of our in-depth analysis and disclosure.
  We deconstruct representative GenAI cases, including Supersonic AI, DeepSeek AI | Free AI Assistant, and Perplexity Search, to illustrate attacker techniques such as Adversary-in-the-Browser, impersonation, bait-and-switch updates, query hijacking, and redirection. Our findings show that threat actors are leveraging GenAI trends and exploiting browser extension APIs and settings for malicious purposes. This demonstrates that the browser extension threat landscape is directly evolving alongside the rapid adoption of GenAI technologies.

</details>


### [61] [LLM-PEA: Leveraging Large Language Models Against Phishing Email Attacks](https://arxiv.org/abs/2512.10104)
*Najmul Hassan,Prashanth BusiReddyGari,Haitao Zhao,Yihao Ren,Jinsheng Xu,Shaohu Zhang*

Main category: cs.CR

TL;DR: 提出 LLMPEA 框架用于跨多向攻击的钓鱼邮件检测，实验表明高达90%+准确率，但也暴露对对抗性攻击、提示注入与多语言攻击的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 随着系统部署LLMs的邮件安全应用，钓鱼攻击在多种向量上利用架构脆弱性，迫切需要在多向向量下的鲁棒检测与防御策略。

Method: 设计并评估 LLMPEA 框架，使用三种前沿LLM（GPT-4o、Claude Sonnet 4、Grok-3）及全面的提示设计，测试跨提示、文本改写、多语言等多向量攻击，对检测可行性、鲁棒性与局限性进行实证分析。

Result: 在实验中，LLMs 能以超过90%准确率检测钓鱼邮件，但也发现可被对抗攻击、提示注入和多语言攻击所利用，需要谨慎部署。

Conclusion: LLM 基于钓鱼检测具有潜力，但需要强化对抗性防御、提示设计与系统级安全性，以实现现实世界的可靠部署。

Abstract: Email phishing is one of the most prevalent and globally consequential vectors of cyber intrusion. As systems increasingly deploy Large Language Models (LLMs) applications, these systems face evolving phishing email threats that exploit their fundamental architectures. Current LLMs require substantial hardening before deployment in email security systems, particularly against coordinated multi-vector attacks that exploit architectural vulnerabilities. This paper proposes LLMPEA, an LLM-based framework to detect phishing email attacks across multiple attack vectors, including prompt injection, text refinement, and multilingual attacks. We evaluate three frontier LLMs (e.g., GPT-4o, Claude Sonnet 4, and Grok-3) and comprehensive prompting design to assess their feasibility, robustness, and limitations against phishing email attacks. Our empirical analysis reveals that LLMs can detect the phishing email over 90% accuracy while we also highlight that LLM-based phishing email detection systems could be exploited by adversarial attack, prompt injection, and multilingual attacks. Our findings provide critical insights for LLM-based phishing detection in real-world settings where attackers exploit multiple vulnerabilities in combination.

</details>


### [62] [Watermarks for Language Models via Probabilistic Automata](https://arxiv.org/abs/2512.10185)
*Yangkun Wang,Jingbo Shang*

Main category: cs.CR

TL;DR: 通过概率自动机构建的新型水印方案，解决了失真嵌入、对抗编辑距离攻击的鲁棒性等问题，同时提供实践与理论两种实现，实验表明在LLaMA-3B及Mistral-7B上具有较高的生成多样性和检测效率。


<details>
  <summary>Details</summary>
Motivation: 现有水印方案在嵌入失真、鲁棒性与生成多样性之间存在权衡，且检测成本高/难以实现不可检测性。需要一种在多样性、效率和不可检测性之间更平衡的方案。

Method: 基于概率自动机构造水印方案，提出两种实现：1) 实用型，具有指数级的生成多样性且计算高效；2) 理论型，在密码学假设下提供形式化的不可检测性保证。通过对大型语言模型（如 LLaMA-3B、Mistral-7B）的广泛实验验证。

Result: 在鲁棒性与效率方面优于现有方案，具有极高的生成多样性和可扩展性，理论保证在某些假设下成立，实验结果支持其在实际大型语言模型上的有效性。

Conclusion: 提出一种新类水印方案，兼具不可检测性证明与实践性能，可显著提高对抗攻击的鲁棒性与应用场景的可扩展性。

Abstract: A recent watermarking scheme for language models achieves distortion-free embedding and robustness to edit-distance attacks. However, it suffers from limited generation diversity and high detection overhead. In parallel, recent research has focused on undetectability, a property ensuring that watermarks remain difficult for adversaries to detect and spoof. In this work, we introduce a new class of watermarking schemes constructed through probabilistic automata. We present two instantiations: (i) a practical scheme with exponential generation diversity and computational efficiency, and (ii) a theoretical construction with formal undetectability guarantees under cryptographic assumptions. Extensive experiments on LLaMA-3B and Mistral-7B validate the superior performance of our scheme in terms of robustness and efficiency.

</details>


### [63] [FLARE: A Wireless Side-Channel Fingerprinting Attack on Federated Learning](https://arxiv.org/abs/2512.10296)
*Md Nahid Hasan Shuvo,Moinul Hossain,Anik Mallik,Jeffrey Twigg,Fikadu Dagefu*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Federated Learning (FL) enables collaborative model training across distributed devices while safeguarding data and user privacy. However, FL remains susceptible to privacy threats that can compromise data via direct means. That said, indirectly compromising the confidentiality of the FL model architecture (e.g., a convolutional neural network (CNN) or a recurrent neural network (RNN)) on a client device by an outsider remains unexplored. If leaked, this information can enable next-level attacks tailored to the architecture. This paper proposes a novel side-channel fingerprinting attack, leveraging flow-level and packet-level statistics of encrypted wireless traffic from an FL client to infer its deep learning model architecture. We name it FLARE, a fingerprinting framework based on FL Architecture REconnaissance. Evaluation across various CNN and RNN variants-including pre-trained and custom models trained over IEEE 802.11 Wi-Fi-shows that FLARE achieves over 98% F1-score in closed-world and up to 91% in open-world scenarios. These results reveal that CNN and RNN models leak distinguishable traffic patterns, enabling architecture fingerprinting even under realistic FL settings with hardware, software, and data heterogeneity. To our knowledge, this is the first work to fingerprint FL model architectures by sniffing encrypted wireless traffic, exposing a critical side-channel vulnerability in current FL systems.

</details>


### [64] [Bit of a Close Talker: A Practical Guide to Serverless Cloud Co-Location Attacks](https://arxiv.org/abs/2512.10361)
*Wei Shao,Najmeh Nazari,Behnam Omidi,Setareh Rafatirad,Houman Homayoun,Khaled N. Khasawneh,Chongzhou Fang*

Main category: cs.CR

TL;DR: 提出了一种针对服务端无服务器云调度器的共定位攻击的研究框架，旨在揭示可被滥用的特征并通过正常用户接口构造共定位攻击，同时给出缓解策略。


<details>
  <summary>Details</summary>
Motivation: 在无服务器计算广泛部署的背景下，调度器的安全性成为关键问题。共定位攻击可利用物理共处和调度器行为泄露敏感信息，因此需要理解和评估现有调度算法的安全性以防止潜在攻击。

Method: 提出一套覆盖从特征挖掘到攻击构造的综合方法学，利用正常用户界面进行共定位攻击的实现，且在开源实现与微软 Azure Functions 上进行实验验证以揭示可利用的漏洞。

Result: 实验表明存在可利用的脆弱性，能够在主流开源基础设施和 Azure Functions 上实现实例共定位，并提出了相应的缓解策略。

Conclusion: 该工作强调了服务器无服务器云调度器的安全薄弱点，为今后安全增强和防御共定位攻击提供了方向，但需要在更广泛的环境和长期评估中验证缓解策略的有效性。

Abstract: Serverless computing has revolutionized cloud computing by offering an efficient and cost-effective way for users to develop and deploy applications without managing infrastructure details. However, serverless cloud users remain vulnerable to various types of attacks, including micro-architectural side-channel attacks. These attacks typically rely on the physical co-location of victim and attacker instances, and attackers will need to exploit cloud schedulers to achieve co-location with victims. Therefore, it is crucial to study vulnerabilities in serverless cloud schedulers and assess the security of different serverless scheduling algorithms. This study addresses the gap in understanding and constructing co-location attacks in serverless clouds. We present a comprehensive methodology to uncover exploitable features in serverless scheduling algorithms and devise strategies for constructing co-location attacks through normal user interfaces. In our experiments, we successfully reveal exploitable vulnerabilities and achieve instance co-location on prevalent open-source infrastructures and Microsoft Azure Functions. We also present a mitigation strategy to defend against co-location attacks in serverless clouds. Our work highlights critical areas for security enhancements in current cloud schedulers, offering insights to fortify serverless computing environments against potential co-location attacks.

</details>


### [65] [Differential Privacy for Secure Machine Learning in Healthcare IoT-Cloud Systems](https://arxiv.org/abs/2512.10426)
*N Mangala,Murtaza Rangwala,S Aishwarya,B Eswara Reddy,Rajkumar Buyya,KR Venugopal,SS Iyengar,LM Patnaik*

Main category: cs.CR

TL;DR: 提出一个多层物联网-边缘云架构，结合差分隐私与混合噪声机制以提升急救场景下的响应速度与隐私保护，同时通过区块链确保安全通信，边缘计算显著降低延迟。


<details>
  <summary>Details</summary>
Motivation: 医疗保健数据驱动应用对实时性与隐私保护提出更高要求。现有系统在紧急响应和隐私保护方面存在挑战，需要在架构分层、隐私机制与安全通信之间取得更好的权衡。

Method: 设计多层IoT-Edge-Cloud架构，依据响应性和存储持续性对任务进行分配；提出差分隐私框架覆盖K-means、逻辑回归、随机森林、朴素贝叶斯等模型，比较Laplace、Gaussian及混合噪声机制，并给出自适应预算分配的混合Laplace-Gaussian噪声策略；构建威胁模型并评估在不同隐私预算下的攻击抵抗（如属性推断和数据重构），在ε=5.0时监督学习算法 achieves 82-84%的准确率并减少属性推断攻击18%及数据重构相关性70%；引入区块链实现时间戳、可追溯性与不可篡改性，确保分析应用的可信通信；在边缘计算实现8倍延迟降低，验证该分层架构在时间敏感场景中的有效性。

Result: 监督学习算法在多种隐私噪声机制下最高可达约86%准确率；在ε=5.0时准确率约82-84%；属性推断攻击降低至18%以下，数据重构相关性降低约70%；边缘计算带来约8×的延迟降低，提升急救场景的实时性。

Conclusion: 该研究提出的多层IoT-Edge-Cloud与差分隐私相结合的架构，在提升急救场景响应速度的同时实现隐私保护的平衡；混合拉普拉斯-高斯噪声及自适应预算分配提升隐私保护与数据有效性之间的折中，区块链与边缘计算进一步增强系统的安全性与实时性。

Abstract: Healthcare has become exceptionally sophisticated, as wearables and connected medical devices are revolutionising remote patient monitoring, emergency response, medication management, diagnosis, and predictive and prescriptive analytics. Internet of Things and Cloud computing integrated systems (IoT-Cloud) facilitate sensing, automation, and processing for these healthcare applications. While real-time response is crucial for alleviating patient emergencies, protecting patient privacy is extremely important in data-driven healthcare. In this paper, we propose a multi-layer IoT, Edge and Cloud architecture to enhance the speed of response for emergency healthcare by distributing tasks based on response criticality and permanence of storage. Privacy of patient data is assured by proposing a Differential Privacy framework across several machine learning models such as K-means, Logistic Regression, Random Forest and Naive Bayes. We establish a comprehensive threat model identifying three adversary classes and evaluate Laplace, Gaussian, and hybrid noise mechanisms across varying privacy budgets, with supervised algorithms achieving up to 86% accuracy. The proposed hybrid Laplace-Gaussian noise mechanism with adaptive budget allocation provides a balanced approach, offering moderate tails and better privacy-utility trade-offs for both low and high dimension datasets. At the practical threshold of $\varepsilon = 5.0$, supervised algorithms achieve 82-84% accuracy while reducing attribute inference attacks by up to 18% and data reconstruction correlation by 70%. Blockchain security further ensures trusted communication through time-stamping, traceability, and immutability for analytics applications. Edge computing demonstrates 8$\times$ latency reduction for emergency scenarios, validating the hierarchical architecture for time-critical operations.

</details>


### [66] [Stealth and Evasion in Rogue AP Attacks: An Analysis of Modern Detection and Bypass Techniques](https://arxiv.org/abs/2512.10470)
*Kaleb Bacztub,Braden Vester,Matteo Hodge,Liulseged Abate*

Main category: cs.CR

TL;DR: 本研究展示了一种隐蔽的Rogue AP/ Evil Twin攻击，并评估了现有NIDS（如Suricata）对2层无线威胁的检测能力，结果显示对无线管理帧攻击存在显著盲区。


<details>
  <summary>Details</summary>
Motivation: 填补对Layer-2无线威胁检测不足的学术空白，评估主流开源NIDS在现实无线攻击场景中的检测能力与局限性，并提出对防御架构的改进需求。

Method: 初始在树莓派等硬件平台进行部署，因兼容性问题转为虚拟化环境；使用Wifipumpkin3构建 captive portal以劫持和收集设备凭证；对攻击过程进行建模并在Suricata环境中测试检测效果，分析回避手段与系统局限。

Result: Suricata未能识别攻击流量，暴露了现有入侵检测系统在无线管理帧攻击方面的明显盲区；研究详细描述了攻击构建、规避技术及NIDS在局部无线威胁检测方面的不足。

Conclusion: 当前NIDS对无线层面威胁的检测能力不足，需要在无线访问点层面、管理帧异常检测以及更贴近无线攻击场景的综合防御策略方面进行改进。

Abstract: Wireless networks act as the backbone of modern digital connectivity, making them a primary target for cyber adversaries. Rogue Access Point attacks, specifically the Evil Twin variant, enable attackers to clone legitimate wireless network identifiers to deceive users into connecting. Once a connection is established, the adversary can intercept traffic and harvest sensitive credentials. While modern defensive architectures often employ Network Intrusion Detection Systems (NIDS) to identify malicious activity, the effectiveness of these systems against Layer 2 wireless threats remains a subject of critical inquiry. This project aimed to design a stealth-capable Rogue AP and evaluate its detectability against Suricata, an open-source NIDS/IPS. The methodology initially focused on a hardware-based deployment using Raspberry Pi platforms but transitioned to a virtualized environment due to severe system compatibility issues. Using Wifipumpkin3, the research team successfully deployed a captive portal that harvested user credentials from connected devices. However, the Suricata NIDS failed to flag the attack, highlighting a significant blind spot in traditional intrusion detection regarding wireless management frame attacks. This paper details the construction of the attack, the evasion techniques employed, and the limitations of current NIDS solutions in detecting localized wireless threats

</details>


### [67] [From Lab to Reality: A Practical Evaluation of Deep Learning Models and LLMs for Vulnerability Detection](https://arxiv.org/abs/2512.10485)
*Chaomeng Lu,Bert Lagaisse*

Main category: cs.CR

TL;DR: 基于DL的漏洞检测在基准数据上表现出色，但对真实世界部署却缺乏鲁棒性；通过部署导向的评估框架揭示学术基准与实际场景之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有GNN/Transformer/LLM在整齐且带噪声标注的基准数据上表现良好，但对具有不同分布的真实世界数据的泛化能力和鲁棒性不足，亟需部署导向的评估与更高质量的数据集。

Method: 系统评估两种代表性DL模型ReVeal和LineVul，在四个数据集（Juliet、Devign、BigVul、ICVul）上独立训练；对代码表示进行t-SNE分析以揭示漏洞相关模式；在VentiVul（包含20个最近的Linux内核漏洞）上，结合四个预训练LLM（Claude 3.5 Sonnet、GPT-o3-mini、GPT-4o、GPT-5）进行部署评估，进行时序分布外的评估。

Result: 在表示空间中，现有模型难以将漏洞与非漏洞区分开来；跨数据集的泛化性差；在VentiVul上性能显著下降，大多数模型无法可靠检测漏洞。

Conclusion: 学术基准与真实世界部署之间存在持续性差距；需要面向部署的评估框架、更加鲁棒的代码表征，以及更高质量的数据集来提升实用性。

Abstract: Vulnerability detection methods based on deep learning (DL) have shown strong performance on benchmark datasets, yet their real-world effectiveness remains underexplored. Recent work suggests that both graph neural network (GNN)-based and transformer-based models, including large language models (LLMs), yield promising results when evaluated on curated benchmark datasets. These datasets are typically characterized by consistent data distributions and heuristic or partially noisy labels. In this study, we systematically evaluate two representative DL models-ReVeal and LineVul-across four representative datasets: Juliet, Devign, BigVul, and ICVul. Each model is trained independently on each respective dataset, and their code representations are analyzed using t-SNE to uncover vulnerability related patterns. To assess realistic applicability, we deploy these models along with four pretrained LLMs, Claude 3.5 Sonnet, GPT-o3-mini, GPT-4o, and GPT-5 on a curated dataset, VentiVul, comprising 20 recently (May 2025) fixed vulnerabilities from the Linux kernel. Our experiments reveal that current models struggle to distinguish vulnerable from non-vulnerable code in representation space and generalize poorly across datasets with differing distributions. When evaluated on VentiVul, our newly constructed time-wise out-of-distribution dataset, performance drops sharply, with most models failing to detect vulnerabilities reliably. These results expose a persistent gap between academic benchmarks and real-world deployment, emphasizing the value of our deployment-oriented evaluation framework and the need for more robust code representations and higher-quality datasets.

</details>


### [68] [Authority Backdoor: A Certifiable Backdoor Mechanism for Authoring DNNs](https://arxiv.org/abs/2512.10600)
*Han Yang,Shaofeng Li,Tian Dong,Xiangyu Xu,Guangchi Liu,Zhen Ling*

Main category: cs.CR

TL;DR: 提出了一种主动式权威保护方案 Authority Backdoor，通过在模型内部植入访问约束，使模型仅在特定触发器存在时才正常工作；在缺失触发器时模型性能下降以防止盗用，且结合可证实鲁棒性以防止自适应攻击，实验验证了其有效性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为DNNs的知识产权提供主动保护，弥补现有数字水印等被动保护只能事后验证的不足，避免模型被未授权使用。

Method: 通过背门学习框架在模型中嵌入访问约束，使模型在特定触发器（如硬件指纹）存在时才具备正常功能，若触发器缺失则性能降级，同时引入可证实鲁棒性以抵抗移除背门的自适应攻击。

Result: 在多种架构和数据集上进行广泛实验，证实该框架的有效性与可证实鲁棒性。

Conclusion: 该框架将访问控制与可证实鲁棒性结合，提供一种安全的DNN权威机制，有望解决DNN知识产权保护中的主动防护需求。

Abstract: Deep Neural Networks (DNNs), as valuable intellectual property, face unauthorized use. Existing protections, such as digital watermarking, are largely passive; they provide only post-hoc ownership verification and cannot actively prevent the illicit use of a stolen model. This work proposes a proactive protection scheme, dubbed ``Authority Backdoor," which embeds access constraints directly into the model. In particular, the scheme utilizes a backdoor learning framework to intrinsically lock a model's utility, such that it performs normally only in the presence of a specific trigger (e.g., a hardware fingerprint). But in its absence, the DNN's performance degrades to be useless. To further enhance the security of the proposed authority scheme, the certifiable robustness is integrated to prevent an adaptive attacker from removing the implanted backdoor. The resulting framework establishes a secure authority mechanism for DNNs, combining access control with certifiable robustness against adversarial attacks. Extensive experiments on diverse architectures and datasets validate the effectiveness and certifiable robustness of the proposed framework.

</details>


### [69] [Objectives and Design Principles in Offline Payments with Central Bank Digital Currency (CBDC)](https://arxiv.org/abs/2512.10636)
*David-Alexandre Guiraud,Andrea Tundis,Marc Winstel*

Main category: cs.CR

TL;DR: 提出离线功能的CBDC设计原则及对策，聚焦访问控制安全、存款人行为安全和隐私保护三大目标，并将它们映射到具体对策；认为在系统中引入安全硬件有助于防止双花等攻击。


<details>
  <summary>Details</summary>
Motivation: 在离线模式下保持资金安全、钱包完整性与用户隐私，同时实现可扩展的央行数字货币框架。

Method: 以概念分析为主，识别三大目标并将其与可执行的设计要素/对策对应，讨论不同目标间的相互干扰性及潜在实现路径（如安全硬件的应用）。

Result: 提出一个统一的设计框架，三大目标可通过特定对策实现，某些目标与对策之间基本不冲突；以安全硬件实现钱包完整性、防止双花为例。

Conclusion: 将离线CBDC的设计要素与对策整合，形成一致的实现路径，安全硬件被视为实现核心机制之一。

Abstract: In this work, fundamental design principles for a central bank digital currency (CBDC) with an offline functionality and corresponding counter measures are discussed. We identify three major objectives for any such CBDC proposal:(i) Access Control Security - protection of a user's funds against unauthorized access by other users; (ii) Security against Depositor's Misbehavior - preservation of the integrity of an environment (potentially the wallet) against misbehavior of its owner (for example, double-spending), and (iii) Privacy by Design - ensuring privacy is embedded into the system architecture. Our central conclusion is the alignment of the objectives to concrete design elements as countermeasures, whereas certain objectives and countermeasures have no or minimal interferences with each other. For example, we work out that the integrity of a user's wallet and, accordingly, the prevention of double-spending race attacks should be addressed through the adoption and integration of \textit{secure hardware} within a CBDC system.

</details>


### [70] [Virtual camera detection: Catching video injection attacks in remote biometric systems](https://arxiv.org/abs/2512.10653)
*Daniyar Kurmankhojayev,Andrei Shadrikov,Dmitrii Gordin,Mikhail Shkorin,Danijar Gabdullin,Aigerim Kambetbayeva,Kanat Kuatov*

Main category: cs.CR

TL;DR: 提出一种基于会话元数据的机器学习虚拟摄像头检测（VCD）方法，用于提升面部防欺诈中的视频注入攻击识别能力。


<details>
  <summary>Details</summary>
Motivation: 视频注入攻击（如深度伪造和虚拟摄像头）对面部识别系统的完整性构成新威胁，而现有VCD研究在实用性评估方面不足。

Method: 在真实用户会话中收集的元数据上训练ML模型，用于VCD，设计并验证该方法，强调从认证用户的会话元数据中学习。

Result: 实证结果表明该VCD方法能有效识别视频注入尝试，降低绕过FAS系统的风险。

Conclusion: 基于元数据的ML-VCD为实际场景中的视频注入攻击防护提供一种可行、易部署的解决方案，需进一步在多场景与不同硬件上评估与确保隐私合规。

Abstract: Face anti-spoofing (FAS) is a vital component of remote biometric authentication systems based on facial recognition, increasingly used across web-based applications. Among emerging threats, video injection attacks -- facilitated by technologies such as deepfakes and virtual camera software -- pose significant challenges to system integrity. While virtual camera detection (VCD) has shown potential as a countermeasure, existing literature offers limited insight into its practical implementation and evaluation. This study introduces a machine learning-based approach to VCD, with a focus on its design and validation. The model is trained on metadata collected during sessions with authentic users. Empirical results demonstrate its effectiveness in identifying video injection attempts and reducing the risk of malicious users bypassing FAS systems.

</details>


### [71] [A Proof of Success and Reward Distribution Protocol for Multi-bridge Architecture in Cross-chain Communication](https://arxiv.org/abs/2512.10667)
*Damilare Peter Oyinloye,Mohd Sameen Chishti,Jingyue Li*

Main category: cs.CR

TL;DR: PSCRD 提出了一种多桥响应协调与奖励分配协议，用以提升跨链桥的去中心化与鲁棒性，同时保持较低用户成本。


<details>
  <summary>Details</summary>
Motivation: 解决单桥跨链方案的中心化和单点故障风险，通过公平的奖励分配激励桥参与。

Method: 提出 Proof of Success and Reward Distribution (PSCRD) 框架，设计多桥协同响应与激励分配算法，结合理论分析与仿真评估。

Result: 仿真和分析显示：Gini 指数随新桥加入逐步下降，奖励分配更公平；Nakamoto 系数随时间提高，去中心化显著提升；用户成本未显著增加。

Conclusion: PSCRD 提供更具鲁棒性和安全性的跨链桥体系，降低单点故障风险并提高去中心化程度。

Abstract: Single-bridge blockchain solutions enable cross-chain communication. However, they are associated with centralization and single-point-of-failure risks. This paper proposes Proof of Success and Reward Distribution (PSCRD), a novel multi-bridge response coordination and incentive distribution protocol designed to address the challenges. PSCRD introduces a fair reward distribution system that equitably distributes the transfer fee among participating bridges, incentivizing honest behavior and sustained commitment. The purpose is to encourage bridge participation for higher decentralization and lower single-point-of-failure risks. The mathematical analysis and simulation results validate the effectiveness of PSCRD using two key metrics: the Gini index, which demonstrates a progressive improvement in the fairness of the reward distribution as new bridge groups joined the network; and the Nakamoto coefficient, which shows a significant improvement in decentralization over time. These findings highlight that PSCRD provides a more resilient and secure cross-chain bridge system without substantially increasing user costs.

</details>


### [72] [TriHaRd: Higher Resilience for TEE Trusted Time](https://arxiv.org/abs/2512.10732)
*Matthieu Bettinger,Sonia Ben Mokhtar,Pascal Felber,Etienne Rivière,Valerio Schiavoni,Anthony Simonet-Boulogne*

Main category: cs.CR

TL;DR: TriHaRd is a more robust TEE time protocol that fixes Triad's vulnerabilities by introducing Byzantine-resilient clock updates and consistency checks to resist clock-speed and offset manipulation.


<details>
  <summary>Details</summary>
Motivation: Accurate and trustworthy time is essential for TEEs, but time sources are exposed to a potentially malicious host. Triad's design can be exploited to speed up or distort time propagation, compromising security. There is a need for a resilient time protocol that tolerates Byzantine behaviors and maintains consistent time across TEEs.

Method: Design and propose TriHaRd, a time-keeping protocol for TEEs that employs Byzantine-resilient clock updates and cross-TEE consistency checks. It builds on a cluster of TEEs and an external Time Authority to ensure a continuous and trustworthy notion of time, even under adversarial conditions.

Result: Empirical evaluation shows that TriHaRd mitigates known attacks against Triad, demonstrating improved resilience to clock-speed and offset manipulations and preventing adversaries from propagating fast time to honest participants.

Conclusion: TriHaRd provides higher resilience to clock manipulation in TEEs, delivering more reliable and consistent time across a network of TEEs compared to Triad.

Abstract: Accurately measuring time passing is critical for many applications. However, in Trusted Execution Environments (TEEs) such as Intel SGX, the time source is outside the Trusted Computing Base: a malicious host can manipulate the TEE's notion of time, jumping in time or affecting perceived time speed. Previous work (Triad) proposes protocols for TEEs to maintain a trustworthy time source by building a cluster of TEEs that collaborate with each other and with a remote Time Authority to maintain a continuous notion of passing time. However, such approaches still allow an attacker to control the operating system and arbitrarily manipulate their own TEE's perceived clock speed. An attacker can even propagate faster passage of time to honest machines participating in Triad's trusted time protocol, causing them to skip to timestamps arbitrarily far in the future. We propose TriHaRd, a TEE trusted time protocol achieving high resilience against clock speed and offset manipulations, notably through Byzantine-resilient clock updates and consistency checks. We empirically show that TriHaRd mitigates known attacks against Triad.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [73] [CSI-Based User Positioning, Channel Charting, and Device Classification with an NVIDIA 5G Testbed](https://arxiv.org/abs/2512.10809)
*Reinhard Wiesmayr,Frederik Zumegen,Sueda Taner,Chris Dick,Christoph Studer*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Channel-state information (CSI)-based sensing will play a key role in future cellular systems. However, no CSI dataset has been published from a real-world 5G NR system that facilitates the development and validation of suitable sensing algorithms. To close this gap, we publish three real-world wideband multi-antenna multi-open RAN radio unit (O-RU) CSI datasets from the 5G NR uplink channel: an indoor lab/office room dataset, an outdoor campus courtyard dataset, and a device classification dataset with six commercial-off-the-shelf (COTS) user equipments (UEs). These datasets have been recorded using a software-defined 5G NR testbed based on NVIDIA Aerial RAN CoLab Over-the-Air (ARC-OTA) with COTS hardware, which we have deployed at ETH Zurich. We demonstrate the utility of these datasets for three CSI-based sensing tasks: neural UE positioning, channel charting in real-world coordinates, and closed-set device classification. For all these tasks, our results show high accuracy: neural UE positioning achieves 0.6cm (indoor) and 5.7cm (outdoor) mean absolute error, channel charting in real-world coordinates achieves 73cm mean absolute error (outdoor), and device classification achieves 99% (same day) and 95% (next day) accuracy. The CSI datasets, ground-truth UE position labels, CSI features, and simulation code are publicly available at https://caez.ethz.ch

</details>


### [74] [Analysis and Compensation of Receiver IQ Imbalance and Residual CFO Error for AFDM](https://arxiv.org/abs/2512.10036)
*Nimesha Gunasekara,Ebrahim Bedeer*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Affine frequency division multiplexing (AFDM) is a promising waveform for future wireless communication systems. In this paper, we analyze the impact of receiver in-phase and quadrature (IQ) imbalance and residual carrier frequency offset (CFO) error on AFDM signals. Our analysis shows that the receiver IQ imbalance may not preserve the sparsity of the AFDM effective channel matrix because of the complex-conjugate operator of the discrete affine Fourier transform (DAFT). Moreover, the residual CFO error causes energy leakage in the effective channel matrix in the affine domain. To mitigate these effects, we extend the linear minimum mean-square error (LMMSE) detector to handle the improper Gaussian noise arising from the receiver IQ imbalance. Simulation results demonstrate that the proposed LMMSE detector effectively compensates for the receiver hardware impairments.

</details>


### [75] [Antenna Coding Design for Multi-User Transmissions Using Pixel Antennas](https://arxiv.org/abs/2512.10246)
*Hongyu Li,Shanpu Shen*

Main category: eess.SP

TL;DR: 提出了一个多用户MISO像素天线系统，用户端采用天线编码，发射端进行前向/维度设计的交替优化，并提出基于离线和分层代码本的天线编码设计以降低复杂度；实验结果显示该系统在和速率方面优于固定天线的对比系统，同时分层代码本在复杂度与性能之间提供更优的折衷。


<details>
  <summary>Details</summary>
Motivation: 像素天线作为可重配置的天线技术，通过天线编码可以在一定程度上灵活调节辐射特性。将其应用到多用户MISO场景有潜力提升系统的和速率，但需要有效的联合设计和低复杂度算法来实现在线自适应。

Method: 提出一个多用户MISO像素天线系统，包含对像素天线的编码建模和多用户波束空间信道建模。通过交替设计实现发射端前馈/波束形成和用户端天线编码的联合优化。为降低计算量，提出基于离线代码本的天线编码设计（在线从代码本中选取最优编码），并进一步提出分层代码本的设计，通过多层分层搜索实现更好的性能-复杂度折衷。

Result: 仿真结果表明，所提的多用户MISO像素天线系统在大多数场景下优于采用固定天线的传统多用户MISO系统。并且分层代码本方法显著降低计算复杂度，同时维持令人满意的和速率性能。

Conclusion: 像素天线结合代码本化设计可以在多用户MISO系统中实现更高的和速率且具有更低的复杂度；分层代码本提供了更优的性能-复杂度权衡，适合在线自适应场景。

Abstract: This work investigates exploiting the potential of pixel antennas, which are a reconfigurable antenna technology that can flexibly adjust the antenna characteristics through antenna coding, in multi-user transmissions. To that end, we propose a multi-user multi-input single-output (MISO) pixel antenna system, which deploys the pixel antenna at users, and develop the system model including pixel antenna with antenna coding and multi-user beamspace channels. Aiming at maximizing the sum rate performance, we first propose an algorithm to alternatively design the precoding at the transmitter and the antenna coding at users, which explores the performance boundary for the proposed multi-user MISO pixel antenna system. To reduce the computational complexity, we propose a codebook-based antenna coding design algorithm, where the antenna coder is online optimized from an offline codebook. To further enhance the computation efficiency, we propose a hierarchical codebook-based antenna coding design that uses a multi-layer hierarchical search to achieve a better performance-complexity trade-off. Simulation results show that, adopting the proposed algorithms, the multi-user MISO pixel antenna system can always outperform conventional multi-user MISO systems with fixed antennas. More importantly, results validate that the proposed (hierarchical) codebook-based algorithms can significantly reduce the computational complexity while maintaining a satisfactory sum rate performance.

</details>


### [76] [Outdoor Crowd Flow Estimation Using RSRP from Commercial LTE Base Station: A Field Study](https://arxiv.org/abs/2512.10447)
*Kaisei Higeta,Masakatsu Ogawa,Tomoki Murakami,Kazuya Ohara,Shinya Otsuki*

Main category: eess.SP

TL;DR:  outdoor crowd flow estimation using commercial LTE via RSRP variance; optimal variance window 0.1–0.2 s; larger counting area yields more predictive features; first quantitative demonstration with LTE+ISAC.


<details>
  <summary>Details</summary>
Motivation: Address the gap in outdoor crowd flow estimation for ISAC using real-world cellular infrastructure, beyond indoor or vehicle-focused studies and limited LTE demonstrations.

Method: A camera-based pedestrian counting method provides counts which are linked to the variance of RSRP from a commercial LTE base station. Features derived from this variance are fed into a CatBoost regression model and interpreted with SHAP. The study also investigates how variance window size and counting area affect feature design.

Result: Identified an optimal RSRP variance window of 0.1–0.2 seconds. Found that enlarging the counting area increases the features obtainable from the variance of RSRP, improving model inputs. Demonstrates, quantitatively, the effectiveness of outdoor crowd flow estimation using commercial LTE.

Conclusion: The work provides the first quantitative demonstration of outdoor crowd flow estimation with commercial LTE and reveals how variance window size and counting area impact feature design for ML-based ISAC applications.

Abstract: With the advent of the 6G era, Integrated Sensing and Communications (ISAC) has attracted increasing attention. One representative of use cases is crowd flow estimation on outdoor streets. However, most existing studies have focused on indoor environments or vehicles, and demonstrations of outdoor crowd flow estimation using commercial LTE base station remain limited. This study addresses this use case and proposes an analysis of a crowd flow estimation method using Reference Signal Received Power (RSRP) obtained from a commercial LTE base station. Specifically, pedestrian counts derived from a camera-based object recognition algorithm were associated with the variance of RSRP. The features obtained from the variance were quantitatively evaluated by combining a CatBoost regression model with SHapley Additive exPlanations (SHAP) analysis. Through this investigation, we clarified that an optimal variance window size for RSRP is 0.1 to 0.2 seconds and that enlarging the counting area increased the features obtained from the variance of RSRP, for machine learning. Consequently, this study is the first to quantitatively demonstrate the effectiveness of outdoor crowd flow estimation using commercial LTE, while also revealing the characteristic behavior of variance window size and counting area size in feature design.

</details>


### [77] [A Novel Pilot Scheme for Uplink Channel Estimation for Sub-array Structured ELAA in XL-MIMO systems](https://arxiv.org/abs/2512.10478)
*Yumeng Zhang,Huayan Guo,Vincent Lau*

Main category: eess.SP

TL;DR: 提出在ELAA/MIMO系统中以可见性区域分组的多用户上行通道估计新型导频方案，利用组间频分复用、组内移位循环码区分，辅以子阵结构ELAA及2-D MRF先验，在Turbo-Bayesian框架下进行低复杂度估计，提升可服务用户数和估计性能。


<details>
  <summary>Details</summary>
Motivation: XL-MIMO在极大孔径下产生空间非平稳性，不同用户在天线阵列上的可观测性差异显著，导致传统的导频开销与干扰管理不足，需新型分组与估计策略来降低开销并提升性能。

Method: 提出以可观测性区域对用户分组共享同一频段导频；组间通过频分复用进行通道估计，组内通过移位循环码实现类CDM的高分辨空间区分；引入子阵结构ELAA使各子阵独立近似时变（静态）且子阵间距增大扩展孔径；对子阵的通道在时延-天线域呈聚簇稀疏，采用二维MRF建模；在Turbo-Bayesian框架中结合2-D MR前验实现低复杂度通道估计。

Result: 仿真表明该方案可服务更多用户并提升通道估计性能。

Conclusion: 通过利用空间非平稳性与稀疏结构，并结合子阵设计与MRF先验，提出的导频与估计算法在XL-MIMO/ELAA场景下有效提升用户容量与估计精度。

Abstract: This paper proposes a novel pilot scheme for multi-user uplink channel estimation in extra-large-scale massive MIMO (XL-MIMO) systems with extremely large aperture arrays (ELAA). The large aperture of ELAA introduces spatial non-stationarity, where far-apart users have significantly distinct visibility at the antennas, thereby reducing inter-user interference. This insight motivates our novel pilot scheme to group users with distinct visibility regions to share the same frequency subcarriers for channel estimation, so that more users can be served with reduced pilot overhead. Specifically, the proposed pilot scheme employs frequency-division multiplexing for inter-group channel estimation, while intra-group users -- benefiting from strong spatial orthogonality -- are distinguished by shifted cyclic codes, similar to code-division multiplexing. Additionally, we introduce a sub-array structured ELAA, where each sub-array is a traditional MIMO array and treated as spatial stationary, while the distances between sub-arrays can be significantly larger to achieve an expanded aperture. The channel support for sub-arrays features clustered sparsity in the antenna-delay domain and is modeled by a 2-dimensional (2-D) Markov random field (MRF). Based on this, we propose a low-complexity channel estimation algorithm within a turbo Bayesian inference framework that incorporates the 2-D MRF prior model. Simulations show that the proposed scheme and algorithm allow the XL-MIMO system to support more users, and deliver superior channel estimation performance.

</details>


### [78] [T-ADD: Enhancing DOA Estimation Robustness Against Adversarial Attacks](https://arxiv.org/abs/2512.10496)
*Shilian Zheng,Xiaoxiang Wu,Luxin Zhang,Keqiang Yue,Peihan Qi,Zhijin Zhao*

Main category: eess.SP

TL;DR: 提出 T-ADD，一种基于变换器的对 DOA 估计的对抗攻击防御方法，通过将防御任务设定为联合重构，并设计定制的联合损失，以提升对广泛对抗攻击的鲁棒性，同时尽量维持估计准确性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在方向到达（DOA）估计中表现突出，但容易受到对抗扰动的削弱，迫切需要鲁棒的防御机制来确保系统在潜在攻击下仍能可靠工作。

Method: 基于 Transformer 的防御框架 T-ADD，将对抗防御问题建模为联合重构任务，通过定制的联合损失函数在鲁棒性与估计精度之间取得平衡。对比了三种最新的对抗防御方法，实验上显示 T-ADD 能显著缓解对抗攻击的负面影响。

Result: 实验结果表明，与三种最新对抗防御方法相比，T-ADD 在对广泛使用的对抗攻击下显著提升了 DOA 模型的鲁棒性，减弱了攻击效果，提升了对抗鲁棒性。

Conclusion: T-ADD 提供了一种有效的对 DOA 估计的对抗防御思路，通过 Transformer 架构和联合重构损失实现更好的鲁棒性，同时对保持估计精准度具有潜在的正向影响。

Abstract: Deep learning has achieved remarkable success in direction-of-arrival (DOA) estimation. However, recent studies have shown that adversarial perturbations can severely compromise the performance of such models. To address this vulnerability, we propose Transformer-based Adversarial Defense for DOA estimation (T-ADD), a transformer-based defense method designed to counter adversarial attacks. To achieve a balance between robustness and estimation accuracy, we formulate the adversarial defense as a joint reconstruction task and introduce a tailored joint loss function. Experimental results demonstrate that, compared with three state-of-the-art adversarial defense methods, the proposed T-ADD significantly mitigates the adverse effects of widely used adversarial attacks, leading to notable improvements in the adversarial robustness of the DOA model.

</details>


### [79] [Symbol-Level Precoding for Integrated Sensing and Covert Communication](https://arxiv.org/abs/2512.10752)
*Yufei Wang,Qiang Li,Hongli Liu,Ying Zhang,Jingran Lin*

Main category: eess.SP

TL;DR: 提出一种基于符号级预编码的ISCC波形设计，通过符号整形提升合法用户可靠性、噪声整形隐藏传输活动，且在CSI不完备下具有鲁棒性。使用低复杂度的Proximal Distance Algorithm（PDA）在PSK/QAM下实现非凸优化，结果显示在隐蔽性、感知与通信性能之间实现良好折衷，优于传统波束赋形与无噪声整形的SLP方法。


<details>
  <summary>Details</summary>
Motivation: 在综合感知与通信（ISAC）场景中，需同时实现安全（隐蔽）传输与高质量感知性能。目标既可能是窃听者又可能是警戒者，传统方法难以在不增加额外资源（如人造噪声）的情况下实现内生隐蔽传输，因此需要新的波形设计来同时提升感知与通信的鲁棒性与保密性。

Method: 提出一个符号级预编码（SLP）为核心的ISCC波形设计，将符号成形用于提升合法用户的可靠性，同时通过噪声整形掩盖传输活动；在用户信道和目标角度存在界定不确定性时建立 bounded-uncertainty 模型，进行鲁棒优化；将非凸优化问题转化为可行的低复杂度 Proximal Distance Algorithm（PDA），并给出 PSK 与 QAM 模式下的闭式更新。

Result: 仿真表明所提方法在隐蔽性、感知和通信性能方面显著优于传统波束赋形及普通SLP方法，且在不使用额外资源（如人造噪声）的前提下实现了极小的性能损失。

Conclusion: 提出的ISCC-PDA框架实现了本质隐蔽通信与多用户下行服务的统一设计，兼顾感知性能，并对CSI不完备具有鲁棒性，且具有低复杂度、易于实现的优点。

Abstract: Integrated sensing and communication (ISAC) systems have emerged as a promising solution to improve spectrum efficiency and enable functional convergence. However, ensuring secure information transmission while maintaining high-quality sensing performance remains a significant challenge. In this paper, we investigate an integrated sensing and covert communication (ISCC) system, in which a base station (BS) simultaneously serves multiple downlink users and senses malicious targets that may act as both potential eavesdroppers (Eves) and wardens. We propose a novel symbol-level precoding (SLP)-based waveform design for ISCC that achieves covert communication intrinsically, without requiring additional transmission resources such as artificial noise. The proposed design integrates symbol shaping to enhance reliability for legitimate users and noise shaping to obscure transmission activities from the targets. For imperfect channel state information (CSI), the framework incorporates bounded uncertainty models for user channels and target angles, yielding a more robust design. The resulting ISCC waveform optimization problem is non-convex; to address this, we develop a low-complexity proximal distance algorithm (PDA) with closed-form updates under both PSK and QAM modulations. Simulation results demonstrate that the proposed method achieves superior covertness and sensing-communication performance with negligible degradation compared to traditional beamforming and conventional SLP approaches without noise-shaping mechanisms.

</details>


### [80] [Comparative analysis of WNG-DF compromising beamformers](https://arxiv.org/abs/2512.10829)
*Vitor G. P. Curtarelli*

Main category: eess.SP

TL;DR: 对多目标波束形成的比较研究：在兼顾白噪声增益与指向性因子的前提下，比较专门为联合目标设计的波束形成器与通过组合单任务波束形成器得到的方案，结果显示鲁棒超指向性和可调波束形成器在性能上最佳且输出在各评估指标上几乎一致，且更具实用性，能在两目标之间持续折衷。


<details>
  <summary>Details</summary>
Motivation: 探索同时实现白噪声增益与指向性等多目标的波束形成器设计，并评估专门的联合设计方法与通过组合单任务波束形成器得到的方案之间的性能与实际可用性。

Method: 通过仿真对比：比较为这两项联合特征设计的波束形成方法与通过组合特定单任务波束形成器得到的方案的性能；重点分析鲁棒超指向性与可调波束形成器的表现与输出一致性。

Result: 鲁棒超指向性与可调波束形成器在所研究的方案中表现最佳，且在所有评估指标上输出几乎相同；这两种方法更具实际可行性，能够在两目标之间持续折衷。

Conclusion: 专门为联合目标设计的鲁棒超指向性与可调波束形成器在本研究中胜出，且提供连续可控的权衡，适合作为兼顾白噪声增益与指向性的实用解。

Abstract: This work studies beamformers designed to achieve multiple characteristics simultaneously, specifically those compromising white-noise gain and directivity factor. We compare methods explicitly designed for these joint features against those obtained by combining specific single-task beamformers. Through simulations, we demonstrate that the robust superdirective and the tunable beamformers yield the best results among those studied. Notably, these two methods produced nearly identical outputs across all evaluated metrics. These two are also more practical, continuously compromising between the two objectives.

</details>


### [81] [A Variable Step Sizes Frequency Offsets-Compensated Least Mean Squares Algorithm](https://arxiv.org/abs/2512.10832)
*Karel Pärlin,Aaron Byman,Tommi Meriläinen,Taneli Riihonen*

Main category: eess.SP

TL;DR: FO-LMS是一种在载波与采样频偏存在时对信道进行估计的通用方法，结合自适应步长以平衡跟踪能力与抗噪声的稳健性。


<details>
  <summary>Details</summary>
Motivation: 在无线通信中，信道和频偏随时间变化，需要鲁棒且自适应的估计算法来保持性能。

Method: 提出频偏补偿的LMS框架，通过随机梯度下降迭代更新信道和频偏估计；推导稳定性条件及学习率对跟踪误差和失配误差的理论表达；提出在时变特性未知时的自适应步长调整策略；通过仿真验证理论表达与自适应步长的有效性。

Result: 给出跟踪误差与失配误差的理论表达式；自适应步长提升在未知时变特性下的鲁棒性和收敛性；仿真结果验证理论预测与性能提升。

Conclusion: 在存在时变信道和频偏的无线场景中，FO-LMS可通过自适应步长实现更稳定且高效的信道与频偏估计，尤其在时变特性未知时仍能保持良好性能。

Abstract: Frequency offsets-compensated least mean squares (FO-LMS) algorithm is a generic method for estimating a wireless channel under carrier and sampling frequency offsets when the transmitted signal is beforehand known to the receiver. The algorithm iteratively and explicitly adjusts its estimates of the channel and frequency offsets using stochastic gradient descent-based rules and the step sizes of these rules determine the learning rate and stability of the algorithm. Within the stability conditions, the choice of step sizes reflects a trade-off between the algorithm's ability to react to changes in the channel and the ability to minimize misadjustments caused by noise. This paper provides theoretical expressions to predict and optimize the tracking and misadjusment errors of FO-LMS when estimating channels and frequency offsets with known time-varying characteristics. This work also proposes a method to adjust the FO-LMS's step sizes based on the algorithm's performance when the time-varying characteristics are not known, which is more often the case in practice. Accuracy of the expressions and performance of the proposed variable step sizes algorithm are studied through simulations.

</details>


### [82] [Decision Feedback-Aided Known-Interference Cancellation](https://arxiv.org/abs/2512.10833)
*Karel Pärlin,Aaron Byman,Tommi Meriläinen,Taneli Riihonen*

Main category: eess.SP

TL;DR: 提出一种决策反馈辅助的已知干扰消除（DF-KIC）方法，通过迭代地同时消除KI和SI，提升KI消除能力和系统吞吐，但增加计算负载。


<details>
  <summary>Details</summary>
Motivation: 在无线通信中，KI若要被有效消除，SI会作为估计噪声干扰KI，限制可消除干扰的程度，从而降低隐藏/安全传输的吞吐潜力，需要改进的干扰抑制机制。

Method: 提出DF-KIC结构，利用决策反馈逐步、迭代地同时对KI和SI进行消除，使KI消除能力与SI干扰相互配合，提升整体性能。

Result: 测量结果表明，引入决策反馈可显著提高KI消除能力和有用吞吐量，但伴随计算复杂度的提高。

Conclusion: DF-KIC在平衡干扰消除和计算成本方面具有潜力，可在合适实现条件下提升隐蔽通信系统的吞吐。

Abstract: Known-interference cancellation (KIC) in combination with cooperative jamming can be used to provide covertness and security to wireless communications at the physical layer. However, since the signal of interest (SI) of a wireless communication system acts as estimation noise, i.e., interference, to KIC, the SI limits the extent to which the known interference (KI) can be canceled and that in turn limits the throughput of the wireless communication system that is being hidden or secured. In this letter, we analyze a decision feedback-aided known-interference cancellation (DF-KIC) structure in which both the KI and SI are canceled iteratively and successively. Measurement results demonstrate that introducing decision feedback to KIC improves its KI cancellation capability and hence increases the wireless communication system's useful throughput, albeit at the expense of a higher computational load.

</details>


### [83] [POLO: Phase-Only Localization in Uplink Distributed MIMO Systems](https://arxiv.org/abs/2512.10879)
*Sauradeep Dey,Musa Furkan Keskin,Dario Tagliaferri,Gonzalo Seco-Granados,Mikko Valkama,Henk Wymeersch*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a low-complexity localization framework for uplink distributed MIMO (D-MIMO) systems, targeting the challenge of minimizing the highly spiky maximum-likelihood (ML) cost function that arises in sparsely deployed phasecoherent access points (APs) with narrowband transmission. In such systems, ML-based localization typically relies on dense grid search, incurring prohibitive computational complexity. To address this, we introduce phase-only localization (POLO), an approach that leverages differential carrier-phase measurements from selected APs to generate a compact set of candidate user positions. The ML cost function is then evaluated only at these candidates, reducing complexity significantly. A key challenge is to devise an AP selection mechanism that reduces the number of candidate points while maintaining reliable coverage. We propose two variants: POLO-I, which selects three APs to provide closed-form candidate positions with low computational cost, and POLO-II, which selects four APs using an alternative strategy that enhances coverage at marginally higher runtime. Comprehensive analytical and simulation results show that POLO achieves a favorable coverage-complexity trade-off, reducing cost by orders of magnitude relative to exhaustive grid search with only marginal loss in coverage. By characterizing this tradeoff under diverse AP configurations, we also provide practical guidelines for selecting between POLO-I and POLO-II depending on latency and coverage requirements.

</details>
