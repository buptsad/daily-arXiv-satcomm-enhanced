{"id": "2601.04198", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.04198", "abs": "https://arxiv.org/abs/2601.04198", "authors": ["L\u00e9o Simpson", "Moritz Diehl"], "title": "Identification of a Kalman filter: consistency of local solutions", "comment": "Submitted for review to the proceedings of the IFAC World Congress 2026", "summary": "Prediction error and maximum likelihood methods are powerful tools for identifying linear dynamical systems and, in particular, enable the joint estimation of model parameters and the Kalman filter used for state estimation. A key limitation, however, is that these methods require solving a generally non-convex optimization problem to global optimality. This paper analyzes the statistical behavior of local minimizers in the special case where only the Kalman gain is estimated. We prove that these local solutions are statistically consistent estimates of the true Kalman gain. This follows from asymptotic unimodularity: as the dataset grows, the objective function converges to a limit with a unique local (and therefore global) minimizer. We further provide guidelines for designing the optimization problem for Kalman filter tuning and discuss extensions to the joint estimation of additional linear parameters and noise covariances. Finally, the theoretical results are illustrated using three examples of increasing complexity. The main practical takeaway of this paper is that difficulties caused by local minimizers in system identification are, at least, not attributable to the tuning of the Kalman gain.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\uff0c\u5728\u53ea\u4f30\u8ba1\u5361\u5c14\u66fc\u589e\u76ca\u7684\u6700\u5927\u4f3c\u7136\u6216\u9884\u6d4b\u8bef\u5dee\u6846\u67b6\u4e2d\uff0c\u5c40\u90e8\u6781\u5c0f\u503c\u968f\u7740\u6837\u672c\u589e\u52a0\u53d8\u4e3a\u552f\u4e00\u503c\uff0c\u800c\u4e14\u662f\u4e00\u81f4\u4f30\u8ba1\uff1b\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u4f18\u5316\u95ee\u9898\u7684\u65b9\u5411\uff0c\u5e76\u901a\u8fc7\u4e09\u7ec4\u4f8b\u5b50\u9a8c\u8bc1\u3002", "motivation": "\u63d0\u5347\u7ebf\u6027\u52a8\u6001\u7cfb\u7edf\u8fa8\u8bc6\u4e2d\u7684\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u8c03\u4f18\u7cbe\u5ea6\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u6613\u9677\u5165\u975e\u51f8\u4f18\u5316\u5c40\u90e8\u6700\u4f18\u5bfc\u81f4\u7684\u8bc6\u522b\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6700\u5927\u4f3c\u7136/\u9884\u6d4b\u8bef\u5dee\u65b9\u6cd5\u5728\u4ec5\u4f30\u8ba1\u5361\u5c14\u66fc\u589e\u76ca\u65f6\u7684\u5c40\u90e8\u6781\u5c0f\u503c\u7684\u7edf\u8ba1\u884c\u4e3a\uff0c\u8bc1\u660e\u76ee\u6807\u51fd\u6570\u7684\u6e10\u8fd1\u5355\u5cf0\u6027\uff0c\u5e76\u7ed9\u51fa\u4f18\u5316\u95ee\u9898\u8bbe\u8ba1\u51c6\u5219\uff1b\u968f\u540e\u63a8\u5e7f\u5230\u8054\u5408\u4f30\u8ba1\u5176\u5b83\u7ebf\u6027\u53c2\u6570\u4e0e\u566a\u58f0\u534f\u65b9\u5dee\u3002", "result": "\u8bc1\u660e\u4e86\u5c40\u90e8\u6700\u4f18\u89e3\u5728\u7edf\u8ba1\u4e0a\u4e0e\u771f\u5b9e\u5361\u5c14\u66fc\u589e\u76ca\u4e00\u81f4\uff1b\u5c55\u793a\u4e86\u76ee\u6807\u51fd\u6570\u968f\u6837\u672c\u589e\u957f\u8d8b\u4e8e\u5355\u5cf0\u7684\u6536\u655b\uff1b\u5e76\u7ed9\u51fa\u4e86\u8c03\u4f18\u51c6\u5219\u548c\u4e09\u4f8b\u5b9e\u8bc1\u6f14\u793a\u3002", "conclusion": "\u8bba\u6587\u8868\u660e\uff0c\u5728\u4ec5\u4f30\u8ba1\u5361\u5c14\u66fc\u589e\u76ca\u7684\u60c5\u5f62\u4e0b\uff0c\u5c40\u90e8\u6781\u5c0f\u503c\u5728\u7edf\u8ba1\u4e0a\u662f\u4e00\u81f4\u7684\uff0c\u4e14\u968f\u7740\u6837\u672c\u91cf\u7684\u589e\u52a0\u76ee\u6807\u51fd\u6570\u53d8\u4e3a\u5355\u5cf0\uff0c\u552f\u4e00\u6781\u5c0f\u70b9\u5373\u5168\u5c40\u6781\u5c0f\u70b9\uff1b\u56e0\u6b64\uff0c\u5728\u7cfb\u7edf\u8fa8\u8bc6\u4e2d\u51fa\u73b0\u5c40\u90e8\u6781\u5c0f\u70b9\u5e76\u975e\u5361\u5c14\u66fc\u589e\u76ca\u8c03\u4f18\u6240\u81f4\u3002"}}
{"id": "2601.04504", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.04504", "abs": "https://arxiv.org/abs/2601.04504", "authors": ["Sojin Park", "Ross Baldick", "Hunyoung Shin"], "title": "Definition and Formulation of Inertia Service Incorporating Inverter-Based Resources", "comment": "10 pages, 5 figures", "summary": "Increasing concerns over the scarcity of inertia have motivated the procurement of inertia as an ancillary service (AS). Despite numerous academic and practical efforts, there remains a lack of consensus regarding the definition and treatment of inertia service in market operations, particularly the specification of inertia variables and the separation between synchronous inertia (SI) from synchronous generators and virtual inertia (VI) from inverter-based resources. To address these issues, this paper proposes a power-oriented (P-oriented) definition based on inertial response, which establishes conceptual consistency between SI and VI and makes the inertia service commensurable with other ASs. This definition explicitly incorporates both positive and negative inertial responses during frequency drop events. We then formulate a security-constrained economic dispatch framework based on this P-oriented definition and demonstrate its practical effectiveness through simulations. Case studies on a modified IEEE 30-bus system show that the proposed bidirectional service definition ensures price signals that reflect the economic value of inertial provision.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04796", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.04796", "abs": "https://arxiv.org/abs/2601.04796", "authors": ["Xi Ru", "Xiaoyu Peng", "Xinghua Chen", "Zhaojian Wang", "Peng Yang", "Feng Liu"], "title": "Matrix-Valued Passivity Indices: Foundations, Properties, and Stability Implications", "comment": "12 pages, 4 figures", "summary": "The passivity index, a quantitative measure of a system's passivity deficiency or excess, has been widely used in stability analysis and control. Existing studies mostly rely on scalar forms of indices, which are restrictive for multi-input, multi-output (MIMO) systems. This paper extends the classical scalar indices to a systematic matrix-valued framework, referred to as passivity matrices. A broad range of classical results in passivity theory can be naturally generalized in this framework. We first show that, under the matrix representation, passivity indices essentially correspond to the curvature of the dissipativity functional under a second-variation interpretation. This result reveals that the intrinsic geometric structure of passivity consists of its directions and intensities, which a scalar index cannot fully capture. For linear time-invariant (LTI) systems, we examine the structural properties of passivity matrices with respect to the Loewner partial order and propose two principled criteria for selecting representative matrices. Compared with conventional scalar indices, the matrix-valued indices capture the passivity coupling among different input-output channels in MIMO systems and provide a more comprehensive description of system passivity. This richer information leads to lower passivation effort and less conservative stability assessment.", "AI": {"tldr": "\u5c06\u88ab\u52a8\u6027\u6307\u6570\u4ece\u6807\u91cf\u6269\u5c55\u4e3a\u77e9\u9635\uff0c\u63ed\u793a\u7cfb\u7edf\u51e0\u4f55\u7ed3\u6784\uff0c\u66f4\u5168\u9762\u5730\u63cf\u8ff0 MIMO \u88ab\u52a8\u6027\uff0c\u964d\u4f4e\u63a7\u5236\u4fdd\u5b88\u6027\u3002", "motivation": "\u4f20\u7edf\u88ab\u52a8\u6027\u6307\u6570\u4ec5\u4e3a\u6807\u91cf\uff0c\u4e0d\u8db3\u4ee5\u63cf\u8ff0 MIMO \u7cfb\u7edf\u4e2d\u4e0d\u540c\u901a\u9053\u95f4\u7684\u8026\u5408\u7279\u6027\uff1b\u8feb\u5207\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6355\u6349\u65b9\u5411\u4e0e\u5f3a\u5ea6\u4fe1\u606f\u7684\u66f4\u4e30\u5bcc\u6307\u6807\u3002", "method": "\u901a\u8fc7\u5c06\u6807\u91cf\u6307\u6570\u63a8\u5e7f\u4e3a\u77e9\u9635\u5f62\u5f0f\uff0c\u5bf9\u88ab\u52a8\u6027\u6307\u6570\u4e0e\u6d88\u8017\u6027\u51fd\u6570\u4e8c\u9636\u53d8\u5206\u5173\u8054\u8fdb\u884c\u51e0\u4f55\u89e3\u8bfb\uff1b\u9488\u5bf9 LTI \u7cfb\u7edf\uff0c\u7814\u7a76\u4e86\u77e9\u9635\u5728 Loewner \u504f\u5e8f\u4e0b\u7684\u7ed3\u6784\uff0c\u5e76\u7ed9\u51fa\u4e24\u79cd\u4ee3\u8868\u6027\u77e9\u9635\u6311\u9009\u51c6\u5219\u3002", "result": "\u6784\u9020\u4e86\u4e00\u822c\u5316\u7684\u77e9\u9635\u88ab\u52a8\u6027\u6846\u67b6\uff0c\u8bc1\u660e\u5176\u5728 LTI \u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\uff1b\u65b0\u6846\u67b6\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u53bb\u88ab\u52a8\u5316\u6295\u5165\u3001\u66f4\u5c11\u7684\u4fdd\u5b88\u6027\uff0c\u5e76\u5728\u591a\u901a\u9053\u8026\u5408\u8868\u73b0\u4e0a\u8d85\u8d8a\u6807\u91cf\u6307\u6570\u3002", "conclusion": "\u6587\u7ae0\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u77e9\u9635\u5f62\u5f0f\u7684\u88ab\u52a8\u6027\u6307\u6570\uff0c\u4f7f\u5f97\u591a\u8f93\u5165\u591a\u8f93\u51fa\u7cfb\u7edf\u7684\u88ab\u52a8\u6027\u5206\u6790\u66f4\u4e3a\u7cbe\u51c6\u4e0e\u5168\u9762\uff1b\u4e0e\u4f20\u7edf\u6807\u91cf\u6307\u6570\u76f8\u6bd4\uff0c\u65b0\u65b9\u6cd5\u63ed\u793a\u4e86\u88ab\u52a8\u6027\u8026\u5408\u3001\u964d\u4f4e\u4e86\u53bb\u88ab\u52a8\u5316\u9700\u6c42\uff0c\u5e76\u63d0\u5347\u4e86\u7a33\u5b9a\u6027\u8bc4\u4f30\u7684\u4fdd\u5b88\u7a0b\u5ea6\u3002"}}
{"id": "2601.04817", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.04817", "abs": "https://arxiv.org/abs/2601.04817", "authors": ["Mattia Merluzzi", "Olivier Bouchet", "Ali Balador", "Gilles Callebaut", "Anastasius Gavras", "Liesbet Van der Perre", "Albert Banchs", "Mauro Renato Boldi", "Emilio Calvanese Strinati", "Bahare M Khorsandi", "Marja Matinmikko-Blue", "Lars Christoph Schmelz"], "title": "Towards Sustainable 6G: A Holistic View of Trade-offs and Enablers", "comment": "This work has been submitted to IEEE Communications Magazine", "summary": "The sixth generation of mobile networks (6G) can play a central role in shaping a sustainable future, the most compelling contemporary challenge. Connecting the unconnected, reducing carbon emissions of vertical sectors, and allowing heterogeneous types of intelligence (including humans) to safely and constructively interact in complex environments, are only a few of the several challenges that can be supported by 6G. However, this requires a careful design that balances positive and negative impacts of 6G, towards a sustainable and sustainability-enabling technology. This paper presents a holistic view that translates the complex interplay between the 6G enabling effects and the sustainability of 6G by design, into concrete trade-offs and research questions. Starting from today's challenges for society and associated key values, we unfold the dilemma into a set of technical trade-offs, whose solutions span from technological innovations to standardization actions towards applicability.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ece\u793e\u4f1a\u4ef7\u503c\u51fa\u53d1\uff0c\u6784\u5efa 6G \u4e0e\u53ef\u6301\u7eed\u6027\u4e4b\u95f4\u7684\u6280\u672f\u6743\u8861\u6846\u67b6\uff0c\u63d0\u51fa\u5177\u4f53\u7814\u7a76\u95ee\u9898\uff0c\u65e8\u5728\u6307\u5bfc 6G \u7684\u751f\u6001\u53cb\u597d\u8bbe\u8ba1\u4e0e\u6807\u51c6\u5316\u8fc7\u7a0b\u3002", "motivation": "\u4e3a\u5b9e\u73b0\u53ef\u6301\u7eed\u672a\u6765\uff0c6G \u9700\u8981\u89e3\u51b3\u8fde\u7f51\u76f2\u533a\u3001\u78b3\u6392\u653e\u4ee5\u53ca\u4eba\u4e0e\u673a\u5668\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u5b89\u5168\u534f\u4f5c\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6574\u4f53\u89c6\u89d2\uff0c\u5c06 6G \u4e0e\u53ef\u6301\u7eed\u6027\u4e4b\u95f4\u590d\u6742\u4ea4\u4e92\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u6280\u672f\u6743\u8861\u4e0e\u7814\u7a76\u95ee\u9898\uff0c\u7ed3\u5408\u6280\u672f\u521b\u65b0\u4e0e\u6807\u51c6\u5316\u8def\u5f84\u3002", "result": "\u5f62\u6210\u4e00\u5957\u6280\u672f\u6743\u8861\u65b9\u6848\u53ca\u5bf9\u5e94\u7684\u7814\u7a76\u8bae\u9898\uff0c\u5c55\u793a\u5982\u4f55\u901a\u8fc7\u8bbe\u8ba1\u4e0e\u6807\u51c6\u5b9e\u73b0 6G \u7684\u53ef\u6301\u7eed\u6027\u3002", "conclusion": "6G \u82e5\u4ee5\u5e73\u8861\u6b63\u8d1f\u5f71\u54cd\u7684\u8bbe\u8ba1\u4e3a\u6838\u5fc3\uff0c\u53ef\u6210\u4e3a\u63a8\u52a8\u793e\u4f1a\u53ef\u6301\u7eed\u53d1\u5c55\u7684\u5173\u952e\u6280\u672f\u3002"}}
{"id": "2601.04415", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04415", "abs": "https://arxiv.org/abs/2601.04415", "authors": ["Charalambos Hadjipanayi", "Maowen Yin", "Alan Bannon", "Ziwei Chen", "Timothy G. Constandinou"], "title": "Towards Radar-Agnostic Gait Analysis Across UWB and FMCW Systems", "comment": null, "summary": "Radar sensing has emerged in recent years as a promising solution for unobtrusive and continuous in-home gait monitoring. This study evaluates whether a unified processing framework can be applied to radar-based spatiotemporal gait analysis independent of radar modality. The framework is validated using collocated impulse-radio ultra-wideband (IR-UWB) and frequency-modulated continuous-wave (FMCW) radars under identical processing settings, without modality-specific tuning, during repeated overground walking trials with 10 healthy participants. A modality-independent approach for automatic walking-segment identification is also introduced to ensure fair and reproducible modality performance assessment. Clinically relevant spatiotemporal gait parameters, including stride time, stride length, walking speed, swing time, and stance time, extracted from each modality were compared against gold-standard motion capture reference estimates. Across all parameters, both radar modalities achieved comparably high mean estimation accuracy in the range of 85-98%, with inter-modality differences remaining below 4.1%, resulting in highly overlapping accuracy distributions. Correlation and Bland-Altman analyses revealed minimal bias, comparable limits of agreement, and strong agreement with reference estimates, while intraclass correlation analysis demonstrated high consistency between radar modalities. These findings indicate that no practically meaningful performance differences arise from radar modality when using a shared processing framework, supporting the feasibility of radar-agnostic gait analysis systems.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u96f7\u8fbe\u4fe1\u53f7\u5904\u7406\u6846\u67b6\uff0cIR-UWB\u4e0eFMCW\u4e24\u79cd\u96f7\u8fbe\u5747\u53ef\u5728\u5bb6\u5c45\u73af\u5883\u4e2d\u7cbe\u51c6\u6301\u7eed\u5730\u76d1\u6d4b\u6b65\u6001\uff0c\u4e0d\u5b58\u5728\u660e\u663e\u7684\u6a21\u6001\u5dee\u5f02\uff0c\u4e3a\u96f7\u8fbe\u65e0\u5173\u5f0f\u6b65\u6001\u5206\u6790\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u8feb\u5207\u9700\u8981\u4e00\u79cd\u975e\u63a5\u89e6\u3001\u8fde\u7eed\u3001\u53ef\u5728\u5c45\u5bb6\u73af\u5883\u4e2d\u5b9e\u65bd\u7684\u6b65\u6001\u76d1\u6d4b\u6280\u672f\uff1b\u5df2\u6709\u96f7\u8fbe\u6b65\u6001\u5206\u6790\u591a\u4e3a\u5355\u6a21\u6001\u4e14\u9700\u9488\u5bf9\u4e0d\u540c\u96f7\u8fbe\u8c03\u53c2\uff0c\u9650\u5236\u4e86\u666e\u9002\u6027\u4e0e\u53ef\u8fc1\u79fb\u6027\u3002", "method": "\u5728\u76f8\u540c\u7684\u5904\u7406\u8bbe\u7f6e\u4e0b\uff0c\u5bf910\u540d\u5065\u5eb7\u5fd7\u613f\u8005\u8fdb\u884c\u591a\u6b21\u5730\u9762\u884c\u8d70\u8bd5\u9a8c\uff0c\u91c7\u96c6IR-UWB\u548cFMCW\u96f7\u8fbe\u4fe1\u53f7\uff0c\u7edf\u4e00\u5e94\u7528\u81ea\u52a8\u6b65\u6001\u6bb5\u5206\u79bb\u65b9\u6cd5\uff0c\u5e76\u5c06\u63d0\u53d6\u7684\u6b65\u6001\u53c2\u6570\u4e0e\u91d1\u6807\u51c6\u8fd0\u52a8\u6355\u6349\u7cfb\u7edf\u8fdb\u884c\u5bf9\u6bd4\uff0c\u91c7\u7528\u76f8\u5173\u6027\u3001Bland\u2011Altman\u53caICC\u7b49\u7edf\u8ba1\u65b9\u6cd5\u8bc4\u4f30\u7cbe\u5ea6\u4e0e\u4e00\u81f4\u6027\u3002", "result": "\u4e24\u79cd\u96f7\u8fbe\u6a21\u6001\u5728\u6b65\u6001\u53c2\u6570\uff08\u6b65\u957f\u3001\u6b65\u901f\u3001\u6446\u6b65\u65f6\u95f4\u7b49\uff09\u4e0a\u5e73\u5747\u4f30\u8ba1\u51c6\u786e\u7387\u5747\u572885-98%\uff1b\u4ea4\u6a21\u6001\u5dee\u5f02\u4f4e\u4e8e4.1%\uff0c\u4e24\u8005\u7684\u8bef\u5dee\u5206\u5e03\u9ad8\u5ea6\u91cd\u53e0\uff0c\u76f8\u5173\u6027\u548cICC\u5747\u663e\u793a\u51fa\u5f3a\u4e00\u81f4\u6027\u4e0e\u65e0\u663e\u8457\u504f\u5dee\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\uff0c\u4f7f\u7528\u7edf\u4e00\u7684\u96f7\u8fbe\u4fe1\u53f7\u5904\u7406\u6846\u67b6\uff0c\u65e0\u8bba\u662f\u8109\u51b2\u5f0f\u8d85\u5bbd\u5e26\uff08IR-UWB\uff09\u8fd8\u662f\u8c03\u9891\u8fde\u7eed\u6ce2\uff08FMCW\uff09\u96f7\u8fbe\uff0c\u90fd\u80fd\u5b9e\u73b0\u76f8\u540c\u7684\u6b65\u6001\u65f6\u7a7a\u53c2\u6570\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u96f7\u8fbe\u6a21\u6001\u5dee\u5f02\u4e0d\u8d85\u8fc74.1%\uff0c\u56e0\u6b64\u96f7\u8fbe\u65e0\u5173\u7684\u6b65\u6001\u5206\u6790\u7cfb\u7edf\u5177\u5907\u53ef\u884c\u6027\u3002"}}
{"id": "2601.04215", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.04215", "abs": "https://arxiv.org/abs/2601.04215", "authors": ["Scott Thomson", "Michael Bewong", "Arash Mahboubi", "Tanveer Zia"], "title": "Social Engineering Attacks: A Systemisation of Knowledge on People Against Humans", "comment": "10 pages, 6 Figures, 3 Tables", "summary": "Our systematisation of knowledge on Social Engineering Attacks (SEAs), identifies the human, organisational, and adversarial dimensions of cyber threats. It addresses the growing risks posed by SEAs, highly relevant in the context physical cyber places, such as travellers at airports and residents in smart cities, and synthesizes findings from peer reviewed studies, industry and government reports to inform effective countermeasures that can be embedded into future smart city strategies. SEAs increasingly sidestep technical controls by weaponising leaked personal data and behavioural cues, an urgency underscored by the Optus, Medibank and now Qantas (2025) mega breaches that placed millions of personal records in criminals' hands. Our review surfaces three critical dimensions: (i) human factors of knowledge, abilities and behaviours (KAB) (ii) organisational culture and informal norms that shape those behaviours and (iii) attacker motivations, techniques and return on investment calculations. Our contributions are threefold: (1) TriLayer Systematisation: to the best of our knowledge, we are the first to unify KAB metrics, cultural drivers and attacker economics into a single analytical lens, enabling practitioners to see how vulnerabilities, norms and threat incentives coevolve. (2) Risk Weighted HAISQ Meta analysis: By normalising and ranking HAISQ scores across recent field studies, we reveal persistent high risk clusters (Internet and Social Media use) and propose impact weightings that make the instrument predictive rather than descriptive. (3) Adaptive 'Segment and Simulate' Training Blueprint: Building on clustering evidence, we outline a differentiated programme that matches low, medium, high risk user cohorts to experiential learning packages including phishing simulations, gamified challenges and realtime feedback thereby aligning effort with measured exposure.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04433", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04433", "abs": "https://arxiv.org/abs/2601.04433", "authors": ["Yuhao Chi", "Zhiyuan Peng", "Lei Liu", "Ying Li", "Yao Ge", "Chau Yuen"], "title": "Achievable Rate and Coding Principle for MIMO Multicarrier Systems With Cross-Domain MAMP Receiver Over Doubly Selective Channels", "comment": "16 pages, 11 figures, accepted in IEEE Transactions on Wireless Communications", "summary": "The integration of multicarrier modulation and multiple-input-multiple-output (MIMO) is critical for reliable transmission of wireless signals in complex environments, which significantly improve spectrum efficiency. Existing studies have shown that popular orthogonal time frequency space (OTFS) and affine frequency division multiplexing (AFDM) offer significant advantages over orthogonal frequency division multiplexing (OFDM) in uncoded doubly selective channels. However, it remains uncertain whether these benefits extend to coded systems. Meanwhile, the information-theoretic limit analysis of coded MIMO multicarrier systems and the corresponding low-complexity receiver design remain unclear. To overcome these challenges, this paper proposes a multi-slot cross-domain memory approximate message passing (MS-CD-MAMP) receiver as well as develops its information-theoretic (i.e., achievable rate) limit and optimal coding principle for MIMO-multicarrier modulation (e.g., OFDM, OTFS, and AFDM) systems. The proposed MS-CD-MAMP receiver can exploit not only the time domain channel sparsity for low complexity but also the corresponding symbol domain constellation constraints for performance enhancement. Meanwhile, limited by the high-dimensional complex state evolution (SE), a simplified single-input single-output variational SE is proposed to derive the achievable rate of MS-CD-MAMP and the optimal coding principle with the goal of maximizing the achievable rate. Numerical results show that coded MIMO-OFDM/OTFS/AFDM with MS-CD-MAMP achieve the same maximum achievable rate in doubly selective channels, whose finite-length performance with practical optimized low-density parity-check (LDPC) codes is only 0.5 $\\sim$ 1.8 dB away from the associated theoretical limit, and has 0.8 $\\sim$ 4.4 dB gain over the well-designed point-to-point LDPC codes.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04199", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04199", "abs": "https://arxiv.org/abs/2601.04199", "authors": ["Jiale Zhao", "Xing Mou", "Jinlin Wu", "Hongyuan Yu", "Mingrui Sun", "Yang Shi", "Xuanwu Yin", "Zhen Chen", "Zhen Lei", "Yaohua Wang"], "title": "The Forgotten Shield: Safety Grafting in Parameter-Space for Medical MLLMs", "comment": null, "summary": "Medical Multimodal Large Language Models (Medical MLLMs) have achieved remarkable progress in specialized medical tasks; however, research into their safety has lagged, posing potential risks for real-world deployment. In this paper, we first establish a multidimensional evaluation framework to systematically benchmark the safety of current SOTA Medical MLLMs. Our empirical analysis reveals pervasive vulnerabilities across both general and medical-specific safety dimensions in existing models, particularly highlighting their fragility against cross-modality jailbreak attacks. Furthermore, we find that the medical fine-tuning process frequently induces catastrophic forgetting of the model's original safety alignment. To address this challenge, we propose a novel \"Parameter-Space Intervention\" approach for efficient safety re-alignment. This method extracts intrinsic safety knowledge representations from original base models and concurrently injects them into the target model during the construction of medical capabilities. Additionally, we design a fine-grained parameter search algorithm to achieve an optimal trade-off between safety and medical performance. Experimental results demonstrate that our approach significantly bolsters the safety guardrails of Medical MLLMs without relying on additional domain-specific safety data, while minimizing degradation to core medical performance.", "AI": {"tldr": "\u533b\u7597\u591a\u6a21\u6001LM\u5b89\u5168\u5b58\u5728\u6f0f\u6d1e\uff0c\u5c24\u5176\u662f\u8de8\u6a21\u6001\u7a81\u7834\u4e0e\u5b89\u5168\u9057\u5fd8\u3002\u672c\u6587\u63d0\u51fa\u53c2\u6570\u7a7a\u95f4\u5e72\u9884\u6cd5\uff0c\u63d0\u53d6\u57fa\u7840\u6a21\u578b\u5b89\u5168\u77e5\u8bc6\u5e76\u6ce8\u5165\u76ee\u6807\u6a21\u578b\uff0c\u7ec6\u7c92\u5ea6\u641c\u7d22\u5e73\u8861\u5b89\u5168\u4e0e\u6027\u80fd\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u5b89\u5168\u663e\u8457\u63d0\u5347\uff0c\u533b\u5b66\u6027\u80fd\u51e0\u4e4e\u4e0d\u53d7\u5f71\u54cd\u3002", "motivation": "\u533b\u7597\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u7814\u7a76\u76f8\u5bf9\u6ede\u540e\uff0c\u53ef\u80fd\u5bfc\u81f4\u771f\u5b9e\u573a\u666f\u90e8\u7f72\u98ce\u9669\u3002\u9700\u7cfb\u7edf\u8bc4\u4f30\u5176\u5b89\u5168\u6027\uff0c\u627e\u51fa\u8584\u5f31\u73af\u8282\uff0c\u5e76\u63d0\u51fa\u9ad8\u6548\u3001\u5b89\u5168\u6027\u518d\u5bf9\u9f50\u65b9\u6848\u3002", "method": "1\uff09\u6784\u5efa\u591a\u7ef4\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u7cfb\u7edf\u5ea6\u91cf\u5f53\u524d\u524d\u6cbf\u6a21\u578b\u7684\u901a\u7528\u4e0e\u533b\u5b66\u5b89\u5168\u7ef4\u5ea6\uff1b2\uff09\u8bbe\u8ba1\u53c2\u6570\u7a7a\u95f4\u5e72\u9884\u673a\u5236\uff0c\u4ece\u57fa\u7840\u6a21\u578b\u4e2d\u63d0\u53d6\u5b89\u5168\u77e5\u8bc6\u8868\u793a\uff0c\u518d\u5c06\u5176\u5e76\u5165\u76ee\u6807\u6a21\u578b\u7684\u533b\u5b66\u6784\u5efa\u9636\u6bb5\uff1b3\uff09\u5236\u5b9a\u7ec6\u7c92\u5ea6\u53c2\u6570\u641c\u7d22\u7b97\u6cd5\uff0c\u5b9e\u73b0\u5b89\u5168\u4e0e\u533b\u5b66\u6027\u80fd\u7684\u6700\u4f18\u6743\u8861\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u53c2\u6570\u7a7a\u95f4\u5e72\u9884\u663e\u8457\u63d0\u5347\u6a21\u578b\u5b89\u5168\u9632\u62a4\u6c34\u5e73\uff0c\u62b5\u5fa1\u8de8\u6a21\u6001 jailbreak \u653b\u51fb\uff0c\u5e76\u5728\u4fdd\u6301\u533b\u5b66\u529f\u80fd\u7684\u540c\u65f6\uff0c\u5c06\u5b89\u5168\u6027\u9057\u5fd8\u6700\u5c0f\u5316\uff1b\u5b89\u5168\u63d0\u5347\u5e45\u5ea6\u5927\uff0c\u6838\u5fc3\u533b\u5b66\u6027\u80fd\u635f\u5931\u6781\u5c0f\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\uff0c\u533b\u7597\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5bf9\u8de8\u6a21\u6001\u7a81\u7834\u653b\u51fb\u53ca\u533b\u5b66\u5fae\u8c03\u540e\u5b89\u5168\u8bb0\u5fc6\u707e\u96be\u6027\u9057\u5fd8\u65f6\u5b58\u5728\u666e\u904d\u7f3a\u9677\u3002\u901a\u8fc7\u5f15\u5165\u53c2\u6570\u7a7a\u95f4\u5e72\u9884\u7b56\u7565\uff0c\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u989d\u5916\u9886\u57df\u5b89\u5168\u6570\u636e\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u91cd\u65b0\u5bf9\u9f50\u6a21\u578b\u5b89\u5168\u6027\uff0c\u5e76\u4fdd\u6301\u6838\u5fc3\u533b\u5b66\u6027\u80fd\u7684\u6700\u5c0f\u8870\u9000\u3002"}}
{"id": "2601.04957", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.04957", "abs": "https://arxiv.org/abs/2601.04957", "authors": ["Xinyi Tao", "Panfeng Huang", "Fan Zhang"], "title": "Safe Reinforcement Learning Beyond Baseline Control: A Hierarchical Framework for Space Triangle Tethered Formation System", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Triangular tethered formation system (TTFS) provide a promising platform for deep space exploration and distributed sensing due to its intrinsic spatial-orientation stability and capability of adjusting distances among node satellites through deployment and retrieval of tethers. However, due to the coupled tether-satellite dynamics and disturbance sensitivity of TTFS, traditional control methods struggle to achieve a balanced trade-off among configuration accuracy requirements, tension constraints, and energy efficiency consumption throughout the deployment process.In this paper, a novel model-reference reinforcement learning control framework is proposed for TTFS. By integrating baseline model-based control with a Soft Actor-Critic (SAC) compensator, the proposed method simultaneously achieves high-precision tracking, fuel efficiency, and compliance with tension limits. A hierarchical training scheme is developed to address the convergence difficulties arising from strongly coupled states in centralized training, while tailored reward functions, reset conditions, and normalization criteria are designed to accelerate training convergence. Closed-loop stability of the overall control law is rigorously proven using Lyapunov methods. Simulation results demonstrate that the proposed controller reduces steady-state tracking errors by over 96% for tethers and 99% for node satellites, while cutting fuel consumption by two orders of magnitude compared with the baseline method. These results validate the effectiveness and stability of the proposed approach for TTFS deployment control.", "AI": {"tldr": "\u57fa\u4e8e\u6a21\u578b\u53c2\u8003\u5f3a\u5316\u5b66\u4e60+SAC\u7684\u5c42\u7ea7\u8bad\u7ec3\u63a7\u5236\u663e\u8457\u63d0\u5347TTFS\u90e8\u7f72\u7cbe\u5ea6\u4e0e\u80fd\u6548\uff0c\u95ed\u73af\u7a33\u5b9a\u6027\u5f97\u5230\u8bc1\u660e\uff0c\u4eff\u771f\u9a8c\u8bc1\u8bef\u5dee\u548c\u71c3\u6599\u6d88\u8017\u5927\u5e45\u964d\u4f4e\u3002", "motivation": "\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\u5728TTFS\u4e2d\u96be\u4ee5\u517c\u987e\u914d\u7f6e\u7cbe\u5ea6\u3001\u5f20\u529b\u7ea6\u675f\u4e0e\u80fd\u6e90\u6548\u7387\uff0c\u4e14\u53d7\u8026\u5408\u52a8\u529b\u5b66\u4e0e\u6270\u52a8\u5f71\u54cd\u663e\u8457\uff0c\u9700\u8981\u65b0\u578b\u63a7\u5236\u7b56\u7565\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6a21\u578b\u53c2\u8003\u7684\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u67b6\u6784\uff0c\u878d\u5408\u8f6f\u6f14\u5458-\u7b56\u52a8\u8005\uff08SAC\uff09\u8865\u507f\u5668\uff0c\u5e76\u6784\u5efa\u5c42\u7ea7\u8bad\u7ec3\u65b9\u6848\uff1b\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\u3001\u590d\u4f4d\u6761\u4ef6\u4e0e\u5f52\u4e00\u5316\u6807\u51c6\u4ee5\u52a0\u901f\u6536\u655b\uff1b\u4f7f\u7528\u674e\u96c5\u666e\u8bfa\u592b\u65b9\u6cd5\u8bc1\u660e\u95ed\u73af\u7a33\u5b9a\u6027\u3002", "result": "\u4eff\u771f\u8868\u660e\u95ed\u73af\u8ddf\u8e2a\u8bef\u5dee\u964d\u4f4e96%\uff08\u7cfb\u6cca\u7ebf\uff09\u548c99%\uff08\u8282\u70b9\u536b\u661f\uff09\uff0c\u71c3\u6599\u6d88\u8017\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u964d\u4f4e\u4e24\u4f4d\u6570\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u4e0e\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u6a21\u578b\u53c2\u8003\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u6846\u67b6\uff0c\u7ed3\u5408\u8f6f\u6f14\u5458-\u7b56\u52a8\u8005\u642d\u914d\u57fa\u7ebf\u6a21\u578b\u63a7\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e09\u89d2\u7cfb\u6cca\u7cfb\u7edf\uff08TTFS\uff09\u90e8\u7f72\u8fc7\u7a0b\u4e2d\u7684\u59ff\u6001\u4e0e\u529b\u5b66\u7cbe\u5ea6\uff0c\u4fdd\u969c\u5f20\u529b\u9650\u5236\u5e76\u663e\u8457\u964d\u4f4e\u71c3\u6599\u6d88\u8017\uff0c\u5b9e\u73b0\u95ed\u73af\u7a33\u5b9a\u6027\u5e76\u5728\u4eff\u771f\u4e2d\u8bc1\u660e\u4e86\u9ad8\u6027\u80fd\u4e0e\u7a33\u5b9a\u6027\u3002"}}
{"id": "2601.04478", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04478", "abs": "https://arxiv.org/abs/2601.04478", "authors": ["Shadeeb Hossain"], "title": "Prediction of Cellular Malignancy Using Electrical Impedance Signatures and Supervised Machine Learning", "comment": null, "summary": "Bioelectrical properties of cells such as relative permittivity, conductivity, and characteristic time constants vary significantly between healthy and malignant cells across different frequencies. These distinctions provide a promising foundation for diagnostic and classification applications. This study systematically reviewed 33 scholarly articles to compile datasets of quantitative bioelectric parameters and evaluated their utility in predictive modeling. Three supervised machine learning algorithms- Random Forest (RF), Support Vector Machine (SVM), and K-Nearest Neighbor (KNN) were implemented and tuned using key hyperparameters to assess classification performance. Model effectiveness was evaluated using accuracy and F1 score as performance metrics. Results demonstrate that Random Forest achieved the highest predictive accuracy of ~ 90% when configured with a maximum depth of 4 and 100 estimators. These findings highlight the potential of integrating bioelectrical property analysis with machine learning for improved diagnostic decision-making. Similarly, for KNN and SVM, the F1 score peaked at approximately 78% and 76.5%, respectively. Future work will explore incorporating additional discriminative features, leveraging stimulated datasets, and optimizing hyperparameter through advanced search strategies. Ultimately, hardware prototype with embedded micro-electrodes and real-time control systems could pave the path for practical diagnostic tools capable of in-situ cell classification.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6839\u636e\u7ec6\u80de\u7535\u5b66\u53c2\u6570\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u968f\u673a\u68ee\u6797\u8868\u73b0\u6700\u4f73\uff0c\u663e\u793a\u51fa\u5728\u764c\u7ec6\u80de\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\u6f5c\u529b", "motivation": "\u7814\u7a76\u7ec6\u80de\u7535\u5b66\u6027\u8d28\u5728\u5065\u5eb7\u4e0e\u6076\u6027\u7ec6\u80de\u95f4\u7684\u5dee\u5f02\uff0c\u4e3a\u8bca\u65ad\u4e0e\u5206\u7c7b\u63d0\u4f9b\u6f5c\u5728\u4f9d\u636e", "method": "\u7cfb\u7edf\u7efc\u8ff033\u7bc7\u6587\u7ae0\uff0c\u6536\u96c6\u91cf\u5316\u7535\u5b66\u53c2\u6570\uff0c\u4f7f\u7528\u968f\u673a\u68ee\u6797\u3001\u652f\u6301\u5411\u91cf\u673a\u3001K\u8fd1\u90bb\u4e09\u79cd\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u8c03\u53c2\u540e\u8bc4\u4f30\u5206\u7c7b\u6027\u80fd\uff08\u51c6\u786e\u7387\u53caF1\u5206\u6570\uff09", "result": "\u968f\u673a\u68ee\u6797\u5728\u6700\u5927\u6df1\u5ea64\u3001100\u68f5\u6811\u65f6\u51c6\u786e\u7387\u7ea690%\uff1bKNN\u548cSVM\u7684F1\u5206\u6570\u5206\u522b\u4e3a78%\u548c76.5%", "conclusion": "\u5c06\u7ec6\u80de\u7535\u5b66\u7279\u6027\u4e0e\u673a\u5668\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u53ef\u663e\u8457\u63d0\u5347\u8bca\u65ad\u51b3\u7b56\u6548\u679c\uff0c\u672a\u6765\u53ef\u901a\u8fc7\u786c\u4ef6\u539f\u578b\u5b9e\u73b0\u73b0\u573a\u7ec6\u80de\u5206\u7c7b"}}
{"id": "2601.04517", "categories": ["cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04517", "abs": "https://arxiv.org/abs/2601.04517", "authors": ["Zimo Yan", "Zheng Xie", "Runfan Duan", "Chang Liu", "Wumei Du"], "title": "Bridging Distance and Spectral Positional Encodings via Anchor-Based Diffusion Geometry Approximation", "comment": null, "summary": "Molecular graph learning benefits from positional signals that capture both local neighborhoods and global topology. Two widely used families are spectral encodings derived from Laplacian or diffusion operators and anchor-based distance encodings built from shortest-path information, yet their precise relationship is poorly understood. We interpret distance encodings as a low-rank surrogate of diffusion geometry and derive an explicit trilateration map that reconstructs truncated diffusion coordinates from transformed anchor distances and anchor spectral positions, with pointwise and Frobenius-gap guarantees on random regular graphs. On DrugBank molecular graphs using a shared GNP-based DDI prediction backbone, a distance-driven Nystr\u00f6m scheme closely recovers diffusion geometry, and both Laplacian and distance encodings substantially outperform a no-encoding baseline.", "AI": {"tldr": "The paper shows that anchor\u2011based distance encodings can approximate diffusion geometry well, and using them (via a trilateration map and Nystr\u00f6m scheme) boosts molecular graph learning performance.", "motivation": "To understand the precise relationship between spectral (Laplacian/diffusion) and anchor\u2011based distance encodings used for positional signals in molecular graph learning, and to develop a principled way to recover diffusion geometry from distance information.", "method": "Interpret distance encodings via a low\u2011rank surrogate of diffusion geometry and construct a trilateration map that reconstructs truncated diffusion coordinates from anchor distances and anchor spectral positions; provide pointwise and Frobenius\u2011gap guarantees on random regular graphs and evaluate a distance\u2011driven Nystr\u00f6m scheme on DrugBank molecular graphs using a shared GNN\u2011based DDI prediction backbone.", "result": "On DrugBank molecular graphs, the distance\u2011driven Nystr\u00f6m scheme closely recovers the diffusion geometry, and both Laplacian and distance encodings substantially outperform a no\u2011encoding baseline in DDI prediction tasks.", "conclusion": "Molecular graph learning benefits from positional signals that capture both local neighborhoods and global topology; distance encodings can serve as a low-rank surrogate of diffusion geometry and recover diffusion coordinates effectively, leading to improved performance over no-encoding baselines."}}
{"id": "2601.04250", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04250", "abs": "https://arxiv.org/abs/2601.04250", "authors": ["Mustapha Hamdi", "Mourad Jabou"], "title": "Green MLOps: Closed-Loop, Energy-Aware Inference with NVIDIA Triton, FastAPI, and Bio-Inspired Thresholding", "comment": "6 pages, 4 figures. Code available at:https://github.com/InnoDeep-repos/Green_MLOps", "summary": "Energy efficiency is a first-order concern in AI deployment, as long-running inference can exceed training in cumulative carbon impact. We propose a bio-inspired framework that maps protein-folding energy basins to inference cost landscapes and controls execution via a decaying, closed-loop threshold. A request is admitted only when the expected utility-to-energy trade-off is favorable (high confidence/utility at low marginal energy and congestion), biasing operation toward the first acceptable local basin rather than pursuing costly global minima. We evaluate DistilBERT and ResNet-18 served through FastAPI with ONNX Runtime and NVIDIA Triton on an RTX 4000 Ada GPU. Our ablation study reveals that the bio-controller reduces processing time by 42% compared to standard open-loop execution (0.50s vs 0.29s on A100 test set), with a minimal accuracy degradation (<0.5%). Furthermore, we establish the efficiency boundaries between lightweight local serving (ORT) and managed batching (Triton). The results connect biophysical energy models to Green MLOps and offer a practical, auditable basis for closed-loop energy-aware inference in production.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.05070", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.05070", "abs": "https://arxiv.org/abs/2601.05070", "authors": ["Maitraya Avadhut Desai", "Ognjen Stanojev", "Simon Muntwiler", "Gabriela Hug"], "title": "Effect of Dispatch Decisions on Small-Signal Stability of Converter-Dominated Power Systems", "comment": null, "summary": "Small-signal stability of modern converter-dominated power systems has been the subject of extensive research, particularly from the perspective of device-level control design for grid-forming (GFM) and grid-following (GFL) converters. However, the influence of power flow variables on system stability has received limited attention. Conventional small-signal stability analyses are typically conducted at a specific operating point, emphasizing the selection of control or system design parameters while neglecting the sensitivity of stability characteristics to operating conditions. This paper seeks to bridge this gap by systematically investigating the impact of dispatch decisions on the small-signal stability of converter-based power systems. Our findings are first illustrated on a three-bus system and then validated on the standard IEEE 39-bus test system to demonstrate scalability. Across the test systems, we find that high-voltage capacitive operation of GFL converters limits its active power injection, whereas inductive operation permits higher injections, and it is generally preferable for the GFM converter to supply more active power.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u63a2\u8ba8\u4e86\u6295 dispatch \u4e0e small\u2011signal stability \u7684\u5173\u7cfb\uff0c\u7ed3\u679c\u663e\u793a GFL \u7684\u7535\u5bb9/\u7535\u611f\u6a21\u5f0f\u53ca GFM \u7684\u529f\u7387\u5206\u914d\u5bf9\u7a33\u5b9a\u6027\u5f71\u54cd\u663e\u8457\uff0c\u63d0\u4f9b\u4e86\u51b3\u7b56\u53c2\u8003\u3002", "motivation": "\u8fc7\u53bb\u7684\u5c0f\u4fe1\u53f7\u7a33\u5b9a\u6027\u7814\u7a76\u591a\u805a\u7126\u4e8e\u63a7\u5236\u8bbe\u8ba1\uff0c\u5ffd\u7565\u4e86\u529f\u7387\u6d41\u53d8\u91cf\u4e0e\u5de5\u51b5\u5bf9\u7cfb\u7edf\u7a33\u5b9a\u6027\u7684\u654f\u611f\u6027\uff0c\u5bfc\u81f4\u5728\u5b9e\u9645\u8c03\u5ea6\u7b56\u7565\u672a\u80fd\u5145\u5206\u8003\u8651\u7a33\u5b9a\u6027\u7684\u573a\u666f\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u5316\u7684\u53c2\u6570\u7075\u654f\u5ea6\u5206\u6790\u65b9\u6cd5\uff0c\u5bf9\u4e09\u8282\u70b9\u7cfb\u7edf\u548cIEEE 39\u8282\u70b9\u6807\u51c6\u7cfb\u7edf\u8fdb\u884c\u9010\u5de5\u51b5\u6a21\u62df\uff0c\u8bc4\u4f30\u4e0d\u540c\u8c03\u5ea6\u4e0b\u7684\u7535\u538b\u3001\u7535\u6d41\u53ca\u9891\u7387\u8026\u5408\u5bf9\u5c0f\u4fe1\u53f7\u7a33\u5b9a\u8fb9\u754c\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u9ad8\u538b\u7535\u5bb9\u5f0fGFL\u64cd\u4f5c\u4f1a\u9650\u5236\u5176\u6709\u529f\u529f\u7387\u6ce8\u5165\uff0c\u7535\u611f\u5f0f\u8fd0\u884c\u53ef\u63d0\u5347\u6ce8\u5165\u80fd\u529b\uff1b\u901a\u5e38\u66f4\u4f18\u7684\u7b56\u7565\u662f\u8ba9GFM\u8f6c\u6362\u5668\u627f\u62c5\u66f4\u591a\u6709\u529f\u529f\u7387\u3002\u8be5\u7ed3\u8bba\u5728\u4e09\u8282\u70b9\u548cIEEE39\u8282\u70b9\u7cfb\u7edf\u4e0a\u5747\u5f97\u5230\u9a8c\u8bc1\uff0c\u5e76\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u672c\u6587\u6307\u51fa\u5728\u4e3a\u4e3b\u7684\u7535\u80fd\u8f6c\u6362\u5668\u7535\u529b\u7cfb\u7edf\u4e2d\uff0c\u8003\u8651\u7535\u52a8\u5ea6\u91cf\u53d8\u91cf\u4e0e\u8c03\u5ea6\u51b3\u7b56\u5bf9\u5c0f\u4fe1\u53f7\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\u81f3\u5173\u91cd\u8981\u3002\u901a\u8fc7\u5728\u4e0d\u540c\u5de5\u51b5\u4e0b\u7cfb\u7edf\u5730\u5206\u6790\uff0c\u5c0f\u4fe1\u53f7\u7a33\u5b9a\u6027\u53d7\u8c03\u5ea6\u5f15\u5bfc\u663e\u8457\u6539\u53d8\uff0c\u5c24\u5176\u662fGFM\u548cGFL\u8f6c\u6362\u5668\u7684\u529f\u7387\u4e0a\u9650\u4e0e\u5de5\u4f5c\u6a21\u5f0f\u51b3\u5b9a\u4e86\u7cfb\u7edf\u7684\u6574\u4f53\u7a33\u5b9a\u533a\u57df\u3002"}}
{"id": "2601.04488", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04488", "abs": "https://arxiv.org/abs/2601.04488", "authors": ["Yinghui He", "Long Fan", "Lei Xie", "Dusit Niyato", "Chau Yuen", "Jun Luo"], "title": "Invisible Walls: Privacy-Preserving ISAC Empowered by Reconfigurable Intelligent Surfaces", "comment": "This paper has been submitted to IEEE", "summary": "The environmental and target-related information inherently carried in wireless signals, such as channel state information (CSI), has brought increasing attention to integrated sensing and communication (ISAC). However, it also raises pressing concerns about privacy leakage through eavesdropping. While existing efforts have attempted to mitigate this issue, they either fail to account for the needs of legitimate communication and sensing users or rely on hardware with high complexity and cost. To overcome these limitations, we propose PrivISAC, a plug-and-play, low-cost solution that leverages RIS to protect user privacy while preserving ISAC performance. At the core of PrivISAC is a novel strategy in which each RIS row is assigned two distinct beamforming vectors, from which we deliberately construct a limited set of RIS configurations. During operation, exactly one configuration is randomly activated at each time slot to introduce additional perturbations, effectively masking sensitive sensing information from unauthorized eavesdroppers. To jointly ensure privacy protection and communication performance, we design the two vectors such that their responses remain nearly identical in the communication direction, thereby preserving stable, high-throughput transmission, while exhibiting pronounced differences in the sensing direction, which introduces sufficient perturbations to thwart eavesdroppers. Additionally, to enable legitimate sensing under such randomized configurations, we introduce a time-domain masking and demasking method that allows the authorized receiver to associate each CSI sample with its underlying configuration and eliminate configuration-induced discrepancies, thereby recovering valid CSI. We implement PrivISAC on commodity wireless devices and experiment results show that PrivISAC provides strong privacy protection while preserving high-quality legitimate ISAC.", "AI": {"tldr": "privisc\u7684\u4e3b\u8981\u601d\u8def\u662f\uff1a\u5728ris\u4e0a\u7528\u4e24\u7ec4\u8fd1\u4f3c\u76f8\u540c\u901a\u4fe1\u54cd\u5e94\u4f46\u5dee\u5f02\u8f83\u5927\u7684\u611f\u77e5\u5411\u91cf\u968f\u673a\u7ec4\u5408\u914d\u7f6e\uff0c\u52a0\u5165\u65f6\u57df\u63a9\u7801/\u53bb\u63a9\u7801\uff0c\u8ba9\u5408\u6cd5\u63a5\u6536\u65b9\u53ef\u6062\u590d\u6240\u9700csi\uff0c\u5b9e\u9a8c\u652f\u6491\u4e86\u5b83\u65e2\u80fd\u9690\u533f\u9690\u79c1\u4e5f\u4e0d\u5f71\u54cd\u901a\u4fe1/\u611f\u77e5\u3002", "motivation": "\u65e0\u7ebf\u4fe1\u53f7\u6240\u643a\u5e26\u7684\u73af\u5883\u548c\u76ee\u6807\u76f8\u5173\u4fe1\u606f\u5728\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u4e2d\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u73b0\u6709\u65b9\u6848\u65e0\u6cd5\u517c\u987e\u5408\u6cd5\u7528\u6237\u9700\u6c42\u6216\u6210\u672c\u9ad8\u6602\u3002", "method": "PrivISAC\u901a\u8fc7\u5728RIS\u6bcf\u884c\u5206\u914d\u4e24\u7ec4\u4e0d\u540c\u6ce2\u675f\u5411\u91cf\uff0c\u6784\u9020\u6709\u9650\u7684RIS\u914d\u7f6e\u96c6\uff1b\u6bcf\u4e2a\u65f6\u9699\u968f\u673a\u6fc0\u6d3b\u4e00\u7ec4\u914d\u7f6e\uff0c\u5f15\u5165\u6270\u52a8\u9690\u85cf\u654f\u611f\u4fe1\u606f\u3002\u4e24\u7ec4\u5411\u91cf\u5728\u901a\u4fe1\u65b9\u5411\u54cd\u5e94\u76f8\u8fd1\u3001\u5728\u611f\u77e5\u65b9\u5411\u5dee\u5f02\u660e\u663e\uff1b\u540c\u65f6\u5f15\u5165\u65f6\u57df\u63a9\u7801/\u53bb\u63a9\u7801\u6280\u672f\uff0c\u4f7f\u5408\u6cd5\u63a5\u6536\u8005\u53ef\u5173\u8054CSI\u4e0e\u914d\u7f6e\u5e76\u6d88\u9664\u5dee\u5f02\u4ee5\u6062\u590d\u6709\u6548CSI\u3002", "result": "\u5b9e\u9a8c\u8868\u660ePrivISAC\u5728\u5546\u7528\u65e0\u7ebf\u8bbe\u5907\u4e0a\u5b9e\u73b0\uff0c\u65e2\u4fdd\u969c\u9690\u79c1\uff0c\u53c8\u4fdd\u6301\u4e86\u9ad8\u8d28\u91cf\u7684\u5408\u6cd5ISAC\u6027\u80fd\u3002", "conclusion": "PrivISAC\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u53ef\u5373\u63d2\u5373\u7528\u7684RIS\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u5408\u6cd5\u901a\u4fe1\u548c\u611f\u77e5\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2601.04247", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04247", "abs": "https://arxiv.org/abs/2601.04247", "authors": ["Zhixin Liu", "Xuanlin Liu", "Sihan Xu", "Yaqiong Qiao", "Ying Zhang", "Xiangrui Cai"], "title": "Beyond Immediate Activation: Temporally Decoupled Backdoor Attacks on Time Series Forecasting", "comment": null, "summary": "Existing backdoor attacks on multivariate time series (MTS) forecasting enforce strict temporal and dimensional coupling between triggers and target patterns, requiring synchronous activation at fixed positions across variables. However, realistic scenarios often demand delayed and variable-specific activation. We identify this critical unmet need and propose TDBA, a temporally decoupled backdoor attack framework for MTS forecasting. By injecting triggers that encode the expected location of the target pattern, TDBA enables the activation of the target pattern at any positions within the forecasted data, with the activation position flexibly varying across different variable dimensions. TDBA introduces two core modules: (1) a position-guided trigger generation mechanism that leverages smoothed Gaussian priors to generate triggers that are position-related to the predefined target pattern; and (2) a position-aware optimization module that assigns soft weights based on trigger completeness, pattern coverage, and temporal offset, facilitating targeted and stealthy attack optimization. Extensive experiments on real-world datasets show that TDBA consistently outperforms existing baselines in effectiveness while maintaining good stealthiness. Ablation studies confirm the controllability and robustness of its design.", "AI": {"tldr": "TDBA\u901a\u8fc7\u4f4d\u7f6e\u7f16\u7801\u89e6\u53d1\u5668\u5b9e\u73b0\u65f6\u95f4\u4e0e\u7ef4\u5ea6\u89e3\u8026\u7684\u540e\u95e8\u653b\u51fb\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u63d0\u5347\u653b\u51fb\u6548\u679c\u7684\u540c\u65f6\u4fdd\u6301\u9690\u853d\u6027\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u653b\u51fb\u5728\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u9700\u4e25\u683c\u65f6\u5e8f\u4e0e\u7ef4\u5ea6\u8026\u5408\uff0c\u96be\u4ee5\u6ee1\u8db3\u73b0\u5b9e\u4e2d\u5bf9\u63a8\u8fdf\u4e14\u53d8\u91cf\u7279\u5b9a\u6fc0\u6d3b\u7684\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u4f4d\u7f6e\u5f15\u5bfc\u89e6\u53d1\u5668\u751f\u6210\u673a\u5236\u4e0e\u57fa\u4e8e\u4f4d\u7f6e\u7684\u4f18\u5316\u6a21\u5757\uff0c\u4f7f\u89e6\u53d1\u5668\u80fd\u591f\u5bf9\u9884\u5b9a\u76ee\u6807\u6a21\u5f0f\u8fdb\u884c\u4f4d\u7f6e\u76f8\u5173\u7f16\u7801\uff0c\u5e76\u6839\u636e\u89e6\u53d1\u5668\u5b8c\u6574\u5ea6\u3001\u6a21\u5f0f\u8986\u76d6\u5ea6\u4e0e\u65f6\u95f4\u504f\u79fb\u7ed9\u51fa\u8f6f\u6743\u91cd\uff0c\u5b9e\u73b0\u7075\u6d3b\u3001\u53ef\u63a7\u4e14\u9690\u853d\u7684\u653b\u51fb\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u4e2d\uff0cTDBA\u5728\u6709\u6548\u6027\u4e0a\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u9690\u853d\u6027\uff1b\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u63a7\u5236\u6027\u4e0e\u9c81\u68d2\u6027\u3002", "conclusion": "TDBA\u5728\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u9c81\u68d2\u6027\u3001\u53ef\u63a7\u6027\u4e0e\u9690\u853d\u6027\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u6784\u5efa\u4e86\u66f4\u5177\u5b9e\u7528\u6027\u7684\u540e\u95e8\u653b\u51fb\u6846\u67b6\u3002"}}
{"id": "2601.04262", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04262", "abs": "https://arxiv.org/abs/2601.04262", "authors": ["Wang Cai", "Yilin Wen", "Jinchang Hou", "Du Su", "Guoqiu Wang", "Zhonghou Lv", "Chenfu Bao", "Yunfang Wu"], "title": "Safety-Utility Conflicts Are Not Global: Surgical Alignment via Head-Level Diagnosis", "comment": null, "summary": "Safety alignment in Large Language Models (LLMs) inherently presents a multi-objective optimization conflict, often accompanied by an unintended degradation of general capabilities. Existing mitigation strategies typically rely on global gradient geometry to resolve these conflicts, yet they overlook Modular Heterogeneity within Transformers, specifically that the functional sensitivity and degree of conflict vary substantially across different attention heads. Such global approaches impose uniform update rules across all parameters, often resulting in suboptimal trade-offs by indiscriminately updating utility sensitive heads that exhibit intense gradient conflicts. To address this limitation, we propose Conflict-Aware Sparse Tuning (CAST), a framework that integrates head-level diagnosis with sparse fine-tuning. CAST first constructs a pre-alignment conflict map by synthesizing Optimization Conflict and Functional Sensitivity, which then guides the selective update of parameters. Experiments reveal that alignment conflicts in LLMs are not uniformly distributed. We find that the drop in general capabilities mainly comes from updating a small group of ``high-conflict'' heads. By simply skipping these heads during training, we significantly reduce this loss without compromising safety, offering an interpretable and parameter-efficient approach to improving the safety-utility trade-off.", "AI": {"tldr": "CAST \u5bf9 LLM \u7684\u5b89\u5168\u5fae\u8c03\u63d0\u51fa\u5934\u7ea7\u8bca\u65ad\u4e0e\u7a00\u758f\u66f4\u65b0\u65b9\u6cd5\uff0c\u8df3\u8fc7\u9ad8\u51b2\u7a81\u5934\u663e\u8457\u7f13\u89e3\u901a\u7528\u80fd\u529b\u4e0b\u964d\uff0c\u4fdd\u6301\u5b89\u5168\u6027\u3002", "motivation": "\u5168\u5c40\u68af\u5ea6\u8c03\u8282\u5ffd\u89c6\u4e86 Transformer \u4e2d\u4e0d\u540c\u5934\u7684\u5f02\u8d28\u6027\uff0c\u5bfc\u81f4\u91cd\u8981\u529f\u80fd\u88ab\u4e0d\u5fc5\u8981\u5730\u7834\u574f\u3002", "method": "\u5148\u8ba1\u7b97\u4f18\u5316\u51b2\u7a81\u4e0e\u529f\u80fd\u654f\u611f\u5ea6\u7684\u7ec4\u5408\u5f97\u5230\u51b2\u7a81\u5730\u56fe\uff0c\u7136\u540e\u5728\u7a00\u758f\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u53ea\u66f4\u65b0\u4f4e\u51b2\u7a81\u5934\uff0c\u8df3\u8fc7\u9ad8\u51b2\u7a81\u5934\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u4f4e\u51b2\u7a81\u5934\u5360\u5927\u591a\u6570\uff0c\u4e00\u5c0f\u90e8\u5206\u9ad8\u51b2\u7a81\u5934\u7684\u66f4\u65b0\u5bfc\u81f4\u5927\u591a\u6570\u4e00\u822c\u80fd\u529b\u4e0b\u964d\uff0c\u53bb\u9664\u8fd9\u4e9b\u5934\u53ef\u5927\u5e45\u964d\u4f4e\u635f\u5931\u3002", "conclusion": "\u901a\u8fc7\u9488\u5bf9\u9ad8\u51b2\u7a81\u6ce8\u610f\u529b\u5934\u7684\u7a00\u758f\u5fae\u8c03\uff0cCAST \u80fd\u5728\u4e0d\u663e\u8457\u635f\u5931\u5b89\u5168\u6027\u7684\u524d\u63d0\u4e0b\u663e\u8457\u51cf\u5c11\u4e00\u822c\u80fd\u529b\u7684\u4e0b\u964d\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u4f18\u7684\u5b89\u5168-\u6548\u7528\u6743\u8861\u3002"}}
{"id": "2601.05087", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.05087", "abs": "https://arxiv.org/abs/2601.05087", "authors": ["Francesco Bianchin", "Robert Lefringhausen", "Sandra Hirche"], "title": "Online Bayesian Learning of Agent Behavior in Differential Games", "comment": null, "summary": "This work introduces an online Bayesian game-theoretic method for behavior identification in multi-agent dynamical systems. By casting Hamilton-Jacobi-Bellman optimality conditions as linear-in-parameter residuals, the method enables fast sequential Bayesian updates, uncertainty-aware inference, and robust prediction from limited, noisy data-without history stacks. The approach accommodates nonlinear dynamics and nonquadratic value functions through basis expansions, providing flexible models. Experiments, including linear-quadratic and nonlinear shared-control scenarios, demonstrate accurate prediction with quantified uncertainty, highlighting the method's relevance for adaptive interaction and real-time decision making.", "AI": {"tldr": "\u5c06HJB\u6761\u4ef6\u7ebf\u6027\u5316\u505a\u4e3a\u8d1d\u53f6\u65af\u66f4\u65b0\u7684\u6b8b\u5dee\uff0c\u5229\u7528\u57fa\u51fd\u6570\u6269\u5c55\u5b9e\u73b0\u5728\u7ebf\u591a\u667a\u80fd\u4f53\u884c\u4e3a\u8bc6\u522b\uff0c\u5b9e\u9a8c\u8868\u660e\u9884\u6d4b\u7cbe\u5ea6\u9ad8\u4e14\u53ef\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u9700\u8981\u5728\u6709\u9650\u3001\u5e26\u566a\u6570\u636e\u4e0b\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u884c\u4e3a\u8fdb\u884c\u5b9e\u65f6\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u9884\u6d4b\uff0c\u4ee5\u652f\u6301\u81ea\u9002\u5e94\u4ea4\u4e92\u548c\u5b9e\u65f6\u51b3\u7b56\u3002", "method": "\u901a\u8fc7\u5c06Hamilton\u2011Jacobi\u2011Bellman\u6700\u4f18\u6027\u6761\u4ef6\u8f6c\u5316\u4e3a\u7ebf\u6027\u53c2\u6570\u6b8b\u5dee\uff0c\u4f7f\u7528\u57fa\u51fd\u6570\u6269\u5c55\uff0c\u5e94\u5bf9\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u4e0e\u975e\u4e8c\u6b21\u4ef7\u503c\u51fd\u6570\uff0c\u4ece\u800c\u5b9e\u73b0\u5feb\u901f Bayesian \u66f4\u65b0\u3002", "result": "\u5728\u7ebf\u6027\u4e8c\u6b21\u4e0e\u975e\u7ebf\u6027\u5171\u4eab\u63a7\u5236\u5b9e\u9a8c\u4e2d\uff0c\u6a21\u578b\u5b9e\u73b0\u4e86\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u7684\u51c6\u786e\u9884\u6d4b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5728\u7ebf\u8d1d\u53f6\u65af\u535a\u5f08\u65b9\u6cd5\uff0c\u53ef\u5728\u591a\u667a\u80fd\u4f53\u52a8\u529b\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u884c\u4e3a\u8bc6\u522b\uff0c\u5e76\u652f\u6301\u5e8f\u8d2f\u66f4\u65b0\u548c\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u3002"}}
{"id": "2601.04261", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.04261", "abs": "https://arxiv.org/abs/2601.04261", "authors": ["Hang Fu", "Wanli Peng", "Yinghan Zhou", "Jiaxuan Wu", "Juan Wen", "Yiming Xue"], "title": "Inhibitory Attacks on Backdoor-based Fingerprinting for Large Language Models", "comment": null, "summary": "The widespread adoption of Large Language Model (LLM) in commercial and research settings has intensified the need for robust intellectual property protection. Backdoor-based LLM fingerprinting has emerged as a promising solution for this challenge. In practical application, the low-cost multi-model collaborative technique, LLM ensemble, combines diverse LLMs to leverage their complementary strengths, garnering significant attention and practical adoption. Unfortunately, the vulnerability of existing LLM fingerprinting for the ensemble scenario is unexplored. In order to comprehensively assess the robustness of LLM fingerprinting, in this paper, we propose two novel fingerprinting attack methods: token filter attack (TFA) and sentence verification attack (SVA). The TFA gets the next token from a unified set of tokens created by the token filter mechanism at each decoding step. The SVA filters out fingerprint responses through a sentence verification mechanism based on perplexity and voting. Experimentally, the proposed methods effectively inhibit the fingerprint response while maintaining ensemble performance. Compared with state-of-the-art attack methods, the proposed method can achieve better performance. The findings necessitate enhanced robustness in LLM fingerprinting.", "AI": {"tldr": "\u5728LLM\u96c6\u6210\u73af\u5883\u4e0b\uff0c\u73b0\u6709\u6307\u7eb9\u8bc6\u522b\u9762\u4e34\u5f31\u70b9\uff1b\u4f5c\u8005\u8bbe\u8ba1\u4e86TFA\u548cSVA\u4e24\u79cd\u653b\u51fb\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u9ad8\u6548\u6027\uff0c\u63d0\u793a\u9700\u52a0\u56fa\u6307\u7eb9\u9632\u62a4\u3002", "motivation": "\u5546\u4e1a\u4e0e\u79d1\u7814\u4e2d\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u4f7f\u7528\uff0c\u7248\u6743\u4fdd\u62a4\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\uff1b\u4f46\u76ee\u524d\u9488\u5bf9LLM\u96c6\u6210\u7684\u6307\u7eb9\u53ef\u9760\u6027\u5c1a\u672a\u5f97\u5230\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b0\u578b\u653b\u51fb\u6280\u672f\uff1aToken Filter Attack (TFA) \u901a\u8fc7\u5728\u6bcf\u4e2a\u89e3\u7801\u6b65\u9aa4\u4ece\u7edf\u4e00\u7684 token \u96c6\u4e2d\u9009\u62e9\u4e0b\u4e00\u4e2a token\uff1bSentence Verification Attack (SVA) \u57fa\u4e8e\u56f0\u60d1\u5ea6\u4e0e\u6295\u7968\u673a\u5236\u8fc7\u6ee4\u6307\u7eb9\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTFA \u4e0e SVA \u80fd\u6709\u6548\u6291\u5236\u6307\u7eb9\u54cd\u5e94\uff0c\u540c\u65f6\u4fdd\u6301\u96c6\u6210\u6a21\u578b\u6027\u80fd\uff0c\u4e14\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u6307\u51fa\uff0c\u5728\u591a\u6a21\u578b\u96c6\u6210\u573a\u666f\u4e0b\u73b0\u6709\u7684LLM\u6307\u7eb9\u8bc6\u522b\u65b9\u6cd5\u6613\u88ab\u8fed\u4ee3\u653b\u51fb\uff0c\u5efa\u8bae\u5fc5\u987b\u63d0\u5347\u6307\u7eb9\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.04723", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04723", "abs": "https://arxiv.org/abs/2601.04723", "authors": ["Zhenyu Li", "Ozan Alp Topal", "\u00d6zlem Tu\u011ffe Demir", "Emil Bj\u00f6rnson", "Cicek Cavdar"], "title": "Feasibility Study Regarding Self-sustainable Reconfigurable Intelligent Surfaces", "comment": "5pages, 3 figures, submitted and accepted by IEEE Wireless Communication Letter", "summary": "Without requiring operational costs such as cabling and powering while maintaining reconfigurable phase-shift capability, self-sustainable reconfigurable intelligent surfaces (ssRISs) can be deployed in locations inaccessible to conventional relays or base stations, offering a novel approach to enhance wireless coverage. This study assesses the feasibility of ssRIS deployment by analyzing two harvest-and-reflect (HaR) schemes: element-splitting (ES) and time-splitting (TS). We examine how element requirements scale with key system parameters, transmit power, data rate demands, and outage constraints under both line-of-sight (LOS) and non-line-of-sight (NLOS) ssRIS-to-user equipment (UE) channels. Analytical and numerical results reveal distinct feasibility characteristics. The TS scheme demonstrates better channel hardening gain, maintaining stable element requirements across varying outage margins, making it advantageous for indoor deployments with favorable harvesting conditions and moderate data rates. However, TS exhibits an element requirement that exponentially scales to harvesting difficulty and data rate. Conversely, the ES scheme shows only linear growth with harvesting difficulty, providing better feasibility under challenging outdoor scenarios. These findings establish that TS excels in benign environments, prioritizing reliability, while ES is preferable for demanding conditions requiring operational robustness.", "AI": {"tldr": "\u7814\u7a76\u8bc1\u660essRIS\u53ef\u884c\uff1aTS\u9002\u5408\u5ba4\u5185\u5c0f\u529f\u7387\u573a\u666f\uff0cES\u9002\u5408\u6237\u5916\u9ad8\u9700\u6c42\u573a\u666f\u3002", "motivation": "\u901a\u8fc7\u81ea\u6211\u53ef\u6301\u7eed\u7684RIS\uff0c\u96f6\u8fd0\u7ef4\u6210\u672c\uff0c\u5728\u4f20\u7edf\u57fa\u7ad9\u65e0\u6cd5\u8986\u76d6\u7684\u4f4d\u7f6e\u63d0\u5347\u8986\u76d6\u3002", "method": "\u5bf9\u6bd4\u5206\u6790\u4e24\u79cdHaR\u65b9\u6848\uff08ES\u4e0eTS\uff09\uff0c\u5728LOS/NLOS\u3001\u53d1\u5c04\u529f\u7387\u3001\u6570\u636e\u901f\u7387\u4e0e\u53ef\u9760\u6027\u7ea6\u675f\u4e0b\u8bc4\u4f30\u6240\u9700\u5929\u7ebf\u6570\u91cf\u4e0e\u6027\u80fd\u3002", "result": "TS\u5728\u53ef\u9760\u6027\u8981\u6c42\u4e0b\u9700\u6c42\u7a33\u5b9a\uff0c\u4f46\u968f\u91c7\u96c6\u96be\u5ea6\u4e0e\u901f\u7387\u5448\u6307\u6570\u589e\u957f\uff1bES\u5219\u968f\u96be\u5ea6\u7ebf\u6027\u589e\u957f\uff0c\u9002\u5408\u6076\u52a3\u73af\u5883\u3002", "conclusion": "TS\u5728\u5ba4\u5185\u65e0\u969c\u788d\u73af\u5883\u4e0b\u8868\u73b0\u66f4\u4f18\uff0cES\u5728\u6237\u5916\u6076\u52a3\u6761\u4ef6\u4e0b\u66f4\u5177\u53ef\u884c\u6027\u3002"}}
{"id": "2601.04265", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.04265", "abs": "https://arxiv.org/abs/2601.04265", "authors": ["Weihao Shen", "Yaxin Xu", "Shuang Li", "Wei Chen", "Yuqin Lan", "Meng Yuan", "Fuzhen Zhuang"], "title": "You Only Anonymize What Is Not Intent-Relevant: Suppressing Non-Intent Privacy Evidence", "comment": "23 pages, 8 figures", "summary": "Anonymizing sensitive information in user text is essential for privacy, yet existing methods often apply uniform treatment across attributes, which can conflict with communicative intent and obscure necessary information. This is particularly problematic when personal attributes are integral to expressive or pragmatic goals. The central challenge lies in determining which attributes to protect, and to what extent, while preserving semantic and pragmatic functions. We propose IntentAnony, a utility-preserving anonymization approach that performs intent-conditioned exposure control. IntentAnony models pragmatic intent and constructs privacy inference evidence chains to capture how distributed cues support attribute inference. Conditioned on intent, it assigns each attribute an exposure budget and selectively suppresses non-intent inference pathways while preserving intent-relevant content, semantic structure, affective nuance, and interactional function. We evaluate IntentAnony using privacy inference success rates, text utility metrics, and human evaluation. The results show an approximately 30% improvement in the overall privacy--utility trade-off, with notably stronger usability of anonymized text compared to prior state-of-the-art methods. Our code is available at https://github.com/Nevaeh7/IntentAnony.", "AI": {"tldr": "IntentAnony \u662f\u4e00\u79cd\u57fa\u4e8e\u610f\u56fe\u7684\u533f\u540d\u5316\u65b9\u6cd5\uff0c\u5229\u7528\u66dd\u5149\u9884\u7b97\u548c\u9690\u79c1\u8bc1\u636e\u94fe\u5b9a\u5236\u5316\u5904\u7406\u5c5e\u6027\uff0c\u63d0\u5347 30% \u7684\u9690\u79c1\u2013\u53ef\u7528\u6027\u5e73\u8861\uff0c\u5e76\u589e\u5f3a\u6587\u672c\u53ef\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u533f\u540d\u5316\u6280\u672f\u7edf\u4e00\u5904\u7406\u6240\u6709\u5c5e\u6027\uff0c\u5e38\u51b2\u7a81\u901a\u4fe1\u610f\u56fe\u5e76\u9690\u85cf\u5fc5\u8981\u4fe1\u606f\uff0c\u5c24\u5176\u5f53\u4e2a\u4eba\u5c5e\u6027\u5bf9\u8868\u8fbe\u6216\u5b9e\u8df5\u76ee\u6807\u81f3\u5173\u91cd\u8981\u65f6\uff0c\u5982\u4f55\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u4e0e\u5b9e\u7528\u6027\u6210\u4e3a\u6838\u5fc3\u6311\u6218\u3002", "method": "\u91c7\u7528\u610f\u56fe\u5206\u6790\u4e0e\u9690\u79c1\u63a8\u7406\u8bc1\u636e\u94fe\u6784\u5efa\uff0c\u4e3a\u6bcf\u4e2a\u5c5e\u6027\u5206\u914d\u66dd\u5149\u9884\u7b97\uff0c\u5e76\u5728\u4fdd\u6301\u610f\u56fe\u76f8\u5173\u5185\u5bb9\u7684\u540c\u65f6\uff0c\u6291\u5236\u975e\u610f\u56fe\u63a8\u7406\u8def\u5f84\uff0c\u5b9e\u73b0\u5b9a\u5236\u5316\u7684\u533f\u540d\u5316\u3002", "result": "\u5728\u9690\u79c1\u63a8\u7406\u6210\u529f\u7387\u3001\u6587\u672c\u53ef\u7528\u6027\u6307\u6807\u548c\u4eba\u5de5\u8bc4\u4f30\u4e0a\uff0cIntentAnony\u663e\u793a\u51fa\u6574\u4f53\u9690\u79c1-\u53ef\u7528\u6027\u6298\u8877\u7ea630% \u7684\u63d0\u5347\uff0c\u5e76\u4e14\u533f\u540d\u6587\u672c\u7684\u53ef\u7528\u6027\u660e\u663e\u4f18\u4e8e\u5148\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "IntentAnony\u901a\u8fc7\u610f\u56fe\u6761\u4ef6\u4e0b\u7684\u66dd\u5149\u63a7\u5236\uff0c\u5b9e\u73b0\u5728\u9690\u79c1\u4e0e\u53ef\u7528\u6027\u4e4b\u95f4\u663e\u8457\u63d0\u5347\uff08\u7ea630%\uff09\uff0c\u5e76\u5728\u4fdd\u6301\u8bed\u4e49\u3001\u60c5\u611f\u7ec6\u5fae\u5dee\u522b\u548c\u4e92\u52a8\u529f\u80fd\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2601.04815", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.04815", "abs": "https://arxiv.org/abs/2601.04815", "authors": ["Amirreza Zamani", "Parastoo Sadeghi", "Mikael Skoglund"], "title": "Privacy-Utility Trade-offs Under Multi-Level Point-Wise Leakage Constraints", "comment": null, "summary": "An information-theoretic privacy mechanism design is studied, where an agent observes useful data $Y$ which is correlated with the private data $X$. The agent wants to reveal the information to a user, hence, the agent utilizes a privacy mechanism to produce disclosed data $U$ that can be revealed. We assume that the agent has no direct access to $X$, i.e., the private data is hidden. We study privacy mechanism design that maximizes the disclosed information about $Y$, measured by the mutual information between $Y$ and $U$, while satisfying a point-wise constraint with different privacy leakage budgets. We introduce a new measure, called the \\emph{multi-level point-wise leakage}, which allows us to impose different leakage levels for different realizations of $U$. In contrast to previous studies on point-wise measures, which use the same leakage level for each realization, we consider a more general scenario in which each data point can leak information up to a different threshold. As a result, this concept also covers cases in which some data points should not leak any information about the private data, i.e., they must satisfy perfect privacy. In other words, a combination of perfect privacy and non-zero leakage can be considered. When the leakage is sufficiently small, concepts from information geometry allow us to locally approximate the mutual information. We show that when the leakage matrix $P_{X|Y}$ is invertible, utilizing this approximation leads to a quadratic optimization problem that has closed-form solution under some constraints. In particular, we show that it is sufficient to consider only binary $U$ to attain the optimal utility. This leads to simple privacy designs with low complexity which are based on finding the maximum singular value and singular vector of a matrix.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u5c42\u70b9\u9645\u6cc4\u6f0f\u9690\u79c1\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u4fe1\u606f\u51e0\u4f55\u4e0e\u77e9\u9635\u5947\u5f02\u503c\u5206\u6790\u5f97\u5230\u4e8c\u6b21\u578b\u95ed\u5f0f\u89e3\uff0c\u8bc1\u660e\u6700\u4f18\u65b9\u6848\u53ef\u91c7\u7528\u4e8c\u503c\u5316 U\uff0c\u6781\u5927\u7b80\u5316\u5b9e\u73b0\u3002", "motivation": "\u5728\u9690\u79c1\u673a\u5236\u8bbe\u8ba1\u4e2d\u5b9e\u73b0\u4fe1\u606f\u4e0e\u9690\u79c1\u7684\u5e73\u8861", "method": "\u57fa\u4e8e\u591a\u5c42\u70b9\u9645\u6cc4\u6f0f\u7684\u6700\u4f18\u65b9\u6848\u5f62\u5f0f\u5316\uff0c\u5229\u7528\u4fe1\u606f\u51e0\u4f55\u8fd1\u4f3c\u5e76\u6784\u6210\u4e8c\u6b21\u4f18\u5316", "result": "\u5f97\u5230\u95ed\u5f0f\u89e3\uff1b\u8bc1\u660e\u4ec5\u9700\u4e8c\u503c\u5316\u8f93\u51faU\u5373\u53ef\u8fbe\u5230\u6700\u4f18\u5b9e\u7528\u6027", "conclusion": "\u63d0\u51fa\u591a\u5c42\u70b9\u9645\u6cc4\u6f0f\uff0c\u4e00\u4e2a\u66f4\u7075\u6d3b\u4e14\u53ef\u5b9e\u73b0\u5b8c\u7f8e\u9690\u79c1\u4e0e\u90e8\u5206\u6cc4\u6f0f\u5171\u5b58\u7684\u6846\u67b6\uff0c\u5e76\u7ed9\u51fa\u4f4e\u590d\u6742\u5ea6\u7684\u5b9e\u73b0\u65b9\u6cd5"}}
{"id": "2601.04831", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04831", "abs": "https://arxiv.org/abs/2601.04831", "authors": ["Shay Kreymer", "Amnon Balanov", "Tamir Bendory"], "title": "An Ultra-Fast MLE for Low SNR Multi-Reference Alignment", "comment": null, "summary": "Motivated by single-particle cryo-electron microscopy, multi-reference alignment (MRA) models the task of recovering an unknown signal from multiple noisy observations corrupted by random rotations. The standard approach, expectation-maximization (EM), often becomes computationally prohibitive, particularly in low signal-to-noise ratio (SNR) settings. We introduce an alternative, ultra-fast algorithm for MRA over the special orthogonal group $\\mathrm{SO}(2)$. By performing a Taylor expansion of the log-likelihood in the low-SNR regime, we estimate the signal by sequentially computing data-driven averages of observations. Our method requires only one pass over the data, dramatically reducing computational cost compared to EM. Numerical experiments show that the proposed approach achieves high accuracy in low-SNR environments and provides an excellent initialization for subsequent EM refinement.", "AI": {"tldr": "\u901a\u8fc7\u5bf9\u5bf9\u6570\u4f3c\u7136\u8fdb\u884c\u6cf0\u52d2\u5c55\u5f00\uff0c\u5229\u7528\u4e00\u6b21\u6570\u636e\u5e73\u5747\u5373\u53ef\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u5feb\u901f\u4f30\u8ba1MRA\u4fe1\u53f7\uff0c\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u8d1f\u62c5\uff0c\u5e76\u4e3aEM\u63d0\u4f9b\u826f\u597d\u521d\u59cb\u5316\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5355\u7c92\u5b50\u51b7\u51bb\u7535\u5b50\u663e\u5fae\u955c\u4e2d\u591a\u53c2\u8003\u5bf9\u9f50\uff08MRA\uff09\u4efb\u52a1\uff0c\u91cd\u5efa\u88ab\u968f\u673a\u65cb\u8f6c\u8bef\u5dee\u548c\u566a\u58f0\u63a9\u76d6\u7684\u672a\u77e5\u4fe1\u53f7\u3002", "method": "\u5728\u4f4e\u4fe1\u566a\u6bd4\uff08SNR\uff09\u60c5\u5f62\u4e0b\uff0c\u5bf9\u5bf9\u6570\u4f3c\u7136\u51fd\u6570\u505a\u6cf0\u52d2\u5c55\u5f00\uff0c\u968f\u540e\u901a\u8fc7\u4e00\u6b21\u6027\u8ba1\u7b97\u6570\u636e\u9a71\u52a8\u7684\u89c2\u6d4b\u5e73\u5747\u5e8f\u5217\u6765\u4f30\u8ba1\u4fe1\u53f7\uff0c\u907f\u514d\u4e86\u4f20\u7edfEM\u8fed\u4ee3\u8fc7\u7a0b\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4f4eSNR\u73af\u5883\u4e2d\u53ef\u8fbe\u9ad8\u7cbe\u5ea6\u4f30\u8ba1\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u80fd\u4e3a\u540e\u7eedEM\u7cbe\u7ec6\u5316\u63d0\u4f9b\u4f18\u79c0\u7684\u521d\u59cb\u5316\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u8d85\u5feb\u901fMRA\u7b97\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u5b9a\u4f4d\u7cbe\u5ea6\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edfEM\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4f4eSNR\u7a97\u53e3\uff0c\u53ef\u4f5c\u4e3aEM\u540e\u7eed\u4f18\u5316\u7684\u9ad8\u8d28\u91cf\u8d77\u70b9\u3002"}}
{"id": "2601.04266", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04266", "abs": "https://arxiv.org/abs/2601.04266", "authors": ["Ji Guo", "Wenbo Jiang", "Yansong Lin", "Yijing Liu", "Ruichen Zhang", "Guomin Lu", "Aiguo Chen", "Xinshuo Han", "Hongwei Li", "Dusit Niyato"], "title": "State Backdoor: Towards Stealthy Real-world Poisoning Attack on Vision-Language-Action Model in State Space", "comment": null, "summary": "Vision-Language-Action (VLA) models are widely deployed in safety-critical embodied AI applications such as robotics. However, their complex multimodal interactions also expose new security vulnerabilities. In this paper, we investigate a backdoor threat in VLA models, where malicious inputs cause targeted misbehavior while preserving performance on clean data. Existing backdoor methods predominantly rely on inserting visible triggers into visual modality, which suffer from poor robustness and low insusceptibility in real-world settings due to environmental variability. To overcome these limitations, we introduce the State Backdoor, a novel and practical backdoor attack that leverages the robot arm's initial state as the trigger. To optimize trigger for insusceptibility and effectiveness, we design a Preference-guided Genetic Algorithm (PGA) that efficiently searches the state space for minimal yet potent triggers. Extensive experiments on five representative VLA models and five real-world tasks show that our method achieves over 90% attack success rate without affecting benign task performance, revealing an underexplored vulnerability in embodied AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u673a\u5668\u624b\u81c2\u521d\u59cb\u72b6\u6001\u7684\u540e\u95e8\u653b\u51fb\uff0c\u5e76\u901a\u8fc7 P-GA \u4f18\u5316\u89e6\u53d1\u5668\u65b9\u6848\uff0c\u5b9e\u9a8c\u8868\u660e\u53ef\u8fbe 90%+ \u6210\u529f\u7387\uff0c\u63ed\u793a\u4e86 VLA \u7cfb\u7edf\u7684\u65b0\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u591a\u4e3a\u53ef\u89c1\u89e6\u53d1\u5668\uff0c\u5728\u73af\u5883\u53d8\u5316\u4e0b\u9c81\u68d2\u6027\u5dee\uff1b\u9700\u8981\u66f4\u9690\u853d\u3001\u7a33\u5065\u7684\u653b\u51fb\u624b\u6bb5\u4ee5\u6d4b\u8bd5\u5d4c\u5165\u5f0f AI \u7684\u5b89\u5168\u6027\uff1b", "method": "\u57fa\u4e8e\u9996\u4f4d\u72b6\u6001\u89e6\u53d1\u7684\u540e\u95e8\u653b\u51fb\uff0c\u5229\u7528\u504f\u597d\u5f15\u5bfc\u9057\u4f20\u7b97\u6cd5\uff08PGA\uff09\u5728\u72b6\u6001\u7a7a\u95f4\u4e2d\u5bfb\u627e\u65e2\u5c0f\u4e14\u6709\u6548\u7684\u89e6\u53d1\u5668\uff1b", "result": "\u5728\u4e94\u4e2a\u4ee3\u8868\u6027 VLA \u6a21\u578b\u4e0e\u4e94\u4e2a\u771f\u5b9e\u4efb\u52a1\u4e0a\uff0c\u653b\u51fb\u6210\u529f\u7387\u8d85\u8fc7 90%\uff0c\u4e14\u5bf9\u5e72\u51c0\u6570\u636e\u6027\u80fd\u65e0\u5f71\u54cd\uff1b", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u5728\u5b89\u5168\u5173\u952e\u7684\u5d4c\u5165\u5f0f AI \u7cfb\u7edf\u4e2d\uff0c\u4f7f\u7528\u673a\u5668\u4eba\u624b\u81c2\u521d\u59cb\u72b6\u6001\u4f5c\u4e3a\u89e6\u53d1\u5668\u7684\u65b0\u578b\u540e\u95e8\u653b\u51fb\u53ef\u5b9e\u73b0\u9ad8\u6210\u529f\u7387\u4e14\u5bf9\u6b63\u5e38\u4efb\u52a1\u65e0\u5e72\u6270\uff0c\u6307\u51fa\u8fd9\u4e00\u653b\u51fb\u65b9\u5f0f\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u6f5c\u5728\u5a01\u80c1\uff1b"}}
{"id": "2601.04849", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.04849", "abs": "https://arxiv.org/abs/2601.04849", "authors": ["Yijun Zhong", "Yi Shen"], "title": "Stability of Constrained Optimization Models for Structured Signal Recovery", "comment": "29 pages", "summary": "Recovering an unknown but structured signal from its measurements is a challenging problem with significant applications in fields such as imaging restoration, wireless communications, and signal processing. In this paper, we consider the inherent problem stems from the prior knowledge about the signal's structure, such as sparsity which is critical for signal recovery models. We investigate three constrained optimization models that effectively address this challenge, each leveraging distinct forms of structural priors to regularize the solution space. Our theoretical analysis demonstrates that these models exhibit robustness to noise while maintaining stability with respect to tuning parameters that is a crucial property for practical applications, when the parameter selection is often nontrivial. By providing theoretical foundations, our work supports their practical use in scenarios where measurement imperfections and model uncertainties are unavoidable. Furthermore, under mild conditions, we establish tradeoff between the sample complexity and the mismatch error.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04844", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04844", "abs": "https://arxiv.org/abs/2601.04844", "authors": ["Guangyu Zhu", "Xidong Mu", "Li Guo", "Shibiao Xu", "Yuanwei Liu", "Naofal Al-Dhahir"], "title": "SE-EE Tradeoff in Pinching-Antenna Systems: Waveguide Multiplexing or Waveguide Switching?", "comment": null, "summary": "The spectral and energy efficiency (SE-EE) trade-off in pinching-antenna systems (PASS) is investigated in this paper. In particular, two practical operating protocols, namely waveguide multiplexing (WM) and waveguide switching (WS), are considered. A multi-objective optimization problem (MOOP) is formulated to jointly optimize the baseband and pinching beamforming for maximizing the achievable SE and EE, which is then converted into a single-objective problem via the \u03b5-constraint method. For WM, the problem is decomposed within the alternating-optimization framework, where the baseband beamforming is optimized using the successive convex approximation, and the pinching beamforming is updated through the particle swarm optimization. For WS, due to the time-division transmission and interference-free nature, the pinching beamforming in each time slot is first adjusted to maximize the served user channel gain, followed by the baseband power allocation. Simulation results demonstrate that 1) PASS outperforms conventional antennas by mitigating large-scale path losses; 2) WS leads to a higher maximum achievable EE by activating a single RF chain, whereas WM yields a higher SE upper bound by serving all users concurrently; and 3) increasing the number of users substantially enhances SE under WM, whereas WS shows more pronounced benefits in low-signal-to-noise ratio regimes.", "AI": {"tldr": "\u7814\u7a76PASS\u7684SE-EE\u6298\u4e2d\uff0c\u5728WM\u4e0b\u4f7f\u7528\u4ea4\u66ff\u4f18\u5316+\u7c92\u5b50\u7fa4\uff0cWS\u5219\u5148\u63d0\u5347\u4fe1\u9053\u589e\u76ca\u540e\u5206\u914d\u529f\u7387\uff0c\u7ed3\u679c\u663e\u793aPASS\u4f18\u4e8e\u4f20\u7edf\u5929\u7ebf\uff0cWM\u548cWS\u5404\u6709\u4f18\u52bf\u3002", "motivation": "\u63d0\u9ad8\u4f20\u8f93\u7cfb\u7edf\u5728\u9891\u8c31\u548c\u80fd\u8017\u65b9\u9762\u7684\u7efc\u5408\u6027\u80fd\uff0c\u63a2\u8ba8\u6ce2\u5bfc\u591a\u8def\u590d\u7528\u4e0e\u6ce2\u5bfc\u5207\u6362\u5728pinching-antenna\u7cfb\u7edf\u4e2d\u7684\u6548\u679c\u3002", "method": "\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\uff08MOOP\uff09\u8054\u5408\u4f18\u5316\u57fa\u5e26\u4e0e\u675f\u7f1a\u6ce2\u675f\uff0c\u968f\u540e\u91c7\u7528\u03b5-\u7ea6\u675f\u5c06\u5176\u8f6c\u5316\u4e3a\u5355\u76ee\u6807\u95ee\u9898\uff1bWM\u4f7f\u7528\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\u7ed3\u5408\u5e8f\u5217\u51f8\u903c\u8fd1\u4e0e\u7c92\u5b50\u7fa4\u4f18\u5316\uff1bWS\u91c7\u7528\u5148\u6700\u5927\u5316\u7528\u6237\u4fe1\u9053\u589e\u76ca\u7684\u675f\u7f1a\u6ce2\u675f\uff0c\u518d\u505a\u57fa\u5e26\u529f\u7387\u5206\u914d\u3002", "result": "PASS\u76f8\u6bd4\u4f20\u7edf\u5929\u7ebf\u964d\u4f4e\u5927\u5c3a\u5ea6\u8def\u5f84\u635f\u5931\uff1bWS\u5728\u6fc0\u6d3b\u5355RF\u94fe\u65f6\u5b9e\u73b0\u66f4\u9ad8\u80fd\u6548\uff0c\u800cWM\u5728\u540c\u65f6\u670d\u52a1\u5168\u90e8\u7528\u6237\u65f6\u5b9e\u73b0\u66f4\u9ad8\u9891\u8c31\u6548\u7387\uff1b\u5f53\u7528\u6237\u6570\u589e\u591a\u65f6WM\u663e\u8457\u63d0\u5347SE\uff0cWS\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u66f4\u5177\u4f18\u52bf\u3002", "conclusion": "PASS\u7cfb\u7edf\u901a\u8fc7\u5408\u9002\u7684\u6ce2\u5bfc\u591a\u8def\u590d\u7528\u6216\u5207\u6362\u534f\u8bae\u8fbe\u6210\u5728\u9891\u8c31\u6548\u7387\u548c\u80fd\u6548\u4e4b\u95f4\u7684\u6298\u4e2d\uff0c\u5e76\u5728\u4e0d\u540c\u7684\u4f7f\u7528\u60c5\u5883\u4e0b\u663e\u793a\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2601.04275", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04275", "abs": "https://arxiv.org/abs/2601.04275", "authors": ["Dinesh Srivasthav P", "Ashok Urlana", "Rahul Mishra", "Bala Mallikarjunarao Garlapati", "Ponnurangam Kumaraguru"], "title": "Shadow Unlearning: A Neuro-Semantic Approach to Fidelity-Preserving Faceless Forgetting in LLMs", "comment": null, "summary": "Machine unlearning aims to selectively remove the influence of specific training samples to satisfy privacy regulations such as the GDPR's 'Right to be Forgotten'. However, many existing methods require access to the data being removed, exposing it to membership inference attacks and potential misuse of Personally Identifiable Information (PII). We address this critical challenge by proposing Shadow Unlearning, a novel paradigm of approximate unlearning, that performs machine unlearning on anonymized forget data without exposing PII. We further propose a novel privacy-preserving framework, Neuro-Semantic Projector Unlearning (NSPU) to achieve Shadow unlearning. To evaluate our method, we compile Multi-domain Fictitious Unlearning (MuFU) forget set across five diverse domains and introduce an evaluation stack to quantify the trade-off between knowledge retention and unlearning effectiveness. Experimental results on various LLMs show that NSPU achieves superior unlearning performance, preserves model utility, and enhances user privacy. Additionally, the proposed approach is at least 10 times more computationally efficient than standard unlearning approaches. Our findings foster a new direction for privacy-aware machine unlearning that balances data protection and model fidelity.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04862", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.04862", "abs": "https://arxiv.org/abs/2601.04862", "authors": ["Ailing Zheng", "Qingqing Wu", "Ziyuan Zheng", "Qiaoyan Peng", "Yanze Zhu", "Honghao Wang", "Wen Chen", "Guoying Zhang"], "title": "Wireless Communication with Cross-Linked Rotatable Antenna Array: Architecture Design and Rotation Optimization", "comment": null, "summary": "Rotatable antenna (RA) technology can harness additional spatial degrees of freedom by enabling the dynamic three-dimensional orientation control of each antenna. Unfortunately, the hardware cost and control complexity of traditional RA systems is proportional to the number of RAs. To address the issue, we consider a cross-linked (CL) RA structure, which enables the coordinated rotation of multiple antennas, thereby offering a cost-effective solution. To evaluate the performance of the CL-RA array, we investigate a CL-RA-aided uplink system. Specifically, we first establish system models for both antenna element-level and antenna panel-level rotation. Then, we formulate a sum rate maximization problem by jointly optimizing the receive beamforming at the base station and the rotation angles. For the antenna element-level rotation, we derive the optimal solution of the CL-RA array under the single-user case. Subsequently, for two rotation schemes, we propose an alternating optimization algorithm to solve the formulated problem in the multi-user case, where the receive beamforming and the antenna rotation angles are obtained by applying the minimum mean square error method and feasible direction method, respectively. In addition, considering the hardware limitations, we apply the genetic algorithm to address the discrete rotation angles selection problem. Simulation results show that by carefully designing the row-column partition scheme, the performance of the CL-RA architecture is quite close to that of the flexible antenna orientation scheme. Moreover, the CL antenna element-level scheme surpasses the CL antenna panel-level scheme by 25% and delivers a 128% performance improvement over conventional fixed-direction antennas.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04270", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04270", "abs": "https://arxiv.org/abs/2601.04270", "authors": ["Anherutowa Calvo"], "title": "Predictable Gradient Manifolds in Deep Learning: Temporal Path-Length and Intrinsic Rank as a Complexity Regime", "comment": "12 Pages. Preprint", "summary": "Deep learning optimization exhibits structure that is not captured by worst-case gradient bounds. Empirically, gradients along training trajectories are often temporally predictable and evolve within a low-dimensional subspace. In this work we formalize this observation through a measurable framework for predictable gradient manifolds.\n  We introduce two computable quantities: a prediction-based path length that measures how well gradients can be forecast from past information, and a predictable rank that quantifies the intrinsic temporal dimension of gradient increments. We show how classical online and nonconvex optimization guarantees can be restated so that convergence and regret depend explicitly on these quantities, rather than on worst-case variation.\n  Across convolutional networks, vision transformers, language models, and synthetic control tasks, we find that gradient trajectories are locally predictable and exhibit strong low-rank structure over time. These properties are stable across architectures and optimizers, and can be diagnosed directly from logged gradients using lightweight random projections.\n  Our results provide a unifying lens for understanding optimization dynamics in modern deep learning, reframing standard training as operating in a low-complexity temporal regime. This perspective suggests new directions for adaptive optimizers, rank-aware tracking, and prediction-based algorithm design grounded in measurable properties of real training runs.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04969", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04969", "abs": "https://arxiv.org/abs/2601.04969", "authors": ["Yichi Zhang", "Yuchen Zhang", "Wenyan Ma", "Lipeng Zhu", "Jianquan Wang", "Wanbin Tang", "Rui Zhang"], "title": "6D Movable Antenna Enhanced Cell-free MIMO: Two-timescale Decentralized Beamforming and Antenna Movement Optimization", "comment": "13 pages, 7 figures, 1 table", "summary": "This paper investigates a six-dimensional movable antenna (6DMA)-aided cell-free multi-user multiple-input multiple-output (MIMO) communication system. In this system, each distributed access point (AP) can flexibly adjust its array orientation and antenna positions to adapt to spatial channel variations and enhance communication performance. However, frequent antenna movements and centralized beamforming based on global instantaneous channel state information (CSI) sharing among APs entail extremely high signal processing delay and system overhead, which is difficult to be practically implemented in high-mobility scenarios with short channel coherence time. To address these practical implementation challenges and improve scalability, a two-timescale decentralized optimization framework is proposed in this paper to jointly design the beamformer, antenna positions, and array orientations. In the short timescale, each AP updates its receive beamformer based on local instantaneous CSI and global statistical CSI. In the long timescale, the central processing unit optimizes the antenna positions and array orientations at all APs based on global statistical CSI to maximize the ergodic sum rate of all users. The resulting optimization problem is non-convex and involves highly coupled variables, thus posing significant challenges for obtaining efficient solutions. To address this problem, a constrained stochastic successive convex approximation algorithm is developed. Numerical results demonstrate that the proposed 6DMA-aided cell-free system with decentralized beamforming significantly outperforms other antenna movement schemes with less flexibility and even achieves a performance comparable to that of the centralized beamforming benchmark.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u53cc\u65f6\u6807\u5206\u6563\u4f18\u5316\u6846\u67b6\uff0c\u4ee5\u5b9e\u73b0\u516d\u7ef4\u53ef\u79fb\u52a8\u5929\u7ebf\u7684\u65e0\u57fa\u7ad9MIMO\uff0c\u5728\u77ed\u65f6\u6807\u4e0b\u5c40\u90e8\u66f4\u65b0\u6ce2\u675f\uff0c\u957f\u65f6\u6807\u4e0b\u5168\u5c40\u4f18\u5316\u5929\u7ebf\u4f4d\u59ff\uff0c\u5229\u7528\u53d7\u9650\u968f\u673a\u8fde\u7eed\u51f8\u8fd1\u4f3c\u6c42\u89e3\u975e\u51f8\u95ee\u9898\uff0c\u7ed3\u679c\u663e\u793a\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6848\u3002", "motivation": "\u96c6\u4e2d\u5f0f\u5168\u5c40CSI\u5171\u4eab\u5bfc\u81f4\u9ad8\u8017\u65f6\u4e0e\u5f00\u9500\uff0c\u96be\u4ee5\u5728\u77ed\u7801\u65f6\u8870\u573a\u666f\u4e0b\u5b9e\u73b0\uff1b\u9700\u5b9e\u73b0\u53ef\u4f38\u7f29\u3001\u4f4e\u65f6\u5ef6\u7684\u5929\u7ebf\u4e0e\u6ce2\u675f\u4f18\u5316\u65b9\u6848\u3002", "method": "\u5728\u77ed\u65f6\u6807\u4e0b\u6bcf\u4e2aAP\u4ec5\u5229\u7528\u672c\u5730\u77ac\u65f6CSI\u4e0e\u5168\u5c40\u7edf\u8ba1CSI\u66f4\u65b0\u63a5\u6536\u6ce2\u675f\u5f62\u6210\u5668\uff1b\u5728\u957f\u65f6\u6807\u4e0bCPU\u57fa\u4e8e\u5168\u5c40\u7edf\u8ba1CSI\u5bf9\u6240\u6709AP\u7684\u5929\u7ebf\u4f4d\u7f6e\u4e0e\u9635\u5217\u65b9\u5411\u8fdb\u884c\u4f18\u5316\uff1b\u91c7\u7528\u53d7\u9650\u968f\u673a\u8fde\u7eed\u51f8\u8fd1\u4f3c\uff08CSCMA\uff09\u7b97\u6cd5\u6c42\u89e3\u8026\u5408\u975e\u51f8\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u76f8\u8f83\u4e8e\u5176\u5b83\u8fd0\u52a8\u5929\u7ebf\u65b9\u6848\uff0c\u63d0\u51fa\u7684\u5206\u6563\u6ce2\u675f\u65b9\u6848\u6027\u80fd\u5927\u5e45\u63d0\u5347\uff0c\u4e14\u4e0e\u96c6\u4e2d\u5f0f\u57fa\u51c6\u76f8\u8fd1\uff1b\u663e\u8457\u63d0\u9ad8\u4e86\u5168\u5c40\u5e73\u5747\u901f\u7387\u3002", "conclusion": "\u901a\u8fc7\u53cc\u65f6\u6807\u5206\u6563\u4f18\u5316\uff0c6DMA\u652f\u6301\u7684\u65e0\u57fa\u7ad9\u65b9\u6848\u5728\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u4e0b\u80fd\u663e\u8457\u964d\u4f4e\u65f6\u5ef6\u548c\u5f00\u9500\uff0c\u540c\u65f6\u5b9e\u73b0\u4e0e\u96c6\u4e2d\u5f0f\u6ce2\u675f\u6210\u5f62\u76f8\u8fd1\u751a\u81f3\u66f4\u4f18\u7684\u6574\u4f53\u541e\u5410\u91cf\u3002"}}
{"id": "2601.04980", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04980", "abs": "https://arxiv.org/abs/2601.04980", "authors": ["Sueda Taner", "Christoph Studer"], "title": "Learning Sparsifying Transforms for mmWave Communication via $\\ell^4$-Norm Maximization", "comment": "Submitted to a journal", "summary": "The high directionality of wave propagation at millimeter-wave (mmWave) carrier frequencies results in only a small number of significant transmission paths between user equipments and the basestation (BS). This sparse nature of wave propagation is revealed in the beamspace domain, which is traditionally obtained by taking the spatial discrete Fourier transform (DFT) across a uniform linear antenna array at the BS, where each DFT output is associated with a distinct beam. In recent years, beamspace processing has emerged as a promising technique to reduce baseband complexity and power consumption in all-digital massive multiuser (MU) multiple-input multiple-output (MIMO) systems operating at mmWave frequencies. However, it remains unclear whether the DFT is the optimal sparsifying transform for finite-dimensional antenna arrays. In this paper, we extend the framework of Zhai et al. for complete dictionary learning via $\\ell^4$-norm maximization to the complex case in order to learn new sparsifying transforms. We provide a theoretical foundation for $\\ell^4$-norm maximization and propose two suitable learning algorithms. We then utilize these algorithms (i) to assess the optimality of the DFT for sparsifying channel vectors theoretically and via simulations and (ii) to learn improved sparsifying transforms for real-world and synthetically generated channel vectors.", "AI": {"tldr": "\u672c\u6587\u9a8c\u8bc1DFT\u5e76\u975e\u6beb\u7c73\u6ce2\u901a\u9053\u7684\u6700\u4f18\u7a00\u758f\u5316\u53d8\u6362\uff0c\u63d0\u51fa\u590d\u6570\u57df\u2113\u2074\u6700\u5927\u5316\u5b57\u5178\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u4e24\u79cd\u7b97\u6cd5\u5b66\u4e60\u5230\u4e86\u66f4\u9ad8\u6548\u7684\u6ce2\u675f\u57df\u53d8\u6362\uff0c\u663e\u8457\u63d0\u5347\u901a\u9053\u7a00\u758f\u5ea6\u5e76\u964d\u4f4e\u5904\u7406\u590d\u6742\u5ea6\u3002", "motivation": "\u6beb\u7c73\u6ce2\u9891\u6bb5\u4fe1\u9053\u9ad8\u5ea6\u53ef\u5b9a\u5411\uff0c\u901a\u9053\u5411\u91cf\u7a00\u758f\uff0c\u4f46\u4f20\u7edf\u57fa\u4e8eDFT\u7684\u6ce2\u675f\u57df\u7a00\u758f\u5316\u662f\u5426\u6700\u4f18\u5c1a\u672a\u77e5\uff1b\u82e5\u80fd\u5f97\u5230\u66f4\u7a00\u758f\u7684\u53d8\u6362\uff0c\u53ef\u8fdb\u4e00\u6b65\u964d\u4f4e\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u590d\u6742\u5ea6\u4e0e\u529f\u8017\u3002", "method": "\u5728\u590d\u6570\u57df\u4e2d\u63a8\u5e7fZhai\u7b49\u4eba\u7684\u2113\u2074\u8303\u6570\u6700\u5927\u5316\u5b57\u5178\u5b66\u4e60\u6846\u67b6\uff0c\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u68af\u5ea6\u4e0e\u5b50\u7a7a\u95f4\u8fed\u4ee3\u7684\u5b66\u4e60\u7b97\u6cd5\uff1b\u901a\u8fc7\u7406\u8bba\u5206\u6790\u4e0e\u4eff\u771f\u5b9e\u9a8c\u8bc4\u4f30DFT\u7684\u7a00\u758f\u6027\u80fd\uff0c\u5e76\u5229\u7528\u6240\u5f97\u7b97\u6cd5\u5b66\u4e60\u9488\u5bf9\u5b9e\u6d4b\u4e0e\u5408\u6210mmWave\u901a\u9053\u7684\u6539\u8fdb\u7a00\u758f\u53d8\u6362\u3002", "result": "\u63d0\u4f9b\u4e86\u2113\u2074\u8303\u6570\u6700\u5927\u5316\u5728\u590d\u6570\u57df\u7684\u7406\u8bba\u57fa\u7840\uff0c\u8bbe\u8ba1\u5e76\u9a8c\u8bc1\u4e86\u4e24\u79cd\u5b66\u4e60\u7b97\u6cd5\uff1b\u7ed3\u679c\u8868\u660eDFT\u5e76\u975e\u6700\u4f18\uff0c\u4e14\u6240\u5b66\u4e60\u7684\u7a00\u758f\u5316\u53d8\u6362\u5728\u5b9e\u6d4b\u4e0e\u5408\u6210\u901a\u9053\u4e0a\u5747\u80fd\u63d0\u5347\u7a00\u758f\u6027\uff0c\u5b9e\u73b0\u66f4\u4f4e\u7684\u57fa\u5e26\u590d\u6742\u5ea6\u3002", "conclusion": "DFT\u5e76\u975e\u5728\u6240\u6709\u6709\u9650\u7ef4\u5929\u7ebf\u9635\u5217\u4e2d\u90fd\u662f\u6700\u4f18\u7684\u7a00\u758f\u5316\u53d8\u6362\uff1b\u901a\u8fc7\u5bf9\u590d\u6570\u57df\u6269\u5c55\u7684\u2113\u2074\u2011\u8303\u6570\u6700\u5927\u5316\u5b57\u5178\u5b66\u4e60\uff0c\u53ef\u5f97\u5230\u66f4\u7a00\u758f\u3001\u66f4\u9ad8\u6548\u7684\u53d8\u6362\u3002"}}
{"id": "2601.04277", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04277", "abs": "https://arxiv.org/abs/2601.04277", "authors": ["Beier Luo", "Cheng Wang", "Hongxin Wei", "Sharon Li", "Xuefeng Du"], "title": "Unlocking the Pre-Trained Model as a Dual-Alignment Calibrator for Post-Trained LLMs", "comment": null, "summary": "Post-training improves large language models (LLMs) but often worsens confidence calibration, leading to systematic overconfidence. Recent unsupervised post-hoc methods for post-trained LMs (PoLMs) mitigate this by aligning PoLM confidence to that of well-calibrated pre-trained counterparts. However, framing calibration as static output-distribution matching overlooks the inference-time dynamics introduced by post-training. In particular, we show that calibration errors arise from two regimes: (i) confidence drift, where final confidence inflates despite largely consistent intermediate decision processes, and (ii) process drift, where intermediate inference pathways diverge. Guided by this diagnosis, we propose Dual-Align, an unsupervised post-hoc framework for dual alignment in confidence calibration. Dual-Align performs confidence alignment to correct confidence drift via final-distribution matching, and introduces process alignment to address process drift by locating the layer where trajectories diverge and realigning the stability of subsequent inference. This dual strategy learns a single temperature parameter that corrects both drift types without sacrificing post-training performance gains. Experiments show consistent improvements over baselines, reducing calibration errors and approaching a supervised oracle.", "AI": {"tldr": "Dual\u2011Align\uff1a\u5355\u6e29\u5ea6\u53cc\u9636\u6bb5\u6821\u51c6\uff0c\u89e3\u51b3\u4fe1\u5fc3\u6f02\u79fb\u4e0e\u63a8\u7406\u8def\u5f84\u6f02\u79fb\uff0c\u663e\u8457\u63d0\u5347LLM\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u8f93\u51fa\u5339\u914d\u5ffd\u89c6\u4e86\u63a8\u7406\u65f6\u52a8\u6001\u53d8\u5316\uff0c\u5bfc\u81f4\u81ea\u4fe1\u6f02\u79fb\u4e0e\u8fc7\u7a0b\u6f02\u79fb\u5e76\u5b58\uff1b\u9700\u517c\u987e\u4e24\u79cd\u8bef\u5dee\u6765\u6e90\u3002", "method": "\u5728\u540e\u8bad\u7ec3\u9636\u6bb5\uff0cDual\u2011Align\u5148\u8fdb\u884c\u6700\u7ec8\u8f93\u51fa\u5206\u5e03\u5339\u914d\u7684\u201cconfidence alignment\u201d\u4ee5\u7ea0\u6b63\u4fe1\u5fc3\u6f02\u79fb\uff1b\u7136\u540e\u5b9a\u4f4d\u63a8\u7406\u8def\u5f84\u5206\u6b67\u5c42\uff0c\u6267\u884c\u201cprocess alignment\u201d\u4ee5\u6062\u590d\u540e\u7eed\u5c42\u6b21\u7684\u7a33\u5b9a\u6027\uff0c\u4e24\u6b65\u5171\u5b66\u4e60\u5355\u4e00\u6e29\u5ea6\u53c2\u6570\u3002", "result": "\u5728\u591a\u7ec4\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b9e\u9a8c\u4e2d\uff0cDual\u2011Align\u76f8\u8f83\u57fa\u7ebf\u663e\u8457\u964d\u4f4e\u6821\u51c6\u8bef\u5dee\uff0c\u4e14\u4fdd\u7559\u4e86\u540e\u8bad\u7ec3\u7684\u6027\u80fd\u63d0\u5347\uff0c\u903c\u8fd1\u6709\u76d1\u7763\u6821\u51c6\u7684\u6548\u679c\u3002", "conclusion": "Dual-Align\u901a\u8fc7\u53cc\u91cd\u6821\u51c6\u7b56\u7565\u6709\u6548\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4fe1\u8fc7\u5ea6\uff0c\u51e0\u4e4e\u8fbe\u5230\u6709\u76d1\u7763\u6837\u672c\u7684\u4fe1\u5fc3\u6821\u51c6\u6c34\u5e73\u3002"}}
{"id": "2601.05000", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.05000", "abs": "https://arxiv.org/abs/2601.05000", "authors": ["Ronit Sohanpal", "Mindaugus Jarmolovicius", "Jiaqian Yang", "Eric Sillekens", "Romulo Aparecido", "Vitaly Mikhailov", "Jiawei Luo", "David J. DiGiovanni", "Ruben S. Luis", "Hideaki Furukawa", "Robert I. Killey", "Polina Bayvel"], "title": "Ultra-Wideband Transmission Systems From an Energy Perspective: Which Band is Next?", "comment": "Optical Fiber Communications Conference (OFC) 2026", "summary": "Measuring the power efficiency of the state-of-the-art OESCL-band amplifiers, we show that 1000 km OESCL-band systems can achieve 2.98x greater throughput for +48% higher energy-per-bit compared to CL-band transmission only.", "AI": {"tldr": "\u4f7f\u7528OESCL-band\u53ef\u57281000 km\u4f20\u8f93\u4e2d\u5b9e\u73b0\u8fd1300%\u541e\u5410\u91cf\u63d0\u5347\uff0c\u4f46\u6bcf\u6bd4\u7279\u80fd\u8017\u63d0\u9ad8\u7ea648%", "motivation": "\u8bc4\u4f30OESCL-band\u76f8\u5bf9\u4e8eCL-band\u5728\u957f\u8ddd\u79bb\u4f20\u8f93\u4e2d\u7684\u6027\u80fd", "method": "\u6d4b\u91cf\u6700\u5148\u8fdbOESCL-band\u653e\u5927\u5668\u7684\u529f\u7387\u6548\u7387", "result": "\u901a\u8fc7\u6d4b\u91cf\uff0c\u53d1\u73b0OESCL-band\u7cfb\u7edf\u57281000 km\u65f6\u6bd4CL-band\u4f20\u8f93\u4ec5\u63d0\u9ad848%\u7684\u80fd\u8017\u4e2d\u5b9e\u73b0\u4e862.98\u500d\u7684\u541e\u5410\u91cf", "conclusion": "1000 km OESCL-band systems achieve 2.98\u500d\u7684\u541e\u5410\u91cf\uff0c\u5e76\u4e14\u80fd\u8017\u6bcf\u6bd4\u7279\u9ad848%"}}
{"id": "2601.05030", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05030", "abs": "https://arxiv.org/abs/2601.05030", "authors": ["Sambhab Mishra"], "title": "Refinements of Jensen's Inequality for Twice-Differentiable Convex Functions with Bounded Hessian", "comment": "15 Pages. Comments welcome!", "summary": "Jensen's inequality, attributed to Johan Jensen -- a Danish mathematician and engineer noted for his contributions to the theory of functions -- is a ubiquitous result in convex analysis, providing a fundamental lower bound for the expectation of a convex function. In this paper, we establish rigorous refinements of this inequality specifically for twice-differentiable functions with bounded Hessians. By utilizing Taylor expansions with integral remainders, we tried to bridge the gap between classical variance-based bounds and higher-precision estimates. We also discover explicit error terms governed by Gruss-type inequalities, allowing for the incorporation of skewness and kurtosis into the bound. Using these new theoretical tools, we improve upon existing estimates for the Shannon entropy of continuous distributions and the ergodic capacity of Rayleigh fading channels, demonstrating the practical efficacy of our refinements.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04279", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04279", "abs": "https://arxiv.org/abs/2601.04279", "authors": ["Pau Esteve", "Massimiliano Zanin"], "title": "Generation of synthetic delay time series for air transport applications", "comment": "18 pages, 13 figures", "summary": "The generation of synthetic data is receiving increasing attention from the scientific community, thanks to its ability to solve problems like data scarcity and privacy, and is starting to find applications in air transport. We here tackle the problem of generating synthetic, yet realistic, time series of delays at airports, starting from large collections of operations in Europe and the US. We specifically compare three models, two of them based on state of the art Deep Learning algorithms, and one simplified Genetic Algorithm approach. We show how the latter can generate time series that are almost indistinguishable from real ones, while maintaining a high variability. We further validate the resulting time series in a problem of detecting delay propagations between airports. We finally make the synthetic data available to the scientific community.", "AI": {"tldr": "\u4f7f\u7528\u7b80\u5316\u7684\u9057\u4f20\u7b97\u6cd5\u751f\u6210\u673a\u573a\u5ef6\u8fdf\u65f6\u95f4\u5e8f\u5217\uff0c\u6548\u679c\u4e0e\u771f\u5b9e\u6570\u636e\u51e0\u4e4e\u76f8\u540c\uff1b\u5df2\u516c\u5f00\u6570\u636e\u53ef\u4f9b\u7814\u7a76\u3002", "motivation": "\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u548c\u9690\u79c1\u9650\u5236\uff0c\u63d0\u4f9b\u53ef\u7528\u4e8e\u79d1\u7814\u548c\u5b9e\u8df5\u7684\u5408\u6210\u822a\u7a7a\u5ef6\u8fdf\u65f6\u95f4\u5e8f\u5217\uff0c\u4ee5\u63a8\u52a8\u822a\u7a7a\u8fd0\u8f93\u9886\u57df\u7684\u7814\u7a76\u4e0e\u5e94\u7528\u3002", "method": "\u6bd4\u8f83\u4e09\u79cd\u6a21\u578b\uff1a\u4e24\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u7b97\u6cd5\uff08\u5982LSTM/Transformer\uff09\u548c\u4e00\u79cd\u7b80\u5316\u7684\u9057\u4f20\u7b97\u6cd5\uff1b\u8bc4\u4f30\u5176\u751f\u6210\u65f6\u95f4\u5e8f\u5217\u7684\u771f\u5b9e\u6027\u3001\u591a\u6837\u6027\uff0c\u5e76\u5728\u5ef6\u8fdf\u4f20\u64ad\u68c0\u6d4b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u6548\u679c\u3002", "result": "\u9057\u4f20\u7b97\u6cd5\u751f\u6210\u7684\u5e8f\u5217\u51e0\u4e4e\u65e0\u6cd5\u4e0e\u771f\u5b9e\u6570\u636e\u533a\u5206\uff0c\u5e76\u4fdd\u6301\u9ad8\u53d8\u5f02\u6027\uff1b\u5728\u673a\u573a\u5ef6\u8fdf\u4f20\u64ad\u68c0\u6d4b\u95ee\u9898\u4e2d\u5f97\u5230\u6709\u6548\u9a8c\u8bc1\uff1b\u5408\u6210\u6570\u636e\u5df2\u5411\u5b66\u672f\u754c\u516c\u5f00\u3002", "conclusion": "\u5408\u6210\u65f6\u5ef6\u5e8f\u5217\u80fd\u591f\u6ee1\u8db3\u5b9e\u9645\u5e94\u7528\u9700\u6c42\uff0c\u9057\u4f20\u7b97\u6cd5\u5728\u53ef\u63a8\u5e7f\u6027\u548c\u591a\u6837\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u6570\u636e\u5df2\u516c\u5f00\u4f9b\u79d1\u7814\u4f7f\u7528\u3002"}}
{"id": "2601.05032", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.05032", "abs": "https://arxiv.org/abs/2601.05032", "authors": ["Steven Rivetti", "Gabor Fodor", "Emil Bj\u00f6rnson", "Mikael Skoglund"], "title": "On the Impact of Channel Aging and Doppler-Affected Clutter on OFDM ISAC Systems", "comment": "13 pages, 21 pictures, submitted to IEEE TWC", "summary": "The temporal evolution of the propagation environment plays a central role in integrated sensing and communication (ISAC) systems. A slow-time evolution manifests as channel aging in communication links, while a fast-time one is associated with structured clutter with non-zero Doppler. Nevertheless, the joint impact of these two phenomena on ISAC performance has been largely overlooked. This addresses this research gap in a network utilizing orthogonal frequency division multiplexing waveforms. Here, a base station simultaneously serves multiple user equipment (UE) devices and performs monostatic sensing. Channel aging is captured through an autoregressive model with exponential correlation decay. In contrast, clutter is modeled as a collection of uncorrelated, coherent patches with non-zero Doppler, resulting in a Kronecker-separable covariance structure. We propose an aging-aware channel estimator that uses prior pilot observations to estimate the time-varying UE channels, characterized by a non-isotropic multipath fading structure. The clutter's structure enables a novel low-complexity sensing pipeline: clutter statistics are estimated from raw data and subsequently used to suppress the clutter's action, after which target parameters are extracted through range-angle and range-velocity maps. We evaluate the influence of frame length and pilot history on channel estimation accuracy and demonstrate substantial performance gains over block fading in low-to-moderate mobility regimes. The sensing pipeline is implemented in a clutter-dominated environment, demonstrating that effective clutter suppression can be achieved under practical configurations. Furthermore, our results show that dedicated sensing streams are required, as communication beams provide insufficient range resolution.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9 ISAC \u4e2d\u6162\u901f\u4fe1\u9053\u8001\u5316\u4e0e\u5feb\u901f\u591a\u666e\u52d2\u6742\u6ce2\u7684\u8054\u5408\u6548\u5e94\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u5386\u53f2\u5bfc\u9891\u7684\u8001\u5316\u611f\u77e5\u4fe1\u9053\u4f30\u8ba1\u5668\u4e0e\u4f4e\u590d\u6742\u5ea6\u6742\u6ce2\u6291\u5236\u611f\u77e5\u7ba1\u7ebf\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4f4e\u81f3\u4e2d\u7b49\u79fb\u52a8\u7387\u573a\u666f\u4e0b\uff0c\u4fe1\u9053\u4f30\u8ba1\u4e0e\u76ee\u6807\u63a2\u6d4b\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5757\u8870\u843d\u6a21\u578b\uff1b\u540c\u65f6\uff0c\u5b9e\u9645\u6742\u6ce2\u6291\u5236\u53ef\u884c\uff0c\u4e14\u901a\u4fe1\u6ce2\u675f\u65e0\u6cd5\u6ee1\u8db3\u8303\u56f4\u5206\u8fa8\u7387\u9700\u6c42\uff0c\u9700\u5f15\u5165\u4e13\u7528\u611f\u77e5\u6ce2\u675f\u3002", "motivation": "\u4f20\u7edf ISAC \u7cfb\u7edf\u5f80\u5f80\u53ea\u5173\u6ce8\u9759\u6001\u6216\u5757\u8870\u843d\u4fe1\u9053\uff0c\u5ffd\u7565\u4e86\u6162\u65f6\u95f4\u5c3a\u5ea6\u7684\u4fe1\u9053\u8001\u5316\u4e0e\u5feb\u65f6\u95f4\u5c3a\u5ea6\u7684 \u591a\u666e\u52d2\u6742\u6ce2\u5bf9\u611f\u77e5\u4e0e\u901a\u4fe1\u53cc\u91cd\u6027\u80fd\u7684\u8026\u5408\u5f71\u54cd\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\uff0c\u672c\u6587\u4fa7\u91cd\u7814\u7a76\u4e24\u8005\u7684\u8054\u5408\u6548\u5e94\u3002", "method": "\u91c7\u7528\u6b63\u4ea4\u9891\u5206\u590d\u7528\u6846\u67b6\uff0c\u5229\u7528\u81ea\u56de\u5f52\u6a21\u578b\u523b\u753b\u4fe1\u9053\u8001\u5316\uff0c\u5e76\u5bf9\u591a\u666e\u52d2\u6742\u6ce2\u5efa\u6a21\u4e3a\u65e0\u76f8\u5173\u3001\u76f8\u5e72\u8865\u4e01\u7684 Kronecker \u53ef\u5206\u79bb\u534f\u65b9\u5dee\u7ed3\u6784\uff1b\u63d0\u51fa\u57fa\u4e8e\u5386\u53f2\u5bfc\u9891\u7684\u8001\u5316\u611f\u77e5\u4fe1\u9053\u4f30\u8ba1\u5668\u548c\u4f4e\u590d\u6742\u5ea6\u7684\u6742\u6ce2\u6291\u5236\u4f20\u611f\u6d41\u6c34\u7ebf\uff0c\u5e76\u901a\u8fc7\u5e45\u5ea6-\u89d2\u5ea6\u4e0e\u5e45\u5ea6-\u901f\u5ea6\u6620\u5c04\u63d0\u53d6\u76ee\u6807\u53c2\u6570\u3002", "result": "\u5728\u4f4e\u81f3\u4e2d\u7b49\u79fb\u52a8\u7387\u4e0b\uff0c\u76f8\u8f83\u4e8e\u5757\u8870\u843d\u6a21\u578b\uff0c\u57fa\u4e8e\u5386\u53f2\u5bfc\u9891\u7684\u8001\u5316\u611f\u77e5\u4f30\u8ba1\u5668\u5728\u4fe1\u9053\u4f30\u8ba1\u7cbe\u5ea6\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u63d0\u5347\uff1b\u5728\u771f\u5b9e\u6742\u6ce2\u73af\u5883\u4e2d\uff0c\u5229\u7528\u4f30\u8ba1\u7684\u6742\u6ce2\u7edf\u8ba1\u5b9e\u73b0\u4f4e\u5f3a\u5ea6\u6291\u5236\u540e\uff0c\u80fd\u591f\u6210\u529f\u63d0\u53d6\u76ee\u6807\u53c2\u6570\uff1b\u5e76\u53d1\u73b0\u901a\u4fe1\u6ce2\u675f\u5728\u8303\u56f4\u5206\u8fa8\u7387\u4e0a\u4e0d\u8db3\uff0c\u9700\u8981\u4e13\u7528\u611f\u77e5\u6ce2\u675f\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u8003\u8651\u4fe1\u9053\u8001\u5316\u4e0e\u591a\u666e\u52d2\u6742\u6ce2\u7684\u8054\u5408\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u9002\u5e94\u65f6\u53d8\u4f20\u64ad\u73af\u5883\u7684 ISAC \u7cfb\u7edf\u6a21\u578b\u548c\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f4e\u81f3\u4e2d\u7b49\u79fb\u52a8\u573a\u666f\u4e0b\u7684\u4fe1\u9053\u4f30\u8ba1\u4e0e\u76ee\u6807\u63a2\u6d4b\u6027\u80fd\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5728\u5b9e\u9645\u6742\u6ce2\u73af\u5883\u4e2d\u5b9e\u73b0\u6709\u6548\u6742\u6ce2\u6291\u5236\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.05092", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05092", "abs": "https://arxiv.org/abs/2601.05092", "authors": ["Boyu Ning", "Haifan Yin", "Sixu Liu", "Hao Deng", "Songjie Yang", "Yuchen Zhang", "Weidong Mei", "David Gesbert", "Jaebum Park", "Robert W. Heath", "Emil Bj\u00f6rnson"], "title": "Precoding Matrix Indicator in the 5G NR Protocol: A Tutorial on 3GPP Beamforming Codebooks", "comment": "This work has been accepted by IEEE COMST with manuscript number 00802-2025.R1", "summary": "This paper bridges this critical gap by providing a systematic examination of the beamforming codebook technology, i.e., precoding matrix indicator (PMI), in the 5G NR from theoretical, standardization, and implementation perspectives. We begin by introducing the background of beamforming in multiple-input multiple-output (MIMO) systems and the signaling procedures for codebook-based beamforming in practical 5G systems. Then, we establish the fundamentals of regular codebooks and port-selection codebooks in 3GPP standards. Next, we provide rigorous technical analysis of 3GPP codebook evolution spanning Releases 15-18, with particular focus on: 1) We elucidate the core principles underlying codebook design, 2) provide clear physical interpretations for each symbolic variable in the codebook formulas, summarized in tabular form, and 3) offer intuitive visual illustrations to explain how codebook parameters convey information. These essential pedagogical elements are almost entirely absent in the often-obscure standardization documents. Through mathematical modeling, performance benchmarking, feedback comparisons, and scenario-dependent applicability analysis, we provide researchers and engineers with a unified understanding of beamforming codebooks in real-world systems. Furthermore, we identify future directions and other beamforming scenarios for ongoing research and development efforts. This work serves as both an informative tutorial and a guidance for future research, facilitating more effective collaboration between academia and industry in advancing wireless communication technologies.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04282", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04282", "abs": "https://arxiv.org/abs/2601.04282", "authors": ["Qiang Chen", "Chun-Wun Cheng", "Xiu Su", "Hongyan Xu", "Xi Lin", "Shan You", "Angelica I. Aviles-Rivero", "Yi Chen"], "title": "LEGATO: Good Identity Unlearning Is Continuous", "comment": null, "summary": "Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget identity of generative models: 1) inefficient, where identity erasure requires fine-tuning all the model's parameters; 2) limited controllability, where forgetting intensity cannot be controlled and explainability is lacking; 3) catastrophic collapse, where the model's retention capability undergoes drastic degradation as forgetting progresses. Forgetting has typically been handled through discrete and unstable updates, often requiring full-model fine-tuning and leading to catastrophic collapse. In this work, we argue that identity forgetting should be modeled as a continuous trajectory, and introduce LEGATO - Learn to ForgEt Identity in GenerAtive Models via Trajectory-consistent Neural Ordinary Differential Equations. LEGATO augments pre-trained generators with fine-tunable lightweight Neural ODE adapters, enabling smooth, controllable forgetting while keeping the original model weights frozen. This formulation allows forgetting intensity to be precisely modulated via ODE step size, offering interpretability and robustness. To further ensure stability, we introduce trajectory consistency constraints that explicitly prevent catastrophic collapse during unlearning. Extensive experiments across in-domain and out-of-domain identity unlearning benchmarks show that LEGATO achieves state-of-the-art forgetting performance, avoids catastrophic collapse and reduces fine-tuned parameters.", "AI": {"tldr": "LEGATO \u7528 Neural ODE \u9002\u914d\u5668\u5b9e\u73b0\u8fde\u7eed\u3001\u53ef\u63a7\u7684\u751f\u6210\u6a21\u578b\u9057\u5fd8\uff0c\u914d\u5408\u8f68\u8ff9\u4e00\u81f4\u6027\u7ea6\u675f\uff0c\u964d\u4f4e\u53c2\u6570\u91cf\u3001\u907f\u514d\u5d29\u6e83\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u751f\u6210\u5f0f\u6a21\u578b\u8bad\u7ec3\u5927\u89c4\u6a21\u6570\u636e\u96c6\u540e\uff0c\u5220\u9664\u654f\u611f\u6216\u53d7\u7248\u6743\u4fdd\u62a4\u7684\u6570\u636e\uff08\u673a\u5668\u9057\u5fd8\uff09\u6781\u4e3a\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u3001\u53ef\u63a7\u6027\u5dee\u548c\u707e\u96be\u6027\u5d29\u6e83\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa LEGATO\uff0c\u901a\u8fc7\u5728\u9884\u8bad\u7ec3\u751f\u6210\u5668\u4e0a\u6dfb\u52a0\u53ef\u5fae\u8c03\u7684\u8f7b\u91cf\u5316 Neural ODE \u9002\u914d\u5668\uff0c\u5c06\u9057\u5fd8\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u8fde\u7eed\u8f68\u8ff9\uff0c\u539f\u6a21\u578b\u53c2\u6570\u51bb\u7ed3\uff0c\u4ec5\u8c03\u6574 ODE \u6b65\u957f\u5b9e\u73b0\u53ef\u8c03\u3001\u53ef\u89e3\u91ca\u7684\u9057\u5fd8\uff1b\u540c\u65f6\u5f15\u5165\u8f68\u8ff9\u4e00\u81f4\u6027\u7ea6\u675f\u9632\u6b62\u707e\u96be\u6027\u5d29\u6e83\u3002", "result": "\u5728\u591a\u79cd\u57df\u5185\u5916\u8eab\u4efd\u9057\u5fd8\u57fa\u51c6\u5b9e\u9a8c\u4e2d\uff0cLEGATO \u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u9057\u5fd8\u6027\u80fd\uff0c\u663e\u8457\u964d\u4f4e\u5dee\u5f02\u5316\u53c2\u6570\u91cf\uff0c\u4e14\u5b8c\u5168\u907f\u514d\u4e86\u707e\u96be\u6027\u5d29\u6e83\u3002", "conclusion": "LEGATO \u6210\u529f\u514b\u670d\u4e86\u73b0\u6709\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\u7684\u4f4e\u6548\u3001\u53ef\u63a7\u6027\u4e0d\u8db3\u4e0e\u6027\u80fd\u5d29\u6e83\u4e09\u5927\u96be\u9898\uff0c\u4e3a\u751f\u6210\u6a21\u578b\u7684\u9690\u79c1\u4e0e\u7248\u6743\u5408\u89c4\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u4e14\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05178", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.05178", "abs": "https://arxiv.org/abs/2601.05178", "authors": ["Ehsan Shourezari", "Ossi Kaltiokallio", "Mehmet C. Ilter", "Jukka Talvitie", "Gonzalo Seco-Granados", "Henk Wymeersch", "Mikko Valkama"], "title": "Multi-band Carrier Phase Positioning toward 6G: Performance Bounds and Efficient Estimators", "comment": "13 pages, 10 figures, under review in IEEE Transactions on Wireless Communications", "summary": "In addition to satellite systems, carrier phase positioning (CPP) is gaining attraction also in terrestrial mobile networks, particularly in 5G New Radio evolution toward 6G. One key challenge is to resolve the integer ambiguity problem, as the carrier phase provides only relative position information. This work introduces and studies a multi-band CPP scenario with intra- and inter-band carrier aggregation (CA) opportunities across FR1, mmWave-FR2, and emerging 6G FR3 bands. Specifically, we derive multi-band CPP performance bounds, showcasing the superiority of multi-band CPP for high-precision localization in current and future mobile networks, while noting also practical imperfections such as clock offsets between the user equipment (UE) and the network as well as mutual clock imperfections between the network nodes. A wide collection of numerical results is provided, covering the impacts of the available carrier bandwidth, number of aggregated carriers, transmit power, and the number of network nodes or base stations. The offered results highlight that only two carriers suffice to substantially facilitate resolving the integer ambiguity problem while also largely enhancing the robustness of positioning against imperfections imposed by the network-side clocks and multi-path propagation. In addition, we also propose a two-stage practical estimator that achieves the derived bounds under all realistic bandwidth and transmit power conditions. Furthermore, we show that with an additional search-based refinement step, the proposed estimator becomes particularly suitable for narrowband Internet of Things applications operating efficiently even under narrow carrier bandwidths. Finally, both the derived bounds and the proposed estimators are extended to scenarios where the bands assigned to each base station are nonuniform or fully disjoint, enhancing the practical deployment flexibility.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.05165", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05165", "abs": "https://arxiv.org/abs/2601.05165", "authors": ["Zhentian Zhang", "Christos Masouros", "Kai-Kit Wong", "Jian Dang", "Zaichen Zhang", "Kaitao Meng", "Farshad Rostami Ghadi", "Mohammad Javad Ahmadi"], "title": "Fundamental Tradeoffs for ISAC Multiple Access in Finite-Blocklength Regime", "comment": null, "summary": "This paper investigates the fundamental communication--sensing tradeoffs of uplink dual-functional integrated sensing and communication (ISAC) multiple access under finite blocklength (FBL) constraints. Unlike conventional asymptotic analyses, we explicitly account for the limitations under FBL constraints imposed by short packets and low-latency transmission. By examining the unbiased channel state sensing estimator, we establish a geometric decomposition of the sensing error, indicating that it is jointly determined by the signal-to-noise ratio and the correlation structure of the information codebook. This insight reveals how cross-correlation among active users in the codebook geometry fundamentally constrains dual-functional ISAC performance. Consequently, we derive achievability and converse bounds that characterize the tradeoff between communication code rate and sensing accuracy in the FBL regime, with the converse further bounded by Shannon capacity. Moreover, by treating channel state sensing as a high-level sensing objective, a universal Cram\u00e9r--Rao bound is derived to link channel estimation accuracy to practical sensing parameters. Examples of parameter sensing are also provided based on 3GPP standard. Numerical results validate the theoretical analysis and demonstrate the impact of blocklength, antenna dimensions, and sensing requirements.", "AI": {"tldr": "\u672c\u6587\u5728\u6709\u9650\u5757\u957f\u5ea6\u73af\u5883\u4e0b\u5206\u6790\u4e0a\u884c\u53cc\u529f\u80fdISAC\u7684\u901a\u4fe1\u2013\u611f\u77e5\u6743\u8861\uff0c\u63d0\u4f9b\u51e0\u4f55\u5206\u89e3\u3001\u53ef\u8fbe/\u5bf9\u5076\u754c\u9650\u548cCRB\uff0c\u5e76\u7528\u6570\u503c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u5728FBL\u7ea6\u675f\u4e0b\uff0c\u4f20\u7edf\u6e10\u8fdb\u5206\u6790\u4e0d\u9002\u7528\u60c5\u5f62\u4e0b\u7684\u901a\u4fe1\u2013\u611f\u77e5\u6743\u8861\uff0c\u4ee5\u6307\u5bfc\u77ed\u5305\u901a\u4fe1\u548c\u4f4e\u65f6\u5ef6\u5e94\u7528\u7684\u7cfb\u7edf\u8bbe\u8ba1\u3002", "method": "\u5bf9\u77ed\u5305\u548c\u4f4e\u65f6\u5ef6\u6761\u4ef6\u4e0b\u7684\u4e0a\u884c\u53cc\u529f\u80fdISAC\u4fe1\u9053\u8fdb\u884c\u51e0\u4f55\u5206\u89e3\uff0c\u63a8\u5bfc\u53ef\u8fbe\u6027\u4e0e\u5bf9\u5076\u6027\u754c\u9650\uff0c\u5e76\u5229\u7528\u901a\u7528CRB\u5c06\u4fe1\u9053\u4f30\u8ba1\u8bef\u5dee\u4e0e\u611f\u77e5\u53c2\u6570\u8054\u7cfb\u3002", "result": "\u5f97\u5230\u53ef\u8fbe\u6027\u4e0e\u5bf9\u5076\u6027\u754c\u9650\u3001\u4ee5Shannon\u5bb9\u91cf\u4e3a\u4e0a\u754c\u7684\u5bf9\u5076\u754c\u9650\uff0c\u4ee5\u53ca\u5c06\u4fe1\u9053\u4f30\u8ba1\u8bef\u5dee\u4e0e\u611f\u77e5\u53c2\u6570\u5173\u8054\u7684CRB\uff1b\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u5e76\u663e\u793a\u4e86\u5757\u957f\u5ea6\u3001\u5929\u7ebf\u5c3a\u5bf8\u548c\u611f\u77e5\u9700\u6c42\u7684\u5f71\u54cd\u3002", "conclusion": "\u5728\u6709\u9650\u5757\u957f\u5ea6\uff08FBL\uff09\u9650\u5236\u4e0b\uff0c\u4f7f\u7528\u51e0\u4f55\u5206\u89e3\u3001\u53ef\u8fbe\u6027\u4e0e\u5bf9\u5076\u6027\u754c\u5b9a\u548cCRB\u5206\u6790\u63ed\u793a\u4e86\u4e0a\u884c\u53cc\u529f\u80fdISAC\u5728\u901a\u4fe1\u901f\u7387\u4e0e\u611f\u77e5\u7cbe\u5ea6\u4e4b\u95f4\u7684\u6839\u672c\u5e73\u8861\uff0c\u5e76\u6307\u51fa\u4fe1\u53f7\u76f8\u5173\u6027\u5bf9\u6027\u80fd\u7684\u5173\u952e\u5f71\u54cd\u3002"}}
{"id": "2601.04283", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04283", "abs": "https://arxiv.org/abs/2601.04283", "authors": ["Nikolay Yudin"], "title": "Mitigating Position-Shift Failures in Text-Based Modular Arithmetic via Position Curriculum and Template Diversity", "comment": null, "summary": "Building on insights from the grokking literature, we study character-level Transformers trained to compute modular addition from text, and focus on robustness under input-format variation rather than only in-distribution accuracy. We identify a previously under-emphasized failure mode: models that achieve high in-distribution accuracy can fail catastrophically when the same expression is shifted to different absolute character positions (\"position shift\") or presented under out-of-distribution natural-language templates. Using a disjoint-pair split over all ordered pairs for p=97, we show that a baseline model reaches strong in-distribution performance yet collapses under position shift and template OOD. We then introduce a simple training recipe that combines (i) explicit expression boundary markers, (ii) position curriculum that broadens the range of absolute positions seen during training, (iii) diverse template mixtures, and (iv) consistency training across multiple variants per example. Across three seeds, this intervention substantially improves robustness to position shift and template OOD while maintaining high in-distribution accuracy, whereas an ALiBi-style ablation fails to learn the task under our setup. Our results suggest that steering procedural generalization under noisy supervision benefits from explicitly training invariances that are otherwise absent from the data distribution, and we provide a reproducible evaluation protocol and artifacts.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04486", "categories": ["cs.CR", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.04486", "abs": "https://arxiv.org/abs/2601.04486", "authors": ["Israt Jahan Chowdhury", "Md Abu Yousuf Tanvir"], "title": "Decision-Aware Trust Signal Alignment for SOC Alert Triage", "comment": null, "summary": "Detection systems that utilize machine learning are progressively implemented at Security Operations Centers (SOCs) to help an analyst to filter through high volumes of security alerts. Practically, such systems tend to reveal probabilistic results or confidence scores which are ill-calibrated and hard to read when under pressure. Qualitative and survey based studies of SOC practice done before reveal that poor alert quality and alert overload greatly augment the burden on the analyst, especially when tool outputs are not coherent with decision requirements, or signal noise. One of the most significant limitations is that model confidence is usually shown without expressing that there are asymmetric costs in decision making where false alarms are much less harmful than missed attacks. The present paper presents a decision-sensitive trust signal correspondence scheme of SOC alert triage. The framework combines confidence that has been calibrated, lightweight uncertainty cues, and cost-sensitive decision thresholds into coherent decision-support layer, instead of making changes to detection models. To enhance probabilistic consistency, the calibration is done using the known post-hoc methods and the uncertainty cues give conservative protection in situations where model certainty is low. To measure the model-independent performance of the suggested model, we apply the Logistic Regression and the Random Forest classifiers to the UNSW-NB15 intrusion detection benchmark. According to simulation findings, false negatives are greatly amplified by the presence of misaligned displays of confidence, whereas cost weighted loss decreases by orders of magnitude between models with decision aligned trust signals. Lastly, we describe a human-in-the-loop study plan that would allow empirically assessing the decision-making of the analysts with aligned and misaligned trust interfaces.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u6821\u51c6\u7684\u7f6e\u4fe1\u5ea6\u3001\u8f7b\u91cf\u4e0d\u786e\u5b9a\u6027\u63d0\u793a\u4e0e\u6210\u672c\u654f\u611f\u9608\u503c\u96c6\u6210\u7684\u4fe1\u4efb\u4fe1\u53f7\u5bf9\u9f50\u65b9\u6848\uff0c\u5728UNSW\u2011NB15\u4e0a\u5b9e\u9a8c\u8868\u660e\u53ef\u663e\u8457\u964d\u4f4e\u6f0f\u62a5\u548c\u6210\u672c\u635f\u5931\u3002\u672a\u6765\u5c06\u901a\u8fc7\u4eba\u673a\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u68c0\u6d4b\u7cfb\u7edf\u5728SOC\u4e2d\u8f93\u51fa\u7684\u6982\u7387\u6216\u7f6e\u4fe1\u5206\u6570\u5f80\u5f80\u672a\u6821\u51c6\uff0c\u96be\u4ee5\u5728\u538b\u529b\u4e0b\u89e3\u8bfb\u3002\u4e14\u7f3a\u4e4f\u5bf9\u8bef\u62a5\u6210\u672c\u8fdc\u4f4e\u4e8e\u6f0f\u62a5\u6210\u672c\u7684\u7ecf\u6d4e\u6743\u8861\u3002\u5f31\u7684\u7f6e\u4fe1\u5ea6\u8868\u73b0\u4e0e\u4e0d\u5339\u914d\u7684\u51b3\u7b56\u9700\u6c42\u4f1a\u663e\u8457\u589e\u5927\u5206\u6790\u5e08\u8d1f\u62c5\u3002", "method": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u51b3\u7b56\u654f\u611f\u7684\u4fe1\u4efb\u4fe1\u53f7\u5bf9\u5e94\u65b9\u6848\uff0c\u7528\u4e8eSOC\u8b66\u62a5\u5206\u7ea7\u3002\u8be5\u6846\u67b6\u5c06\u5df2\u6821\u51c6\u7684\u7f6e\u4fe1\u5ea6\u3001\u8f7b\u91cf\u7ea7\u4e0d\u786e\u5b9a\u6027\u63d0\u793a\u4ee5\u53ca\u6210\u672c\u654f\u611f\u7684\u51b3\u7b56\u9608\u503c\u7ed3\u5408\u6210\u4e00\u81f4\u7684\u51b3\u7b56\u652f\u6301\u5c42\uff0c\u800c\u65e0\u9700\u6539\u52a8\u68c0\u6d4b\u6a21\u578b\u3002\u7f6e\u4fe1\u5ea6\u6821\u51c6\u91c7\u7528\u5df2\u77e5\u7684\u4e8b\u540e\u6821\u51c6\u65b9\u6cd5\uff1b\u5728\u6a21\u578b\u7f6e\u4fe1\u5ea6\u8f83\u4f4e\u7684\u60c5\u51b5\u4e0b\u5f15\u5165\u4fdd\u5b88\u7684\u4e0d\u786e\u5b9a\u6027\u63d0\u793a\u3002\u968f\u540e\u5c06\u8be5\u65b9\u6848\u5e94\u7528\u4e8eUNSW\u2011NB15\u5165\u4fb5\u68c0\u6d4b\u57fa\u51c6\uff0c\u5206\u522b\u4f7f\u7528\u903b\u8f91\u56de\u5f52\u548c\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8bef\u5bf9\u9f50\u7684\u7f6e\u4fe1\u5ea6\u663e\u793a\u663e\u8457\u589e\u52a0\u6f0f\u62a5\u7387\uff1b\u800c\u91c7\u7528\u5bf9\u9f50\u7684\u4fe1\u4efb\u4fe1\u53f7\u540e\uff0c\u6210\u672c\u52a0\u6743\u635f\u5931\u53ef\u4e0b\u964d\u6570\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u63d0\u4f9b\u4e00\u79cd\u51b3\u7b56\u5bfc\u5411\u7684\u4fe1\u4efb\u4fe1\u53f7\u673a\u5236\uff0c\u80fd\u591f\u63d0\u5347\u8b66\u62a5\u8d28\u91cf\u5e76\u964d\u4f4e\u6f0f\u62a5\u98ce\u9669\uff0c\u4e3a\u5206\u6790\u5e08\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u51b3\u7b56\u652f\u6301\u3002\u672a\u6765\u8ba1\u5212\u5f00\u5c55\u4eba\u673a\u4ea4\u4e92\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u5bf9\u9f50\u4e0e\u672a\u5bf9\u9f50\u4fe1\u4efb\u754c\u9762\u7684\u5206\u6790\u5e08\u51b3\u7b56\u3002"}}
{"id": "2601.05173", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05173", "abs": "https://arxiv.org/abs/2601.05173", "authors": ["Chun Hei Michael Shiu", "Hei Victor Cheng", "Lele Wang"], "title": "Information-Theoretic Limits on Exact Subgraph Alignment Problem", "comment": "This work was presented in part at the 2025 IEEE International Symposium on Information Theory and submitted in part to the 2026 IEEE International Symposium on Information Theory", "summary": "The graph alignment problem aims to identify the vertex correspondence between two correlated graphs. Most existing studies focus on the scenario in which the two graphs share the same vertex set. However, in many real-world applications, such as computer vision, social network analysis, and bioinformatics, the task often involves locating a small graph pattern within a larger graph. Existing graph alignment algorithms and analysis cannot directly address these scenarios because they are not designed to identify the specific subset of vertices where the small graph pattern resides within the larger graph. Motivated by this limitation, we introduce the subgraph alignment problem, which seeks to recover both the vertex set and/or the vertex correspondence of a small graph pattern embedded in a larger graph. In the special case where the small graph pattern is an induced subgraph of the larger graph and both the vertex set and correspondence are to be recovered, the problem reduces to the subgraph isomorphism problem, which is NP-complete in the worst case. In this paper, we formally formulate the subgraph alignment problem by proposing the Erdos-Renyi subgraph pair model together with some appropriate recovery criterion. We then establish almost-tight information-theoretic results for the subgraph alignment problem and present some novel approaches for the analysis.", "AI": {"tldr": "\u672c\u6587\u5b9a\u4e49\u5b50\u56fe\u5bf9\u9f50\u95ee\u9898\uff0c\u4f7f\u7528\u968f\u673a\u6a21\u578b\u7ed9\u51fa\u4fe1\u606f\u8bba\u6781\u9650\uff0c\u8bc1\u660e\u51e0\u4e4e\u7d27\u81f4\u53ef\u6062\u590d\uff0c\u5e76\u63d0\u4f9b\u65b0\u7684\u5206\u6790\u601d\u8def\u3002", "motivation": "\u73b0\u6709\u56fe\u5bf9\u9f50\u5047\u8bbe\u4e24\u56fe\u5171\u4eab\u9876\u70b9\u96c6\u5408\uff0c\u65e0\u6cd5\u5b9a\u4f4d\u5927\u56fe\u4e2d\u7684\u5c0f\u56fe\u6a21\u5f0f\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u8bc6\u522b\u5b50\u56fe\u6a21\u5f0f\uff0c\u56e0\u800c\u5f15\u5165\u5b50\u56fe\u5bf9\u9f50\u3002", "method": "\u6784\u9020Erd\u0151s\u2013R\u00e9nyi\u5b50\u56fe\u5bf9\u5076\u6a21\u578b\u5e76\u5b9a\u4e49\u6062\u590d\u6307\u6807\uff0c\u5229\u7528\u4fe1\u606f\u8bba\u65b9\u6cd5\u4e0e\u56fe\u7ed3\u6784\u6027\u8d28\u5206\u6790\u5f97\u5230\u9608\u503c\u3002", "result": "\u7ed9\u51fa\u5b50\u56fe\u5bf9\u9f50\u7684\u4e0a\u9650\u4e0e\u4e0b\u9650\uff0c\u5e76\u8bc1\u660e\u5728\u968f\u673a\u6a21\u578b\u4e2d\u4e0a\u4e0b\u754c\u76f8\u5dee\u65e0\u591a\u89d2\uff0c\u63d0\u51fa\u65b0\u5206\u6790\u5de5\u5177\uff0c\u5b9e\u73b0\u51e0\u4e4e\u7d27\u81f4\u6062\u590d\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u5b50\u56fe\u5bf9\u9f50\u95ee\u9898\u5e76\u7ed9\u51fa\u4e86\u4fe1\u606f\u8bba\u6781\u9650\uff0c\u8bc1\u660e\u8be5\u95ee\u9898\u5728\u591a\u79cd\u60c5\u5f62\u4e0b\u51e0\u4e4e\u7d27\u81f4\u53ef\u6062\u590d\uff0c\u8868\u660e\u5728\u968f\u673a\u5efa\u6a21\u4e0b\u53ef\u7528\u7b56\u7565\u53ef\u5b9a\u4f4d\u5c0f\u56fe\u6a21\u5f0f\u5e76\u6062\u590d\u5bf9\u5e94\u5173\u7cfb\u3002"}}
{"id": "2601.04286", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04286", "abs": "https://arxiv.org/abs/2601.04286", "authors": ["Niklas Kueper", "Kartik Chari", "Elsa Andrea Kirchner"], "title": "Enhancing Robustness of Asynchronous EEG-Based Movement Prediction using Classifier Ensembles", "comment": null, "summary": "Objective: Stroke is one of the leading causes of disabilities. One promising approach is to extend the rehabilitation with self-initiated robot-assisted movement therapy. To enable this, it is required to detect the patient's intention to move to trigger the assistance of a robotic device. This intention to move can be detected from human surface electroencephalography (EEG) signals; however, it is particularly challenging to decode when classifications are performed online and asynchronously. In this work, the effectiveness of classifier ensembles and a sliding-window postprocessing technique was investigated to enhance the robustness of such asynchronous classification. Approach: To investigate the effectiveness of classifier ensembles and a sliding-window postprocessing, two EEG datasets with 14 healthy subjects who performed self-initiated arm movements were analyzed. Offline and pseudo-online evaluations were conducted to compare ensemble combinations of the support vector machine (SVM), multilayer perceptron (MLP), and EEGNet classification models. Results: The results of the pseudo-online evaluation show that the two model ensembles significantly outperformed the best single model for the optimal number of postprocessing windows. In particular, for single models, an increased number of postprocessing windows significantly improved classification performances. Interestingly, we found no significant improvements between performances of the best single model and classifier ensembles in the offline evaluation. Significance: We demonstrated that classifier ensembles and appropriate postprocessing methods effectively enhance the asynchronous detection of movement intentions from EEG signals. In particular, the classifier ensemble approach yields greater improvements in online classification than in offline classification, and reduces false detections, i.e., early false positives.", "AI": {"tldr": "\u96c6\u6210\u6a21\u578b+\u6ed1\u52a8\u7a97\u53e3\u540e\u5904\u7406\u80fd\u63d0\u9ad8EEG\u5f02\u6b65\u8fd0\u52a8\u610f\u56fe\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u6700\u4f73\u6548\u679c\u89c1\u4f2a\u5728\u7ebf\u6761\u4ef6\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u68c0\u6d4b\u8111\u7535\uff08EEG\uff09\u4fe1\u53f7\u4e2d\u7684\u8fd0\u52a8\u610f\u56fe\uff0c\u652f\u6301\u60a3\u8005\u81ea\u53d1\u6027\u673a\u5668\u4eba\u8f85\u52a9\u624b\u6bb5\uff0c\u4ee5\u6539\u5584\u4e2d\u98ce\u540e\u5eb7\u590d\u3002\u8be5\u76ee\u6807\u9700\u8981\u5728\u5f02\u6b65\u5728\u7ebf\u73af\u5883\u4e2d\u9ad8\u6548\u8bc6\u522b\u610f\u56fe\uff0c\u800c\u4f20\u7edf\u5355\u6a21\u578b\u65b9\u6cd5\u5f80\u5f80\u53d7\u9650\u3002", "method": "\u4f7f\u7528\u4e24\u5957\u542b14\u540d\u5065\u5eb7\u53d7\u8bd5\u8005\u7684EEG\u6570\u636e\uff0c\u5206\u522b\u5bf9\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u3001\u591a\u5c42\u611f\u77e5\u5668\uff08MLP\uff09\u53caEEGNet\u4e09\u79cd\u5206\u7c7b\u6a21\u578b\u8fdb\u884c\u79bb\u7ebf\u53ca\u4f2a\u5728\u7ebf\u8bc4\u4f30\uff0c\u5e76\u6784\u5efa\u5404\u7c7b\u7ec4\u5408\u96c6\u6210\u6a21\u578b\u3002\u540c\u65f6\u5e94\u7528\u6ed1\u52a8\u7a97\u53e3\u540e\u5904\u7406\u6280\u672f\uff0c\u63a2\u7a76\u7a97\u53e3\u6570\u5bf9\u5f02\u6b65\u8bc6\u522b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u4f2a\u5728\u7ebf\u8bc4\u4f30\u8868\u660e\uff0c\u5728\u6700\u4f18\u7a97\u53e3\u6570\u4e0b\uff0c\u6a21\u578b\u96c6\u6210\u663e\u8457\u8d85\u8d8a\u6700\u4f73\u5355\u6a21\u578b\u3002\u968f\u7740\u7a97\u53e3\u6570\u589e\u52a0\uff0c\u5355\u6a21\u578b\u6027\u80fd\u4ea6\u5927\u5e45\u63d0\u5347\u3002\u79bb\u7ebf\u8bc4\u4f30\u4e2d\uff0c\u5355\u6a21\u578b\u4e0e\u96c6\u6210\u6a21\u578b\u4e4b\u95f4\u65e0\u663e\u8457\u5dee\u8ddd\u3002", "conclusion": "\u96c6\u6210\u5b66\u4e60\u4e0e\u6070\u5f53\u7684\u540e\u5904\u7406\u53ef\u663e\u8457\u63d0\u5347EEG\u9a71\u52a8\u7684\u5f02\u6b65\u8fd0\u52a8\u610f\u56fe\u8bc6\u522b\u6548\u679c\uff0c\u5c24\u5176\u5728\u5728\u7ebf\u573a\u666f\u4e0b\u80fd\u66f4\u6709\u6548\u964d\u4f4e\u8bef\u68c0\u7387\u3002"}}
{"id": "2601.04512", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.04512", "abs": "https://arxiv.org/abs/2601.04512", "authors": ["Yinghan Hou", "Zongyou Yang", "Xiaokun Yang"], "title": "Application of Hybrid Chain Storage Framework in Energy Trading and Carbon Asset Management", "comment": "6 pages, 5 figures", "summary": "Distributed energy trading and carbon asset management involve high-frequency, small-value settlements with strong audit requirements. Fully on-chain designs incur excessive cost, while purely off-chain approaches lack verifiable consistency. This paper presents a hybrid on-chain and off-chain settlement framework that anchors settlement commitments and key constraints on-chain and links off-chain records through deterministic digests and replayable auditing. Experiments under publicly constrained workloads show that the framework significantly reduces on-chain execution and storage cost while preserving audit trustworthiness.", "AI": {"tldr": "\u8be5\u6846\u67b6\u628a\u9ad8\u9891\u5c0f\u989d\u7ed3\u7b97\u94fe\u4e0b\u5904\u7406\uff0c\u51cf\u5c11\u94fe\u4e0a\u8d1f\u62c5\uff0c\u4ecd\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u5ba1\u8ba1", "motivation": "\u9ad8\u9891\u3001\u5c0f\u989d\u7ed3\u7b97\u4e0e\u4e25\u82db\u5ba1\u8ba1\u9700\u6c42", "method": "\u5c06\u7ed3\u7b97\u627f\u8bfa\u4e0e\u5173\u952e\u7ea6\u675f\u951a\u5b9a\u81f3\u94fe\u4e0a\uff0c\u540c\u65f6\u901a\u8fc7\u786e\u5b9a\u6027\u6458\u8981\u548c\u53ef\u91cd\u653e\u5ba1\u8ba1\u5173\u8054\u94fe\u4e0b\u8bb0\u5f55\uff0c\u6784\u5efa\u6df7\u5408\u94fe\u4e0a\u94fe\u4e0b\u7ed3\u7b97\u6846\u67b6", "result": "\u5728\u516c\u5f00\u53d7\u9650\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\uff0c\u663e\u8457\u964d\u4f4e\u94fe\u4e0a\u6267\u884c\u4e0e\u5b58\u50a8\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u5ba1\u8ba1\u53ef\u4fe1\u6027", "conclusion": "\u6df7\u5408\u94fe\u4e0a\u94fe\u4e0b\u8bbe\u8ba1\u517c\u987e\u6210\u672c\u4e0e\u53ef\u5ba1\u8ba1\u6027\uff0c\u662f\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.04483", "categories": ["cs.LG", "cs.AI", "cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04483", "abs": "https://arxiv.org/abs/2601.04483", "authors": ["Yongjun Kim", "Hyeongjun Park", "Hwanjin Kim", "Junil Choi"], "title": "Hybrid Federated Learning for Noise-Robust Training", "comment": null, "summary": "Federated learning (FL) and federated distillation (FD) are distributed learning paradigms that train UE models with enhanced privacy, each offering different trade-offs between noise robustness and learning speed. To mitigate their respective weaknesses, we propose a hybrid federated learning (HFL) framework in which each user equipment (UE) transmits either gradients or logits, and the base station (BS) selects the per-round weights of FL and FD updates. We derive convergence of HFL framework and introduce two methods to exploit degrees of freedom (DoF) in HFL, which are (i) adaptive UE clustering via Jenks optimization and (ii) adaptive weight selection via a damped Newton method. Numerical results show that HFL achieves superior test accuracy at low SNR when both DoF are exploited.", "AI": {"tldr": "HFL\u901a\u8fc7\u5728UE\u4fa7\u4ea4\u66ff\u4f20\u8f93\u68af\u5ea6/\u65e5\u5fd7\u3001\u57fa\u7ad9\u52a8\u6001\u8c03\u5ea6\u6743\u91cd\uff0c\u5e76\u7ed3\u5408Jenks\u805a\u7c7b\u4e0e\u963b\u5c3c\u725b\u987f\u6743\u91cd\u4f18\u5316\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u73af\u5883\u4e0b\u663e\u8457\u63d0\u5347\u5b66\u4e60\u51c6\u786e\u7387\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e0e\u8054\u90a6\u84b8\u998f\u5404\u6709\u566a\u58f0\u9c81\u68d2\u6027\u4e0e\u5b66\u4e60\u901f\u5ea6\u7684\u6743\u8861\uff0c\u5355\u4e00\u8303\u5f0f\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u4e24\u8005\u9700\u6c42\uff1b\u56e0\u6b64\uff0c\u878d\u5408\u4e24\u8005\u4ee5\u517c\u987e\u9690\u79c1\u3001\u9c81\u68d2\u6027\u4e0e\u6548\u7387\uff0c\u63d0\u5347\u5728\u65e0\u7ebf\u73af\u5883\u4e0b\u7684\u6027\u80fd\u6210\u4e3a\u8feb\u5207\u9700\u6c42\u3002", "method": "\u2460\u5728\u6bcf\u8f6e\u8bad\u7ec3\u4e2d\uff0c\u7528\u6237\u7ec8\u7aef\uff08UE\uff09\u968f\u673a\u6216\u6309\u7b56\u7565\u53d1\u9001\u68af\u5ea6\u6216logits\uff1b\u2461\u57fa\u7ad9\uff08BS\uff09\u6839\u636e\u5f53\u524d\u73af\u5883\u548c\u6a21\u578b\u66f4\u65b0\u60c5\u51b5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6743\u91cd\uff08\u4f7f\u7528\u963b\u5c3c\u725b\u987f\u6cd5\uff09\u51b3\u5b9aFL\u548cFD\u7684\u52a0\u6743\u6bd4\u4f8b\uff1b\u2462\u5229\u7528Jenks\u4f18\u5316\u7b97\u6cd5\u5bf9UE\u8fdb\u884c\u805a\u7c7b\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u5b66\u4e60\u6548\u679c\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86HFL\u6846\u67b6\u7684\u6536\u655b\u6027\uff1b\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u540c\u65f6\u5229\u7528\u81ea\u9002\u5e94\u805a\u7c7b\u548c\u6743\u91cd\u9009\u62e9\u7684\u81ea\u7531\u5ea6\u65f6\uff0cHFL\u5728\u4f4eSNR\u6761\u4ef6\u4e0b\u53d6\u5f97\u663e\u8457\u63d0\u5347\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u6df7\u5408\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff08HFL\uff09\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u68af\u5ea6\u6216logits\u5e76\u5bf9\u6bcf\u8f6e\u6743\u91cd\u8fdb\u884c\u8c03\u5ea6\uff0c\u878d\u5408\u4e86FL\u548cFD\u7684\u4f18\u52bf\uff0c\u5b9e\u73b0\u4e86\u5728\u4f4e\u4fe1\u566a\u6bd4\u73af\u5883\u4e0b\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\u3002"}}
{"id": "2601.04287", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.04287", "abs": "https://arxiv.org/abs/2601.04287", "authors": ["Ben Carvell", "George De Ath", "Eseoghene Benjamin", "Richard Everson"], "title": "Online Action-Stacking Improves Reinforcement Learning Performance for Air Traffic Control", "comment": null, "summary": "We introduce online action-stacking, an inference-time wrapper for reinforcement learning policies that produces realistic air traffic control commands while allowing training on a much smaller discrete action space. Policies are trained with simple incremental heading or level adjustments, together with an action-damping penalty that reduces instruction frequency and leads agents to issue commands in short bursts. At inference, online action-stacking compiles these bursts of primitive actions into domain-appropriate compound clearances. Using Proximal Policy Optimisation and the BluebirdDT digital twin platform, we train agents to navigate aircraft along lateral routes, manage climb and descent to target flight levels, and perform two-aircraft collision avoidance under a minimum separation constraint. In our lateral navigation experiments, action stacking greatly reduces the number of issued instructions relative to a damped baseline and achieves comparable performance to a policy trained with a 37-dimensional action space, despite operating with only five actions. These results indicate that online action-stacking helps bridge a key gap between standard reinforcement learning formulations and operational ATC requirements, and provides a simple mechanism for scaling to more complex control scenarios.", "AI": {"tldr": "\u63d0\u51fa\u5728\u7ebf\u52a8\u4f5c\u5806\u53e0\u65b9\u6cd5\uff0c\u5728\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2d\u4f7f\u7528\u5c11\u91cf\u79bb\u6563\u52a8\u4f5c\u5e76\u901a\u8fc7\u63a8\u7406\u65f6\u5408\u6210\u590d\u5408\u6307\u4ee4\uff0c\u663e\u8457\u964d\u4f4e\u6307\u4ee4\u9891\u7387\uff0c\u5b9e\u6d4b\u5728 ATC \u4efb\u52a1\u4e2d\u6027\u80fd\u4e0e\u9ad8\u7ef4\u52a8\u4f5c\u6a21\u578b\u76f8\u5f53\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5728\u822a\u7a7a\u4ea4\u901a\u63a7\u5236\uff08ATC\uff09\u4e2d\u96be\u4ee5\u76f4\u63a5\u6620\u5c04\u5230\u5b9e\u9645\u64cd\u4f5c\uff0c\u56e0\u4e3a\u9700\u8981\u5927\u91cf\u79bb\u6563\u52a8\u4f5c\u4e14\u6307\u4ee4\u9891\u7387\u8fc7\u9ad8\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5728\u4fdd\u6301\u884c\u52a8\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\uff0c\u51cf\u5c11\u6307\u4ee4\u6570\u91cf\u5e76\u5339\u914dATC\u64cd\u4f5c\u89c4\u8303\u3002", "method": "\u5728\u8bad\u7ec3\u9636\u6bb5\u4f7f\u7528\u589e\u91cf\u822a\u5411\u6216\u722c\u5347/\u4e0b\u964d\u7684\u7b80\u5355\u79bb\u6563\u52a8\u4f5c\uff0c\u5e76\u52a0\u5165\u52a8\u4f5c\u963b\u5c3c\u60e9\u7f5a\u4ee5\u964d\u4f4e\u6307\u4ee4\u9891\u7387\uff1b\u5728\u63a8\u7406\u9636\u6bb5\uff0c\u5c06\u77ed\u65f6\u539f\u5b50\u52a8\u4f5c\u5806\u53e0\u6210\u57df\u9002\u5f53\u7684\u590d\u5408\u6307\u4ee4\u3002\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u4e0eBluebirdDT\u6570\u5b57\u5b6a\u751f\u5e73\u53f0\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u6a2a\u5411\u5bfc\u822a\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u4e8e\u963b\u5c3c\u57fa\u7ebf\uff0c\u5728\u7ebf\u52a8\u4f5c\u5806\u53e0\u663e\u8457\u964d\u4f4e\u6307\u4ee4\u6570\u91cf\uff1b\u4e14\u4ec5\u4f7f\u7528\u4e94\u4e2a\u539f\u5b50\u52a8\u4f5c\u5373\u53ef\u4e0e\u4f7f\u752837\u7ef4\u52a8\u4f5c\u7a7a\u95f4\u7684\u6a21\u578b\u83b7\u5f97\u76f8\u4f3c\u6027\u80fd\u3002", "conclusion": "\u5728\u7ebf\u52a8\u4f5c\u5806\u53e0\u901a\u8fc7\u5728\u63a8\u7406\u65f6\u5c06\u4f4e\u7ef4\u539f\u5b50\u52a8\u4f5c\u5408\u5e76\u4e3a\u590d\u5408\u6307\u4ee4\uff0c\u663e\u8457\u51cf\u5c11\u6307\u4ee4\u9891\u7387\uff0c\u5e76\u80fd\u5728\u4ec5\u4f7f\u7528\u4e94\u52a8\u4f5c\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e0e\u9ad8\u7ef4\u52a8\u4f5c\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u5176\u5728\u822a\u7a7a\u4ea4\u901a\u63a7\u5236\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u6027\u5e76\u4e3a\u66f4\u590d\u6742\u573a\u666f\u63d0\u4f9b\u53ef\u6269\u5c55\u65b9\u6848\u3002"}}
{"id": "2601.04297", "categories": ["cs.LG", "cs.CV", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.04297", "abs": "https://arxiv.org/abs/2601.04297", "authors": ["Behrad Binaei-Haghighi", "Nafiseh Sadat Sajadi", "Mehrad Liviyan", "Reyhane Akhavan Kharazi", "Fatemeh Amirkhani", "Behnam Bahrak"], "title": "ArtCognition: A Multimodal AI Framework for Affective State Sensing from Visual and Kinematic Drawing Cues", "comment": "12 pages, 7 figures", "summary": "The objective assessment of human affective and psychological states presents a significant challenge, particularly through non-verbal channels. This paper introduces digital drawing as a rich and underexplored modality for affective sensing. We present a novel multimodal framework, named ArtCognition, for the automated analysis of the House-Tree-Person (HTP) test, a widely used psychological instrument. ArtCognition uniquely fuses two distinct data streams: static visual features from the final artwork, captured by computer vision models, and dynamic behavioral kinematic cues derived from the drawing process itself, such as stroke speed, pauses, and smoothness. To bridge the gap between low-level features and high-level psychological interpretation, we employ a Retrieval-Augmented Generation (RAG) architecture. This grounds the analysis in established psychological knowledge, enhancing explainability and reducing the potential for model hallucination. Our results demonstrate that the fusion of visual and behavioral kinematic cues provides a more nuanced assessment than either modality alone. We show significant correlations between the extracted multimodal features and standardized psychological metrics, validating the framework's potential as a scalable tool to support clinicians. This work contributes a new methodology for non-intrusive affective state assessment and opens new avenues for technology-assisted mental healthcare.", "AI": {"tldr": "ArtCognition\u5229\u7528\u6570\u5b57\u7ed8\u753b\u7684\u89c6\u89c9\u4e0e\u8fd0\u52a8\u4fe1\u606f\uff0c\u52a0\u4e0a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u63d0\u5347\u4e86\u60c5\u7eea\u8bc4\u4f30\u7684\u7ec6\u81f4\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u975e\u8bed\u8a00\u60c5\u7eea\u8bc4\u4f30\u65b9\u6cd5\u53d7\u9650\uff0c\u6570\u5b57\u7ed8\u753b\u4f5c\u4e3a\u4e30\u5bcc\u4f46\u672a\u5145\u5206\u5229\u7528\u7684\u975e\u8bed\u8a00\u5a92\u4ecb\uff0c\u53ef\u4e3a\u60c5\u7eea\u611f\u77e5\u63d0\u4f9b\u65b0\u7ef4\u5ea6\u3002", "method": "\u591a\u6a21\u6001\u6846\u67b6ArtCognition\u5c06HTP\u7ed8\u753b\u7684\u7535\u8111\u89c6\u89c9\u7279\u5f81\u4e0e\u7ed8\u5236\u8fc7\u7a0b\u7684\u8fd0\u52a8\u5b66\u6570\u636e\u7ed3\u5408\uff0c\u5e76\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u67b6\u6784\u5b9e\u73b0\u57fa\u4e8e\u5fc3\u7406\u5b66\u77e5\u8bc6\u7684\u89e3\u91ca\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u89c6\u89c9\u4e0e\u884c\u4e3a\u6a21\u6001\u878d\u5408\u540e\u4e0e\u6807\u51c6\u5fc3\u7406\u6307\u6807\u7684\u76f8\u5173\u5ea6\u663e\u8457\u9ad8\u4e8e\u5355\u4e00\u6a21\u6001\uff0c\u9a8c\u8bc1\u4e86\u5176\u53ef\u6269\u5c55\u6027\u4e0e\u4e34\u5e8a\u8f85\u52a9\u6f5c\u529b\u3002", "conclusion": "\u901a\u8fc7\u878d\u5408\u9759\u6001\u89c6\u89c9\u7279\u5f81\u4e0e\u52a8\u6001\u7ed8\u753b\u884c\u4e3a\uff0cArtCognition\u63d0\u4f9b\u66f4\u7ec6\u81f4\u3001\u53ef\u89e3\u91ca\u7684\u60c5\u7eea\u4e0e\u5fc3\u7406\u8bc4\u4f30\u3002"}}
{"id": "2601.04603", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04603", "abs": "https://arxiv.org/abs/2601.04603", "authors": ["Hoagy Cunningham", "Jerry Wei", "Zihan Wang", "Andrew Persic", "Alwin Peng", "Jordan Abderrachid", "Raj Agarwal", "Bobby Chen", "Austin Cohen", "Andy Dau", "Alek Dimitriev", "Rob Gilson", "Logan Howard", "Yijin Hua", "Jared Kaplan", "Jan Leike", "Mu Lin", "Christopher Liu", "Vladimir Mikulik", "Rohit Mittapalli", "Clare O'Hara", "Jin Pan", "Nikhil Saxena", "Alex Silverstein", "Yue Song", "Xunjie Yu", "Giulio Zhou", "Ethan Perez", "Mrinank Sharma"], "title": "Constitutional Classifiers++: Efficient Production-Grade Defenses against Universal Jailbreaks", "comment": null, "summary": "We introduce enhanced Constitutional Classifiers that deliver production-grade jailbreak robustness with dramatically reduced computational costs and refusal rates compared to previous-generation defenses. Our system combines several key insights. First, we develop exchange classifiers that evaluate model responses in their full conversational context, which addresses vulnerabilities in last-generation systems that examine outputs in isolation. Second, we implement a two-stage classifier cascade where lightweight classifiers screen all traffic and escalate only suspicious exchanges to more expensive classifiers. Third, we train efficient linear probe classifiers and ensemble them with external classifiers to simultaneously improve robustness and reduce computational costs. Together, these techniques yield a production-grade system achieving a 40x computational cost reduction compared to our baseline exchange classifier, while maintaining a 0.05% refusal rate on production traffic. Through extensive red-teaming comprising over 1,700 hours, we demonstrate strong protection against universal jailbreaks -- no attack on this system successfully elicited responses to all eight target queries comparable in detail to an undefended model. Our work establishes Constitutional Classifiers as practical and efficient safeguards for large language models.", "AI": {"tldr": "\u6539\u8fdb\u5baa\u6cd5\u5206\u7c7b\u5668\u5b9e\u73b0\u4e8640\u00d7\u6210\u672c\u8282\u7701\u30010.05%\u62d2\u7edd\u7387\uff0c\u9ad8\u6548\u62b5\u5fa1\u89e3\u9501\u653b\u51fb\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4e0a\u4e00\u4ee3\u7cfb\u7edf\u5728\u5355\u4e00\u8f93\u51fa\u68c0\u67e5\u65f6\u7684\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u5347\u5bf9\u6301\u7eed\u89e3\u9501\u653b\u51fb\u7684\u9632\u62a4\u6027\u80fd\u4e0e\u751f\u4ea7\u53ef\u884c\u6027\u3002", "method": "\u901a\u8fc7\u5168\u4e0a\u4e0b\u6587\u4ea4\u6d41\u5206\u7c7b\u3001\u8f7b\u91cf\u7ea7\u4e0e\u9ad8\u6210\u672c\u5206\u7c7b\u5668\u7684\u4e24\u7ea7\u7ea7\u8054\u3001\u7ebf\u6027\u63a2\u6d4b\u5668\u4e0e\u5916\u90e8\u5206\u7c7b\u5668\u7684\u96c6\u6210\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u5b89\u5168\u7684\u5bf9\u8bdd\u8bc4\u4f30\u6d41\u7a0b\u3002", "result": "\u57281,700\u5c0f\u65f6\u7684\u7ea2\u961f\u6d4b\u8bd5\u4e2d\uff0c\u65e0\u653b\u51fb\u80fd\u8ba9\u6a21\u578b\u5728\u516b\u4e2a\u76ee\u6807\u67e5\u8be2\u4e0a\u4ea7\u751f\u5b8c\u6574\u4e14\u7ec6\u8282\u76f8\u5f53\u7684\u56de\u7b54\uff0c\u62d2\u7edd\u7387\u4ec50.05%\uff0c\u6210\u672c\u76f8\u8f83\u57fa\u7ebf\u964d\u4f4e40\u500d\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86\u6539\u8fdb\u7248\u5baa\u6cd5\u5206\u7c7b\u5668\u80fd\u591f\u5728\u4fdd\u6301\u6781\u4f4e\u62d2\u7edd\u7387\u7684\u524d\u63d0\u4e0b\u5b9e\u73b040\u500d\u7684\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\uff0c\u5b9e\u7528\u4e14\u6709\u6548\u3002"}}
{"id": "2601.04299", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.04299", "abs": "https://arxiv.org/abs/2601.04299", "authors": ["Pir Bakhsh Khokhar", "Carmine Gravino", "Fabio Palomba", "Sule Yildrim Yayilgan", "Sarang Shaikh"], "title": "Transformer-Based Multi-Modal Temporal Embeddings for Explainable Metabolic Phenotyping in Type 1 Diabetes", "comment": null, "summary": "Type 1 diabetes (T1D) is a highly metabolically heterogeneous disease that cannot be adequately characterized by conventional biomarkers such as glycated hemoglobin (HbA1c). This study proposes an explainable deep learning framework that integrates continuous glucose monitoring (CGM) data with laboratory profiles to learn multimodal temporal embeddings of individual metabolic status. Temporal dependencies across modalities are modeled using a transformer encoder, while latent metabolic phenotypes are identified via Gaussian mixture modeling. Model interpretability is achieved through transformer attention visualization and SHAP-based feature attribution. Five latent metabolic phenotypes, ranging from metabolic stability to elevated cardiometabolic risk, were identified among 577 individuals with T1D. These phenotypes exhibit distinct biochemical profiles, including differences in glycemic control, lipid metabolism, renal markers, and thyrotropin (TSH) levels. Attention analysis highlights glucose variability as a dominant temporal factor, while SHAP analysis identifies HbA1c, triglycerides, cholesterol, creatinine, and TSH as key contributors to phenotype differentiation. Phenotype membership shows statistically significant, albeit modest, associations with hypertension, myocardial infarction, and heart failure. Overall, this explainable multimodal temporal embedding framework reveals physiologically coherent metabolic subgroups in T1D and supports risk stratification beyond single biomarkers.", "AI": {"tldr": "\u7528Transformer+Gaussian\u6df7\u5408+SHAP\u7684\u53ef\u89e3\u91ca\u6df1\u5ea6\u5b66\u4e60\uff0c\u8bc6\u522b1\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u4ee3\u8c22\u4e9a\u7fa4\u53ca\u5176\u98ce\u9669\u5173\u8054", "motivation": "\u7cd6\u5316\u8840\u7ea2\u86cb\u767d\u7b49\u4f20\u7edf\u751f\u7269\u6807\u5fd7\u7269\u65e0\u6cd5\u5145\u5206\u523b\u753b1\u578b\u7cd6\u5c3f\u75c5\u7684\u4ee3\u8c22\u5f02\u8d28\u6027\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u6570\u636e\u878d\u5408\u4e0e\u89e3\u91ca\u5de5\u5177", "method": "\u4f7f\u7528Transformer\u7f16\u7801\u5668\u6355\u6349\u8de8\u6a21\u6001\u65f6\u95f4\u4f9d\u8d56\uff0c\u968f\u540e\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u5f97\u5230\u6f5c\u5728\u4ee3\u8c22\u8868\u578b\uff0c\u5e76\u901a\u8fc7\u6ce8\u610f\u529b\u53ef\u89c6\u5316\u53caSHAP\u7279\u5f81\u5f52\u56e0\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027", "result": "\u5728577\u540dT1D\u60a3\u8005\u4e2d\u53d1\u73b0\u4e94\u79cd\u4ee3\u8c22\u8868\u578b\uff0c\u8868\u578b\u5728\u8840\u7cd6\u63a7\u5236\u3001\u8102\u8d28\u3001\u80be\u529f\u80fd\u53caTSH\u7b49\u6307\u6807\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5e76\u4e0e\u9ad8\u8840\u538b\u3001\u5fc3\u808c\u6897\u6b7b\u3001\u5fc3\u529b\u8870\u7aed\u7b49\u5fc3\u8840\u7ba1\u98ce\u9669\u5448\u7edf\u8ba1\u5b66\u5173\u8054", "conclusion": "\u663e\u793a\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u65f6\u95f4\u5d4c\u5165\u6846\u67b6\u80fd\u4eceCGM\u4e0e\u5b9e\u9a8c\u5ba4\u6570\u636e\u4e2d\u8bc6\u522b\u51fa\u4e94\u79cd\u751f\u7406\u5b66\u4e00\u81f4\u7684\u4ee3\u8c22\u4e9a\u7fa4\uff0c\u5e76\u53ef\u7528\u4e8e\u98ce\u9669\u5206\u5c42"}}
{"id": "2601.04641", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04641", "abs": "https://arxiv.org/abs/2601.04641", "authors": ["Lionel Z. Wang", "Yusheng Zhao", "Jiabin Luo", "Xinfeng Li", "Lixu Wang", "Yinan Peng", "Haoyang Li", "XiaoFeng Wang", "Wei Dong"], "title": "DP-MGTD: Privacy-Preserving Machine-Generated Text Detection via Adaptive Differentially Private Entity Sanitization", "comment": "12 pages, 1 figure, 1 tables", "summary": "The deployment of Machine-Generated Text (MGT) detection systems necessitates processing sensitive user data, creating a fundamental conflict between authorship verification and privacy preservation. Standard anonymization techniques often disrupt linguistic fluency, while rigorous Differential Privacy (DP) mechanisms typically degrade the statistical signals required for accurate detection. To resolve this dilemma, we propose \\textbf{DP-MGTD}, a framework incorporating an Adaptive Differentially Private Entity Sanitization algorithm. Our approach utilizes a two-stage mechanism that performs noisy frequency estimation and dynamically calibrates privacy budgets, applying Laplace and Exponential mechanisms to numerical and textual entities respectively. Crucially, we identify a counter-intuitive phenomenon where the application of DP noise amplifies the distinguishability between human and machine text by exposing distinct sensitivity patterns to perturbation. Extensive experiments on the MGTBench-2.0 dataset show that our method achieves near-perfect detection accuracy, significantly outperforming non-private baselines while satisfying strict privacy guarantees.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u81ea\u9002\u5e94\u5dee\u5206\u9690\u79c1\u5b9e\u4f53\u8131\u654f\u6846\u67b6DP-MGTD\uff0c\u65e2\u80fd\u4fdd\u62a4\u7528\u6237\u6570\u636e\u9690\u79c1\uff0c\u53c8\u80fd\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u673a\u5668\u751f\u6210\u6587\u672c\u68c0\u6d4b\uff0c\u53d1\u73b0\u5dee\u5206\u9690\u79c1\u566a\u58f0\u53ef\u63d0\u5347\u4eba\u7c7b\u4e0e\u673a\u5668\u6587\u672c\u7684\u53ef\u533a\u5206\u6027\u3002", "motivation": "\u673a\u5668\u751f\u6210\u6587\u672c\u68c0\u6d4b\u9700\u8981\u5206\u6790\u5305\u542b\u654f\u611f\u7528\u6237\u6570\u636e\u7684\u6587\u672c\uff0c\u7136\u800c\u4f20\u7edf\u533f\u540d\u5316\u4f1a\u7834\u574f\u8bed\u8a00\u6d41\u7545\u6027\uff0c\u4e25\u683c\u7684\u5dee\u5206\u9690\u79c1\u673a\u5236\u53c8\u4f1a\u524a\u5f31\u68c0\u6d4b\u6240\u9700\u7684\u7edf\u8ba1\u4fe1\u53f7\uff0c\u4e24\u8005\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u51b2\u7a81\u3002", "method": "\u5f15\u5165DP-MGTD\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u6b65\u673a\u5236\uff1a\u5148\u5bf9\u654f\u611f\u5b9e\u4f53\u505a\u566a\u58f0\u7684\u9891\u7387\u4f30\u8ba1\uff0c\u518d\u52a8\u6001\u8c03\u8282\u9690\u79c1\u9884\u7b97\uff1b\u5bf9\u6570\u503c\u5b9e\u4f53\u4f7f\u7528Laplace\u673a\u5236\uff0c\u5bf9\u6587\u672c\u5b9e\u4f53\u4f7f\u7528\u6307\u6570\u673a\u5236\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u5dee\u5206\u79c1\u6709\u5b9e\u4f53\u8131\u654f\u7b97\u6cd5\u3002", "result": "\u5728MGTBench-2.0\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cDP-MGTD\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u663e\u8457\u4f18\u4e8e\u975e\u79c1\u6709\u57fa\u7ebf\uff0c\u540c\u65f6\u6ee1\u8db3\u4e25\u683c\u7684\u9690\u79c1\u4fdd\u969c\u3002", "conclusion": "\u5c3d\u7ba1\u4f7f\u7528\u5dee\u5206\u9690\u79c1\u566a\u58f0\u4f1a\u6539\u53d8\u6587\u672c\u7279\u5f81\uff0c\u4f46\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u566a\u58f0\u53cd\u800c\u589e\u5f3a\u4e86\u4eba\u7c7b\u6587\u672c\u4e0e\u673a\u5668\u751f\u6210\u6587\u672c\u5728\u654f\u611f\u5b9e\u4f53\u4e0a\u7684\u53ef\u533a\u5206\u6027\uff0c\u56e0\u800c\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u4f5c\u8005\u8eab\u4efd\u68c0\u6d4b\u7684\u517c\u987e\u3002"}}
{"id": "2601.04697", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.04697", "abs": "https://arxiv.org/abs/2601.04697", "authors": ["Hongming Fei", "Zilong Hu", "Prosanta Gope", "Biplab Sikdar"], "title": "Unified Framework for Qualifying Security Boundary of PUFs Against Machine Learning Attacks", "comment": "13 pages, 8 figures", "summary": "Physical Unclonable Functions (PUFs) serve as lightweight, hardware-intrinsic entropy sources widely deployed in IoT security applications. However, delay-based PUFs are vulnerable to Machine Learning Attacks (MLAs), undermining their assumed unclonability. There are no valid metrics for evaluating PUF MLA resistance, but empirical modelling experiments, which lack theoretical guarantees and are highly sensitive to advances in machine learning techniques. To address the fundamental gap between PUF designs and security qualifications, this work proposes a novel, formal, and unified framework for evaluating PUF security against modelling attacks by providing security lower bounds, independent of specific attack models or learning algorithms. We mathematically characterise the adversary's advantage in predicting responses to unseen challenges based solely on observed challenge-response pairs (CRPs), formulating the problem as a conditional probability estimation over the space of candidate PUFs. We present our analysis on previous \"broken\" PUFs, e.g., Arbiter PUFs, XOR PUFs, Feed-Forward PUFs, and for the first time compare their MLA resistance in a formal way. In addition, we evaluate the currently \"secure\" CT PUF, and show its security boundary. We demonstrate that the proposed approach systematically quantifies PUF resilience, captures subtle security differences, and provides actionable, theoretically grounded security guarantees for the practical deployment of PUFs.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04361", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04361", "abs": "https://arxiv.org/abs/2601.04361", "authors": ["Mohammad Ali Javidian"], "title": "Causally-Aware Information Bottleneck for Domain Adaptation", "comment": "An extended abstract version of this work was accepted for the Proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "We tackle a common domain adaptation setting in causal systems. In this setting, the target variable is observed in the source domain but is entirely missing in the target domain. We aim to impute the target variable in the target domain from the remaining observed variables under various shifts. We frame this as learning a compact, mechanism-stable representation. This representation preserves information relevant for predicting the target while discarding spurious variation. For linear Gaussian causal models, we derive a closed-form Gaussian Information Bottleneck (GIB) solution. This solution reduces to a canonical correlation analysis (CCA)-style projection and offers Directed Acyclic Graph (DAG)-aware options when desired. For nonlinear or non-Gaussian data, we introduce a Variational Information Bottleneck (VIB) encoder-predictor. This approach scales to high dimensions and can be trained on source data and deployed zero-shot to the target domain. Across synthetic and real datasets, our approach consistently attains accurate imputations, supporting practical use in high-dimensional causal models and furnishing a unified, lightweight toolkit for causal domain adaptation.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04852", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.04852", "abs": "https://arxiv.org/abs/2601.04852", "authors": ["Tooba Qasim", "Vasilios A. Siris", "Izak Oosthuizen", "Muttukrishnan Rajarajan", "Sujit Biswas"], "title": "Quantum Secure Biometric Authentication in Decentralised Systems", "comment": null, "summary": "Biometric authentication has become integral to digital identity systems, particularly in smart cities where it en-ables secure access to services across governance, trans-portation, and public infrastructure. Centralised archi-tectures, though widely used, pose privacy and scalabil-ity challenges due to the aggregation of sensitive biomet-ric data. Decentralised identity frameworks offer better data sovereignty and eliminate single points of failure but introduce new security concerns, particularly around mu-tual trust among distributed devices. In such environments, biometric sensors and verification agents must authenticate one another before sharing sensitive biometric data. Ex-isting authentication schemes rely on classical public key infrastructure, which is increasingly susceptible to quan-tum attacks. This work addresses this gap by propos-ing a quantum-secure communication protocol for decen-tralised biometric systems, built upon an enhanced Quan-tum Key Distribution (QKD) system. The protocol incorpo-rates quantum-resilient authentication at both the classical and quantum layers of QKD: post-quantum cryptography (PQC) is used to secure the classical channel, while authen-tication qubits verify the integrity of the quantum channel. Once trust is established, QKD generates symmetric keys for encrypting biometric data in transit. Qiskit-based sim-ulations show a key generation rate of 15 bits/sec and 89% efficiency. This layered, quantum-resilient approach offers scalable, robust authentication for next-generation smart city infrastructures.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04940", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04940", "abs": "https://arxiv.org/abs/2601.04940", "authors": ["Arthur Nijdam", "Harri K\u00e4hk\u00f6nen", "Valtteri Niemi", "Paul Stankovski Wagner", "Sara Ramezanian"], "title": "CurricuLLM: Designing Personalized and Workforce-Aligned Cybersecurity Curricula Using Fine-Tuned LLMs", "comment": null, "summary": "The cybersecurity landscape is constantly evolving, driven by increased digitalization and new cybersecurity threats. Cybersecurity programs often fail to equip graduates with skills demanded by the workforce, particularly concerning recent developments in cybersecurity, as curriculum design is costly and labor-intensive. To address this misalignment, we present a novel Large Language Model (LLM)-based framework for automated design and analysis of cybersecurity curricula, called CurricuLLM. Our approach provides three key contributions: (1) automation of personalized curriculum design, (2) a data-driven pipeline aligned with industry demands, and (3) a comprehensive methodology for leveraging fine-tuned LLMs in curriculum development.\n  CurricuLLM utilizes a two-tier approach consisting of PreprocessLM, which standardizes input data, and ClassifyLM, which assigns course content to nine Knowledge Areas in cybersecurity. We systematically evalu- ated multiple Natural Language Processing (NLP) architectures and fine-tuning strategies, ultimately selecting the Bidirectional Encoder Representations from Transformers (BERT) model as ClassifyLM, fine-tuned on founda- tional cybersecurity concepts and workforce competencies.\n  We are the first to validate our method with human experts who analyzed real-world cybersecurity curricula and frameworks, motivating that CurricuLLM is an efficient solution to replace labor-intensive curriculum analysis. Moreover, once course content has been classified, it can be integrated with established cybersecurity role-based weights, enabling alignment of the educational program with specific job roles, workforce categories, or general market needs. This lays the foundation for personalized, workforce-aligned cybersecurity curricula that prepare students for the evolving demands in cybersecurity.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.05022", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.05022", "abs": "https://arxiv.org/abs/2601.05022", "authors": ["Konstantinos E. Kampourakis", "Vyron Kampourakis", "Efstratios Chatzoglou", "Georgios Kambourakis", "Stefanos Gritzalis"], "title": "Knowledge-to-Data: LLM-Driven Synthesis of Structured Network Traffic for Testbed-Free IDS Evaluation", "comment": null, "summary": "Realistic, large-scale, and well-labeled cybersecurity datasets are essential for training and evaluating Intrusion Detection Systems (IDS). However, they remain difficult to obtain due to privacy constraints, data sensitivity, and the cost of building controlled collection environments such as testbeds and cyber ranges. This paper investigates whether Large Language Models (LLMs) can operate as controlled knowledge-to-data engines for generating structured synthetic network traffic datasets suitable for IDS research. We propose a methodology that combines protocol documentation, attack semantics, and explicit statistical rules to condition LLMs without fine-tuning or access to raw samples. Using the AWID3 IEEE~802.11 benchmark as a demanding case study, we generate labeled datasets with four state-of-the-art LLMs and assess fidelity through a multi-level validation framework including global similarity metrics, per-feature distribution testing, structural comparison, and cross-domain classification. Results show that, under explicit constraints, LLM-generated datasets can closely approximate the statistical and structural characteristics of real network traffic, enabling gradient-boosting classifiers to achieve F1-scores up to 0.956 when evaluated on real samples. Overall, the findings suggest that constrained LLM-driven generation can facilitate on-demand IDS experimentation, providing a testbed-free, privacy-preserving alternative that overcomes the traditional bottlenecks of physical traffic collection and manual labeling.", "AI": {"tldr": "By feeding protocol docs, attack scenarios, and statistical rules into large language models, researchers can generate realistic, labeled network traffic that rivals real data, enabling IDS training without physical testbeds or privacy risks. ", "motivation": "Lack of realistic, large\u2011scale cybersecurity datasets due to privacy, sensitivity, and infrastructure costs hampers IDS research; need a privacy\u2011preserving, on\u2011demand data generation solution.", "method": "Develop a controlled\u2011generation pipeline that inputs protocol specifications, defined attack narratives, and explicit statistical constraints into large language models; generate labeled traffic samples without fine\u2011tuning; validate outputs using global similarity, feature\u2011distribution tests, structural comparisons, and cross\u2011domain classification.", "result": "Used AWID3 IEEE 802.11 benchmark; four state\u2011of\u2011the\u2011art LLMs produced datasets whose statistical/structural properties matched real traffic closely; gradient\u2011boosting classifiers achieved F1 up to 0.956 on real test samples, demonstrating the datasets\u2019 utility.", "conclusion": "LLMs constrained by protocol docs, attack semantics, and statistical rules can synthesize realistic, labeled network traffic datasets suitable for IDS training and evaluation, eliminating the need for costly, privacy\u2011sensitive real traffic collection."}}
{"id": "2601.04378", "categories": ["cs.LG", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.04378", "abs": "https://arxiv.org/abs/2601.04378", "authors": ["Corentin Lobet", "Francesca Chiaromonte"], "title": "Aligned explanations in neural networks", "comment": null, "summary": "Feature attribution is the dominant paradigm for explaining deep neural networks. However, most existing methods only loosely reflect the model's prediction-making process, thereby merely white-painting the black box. We argue that explanatory alignment is a key aspect of trustworthiness in prediction tasks: explanations must be directly linked to predictions, rather than serving as post-hoc rationalizations. We present model readability as a design principle enabling alignment, and PiNets as a modeling framework to pursue it in a deep learning context. PiNets are pseudo-linear networks that produce instance-wise linear predictions in an arbitrary feature space, making them linearly readable. We illustrate their use on image classification and segmentation tasks, demonstrating how PiNets produce explanations that are faithful across multiple criteria in addition to alignment.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.05057", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.05057", "abs": "https://arxiv.org/abs/2601.05057", "authors": ["Kartik Ramkrishnan", "Stephen McCamant", "Antonia Zhai", "Pen-Chung Yew"], "title": "Supporting Secured Integration of Microarchitectural Defenses", "comment": null, "summary": "There has been a plethora of microarchitectural-level attacks leading to many proposed countermeasures. This has created an unexpected and unaddressed security issue where naive integration of those defenses can potentially lead to security vulnerabilities. This occurs when one defense changes an aspect of a microarchitecture that is crucial for the security of another defense. We refer to this problem as a microarchitectural defense assumption violation} (MDAV).\n  We propose a two-step methodology to screen for potential MDAVs in the early-stage of integration. The first step is to design and integrate a composed model, guided by bounded model checking of security properties. The second step is to implement the model concretely on a simulator and to evaluate with simulated attacks. As a contribution supporting the first step, we propose an event-based modeling framework, called Maestro, for testing and evaluating microarchitectural models with integrated defenses. In our evaluation, Maestro reveals MDAVs (8), supports compact expression (~15x Alloy LoC ratio), enables semantic composability and eliminates performance degradations (>100x).\n  As a contribution supporting the second step, we use an event-based simulator (GEM5) for investigating integrated microarchitectural defenses. We show that a covert channel attack is possible on a naively integrated implementation of some state-of-the-art defenses, and a repaired implementation using our integration methodology is resilient to the attack.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u4e24\u6b65\u81ea\u52a8\u5316\u65b9\u6cd5\uff1a\u5148\u7528Maestro\u6846\u67b6\u6784\u5efa\u5408\u6210\u6a21\u578b\u5e76\u8fdb\u884c\u6a21\u578b\u68c0\u67e5\uff0c\u518d\u5728GEM5\u4e0a\u5b9e\u73b0\u5e76\u8bc4\u4f30\u9632\u5fa1\u7ec4\u5408\uff0c\u6210\u529f\u68c0\u6d4b\u5e76\u4fee\u590d\u4e86\u591a\u9879\u9690\u853d\u901a\u9053\u653b\u51fb\u3002", "motivation": "\u4f17\u591a\u5fae\u67b6\u6784\u7ea7\u653b\u51fb\u4e0e\u9632\u5fa1\u65b9\u6848\u5b58\u5728\u4e92\u76f8\u7834\u574f\u7684\u5b89\u5168\u9690\u60a3\uff0c\u7f3a\u4e4f\u7edf\u4e00\u8bc4\u4f30\u673a\u5236\uff0c\u5bfc\u81f4\u9632\u5fa1\u96c6\u6210\u540e\u6f5c\u5728\u6f0f\u6d1e\u3002", "method": "\u9996\u5148\u4f7f\u7528\u8fb9\u754c\u6a21\u578b\u68c0\u67e5\u8bbe\u8ba1\u5408\u6210\u6a21\u578b\uff0c\u968f\u540e\u5728GEM5\u6a21\u62df\u5668\u4e0a\u5b9e\u73b0\u5e76\u9a8c\u8bc1\u653b\u9632\u6548\u679c\uff0c\u914d\u5408Maestro\u4e8b\u4ef6\u5efa\u6a21\u652f\u6301\u5feb\u901f\u8bc4\u4f30\u3002", "result": "\u53d1\u73b08\u4e2aMDAV\u6837\u672c\uff1bMaestro\u6027\u80fd\u63d0\u5347\u8d85100\u500d\uff1b\u4f7f\u7528\u65b9\u6cd5\u7684\u4fee\u590d\u5b9e\u73b0\u5bf9Covert Channel\u653b\u51fb\u7684\u5b8c\u6574\u9632\u5fa1\u3002", "conclusion": "\u63d0\u51fa\u4e00\u79cd\u4e24\u6b65\u65b9\u6cd5\u6765\u68c0\u6d4b\u5e76\u907f\u514d\u5fae\u67b6\u6784\u9632\u5fa1\u5047\u8bbe\u8fdd\u89c4\uff08MDAV\uff09\uff0c\u5e76\u901a\u8fc7Maestro\u6846\u67b6\u5b9e\u73b0\u6709\u6548\u7684\u96c6\u6210\u4e0e\u653b\u51fb\u8bc4\u4f30\u3002"}}
{"id": "2601.05150", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.05150", "abs": "https://arxiv.org/abs/2601.05150", "authors": ["Wonwoo Choi", "Minjae Seo", "Minkyoo Song", "Hwanjo Heo", "Seungwon Shin", "Myoungsung You"], "title": "$PC^2$: Politically Controversial Content Generation via Jailbreaking Attacks on GPT-based Text-to-Image Models", "comment": null, "summary": "The rapid evolution of text-to-image (T2I) models has enabled high-fidelity visual synthesis on a global scale. However, these advancements have introduced significant security risks, particularly regarding the generation of harmful content. Politically harmful content, such as fabricated depictions of public figures, poses severe threats when weaponized for fake news or propaganda. Despite its criticality, the robustness of current T2I safety filters against such politically motivated adversarial prompting remains underexplored. In response, we propose $PC^2$, the first black-box political jailbreaking framework for T2I models. It exploits a novel vulnerability where safety filters evaluate political sensitivity based on linguistic context. $PC^2$ operates through: (1) Identity-Preserving Descriptive Mapping to obfuscate sensitive keywords into neutral descriptions, and (2) Geopolitically Distal Translation to map these descriptions into fragmented, low-sensitivity languages. This strategy prevents filters from constructing toxic relationships between political entities within prompts, effectively bypassing detection. We construct a benchmark of 240 politically sensitive prompts involving 36 public figures. Evaluation on commercial T2I models, specifically GPT-series, shows that while all original prompts are blocked, $PC^2$ achieves attack success rates of up to 86%.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04411", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04411", "abs": "https://arxiv.org/abs/2601.04411", "authors": ["Ali Rad", "Khashayar Filom", "Darioush Keivan", "Peyman Mohajerin Esfahani", "Ehsan Kamalinejad"], "title": "Rate or Fate? RLV$^\\varepsilon$R: Reinforcement Learning with Verifiable Noisy Rewards", "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) is a simple but powerful paradigm for training LLMs: sample a completion, verify it, and update. In practice, however, the verifier is almost never clean--unit tests probe only limited corner cases; human and synthetic labels are imperfect; and LLM judges (e.g., RLAIF) are noisy and can be exploited--and this problem worsens on harder domains (especially coding) where tests are sparse and increasingly model-generated. We ask a pragmatic question: does the verification noise merely slow down the learning (rate), or can it flip the outcome (fate)?\n  To address this, we develop an analytically tractable multi-armed bandit view of RLVR dynamics, instantiated with GRPO and validated in controlled experiments. Modeling false positives and false negatives and grouping completions into recurring reasoning modes yields a replicator-style (natural-selection) flow on the probability simplex. The dynamics decouples into within-correct-mode competition and a one-dimensional evolution for the mass on incorrect modes, whose drift is determined solely by Youden's index J=TPR-FPR. This yields a sharp phase transition: when J>0, the incorrect mass is driven toward extinction (learning); when J=0, the process is neutral; and when J<0, incorrect modes amplify until they dominate (anti-learning and collapse). In the learning regime J>0, noise primarily rescales convergence time (\"rate, not fate\"). Experiments on verifiable programming tasks under synthetic noise reproduce the predicted J=0 boundary. Beyond noise, the framework offers a general lens for analyzing RLVR stability, convergence, and algorithmic interventions.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u591a\u81c2\u8d4c\u535a\u673a\u6a21\u578b\u4e0eYouden\u6307\u6570\u63ed\u793a\u4e86\u5956\u52b1\u9a8c\u8bc1\u566a\u58f0\u7684\u5173\u952e\u5f71\u54cd\uff1a\u82e5\u68c0\u6d4b\u51c6\u786e\u5ea6\uff08J\uff09\u5927\u4e8e0\uff0c\u9519\u8bef\u6a21\u5f0f\u4f1a\u88ab\u6d88\u706d\uff1b\u82e5\u5c0f\u4e8e0\uff0c\u5219\u5bfc\u81f4\u9519\u8bef\u6a21\u5f0f\u4e3b\u5bfc\u3002\u566a\u58f0\u5728\u5b66\u4e60\u6709\u6548\u65f6\u4ec5\u964d\u4f4e\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u5956\u52b1\u503c\u7684\u53ef\u9a8c\u8bc1\u6027\u91cd\u8981\uff0c\u4f46\u5b9e\u9645\u68c0\u6d4b\u5668\u5f80\u5f80\u4e0d\u5e72\u51c0\uff0c\u5bfc\u81f4\u5b66\u4e60\u8fc7\u7a0b\u53d7\u566a\u58f0\u5f71\u54cd\uff0c\u9700\u8981\u7814\u7a76\u566a\u58f0\u5bf9\u5b66\u4e60\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "method": "\u5c06RLVR\u89c6\u4f5c\u53ef\u5206\u6790\u7684\u591a\u81c2\u8d4c\u535a\u673a\u6a21\u578b\uff0c\u91c7\u7528GRPO\u7b97\u6cd5\u5e76\u901a\u8fc7\u7fa4\u7ec4\u5316\u63a8\u7406\u6a21\u5f0f\u5f97\u5230\u590d\u5236\u8005\u5f0f\u52a8\u529b\u5b66\uff0c\u5229\u7528Youden\u6307\u6570J\u6765\u5224\u5b9a\u4e0d\u6b63\u786e\u6a21\u5f0f\u7684\u6d41\u884c\u8d8b\u52bf\u3002", "result": "\u53d1\u73b0\u4e00\u4e2a\u6e05\u6670\u7684\u76f8\u4f4d\u9608\u503c\uff1aJ>0\u65f6\u9519\u8bef\u6a21\u5f0f\u88ab\u6d88\u706d\uff0c\u5b9e\u73b0\u5b66\u4e60\uff1bJ=0\u65f6\u4fdd\u6301\u4e2d\u6027\uff1bJ<0\u65f6\u9519\u8bef\u6a21\u5f0f\u5360\u4f18\u52bf\u5bfc\u81f4\u201c\u53cd\u5b66\u4e60\u201d\u3002\u5728\u5b66\u4e60\u533a\u95f4\u5185\u566a\u58f0\u53ea\u51cf\u6162\u6536\u655b\u901f\u5ea6\u800c\u4e0d\u6539\u53d8\u6700\u7ec8\u65b9\u5411\u3002", "conclusion": "\u566a\u58f0\u5bf9RLVR\u7684\u5f71\u54cd\u53ef\u89c6\u4f5c\u901f\u7387\u95ee\u9898\u3002\u8be5\u6846\u67b6\u4e3a\u5206\u6790RLVR\u7684\u7a33\u5b9a\u6027\u4e0e\u6536\u655b\u63d0\u4f9b\u4e86\u901a\u7528\u89c6\u89d2\uff0c\u5e76\u4e3a\u7b97\u6cd5\u6539\u8fdb\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2601.05180", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.05180", "abs": "https://arxiv.org/abs/2601.05180", "authors": ["\u00c0lex Miranda-Pascual", "Javier Parra-Arnau", "Thorsten Strufe"], "title": "The Adverse Effects of Omitting Records in Differential Privacy: How Sampling and Suppression Degrade the Privacy--Utility Tradeoff (Long Version)", "comment": null, "summary": "Sampling is renowned for its privacy amplification in differential privacy (DP), and is often assumed to improve the utility of a DP mechanism by allowing a noise reduction. In this paper, we further show that this last assumption is flawed: When measuring utility at equal privacy levels, sampling as preprocessing consistently yields penalties due to utility loss from omitting records over all canonical DP mechanisms -- Laplace, Gaussian, exponential, and report noisy max -- , as well as recent applications of sampling, such as clustering.\n  Extending this analysis, we investigate suppression as a generalized method of choosing, or omitting, records. Developing a theoretical analysis of this technique, we derive privacy bounds for arbitrary suppression strategies under unbounded approximate DP. We find that our tested suppression strategy also fails to improve the privacy--utility tradeoff. Surprisingly, uniform sampling emerges as one of the best suppression methods -- despite its still degrading effect. Our results call into question common preprocessing assumptions in DP practice.", "AI": {"tldr": "\u7814\u7a76\u4e86\u91c7\u6837\u548c\u6291\u5236\u5bf9\u5dee\u5206\u9690\u79c1\u673a\u5236\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5b83\u4eec\u5e76\u4e0d\u80fd\u63d0\u5347\u6548\u7528\uff0c\u751a\u81f3\u4f1a\u964d\u4f4e\uff1b\u5747\u5300\u91c7\u6837\u8868\u73b0\u76f8\u5bf9\u6700\u597d\u3002", "motivation": "\u901a\u8fc7\u8bc4\u4f30\u91c7\u6837\u4f5c\u4e3a\u9884\u5904\u7406\u5728LP\u4e2d\u8bf7\u6295\u3002", "method": "\u5bf9\u7ecf\u5178DP\u673a\u5236\uff08Laplace\u3001Gaussian\u3001exponential\u3001report noisy max\uff09\u8fdb\u884c\u7406\u8bba\u4e0e\u5b9e\u9a8c\u5206\u6790\uff0c\u5e76\u901a\u8fc7\u4e00\u822c\u5316\u6291\u5236\u65b9\u6cd5\u63a8\u5bfcunbounded approximate DP\u7684\u9690\u79c1\u754c\u9650\u3002", "result": "\u8bc1\u5b9e\u91c7\u6837\u548c\u6291\u5236\u5747\u672a\u6539\u5584\u9690\u79c1-\u6548\u7528\u5e73\u8861\uff0c\u5747\u5300\u91c7\u6837\u7684\u8868\u73b0\u6700\u4f18\u4f46\u4ecd\u964d\u4f4e\u6548\u7528\u3002", "conclusion": "\u91c7\u6837\u5e76\u4e0d\u80fd\u63d0\u5347\u5dee\u5206\u9690\u79c1\u673a\u5236\u7684\u6548\u7528\uff0c\u5b83\u4ee5\u66f4\u9ad8\u7684\u9690\u79c1\u4fdd\u969c\u4e0b\u5bfc\u81f4\u5b9e\u7528\u6027\u4e0b\u964d\uff1b\u5728\u4e0d\u540c\u62bd\u6837\u7b56\u7565\u4e2d\uff0c\u5747\u5300\u91c7\u6837\u8868\u73b0\u6700\u4f18\uff0c\u4f46\u4ecd\u4e0d\u6539\u5584\u9690\u79c1\u6548\u7528\u6743\u8861\u3002"}}
{"id": "2601.04413", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04413", "abs": "https://arxiv.org/abs/2601.04413", "authors": ["Nausherwan Malik", "Zubair Khalid", "Muhammad Faryad"], "title": "Distribution-Guided and Constrained Quantum Machine Unlearning", "comment": "8 pages", "summary": "Machine unlearning aims to remove the influence of specific training data from a learned model without full retraining. While recent work has begun to explore unlearning in quantum machine learning, existing approaches largely rely on fixed, uniform target distributions and do not explicitly control the trade-off between forgetting and retained model behaviour. In this work, we propose a distribution-guided framework for class-level quantum machine unlearning that treats unlearning as a constrained optimization problem. Our method introduces a tunable target distribution derived from model similarity statistics, decoupling the suppression of forgotten-class confidence from assumptions about redistribution among retained classes. We further incorporate an anchor-based preservation constraint that explicitly maintains predictive behaviour on selected retained data, yielding a controlled optimization trajectory that limits deviation from the original model. We evaluate the approach on variational quantum classifiers trained on the Iris and Covertype datasets. Results demonstrate sharp suppression of forgotten-class confidence, minimal degradation of retained-class performance, and closer alignment with the gold retrained model baselines compared to uniform-target unlearning. These findings highlight the importance of target design and constraint-based formulations for reliable and interpretable quantum machine unlearning.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u5206\u5e03\u5f15\u5bfc\u4e14\u5e26\u951a\u70b9\u7ea6\u675f\u7684\u91cf\u5b50\u672a\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u8868\u73b0\u7684\u540c\u65f6\u663e\u8457\u524a\u5f31\u9057\u5fd8\u7c7b\u522b\uff0c\u53ef\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5747\u5300\u76ee\u6807\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u672a\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u91c7\u7528\u56fa\u5b9a\u4e14\u5747\u5300\u7684\u76ee\u6807\u5206\u5e03\uff0c\u96be\u4ee5\u663e\u5f0f\u5e73\u8861\u9057\u5fd8\u4e0e\u6a21\u578b\u4fdd\u7559\u6027\u80fd\uff0c\u5bfc\u81f4\u5bf9\u7279\u5b9a\u8bad\u7ec3\u6837\u672c\u7684\u5904\u7406\u4e0d\u591f\u7075\u6d3b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5206\u5e03\u5f15\u5bfc\u7684\u7c7b\u7ea7\u91cf\u5b50\u672a\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u672a\u5b66\u4e60\u89c6\u4e3a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u3002\u901a\u8fc7\u6a21\u578b\u76f8\u4f3c\u6027\u7edf\u8ba1\u5f97\u5230\u53ef\u8c03\u76ee\u6807\u5206\u5e03\uff0c\u89e3\u8026\u5931\u53bb\u7684\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u4e0e\u5176\u5728\u4fdd\u7559\u7c7b\u522b\u95f4\u7684\u518d\u5206\u5e03\uff0c\u5e76\u52a0\u5165\u951a\u70b9\u7ea6\u675f\u4fdd\u6301\u9009\u5b9a\u4fdd\u7559\u6570\u636e\u7684\u9884\u6d4b\u884c\u4e3a\uff0c\u4ece\u800c\u5b9e\u73b0\u53d7\u63a7\u7684\u4f18\u5316\u8f68\u8ff9\u3002", "result": "\u5728Iris\u548cCovertype\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u663e\u793a\u5bf9\u9057\u5fd8\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u7684\u6291\u5236\u660e\u663e\uff0c\u4fdd\u7559\u7c7b\u522b\u6027\u80fd\u964d\u89e3\u6700\u5c0f\uff0c\u5e76\u4e14\u76f8\u8f83\u4e8e\u5747\u5300\u76ee\u6807\u672a\u5b66\u4e60\u65b9\u6cd5\uff0c\u66f4\u8d34\u8fd1\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7684\u57fa\u51c6\u3002", "conclusion": "\u76ee\u6807\u8bbe\u8ba1\u4e0e\u57fa\u4e8e\u7ea6\u675f\u7684\u6c42\u89e3\u5f62\u5f0f\u662f\u5b9e\u73b0\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\u7684\u91cf\u5b50\u673a\u5668\u672a\u5b66\u4e60\u7684\u5173\u952e\u3002"}}
{"id": "2601.04447", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04447", "abs": "https://arxiv.org/abs/2601.04447", "authors": ["Gal Fybish", "Teo Susnjak"], "title": "When Predictions Shape Reality: A Socio-Technical Synthesis of Performative Predictions in Machine Learning", "comment": null, "summary": "Machine learning models are increasingly used in high-stakes domains where their predictions can actively shape the environments in which they operate, a phenomenon known as performative prediction. This dynamic, in which the deployment of the model influences the very outcome it seeks to predict, can lead to unintended consequences, including feedback loops, performance issues, and significant societal risks. While the literature in the field has grown rapidly in recent years, a socio-technical synthesis that systemises the phenomenon concepts and provides practical guidance has been lacking. This Systematisation of Knowledge (SoK) addresses this gap by providing a comprehensive review of the literature on performative predictions. We provide an overview of the primary mechanisms through which performativity manifests, present a typology of associated risks, and survey the proposed solutions offered in the literature. Our primary contribution is the ``Performative Strength vs. Impact Matrix\" assessment framework. This practical tool is designed to help practitioners assess the potential influence and severity of performativity on their deployed predictive models and select the appropriate level of algorithmic or human intervention.", "AI": {"tldr": "\u603b\u7ed3\u4e86\u8868\u73b0\u6027\u9884\u6d4b\u7684\u5371\u5bb3\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\uff0c\u5e2e\u52a9\u5b9e\u8df5\u8005\u6709\u6548\u7ba1\u7406\u6a21\u578b\u7684\u81ea\u6211\u5f71\u54cd\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u9886\u57df\u4f7f\u7528\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u88ab\u90e8\u7f72\u540e\u4f1a\u5f71\u54cd\u5176\u9884\u6d4b\u7ed3\u679c\uff0c\u5f62\u6210\u53cd\u9988\u5faa\u73af\u4e0e\u4e0d\u53ef\u9884\u89c1\u7684\u540e\u679c\uff0c\u6587\u732e\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u68b3\u7406\u548c\u5b9e\u7528\u6307\u5bfc\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5316\u7efc\u8ff0\uff08SoK\uff09\u5206\u6790\u73b0\u6709\u6587\u732e\uff0c\u68b3\u7406\u8868\u73b0\u6027\u9884\u6d4b\u7684\u4e3b\u8981\u673a\u5236\u3001\u98ce\u9669\u7c7b\u578b\u548c\u5df2\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6784\u5efa\u6846\u67b6\u4e0e\u8bc4\u4f30\u5de5\u5177\u3002", "result": "\u5b8c\u6210\u4e86\u6587\u732e\u7efc\u8ff0\uff0c\u5f62\u6210\u4e86\u8868\u73b0\u6027\u9884\u6d4b\u7684\u673a\u5236\u4e0e\u98ce\u9669\u5206\u7c7b\uff0c\u5e76\u63d0\u51fa\u4e86\u53ef\u64cd\u4f5c\u7684\u8bc4\u4f30\u77e9\u9635\u548c\u5b9e\u7528\u5efa\u8bae\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u00a0Performative\u00a0Strength\u00a0vs. Impact\u00a0Matrix\uff0c\u5e2e\u52a9\u4ece\u4e1a\u8005\u8bc4\u4f30\u90e8\u7f72\u6a21\u578b\u53ef\u80fd\u4ea7\u751f\u7684\u8868\u73b0\u6027\u5f71\u54cd\u4e0e\u4e25\u91cd\u6027\uff0c\u5e76\u6307\u5bfc\u9009\u62e9\u76f8\u5e94\u7684\u7b97\u6cd5\u6216\u4eba\u5de5\u5e72\u9884\uff0c\u4ee5\u964d\u4f4e\u53cd\u9988\u73af\u3001\u6027\u80fd\u95ee\u9898\u53ca\u793e\u4f1a\u98ce\u9669\u3002"}}
{"id": "2601.04449", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04449", "abs": "https://arxiv.org/abs/2601.04449", "authors": ["Daniel Sierra-Botero", "Ana Molina-Taborda", "Leonardo Espinosa-Leal", "Alexander Karpenko", "Alejandro Hernandez", "Olga Lopez-Acevedo"], "title": "Explainable Admission-Level Predictive Modeling for Prolonged Hospital Stay in Elderly Populations: Challenges in Low- and Middle-Income Countries", "comment": "23 pages, 6 figures", "summary": "Prolonged length of stay (pLoS) is a significant factor associated with the risk of adverse in-hospital events. We develop and explain a predictive model for pLos using admission-level patient and hospital administrative data. The approach includes a feature selection method by selecting non-correlated features with the highest information value. The method uses features weights of evidence to select a representative within cliques from graph theory. The prognosis study analyzed the records from 120,354 hospital admissions at the Hospital Alma Mater de Antioquia between January 2017 and March 2022. After a cleaning process the dataset was split into training (67%), test (22%), and validation (11%) cohorts. A logistic regression model was trained to predict the pLoS in two classes: less than or greater than 7 days. The performance of the model was evaluated using accuracy, precision, sensitivity, specificity, and AUC-ROC metrics. The feature selection method returns nine interpretable variables, enhancing the models' transparency. In the validation cohort, the pLoS model achieved a specificity of 0.83 (95% CI, 0.82-0.84), sensitivity of 0.64 (95% CI, 0.62-0.65), accuracy of 0.76 (95% CI, 0.76-0.77), precision of 0.67 (95% CI, 0.66-0.69), and AUC-ROC of 0.82 (95% CI, 0.81-0.83). The model exhibits strong predictive performance and offers insights into the factors that influence prolonged hospital stays. This makes it a valuable tool for hospital management and for developing future intervention studies aimed at reducing pLoS.", "AI": {"tldr": "\u57fa\u4e8e\u673a\u6784\u6570\u636e\u6784\u5efa\u7684\u903b\u8f91\u56de\u5f52\u9884\u6d4b\u6a21\u578b\uff0c\u5229\u7528\u4fe1\u606f\u503c\u4e0e\u56fe\u8bba\u7279\u5f81\u7b5b\u9009\u6280\u672f\u6311\u9009\u4e5d\u4e2a\u5173\u952e\u53d8\u91cf\uff0c\u4ee5 0.82 \u7684 AUC\u2011ROC \u51c6\u786e\u9884\u6d4b\u4f4f\u9662\u65f6\u95f4\u662f\u5426\u8d85\u8fc7 7 \u5929\uff0c\u5177\u6709\u826f\u597d\u7684\u89e3\u91ca\u6027\u548c\u7ba1\u7406\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u5ef6\u957f\u4f4f\u9662\u65f6\u95f4\u4e0e\u4f4f\u9662\u671f\u95f4\u4e0d\u826f\u4e8b\u4ef6\u98ce\u9669\u76f8\u5173\uff0c\u4e9f\u9700\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u7684\u9884\u6d4b\u5de5\u5177\u4ee5\u63d0\u524d\u8bc6\u522b\u9ad8\u98ce\u9669\u75c5\u4eba\u5e76\u5236\u5b9a\u5e72\u9884\u63aa\u65bd\u3002", "method": "\u4f7f\u7528\u5165\u9662\u7ea7\u522b\u60a3\u8005\u548c\u533b\u9662\u884c\u653f\u6570\u636e\uff0c\u91c7\u7528\u4fe1\u606f\u503c\u548c\u56fe\u8bba\u5934\u90e8\u9009\u62e9\u7684\u65e0\u76f8\u5173\u7279\u5f81\u7b5b\u9009\u6cd5\uff0c\u6700\u540e\u7528\u903b\u8f91\u56de\u5f52\u6a21\u578b\u8bad\u7ec3\u4e8c\u5206\u7c7b\u6a21\u578b\uff0c\u6570\u636e\u96c6\u6309 67%/22%/11% \u5212\u5206\u4e3a\u8bad\u7ec3\u3001\u6d4b\u8bd5\u548c\u9a8c\u8bc1\u96c6\u3002", "result": "\u9a8c\u8bc1\u96c6\u4e0a\uff0c\u6a21\u578b\u7279\u5f02\u6027 0.83\u3001\u7075\u654f\u6027 0.64\u3001\u51c6\u786e\u7387 0.76\u3001\u7cbe\u786e\u7387 0.67\uff0cAUC\u2011ROC \u8fbe 0.82\u3002", "conclusion": "\u8be5\u6a21\u578b\u6210\u529f\u9884\u6d4b\u51fa\u4f4f\u9662\u65f6\u95f4\u662f\u5426\u8d85\u8fc77\u5929\uff0c\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u51c6\u786e\u7387\u3001\u7075\u654f\u5ea6\u548c\u7279\u5f02\u6027\uff0c\u5e76\u901a\u8fc7\u4e5d\u4e2a\u53ef\u89e3\u91ca\u53d8\u91cf\u63d0\u4f9b\u4e86\u5bf9\u5f71\u54cd\u4f4f\u9662\u65f6\u957f\u56e0\u7d20\u7684\u6d1e\u5bdf\uff0c\u5177\u5907\u4e34\u5e8a\u548c\u7ba1\u7406\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.04458", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04458", "abs": "https://arxiv.org/abs/2601.04458", "authors": ["Jiayi Zhang", "Conrad Borchers", "Clayton Cohn", "Namrata Srivastava", "Caitlin Snyder", "Siyuan Guo", "Ashwin T S", "Naveeduddin Mohammed", "Haley Noh", "Gautam Biswas"], "title": "Using Large Language Models to Detect Socially Shared Regulation of Collaborative Learning", "comment": "Short research paper accepted at Learning Analytics and Knowledge (LAK '26)", "summary": "The field of learning analytics has made notable strides in automating the detection of complex learning processes in multimodal data. However, most advancements have focused on individualized problem-solving instead of collaborative, open-ended problem-solving, which may offer both affordances (richer data) and challenges (low cohesion) to behavioral prediction. Here, we extend predictive models to automatically detect socially shared regulation of learning (SSRL) behaviors in collaborative computational modeling environments using embedding-based approaches. We leverage large language models (LLMs) as summarization tools to generate task-aware representations of student dialogue aligned with system logs. These summaries, combined with text-only embeddings, context-enriched embeddings, and log-derived features, were used to train predictive models. Results show that text-only embeddings often achieve stronger performance in detecting SSRL behaviors related to enactment or group dynamics (e.g., off-task behavior or requesting assistance). In contrast, contextual and multimodal features provide complementary benefits for constructs such as planning and reflection. Overall, our findings highlight the promise of embedding-based models for extending learning analytics by enabling scalable detection of SSRL behaviors, ultimately supporting real-time feedback and adaptive scaffolding in collaborative learning environments that teachers value.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u5927\u6a21\u578b\u751f\u6210\u4efb\u52a1\u6458\u8981\u5e76\u4e0e\u4e0d\u540c\u5d4c\u5165\u3001\u65e5\u5fd7\u7279\u5f81\u7ed3\u5408\uff0c\u6210\u529f\u5728\u534f\u4f5c\u5b66\u4e60\u73af\u5883\u4e2d\u68c0\u6d4bSSRL\u884c\u4e3a\uff1b\u6587\u672c\u5d4c\u5165\u64c5\u957f\u52a8\u6001\u884c\u4e3a\uff0c\u8bed\u5883\u4e0e\u591a\u6a21\u6001\u7279\u5f81\u5219\u8865\u5145\u8ba1\u5212\u53cd\u601d\u3002", "motivation": "\u5b66\u4e60\u5206\u6790\u591a\u805a\u7126\u4e2a\u4eba\u95ee\u9898\u89e3\u51b3\uff0c\u7f3a\u4e4f\u9488\u5bf9\u534f\u4f5c\u6027\u3001\u5f00\u653e\u5f0f\u95ee\u9898\u89e3\u51b3\u7684\u81ea\u52a8\u68c0\u6d4b\uff1b\u56e0\u6b64\u9700\u8981\u80fd\u591f\u5904\u7406\u534f\u4f5c\u73af\u5883\u4e2d\u4e30\u5bcc\u6570\u636e\u5e76\u6355\u6349\u4f4e\u51dd\u805a\u6027\u7684\u884c\u4e3a\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4efb\u52a1\u611f\u77e5\u6458\u8981\uff0c\u7ed3\u5408\u6587\u672c\u5d4c\u5165\u3001\u4e0a\u4e0b\u6587\u5d4c\u5165\u548c\u65e5\u5fd7\u7279\u5f81\u8bad\u7ec3\u9884\u6d4b\u6a21\u578b\uff1b\u5b9e\u9a8c\u5bf9\u6bd4\u4e0d\u540c\u5d4c\u5165\u4e0e\u591a\u6a21\u6001\u7279\u5f81\u7684\u8868\u73b0\u3002", "result": "\u6587\u672c\u5d4c\u5165\u5728\u68c0\u6d4b\u4e0e\u6267\u884c\u6216\u5c0f\u7ec4\u52a8\u6001\u76f8\u5173\u7684SSRL\u884c\u4e3a\uff08\u5982\u504f\u79bb\u4efb\u52a1\u3001\u8bf7\u6c42\u534f\u52a9\uff09\u8868\u73b0\u66f4\u5f3a\uff1b\u4e0a\u4e0b\u6587\u4e0e\u591a\u6a21\u6001\u7279\u5f81\u5219\u5bf9\u8ba1\u5212\u4e0e\u53cd\u601d\u6784\u5efa\u5177\u6709\u4e92\u8865\u4f18\u52bf\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86\u57fa\u4e8e\u5d4c\u5165\u7684\u6a21\u578b\u5728\u534f\u4f5c\u8ba1\u7b97\u5efa\u6a21\u73af\u5883\u4e2d\u81ea\u52a8\u68c0\u6d4b\u793e\u4f1a\u5171\u4eab\u5b66\u4e60\u8c03\u8282\uff08SSRL\uff09\u884c\u4e3a\u7684\u53ef\u884c\u6027\uff0c\u5e76\u8868\u660e\u6b64\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u5b9e\u65f6\u53cd\u9988\u4e0e\u9002\u5e94\u6027\u652f\u67b6\u3002"}}
{"id": "2601.04480", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04480", "abs": "https://arxiv.org/abs/2601.04480", "authors": ["Wes Gurnee", "Emmanuel Ameisen", "Isaac Kauvar", "Julius Tarng", "Adam Pearce", "Chris Olah", "Joshua Batson"], "title": "When Models Manipulate Manifolds: The Geometry of a Counting Task", "comment": null, "summary": "Language models can perceive visual properties of text despite receiving only sequences of tokens-we mechanistically investigate how Claude 3.5 Haiku accomplishes one such task: linebreaking in fixed-width text. We find that character counts are represented on low-dimensional curved manifolds discretized by sparse feature families, analogous to biological place cells. Accurate predictions emerge from a sequence of geometric transformations: token lengths are accumulated into character count manifolds, attention heads twist these manifolds to estimate distance to the line boundary, and the decision to break the line is enabled by arranging estimates orthogonally to create a linear decision boundary. We validate our findings through causal interventions and discover visual illusions--character sequences that hijack the counting mechanism. Our work demonstrates the rich sensory processing of early layers, the intricacy of attention algorithms, and the importance of combining feature-based and geometric views of interpretability.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u529b\u5b66\u65b9\u6cd5\u63ed\u793a Claude 3.5 Haiku \u5728\u56fa\u5b9a\u5bbd\u5ea6\u6587\u672c\u4e2d\u6362\u884c\u7684\u5185\u90e8\u673a\u5236\uff1a\u5b57\u7b26\u8ba1\u6570\u5728\u4f4e\u7ef4\u6d41\u5f62\u4e0a\u8868\u8fbe\uff0c\u6ce8\u610f\u529b\u5934\u626d\u66f2\u6d41\u5f62\u63a8\u65ad\u8ddd\u79bb\uff0c\u51b3\u7b56\u901a\u8fc7\u7ebf\u6027\u8fb9\u754c\u5b9e\u73b0\uff0c\u5e76\u9a8c\u8bc1\u4e86\u89c6\u89c9\u9519\u89c9\u4e0e\u56e0\u679c\u5e72\u9884\u7684\u5f71\u54cd\u3002", "motivation": "\u63a2\u7a76 Claude 3.5 Haiku \u5982\u4f55\u5728\u4ec5\u63a5\u6536 token \u5e8f\u5217\u7684\u6761\u4ef6\u4e0b\u611f\u77e5\u6587\u672c\u7684\u89c6\u89c9\u5c5e\u6027\uff0c\u5e76\u805a\u7126\u4e8e\u56fa\u5b9a\u5bbd\u5ea6\u6587\u672c\u7684\u6362\u884c\u4efb\u52a1", "method": "\u901a\u8fc7\u5bf9\u5b57\u7b26\u8ba1\u6570\u5728\u4f4e\u7ef4\u5377\u66f2\u6d41\u5f62\u4e0a\u7684\u8868\u793a\u8fdb\u884c\u529b\u5b66\u5206\u6790\uff0c\u5e76\u89c2\u5bdf\u6ce8\u610f\u529b\u5934\u5982\u4f55\u8f6c\u6362\u6b64\u6d41\u5f62\u3001\u4f30\u7b97\u8ddd\u79bb\u53ca\u5f62\u6210\u7ebf\u6027\u51b3\u7b56\u8fb9\u754c\uff1b\u968f\u540e\u5229\u7528\u56e0\u679c\u5e72\u9884\u9a8c\u8bc1\u6a21\u578b\u884c\u4e3a", "result": "\u53d1\u73b0\u5b57\u7b26\u8ba1\u6570\u6620\u5c04\u4e3a\u79bb\u6563\u7a00\u758f\u7279\u5f81\u65cf\u7684\u4f4e\u7ef4\u6d41\u5f62\uff0c\u6ce8\u610f\u529b\u5934\u5bf9\u6d41\u5f62\u8fdb\u884c\u626d\u66f2\u4ee5\u4f30\u8ba1\u5230\u884c\u5c3e\u8ddd\u79bb\uff0c\u6700\u7ec8\u901a\u8fc7\u6b63\u4ea4\u6392\u5217\u5f97\u5230\u7ebf\u6027\u51b3\u7b56\u8fb9\u754c\uff1b\u540c\u65f6\u53d1\u73b0\u5b57\u7b26\u5e8f\u5217\u53ef\u8bf1\u53d1\u89c6\u89c9\u9519\u89c9\uff0c\u5e72\u6270\u8ba1\u6570\u673a\u5236\uff0c\u9a8c\u8bc1\u4e86\u65e9\u671f\u5c42\u7684\u611f\u77e5\u529f\u80fd\u548c\u6ce8\u610f\u529b\u7b97\u6cd5\u7684\u590d\u6742\u6027", "conclusion": "\u6587\u672c\u6362\u884c\u53ef\u7531\u5b57\u7b26\u8ba1\u6570\u6d41\u5f62\u3001\u51e0\u4f55\u53d8\u6362\u4e0e\u7ebf\u6027\u51b3\u7b56\u5171\u540c\u5b9e\u73b0\uff0c\u4f53\u73b0\u4e86\u6a21\u578b\u5728\u65e9\u5c42\u7684\u4e30\u5bcc\u611f\u77e5\u4e0e\u6ce8\u610f\u529b\u5904\u7406\uff0c\u5f3a\u8c03\u5c06\u7279\u5f81\u4e0e\u51e0\u4f55\u89c6\u89d2\u7ed3\u5408\u5bf9\u4e8e\u89e3\u91ca\u6027\u7684\u91cd\u8981\u6027"}}
{"id": "2601.04498", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.04498", "abs": "https://arxiv.org/abs/2601.04498", "authors": ["Yinghao Tang", "Xueding Liu", "Boyuan Zhang", "Tingfeng Lan", "Yupeng Xie", "Jiale Lao", "Yiyao Wang", "Haoxuan Li", "Tingting Gao", "Bo Pan", "Luoxuan Weng", "Xiuqi Huang", "Minfeng Zhu", "Yingchaojie Feng", "Yuyu Luo", "Wei Chen"], "title": "IGenBench: Benchmarking the Reliability of Text-to-Infographic Generation", "comment": null, "summary": "Infographics are composite visual artifacts that combine data visualizations with textual and illustrative elements to communicate information. While recent text-to-image (T2I) models can generate aesthetically appealing images, their reliability in generating infographics remains unclear. Generated infographics may appear correct at first glance but contain easily overlooked issues, such as distorted data encoding or incorrect textual content. We present IGENBENCH, the first benchmark for evaluating the reliability of text-to-infographic generation, comprising 600 curated test cases spanning 30 infographic types. We design an automated evaluation framework that decomposes reliability verification into atomic yes/no questions based on a taxonomy of 10 question types. We employ multimodal large language models (MLLMs) to verify each question, yielding question-level accuracy (Q-ACC) and infographic-level accuracy (I-ACC). We comprehensively evaluate 10 state-of-the-art T2I models on IGENBENCH. Our systematic analysis reveals key insights for future model development: (i) a three-tier performance hierarchy with the top model achieving Q-ACC of 0.90 but I-ACC of only 0.49; (ii) data-related dimensions emerging as universal bottlenecks (e.g., Data Completeness: 0.21); and (iii) the challenge of achieving end-to-end correctness across all models. We release IGENBENCH at https://igen-bench.vercel.app/.", "AI": {"tldr": "\u672c\u6587\u521b\u5efa\u4e86 IGENBENCH \u57fa\u51c6\uff0c\u7528\u81ea\u52a8\u539f\u5b50\u95ee\u7b54\u65b9\u5f0f\u8bc4\u4f30\u6587\u672c-\u4fe1\u606f\u56fe\u751f\u6210\u7684\u53ef\u9760\u6027\uff0c\u5bf9 10 \u5927\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u6d4b\u8bc4\uff0c\u63ed\u793a\u5f53\u524d\u6280\u672f\u7684\u4e3b\u8981\u77ed\u677f\u4e0e\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u5c3d\u7ba1\u6587\u672c\u751f\u6210\u56fe\u50cf\u6a21\u578b\u5df2\u80fd\u4ea7\u751f\u89c6\u89c9\u4e0a\u4ee4\u4eba\u6ee1\u610f\u7684\u56fe\u50cf\uff0c\u4f46\u5728\u751f\u6210\u4fe1\u606f\u56fe\u65f6\u5f80\u5f80\u5305\u542b\u96be\u4ee5\u5bdf\u89c9\u7684\u9519\u8bef\uff08\u6570\u636e\u5931\u771f\u3001\u6587\u672c\u9519\u8bef\u7b49\uff09\uff0c\u7f3a\u4e4f\u7edf\u4e00\u8bc4\u6d4b\u624b\u6bb5\uff0c\u9650\u5236\u4e86\u6a21\u578b\u4e0e\u5e94\u7528\u7684\u6539\u8fdb\u3002", "method": "\u6784\u5efa 600 \u6761\u7cbe\u9009 30 \u79cd\u4fe1\u606f\u56fe\u6d4b\u8bd5\u6848\u4f8b\uff1b\u91c7\u7528 10 \u7c7b\u95ee\u9898\u7684\u539f\u5b50\u662f\u975e\u95ee\u7b54\u5f62\u5f0f\uff1b\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u9010\u4e00\u9a8c\u8bc1\u6bcf\u4e2a\u95ee\u9898\uff0c\u4ece\u800c\u5f97\u5230 Q-ACC \u4e0e I-ACC \u4e24\u7ea7\u51c6\u786e\u7387\uff1b\u5bf9 10 \u5bb6\u9876\u5c16\u6587\u672c-\u56fe\u50cf\u6a21\u578b\u8fdb\u884c\u8bc4\u6d4b\u3002", "result": "\u5bf9 10 \u7cfb\u7edf\u6a21\u578b\u8bc4\u6d4b\u8868\u660e\uff1a\u5b58\u5728\u4e09\u5c42\u6027\u80fd\u7b49\u7ea7\uff1b\u6570\u636e\u76f8\u5173\u7ef4\u5ea6\u666e\u904d\u662f\u74f6\u9888\uff08\u4f8b\u5982\u6570\u636e\u5b8c\u6574\u5ea6\u4ec5 0.21\uff09\uff1b\u5355\u4e2a\u6a21\u578b\u65e0\u6cd5\u5728\u6240\u6709\u7ef4\u5ea6\u4e0a\u5b9e\u73b0\u7aef\u5230\u7aef\u6b63\u786e\u3002", "conclusion": "IGENBENCH\u63d0\u51fa\u4e86\u8861\u91cf\u6587\u672c\u81f3\u4fe1\u606f\u56fe\u53ef\u9760\u6027\u7684\u57fa\u51c6\uff0c\u5c55\u793a\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6587\u672c-\u56fe\u50cf\u6a21\u578b\u4e5f\u4ec5\u5728\u6570\u636e\u7f16\u7801\u548c\u6587\u672c\u51c6\u786e\u6027\u4e0a\u8fbe\u4e0d\u5230\u5b8c\u7f8e\u8868\u73b0\uff1b\u6700\u9ad8\u6a21\u578b\u7684 Q-ACC 0.90 \u4f46 I-ACC \u4ec5 0.49\uff0c\u8868\u660e\u6574\u4f53\u4e00\u81f4\u6027\u4ecd\u662f\u74f6\u9888\u3002"}}
{"id": "2601.04506", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.04506", "abs": "https://arxiv.org/abs/2601.04506", "authors": ["Fang Wu", "Zhengyuan Zhou", "Shuting Jin", "Xiangxiang Zeng", "Jure Leskovec", "Jinbo Xu"], "title": "Surface-based Molecular Design with Multi-modal Flow Matching", "comment": null, "summary": "Therapeutic peptides show promise in targeting previously undruggable binding sites, with recent advancements in deep generative models enabling full-atom peptide co-design for specific protein receptors. However, the critical role of molecular surfaces in protein-protein interactions (PPIs) has been underexplored. To bridge this gap, we propose an omni-design peptides generation paradigm, called SurfFlow, a novel surface-based generative algorithm that enables comprehensive co-design of sequence, structure, and surface for peptides. SurfFlow employs a multi-modality conditional flow matching (CFM) architecture to learn distributions of surface geometries and biochemical properties, enhancing peptide binding accuracy. Evaluated on the comprehensive PepMerge benchmark, SurfFlow consistently outperforms full-atom baselines across all metrics. These results highlight the advantages of considering molecular surfaces in de novo peptide discovery and demonstrate the potential of integrating multiple protein modalities for more effective therapeutic peptide discovery.", "AI": {"tldr": "SurfFlow\u662f\u4e00\u79cd\u57fa\u4e8e\u8868\u9762\u7684\u751f\u6210\u7b97\u6cd5\uff0c\u5229\u7528\u591a\u6a21\u6001\u5173\u7cfb\u6d41\u5339\u914d\u5728\u6b65\u5e8f\u5217\u3001\u7ed3\u6784\u4e0e\u8868\u9762\u5c42\u9762\u5171\u540c\u8bbe\u8ba1\u80bd\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u518d\u751f\u80bd\u53d1\u73b0\u4e2d\u7684\u5353\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u5df2\u53ef\u5b9e\u73b0\u5168\u539f\u5b50\u80bd\u5171\u8bbe\u8ba1\uff0c\u4f46\u5bf9\u5206\u5b50\u8868\u9762\u5728\u86cb\u767d-\u86cb\u767d\u76f8\u4e92\u4f5c\u7528\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u8981\u901a\u8fc7\u8868\u9762\u5bfc\u5411\u7684\u65b9\u6cd5\u586b\u8865\u8fd9\u4e00\u7a7a\u7f3a\u3002", "method": "SurfFlow\u91c7\u7528\u591a\u6a21\u6001\u6761\u4ef6\u6d41\u5339\u914d(CFM)\u67b6\u6784\uff0c\u5b66\u4e60\u8868\u9762\u51e0\u4f55\u4e0e\u751f\u5316\u5c5e\u6027\u7684\u5206\u5e03\uff0c\u4ee5\u6b64\u6307\u5bfc\u80bd\u5206\u5b50\u751f\u6210\u3002", "result": "\u5728PepMerge\u57fa\u51c6\u4e0a\uff0cSurfFlow\u5728\u6240\u6709\u8bc4\u4ef7\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u5168\u539f\u5b50\u57fa\u7ebf\uff0c\u9a8c\u8bc1\u4e86\u8868\u9762\u5bfc\u5411\u751f\u6210\u7684\u4f18\u52bf\u3002", "conclusion": "SurfFlow\u901a\u8fc7\u8868\u9762\u4e3a\u6838\u5fc3\u7684\u751f\u6210\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5728\u5e8f\u5217\u3001\u7ed3\u6784\u53ca\u8868\u9762\u4e09\u91cd\u5c42\u9762\u5171\u540c\u8bbe\u8ba1\u7684\u6f5c\u80fd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e0d\u540c\u6307\u6807\u4e0b\u7684\u6027\u80fd\uff0c\u8868\u660e\u8868\u9762\u4fe1\u606f\u5728\u518d\u751f\u80bd\u8bbe\u8ba1\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.04537", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04537", "abs": "https://arxiv.org/abs/2601.04537", "authors": ["Tianle Wang", "Zhongyuan Wu", "Shenghao Jin", "Hao Xu", "Wei Chen", "Ning Miao"], "title": "Not All Steps are Informative: On the Linearity of LLMs' RLVR Training", "comment": "pre-print", "summary": "Reinforcement learning with verifiable rewards (RLVR) has become a central component of large language model (LLM) post-training. Unlike supervised fine-tuning (SFT), RLVR lets an LLM generate multiple candidate solutions and reinforces those that lead to a verifiably correct final answer. However, in practice, RLVR often requires thousands of training steps to reach strong performance, incurring substantial computation largely attributed to prolonged exploration. In this work, we make a surprising observation: during RLVR, LLMs evolve in a strongly linear manner. Specifically, both model weights and model output log-probabilities exhibit strong linear correlations with RL training steps. This suggests that RLVR predominantly amplifies trends that emerge early in training, rather than continuously discovering new behaviors throughout the entire optimization trajectory. Motivated by this linearity, we investigate whether future model states can be predicted from intermediate checkpoints via extrapolation, avoiding continued expensive training. We show that Weight Extrapolation produces models with performance comparable to standard RL training while requiring significantly less computation. Moreover, Logits Extrapolation consistently outperforms continued RL training on all four benchmarks by extrapolating beyond the step range where RL training remains stable.", "AI": {"tldr": "RLVR\u8bad\u7ec3\u5448\u5f3a\u7ebf\u6027\uff0c\u5229\u7528\u6743\u91cd\u6216\u5bf9\u6570\u6982\u7387\u7684\u5916\u63a8\u80fd\u5feb\u901f\u83b7\u5f97\u51e0\u4e4e\u7b49\u540c\u6216\u66f4\u597d\u7684\u6a21\u578b\uff0c\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u3002", "motivation": "\u89e3\u51b3RLVR\u8bad\u7ec3\u9700\u8981\u6210\u5343\u4e0a\u4e07\u6b65\u3001\u8ba1\u7b97\u91cf\u5927\u3001\u63a2\u7d22\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff1b\u901a\u8fc7\u53d1\u73b0\u8bad\u7ec3\u7684\u7ebf\u6027\u89c4\u5f8b\uff0c\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u66f4\u65b0\u65b9\u5f0f\u3002", "method": "\u9996\u5148\u5728RLVR\u8bad\u7ec3\u4e2d\u89c2\u5bdf\u6a21\u578b\u6743\u91cd\u548c\u5bf9\u6570\u6982\u7387\u968f\u8bad\u7ec3\u6b65\u6570\u7684\u7ebf\u6027\u8d70\u52bf\uff0c\u7136\u540e\u6839\u636e\u4e2d\u95f4\u68c0\u67e5\u70b9\u505a\u7ebf\u6027\u5916\u63a8\uff08Weight Extrapolation \u4e0e Logits Extrapolation\uff09\uff0c\u5f97\u5230\u672a\u6765\u6a21\u578b\u72b6\u6001\u800c\u65e0\u9700\u7ee7\u7eed\u6602\u8d35\u7684RL\u8bad\u7ec3\u3002", "result": "\u6743\u91cd\u5916\u63a8\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\uff1b\u5bf9\u6570\u6982\u7387\u5916\u63a8\u5728\u56db\u4e2a\u57fa\u51c6\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u7ee7\u7eedRL\u8bad\u7ec3\uff0c\u80fd\u591f\u5728\u7814 \u8bad\u4e0d\u7a33\u5b9a\u7684\u6b65\u6570\u8303\u56f4\u4e4b\u5916\u8fdb\u884c\u9884\u6d4b\u3002", "conclusion": "RLVR\u7684\u8bad\u7ec3\u8fc7\u7a0b\u8868\u73b0\u51fa\u5f3a\u7ebf\u6027\u7279\u5f81\uff0c\u6a21\u578b\u6743\u91cd\u4e0e\u8f93\u51fa\u5bf9\u6570\u6982\u7387\u4e0e\u8bad\u7ec3\u6b65\u6570\u9ad8\u5ea6\u76f8\u5173\uff1b\u5229\u7528\u6743\u91cd\u6216\u5bf9\u6570\u6982\u7387\u7684\u5916\u63a8\u53ef\u83b7\u5f97\u4e0e\u6807\u51c6RL\u8bad\u7ec3\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u7684\u6a21\u578b\uff0c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2601.04542", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04542", "abs": "https://arxiv.org/abs/2601.04542", "authors": ["Mengmeng Zhu", "Yuxuan Sun", "Yukuan Jia", "Wei Chen", "Bo Ai", "Sheng Zhou"], "title": "Timeliness-Oriented Scheduling and Resource Allocation in Multi-Region Collaborative Perception", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Collaborative perception (CP) is a critical technology in applications like autonomous driving and smart cities. It involves the sharing and fusion of information among sensors to overcome the limitations of individual perception, such as blind spots and range limitations. However, CP faces two primary challenges. First, due to the dynamic nature of the environment, the timeliness of the transmitted information is critical to perception performance. Second, with limited computational power at the sensors and constrained wireless bandwidth, the communication volume must be carefully designed to ensure feature representations are both effective and sufficient. This work studies the dynamic scheduling problem in a multi-region CP scenario, and presents a Timeliness-Aware Multi-region Prioritized (TAMP) scheduling algorithm to trade-off perception accuracy and communication resource usage. Timeliness reflects the utility of information that decays as time elapses, which is manifested by the perception performance in CP tasks. We propose an empirical penalty function that maps the joint impact of Age of Information (AoI) and communication volume to perception performance. Aiming to minimize this timeliness-oriented penalty in the long-term, and recognizing that scheduling decisions have a cumulative effect on subsequent system states, we propose the TAMP scheduling algorithm. TAMP is a Lyapunov-based optimization policy that decomposes the long-term average objective into a per-slot prioritization problem, balancing the scheduling worth against resource cost. We validate our algorithm in both intersection and corridor scenarios with the real-world Roadside Cooperative perception (RCooper) dataset. Extensive simulations demonstrate that TAMP outperforms the best-performing baseline, achieving an Average Precision (AP) improvement of up to 27% across various configurations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65f6\u6548\u611f\u77e5\u8c03\u5ea6\u7b97\u6cd5TAMP\uff0c\u89e3\u51b3\u591a\u533a\u57df\u534f\u540c\u611f\u77e5\u4e2d\u7684\u65f6\u6548\u4e0e\u5e26\u5bbd\u5e73\u8861\u95ee\u9898\uff0c\u5728\u5b9e\u6d4b\u6570\u636e\u4e0a\u63d0\u534727% AP\u3002", "motivation": "\u63d0\u5347\u534f\u540c\u611f\u77e5\u7684\u65f6\u6548\u6027\u548c\u901a\u4fe1\u6548\u7387", "method": "\u91c7\u7528Lyapunov\u6846\u67b6\u7684TAMP\u8c03\u5ea6\u7b97\u6cd5\uff0c\u5c06\u957f\u671f\u5e73\u5747\u76ee\u6807\u62c6\u5206\u4e3a\u6bcf\u65f6\u9699\u4f18\u5148\u7ea7\u95ee\u9898", "result": "\u5728RCooper\u6570\u636e\u96c6\u7684\u4ea4\u53c9\u53e3\u4e0e\u8d70\u5eca\u573a\u666f\u4e2d\uff0cTAMP\u76f8\u8f83\u6700\u4f73\u57fa\u7ebf\u63d0\u5347\u4e86\u9ad8\u8fbe27%\u7684\u5e73\u5747\u7cbe\u5ea6", "conclusion": "TAMP\u901a\u8fc7\u5e73\u8861\u4fe1\u606f\u65f6\u6548\u4e0e\u901a\u4fe1\u6210\u672c\uff0c\u663e\u8457\u63d0\u5347\u534f\u540c\u611f\u77e5\u6027\u80fd"}}
{"id": "2601.04555", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04555", "abs": "https://arxiv.org/abs/2601.04555", "authors": ["Shogo Nakayama", "Masahiro Okuda"], "title": "Improving Semi-Supervised Contrastive Learning via Entropy-Weighted Confidence Integration of Anchor-Positive Pairs", "comment": null, "summary": "Conventional semi-supervised contrastive learning methods assign pseudo-labels only to samples whose highest predicted class probability exceeds a predefined threshold, and then perform supervised contrastive learning using those selected samples. In this study, we propose a novel loss function that estimates the confidence of each sample based on the entropy of its predicted probability distribution and applies confidence-based adaptive weighting. This approach enables pseudo-label assignment even to samples that were previously excluded from training and facilitates contrastive learning that accounts for the confidence of both anchor and positive samples in a more principled manner. Experimental results demonstrate that the proposed method improves classification accuracy and achieves more stable learning performance even under low-label conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u71b5\u7684\u7f6e\u4fe1\u5ea6\u81ea\u9002\u5e94\u52a0\u6743\u5bf9\u6bd4\u635f\u5931\uff0c\u80fd\u591f\u5728\u8f7b\u6807\u7b7e\u4e0b\u63d0\u5347\u51c6\u786e\u7387\u5e76\u7a33\u5b9a\u8bad\u7ec3\u3002", "motivation": "\u4f20\u7edf\u534a\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u53ea\u4e3a\u7f6e\u4fe1\u5ea6\u9ad8\u7684\u6837\u672c\u5206\u914d\u4f2a\u6807\u7b7e\uff0c\u5bfc\u81f4\u4e2d\u4f4e\u7f6e\u4fe1\u5ea6\u6837\u672c\u88ab\u5ffd\u7565\uff0c\u5c24\u5176\u5728\u7f3a\u6807\u7b7e\u60c5\u51b5\u4e0b\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u6837\u672c\u9884\u6d4b\u6982\u7387\u5206\u5e03\u7684\u71b5\u6765\u4f30\u8ba1\u6837\u672c\u7f6e\u4fe1\u5ea6\uff0c\u5bf9\u6837\u672c\u8fdb\u884c\u81ea\u9002\u5e94\u52a0\u6743\uff1b\u5728\u5bf9\u6bd4\u635f\u5931\u4e2d\u540c\u65f6\u8003\u8651\u951a\u70b9\u548c\u6b63\u6837\u672c\u7684\u7f6e\u4fe1\u5ea6\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u4f4e\u7f6e\u4fe1\u5ea6\u6837\u672c\u7684\u4f2a\u6807\u7b7e\u5206\u914d\u4e0e\u5bf9\u6bd4\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4f4e\u6807\u7b7e\u548c\u4f4e\u7f6e\u4fe1\u5ea6\u73af\u5883\u4e0b\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u63d0\u5347\u4e86\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u5e76\u5728\u591a\u7ec4\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u6bd4\u57fa\u7ebf\u66f4\u7a33\u5065\u7684\u5b66\u4e60\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u71b5\u7684\u81ea\u9002\u5e94\u52a0\u6743\u635f\u5931\u51fd\u6570\u80fd\u591f\u6709\u6548\u5229\u7528\u4f4e\u7f6e\u4fe1\u5ea6\u6837\u672c\uff0c\u663e\u8457\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u7387\u5e76\u5728\u4f4e\u6807\u7b7e\u6761\u4ef6\u4e0b\u4f7f\u5b66\u4e60\u8fc7\u7a0b\u66f4\u4e3a\u7a33\u5b9a\u3002"}}
{"id": "2601.04563", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.04563", "abs": "https://arxiv.org/abs/2601.04563", "authors": ["Paul Pu Liang"], "title": "A Vision for Multisensory Intelligence: Sensing, Synergy, and Science", "comment": null, "summary": "Our experience of the world is multisensory, spanning a synthesis of language, sight, sound, touch, taste, and smell. Yet, artificial intelligence has primarily advanced in digital modalities like text, vision, and audio. This paper outlines a research vision for multisensory artificial intelligence over the next decade. This new set of technologies can change how humans and AI experience and interact with one another, by connecting AI to the human senses and a rich spectrum of signals from physiological and tactile cues on the body, to physical and social signals in homes, cities, and the environment. We outline how this field must advance through three interrelated themes of sensing, science, and synergy. Firstly, research in sensing should extend how AI captures the world in richer ways beyond the digital medium. Secondly, developing a principled science for quantifying multimodal heterogeneity and interactions, developing unified modeling architectures and representations, and understanding cross-modal transfer. Finally, we present new technical challenges to learn synergy between modalities and between humans and AI, covering multisensory integration, alignment, reasoning, generation, generalization, and experience. Accompanying this vision paper are a series of projects, resources, and demos of latest advances from the Multisensory Intelligence group at the MIT Media Lab, see https://mit-mi.github.io/.", "AI": {"tldr": "\u672a\u6765\u5341\u5e74\u5c06\u901a\u8fc7\u66f4\u4e30\u5bcc\u7684\u611f\u77e5\u3001\u7edf\u4e00\u79d1\u5b66\u5efa\u6a21\u548c\u591a\u6a21\u6001\u534f\u540c\uff0c\u63a8\u52a8AI\u4e0e\u4eba\u7c7b\u591a\u611f\u5b98\u4ea4\u4e92\u7684\u9769\u547d\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u76ee\u524d\u4ec5\u805a\u7126\u6570\u7801\u6a21\u6001\uff0c\u7f3a\u4e4f\u4e0e\u4eba\u7c7b\u591a\u611f\u5b98\u878d\u901a\u7684\u80fd\u529b\uff0c\u9650\u5236\u4e86\u4eba\u673a\u4f53\u9a8c\u3002", "method": "\u652f\u6301\u591a\u6a21\u6001\u611f\u77e5\u3001\u7edf\u4e00\u5efa\u6a21\u4e0e\u8de8\u6a21\u6001\u8fc1\u79fb\u7684\u5b9e\u9a8c\u4e0e\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u8de8\u6a21\u6001\u534f\u540c\u5b66\u4e60\u3001\u63a8\u7406\u4e0e\u751f\u6210\u7b49\u6280\u672f\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u6280\u672f\u6311\u6218\u4e0e\u9879\u76ee\u8d44\u6e90\uff0c\u5c55\u793aMIT\u591a\u611f\u5b98\u667a\u80fd\u7ec4\u7684\u6700\u65b0\u5b9e\u9a8c\u548c\u6f14\u793a\uff0c\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u539f\u578b\u4e0e\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u8bba\u6587\u5c55\u671b\u4e86\u672a\u6765\u5341\u5e74\u591a\u611f\u5b98\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u4f20\u611f\u3001\u79d1\u5b66\u4e0e\u534f\u540c\u4e09\u5927\u4e3b\u9898\u5b9e\u73b0\u66f4\u4e30\u5bcc\u611f\u77e5\u4e0e\u4eba\u673a\u4ea4\u4e92\u3002"}}
{"id": "2601.04572", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04572", "abs": "https://arxiv.org/abs/2601.04572", "authors": ["Xiaowei Mao", "Huihu Ding", "Yan Lin", "Tingrui Wu", "Shengnan Guo", "Dazhuo Qiu", "Feiling Fang", "Jilin Hu", "Huaiyu Wan"], "title": "Spatial-Temporal Feedback Diffusion Guidance for Controlled Traffic Imputation", "comment": null, "summary": "Imputing missing values in spatial-temporal traffic data is essential for intelligent transportation systems. Among advanced imputation methods, score-based diffusion models have demonstrated competitive performance. These models generate data by reversing a noising process, using observed values as conditional guidance. However, existing diffusion models typically apply a uniform guidance scale across both spatial and temporal dimensions, which is inadequate for nodes with high missing data rates. Sparse observations provide insufficient conditional guidance, causing the generative process to drift toward the learned prior distribution rather than closely following the conditional observations, resulting in suboptimal imputation performance.\n  To address this, we propose FENCE, a spatial-temporal feedback diffusion guidance method designed to adaptively control guidance scales during imputation. First, FENCE introduces a dynamic feedback mechanism that adjusts the guidance scale based on the posterior likelihood approximations. The guidance scale is increased when generated values diverge from observations and reduced when alignment improves, preventing overcorrection. Second, because alignment to observations varies across nodes and denoising steps, a global guidance scale for all nodes is suboptimal. FENCE computes guidance scales at the cluster level by grouping nodes based on their attention scores, leveraging spatial-temporal correlations to provide more accurate guidance. Experimental results on real-world traffic datasets show that FENCE significantly enhances imputation accuracy.", "AI": {"tldr": "FENCE\u4f7f\u7528\u52a8\u6001\u53cd\u9988\u548c\u805a\u7c7b\u6307\u5bfc\u5c3a\u5ea6\u6539\u8fdb\u6269\u6563\u6a21\u578b\u5728\u4ea4\u901a\u6570\u636e\u7f3a\u5931\u586b\u8865\u4e2d\u7684\u7cbe\u5ea6\u3002", "motivation": "\u7f3a\u5931\u503c\u586b\u8865\u5bf9\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u6269\u6563\u6a21\u578b\u5728\u7a7a\u95f4\u4e0e\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u4f7f\u7528\u7edf\u4e00\u7684\u6307\u5bfc\u5c3a\u5ea6\uff0c\u5bfc\u81f4\u9ad8\u7f3a\u5931\u7387\u8282\u70b9\u586b\u8865\u6548\u679c\u5dee\u3002", "method": "\u63d0\u51faFENCE\uff0c\u901a\u8fc7\u52a8\u6001\u53cd\u9988\u673a\u5236\u6839\u636e\u540e\u9a8c\u4f3c\u7136\u8c03\u6574\u6307\u5bfc\u5c3a\u5ea6\uff0c\u5e76\u6309\u8282\u70b9\u805a\u7c7b\uff08\u57fa\u4e8e\u6ce8\u610f\u529b\u5206\u6570\uff09\u5728\u7a7a\u95f4-\u65f6\u95f4\u5c42\u9762\u8ba1\u7b97\u4e0d\u540c\u5c3a\u5ea6\uff1b\u5b9e\u73b0\u5bf9\u586b\u8865\u8fc7\u7a0b\u4e2d\u751f\u6210\u503c\u4e0e\u5df2\u89c2\u6d4b\u503c\u504f\u5dee\u7684\u81ea\u9002\u5e94\u6821\u6b63\u3002", "result": "\u5728\u771f\u5b9e\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u8457\u63d0\u5347\u586b\u8865\u7cbe\u5ea6\uff0c\u4f18\u4e8e\u4f20\u7edf\u7edf\u4e00\u5c3a\u5ea6\u6269\u6563\u6a21\u578b\u3002", "conclusion": "FENCE\u901a\u8fc7\u7a7a\u95f4-\u65f6\u95f4\u53cd\u9988\u6307\u5bfc\u6709\u6548\u89e3\u51b3\u9ad8\u7f3a\u5931\u7387\u8282\u70b9\u7684\u586b\u8865\u96be\u9898\uff0c\u4e3a\u4ea4\u901a\u6570\u636e\u63d2\u8865\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.04587", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04587", "abs": "https://arxiv.org/abs/2601.04587", "authors": ["Quang-Tu Pham", "Hoang-Dieu Vu", "Dinh-Dat Pham", "Hieu H. Pham"], "title": "FedKDX: Federated Learning with Negative Knowledge Distillation for Enhanced Healthcare AI Systems", "comment": null, "summary": "This paper introduces FedKDX, a federated learning framework that addresses limitations in healthcare AI through Negative Knowledge Distillation (NKD). Unlike existing approaches that focus solely on positive knowledge transfer, FedKDX captures both target and non-target information to improve model generalization in healthcare applications. The framework integrates multiple knowledge transfer techniques--including traditional knowledge distillation, contrastive learning, and NKD--within a unified architecture that maintains privacy while reducing communication costs. Through experiments on healthcare datasets (SLEEP, UCI-HAR, and PAMAP2), FedKDX demonstrates improved accuracy (up to 2.53% over state-of-the-art methods), faster convergence, and better performance on non-IID data distributions. Theoretical analysis supports NKD's contribution to addressing statistical heterogeneity in distributed healthcare data. The approach shows promise for privacy-sensitive medical applications under regulatory frameworks like HIPAA and GDPR, offering a balanced solution between performance and practical implementation requirements in decentralized healthcare settings. The code and model are available at https://github.com/phamdinhdat-ai/Fed_2024.", "AI": {"tldr": "FedKDX\uff1a\u7ed3\u5408\u8d1f\u77e5\u8bc6\u84b8\u998f\u3001\u4f20\u7edf\u84b8\u998f\u4e0e\u5bf9\u6bd4\u5b66\u4e60\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u63d0\u5347\u533b\u7597AI\u6a21\u578b\u7cbe\u5ea6\uff08+2.53%\uff09\uff0c\u52a0\u901f\u6536\u655b\uff0c\u5e76\u517c\u987e\u9690\u79c1\u4e0e\u4f4e\u901a\u4fe1\u6210\u672c\u3002", "motivation": "\u533b\u7597AI\u5728\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e0b\u53d7\u9650\u4e8e\u4fe1\u606f\u4e0d\u8db3\u3001\u6570\u636e\u5f02\u6784\u4e0e\u901a\u4fe1\u5f00\u9500\uff0c\u4ee5\u53ca\u4e25\u683c\u7684\u9690\u79c1\u6cd5\u89c4\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u591f\u5145\u5206\u6316\u6398\u6b63\u8d1f\u77e5\u8bc6\u5e76\u517c\u987e\u9690\u79c1\u4e0e\u6548\u7387\u7684\u6846\u67b6\u3002", "method": "\u5728\u7edf\u4e00\u7684\u8054\u90a6\u67b6\u6784\u4e0b\uff0cFedKDX\u540c\u65f6\u91c7\u7528\u4f20\u7edf\u77e5\u8bc6\u84b8\u998f\u3001\u5bf9\u6bd4\u5b66\u4e60\u4e0eNKD\u6280\u672f\uff0c\u6355\u83b7\u76ee\u6807\u4e0e\u975e\u76ee\u6807\u77e5\u8bc6\u3002\u5404\u5ba2\u6237\u7aef\u5bf9\u672c\u5730\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u540e\uff0c\u5c06\u538b\u7f29\u540e\u7684\u77e5\u8bc6\u5411\u4e2d\u5fc3\u670d\u52a1\u5668\u4e0a\u4f20\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u5e76\u6781\u5927\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u3002", "result": "\u5728SLEEP\u3001UCI-HAR\u4e0ePAMAP2\u533b\u7597\u6570\u636e\u96c6\u4e0a\uff0cFedKDX\u76f8\u8f83\u4e8e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u63d0\u5347\u4e86\u6700\u9ad82.53%\u7684\u51c6\u786e\u7387\uff0c\u6536\u655b\u901f\u5ea6\u66f4\u5feb\uff0c\u5e76\u5728\u975eIID\u6570\u636e\u4e0b\u8868\u73b0\u66f4\u7a33\u5065\u3002", "conclusion": "FedKDX\u901a\u8fc7\u5f15\u5165\u8d1f\u77e5\u8bc6\u84b8\u998f\uff08NKD\uff09\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u533b\u7597AI\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u7edf\u8ba1\u5f02\u6784\u6027\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6cdb\u5316\u6027\u4e0e\u7a33\u5065\u6027\uff0c\u5df2\u5728\u591a\u7ec4\u533b\u7597\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u663e\u8457\u51c6\u786e\u7387\u63d0\u5347\uff0c\u5e76\u5728\u9690\u79c1\u5b89\u5168\u4e0e\u901a\u4fe1\u6210\u672c\u65b9\u9762\u4f53\u73b0\u51fa\u53ef\u884c\u6027\u3002"}}
{"id": "2601.04592", "categories": ["cs.LG", "cs.SD", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.04592", "abs": "https://arxiv.org/abs/2601.04592", "authors": ["Joonwon Seo", "Mariana Montiel"], "title": "Density Matrix RNN (DM-RNN): A Quantum Information Theoretic Framework for Modeling Musical Context and Polyphony", "comment": "Submitted to the 10th International Conference on Mathematics and Computation in Music (MCM 2026)", "summary": "Classical Recurrent Neural Networks (RNNs) summarize musical context into a deterministic hidden state vector, imposing an information bottleneck that fails to capture the inherent ambiguity in music. We propose the Density Matrix RNN (DM-RNN), a novel theoretical architecture utilizing the Density Matrix. This allows the model to maintain a statistical ensemble of musical interpretations (a mixed state), capturing both classical probabilities and quantum coherences. We rigorously define the temporal dynamics using Quantum Channels (CPTP maps). Crucially, we detail a parameterization strategy based on the Choi-Jamiolkowski isomorphism, ensuring the learned dynamics remain physically valid (CPTP) by construction. We introduce an analytical framework using Von Neumann Entropy to quantify musical uncertainty and Quantum Mutual Information (QMI) to measure entanglement between voices. The DM-RNN provides a mathematically rigorous framework for modeling complex, ambiguous musical structures.", "AI": {"tldr": "DM\u2011RNN\u5c06RNN\u6539\u4e3a\u5bc6\u5ea6\u77e9\u9635\uff0c\u5229\u7528CPTP\u901a\u9053\u4fdd\u6301\u7269\u7406\u5408\u6cd5\u6027\uff0c\u4ee5\u91cf\u5b50\u71b5\u548c\u4e92\u4fe1\u606f\u8bc4\u4f30\u97f3\u4e50\u4e0d\u786e\u5b9a\u6027\u4e0e\u7ea0\u7f20\u3002", "motivation": "\u4f20\u7edfRNN\u7684\u5355\u4e00\u9690\u85cf\u5411\u91cf\u53d7\u4fe1\u606f\u74f6\u9888\u9650\u5236\uff0c\u65e0\u6cd5\u6355\u83b7\u97f3\u4e50\u56fa\u6709\u7684\u4e0d\u786e\u5b9a\u6027\u4e0e\u591a\u91cd\u8be0\u91ca\uff0c\u9700\u66f4\u4e30\u5bcc\u7684\u8868\u793a\u5bb9\u91cf\u3002", "method": "\u901a\u8fc7\u5c06RNN\u9690\u85cf\u72b6\u6001\u4ece\u786e\u5b9a\u6027\u5411\u91cf\u6269\u5c55\u4e3a\u5bc6\u5ea6\u77e9\u9635\uff0c\u5e76\u4f7f\u7528\u91cf\u5b50\u4fe1\u9053\uff08CPTP\uff09\u5b9a\u4e49\u65f6\u5e8f\u66f4\u65b0\uff1b\u53c2\u6570\u5316\u91c7\u7528Choi\u2011Jamiolkowski\u540c\u6784\uff0c\u4fdd\u8bc1\u5b66\u4e60\u5230\u7684\u52a8\u6001\u7269\u7406\u5408\u6cd5\u3002", "result": "\u63d0\u51faDM\u2011RNN\u540e\uff0c\u5b9e\u73b0\u4e86\u5bf9\u97f3\u4e50\u4e0d\u786e\u5b9a\u6027\u7684Von Neumann\u71b5\u91cf\u5316\u4ee5\u53ca\u58f0\u97f3\u95f4\u7ea0\u7f20\u7684\u91cf\u5b50\u4e92\u4fe1\u606f\u8bc4\u4f30\uff0c\u4e3a\u590d\u6742\u6a21\u7cca\u97f3\u4e50\u7ed3\u6784\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e25\u8c28\u6846\u67b6\u3002", "conclusion": "DM\u2011RNN\u5229\u7528\u5bc6\u5ea6\u77e9\u9635\u6355\u83b7\u97f3\u4e50\u7ed3\u6784\u4e2d\u7684\u968f\u673a\u6027\u4e0e\u76f8\u5e72\u6027\uff0c\u5f62\u6210\u53ef\u517c\u5bb9\u7ecf\u5178\u4e0e\u91cf\u5b50\u6982\u7387\u7684\u6df7\u6001\u52a8\u6001\u6a21\u578b\uff1b\u5176\u57fa\u4e8eChoi\u2011Jamiolkowski\u53c2\u6570\u5316\u4fdd\u8bc1\u52a8\u6001\u4fdd\u6301\u5b8c\u5168\u6b63\u6620\u5c04\uff08CPTP\uff09\u3002"}}
{"id": "2601.04616", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04616", "abs": "https://arxiv.org/abs/2601.04616", "authors": ["Shuhan Zhang", "Zhi Wang", "Rui Gao", "Shuang Li"], "title": "DeepHalo: A Neural Choice Model with Controllable Context Effects", "comment": null, "summary": "Modeling human decision-making is central to applications such as recommendation, preference learning, and human-AI alignment. While many classic models assume context-independent choice behavior, a large body of behavioral research shows that preferences are often influenced by the composition of the choice set itself -- a phenomenon known as the context effect or Halo effect. These effects can manifest as pairwise (first-order) or even higher-order interactions among the available alternatives. Recent models that attempt to capture such effects either focus on the featureless setting or, in the feature-based setting, rely on restrictive interaction structures or entangle interactions across all orders, which limits interpretability. In this work, we propose DeepHalo, a neural modeling framework that incorporates features while enabling explicit control over interaction order and principled interpretation of context effects. Our model enables systematic identification of interaction effects by order and serves as a universal approximator of context-dependent choice functions when specialized to a featureless setting. Experiments on synthetic and real-world datasets demonstrate strong predictive performance while providing greater transparency into the drivers of choice.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04670", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04670", "abs": "https://arxiv.org/abs/2601.04670", "authors": ["Akiyoshi Tomihari"], "title": "Learning Dynamics in RL Post-Training for Language Models", "comment": null, "summary": "Reinforcement learning (RL) post-training is a critical stage in modern language model development, playing a key role in improving alignment and reasoning ability. However, several phenomena remain poorly understood, including the reduction in output diversity. To gain a broader understanding of RL post-training, we analyze the learning dynamics of RL post-training from a perspective that has been studied in supervised learning but remains underexplored in RL. We adopt an empirical neural tangent kernel (NTK) framework and decompose the NTK into two components to characterize how RL updates propagate across training samples. Our analysis reveals that limited variability in feature representations can cause RL updates to systematically increase model confidence, providing an explanation for the commonly observed reduction in output diversity after RL post-training. Furthermore, we show that effective learning in this regime depends on rapidly shaping the classifier, which directly affects the gradient component of the NTK. Motivated by these insights, we propose classifier-first reinforcement learning (CF-RL), a simple two-stage training strategy that prioritizes classifier updates before standard RL optimization. Experimental results validate our theoretical analysis by demonstrating increased model confidence and accelerated optimization under CF-RL. Additional analysis shows that the mechanism underlying CF-RL differs from that of linear-probing-then-fine-tuning in supervised learning. Overall, our study formalizes the learning dynamics of RL post-training and motivates further analysis and improvement.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04673", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.04673", "abs": "https://arxiv.org/abs/2601.04673", "authors": ["Aurghya Maiti", "Prateek Jain"], "title": "Estimating Causal Effects in Gaussian Linear SCMs with Finite Data", "comment": "Accepted at the Workshop on Scaling Up Intervention Models at the 42nd International Conference on Machine Learning (ICML 2025)", "summary": "Estimating causal effects from observational data remains a fundamental challenge in causal inference, especially in the presence of latent confounders. This paper focuses on estimating causal effects in Gaussian Linear Structural Causal Models (GL-SCMs), which are widely used due to their analytical tractability. However, parameter estimation in GL-SCMs is often infeasible with finite data, primarily due to overparameterization. To address this, we introduce the class of Centralized Gaussian Linear SCMs (CGL-SCMs), a simplified yet expressive subclass where exogenous variables follow standardized distributions. We show that CGL-SCMs are equally expressive in terms of causal effect identifiability from observational distributions and present a novel EM-based estimation algorithm that can learn CGL-SCM parameters and estimate identifiable causal effects from finite observational samples. Our theoretical analysis is validated through experiments on synthetic data and benchmark causal graphs, demonstrating that the learned models accurately recover causal distributions.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04686", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.04686", "abs": "https://arxiv.org/abs/2601.04686", "authors": ["Oluwatosin Oseni", "Shengjie Wang", "Jun Zhu", "Micah Corah"], "title": "Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead", "comment": "RSS'25: Multi-Objective Optimization and Planning in Robotics Workshop: 5 pages, 8 figures", "summary": "Reinforcement Learning (RL) has shown remarkable success in real-world applications, particularly in robotics control. However, RL adoption remains limited due to insufficient safety guarantees. We introduce Nightmare Dreamer, a model-based Safe RL algorithm that addresses safety concerns by leveraging a learned world model to predict potential safety violations and plan actions accordingly. Nightmare Dreamer achieves nearly zero safety violations while maximizing rewards. Nightmare Dreamer outperforms model-free baselines on Safety Gymnasium tasks using only image observations, achieving nearly a 20x improvement in efficiency.", "AI": {"tldr": "Nightmare Dreamer \u901a\u8fc7\u4e16\u754c\u6a21\u578b\u9884\u5224\u5b89\u5168\u8fdd\u89c4\uff0c\u5b9e\u73b0\u96f6\u8fdd\u89c4\u4e14\u5956\u52b1\u6700\u5927\u5316\uff0c\u5728 Safety Gymnasium \u4e0a\u76f8\u8f83\u65e0\u6a21\u578b\u57fa\u7ebf\u63d0\u9ad8\u7ea620\u500d\u6548\u7387\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u5b9e\u9645\u4e16\u754c\u4e2d\u7684\u5b89\u5168\u4fdd\u969c\u4e0d\u8db3\u5bfc\u81f4\u91c7\u7528\u53d7\u9650\u3002", "method": "Nightmare Dreamer \u901a\u8fc7\u5b66\u4e60\u4e16\u754c\u6a21\u578b\u9884\u6d4b\u6f5c\u5728\u5b89\u5168\u8fdd\u89c4\u5e76\u76f8\u5e94\u89c4\u5212\u52a8\u4f5c\uff0c\u5229\u7528\u57fa\u4e8e\u6a21\u578b\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728 Safety Gymnasium \u4efb\u52a1\u4e0a\uff0c\u4ec5\u4f7f\u7528\u56fe\u50cf\u89c2\u6d4b\u5c31\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u96f6\u5b89\u5168\u8fdd\u89c4\uff0c\u540c\u65f6\u5c06\u6548\u7387\u63d0\u5347\u8fd120\u500d\uff0c\u5e76\u4f18\u4e8e\u65e0\u6a21\u578b\u57fa\u7ebf\u3002", "conclusion": "Nightmare Dreamer \u5728\u4fdd\u6301\u9ad8\u5956\u52b1\u7684\u540c\u65f6\u51e0\u4e4e\u6d88\u9664\u5b89\u5168\u8fdd\u89c4\uff0c\u5e76\u663e\u8457\u63d0\u5347\u5b66\u4e60\u6548\u7387\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u5728\u5de5\u4e1a\u673a\u5668\u4eba\u7b49\u9886\u57df\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.04690", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04690", "abs": "https://arxiv.org/abs/2601.04690", "authors": ["Mir Rayat Imtiaz Hossain", "Leo Feng", "Leonid Sigal", "Mohamed Osama Ahmed"], "title": "Do LLMs Benefit from User and Item Embeddings in Recommendation Tasks?", "comment": "Presented in Multimodal Algorithmic Reasoning Workshop at NeurIPS 2025", "summary": "Large Language Models (LLMs) have emerged as promising recommendation systems, offering novel ways to model user preferences through generative approaches. However, many existing methods often rely solely on text semantics or incorporate collaborative signals in a limited manner, typically using only user or item embeddings. These methods struggle to handle multiple item embeddings representing user history, reverting to textual semantics and neglecting richer collaborative information. In this work, we propose a simple yet effective solution that projects user and item embeddings, learned from collaborative filtering, into the LLM token space via separate lightweight projector modules. A finetuned LLM then conditions on these projected embeddings alongside textual tokens to generate recommendations. Preliminary results show that this design effectively leverages structured user-item interaction data, improves recommendation performance over text-only LLM baselines, and offers a practical path for bridging traditional recommendation systems with modern LLMs.", "AI": {"tldr": "\u901a\u8fc7\u8f7b\u91cf\u6295\u5f71\u5c06CF\u5d4c\u5165\u6620\u5c04\u5230LLM token\u7a7a\u95f4\uff0c\u7ed3\u5408\u6587\u672c\u751f\u6210\u5f0f\u63a8\u8350\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u6027\u80fd\u5e76\u6865\u63a5\u4f20\u7edfCF\u4e0eLLM\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eLLM\u7684\u63a8\u8350\u65b9\u6cd5\u5f80\u5f80\u4ec5\u4f9d\u8d56\u6587\u672c\u8bed\u4e49\u6216\u53ea\u5229\u7528\u5355\u4e00\u7528\u6237/\u7269\u54c1embedding\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u7528\u6237\u5386\u53f2\u4e2d\u7684\u591a\u7269\u54c1\u534f\u540c\u4fe1\u53f7\uff0c\u5bfc\u81f4\u534f\u540c\u4fe1\u606f\u88ab\u5ffd\u7565\u6216\u88ab\u201c\u6587\u672c\u5316\u201d\u3002", "method": "\u5148\u4f7f\u7528\u8f7b\u91cf\u7ea7\u6295\u5f71\u6a21\u5757\u5c06\u534f\u540c\u8fc7\u6ee4\u5b66\u4e60\u5230\u7684\u7528\u6237\u548c\u7269\u54c1\u5d4c\u5165\u6620\u5c04\u81f3LLM\u7684token\u7a7a\u95f4\uff0c\u7136\u540e\u5728\u5df2\u5fae\u8c03\u7684LLM\u4e2d\u5c06\u8fd9\u4e9b\u6295\u5f71\u5d4c\u5165\u4e0e\u6587\u672ctokens\u5171\u540c\u4f5c\u4e3a\u6761\u4ef6\u8f93\u5165\uff0c\u76f4\u63a5\u751f\u6210\u63a8\u8350\u5217\u8868\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u8bbe\u8ba1\u6709\u6548\u5229\u7528\u4e86\u7ed3\u6784\u5316\u7684\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u6570\u636e\uff0c\u63a8\u8350\u6548\u679c\u663e\u8457\u4f18\u4e8e\u4ec5\u4f7f\u7528\u6587\u672c\u7684LLM\u57fa\u7ebf\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6848\u901a\u8fc7\u5c06\u534f\u540c\u8fc7\u6ee4\u5f97\u5230\u7684\u7528\u6237\u4e0e\u7269\u54c1\u5d4c\u5165\u6295\u5c04\u5230LLM\u8bcd\u6807\u8bc6\u7a7a\u95f4\uff0c\u5e76\u7ed3\u5408\u6587\u672c\u4fe1\u606f\u8fdb\u884c\u751f\u6210\u5f0f\u63a8\u8350\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728\u6587\u672c\u4ec5\u4f7f\u7528\u7684LLM\u63a8\u8350\u57fa\u7ebf\u4e4b\u4e0a\u7684\u6027\u80fd\uff0c\u4e3a\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u4e0e\u73b0\u4ee3LLM\u7684\u878d\u5408\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2601.04707", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.04707", "abs": "https://arxiv.org/abs/2601.04707", "authors": ["Irfan Ullah", "Young-Koo Lee"], "title": "MQ-GNN: A Multi-Queue Pipelined Architecture for Scalable and Efficient GNN Training", "comment": null, "summary": "Graph Neural Networks (GNNs) are powerful tools for learning graph-structured data, but their scalability is hindered by inefficient mini-batch generation, data transfer bottlenecks, and costly inter-GPU synchronization. Existing training frameworks fail to overlap these stages, leading to suboptimal resource utilization. This paper proposes MQ-GNN, a multi-queue pipelined framework that maximizes training efficiency by interleaving GNN training stages and optimizing resource utilization. MQ-GNN introduces Ready-to-Update Asynchronous Consistent Model (RaCoM), which enables asynchronous gradient sharing and model updates while ensuring global consistency through adaptive periodic synchronization. Additionally, it employs global neighbor sampling with caching to reduce data transfer overhead and an adaptive queue-sizing strategy to balance computation and memory efficiency. Experiments on four large-scale datasets and ten baseline models demonstrate that MQ-GNN achieves up to \\boldmath $\\bm{4.6\\,\\times}$ faster training time and 30% improved GPU utilization while maintaining competitive accuracy. These results establish MQ-GNN as a scalable and efficient solution for multi-GPU GNN training.", "AI": {"tldr": "MQ-GNN\u901a\u8fc7\u591a\u961f\u5217\u6d41\u6c34\u7ebf\u548c\u5f02\u6b65\u4e00\u81f4\u66f4\u65b0\uff0c\u63d0\u5347GNN\u8bad\u7ec3\u901f\u5ea64.6\u00d7\u3001GPU\u5229\u7528\u738730%\uff0c\u5e76\u4fdd\u6301\u51c6\u786e\u5ea6", "motivation": "GNN\u8bad\u7ec3\u5728\u591aGPU\u73af\u5883\u4e0b\u53d7\u5236\u4e8emini-batch\u751f\u6210\u3001\u6570\u636e\u4f20\u8f93\u74f6\u9888\u548cGPU\u95f4\u540c\u6b65\u8d39\u7528\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b", "method": "\u591a\u961f\u5217\u6d41\u6c34\u7ebfMQ-GNN\u7ed3\u5408Ready-to-Update Asynchronous Consistent Model (RaCoM)\u5b9e\u73b0\u5f02\u6b65\u68af\u5ea6\u5171\u4eab\u4e0e\u6a21\u578b\u66f4\u65b0\uff0c\u914d\u5408\u5168\u5c40\u90bb\u5c45\u91c7\u6837\u7f13\u5b58\u4e0e\u81ea\u9002\u5e94\u961f\u5217\u5c3a\u5bf8\u8c03\u5ea6\u4ee5\u63d0\u9ad8\u8ba1\u7b97\u4e0e\u5185\u5b58\u5229\u7528", "result": "\u5b9e\u9a8c\u663e\u793aMQ-GNN\u5728\u56db\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0e\u5341\u4e2a\u57fa\u7ebf\u6a21\u578b\u4e0a\u8bad\u7ec3\u901f\u5ea6\u63d0\u53474.6\u500d\uff0cGPU\u5229\u7528\u7387\u63d0\u534730%\uff0c\u4e14\u4fdd\u6301\u7ade\u4e89\u6027\u51c6\u786e\u7387", "conclusion": "MQ-GNN\u901a\u8fc7\u91cd\u53e0\u8bad\u7ec3\u9636\u6bb5\u3001\u5f02\u6b65\u4e00\u81f4\u66f4\u65b0\u53ca\u8d44\u6e90\u8c03\u5ea6\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u591aGPU GNN\u8bad\u7ec3\u6846\u67b6"}}
{"id": "2601.04719", "categories": ["cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.04719", "abs": "https://arxiv.org/abs/2601.04719", "authors": ["Maanas Taneja", "Purab Shingvi"], "title": "GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models", "comment": null, "summary": "The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compression, achieving 4$\\times$ memory reduction with minimal accuracy degradation. We develop four CUDA kernel variants -- naive, tiled, coarsened, and vectorized -- and benchmark them across realistic workload sizes up to 1 billion elements. Our vectorized kernel achieves up to 1,694$\\times$ speedup over CPU baselines while maintaining reconstruction error below 0.004 and attention score error below 0.1 even for 8K-dimensional heads. These results demonstrate that INT8 quantization provides a practical approach for reducing memory pressure in LLM inference with negligible computational overhead (6--58ms) and minimal impact on downstream model behavior", "AI": {"tldr": "INT8\u91cf\u5316+GPU\u5411\u91cf\u5316\u6838\u53ef\u5c06KV\u7f13\u5b58\u5185\u5b58\u538b\u7f294\u500d\uff0c\u51e0\u4e4e\u65e0\u7cbe\u5ea6\u635f\u5931\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "KV\u7f13\u5b58\u968f\u5e8f\u5217\u957f\u5ea6\u7ebf\u6027\u589e\u957f\uff0c\u5185\u5b58\u6210\u4e3a\u63a8\u7406\u74f6\u9888\uff1b\u9700\u8981\u4e00\u79cd\u65e2\u538b\u7f29\u5185\u5b58\u53c8\u4fdd\u6301\u7cbe\u5ea6\u7684\u65b9\u6848\u3002", "method": "\u5b9e\u73b0\u5e76\u8bc4\u4f30GPU\u52a0\u901f\u7684INT8\u91cf\u5316\uff0c\u6784\u5efa\u56db\u79cdCUDA\u6838\uff1anaive\u3001tiled\u3001coarsened\u3001vectorized\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5411\u91cf\u5316\u6838\u5b9e\u73b0\u9ad8\u8fbe1694\u500d\u901f\u5ea6\u63d0\u5347\uff0c\u5185\u5b58\u538b\u7f294\u500d\uff0c\u91cd\u5efa\u8bef\u5dee<0.004\uff0c\u6ce8\u610f\u529b\u5206\u6570\u8bef\u5dee<0.1\uff0c\u8ba1\u7b97\u5f00\u9500\u4ec56\u201358ms\u3002", "conclusion": "INT8\u91cf\u5316\u53ef\u4ee5\u5728LLM\u63a8\u7406\u4e2d\u663e\u8457\u964d\u4f4eKV\u7f13\u5b58\u5185\u5b58\u5360\u7528\uff0c\u51e0\u4e4e\u4e0d\u5f71\u54cd\u6027\u80fd\u548c\u7ed3\u679c\u3002"}}
{"id": "2601.04728", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04728", "abs": "https://arxiv.org/abs/2601.04728", "authors": ["Elizabeth Donoway", "Hailey Joren", "Fabien Roger", "Jan Leike"], "title": "Excess Description Length of Learning Generalizable Predictors", "comment": null, "summary": "Understanding whether fine-tuning elicits latent capabilities or teaches new ones is a fundamental question for language model evaluation and safety. We develop a formal information-theoretic framework for quantifying how much predictive structure fine-tuning extracts from the train dataset and writes into a model's parameters. Our central quantity, Excess Description Length (EDL), is defined via prequential coding and measures the gap between the bits required to encode training labels sequentially using an evolving model (trained online) and the residual encoding cost under the final trained model. We establish that EDL is non-negative in expectation, converges to surplus description length in the infinite-data limit, and provides bounds on expected generalization gain. Through a series of toy models, we clarify common confusions about information in learning: why random labels yield EDL near zero, how a single example can eliminate many bits of uncertainty about the underlying rule(s) that describe the data distribution, why structure learned on rare inputs contributes proportionally little to expected generalization, and how format learning creates early transients distinct from capability acquisition. This framework provides rigorous foundations for the empirical observation that capability elicitation and teaching exhibit qualitatively distinct scaling signatures.", "AI": {"tldr": "\u672c\u6587\u7528 Excess Description Length \u8861\u91cf\u5fae\u8c03\u65f6\u4fe1\u606f\u83b7\u5f97\uff0c\u8bc1\u660e\u5176\u53ef\u91cf\u5316\u5e76\u89e3\u91ca\u80fd\u529b\u6fc0\u6d3b\u4e0e\u65b0\u80fd\u529b\u5b66\u4e60\u7684\u4e0d\u540c\u5c3a\u5ea6\u7279\u5f81\u3002", "motivation": "\u4e86\u89e3\u5fae\u8c03\u662f\u6fc0\u6d3b\u6f5c\u5728\u80fd\u529b\u8fd8\u662f\u6559\u6388\u65b0\u80fd\u529b\uff0c\u5bf9\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u4e0e\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5b9a\u4e49 Excess Description Length\uff08EDL\uff09\u4f5c\u4e3a\u524d\u5e8f\u7f16\u7801\u5dee\u503c\uff0c\u8bc1\u660e\u5176\u975e\u8d1f\u6027\u3001\u6536\u655b\u6027\u4e0e\u6cdb\u5316\u6536\u76ca\u7684\u4e0a\u4e0b\u754c\uff0c\u5e76\u5728\u591a\u7ec4\u7b80\u5316\u6a21\u578b\u4e2d\u68c0\u9a8c\u5176\u7279\u6027\u3002", "result": "EDL \u91cf\u5316\u4e86\u8bad\u7ec3\u6570\u636e\u5bf9\u6a21\u578b\u53c2\u6570\u7684\u71b5\u589e\uff0c\u5e76\u901a\u8fc7 toy \u4f8b\u5b50\u9610\u91ca\u4e86\u968f\u673a\u6807\u7b7e\u3001\u5355\u4f8b\u5b66\u4e60\u3001\u7a00\u6709\u8f93\u5165\u4e0e\u683c\u5f0f\u5b66\u4e60\u7684\u89c4\u5f8b\uff0c\u9a8c\u8bc1\u4e86\u80fd\u529b\u6fc0\u6d3b\u4e0e\u65b0\u80fd\u529b\u6559\u5b66\u5728\u89c4\u6a21\u884c\u4e3a\u4e0a\u5b58\u5728\u4e0d\u540c\u6807\u8bb0\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u4fe1\u606f\u8bba\u6846\u67b6\u8868\u660e\u5fae\u8c03\u63d0\u53d6\u5e76\u5199\u5165\u6a21\u578b\u53c2\u6570\u7684\u53ef\u9884\u6d4b\u7ed3\u6784\u53ef\u91cf\u5316\uff0c\u63d0\u4f9b\u4e86\u533a\u5206\u80fd\u529b\u6fc0\u6d3b\u4e0e\u65b0\u80fd\u529b\u5b66\u4e60\u7684\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2601.04741", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04741", "abs": "https://arxiv.org/abs/2601.04741", "authors": ["Kota Nakamura", "Koki Kawabata", "Yasuko Matsubara", "Yasushi Sakurai"], "title": "Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams", "comment": "Accepted by KDD 2026", "summary": "Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.", "AI": {"tldr": "TimeCast\u662f\u9762\u5411\u5b9e\u65f6\u591a\u4f20\u611f\u5668\u6d41\u7684\u52a8\u6001\u4e8b\u4ef6\u65f6\u95f4\u9884\u6d4b\u6846\u67b6\uff0c\u5229\u7528\u9636\u6bb5\u8bc6\u522b\u548c\u5728\u7ebf\u6a21\u578b\u66f4\u65b0\uff0c\u8fbe\u5230\u66f4\u51c6\u3001\u66f4\u5feb\u7684\u6545\u969c\u9884\u6d4b\u3002", "motivation": "\u5b9e\u65f6\u4f20\u611f\u5668\u6d41\u6570\u636e\u968f\u65f6\u95f4\u6f14\u5316\uff0c\u4f20\u7edf\u9759\u6001\u9884\u6d4b\u6a21\u578b\u96be\u4ee5\u8ddf\u4e0a\u6f14\u5316\u901f\u5ea6\uff1b\u6545\u969c\u9884\u6d4b\u8981\u6c42\u5728\u53d8\u5316\u7684\u52a8\u6001\u73af\u5883\u4e2d\u6301\u7eed\u7cbe\u786e\u3002", "method": "\u6784\u5efa\u5c42\u6b21\u5316\u5206\u6bb5\u5b66\u4e60\u4f53\u7cfb\uff08Stage Learning\uff09\uff0c\u5728\u6bcf\u4e2a\u9636\u6bb5\u5185\u8bad\u7ec3\u72ec\u7acb\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u5728\u7ebf\u66f4\u65b0\u673a\u5236\u5feb\u901f\u9002\u5e94\u4f20\u611f\u5668\u6570\u636e\u7684\u65f6\u95f4\u6f14\u53d8\uff1b\u901a\u8fc7\u591a\u4f20\u611f\u5668\u4ea4\u4e92\u7279\u5f81\u6355\u6349\uff0c\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTimeCast\u5728\u771f\u5b9e\u5de5\u51b5\u6570\u636e\u96c6\u4e0a\u76f8\u8f83\u4e8e\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u4e86\u591a\u8fbe15% \u7684\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u5e76\u5c06\u8ba1\u7b97\u65f6\u95f4\u4e0b\u964d\u81f3\u539f~20%\u3002", "conclusion": "TimeCast\u901a\u8fc7\u52a8\u6001\u6a21\u578b\u8bc6\u522b\u4e0e\u8ddf\u8e2a\u6570\u636e\u6d41\u4e2d\u7684\u9636\u6bb5\u6027\u6a21\u5f0f\u53d8\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u672a\u6765\u673a\u5668\u6545\u969c\u65f6\u95f4\u70b9\u7684\u9884\u6d4b\u51c6\u786e\u7387\uff1b\u540c\u65f6\uff0c\u8be5\u6846\u67b6\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b9e\u73b0\u4e86\u7ebf\u6027\u6269\u5c55\u53ca\u5728\u7ebf\u6a21\u578b\u66f4\u65b0\u3002"}}
{"id": "2601.04751", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04751", "abs": "https://arxiv.org/abs/2601.04751", "authors": ["Luca Lanzilao", "Angela Meyer"], "title": "Intraday spatiotemporal PV power prediction at national scale using satellite-based solar forecast models", "comment": null, "summary": "We present a novel framework for spatiotemporal photovoltaic (PV) power forecasting and use it to evaluate the reliability, sharpness, and overall performance of seven intraday PV power nowcasting models. The model suite includes satellite-based deep learning and optical-flow approaches and physics-based numerical weather prediction models, covering both deterministic and probabilistic formulations. Forecasts are first validated against satellite-derived surface solar irradiance (SSI). Irradiance fields are then converted into PV power using station-specific machine learning models, enabling comparison with production data from 6434 PV stations across Switzerland. To our knowledge, this is the first study to investigate spatiotemporal PV forecasting at a national scale. We additionally provide the first visualizations of how mesoscale cloud systems shape national PV production on hourly and sub-hourly timescales. Our results show that satellite-based approaches outperform the Integrated Forecast System (IFS-ENS), particularly at short lead times. Among them, SolarSTEPS and SHADECast deliver the most accurate SSI and PV power predictions, with SHADECast providing the most reliable ensemble spread. The deterministic model IrradianceNet achieves the lowest root mean square error, while probabilistic forecasts of SolarSTEPS and SHADECast provide better-calibrated uncertainty. Forecast skill generally decreases with elevation. At a national scale, satellite-based models forecast the daily total PV generation with relative errors below 10% for 82% of the days in 2019-2020, demonstrating robustness and their potential for operational use.", "AI": {"tldr": "\u5148\u7528\u536b\u661f\u8f90\u5c04\u9a8c\u8bc1\uff0c\u518d\u8f6c\u5316\u4e3a\u5149\u4f0f\u529f\u7387\uff0c\u8bc4\u4f30\u4e03\u6a21\u578b\u3002\u536b\u661f\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6700\u9ad8\u51c6\u786e\u6027\uff0c\u8bef\u5dee\u4f4e\u4e8e10%\u7684\u5929\u6570\u8fbe82%\u3002", "motivation": "\u5927\u533a\u57df\u5149\u4f0f\u9884\u6d4b\u5c1a\u7f3a\u5c11\u7a7a\u95f4-\u65f6\u95f4\u4e00\u81f4\u7684\u8bc4\u4f30\u548c\u73b0\u5b9e\u64cd\u4f5c\u68c0\u9a8c\uff0c\u9700\u9a8c\u8bc1\u536b\u661f\u9884\u62a5\u5728\u5168\u56fd\u5c3a\u5ea6\u7684\u6709\u6548\u6027\u4e0e\u53ef\u89c6\u5316\u4e91\u7cfb\u7edf\u5bf9\u7535\u91cf\u7684\u5f71\u54cd\u3002", "method": "\u7ed3\u5408\u536b\u661f\u8f90\u5c04\u6df1\u5ea6\u5b66\u4e60\u3001\u5149\u6d41\u4e0e\u6570\u503c\u5929\u6c14\u9884\u62a5\u7684\u6df7\u5408\u6846\u67b6\uff1b\u5148\u68c0\u9a8c\u8f90\u5c04\u573a\uff0c\u518d\u7528\u7ad9\u70b9\u7279\u5b9a\u673a\u5b66\u4e60\u6620\u5c04\u5230\u53d1\u7535\u91cf\uff1b\u5bf9\u6bd4\u4e03\u5957\u73b0\u6709\u73b0\u65f6\u9884\u6d4b\u65b9\u6cd5\u3002", "result": "SolarSTEPS\u4e0eSHADECast\u7684SSI/\u529f\u7387\u9884\u6d4b\u6700\u7cbe\u51c6\uff1bSHADECast\u7684\u96c6\u6210\u5206\u5e03\u6700\u53ef\u9760\uff1bIrradianceNet\u8bef\u5dee\u6700\u4f4e\uff1b\u5728\u4f4e\u6d77\u62d4\u5730\u533a\u6a21\u578b\u7cbe\u5ea6\u9ad8\uff0c\u745e\u58eb\u5168\u56fd\u65e5\u7d2f\u8ba1\u529f\u7387\u76f8\u5bf9\u8bef\u5dee<10%\u8fbe\u523082%\u5929\u3002", "conclusion": "\u536b\u661f\u57fa\u9884\u62a5\u5728\u5168\u745e\u58eb\u5168\u5c3a\u5ea6\u77ed\u671f\u5149\u4f0f\u7535\u91cf\u9884\u6d4b\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u5177\u5907\u826f\u597d\u7684\u53ef\u9760\u6027\u548c\u53ef\u64cd\u4f5c\u6027\u3002"}}
{"id": "2601.04807", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04807", "abs": "https://arxiv.org/abs/2601.04807", "authors": ["Oscar Llorente", "Jaime Boal", "Eugenio F. S\u00e1nchez-\u00dabeda", "Antonio Diaz-Cano", "Miguel Familiar"], "title": "Parallelizing Node-Level Explainability in Graph Neural Networks", "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated remarkable performance in a wide range of tasks, such as node classification, link prediction, and graph classification, by exploiting the structural information in graph-structured data. However, in node classification, computing node-level explainability becomes extremely time-consuming as the size of the graph increases, while batching strategies often degrade explanation quality. This paper introduces a novel approach to parallelizing node-level explainability in GNNs through graph partitioning. By decomposing the graph into disjoint subgraphs, we enable parallel computation of explainability for node neighbors, significantly improving the scalability and efficiency without affecting the correctness of the results, provided sufficient memory is available. For scenarios where memory is limited, we further propose a dropout-based reconstruction mechanism that offers a controllable trade-off between memory usage and explanation fidelity. Experimental results on real-world datasets demonstrate substantial speedups, enabling scalable and transparent explainability for large-scale GNN models.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04873", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04873", "abs": "https://arxiv.org/abs/2601.04873", "authors": ["Elisa Roldan", "Kirstie Andrews", "Stephen M. Richardson", "Reyhaneh Fatahian", "Glen Cooper", "Rasool Erfani", "Tasneem Sabir", "Neil D. Reeves"], "title": "FibreCastML: An Open Web Platform for Predicting Electrospun Nanofibre Diameter Distributions", "comment": null, "summary": "Electrospinning is a scalable technique for producing fibrous scaffolds with tunable micro- and nanoscale architectures for applications in tissue engineering, drug delivery, and wound care. While machine learning (ML) has been used to support electrospinning process optimisation, most existing approaches predict only mean fibre diameters, neglecting the full diameter distribution that governs scaffold performance. This work presents FibreCastML, an open, distribution-aware ML framework that predicts complete fibre diameter spectra from routinely reported electrospinning parameters and provides interpretable insights into process structure relationships.\n  A meta-dataset comprising 68538 individual fibre diameter measurements extracted from 1778 studies across 16 biomedical polymers was curated. Six standard processing parameters, namely solution concentration, applied voltage, flow rate, tip to collector distance, needle diameter, and collector rotation speed, were used to train seven ML models using nested cross validation with leave one study out external folds. Model interpretability was achieved using variable importance analysis, SHapley Additive exPlanations, correlation matrices, and three dimensional parameter maps.\n  Non linear models consistently outperformed linear baselines, achieving coefficients of determination above 0.91 for several widely used polymers. Solution concentration emerged as the dominant global driver of fibre diameter distributions. Experimental validation across different electrospinning systems demonstrated close agreement between predicted and measured distributions. FibreCastML enables more reproducible and data driven optimisation of electrospun scaffold architectures.", "AI": {"tldr": "FibreCastML\u5229\u7528\u591a\u6e90\u5b9e\u9a8c\u6570\u636e\u548c\u53ef\u89e3\u91caML\uff0c\u51c6\u786e\u9884\u6d4b\u7535\u7eba\u7ea4\u7ef4\u76f4\u5f84\u5206\u5e03\uff0c\u4e3a\u652f\u67b6\u5236\u9020\u63d0\u4f9b\u6570\u636e\u9a71\u52a8\u4f18\u5316\u3002", "motivation": "\u4f20\u7edfML\u65b9\u6cd5\u4ec5\u9884\u6d4b\u5e73\u5747\u7ea4\u7ef4\u76f4\u5f84\uff0c\u5ffd\u89c6\u5b8c\u6574\u5206\u5e03\uff0c\u5bfc\u81f4\u652f\u67b6\u6027\u80fd\u8bc4\u4f30\u4e0d\u8db3\uff1b\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u5206\u5e03\u611f\u77e5\u3001\u53ef\u89e3\u91ca\u7684ML\u6846\u67b6\u3002", "method": "\u6784\u5efa\u5305\u542b68538\u6761\u7ea4\u7ef4\u76f4\u5f84\u7684\u5143\u6570\u636e\u96c6\uff0c\u6311\u9009\u516d\u4e2a\u5e38\u89c4\u5de5\u827a\u53c2\u6570\uff0c\u4f7f\u7528\u5d4c\u5957\u4ea4\u53c9\u9a8c\u8bc1(Leave-One-Study-Out)\u8bad\u7ec3\u4e03\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u53d8\u91cf\u91cd\u8981\u6027\u3001SHAP\u3001\u76f8\u5173\u77e9\u9635\u53ca\u4e09\u7ef4\u53c2\u6570\u56fe\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u975e\u7ebf\u6027\u6a21\u578b\u5728\u591a\u79cd\u805a\u5408\u7269\u4e0a$R^2>0.91$\uff0c\u663e\u793a\u51fa\u5353\u8d8a\u6027\u80fd\uff1b\u5b9e\u9a8c\u9a8c\u8bc1\u8bc1\u5b9e\u9884\u6d4b\u5206\u5e03\u4e0e\u6d4b\u91cf\u7ed3\u679c\u9ad8\u5ea6\u543b\u5408\u3002", "conclusion": "FibreCastML\u80fd\u591f\u9884\u6d4b\u5b8c\u6574\u7684\u7ea4\u7ef4\u76f4\u5f84\u5206\u5e03\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8fc7\u7a0b\u5173\u7cfb\uff0c\u663e\u8457\u63d0\u9ad8\u7535\u7eba\u652f\u67b6\u8bbe\u8ba1\u7684\u53ef\u91cd\u590d\u6027\u4e0e\u6570\u636e\u9a71\u52a8\u6027\u3002"}}
{"id": "2601.04890", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04890", "abs": "https://arxiv.org/abs/2601.04890", "authors": ["Maksim Velikanov", "Ilyas Chahed", "Jingwei Zuo", "Dhia Eddine Rhaiem", "Younes Belkada", "Hakim Hacid"], "title": "Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers", "comment": null, "summary": "Applying weight decay (WD) to matrix layers is standard practice in large-language-model pretraining. Prior work suggests that stochastic gradient noise induces a Brownian-like expansion of the weight matrices W, whose growth is counteracted by WD, leading to a WD-noise equilibrium with a certain weight norm ||W||. In this work, we view the equilibrium norm as a harmful artifact of the training procedure, and address it by introducing learnable multipliers to learn the optimal scale. First, we attach a learnable scalar multiplier to W and confirm that the WD-noise equilibrium norm is suboptimal: the learned scale adapts to data and improves performance. We then argue that individual row and column norms are similarly constrained, and free their scale by introducing learnable per-row and per-column multipliers. Our method can be viewed as a learnable, more expressive generalization of muP multipliers. It outperforms a well-tuned muP baseline, reduces the computational overhead of multiplier tuning, and surfaces practical questions such as forward-pass symmetries and the width-scaling of the learned multipliers. Finally, we validate learnable multipliers with both Adam and Muon optimizers, where it shows improvement in downstream evaluations matching the improvement of the switching from Adam to Muon.", "AI": {"tldr": "\u901a\u8fc7\u5728\u77e9\u9635\u5c42\u53ca\u5176\u884c\u5217\u4e0a\u5f15\u5165\u53ef\u5b66\u4e60\u4e58\u5b50\uff0c\u6253\u7834WD\u566a\u58f0\u5e73\u8861\u7684\u89c4\u6a21\u9650\u5236\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u5e76\u51cf\u5c11\u8c03\u53c2\u6210\u672c\u3002", "motivation": "\u6743\u91cd\u8870\u51cf\uff08WD\uff09\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\u5e38\u89c1\uff0c\u4f46\u5176\u5728\u77e9\u9635\u5c42\u4e0a\u7684\u5e73\u8861\u4f7f\u5f97\u6743\u91cd\u77e9\u9635\u7684\u5927\u5c0f\u4e3a\u4e0d\u5229\u7684\u8bad\u7ec3\u4ea7\u7269\u3002\u8be5\u65b9\u6cd5\u8ba4\u4e3a\u57fa\u4e8e\u968f\u673a\u68af\u5ea6\u566a\u58f0\u7684Brownian-like\u6269\u5f20\u4ea7\u751f\u7684WD-\u566a\u58f0\u5e73\u8861\u5bfc\u81f4\u6743\u91cd\u8303\u6570\u5b50\u6700\u4f18\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u5c3a\u5ea6\u5b66\u4e60\u3002", "method": "\u4e3a\u6bcf\u4e2a\u6743\u91cd\u77e9\u9635\u5f15\u5165\u53ef\u5b66\u4e60\u7684\u6807\u91cf\u4e58\u5b50\uff0c\u5e76\u8fdb\u4e00\u6b65\u62c6\u5206\u4e3a\u6bcf\u884c\u6bcf\u5217\u7684\u4e58\u5b50\uff0c\u4ee5\u89e3\u9501\u66f4\u5177\u8868\u73b0\u529b\u7684\u5c3a\u5ea6\u8c03\u8282\uff0c\u5f62\u6210\u5bf9muP\u4e58\u5b50\u7684\u4e00\u822c\u5316\u6269\u5c55\u3002", "result": "\u5b66\u4e60\u7684\u4e58\u5b50\u5728Adam\u548cMuon\u4f18\u5316\u5668\u4e0b\u5747\u80fd\u63d0\u5347\u4e0b\u6e38\u8bc4\u4f30\uff0c\u4e14\u76f8\u5bf9\u4e8e\u7cbe\u8c03\u7684muP\u57fa\u7ebf\u53d6\u5f97\u66f4\u4f18\u6027\u80fd\uff0c\u51cf\u5c11\u4e86\u4e58\u5b50\u8c03\u8282\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u5f15\u5165\u53ef\u5b66\u4e60\u7684\u591a\u5c3a\u5ea6\u4e58\u5b50\u80fd\u591f\u663e\u8457\u7a81\u7834WD\u566a\u58f0\u5e73\u8861\u5bfc\u81f4\u7684\u6027\u80fd\u74f6\u9888\uff0c\u5728\u4fdd\u6301\u6216\u52a0\u901f\u6536\u655b\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002"}}
{"id": "2601.04954", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04954", "abs": "https://arxiv.org/abs/2601.04954", "authors": ["Yirong Zeng", "Yufei Liu", "Xiao Ding", "Yutai Hou", "Yuxian Wang", "Haonan Song", "Wu Ning", "Dandan Tu", "Qixun Zhang", "Bibo Cai", "Yuxiang He", "Ting Liu"], "title": "Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following", "comment": "ACL under review 13 pages, 8 figures", "summary": "A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperform those trained on mixed datasets. Extensive experiments reveal that reward precision, rather than constraint diversity, is the primary driver of effective alignment. The LLM judge suffers from a low recall rate in detecting false response, which leads to severe reward hacking, thereby undermining the benefits of diversity. Furthermore, analysis of the attention mechanism reveals that high-precision rewards develop a transferable meta-skill for IF. Motivated by these insights, we propose a simple yet effective data-centric refinement strategy that prioritizes reward precision. Evaluated on five benchmarks, our approach outperforms competitive baselines by 13.4\\% in performance while achieving a 58\\% reduction in training time, maintaining strong generalization beyond instruction following. Our findings advocate for a paradigm shift: moving away from the indiscriminate pursuit of data diversity toward high-precision rewards.", "AI": {"tldr": "\u4ec5\u7528\u9ad8\u7cbe\u5ea6\u786c\u7ea6\u675f\u8bad\u7ec3\u53ef\u8d85\u8d8a\u6df7\u5408\u7ea6\u675f\u6a21\u578b\uff0c\u53d6\u5f9713.4%\u6027\u80fd\u63d0\u5347\u5e76\u51cf\u5c1158%\u8bad\u7ec3\u65f6\u95f4\u3002", "motivation": "\u8d28\u7591\u4f20\u7edf\u8ba4\u4e3a\u7ea6\u675f\u591a\u6837\u6027\u662f\u6cdb\u5316\u5173\u952e\u7684\u89c2\u70b9\uff0c\u63a2\u7d22\u5956\u52b1\u7cbe\u786e\u5ea6\u5bf9\u6a21\u578b\u5bf9\u9f50\u548c\u6cdb\u5316\u7684\u5f71\u54cd\u3002", "method": "\u8fdb\u884c\u7cfb\u7edf\u6027\u5b9e\u8bc1\u8c03\u67e5\uff0c\u6bd4\u8f83\u4ec5\u786c\u7ea6\u675f\u3001\u6df7\u5408\u7ea6\u675f\u6a21\u578b\u5e76\u5206\u6790\u5956\u52b1\u7cbe\u5ea6\u3001\u6ce8\u610f\u529b\u673a\u5236\uff0c\u968f\u540e\u63d0\u51fa\u57fa\u4e8e\u5956\u52b1\u7cbe\u5ea6\u7684\u6570\u636e\u4e2d\u5fc3\u5316\u7cbe\u70bc\u7b56\u7565\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u76f8\u8f83\u7ade\u4e89\u57fa\u7ebf\u63d0\u534713.4%\u6027\u80fd\uff0c\u8bad\u7ec3\u65f6\u95f4\u7f29\u77ed58%\uff0c\u5e76\u4fdd\u6301\u826f\u597d\u6cdb\u5316\u3002", "conclusion": "\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528\u9ad8\u7cbe\u5ea6\u786c\u7ea6\u675f\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5305\u542b\u8f6f\u7ea6\u675f\u7684\u6df7\u5408\u6570\u636e\u96c6\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u5e76\u7f29\u77ed\u4e86\u8bad\u7ec3\u65f6\u95f4\u3002"}}
{"id": "2601.04977", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04977", "abs": "https://arxiv.org/abs/2601.04977", "authors": ["James Hinns", "Sofie Goethals", "Stephan Van der Veeken", "Theodoros Evgeniou", "David Martens"], "title": "On the Definition and Detection of Cherry-Picking in Counterfactual Explanations", "comment": null, "summary": "Counterfactual explanations are widely used to communicate how inputs must change for a model to alter its prediction. For a single instance, many valid counterfactuals can exist, which leaves open the possibility for an explanation provider to cherry-pick explanations that better suit a narrative of their choice, highlighting favourable behaviour and withholding examples that reveal problematic behaviour. We formally define cherry-picking for counterfactual explanations in terms of an admissible explanation space, specified by the generation procedure, and a utility function. We then study to what extent an external auditor can detect such manipulation. Considering three levels of access to the explanation process: full procedural access, partial procedural access, and explanation-only access, we show that detection is extremely limited in practice. Even with full procedural access, cherry-picked explanations can remain difficult to distinguish from non cherry-picked explanations, because the multiplicity of valid counterfactuals and flexibility in the explanation specification provide sufficient degrees of freedom to mask deliberate selection. Empirically, we demonstrate that this variability often exceeds the effect of cherry-picking on standard counterfactual quality metrics such as proximity, plausibility, and sparsity, making cherry-picked explanations statistically indistinguishable from baseline explanations. We argue that safeguards should therefore prioritise reproducibility, standardisation, and procedural constraints over post-hoc detection, and we provide recommendations for algorithm developers, explanation providers, and auditors.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u5bf9\u6297\u6027\u89e3\u91ca\u7684\u201c\u6311\u98df\u201d\u53ef\u80fd\u6027\uff0c\u8bc1\u660e\u5bf9\u5176\u68c0\u6d4b\u975e\u5e38\u56f0\u96be\uff0c\u5e76\u5efa\u8bae\u901a\u8fc7\u53ef\u590d\u73b0\u6027\u3001\u6807\u51c6\u5316\u53ca\u7a0b\u5e8f\u9650\u5236\u6765\u9884\u9632\u3002", "motivation": "\u5355\u4e2a\u6570\u636e\u6837\u672c\u53ef\u80fd\u4ea7\u751f\u591a\u4e2a\u5408\u6cd5\u7684\u5bf9\u6297\u6027\u89e3\u91ca\uff0c\u89e3\u91ca\u63d0\u4f9b\u8005\u53ef\u80fd\u6311\u9009\u6709\u5229\u7684\u89e3\u91ca\uff0c\u4ece\u800c\u64cd\u7eb5\u89e3\u91ca\u7ed3\u679c\u3002", "method": "\u5728\u8bbe\u5b9a\u53ef\u63a5\u53d7\u89e3\u91ca\u7a7a\u95f4\u548c\u6548\u7528\u51fd\u6570\u7684\u6b63\u5f0f\u5b9a\u4e49\u4e0b\uff0c\u63a2\u8ba8\u5728\u4e09\u79cd\u4fe1\u606f\u83b7\u53d6\u7ea7\u522b\uff08\u5b8c\u5168\u7a0b\u5e8f\u8bbf\u95ee\u3001\u90e8\u5206\u7a0b\u5e8f\u8bbf\u95ee\u3001\u4ec5\u89e3\u91ca\u8bbf\u95ee\uff09\u4e0b\u7684\u68c0\u6d4b\u53ef\u884c\u6027\uff0c\u7ed3\u5408\u7406\u8bba\u8bc1\u660e\u4e0e\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5373\u4fbf\u5728\u5b8c\u5168\u7a0b\u5e8f\u8bbf\u95ee\u65f6\uff0c\u6311\u9009\u51fa\u7684\u89e3\u91ca\u5728\u591a\u6837\u6027\u4e0e\u7075\u6d3b\u6027\u652f\u6301\u4e0b\u4ecd\u96be\u4ee5\u4e0e\u975e\u6311\u9009\u89e3\u91ca\u533a\u522b\uff1b\u5728\u5b9e\u9a8c\u4e2d\uff0c\u89e3\u91ca\u8d28\u91cf\u6307\u6807\u7684\u53d8\u5316\u51e0\u4e4e\u88ab\u89e3\u91ca\u591a\u6837\u6027\u6240\u63a9\u76d6\uff0c\u4f7f\u6311\u9009\u4e0e\u57fa\u7ebf\u89e3\u91ca\u5728\u7edf\u8ba1\u4e0a\u4e0d\u53ef\u533a\u5206\u3002", "conclusion": "\u63d0\u793a\u201c\u6311\u98df\u201d\u5f0f\u7684\u5bf9\u6297\u6027\u89e3\u91ca\uff08cherry\u2011picking\uff09\u5f88\u96be\u88ab\u5916\u90e8\u5ba1\u8ba1\u5458\u6839\u636e\u53ef\u9009\u89e3\u91ca\u7a7a\u95f4\u548c\u6548\u7528\u51fd\u6570\u68c0\u6d4b\uff0c\u56e0\u800c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ea\u9760\u4e8b\u540e\u68c0\u6d4b\u5f80\u5f80\u65e0\u6548\uff1b\u5efa\u8bae\u4fa7\u91cd\u53ef\u590d\u73b0\u6027\u3001\u6807\u51c6\u5316\u4e0e\u5bf9\u751f\u6210\u8fc7\u7a0b\u7684\u7ea6\u675f\u3002"}}
{"id": "2601.05017", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05017", "abs": "https://arxiv.org/abs/2601.05017", "authors": ["Xiaopeng Luo", "Zexi Tan", "Zhuowei Wang"], "title": "HMVI: Unifying Heterogeneous Attributes with Natural Neighbors for Missing Value Inference", "comment": "Submitted to ICASSP 2026", "summary": "Missing value imputation is a fundamental challenge in machine intelligence, heavily dependent on data completeness. Current imputation methods often handle numerical and categorical attributes independently, overlooking critical interdependencies among heterogeneous features. To address these limitations, we propose a novel imputation approach that explicitly models cross-type feature dependencies within a unified framework. Our method leverages both complete and incomplete instances to ensure accurate and consistent imputation in tabular data. Extensive experimental results demonstrate that the proposed approach achieves superior performance over existing techniques and significantly enhances downstream machine learning tasks, providing a robust solution for real-world systems with missing data.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.05028", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05028", "abs": "https://arxiv.org/abs/2601.05028", "authors": ["Torben Berndt", "Jan St\u00fchmer"], "title": "Approximate equivariance via projection-based regularisation", "comment": null, "summary": "Equivariance is a powerful inductive bias in neural networks, improving generalisation and physical consistency. Recently, however, non-equivariant models have regained attention, due to their better runtime performance and imperfect symmetries that might arise in real-world applications. This has motivated the development of approximately equivariant models that strike a middle ground between respecting symmetries and fitting the data distribution. Existing approaches in this field usually apply sample-based regularisers which depend on data augmentation at training time, incurring a high sample complexity, in particular for continuous groups such as $SO(3)$. This work instead approaches approximate equivariance via a projection-based regulariser which leverages the orthogonal decomposition of linear layers into equivariant and non-equivariant components. In contrast to existing methods, this penalises non-equivariance at an operator level across the full group orbit, rather than point-wise. We present a mathematical framework for computing the non-equivariance penalty exactly and efficiently in both the spatial and spectral domain. In our experiments, our method consistently outperforms prior approximate equivariance approaches in both model performance and efficiency, achieving substantial runtime gains over sample-based regularisers.", "AI": {"tldr": "\u63d0\u51fa\u6295\u5f71\u6b63\u5219\u5316\u65b9\u5f0f\uff0c\u901a\u8fc7\u6b63\u4ea4\u5206\u89e3\u5728\u6574\u4e2a\u5bf9\u79f0\u7fa4\u8f68\u9053\u4e0a\u7cbe\u786e\u60e9\u7f5a\u975e\u7b49\u53d8\u9879\uff0c\u663e\u8457\u63d0\u5347\u901f\u5ea6\u4e0e\u6027\u80fd\uff0c\u4f18\u4e8e\u4f20\u7edf\u6837\u672c\u6b63\u5219\u5316\u3002", "motivation": "\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5bf9\u79f0\u6027\u53ef\u80fd\u4e0d\u5b8c\u7f8e\uff0c\u975e\u7b49\u53d8\u6a21\u578b\u517c\u987e\u6548\u7387\uff0c\u4fc3\u4f7f\u9700\u5f00\u53d1\u65e2\u80fd\u5c0a\u91cd\u5bf9\u79f0\u6027\u53c8\u80fd\u9002\u5e94\u6570\u636e\u5206\u5e03\u7684\u8fd1\u4f3c\u7b49\u53d8\u6a21\u578b\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6295\u5f71\u7684\u6b63\u5219\u5316\uff0c\u5229\u7528\u7ebf\u6027\u5c42\u5728\u7b49\u53d8\u548c\u975e\u7b49\u53d8\u5206\u91cf\u7684\u6b63\u4ea4\u5206\u89e3\uff0c\u5728\u6574\u4e2a\u7fa4\u8f68\u9053\u7ea7\u522b\u5bf9\u975e\u7b49\u53d8\u6027\u8fdb\u884c\u60e9\u7f5a\uff1b\u901a\u8fc7\u7a7a\u95f4\u57df\u4e0e\u9891\u8c31\u57df\u7684\u89e3\u6790\u6846\u67b6\u7cbe\u786e\u9ad8\u6548\u8ba1\u7b97\u8be5\u60e9\u7f5a\u3002", "result": "\u5728\u591a\u7ec4\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u6a21\u578b\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u4ee5\u5f80\u7684\u6837\u672c\u91cf\u5927\u3001\u4f9d\u8d56\u6570\u636e\u589e\u5f3a\u7684\u8fd1\u4f3c\u7b49\u53d8\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8fd0\u884c\u65f6\u901f\u5ea6\u3002", "conclusion": "\u672c\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u7cbe\u51c6\u7684\u8fd1\u4f3c\u7b49\u53d8\u6b63\u5219\u5316\u7b56\u7565\uff0c\u517c\u987e\u5bf9\u79f0\u6027\u4e0e\u5b9e\u9645\u6570\u636e\u9002\u914d\uff0c\u5e7f\u6cdb\u9002\u7528\u4e8e\u8fde\u7eed\u7fa4\u5982SO(3)\u7684\u4efb\u52a1\u3002"}}
{"id": "2601.05033", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05033", "abs": "https://arxiv.org/abs/2601.05033", "authors": ["Anees Fatima", "Mohammad Abdus Salam"], "title": "A Data-Driven Predictive Framework for Inventory Optimization Using Context-Augmented Machine Learning Models", "comment": null, "summary": "Demand forecasting in supply chain management (SCM) is critical for optimizing inventory, reducing waste, and improving customer satisfaction. Conventional approaches frequently neglect external influences like weather, festivities, and equipment breakdowns, resulting in inefficiencies. This research investigates the use of machine learning (ML) algorithms to improve demand prediction in retail and vending machine sectors. Four machine learning algorithms. Extreme Gradient Boosting (XGBoost), Autoregressive Integrated Moving Average (ARIMA), Facebook Prophet (Fb Prophet), and Support Vector Regression (SVR) were used to forecast inventory requirements. Ex-ternal factors like weekdays, holidays, and sales deviation indicators were methodically incorporated to enhance precision. XGBoost surpassed other models, reaching the lowest Mean Absolute Error (MAE) of 22.7 with the inclusion of external variables. ARIMAX and Fb Prophet demonstrated noteworthy enhancements, whereas SVR fell short in performance. Incorporating external factors greatly improves the precision of demand forecasting models, and XGBoost is identified as the most efficient algorithm. This study offers a strong framework for enhancing inventory management in retail and vending machine systems.", "AI": {"tldr": "\u4f7f\u7528XGBoost\u5e76\u52a0\u5165\u5916\u90e8\u56e0\u7d20\u53ef\u5927\u5e45\u6539\u5584\u96f6\u552e\u4e0e\u81ea\u52a8\u552e\u8d27\u673a\u7684\u9700\u6c42\u9884\u6d4b\uff0c\u5e73\u5747\u8bef\u5dee\u964d\u81f322.7\uff0c\u4f18\u4e8eARIMA\u3001Prophet\u548cSVR\u3002", "motivation": "\u4f20\u7edf\u9700\u6c42\u9884\u6d4b\u65b9\u6cd5\u5ffd\u89c6\u5929\u6c14\u3001\u8282\u65e5\u7b49\u5916\u90e8\u5f71\u54cd\uff0c\u5bfc\u81f4\u5e93\u5b58\u7ba1\u7406\u4f4e\u6548\u3002\u8be5\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7ed3\u5408\u5916\u90e8\u53d8\u91cf\uff0c\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u4e0e\u5e93\u5b58\u7ba1\u7406\u6548\u679c\u3002", "method": "\u672c\u7814\u7a76\u9009\u53d6XGBoost\u3001ARIMA\u3001Facebook Prophet\u4ee5\u53caSVR\u56db\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u7cfb\u7edf\u5730\u52a0\u5165\u5de5\u4f5c\u65e5\u3001\u8282\u5047\u65e5\u53ca\u9500\u552e\u504f\u5dee\u7b49\u5916\u90e8\u56e0\u7d20\uff0c\u5bf9\u96f6\u552e\u548c\u81ea\u52a8\u552e\u8d27\u673a\u7684\u5e93\u5b58\u9700\u6c42\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002", "result": "XGBoost\u5728\u52a0\u5165\u5916\u90e8\u53d8\u91cf\u540eMAE\u964d\u81f3\u6700\u4f4e22.7\uff1bARIMAX \u4e0e Facebook Prophet \u4ea6\u663e\u8457\u6539\u5584\uff1bSVR\u8868\u73b0\u4e0d\u4f73\u3002\u5916\u90e8\u56e0\u7d20\u7684\u52a0\u5165\u663e\u8457\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u3002", "conclusion": "XGBoost\u5728\u5f15\u5165\u5916\u90e8\u53d8\u91cf\u540e\u8868\u73b0\u6700\u4f73\uff0c\u6700\u4f4eMAE\u4e3a22.7\uff0c\u9a8c\u8bc1\u4e86\u52a0\u5165\u5916\u90e8\u56e0\u7d20\u80fd\u591f\u663e\u8457\u63d0\u5347\u96f6\u552e\u4e0e\u81ea\u52a8\u552e\u8d27\u673a\u7684\u9700\u6c42\u9884\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2601.05073", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05073", "abs": "https://arxiv.org/abs/2601.05073", "authors": ["Jianlong Chen", "Daocheng Fu", "Shengze Xu", "Jiawei Chen", "Yuan Feng", "Yue Yang", "Junchi Yan", "Hongyuan Zha", "Renqiu Xia"], "title": "Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) struggle with complex geometric reasoning, largely because \"black box\" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces sparse signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.05082", "categories": ["cs.LG", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05082", "abs": "https://arxiv.org/abs/2601.05082", "authors": ["Hayk Asatryan", "Basile Tousside", "Janis Mohr", "Malte Neugebauer", "Hildo Bijl", "Paul Spiegelberg", "Claudia Frohn-Schauf", "J\u00f6rg Frochte"], "title": "Exploring Student Expectations and Confidence in Learning Analytics", "comment": "7 pages, Keywords: Learning Analytics, Survey, Data Protection, Clustering", "summary": "Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.", "AI": {"tldr": "\u901a\u8fc7\u95ee\u5377+\u805a\u7c7b\uff0c\u627e\u51fa\u56db\u7c7b\u5b66\u751f\u5bf9\u5b66\u4e60\u5206\u6790\u7684\u6001\u5ea6\u5dee\u5f02\uff0c\u4e3a\u7b26\u5408\u9690\u79c1\u6cd5\u89c4\u7684\u5b66\u4e60\u5206\u6790\u63a8\u5e7f\u63d0\u4f9b\u6d1e\u5bdf\u3002", "motivation": "\u5728\u5b66\u4e60\u5206\u6790\u666e\u53ca\u7684\u540c\u65f6\uff0c\u589e\u5f3a\u5b66\u751f\u5bf9\u6570\u636e\u9690\u79c1\u7684\u5173\u6ce8\uff0c\u9700\u4e86\u89e3\u5b66\u751f\u5bf9\u6570\u636e\u5904\u7406\u7684\u6001\u5ea6\uff0c\u4ee5\u5b9e\u73b0\u5408\u6cd5\u5408\u89c4\u5e76\u63d0\u5347\u5b66\u4e60\u5206\u6790\u5de5\u5177\u7684\u63a5\u53d7\u5ea6\u3002", "method": "\u91c7\u7528SELAQ\u95ee\u5377\u6536\u96c6\u5b66\u751f\u6570\u636e\uff0c\u8fd0\u7528\u805a\u7c7b\u7b97\u6cd5\u5bf9\u5b66\u751f\u8fdb\u884c\u5206\u7fa4\uff0c\u968f\u540e\u5bf9\u5404\u7fa4\u4f53\u7684\u671f\u671b\u548c\u4fe1\u4efb\u8fdb\u884c\u5b9a\u91cf\u4e0e\u5b9a\u6027\u5206\u6790\u3002", "result": "\u5c06\u5b66\u751f\u5212\u5206\u4e3a\u7231\u597d\u8005\u3001\u73b0\u5b9e\u4e3b\u4e49\u8005\u3001\u8c28\u614e\u8005\u4e0e\u6f20\u4e0d\u5173\u5fc3\u8005\u56db\u7ec4\uff0c\u6bcf\u7ec4\u5728\u6570\u636e\u4fe1\u4efb\u4e0e\u671f\u671b\u4e0a\u8868\u73b0\u51fa\u660e\u663e\u5dee\u5f02\uff0c\u4e3a\u5b66\u6821\u5728\u653f\u7b56\u5236\u5b9a\u4e0e\u5de5\u5177\u5f00\u53d1\u63d0\u4f9b\u4f9d\u636e\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7SELAQ\u95ee\u5377\u63a2\u8ba8\u4e0d\u540c\u5b66\u9662\u5b66\u751f\u5bf9\u5b66\u4e60\u5206\u6790\u6570\u636e\u5904\u7406\u7684\u671f\u671b\u4e0e\u4fe1\u4efb\uff0c\u5e76\u57fa\u4e8e\u805a\u7c7b\u7b97\u6cd5\u8bc6\u522b\u56db\u7c7b\u5b66\u751f\u7fa4\u4f53\uff0c\u4e3a\u6559\u80b2\u7cfb\u7edf\u9002\u5e94\u9690\u79c1\u6cd5\u89c4\u4e0e\u63d0\u5347\u5b66\u4e60\u5206\u6790\u63a5\u53d7\u5ea6\u63d0\u4f9b\u7b56\u7565\u3002"}}
{"id": "2601.05134", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05134", "abs": "https://arxiv.org/abs/2601.05134", "authors": ["Polina Dolgova", "Sebastian U. Stich"], "title": "Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning", "comment": null, "summary": "Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\\varepsilon,\u03b4)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.", "AI": {"tldr": "\u5c06\u566a\u58f0\u9884\u7b97\u5206\u6563\u5230\u6b63\u4ea4\u5b50\u7a7a\u95f4\u800c\u975e\u4e00\u6b21\u6027\u6ce8\u5165\uff0c\u53ef\u5728\u4fdd\u8bc1(\u03b5,\u03b4)\u5dee\u5206\u9690\u79c1\u8ba4\u8bc1\u7684\u524d\u63d0\u4e0b\u5927\u5e45\u63d0\u5347\u53bb\u5b66\u4e60\u540e\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u7684\u566a\u58f0\u5fae\u8c03\u65b9\u6cd5\u5c3d\u7ba1\u80fd\u5b9e\u73b0\u5dee\u5206\u9690\u79c1\u8ba4\u8bc1\uff0c\u4f46\u4f1a\u5bfc\u81f4\u6a21\u578b\u51c6\u786e\u6027\u5927\u5e45\u4e0b\u964d\uff1b\u7814\u7a76\u8005\u5e0c\u671b\u5728\u786e\u4fdd\u5b89\u5168\u6027\u7684\u540c\u65f6\u63d0\u5347\u5b9e\u7528\u6027\u3002", "method": "\u901a\u8fc7\u5c06\u566a\u58f0\u9884\u7b97\u5206\u914d\u5230\u53c2\u6570\u7a7a\u95f4\u7684\u6b63\u4ea4\u5b50\u7a7a\u95f4\uff0c\u800c\u975e\u4e00\u6b21\u6027\u6ce8\u5165\u566a\u58f0\uff0c\u6784\u5efa\u987a\u5e8f\u566a\u58f0\u8c03\u5ea6\u673a\u5236\uff0c\u5e76\u5bf9\u8be5\u65b9\u6cd5\u5728\u5b50\u7a7a\u95f4\u6846\u67b6\u4e0b\u7684\u5dee\u5206\u9690\u79c1\u6027\u8fdb\u884c\u7406\u8bba\u6269\u5c55\u3002", "result": "\u5728\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u4e0a\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5206\u6bb5\u566a\u58f0\u8c03\u5ea6\u65b9\u6848\u5728\u5b8c\u6210\u53bb\u5b66\u4e60\u540e\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5bf9\u6210\u5458\u63a8\u65ad\u653b\u51fb\u4fdd\u6301\u7a33\u5065\u3002", "conclusion": "\u4f7f\u7528\u5206\u6bb5\u566a\u58f0\u8c03\u5ea6\u7684\u5dee\u5206\u9690\u79c1\u8ba4\u8bc1\u65e0\u5b66\u4e60\u65b9\u6848\u80fd\u591f\u5728\u4fdd\u6301\u4e25\u683c\u5b89\u5168\u4fdd\u8bc1\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u53bb\u5b66\u4e60\u540e\u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2601.05194", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05194", "abs": "https://arxiv.org/abs/2601.05194", "authors": ["Fardin Ganjkhanloo", "Emmett Springer", "Erik H. Hoyer", "Daniel L. Young", "Holley Farley", "Kimia Ghobadi"], "title": "An interpretable data-driven approach to optimizing clinical fall risk assessment", "comment": "arXiv admin note: substantial text overlap with arXiv:2510.20714", "summary": "In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.", "AI": {"tldr": "\u4f7f\u7528\u53d7\u9650\u5f97\u5206\u4f18\u5316\u5bf9JHFRAT\u8fdb\u884c\u91cd\u6743\u540e\uff0c\u9884\u6d4b\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u53ef\u6bcf\u5468\u591a\u8bc6\u522b35\u540d\u4f4f\u9662\u9ad8\u5371\u8dcc\u5012\u60a3\u8005\u3002", "motivation": "\u63d0\u5347JHFRAT\u4e0e\u4e34\u5e8a\u5b9e\u9645\u9700\u6c42\u7684\u5951\u5408\u5ea6\uff0c\u51cf\u5c11\u8dcc\u5012\u4e8b\u4ef6\uff0c\u63d0\u9ad8\u60a3\u8005\u5b89\u5168\u548c\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002", "method": "\u5bf92022\u5e74\u81f32023\u5e74\u7ea6\u7ff0\u970d\u666e\u91d1\u65af\u5065\u5eb7\u4f53\u7cfb\u518554,209\u4f8b\u4f4f\u9662\u75c5\u4f8b\u8fdb\u884c\u56de\u987e\u6027\u961f\u5217\u5206\u6790\uff0c\u91c7\u7528\u53d7\u9650\u5f97\u5206\u4f18\u5316\uff08CSO\uff09\u6a21\u578b\u91cd\u65b0\u52a0\u6743JHFRAT\u5f97\u5206\uff0c\u4fdd\u6301\u5176\u52a0\u6027\u7ed3\u6784\u548c\u9608\u503c\uff1b\u4e0e\u539f\u59cbJHFRAT\u3001\u53d7\u9650\u903b\u8f91\u56de\u5f52\u4ee5\u53caXGBoost\u7b49\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "CSO\u6a21\u578bROC AUC\u63d0\u9ad8\u81f30.91\uff08\u539f\u59cb0.86\uff09\uff0c\u6bcf\u5468\u53ef\u989d\u5916\u8bc6\u522b35\u540d\u9ad8\u5371\u60a3\u8005\uff1b\u4e0eXGBoost\u76f8\u6bd4\uff0cCSO\u5728\u98ce\u9669\u6807\u7b7e\u53d8\u5316\u65f6\u66f4\u7a33\u5065\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bc1\u636e\u7684\u3001\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u6539\u8fdb\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ea6\u7ff0\u970d\u666e\u91d1\u65af\u7cfb\u7edf\u5185\u4f4f\u9662\u8dcc\u5012\u98ce\u9669\u9884\u6d4b\u7684\u51c6\u786e\u5ea6\uff0c\u5e76\u4e3a\u533b\u7597\u673a\u6784\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u3001\u7a33\u5065\u7684\u8dcc\u5012\u9884\u9632\u4e0e\u8d44\u6e90\u5206\u914d\u57fa\u7840\u3002"}}
{"id": "2601.05245", "categories": ["cs.LG", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.05245", "abs": "https://arxiv.org/abs/2601.05245", "authors": ["Natalie Collina", "Jiuyao Lu", "Georgy Noarov", "Aaron Roth"], "title": "Optimal Lower Bounds for Online Multicalibration", "comment": null, "summary": "We prove tight lower bounds for online multicalibration, establishing an information-theoretic separation from marginal calibration.\n  In the general setting where group functions can depend on both context and the learner's predictions, we prove an $\u03a9(T^{2/3})$ lower bound on expected multicalibration error using just three disjoint binary groups. This matches the upper bounds of Noarov et al. (2025) up to logarithmic factors and exceeds the $O(T^{2/3-\\varepsilon})$ upper bound for marginal calibration (Dagan et al., 2025), thereby separating the two problems.\n  We then turn to lower bounds for the more difficult case of group functions that may depend on context but not on the learner's predictions. In this case, we establish an $\\widetilde\u03a9(T^{2/3})$ lower bound for online multicalibration via a $\u0398(T)$-sized group family constructed using orthogonal function systems, again matching upper bounds up to logarithmic factors.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
