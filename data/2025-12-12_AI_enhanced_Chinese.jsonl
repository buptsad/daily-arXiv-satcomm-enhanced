{"id": "2512.09941", "categories": ["cs.IT", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09941", "abs": "https://arxiv.org/abs/2512.09941", "authors": ["Fatemeh Ghasemi", "Swastik Kopparty"], "title": "Fourier Sparsity of Delta Functions and Matching Vector PIRs", "comment": "Full version. Accepted to ITCS 2026", "summary": "In this paper we study a basic and natural question about Fourier analysis of Boolean functions, which has applications to the study of Matching Vector based Private Information Retrieval (PIR) schemes. For integers m and r, define a delta function on {0,1}^r to be a function f: Z_m^r -> C with f(0) = 1 and f(x) = 0 for all nonzero Boolean x. The basic question we study is how small the Fourier sparsity of a delta function can be; namely how sparse such an f can be in the Fourier basis?\n  In addition to being intrinsically interesting and natural, such questions arise naturally when studying \"S-decoding polynomials\" for the known matching vector families. Finding S-decoding polynomials of reduced sparsity, which corresponds to finding delta functions with low Fourier sparsity, would improve the current best PIR schemes.\n  We show nontrivial upper and lower bounds on the Fourier sparsity of delta functions. Our proofs are elementary and clean. These results imply limitations on improving Matching Vector PIR schemes simply by finding better S-decoding polynomials. In particular, there are no S-decoding polynomials that can make Matching Vector PIRs based on the known matching vector families achieve polylogarithmic communication with a constant number of servers. Many interesting questions remain open.", "AI": {"tldr": "\u7ed9\u51fa delta \u51fd\u6570\u5728\u5085\u91cc\u53f6\u57fa\u4e2d\u7684\u7a00\u758f\u5ea6\u4e0a\u4e0b\u754c\uff0c\u5e76\u636e\u6b64\u9650\u5b9a\u57fa\u4e8e\u5339\u914d\u5411\u91cf\u7684PIR\u4e2d\u901a\u8fc7\u6539\u8fdb S \u89e3\u7801\u591a\u9879\u5f0f\u65e0\u6cd5\u5b9e\u73b0\u5e38\u6570\u670d\u52a1\u5668\u3001polylog \u7ea7\u522b\u901a\u4fe1\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u5c06\u5085\u91cc\u53f6\u5206\u6790\u5e94\u7528\u5230 {0,1}^r \u4e0a\u7684 delta \u51fd\u6570\uff0c\u7814\u7a76\u5176\u5728 Z_m^r \u7684\u5085\u91cc\u53f6\u7a00\u758f\u5ea6\uff0c\u4ee5\u63ed\u793a\u5bf9 Matching Vector \u57faPIR \u65b9\u6848\u7684\u6f5c\u5728\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u7ed9\u51fa\u5bf9 delta \u51fd\u6570\u7684\u5085\u91cc\u53f6\u7a00\u758f\u5ea6\u7684\u975e\u5e73\u51e1\u4e0a\u754c\u548c\u4e0b\u754c\uff0c\u8bc1\u660e\u5176\u63a8\u5bfc\u8fc7\u7a0b\u6e05\u6670\u3001\u7b80\u6d01\uff1b\u5e76\u5c06\u7ed3\u679c\u5e94\u7528\u4e8e\u5206\u6790 S \u89e3\u7801\u591a\u9879\u5f0f\u5728 MV-PIR \u7684\u4f5c\u7528\u4e0e\u5c40\u9650\u6027\u3002", "result": "\u5f97\u5230\u5173\u4e8e delta \u51fd\u6570\u5085\u91cc\u53f6\u7a00\u758f\u5ea6\u7684\u4e0a\u4e0b\u754c\uff0c\u8868\u660e\u4ec5\u901a\u8fc7\u5bfb\u627e\u66f4\u7a00\u758f\u7684 S \u89e3\u7801\u591a\u9879\u5f0f\uff0c\u65e0\u6cd5\u663e\u8457\u63d0\u5347\u73b0\u6709\u57fa\u4e8e\u5df2\u77e5\u5339\u914d\u5411\u91cf\u65cf\u7684 MV-PIR \u7684\u901a\u4fe1\u590d\u6742\u5ea6\uff08\u5728\u5e38\u6570\u670d\u52a1\u5668\u6761\u4ef6\u4e0b\u8fbe\u5230 polylog \u7ea7\u522b\uff09\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5bf9 MV-PIR \u7684\u4e00\u4e2a\u91cd\u8981\u9650\u5236\uff0c\u63d0\u51fa\u4e86\u82e5\u5e72\u672a\u89e3\u7684\u6709\u8da3\u95ee\u9898\uff0c\u6307\u5411\u672a\u6765\u5728\u5085\u91cc\u53f6\u5206\u6790\u4e0e PIR \u8bbe\u8ba1\u65b9\u9762\u7684\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2512.10223", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10223", "abs": "https://arxiv.org/abs/2512.10223", "authors": ["Jiewei Feng", "Peihong Yuan", "Ken R. Duffy", "Muriel M\u00e9dard"], "title": "Improving the decoding performance of CA-polar codes", "comment": null, "summary": "We investigate the use of modern code-agnostic decoders to convert CA-SCL from an incomplete decoder to a complete one. When CA-SCL fails to identify a codeword that passes the CRC check, we apply a code-agnostic decoder that identifies a codeword that satisfies the CRC. We establish that this approach gives gains of up to 0.2 dB in block error rate for CA-Polar codes from the 5G New Radio standard. If, instead, the message had been encoded in a systematic CA-polar code, the gain improves to 0.2 ~ 1dB. Leveraging recent developments in blockwise soft output, we additionally establish that it is possible to control the undetected error rate even when using the CRC for error correction.", "AI": {"tldr": "\u901a\u8fc7\u4f7f\u7528\u4e0e\u7f16\u7801\u65e0\u5173\u7684\u89e3\u7801\u5668\uff0c\u5c06 CA-SCL \u4ece\u4e0d\u5b8c\u6574\u89e3\u7801\u8f6c\u53d8\u4e3a\u5b8c\u6574\u89e3\u7801\uff1b\u5728 CRC \u672a\u901a\u8fc7\u65f6\u4ecd\u53ef\u627e\u5230\u901a\u8fc7 CRC \u7684\u7801\u5b57\uff0c\u4ece\u800c\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u63d0\u5347 CA-SCL \u5728 CRC \u7ea6\u675f\u4e0b\u7684\u89e3\u7801\u6027\u80fd\uff0c\u89e3\u51b3 CRC \u672a\u901a\u8fc7\u65f6\u7684\u89e3\u7801\u4e0d\u8db3\uff0c\u5e76\u7814\u7a76\u7cfb\u7edf\u5316 CA-Polar \u7f16\u7801\u7684\u6f5c\u5728\u6536\u76ca\u3002", "method": "\u5728 CRC \u672a\u901a\u8fc7\u65f6\uff0c\u5e94\u7528\u4e0e\u7f16\u7801\u65e0\u5173\u7684\u89e3\u7801\u5668\u5bfb\u627e\u6ee1\u8db3 CRC \u7684\u7801\u5b57\uff1b\u5bf9 CA-Polar\uff085G NR \u6807\u51c6\uff09\u4e0e\u7cfb\u7edf\u5316 CA-Polar \u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\uff1b\u7ed3\u5408\u57fa\u4e8e\u5757\u7684\u8f6f\u8f93\u51fa\u4ee5\u63a7\u5236\u672a\u68c0\u6d4b\u9519\u8bef\u7387\u3002", "result": "\u5bf9\u4e8e CA-Polar\uff085G NR\uff09\u7684\u65e0\u7cfb\u7edf\u7f16\u7801\uff0cBLER \u63d0\u5347\u53ef\u8fbe\u7ea6 0.2 dB\uff1b\u82e5\u6539\u4e3a\u7cfb\u7edf\u5316 CA-Polar\uff0c\u63d0\u5347\u8303\u56f4\u4e3a\u7ea6 0.2 dB \u81f3 1 dB\uff1b\u5e76\u4e14\u901a\u8fc7\u5757\u5f0f\u8f6f\u8f93\u51fa\u5b9e\u73b0\u5bf9\u672a\u68c0\u6d4b\u9519\u8bef\u7387\u7684\u63a7\u5236\u3002", "conclusion": "\u7f16\u7801\u65e0\u5173\u89e3\u7801\u7b56\u7565\u5728\u4fdd\u6301 CRC \u7ea6\u675f\u4e0b\u53ef\u63d0\u5347 CA-Polar \u7684\u89e3\u7801\u6027\u80fd\uff0c\u4e14\u7cfb\u7edf\u5316\u7f16\u7801\u5e26\u6765\u66f4\u663e\u8457\u7684\u6536\u76ca\uff0c\u540c\u65f6\u80fd\u591f\u901a\u8fc7\u8f6f\u8f93\u51fa\u673a\u5236\u5bf9\u672a\u68c0\u6d4b\u9519\u8bef\u7387\u8fdb\u884c\u63a7\u5236\u3002"}}
{"id": "2512.10809", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.10809", "abs": "https://arxiv.org/abs/2512.10809", "authors": ["Reinhard Wiesmayr", "Frederik Zumegen", "Sueda Taner", "Chris Dick", "Christoph Studer"], "title": "CSI-Based User Positioning, Channel Charting, and Device Classification with an NVIDIA 5G Testbed", "comment": "This work has been presented at the 59th Asilomar Conference on Signals, Systems, and Computers 2025", "summary": "Channel-state information (CSI)-based sensing will play a key role in future cellular systems. However, no CSI dataset has been published from a real-world 5G NR system that facilitates the development and validation of suitable sensing algorithms. To close this gap, we publish three real-world wideband multi-antenna multi-open RAN radio unit (O-RU) CSI datasets from the 5G NR uplink channel: an indoor lab/office room dataset, an outdoor campus courtyard dataset, and a device classification dataset with six commercial-off-the-shelf (COTS) user equipments (UEs). These datasets have been recorded using a software-defined 5G NR testbed based on NVIDIA Aerial RAN CoLab Over-the-Air (ARC-OTA) with COTS hardware, which we have deployed at ETH Zurich. We demonstrate the utility of these datasets for three CSI-based sensing tasks: neural UE positioning, channel charting in real-world coordinates, and closed-set device classification. For all these tasks, our results show high accuracy: neural UE positioning achieves 0.6cm (indoor) and 5.7cm (outdoor) mean absolute error, channel charting in real-world coordinates achieves 73cm mean absolute error (outdoor), and device classification achieves 99% (same day) and 95% (next day) accuracy. The CSI datasets, ground-truth UE position labels, CSI features, and simulation code are publicly available at https://caez.ethz.ch", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.10318", "categories": ["cs.NI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10318", "abs": "https://arxiv.org/abs/2512.10318", "authors": ["Aniruddh Mishra", "Benjamin Oommen", "Jimmy Liang"], "title": "L2 Ethernet Switch VLSI Implementation", "comment": "9 pages, 21 figures", "summary": "Ethernet switches are foundational to the global internet infrastructure. These devices route packets of data on a local area network between source addresses to destination media access control addresses. On the L2 layer of the Open Systems Interconnections model, Ethernet switches take in digitized data from a Media Independent Interface and send it to the corresponding output port for the destination address. Switches need to handle parallel input and output streams from each port, prioritizing throughput, efficiency, and packet integrity. Due to the confidential nature of the networking device industry, there do not exist many open source implementations of switching fabrics. We propose an open source design for an L2 Ethernet switch along with the power, performance, and area tradeoffs for architecture decisions.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.10036", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10036", "abs": "https://arxiv.org/abs/2512.10036", "authors": ["Nimesha Gunasekara", "Ebrahim Bedeer"], "title": "Analysis and Compensation of Receiver IQ Imbalance and Residual CFO Error for AFDM", "comment": null, "summary": "Affine frequency division multiplexing (AFDM) is a promising waveform for future wireless communication systems. In this paper, we analyze the impact of receiver in-phase and quadrature (IQ) imbalance and residual carrier frequency offset (CFO) error on AFDM signals. Our analysis shows that the receiver IQ imbalance may not preserve the sparsity of the AFDM effective channel matrix because of the complex-conjugate operator of the discrete affine Fourier transform (DAFT). Moreover, the residual CFO error causes energy leakage in the effective channel matrix in the affine domain. To mitigate these effects, we extend the linear minimum mean-square error (LMMSE) detector to handle the improper Gaussian noise arising from the receiver IQ imbalance. Simulation results demonstrate that the proposed LMMSE detector effectively compensates for the receiver hardware impairments.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.09936", "categories": ["eess.SY", "cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.09936", "abs": "https://arxiv.org/abs/2512.09936", "authors": ["Yang Li", "Chong Ma", "Yuanzheng Li", "Sen Li", "Yanbo Chen", "Zhaoyang Dong"], "title": "QSTAformer: A Quantum-Enhanced Transformer for Robust Short-Term Voltage Stability Assessment against Adversarial Attacks", "comment": "15 pages, 12 figures. Accepted by Applied Energy", "summary": "Short-term voltage stability assessment (STVSA) is critical for secure power system operation. While classical machine learning-based methods have demonstrated strong performance, they still face challenges in robustness under adversarial conditions. This paper proposes QSTAformer-a tailored quantum-enhanced Transformer architecture that embeds parameterized quantum circuits (PQCs) into attention mechanisms-for robust and efficient STVSA. A dedicated adversarial training strategy is developed to defend against both white-box and gray-box attacks. Furthermore, diverse PQC architectures are benchmarked to explore trade-offs between expressiveness, convergence, and efficiency. To the best of our knowledge, this is the first work to systematically investigate the adversarial vulnerability of quantum machine learning-based STVSA. Case studies on the IEEE 39-bus system demonstrate that QSTAformer achieves competitive accuracy, reduced complexity, and stronger robustness, underscoring its potential for secure and scalable STVSA under adversarial conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5b50\u589e\u5f3aTransformer\uff08QSTAformer\uff09\u7528\u4e8e\u77ed\u671f\u7535\u538b\u7a33\u5b9a\u6027\u8bc4\u4f30\uff08STVSA\uff09\uff0c\u5728\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u5d4c\u5165\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\uff0c\u7ed3\u5408\u5bf9\u6297\u8bad\u7ec3\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u5e76\u6bd4\u8f83\u591a\u79cdPQC\u67b6\u6784\u3002", "motivation": "\u77ed\u671f\u7535\u538b\u7a33\u5b9a\u6027\u8bc4\u4f30\u5bf9\u7535\u529b\u7cfb\u7edf\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edfML\u5728\u5bf9\u6297\u6761\u4ef6\u4e0b\u9c81\u68d2\u6027\u4e0d\u8db3\uff1b\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u91cf\u5b50\u589e\u5f3a\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1QSTAformer\uff0c\u5c06PQCs\u5d4c\u5165\u6ce8\u610f\u529b\u673a\u5236\uff1b\u5f00\u53d1\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565\u4ee5\u5bf9\u6297\u767d\u76d2\u4e0e\u7070\u76d2\u653b\u51fb\uff1b\u5bf9\u591a\u79cdPQC\u67b6\u6784\u8fdb\u884c\u57fa\u51c6\u6bd4\u8f83\uff1b\u5728IEEE 39\u6bcd\u7ebf\u7cfb\u7edf\u4e0a\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u5728IEEE 39-bus\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u7ade\u4e89\u6027\u7cbe\u5ea6\u3001\u964d\u4f4e\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3001\u4ee5\u53ca\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u8bc1\u660e\u5728\u5bf9\u6297\u6761\u4ef6\u4e0b\u7684\u5b89\u5168\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u9996\u6b21\u7cfb\u7edf\u6027\u7814\u7a76\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5728STVSA\u4e2d\u7684\u5bf9\u6297\u8106\u5f31\u6027\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5b89\u5168\u53ef\u6269\u5c55\u7684STVSA\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2512.09947", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.09947", "abs": "https://arxiv.org/abs/2512.09947", "authors": ["Fuyan Ou", "Siqi Ai", "Yulin Hu"], "title": "HGC-Herd: Efficient Heterogeneous Graph Condensation via Representative Node Herding", "comment": "8 pages, 2 figures", "summary": "Heterogeneous graph neural networks (HGNNs) have demonstrated strong capability in modeling complex semantics across multi-type nodes and relations. However, their scalability to large-scale graphs remains challenging due to structural redundancy and high-dimensional node features. Existing graph condensation approaches, such as GCond, are primarily developed for homogeneous graphs and rely on gradient matching, resulting in considerable computational, memory, and optimization overhead. We propose HGC-Herd, a training-free condensation framework that generates compact yet informative heterogeneous graphs while maintaining both semantic and structural fidelity. HGC-Herd integrates lightweight feature propagation to encode multi-hop relational context and employs a class-wise herding mechanism to identify representative nodes per class, producing balanced and discriminative subsets for downstream learning tasks. Extensive experiments on ACM, DBLP, and Freebase validate that HGC-Herd attains comparable or superior accuracy to full-graph training while markedly reducing both runtime and memory consumption. These results underscore its practical value for efficient and scalable heterogeneous graph representation learning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8bad\u7ec3\u65e0\u5173\u7684\u8de8\u5f02\u6784\u56fe\u538b\u7f29\u65b9\u6cd5HGC-Herd\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u8bed\u4e49\u4e0e\u7ed3\u6784\u4fdd\u771f\u5ea6\u7684\u524d\u63d0\u4e0b\uff0c\u751f\u6210\u7d27\u51d1\u7684\u5f02\u6784\u56fe\u4ee5\u4f9b\u4e0b\u6e38\u4efb\u52a1\u4f7f\u7528\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u8fd0\u884c\u65f6\u95f4\u548c\u5185\u5b58\u5f00\u9500\u3002", "motivation": "- HGNNs\u5728\u5927\u89c4\u6a21\u5f02\u6784\u56fe\u4e0a\u7684\u6269\u5c55\u6027\u53d7\u5236\u4e8e\u7ed3\u6784\u5197\u4f59\u548c\u9ad8\u7ef4\u7279\u5f81\u3002\u73b0\u6709\u56fe\u538b\u7f29\u65b9\u6cd5\uff08\u5982GCond\uff09\u591a\u7528\u4e8e\u540c\u6784\u56fe\uff0c\u57fa\u4e8e\u68af\u5ea6\u5339\u914d\uff0c\u8ba1\u7b97\u3001\u5185\u5b58\u548c\u4f18\u5316\u5f00\u9500\u8f83\u5927\u3002\u9700\u4e00\u79cd\u8bad\u7ec3\u65e0\u5173\u3001\u9002\u7528\u4e8e\u5f02\u6784\u56fe\u7684\u9ad8\u6548\u538b\u7f29\u65b9\u6848\u3002", "method": "- HGC-Herd\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7279\u5f81\u4f20\u64ad\u6765\u7f16\u7801\u591a\u8df3\u5173\u7cfb\u4e0a\u4e0b\u6587\uff0c\u63d0\u5347\u8bed\u4e49\u4fe1\u606f\u8868\u8fbe\uff1b- \u91c7\u7528\u7c7b\u522b\u7ea7\u7684\u9a71\u52a8\u673a\u5236(\u7c7b\u5185\u4e3a\u4ee3\u8868\u8282\u70b9\u7684\u201cherding\u201d)\u9009\u53d6\u6bcf\u4e2a\u7c7b\u522b\u7684\u4ee3\u8868\u8282\u70b9\uff0c\u751f\u6210\u5e73\u8861\u4e14\u5177\u5224\u522b\u6027\u7684\u5b50\u56fe\u96c6\u5408\uff1b- \u8be5\u8fc7\u7a0b\u65e0\u9700\u6a21\u578b\u8bad\u7ec3\u5373\u53ef\u5b8c\u6210\u538b\u7f29\uff0c\u6240\u5f97\u5b50\u56fe\u53ef\u7528\u4e8e\u540e\u7eed\u5b66\u4e60\u4efb\u52a1\u3002", "result": "\u5728ACM\u3001DBLP\u548cFreebase\u6570\u636e\u96c6\u4e0a\uff0c\u538b\u7f29\u540e\u56fe\u5728\u4fdd\u6301\u4e0e\u5168\u56fe\u8bad\u7ec3\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u7684\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u5927\u5e45\u964d\u4f4e\u4e86\u8fd0\u884c\u65f6\u548c\u5185\u5b58\u6d88\u8017\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u5f02\u6784\u56fe\u8868\u793a\u5b66\u4e60\u65b9\u9762\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.10118", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.10118", "abs": "https://arxiv.org/abs/2512.10118", "authors": ["Pol Mestres", "Shima Sadat Mousavi", "Pio Ong", "Lizhi Yang", "Ersin Das", "Joel W. Burdick", "Aaron D. Ames"], "title": "Explicit Control Barrier Function-based Safety Filters and their Resource-Aware Computation", "comment": null, "summary": "This paper studies the efficient implementation of safety filters that are designed using control barrier functions (CBFs), which minimally modify a nominal controller to render it safe with respect to a prescribed set of states. Although CBF-based safety filters are often implemented by solving a quadratic program (QP) in real time, the use of off-the-shelf solvers for such optimization problems poses a challenge in applications where control actions need to be computed efficiently at very high frequencies. In this paper, we introduce a closed-form expression for controllers obtained through CBF-based safety filters. This expression is obtained by partitioning the state-space into different regions, with a different closed-form solution in each region. We leverage this formula to introduce a resource-aware implementation of CBF-based safety filters that detects changes in the partition region and uses the closed-form expression between changes. We showcase the applicability of our approach in examples ranging from aerospace control to safe reinforcement learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u533a\u57df\u5206\u6bb5\u7684\u95ed\u5f0f\u89e3\u7528\u4e8eCBF\u5b89\u5168\u6ee4\u6ce2\u7684\u9ad8\u9891\u5b9e\u73b0\uff0c\u901a\u8fc7\u5728\u72b6\u6001\u7a7a\u95f4\u5212\u5206\u533a\u57df\u5e76\u5728\u6bcf\u4e2a\u533a\u57df\u7ed9\u51fa\u95ed\u5f0f\u63a7\u5236\u5f8b\uff0c\u4ece\u800c\u5b9e\u73b0\u65e0\u9700\u5b9e\u65f6\u6c42\u89e3QP\u7684\u8d44\u6e90\u611f\u77e5\u5b89\u5168\u63a7\u5236\uff0c\u5e76\u5728\u533a\u57df\u53d8\u5316\u65f6\u66f4\u65b0\u7b56\u7565\u3002", "motivation": "CBF\u5b89\u5168\u6ee4\u6ce2\u901a\u5e38\u901a\u8fc7\u5728\u5b9e\u65f6\u6c42\u89e3\u4e8c\u6b21\u89c4\u5212(QP)\u6765\u5b9e\u73b0\uff0c\u4ee5\u4fdd\u8bc1\u72b6\u6001\u5b89\u5168\uff1b\u7136\u800c\u5728\u9700\u8981\u6781\u9ad8\u63a7\u5236\u9891\u7387\u7684\u5e94\u7528\u4e2d\uff0c\u73b0\u6210\u7684QP\u6c42\u89e3\u5668\u53ef\u80fd\u6210\u4e3a\u74f6\u9888\u3002", "method": "\u5c06\u72b6\u6001\u7a7a\u95f4\u5212\u5206\u4e3a\u82e5\u5e72\u533a\u57df\uff0c\u5728\u6bcf\u4e2a\u533a\u57df\u63a8\u5bfc\u4e00\u6761\u95ed\u5f0f\u63a7\u5236\u5f8b\u4ee5\u5b9e\u73b0\u7b49\u6548\u7684CBF\u7ea6\u675f\uff1b\u8bbe\u8ba1\u533a\u57df\u53d8\u5316\u68c0\u6d4b\u673a\u5236\uff0c\u5728\u533a\u57df\u4e4b\u95f4\u65f6\u4f7f\u7528\u8be5\u533a\u57df\u7684\u95ed\u5f0f\u89e3\uff0c\u5728\u533a\u57df\u672a\u53d8\u5316\u65f6\u590d\u7528\uff1b\u5b9e\u73b0\u8d44\u6e90\u611f\u77e5\u7684CBF\u5b89\u5168\u6ee4\u6ce2\u5668\u3002", "result": "\u5728\u4e00\u7cfb\u5217\u793a\u4f8b\u4e2d\u5c55\u793a\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8986\u76d6\u822a\u5929\u63a7\u5236\u548c\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u7b49\u573a\u666f\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u9700\u6c42\u5e76\u4fdd\u6301\u5b89\u5168\u6027\u3002", "conclusion": "\u533a\u57df\u5206\u6bb5\u7684\u95ed\u5f0fCBF\u5b89\u5168\u6ee4\u6ce2\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u9891\u63a7\u5236\u4e2d\u7684\u9ad8\u6548\u5b9e\u73b0\u8def\u5f84\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u4e5f\u9700\u6ce8\u610f\u533a\u57df\u5212\u5206\u7684\u4fdd\u5b88\u6027\u3001\u8fb9\u754c\u5904\u7406\u548c\u5207\u6362\u5f00\u9500\u7b49\u95ee\u9898\u3002"}}
{"id": "2512.09938", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.09938", "abs": "https://arxiv.org/abs/2512.09938", "authors": ["Balakumar Ravindranath Kunthu", "Ranganath Nagesh Taware", "Sathish Krishna Anumula"], "title": "Blockchain-Anchored Audit Trail Model for Transparent Inter-Operator Settlement", "comment": null, "summary": "The telecommunications and financial services industries face substantial challenges in inter-operator settlement processes, characterized by extended reconciliation cycles, high transaction costs, and limited real-time transparency. Traditional settlement mechanisms rely on multiple intermediaries and manual procedures, resulting in settlement periods exceeding 120 days with operational costs consuming approximately 5 percent of total revenue. This research presents a blockchain-anchored audit trail model enabling transparent, immutable, and automated inter-operator settlement. The framework leverages distributed ledger technology, smart contract automation, and cryptographic verification to establish a unified, tamper-proof transaction record. Empirical evaluation demonstrates 87 percent reduction in transaction fees, settlement cycle compression from 120 days to 3 minutes, and 100 percent audit trail integrity. Smart contract automation reduces manual intervention by 92 percent and eliminates 88 percent of settlement disputes. Market analysis indicates institutional adoption accelerated from 8 percent in 2020 to 52 percent by April 2024, with projected industry investment reaching 9.2 billion USD annually. The framework addresses scalability (12,000 transactions per second), interoperability, and regulatory compliance across multiple jurisdictions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u533a\u5757\u94fe\u951a\u5b9a\u7684\u5ba1\u8ba1\u8ffd\u8e2a\u6a21\u578b\uff0c\u7528\u4ee5\u5b9e\u73b0\u8de8\u8fd0\u8425\u5546\u6e05\u7b97\u7684\u900f\u660e\u3001\u4e0d\u53ef\u7be1\u6539\u548c\u81ea\u52a8\u5316\uff0c\u663e\u8457\u964d\u4f4e\u6210\u672c\u548c\u65f6\u95f4\uff0c\u5177\u5907\u9ad8\u541e\u5410\u3001\u4e92\u64cd\u4f5c\u6027\u548c\u5408\u89c4\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u8de8\u8fd0\u8425\u5546\u6e05\u7b97\u4e2d\u7684\u957f\u5468\u671f\u3001\u9ad8\u6210\u672c\u4e0e\u4f4e\u900f\u660e\u5ea6\u7b49\u75db\u70b9\uff1b\u73b0\u6709\u7cfb\u7edf\u4f9d\u8d56\u591a\u4e2d\u4ecb\u4e0e\u4eba\u5de5\uff0c\u96be\u4ee5\u5b9e\u73b0\u5feb\u901f\u5bf9\u8d26\u3002", "method": "\u57fa\u4e8e\u5206\u5e03\u5f0f\u8d26\u672c\u3001\u667a\u80fd\u5408\u7ea6\u548c\u52a0\u5bc6\u9a8c\u8bc1\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u4e0d\u53ef\u7be1\u6539\u4ea4\u6613\u8bb0\u5f55\u548c\u81ea\u52a8\u5316\u6e05\u7b97\u6d41\u7a0b\uff0c\u63d0\u4f9b\u8de8\u57df\u5ba1\u8ba1\u8ffd\u8e2a\u4e0e\u5408\u89c4\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c/\u8bc4\u4f30\u663e\u793a\u4ea4\u6613\u8d39\u7528\u4e0b\u964d87%\uff0c\u6e05\u7b97\u5468\u671f\u4ece120\u5929\u7f29\u77ed\u52303\u5206\u949f\uff0c\u5ba1\u8ba1\u8f68\u8ff9\u5b8c\u6574\u6027\u8fbe100%\uff1b\u667a\u80fd\u5408\u7ea6\u5c06\u4eba\u5de5\u5e72\u9884\u964d\u4f4e92%\uff0c\u6e05\u7b97\u4e89\u8bae\u51cf\u5c1188%\uff1b\u5e02\u573a\u5206\u6790\u663e\u793a\u673a\u6784\u91c7\u7528\u7387\u4ece2020\u5e74\u76848%\u589e\u81f32024\u5e744\u6708\u768452%\uff0c\u884c\u4e1a\u6295\u8d44\u9884\u6d4b\u4e3a9.2\u5341\u4ebf\u7f8e\u5143/\u5e74\u3002", "conclusion": "\u8be5\u6846\u67b6\u89e3\u51b3\u53ef\u6269\u5c55\u6027\u3001\u4e92\u64cd\u4f5c\u6027\u53ca\u8de8\u53f8\u6cd5\u8f96\u5408\u89c4\u6027\u6311\u6218\uff0c\u5177\u5907\u6bcf\u79d212,000\u7b14\u4ea4\u6613\u7684\u541e\u5410\u80fd\u529b\u3002"}}
{"id": "2512.09972", "categories": ["cs.LG", "cs.CL", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.09972", "abs": "https://arxiv.org/abs/2512.09972", "authors": ["Kesheng Chen", "Wenjian Luo", "Zhenqian Zhu", "Yamin Hu", "Yiya Xi"], "title": "BAMBO: Construct Ability and Efficiency LLM Pareto Set via Bayesian Adaptive Multi-objective Block-wise Optimization", "comment": null, "summary": "Constructing a Pareto set is pivotal for navigating the capability-efficiency trade-offs in Large Language Models (LLMs); however, existing merging techniques remain inadequate for this task. Coarse-grained, model-level methods yield only a sparse set of suboptimal solutions, while fine-grained, layer-wise approaches suffer from the \"curse of dimensionality,\" rendering the search space computationally intractable. To resolve this dichotomy, we propose BAMBO (Bayesian Adaptive Multi-objective Block-wise Optimization), a novel framework that automatically constructs the LLM Pareto set. BAMBO renders the search tractable by introducing a Hybrid Optimal Block Partitioning strategy. Formulated as a 1D clustering problem, this strategy leverages a dynamic programming approach to optimally balance intra-block homogeneity and inter-block information distribution, thereby dramatically reducing dimensionality without sacrificing critical granularity. The entire process is automated within an evolutionary loop driven by the q-Expected Hypervolume Improvement (qEHVI) acquisition function. Experiments demonstrate that BAMBO discovers a superior and more comprehensive Pareto frontier than baselines, enabling agile model selection tailored to diverse operational constraints. Code is available at: https://github.com/xin8coder/BAMBO.", "AI": {"tldr": "\u63d0\u51fa BAMBOO\uff1a\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u7684\u81ea\u9002\u5e94\u591a\u76ee\u6807\u5206\u5757\u4f18\u5316\u6846\u67b6\uff0c\u81ea\u52a8\u6784\u5efa\u5927\u8bed\u8a00\u6a21\u578b\u7684 Pareto \u524d\u6cbf\uff0c\u901a\u8fc7\u5206\u5757\u805a\u7c7b\u4e0e\u52a8\u6001\u89c4\u5212\u964d\u4f4e\u7ef4\u5ea6\uff0c\u5e76\u5728\u8fdb\u5316\u5faa\u73af\u4e2d\u7528 qEHVI \u83b7\u53d6\u9ad8\u6548\u89e3\u96c6\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684 Pareto \u524d\u6cbf\u6784\u5efa\u65b9\u6cd5\u8981\u4e48\u662f\u7c97\u7c92\u5ea6\u7684\u6a21\u578b\u7ea7\u6574\u5408\uff0c\u5f97\u5230\u7a00\u758f\u4e14\u6b21\u4f18\u7684\u89e3\u96c6\uff1b\u8981\u4e48\u662f\u7c92\u5ea6\u592a\u7ec6\u3001\u9010\u5c42\u641c\u7d22\uff0c\u9762\u4e34\u7ef4\u6570\u707e\u96be\uff0c\u8ba1\u7b97\u4ee3\u4ef7\u9ad8\u3002\u9700\u5728\u80fd\u529b-\u6548\u7387\u4e4b\u95f4\u7684\u6298\u8877\u4e0a\u9ad8\u6548\u3001\u5168\u9762\u5730\u6784\u5efa Pareto \u96c6\u3002", "method": "\u63d0\u51fa BAMBOO \u6846\u67b6\uff0c\u6838\u5fc3\u5728\u4e8e\u6df7\u5408\u6700\u4f18\u5206\u5757\u5206\u533a\uff08Hybrid Optimal Block Partitioning\uff0cHOBP\uff09\u3002\u5c06\u641c\u7d22\u95ee\u9898\u5efa\u6a21\u4e3a\u4e00\u7ef4\u805a\u7c7b\uff0c\u901a\u8fc7\u52a8\u6001\u89c4\u5212\u5728\u5757\u5185\u540c\u8d28\u6027\u4e0e\u5757\u95f4\u4fe1\u606f\u5206\u5e03\u4e4b\u95f4\u5b9e\u73b0\u6700\u4f18\u5e73\u8861\uff0c\u4ece\u800c\u5728\u4e0d\u727a\u7272\u9897\u7c92\u5ea6\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u7ef4\u5ea6\u3002\u6574\u4e2a\u8fc7\u7a0b\u5728\u4ee5 q-Expected Hypervolume Improvement\uff08qEHVI\uff09\u4e3a\u91c7\u96c6\u51fd\u6570\u7684\u8fdb\u5316\u5faa\u73af\u4e2d\u81ea\u52a8\u5316\u6267\u884c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a BAMBOO \u80fd\u53d1\u73b0\u6bd4\u57fa\u7ebf\u66f4\u4f18\u4e14\u66f4\u5b8c\u6574\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u652f\u6301\u9488\u5bf9\u4e0d\u540c\u8fd0\u8425\u7ea6\u675f\u7684\u7075\u6d3b\u6a21\u578b\u9009\u62e9\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u4e14\u9ad8\u6548\u7684 LLM Pareto \u96c6\u6784\u5efa\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5757\u805a\u7c7b\u964d\u7ef4\u5e76\u7ef4\u6301\u5fc5\u8981\u7684\u7c92\u5ea6\uff0c\u4ece\u800c\u5728\u80fd\u529b-\u6548\u7387\u6743\u8861\u4e2d\u5b9e\u73b0\u66f4\u4f18\u7684\u591a\u76ee\u6807\u4f18\u5316\u3002"}}
{"id": "2512.10194", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10194", "abs": "https://arxiv.org/abs/2512.10194", "authors": ["Jiaxin Hou", "Kexin Wang", "Ruolin Li", "Jong-shi Pang"], "title": "Traffic Equilibrium in Mixed-Autonomy Network with Capped Customer Waiting", "comment": "under review for journal", "summary": "This paper develops a unified modeling framework to capture the equilibrium-state interactions among ride-hailing companies, travelers, and traffic of mixed-autonomy transportation networks. Our framework integrates four interrelated sub-modules: (i) the operational behavior of representative ride-hailing Mixed-Fleet Traffic Network Companies (MiFleet TNCs) managing autonomous vehicle (AV) and human-driven vehicle (HV) fleets, (ii) traveler mode-choice decisions taking into account travel costs and waiting time, (iii) capped customer waiting times to reflect the option available to travelers not to wait for TNCs' service beyond his/her patience and to resort to existing travel modes, and (iv) a flow-dependent traffic congestion model for travel times. A key modeling feature distinguishes AVs and HVs across the pickup and service (customer-on-board) stages: AVs follow Wardrop pickup routes but may deviate during service under company coordination, whereas HVs operate in the reverse manner. The overall framework is formulated as a Nonlinear Complementarity Problem (NCP), which is equivalent to a Variational Inequality(VI) formulation based on which the existence of a variational equilibrium solution to the traffic model is established. Numerical experiments examine how AV penetration and Wardrop relaxation factors, which bound route deviation, affect company, traveler, and system performance to various degrees. The results provide actionable insights for policymakers on regulating AV adoption and company vehicle deviation behavior in modern-day traffic systems that are fast changing due to the advances in technology and information accessibility.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.09953", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.09953", "abs": "https://arxiv.org/abs/2512.09953", "authors": ["Mohammad M Maheri", "Sunil Cotterill", "Alex Davidson", "Hamed Haddadi"], "title": "ZK-APEX: Zero-Knowledge Approximate Personalized Unlearning with Executable Proofs", "comment": null, "summary": "Machine unlearning aims to remove the influence of specific data points from a trained model to satisfy privacy, copyright, and safety requirements. In real deployments, providers distribute a global model to many edge devices, where each client personalizes the model using private data. When a deletion request is issued, clients may ignore it or falsely claim compliance, and providers cannot check their parameters or data. This makes verification difficult, especially because personalized models must forget the targeted samples while preserving local utility, and verification must remain lightweight on edge devices.\n  We introduce ZK APEX, a zero-shot personalized unlearning method that operates directly on the personalized model without retraining. ZK APEX combines sparse masking on the provider side with a small Group OBS compensation step on the client side, using a blockwise empirical Fisher matrix to create a curvature-aware update designed for low overhead. Paired with Halo2 zero-knowledge proofs, it enables the provider to verify that the correct unlearning transformation was applied without revealing any private data or personalized parameters.\n  On Vision Transformer classification tasks, ZK APEX recovers nearly all personalization accuracy while effectively removing the targeted information. Applied to the OPT125M generative model trained on code data, it recovers around seventy percent of the original accuracy. Proof generation for the ViT case completes in about two hours, more than ten million times faster than retraining-based checks, with less than one gigabyte of memory use and proof sizes around four hundred megabytes. These results show the first practical framework for verifiable personalized unlearning on edge devices.", "AI": {"tldr": "\u63d0\u51fa ZK APEX\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u96f6\u91cd\u8bad\u7ec3\u7684\u4e2a\u6027\u5316\u53bb\u5b66\u4e60\uff0c\u7ed3\u5408\u63d0\u4f9b\u65b9\u7684\u7a00\u758f\u5c4f\u853d\u548c\u5ba2\u6237\u7aef\u7684\u5c0f\u89c4\u6a21 Group OBS \u8865\u507f\uff0c\u4ee5\u53ca Halo2 \u7684\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u5728\u4e0d\u66b4\u9732\u79c1\u6709\u6570\u636e\u6216\u4e2a\u6027\u5316\u53c2\u6570\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u7684\u53bb\u5b66\u4e60\u3002", "motivation": "\u5728\u5168\u7403\u6a21\u578b\u5206\u53d1\u5230\u5927\u91cf\u8fb9\u7f18\u8bbe\u5907\u3001\u7528\u6237\u4f7f\u7528\u79c1\u6709\u6570\u636e\u8fdb\u884c\u672c\u5730\u4e2a\u6027\u5316\u7684\u60c5\u5883\u4e0b\uff0c\u5220\u9664\u8bf7\u6c42\u53ef\u80fd\u88ab\u5ffd\u7565\u6216\u88ab\u4f2a\u9020\uff0c\u63d0\u4f9b\u65b9\u4e5f\u96be\u4ee5\u9a8c\u8bc1\u6bcf\u4e2a\u8bbe\u5907\u7684\u53c2\u6570\u548c\u6570\u636e\u3002\u9700\u8981\u4e00\u4e2a\u4f4e\u5f00\u9500\u4e14\u53ef\u9a8c\u8bc1\u7684\u53bb\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u5c3d\u91cf\u4fdd\u7559\u672c\u5730\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\uff0c\u786e\u4fdd\u5220\u9664\u4fe1\u606f\u88ab\u771f\u6b63\u5fd8\u8bb0\uff0c\u5e76\u4e14\u9a8c\u8bc1\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u4fdd\u6301\u8f7b\u91cf\u3002", "method": "\u63d0\u51fa ZK APEX\uff1a\u76f4\u63a5\u5728\u4e2a\u6027\u5316\u6a21\u578b\u4e0a\u5b9e\u73b0\u53bb\u5b66\u4e60\uff0c\u65e0\u9700\u518d\u8bad\u7ec3\u3002\u901a\u8fc7\u63d0\u4f9b\u65b9\u7684\u7a00\u758f\u5c4f\u853d\u4e0e\u5ba2\u6237\u7aef\u7684\u5c0f\u578b Group OBS \u8865\u507f\uff0c\u4ee5\u53ca\u57fa\u4e8e\u5757\u7684\u7ecf\u9a8cFisher\u77e9\u9635\u6765\u6784\u9020\u5177\u6709\u66f2\u7387\u611f\u77e5\u7684\u66f4\u65b0\uff0c\u4ee5\u964d\u4f4e\u5f00\u9500\u3002\u518d\u7ed3\u5408 Halo2 \u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u8bc1\u660e\u6b63\u786e\u7684\u53bb\u5b66\u4e60\u53d8\u6362\u5df2\u5e94\u7528\u4e14\u4e0d\u66b4\u9732\u79c1\u6709\u6570\u636e\u6216\u4e2a\u6027\u5316\u53c2\u6570\u3002", "result": "\u5728\u89c6\u89c9Transformer\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0c\u51e0\u4e4e\u6062\u590d\u6240\u6709\u4e2a\u6027\u5316\u7cbe\u5ea6\uff0c\u540c\u65f6\u6709\u6548\u53bb\u9664\u76ee\u6807\u4fe1\u606f\uff1b\u5728 OPT125M \u7684\u4ee3\u7801\u6570\u636e\u6a21\u578b\u4e0a\uff0c\u6062\u590d\u7ea6\u539f\u59cb\u7cbe\u5ea6\u768470%\u3002\u8bc1\u636e\u751f\u6210\u5bf9 ViT \u6848\u4f8b\u7ea6\u4e24\u5c0f\u65f6\uff0c\u662f\u57fa\u4e8e\u91cd\u65b0\u8bad\u7ec3\u7684\u68c0\u67e5\u901f\u5ea6\u7684\u5341\u4e07\u500d\u7ea7\u522b\u63d0\u5347\uff0c\u5185\u5b58\u8017<1GB\uff0c\u8bc1\u636e\u5927\u5c0f\u7ea6400MB\u3002\u5219\u9996\u6b21\u5448\u73b0\u4e86\u4e00\u4e2a\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u53ef\u884c\u7684\u53ef\u9a8c\u8bc1\u4e2a\u6027\u5316\u53bb\u5b66\u4e60\u6846\u67b6\u3002", "conclusion": "\u672c\u5de5\u4f5c\u9996\u6b21\u5c06 verifiable personalized unlearning \u5f15\u5165\u5230\u53ef\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fd0\u884c\u7684\u5b9e\u9645\u6846\u67b6\u4e2d\uff0c\u7ed3\u5408\u5206\u5e03\u5f0f\u6a21\u578b\u3001\u8f7b\u91cf\u66f4\u65b0\u4e0e\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u517c\u987e\u9690\u79c1\u3001\u5408\u89c4\u4e0e\u6027\u80fd\uff0c\u5f00\u542f\u4e86\u8fb9\u7f18\u7aef\u53ef\u9a8c\u8bc1\u53bb\u5b66\u4e60\u7684\u65b0\u65b9\u5411\u3002"}}
{"id": "2512.10016", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10016", "abs": "https://arxiv.org/abs/2512.10016", "authors": ["Marvin Alles", "Xingyuan Zhang", "Patrick van der Smagt", "Philip Becker-Ehmck"], "title": "Latent Action World Models for Control with Unlabeled Trajectories", "comment": null, "summary": "Inspired by how humans combine direct interaction with action-free experience (e.g., videos), we study world models that learn from heterogeneous data. Standard world models typically rely on action-conditioned trajectories, which limits effectiveness when action labels are scarce. We introduce a family of latent-action world models that jointly use action-conditioned and action-free data by learning a shared latent action representation. This latent space aligns observed control signals with actions inferred from passive observations, enabling a single dynamics model to train on large-scale unlabeled trajectories while requiring only a small set of action-labeled ones. We use the latent-action world model to learn a latent-action policy through offline reinforcement learning (RL), thereby bridging two traditionally separate domains: offline RL, which typically relies on action-conditioned data, and action-free training, which is rarely used with subsequent RL. On the DeepMind Control Suite, our approach achieves strong performance while using about an order of magnitude fewer action-labeled samples than purely action-conditioned baselines. These results show that latent actions enable training on both passive and interactive data, which makes world models learn more efficiently.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6f5c\u5728\u884c\u52a8\uff08latent-action\uff09\u4e16\u754c\u6a21\u578b\uff0c\u7ed3\u5408\u884c\u52a8\u6709\u6761\u4ef6\u548c\u65e0\u884c\u52a8\u6570\u636e\uff0c\u901a\u8fc7\u5b66\u4e60\u5171\u4eab\u7684\u6f5c\u5728\u884c\u52a8\u8868\u793a\u6765\u5bf9\u9f50\u89c2\u6d4b\u5230\u7684\u63a7\u5236\u4fe1\u53f7\u4e0e\u4ece\u88ab\u52a8\u89c2\u5bdf\u4e2d\u63a8\u65ad\u7684\u884c\u52a8\uff0c\u4f7f\u5355\u4e00\u52a8\u529b\u5b66\u6a21\u578b\u5373\u53ef\u5728\u5927\u89c4\u6a21\u672a\u6807\u8bb0\u8f68\u8ff9\u548c\u5c11\u91cf\u5e26\u6807\u7b7e\u7684\u884c\u52a8\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u5e76\u901a\u8fc7\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u6f5c\u5728\u884c\u52a8\u7b56\u7565\u3002\u5728 DeepMind Control Suite \u4e0a\uff0c\u4e0e\u7eaf\u884c\u52a8\u6709\u6761\u4ef6\u57fa\u7ebf\u76f8\u6bd4\uff0c\u4f7f\u7528\u6807\u6ce8\u884c\u52a8\u7684\u6570\u636e\u6837\u672c\u663e\u8457\u51cf\u5c11\u4e00\u4e2a\u6570\u91cf\u7ea7\u91cf\u7ea7\u4e14\u6027\u80fd\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u4e16\u754c\u6a21\u578b\u901a\u5e38\u4f9d\u8d56\u5e26\u884c\u52a8\u6807\u7b7e\u7684\u8f68\u8ff9\uff0c\u884c\u52a8\u6807\u7b7e\u7a00\u7f3a\u65f6\u6548\u679c\u53d7\u9650\u3002\u5e0c\u671b\u7ed3\u5408\u5927\u91cf\u65e0\u884c\u52a8\u6570\u636e\uff08\u5982\u88ab\u52a8\u89c2\u6d4b\uff09\u4e0e\u5c11\u91cf\u5e26\u6807\u7b7e\u7684\u6570\u636e\uff0c\u63d0\u5347\u6570\u636e\u5229\u7528\u7387\u4e0e\u5b66\u4e60\u6548\u7387\uff0c\u5e76\u63a2\u7d22\u5982\u4f55\u5c06\u79bb\u7ebfRL\u4e0e\u65e0\u884c\u52a8\u8bad\u7ec3\u7ed3\u5408\u3002", "method": "\u63d0\u51fa\u4e00\u7c7b\u6f5c\u5728\u884c\u52a8\u4e16\u754c\u6a21\u578b\uff0c\u5b66\u4e60\u5171\u4eab\u7684\u6f5c\u5728\u884c\u52a8\u8868\u793a\uff0c\u4f7f\u89c2\u6d4b\u5230\u7684\u63a7\u5236\u4fe1\u53f7\u4e0e\u88ab\u52a8\u89c2\u6d4b\u4e2d\u63a8\u65ad\u7684\u52a8\u4f5c\u5bf9\u9f50\uff1b\u5355\u4e00\u52a8\u529b\u5b66\u6a21\u578b\u5728\u672a\u6807\u8bb0\u8f68\u8ff9\u4e0a\u5927\u89c4\u6a21\u8bad\u7ec3\uff0c\u540c\u65f6\u7528\u5c11\u91cf\u5e26\u6807\u7b7e\u6570\u636e\u5fae\u8c03\u3002\u968f\u540e\u901a\u8fc7\u79bb\u7ebfRL\u5728\u6f5c\u5728\u884c\u52a8\u7a7a\u95f4\u4e0a\u5b66\u4e60\u7b56\u7565\uff0c\u5b9e\u73b0\u4ece\u79bb\u7ebf\u6570\u636e\u5230\u884c\u52a8\u81ea\u7531\u6570\u636e\u7684\u65e0\u7f1d\u7ed3\u5408\u3002", "result": "\u5728 DeepMind Control Suite \u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u4f7f\u7528\u8fdc\u5c11\u4e8e\u7eaf\u884c\u52a8\u6709\u6761\u4ef6\u57fa\u7ebf\u7684\u6807\u6ce8\u6570\u636e\u60c5\u51b5\u4e0b\uff0c\u4ecd\u5b9e\u73b0\u4e86\u5f3a\u52b2\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u6f5c\u5728\u884c\u52a8\u4f7f\u4e16\u754c\u6a21\u578b\u80fd\u591f\u5728\u88ab\u52a8\u548c\u4ea4\u4e92\u6570\u636e\u4e0a\u5171\u540c\u8bad\u7ec3\uff0c\u4ece\u800c\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u548c\u6570\u636e\u5229\u7528\u7387\uff0c\u63a8\u52a8\u884c\u52a8\u81ea\u7531\u8bad\u7ec3\u4e0e\u79bb\u7ebfRL\u7684\u878d\u5408\u3002"}}
{"id": "2512.10246", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10246", "abs": "https://arxiv.org/abs/2512.10246", "authors": ["Hongyu Li", "Shanpu Shen"], "title": "Antenna Coding Design for Multi-User Transmissions Using Pixel Antennas", "comment": "12 pages, 9 figures, submitted to IEEE journal for possible publication", "summary": "This work investigates exploiting the potential of pixel antennas, which are a reconfigurable antenna technology that can flexibly adjust the antenna characteristics through antenna coding, in multi-user transmissions. To that end, we propose a multi-user multi-input single-output (MISO) pixel antenna system, which deploys the pixel antenna at users, and develop the system model including pixel antenna with antenna coding and multi-user beamspace channels. Aiming at maximizing the sum rate performance, we first propose an algorithm to alternatively design the precoding at the transmitter and the antenna coding at users, which explores the performance boundary for the proposed multi-user MISO pixel antenna system. To reduce the computational complexity, we propose a codebook-based antenna coding design algorithm, where the antenna coder is online optimized from an offline codebook. To further enhance the computation efficiency, we propose a hierarchical codebook-based antenna coding design that uses a multi-layer hierarchical search to achieve a better performance-complexity trade-off. Simulation results show that, adopting the proposed algorithms, the multi-user MISO pixel antenna system can always outperform conventional multi-user MISO systems with fixed antennas. More importantly, results validate that the proposed (hierarchical) codebook-based algorithms can significantly reduce the computational complexity while maintaining a satisfactory sum rate performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u7528\u6237MISO\u50cf\u7d20\u5929\u7ebf\u7cfb\u7edf\uff0c\u7528\u6237\u7aef\u91c7\u7528\u5929\u7ebf\u7f16\u7801\uff0c\u53d1\u5c04\u7aef\u8fdb\u884c\u524d\u5411/\u7ef4\u5ea6\u8bbe\u8ba1\u7684\u4ea4\u66ff\u4f18\u5316\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u79bb\u7ebf\u548c\u5206\u5c42\u4ee3\u7801\u672c\u7684\u5929\u7ebf\u7f16\u7801\u8bbe\u8ba1\u4ee5\u964d\u4f4e\u590d\u6742\u5ea6\uff1b\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u7cfb\u7edf\u5728\u548c\u901f\u7387\u65b9\u9762\u4f18\u4e8e\u56fa\u5b9a\u5929\u7ebf\u7684\u5bf9\u6bd4\u7cfb\u7edf\uff0c\u540c\u65f6\u5206\u5c42\u4ee3\u7801\u672c\u5728\u590d\u6742\u5ea6\u4e0e\u6027\u80fd\u4e4b\u95f4\u63d0\u4f9b\u66f4\u4f18\u7684\u6298\u8877\u3002", "motivation": "\u50cf\u7d20\u5929\u7ebf\u4f5c\u4e3a\u53ef\u91cd\u914d\u7f6e\u7684\u5929\u7ebf\u6280\u672f\uff0c\u901a\u8fc7\u5929\u7ebf\u7f16\u7801\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u7075\u6d3b\u8c03\u8282\u8f90\u5c04\u7279\u6027\u3002\u5c06\u5176\u5e94\u7528\u5230\u591a\u7528\u6237MISO\u573a\u666f\u6709\u6f5c\u529b\u63d0\u5347\u7cfb\u7edf\u7684\u548c\u901f\u7387\uff0c\u4f46\u9700\u8981\u6709\u6548\u7684\u8054\u5408\u8bbe\u8ba1\u548c\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\u6765\u5b9e\u73b0\u5728\u7ebf\u81ea\u9002\u5e94\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u591a\u7528\u6237MISO\u50cf\u7d20\u5929\u7ebf\u7cfb\u7edf\uff0c\u5305\u542b\u5bf9\u50cf\u7d20\u5929\u7ebf\u7684\u7f16\u7801\u5efa\u6a21\u548c\u591a\u7528\u6237\u6ce2\u675f\u7a7a\u95f4\u4fe1\u9053\u5efa\u6a21\u3002\u901a\u8fc7\u4ea4\u66ff\u8bbe\u8ba1\u5b9e\u73b0\u53d1\u5c04\u7aef\u524d\u9988/\u6ce2\u675f\u5f62\u6210\u548c\u7528\u6237\u7aef\u5929\u7ebf\u7f16\u7801\u7684\u8054\u5408\u4f18\u5316\u3002\u4e3a\u964d\u4f4e\u8ba1\u7b97\u91cf\uff0c\u63d0\u51fa\u57fa\u4e8e\u79bb\u7ebf\u4ee3\u7801\u672c\u7684\u5929\u7ebf\u7f16\u7801\u8bbe\u8ba1\uff08\u5728\u7ebf\u4ece\u4ee3\u7801\u672c\u4e2d\u9009\u53d6\u6700\u4f18\u7f16\u7801\uff09\uff0c\u5e76\u8fdb\u4e00\u6b65\u63d0\u51fa\u5206\u5c42\u4ee3\u7801\u672c\u7684\u8bbe\u8ba1\uff0c\u901a\u8fc7\u591a\u5c42\u5206\u5c42\u641c\u7d22\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd-\u590d\u6742\u5ea6\u6298\u8877\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7684\u591a\u7528\u6237MISO\u50cf\u7d20\u5929\u7ebf\u7cfb\u7edf\u5728\u5927\u591a\u6570\u573a\u666f\u4e0b\u4f18\u4e8e\u91c7\u7528\u56fa\u5b9a\u5929\u7ebf\u7684\u4f20\u7edf\u591a\u7528\u6237MISO\u7cfb\u7edf\u3002\u5e76\u4e14\u5206\u5c42\u4ee3\u7801\u672c\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u7ef4\u6301\u4ee4\u4eba\u6ee1\u610f\u7684\u548c\u901f\u7387\u6027\u80fd\u3002", "conclusion": "\u50cf\u7d20\u5929\u7ebf\u7ed3\u5408\u4ee3\u7801\u672c\u5316\u8bbe\u8ba1\u53ef\u4ee5\u5728\u591a\u7528\u6237MISO\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u7684\u548c\u901f\u7387\u4e14\u5177\u6709\u66f4\u4f4e\u7684\u590d\u6742\u5ea6\uff1b\u5206\u5c42\u4ee3\u7801\u672c\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u6027\u80fd-\u590d\u6742\u5ea6\u6743\u8861\uff0c\u9002\u5408\u5728\u7ebf\u81ea\u9002\u5e94\u573a\u666f\u3002"}}
{"id": "2512.10032", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.10032", "abs": "https://arxiv.org/abs/2512.10032", "authors": ["Jan Marco Ruiz de Vargas", "Kirtan Padh", "Niki Kilbertus"], "title": "Cluster-Dags as Powerful Background Knowledge For Causal Discovery", "comment": "23 pages, 5 figures", "summary": "Finding cause-effect relationships is of key importance in science. Causal discovery aims to recover a graph from data that succinctly describes these cause-effect relationships. However, current methods face several challenges, especially when dealing with high-dimensional data and complex dependencies. Incorporating prior knowledge about the system can aid causal discovery. In this work, we leverage Cluster-DAGs as a prior knowledge framework to warm-start causal discovery. We show that Cluster-DAGs offer greater flexibility than existing approaches based on tiered background knowledge and introduce two modified constraint-based algorithms, Cluster-PC and Cluster-FCI, for causal discovery in the fully and partially observed setting, respectively. Empirical evaluation on simulated data demonstrates that Cluster-PC and Cluster-FCI outperform their respective baselines without prior knowledge.", "AI": {"tldr": "Using Cluster-DAGs as a prior knowledge framework to warm-start causal discovery, introducing Cluster-PC and Cluster-FCI for fully and partially observed settings, which outperform their baselines without prior knowledge on simulated data.", "motivation": "To address challenges in causal discovery under high-dimensional data and complex dependencies by leveraging a flexible prior knowledge structure.", "method": "Introduce Cluster-DAGs as a prior framework and develop two modified constraint-based algorithms, Cluster-PC (fully observed) and Cluster-FCI (partially observed) for causal discovery.", "result": "On simulated data, Cluster-PC and Cluster-FCI outperform their respective baselines without prior knowledge.", "conclusion": "Cluster-DAGs offer greater flexibility than existing tiered background knowledge, and the proposed algorithms improve causal discovery when prior knowledge is available."}}
{"id": "2512.10447", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10447", "abs": "https://arxiv.org/abs/2512.10447", "authors": ["Kaisei Higeta", "Masakatsu Ogawa", "Tomoki Murakami", "Kazuya Ohara", "Shinya Otsuki"], "title": "Outdoor Crowd Flow Estimation Using RSRP from Commercial LTE Base Station: A Field Study", "comment": "6 pages, 15 figures, Accepted for presentation at the International Conference on Information Networking (ICOIN) 2026", "summary": "With the advent of the 6G era, Integrated Sensing and Communications (ISAC) has attracted increasing attention. One representative of use cases is crowd flow estimation on outdoor streets. However, most existing studies have focused on indoor environments or vehicles, and demonstrations of outdoor crowd flow estimation using commercial LTE base station remain limited. This study addresses this use case and proposes an analysis of a crowd flow estimation method using Reference Signal Received Power (RSRP) obtained from a commercial LTE base station. Specifically, pedestrian counts derived from a camera-based object recognition algorithm were associated with the variance of RSRP. The features obtained from the variance were quantitatively evaluated by combining a CatBoost regression model with SHapley Additive exPlanations (SHAP) analysis. Through this investigation, we clarified that an optimal variance window size for RSRP is 0.1 to 0.2 seconds and that enlarging the counting area increased the features obtained from the variance of RSRP, for machine learning. Consequently, this study is the first to quantitatively demonstrate the effectiveness of outdoor crowd flow estimation using commercial LTE, while also revealing the characteristic behavior of variance window size and counting area size in feature design.", "AI": {"tldr": " outdoor crowd flow estimation using commercial LTE via RSRP variance; optimal variance window 0.1\u20130.2 s; larger counting area yields more predictive features; first quantitative demonstration with LTE+ISAC.", "motivation": "Address the gap in outdoor crowd flow estimation for ISAC using real-world cellular infrastructure, beyond indoor or vehicle-focused studies and limited LTE demonstrations.", "method": "A camera-based pedestrian counting method provides counts which are linked to the variance of RSRP from a commercial LTE base station. Features derived from this variance are fed into a CatBoost regression model and interpreted with SHAP. The study also investigates how variance window size and counting area affect feature design.", "result": "Identified an optimal RSRP variance window of 0.1\u20130.2 seconds. Found that enlarging the counting area increases the features obtainable from the variance of RSRP, improving model inputs. Demonstrates, quantitatively, the effectiveness of outdoor crowd flow estimation using commercial LTE.", "conclusion": "The work provides the first quantitative demonstration of outdoor crowd flow estimation with commercial LTE and reveals how variance window size and counting area impact feature design for ML-based ISAC applications."}}
{"id": "2512.10033", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10033", "abs": "https://arxiv.org/abs/2512.10033", "authors": ["Sarwan Ali"], "title": "Robust Gradient Descent via Heavy-Ball Momentum with Predictive Extrapolation", "comment": null, "summary": "Accelerated gradient methods like Nesterov's Accelerated Gradient (NAG) achieve faster convergence on well-conditioned problems but often diverge on ill-conditioned or non-convex landscapes due to aggressive momentum accumulation. We propose Heavy-Ball Synthetic Gradient Extrapolation (HB-SGE), a robust first-order method that combines heavy-ball momentum with predictive gradient extrapolation. Unlike classical momentum methods that accumulate historical gradients, HB-SGE estimates future gradient directions using local Taylor approximations, providing adaptive acceleration while maintaining stability. We prove convergence guarantees for strongly convex functions and demonstrate empirically that HB-SGE prevents divergence on problems where NAG and standard momentum fail. On ill-conditioned quadratics (condition number $\u03ba=50$), HB-SGE converges in 119 iterations while both SGD and NAG diverge. On the non-convex Rosenbrock function, HB-SGE achieves convergence in 2,718 iterations where classical momentum methods diverge within 10 steps. While NAG remains faster on well-conditioned problems, HB-SGE provides a robust alternative with speedup over SGD across diverse landscapes, requiring only $O(d)$ memory overhead and the same hyperparameters as standard momentum.", "AI": {"tldr": "HB-SGE is a robust first-order optimizer that combines heavy-ball momentum with predictive gradient extrapolation, enabling stable acceleration on ill-conditioned and non-convex problems where NAG and standard momentum can diverge.", "motivation": "Nesterov's Accelerated Gradient (NAG) accelerates well-conditioned problems but often diverges on ill-conditioned or non-convex landscapes due to aggressive momentum accumulation; there is a need for a first-order method that maintains acceleration while ensuring stability across diverse landscapes.", "method": "HB-SGE uses heavy-ball momentum together with predictive gradient extrapolation via local Taylor approximations to estimate future gradient directions, providing adaptive acceleration with stability. It maintains O(d) memory overhead and uses the same hyperparameters as standard momentum.", "result": "Provides convergence guarantees for strongly convex functions. Empirically, HB-SGE converges on ill-conditioned quadratics with condition number \u03ba=50 in 119 iterations where SGD and NAG diverge. On the non-convex Rosenbrock function, HB-SGE converges in 2,718 iterations while classical momentum methods diverge within 10 steps. NAG remains faster on well-conditioned problems, but HB-SGE offers robust acceleration and speedups over SGD across diverse landscapes.", "conclusion": "HB-SGE offers a robust alternative to SGD and classical momentum, delivering stable acceleration on ill-conditioned and non-convex problems with modest memory overhead and no extra hyperparameter tuning, while maintaining competitive performance on well-conditioned problems."}}
{"id": "2512.10478", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10478", "abs": "https://arxiv.org/abs/2512.10478", "authors": ["Yumeng Zhang", "Huayan Guo", "Vincent Lau"], "title": "A Novel Pilot Scheme for Uplink Channel Estimation for Sub-array Structured ELAA in XL-MIMO systems", "comment": null, "summary": "This paper proposes a novel pilot scheme for multi-user uplink channel estimation in extra-large-scale massive MIMO (XL-MIMO) systems with extremely large aperture arrays (ELAA). The large aperture of ELAA introduces spatial non-stationarity, where far-apart users have significantly distinct visibility at the antennas, thereby reducing inter-user interference. This insight motivates our novel pilot scheme to group users with distinct visibility regions to share the same frequency subcarriers for channel estimation, so that more users can be served with reduced pilot overhead. Specifically, the proposed pilot scheme employs frequency-division multiplexing for inter-group channel estimation, while intra-group users -- benefiting from strong spatial orthogonality -- are distinguished by shifted cyclic codes, similar to code-division multiplexing. Additionally, we introduce a sub-array structured ELAA, where each sub-array is a traditional MIMO array and treated as spatial stationary, while the distances between sub-arrays can be significantly larger to achieve an expanded aperture. The channel support for sub-arrays features clustered sparsity in the antenna-delay domain and is modeled by a 2-dimensional (2-D) Markov random field (MRF). Based on this, we propose a low-complexity channel estimation algorithm within a turbo Bayesian inference framework that incorporates the 2-D MRF prior model. Simulations show that the proposed scheme and algorithm allow the XL-MIMO system to support more users, and deliver superior channel estimation performance.", "AI": {"tldr": "\u63d0\u51fa\u5728ELAA/MIMO\u7cfb\u7edf\u4e2d\u4ee5\u53ef\u89c1\u6027\u533a\u57df\u5206\u7ec4\u7684\u591a\u7528\u6237\u4e0a\u884c\u901a\u9053\u4f30\u8ba1\u65b0\u578b\u5bfc\u9891\u65b9\u6848\uff0c\u5229\u7528\u7ec4\u95f4\u9891\u5206\u590d\u7528\u3001\u7ec4\u5185\u79fb\u4f4d\u5faa\u73af\u7801\u533a\u5206\uff0c\u8f85\u4ee5\u5b50\u9635\u7ed3\u6784ELAA\u53ca2-D MRF\u5148\u9a8c\uff0c\u5728Turbo-Bayesian\u6846\u67b6\u4e0b\u8fdb\u884c\u4f4e\u590d\u6742\u5ea6\u4f30\u8ba1\uff0c\u63d0\u5347\u53ef\u670d\u52a1\u7528\u6237\u6570\u548c\u4f30\u8ba1\u6027\u80fd\u3002", "motivation": "XL-MIMO\u5728\u6781\u5927\u5b54\u5f84\u4e0b\u4ea7\u751f\u7a7a\u95f4\u975e\u5e73\u7a33\u6027\uff0c\u4e0d\u540c\u7528\u6237\u5728\u5929\u7ebf\u9635\u5217\u4e0a\u7684\u53ef\u89c2\u6d4b\u6027\u5dee\u5f02\u663e\u8457\uff0c\u5bfc\u81f4\u4f20\u7edf\u7684\u5bfc\u9891\u5f00\u9500\u4e0e\u5e72\u6270\u7ba1\u7406\u4e0d\u8db3\uff0c\u9700\u65b0\u578b\u5206\u7ec4\u4e0e\u4f30\u8ba1\u7b56\u7565\u6765\u964d\u4f4e\u5f00\u9500\u5e76\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4ee5\u53ef\u89c2\u6d4b\u6027\u533a\u57df\u5bf9\u7528\u6237\u5206\u7ec4\u5171\u4eab\u540c\u4e00\u9891\u6bb5\u5bfc\u9891\uff1b\u7ec4\u95f4\u901a\u8fc7\u9891\u5206\u590d\u7528\u8fdb\u884c\u901a\u9053\u4f30\u8ba1\uff0c\u7ec4\u5185\u901a\u8fc7\u79fb\u4f4d\u5faa\u73af\u7801\u5b9e\u73b0\u7c7bCDM\u7684\u9ad8\u5206\u8fa8\u7a7a\u95f4\u533a\u5206\uff1b\u5f15\u5165\u5b50\u9635\u7ed3\u6784ELAA\u4f7f\u5404\u5b50\u9635\u72ec\u7acb\u8fd1\u4f3c\u65f6\u53d8\uff08\u9759\u6001\uff09\u4e14\u5b50\u9635\u95f4\u8ddd\u589e\u5927\u6269\u5c55\u5b54\u5f84\uff1b\u5bf9\u5b50\u9635\u7684\u901a\u9053\u5728\u65f6\u5ef6-\u5929\u7ebf\u57df\u5448\u805a\u7c07\u7a00\u758f\uff0c\u91c7\u7528\u4e8c\u7ef4MRF\u5efa\u6a21\uff1b\u5728Turbo-Bayesian\u6846\u67b6\u4e2d\u7ed3\u54082-D MR\u524d\u9a8c\u5b9e\u73b0\u4f4e\u590d\u6742\u5ea6\u901a\u9053\u4f30\u8ba1\u3002", "result": "\u4eff\u771f\u8868\u660e\u8be5\u65b9\u6848\u53ef\u670d\u52a1\u66f4\u591a\u7528\u6237\u5e76\u63d0\u5347\u901a\u9053\u4f30\u8ba1\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u7a7a\u95f4\u975e\u5e73\u7a33\u6027\u4e0e\u7a00\u758f\u7ed3\u6784\uff0c\u5e76\u7ed3\u5408\u5b50\u9635\u8bbe\u8ba1\u4e0eMRF\u5148\u9a8c\uff0c\u63d0\u51fa\u7684\u5bfc\u9891\u4e0e\u4f30\u8ba1\u7b97\u6cd5\u5728XL-MIMO/ELAA\u573a\u666f\u4e0b\u6709\u6548\u63d0\u5347\u7528\u6237\u5bb9\u91cf\u4e0e\u4f30\u8ba1\u7cbe\u5ea6\u3002"}}
{"id": "2512.09959", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09959", "abs": "https://arxiv.org/abs/2512.09959", "authors": ["Dae-young Kim", "Karuna Pande Joshi"], "title": "TRUCE: TRUsted Compliance Enforcement Service for Secure Health Data Exchange", "comment": null, "summary": "Organizations are increasingly sharing large volumes of sensitive Personally Identifiable Information (PII), like health records, with each other to better manage their services. Protecting PII data has become increasingly important in today's digital age, and several regulations have been formulated to ensure the secure exchange and management of sensitive personal data. However, at times some of these regulations are at loggerheads with each other, like the Health Insurance Portability and Accountability Act (HIPAA) and Cures Act; and this adds complexity to the already challenging task of Health Data compliance. As public concern regarding sensitive data breaches grows, finding solutions that streamline compliance processes and enhance individual privacy is crucial. We have developed a novel TRUsted Compliance Enforcement (TRUCE) framework for secure data exchange which aims to automate compliance procedures and enhance trusted data management within organizations. The TRUCE framework reasons over contexts of data exchange and assesses the trust score of users and the veracity of data based on corresponding regulations. This framework, developed using approaches from AI/Knowledge representation and Semantic Web technologies, includes a trust management method that incorporates static ground truth, represented by regulations such as HIPAA, and dynamic ground truth, defined by an organization's policies. In this paper, we present our framework in detail along with the validation against the Health Insurance Portability and Accountability Act (HIPAA) Data Usage Agreement (DUA) on CDC Contact Tracing patient data, up to one million patient records. TRUCE service will streamline compliance efforts and ensure adherence to privacy regulations and can be used by organizations to manage compliance of large velocity data exchange in real time.", "AI": {"tldr": "A novel TRUCE framework automates regulatory-compliant secure data exchange using context-aware trust scoring, validated against HIPAA DUA with up to 1M records; enables real-time, large-volume compliance.", "motivation": "Rising sharing of sensitive PII and regulatory conflicts (e.g., HIPAA vs. Cures Act) create complexity in health data compliance; there is a need for automated, trustworthy data management to protect privacy.", "method": "AI/Knowledge representation and Semantic Web techniques for context-aware reasoning. A trust management component combines static ground truth (regulations like HIPAA) with dynamic ground truth (organizational policies) to assess data exchange, user trust, and data veracity.", "result": "Validation against HIPAA Data Usage Agreement (DUA) on CDC Contact Tracing patient data, up to one million records. TRUCE enables streamlined compliance for large-velocity data exchanges in real time.", "conclusion": "TRUCE can streamline privacy-compliant data exchange, enforce regulatory adherence in real time, and assist organizations in managing compliance for high-volume data sharing."}}
{"id": "2512.10040", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.10040", "abs": "https://arxiv.org/abs/2512.10040", "authors": ["Skyler Wu", "Aymen Echarghaoui"], "title": "Intelligently Weighting Multiple Reference Models for Direct Preference Optimization of LLMs", "comment": "Working paper. 13 pages, 4 figures", "summary": "Fine-tuning is integral for aligning large language models (LLMs) with human preferences. Multiple-Reference Preference Optimization (MRPO) builds on Direct Preference Optimization (DPO) by fine-tuning LLMs on preference datasets while regularizing the policy towards a mixture of reference models to leverage their collective desirable properties. However, current methods for setting the reference weights are ad-hoc and statistically unsound, leading to unreliable performance. To address this, we introduce four new weighting strategies: two offline methods that leverage held-out validation signal; one online method that uses a sliding-window estimator to reduce overfitting; and an online method that treats reference weighting as a $K$-armed bandit via Thompson Sampling. Experiments using Qwen2.5-0.5B as the policy model and seven reference models from the Llama, Mistral, Qwen, Yi, and Phi families (0.5B-14B each) show that all 4 of our strategies outperform the current MRPO weighting methods on UltraFeedback and SafeRLHF in preference accuracy. More thought-provokingly, however, we find that single-reference DPO, using any of 6 out of 7 references, consistently outperforms all tested multiple-reference approaches -- calling into question the practical appeal of multiple-reference approaches.", "AI": {"tldr": "\u63d0\u51fa\u56db\u79cd\u5bf9\u53c2\u8003\u6a21\u578b\u6743\u91cd\u8fdb\u884c\u79bb\u7ebf/\u5728\u7ebf\u4f30\u8ba1\u7684\u7b56\u7565\u4ee5\u6539\u8fdb MRPO\uff0c\u4f46\u5b9e\u9a8c\u663e\u793a\u5355\u53c2\u8003 DPO \u5728\u591a\u6570\u8bbe\u7f6e\u4f18\u4e8e\u591a\u53c2\u8003 MRPO\uff0c\u8d28\u7591\u591a\u53c2\u8003\u65b9\u6cd5\u7684\u5b9e\u9645\u6548\u7528\u3002", "motivation": "\u5728\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u4ee5\u5bf9\u9f50\u4eba\u7c7b\u504f\u597d\u65f6\uff0c\u5982\u4f55\u4e3a\u53c2\u8003\u6a21\u578b\u6743\u91cd\u8bbe\u5b9a\u4e00\u4e2a\u7edf\u8ba1\u4e0a\u7a33\u5065\u4e14\u6709\u6548\u7684\u7b56\u7565\u4ecd\u4e0d\u6e05\u6670\u3002\u73b0\u6709 MRPO \u7684\u6743\u91cd\u8bbe\u5b9a\u591a\u4e3a ad-hoc\uff0c\u7f3a\u4e4f\u7a33\u5065\u6027\u8bc4\u4f30\uff0c\u56e0\u6b64\u4e9f\u9700\u66f4\u7cfb\u7edf\u7684\u6743\u91cd\u7b56\u7565\u4ee5\u63d0\u5347\u504f\u597d\u5bf9\u9f50\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u56db\u79cd weighting \u7b56\u7565\uff1a\u4e24\u79cd\u79bb\u7ebf\u65b9\u6cd5\u5229\u7528\u4fdd\u7559\uff08held-out\uff09\u9a8c\u8bc1\u4fe1\u53f7\uff0c\u53e6\u4e00\u79cd\u5728\u7ebf\u65b9\u6cd5\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u4f30\u8ba1\u4ee5\u964d\u4f4e\u8fc7\u62df\u5408\uff0c\u53e6\u4e00\u4e2a\u5728\u7ebf\u65b9\u6cd5\u5c06\u53c2\u8003\u6743\u91cd\u770b\u4f5c\u4e00\u4e2a K \u81c2\u8d4c\u535a\u673a\u95ee\u9898\u5e76\u4f7f\u7528 Thompson Sampling\u3002\u5b9e\u9a8c\u4ee5 Qwen2.5-0.5B \u4f5c\u4e3a\u7b56\u7565\u6a21\u578b\uff0c\u4e03\u4e2a\u6765\u81ea Llama\u3001Mistral\u3001Qwen\u3001Yi\u3001Phi \u5bb6\u65cf\u7684\u53c2\u8003\u6a21\u578b\uff080.5B-14B\uff09\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u8fd9\u56db\u79cd\u65b0\u7b56\u7565\u5728 UltraFeedback \u548c SafeRLHF \u7684\u504f\u597d\u51c6\u786e\u6027\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u7684 MRPO \u6743\u91cd\u8bbe\u5b9a\u65b9\u6cd5\u3002\u66f4\u5177\u542f\u53d1\u6027\u7684\u662f\uff0c\u5355\u53c2\u8003 DPO \u5728\u4f7f\u7528\u4efb\u610f 6/7 \u4e2a\u53c2\u8003\u65f6\u51e0\u4e4e\u59cb\u7ec8\u4f18\u4e8e\u6240\u6709\u6d4b\u8bd5\u4e2d\u7684\u591a\u53c2\u8003\u65b9\u6cd5\u3002", "conclusion": "\u591a\u53c2\u8003 MRPO \u7684\u5b9e\u9645\u6548\u7528\u53d7\u5230\u8d28\u7591\uff1b\u5728\u5f53\u524d\u5b9e\u9a8c\u6761\u4ef6\u4e0b\uff0c\u5355\u53c2\u8003 DPO \u5f80\u5f80\u66f4\u5177\u53ef\u884c\u6027\uff0c\u9700\u91cd\u65b0\u8bc4\u4f30\u53c2\u8003\u6a21\u578b\u7684\u7ec4\u5408\u4e0e\u6743\u91cd\u7b56\u7565\uff0c\u672a\u6765\u5de5\u4f5c\u5e94\u805a\u7126\u4e8e\u7a33\u5065\u7684\u5355\u4e00\u53c2\u8003\u6216\u66f4\u7cfb\u7edf\u7684\u591a\u53c2\u8003\u6743\u91cd\u8bbe\u8ba1\u3002"}}
{"id": "2512.10496", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10496", "abs": "https://arxiv.org/abs/2512.10496", "authors": ["Shilian Zheng", "Xiaoxiang Wu", "Luxin Zhang", "Keqiang Yue", "Peihan Qi", "Zhijin Zhao"], "title": "T-ADD: Enhancing DOA Estimation Robustness Against Adversarial Attacks", "comment": null, "summary": "Deep learning has achieved remarkable success in direction-of-arrival (DOA) estimation. However, recent studies have shown that adversarial perturbations can severely compromise the performance of such models. To address this vulnerability, we propose Transformer-based Adversarial Defense for DOA estimation (T-ADD), a transformer-based defense method designed to counter adversarial attacks. To achieve a balance between robustness and estimation accuracy, we formulate the adversarial defense as a joint reconstruction task and introduce a tailored joint loss function. Experimental results demonstrate that, compared with three state-of-the-art adversarial defense methods, the proposed T-ADD significantly mitigates the adverse effects of widely used adversarial attacks, leading to notable improvements in the adversarial robustness of the DOA model.", "AI": {"tldr": "\u63d0\u51fa T-ADD\uff0c\u4e00\u79cd\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u5bf9 DOA \u4f30\u8ba1\u7684\u5bf9\u6297\u653b\u51fb\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u9632\u5fa1\u4efb\u52a1\u8bbe\u5b9a\u4e3a\u8054\u5408\u91cd\u6784\uff0c\u5e76\u8bbe\u8ba1\u5b9a\u5236\u7684\u8054\u5408\u635f\u5931\uff0c\u4ee5\u63d0\u5347\u5bf9\u5e7f\u6cdb\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u5c3d\u91cf\u7ef4\u6301\u4f30\u8ba1\u51c6\u786e\u6027\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u65b9\u5411\u5230\u8fbe\uff08DOA\uff09\u4f30\u8ba1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6270\u52a8\u7684\u524a\u5f31\uff0c\u8feb\u5207\u9700\u8981\u9c81\u68d2\u7684\u9632\u5fa1\u673a\u5236\u6765\u786e\u4fdd\u7cfb\u7edf\u5728\u6f5c\u5728\u653b\u51fb\u4e0b\u4ecd\u80fd\u53ef\u9760\u5de5\u4f5c\u3002", "method": "\u57fa\u4e8e Transformer \u7684\u9632\u5fa1\u6846\u67b6 T-ADD\uff0c\u5c06\u5bf9\u6297\u9632\u5fa1\u95ee\u9898\u5efa\u6a21\u4e3a\u8054\u5408\u91cd\u6784\u4efb\u52a1\uff0c\u901a\u8fc7\u5b9a\u5236\u7684\u8054\u5408\u635f\u5931\u51fd\u6570\u5728\u9c81\u68d2\u6027\u4e0e\u4f30\u8ba1\u7cbe\u5ea6\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u5bf9\u6bd4\u4e86\u4e09\u79cd\u6700\u65b0\u7684\u5bf9\u6297\u9632\u5fa1\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u4e0a\u663e\u793a T-ADD \u80fd\u663e\u8457\u7f13\u89e3\u5bf9\u6297\u653b\u51fb\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4e09\u79cd\u6700\u65b0\u5bf9\u6297\u9632\u5fa1\u65b9\u6cd5\u76f8\u6bd4\uff0cT-ADD \u5728\u5bf9\u5e7f\u6cdb\u4f7f\u7528\u7684\u5bf9\u6297\u653b\u51fb\u4e0b\u663e\u8457\u63d0\u5347\u4e86 DOA \u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u51cf\u5f31\u4e86\u653b\u51fb\u6548\u679c\uff0c\u63d0\u5347\u4e86\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "conclusion": "T-ADD \u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5bf9 DOA \u4f30\u8ba1\u7684\u5bf9\u6297\u9632\u5fa1\u601d\u8def\uff0c\u901a\u8fc7 Transformer \u67b6\u6784\u548c\u8054\u5408\u91cd\u6784\u635f\u5931\u5b9e\u73b0\u66f4\u597d\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u5bf9\u4fdd\u6301\u4f30\u8ba1\u7cbe\u51c6\u5ea6\u5177\u6709\u6f5c\u5728\u7684\u6b63\u5411\u5f71\u54cd\u3002"}}
{"id": "2512.10392", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10392", "abs": "https://arxiv.org/abs/2512.10392", "authors": ["Sungjun Seo", "Kooktae Lee"], "title": "Collision-Aware Density-Driven Control of Multi-Agent Systems via Control Barrier Functions", "comment": "6 pages, 7 figures, Accepted for presentation at the 5th Modeling, Estimation and Control Conference (MECC 2025), Pittsburgh, USA", "summary": "This paper tackles the problem of safe and efficient area coverage using a multi-agent system operating in environments with obstacles. Applications such as environmental monitoring and search and rescue require robot swarms to cover large domains under resource constraints, making both coverage efficiency and safety essential. To address the efficiency aspect, we adopt the Density-Driven Control (D$^2$C) framework, which uses optimal transport theory to steer agents according to a reference distribution that encodes spatial coverage priorities. To ensure safety, we incorporate Control Barrier Functions (CBFs) into the framework. While CBFs are commonly used for collision avoidance, we extend their applicability by introducing obstacle-specific formulations for both circular and rectangular shapes. In particular, we analytically derive a unit normal vector based on the agent's position relative to the nearest face of a rectangular obstacle, improving safety enforcement in environments with non-smooth boundaries. Additionally, a velocity-dependent term is incorporated into the CBF to enhance collision avoidance. Simulation results validate the proposed method by demonstrating smoother navigation near obstacles and more efficient area coverage than the existing method, while still ensuring collision-free operation.", "AI": {"tldr": "The paper proposes a Density-Driven Control (D^2C) framework for multi-agent area coverage with obstacle-aware Control Barrier Functions (CBFs). It integrates optimal-transport-based coverage with obstacle-specific, velocity-enhanced CBFs to ensure safety and efficient navigation in cluttered environments.", "motivation": "Efficiently-covered deployment of robot swarms in large, obstacle-rich environments is essential for environmental monitoring and search-and-rescue, balancing coverage performance with safety under resource constraints.", "method": "1) Use D^2C to steer agents to a target distribution encoding spatial coverage priorities via optimal transport. 2) Integrate CBFs for safety; extend CBFs to handle circular and rectangular obstacles with analytic unit normals toward the nearest obstacle face. 3) Introduce a velocity-dependent term in the CBF to improve collision avoidance. ", "result": "Simulations show smoother navigation near obstacles and improved area coverage efficiency compared to the existing method, while maintaining collision-free operation.", "conclusion": "The proposed framework effectively combines density-driven coverage control with obstacle-aware safety mechanisms, enhancing both coverage efficiency and safety in cluttered environments."}}
{"id": "2512.10020", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.10020", "abs": "https://arxiv.org/abs/2512.10020", "authors": ["Ayush Nainwal", "Atharva Kamble", "Nitin Awathare"], "title": "A Comparative Analysis of zk-SNARKs and zk-STARKs: Theory and Practice", "comment": null, "summary": "Zero-knowledge proofs (ZKPs) are central to secure and privacy-preserving computation, with zk-SNARKs and zk-STARKs emerging as leading frameworks offering distinct trade-offs in efficiency, scalability, and trust assumptions. While their theoretical foundations are well studied, practical performance under real-world conditions remains less understood.\n  In this work, we present a systematic, implementation-level comparison of zk-SNARKs (Groth16) and zk-STARKs using publicly available reference implementations on a consumer-grade ARM platform. Our empirical evaluation covers proof generation time, verification latency, proof size, and CPU profiling. Results show that zk-SNARKs generate proofs 68x faster with 123x smaller proof size, but verify slower and require trusted setup, whereas zk-STARKs, despite larger proofs and slower generation, verify faster and remain transparent and post-quantum secure. Profiling further identifies distinct computational bottlenecks across the two systems, underscoring how execution models and implementation details significantly affect real-world performance. These findings provide actionable insights for developers, protocol designers, and researchers in selecting and optimizing proof systems for applications such as privacy-preserving transactions, verifiable computation, and scalable rollups.", "AI": {"tldr": "\u5bf9\u6bd4 zk-SNARK\uff08Groth16\uff09\u4e0e zk-STARKs \u5728\u5b9e\u9645\u5b9e\u73b0\u5c42\u9762\u7684\u6027\u80fd\uff1a\u5728\u6d88\u8d39\u7ea7 ARM \u5e73\u53f0\u4e0a\uff0cSNARK \u5728\u8bc1\u660e\u751f\u6210\u901f\u5ea6\u548c\u8bc1\u660e\u5927\u5c0f\u65b9\u9762\u663e\u8457\u4f18\u4e8e STARK\uff1b\u800c STARK \u5728\u9a8c\u8bc1\u901f\u5ea6\u548c\u900f\u660e\u6027/\u6297\u91cf\u5b50\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u9700\u8981\u66f4\u5927\u7684\u8bc1\u660e\u3002", "motivation": "\u5728\u771f\u5b9e\u4e16\u754c\u6761\u4ef6\u4e0b\u8bc4\u4f30\u4e24\u7c7b\u4e3b\u6d41\u96f6\u77e5\u8bc6\u8bc1\u660e\u4f53\u7cfb\u7684\u5b9e\u9645\u6027\u80fd\u4e0e\u6743\u8861\uff0c\u4ee5\u6307\u5bfc\u5f00\u53d1\u8005\u5728\u9690\u79c1\u4ea4\u6613\u3001\u53ef\u9a8c\u8bc1\u8ba1\u7b97\u4e0e\u53ef\u6269\u5c55\u6027\u65b9\u6848\u4e2d\u7684\u9009\u578b\u4e0e\u4f18\u5316\u3002", "method": "\u57fa\u4e8e\u516c\u5f00\u7684\u53c2\u8003\u5b9e\u73b0\uff0c\u5728\u6d88\u8d39\u7ea7 ARM \u5e73\u53f0\u4e0a\u8fdb\u884c\u5b9e\u73b0\u7ea7\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e24\u8005\u7684\u8bc1\u660e\u751f\u6210\u65f6\u95f4\u3001\u9a8c\u8bc1\u65f6\u5ef6\u3001\u8bc1\u660e\u5927\u5c0f\uff0c\u5e76\u8fdb\u884c CPU \u914d\u7f6e\u5206\u6790\u4ee5\u5b9a\u4f4d\u8ba1\u7b97\u74f6\u9888\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1azk-SNARKs\uff08Groth16\uff09\u5728\u8bc1\u660e\u751f\u6210\u65b9\u9762\u5feb\u7ea6 68 \u500d\uff0c\u8bc1\u660e\u5c3a\u5bf8\u5c0f\u7ea6 123 \u500d\uff1b\u4f46\u9a8c\u8bc1\u9636\u6bb5\u8f83\u6162\u4e14\u9700\u8981\u53d7\u4fe1\u4efb\u8bbe\u7f6e\u3002zk-STARKs \u5c3d\u7ba1\u751f\u6210\u6162\u4e14\u8bc1\u660e\u66f4\u5927\uff0c\u4f46\u9a8c\u8bc1\u66f4\u5feb\u3001\u4fdd\u6301\u900f\u660e\u6027\u4e14\u5bf9\u91cf\u5b50\u5b89\u5168\u3002CPU profiling \u53d1\u73b0\u4e24\u8005\u5728\u8ba1\u7b97\u74f6\u9888\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u53d7\u6267\u884c\u6a21\u578b\u4e0e\u5b9e\u73b0\u7ec6\u8282\u5f71\u54cd\u663e\u8457\u3002", "conclusion": "\u8be5\u5bf9\u6bd4\u4e3a\u5f00\u53d1\u8005\u3001\u534f\u8bae\u8bbe\u8ba1\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u5728\u4e0d\u540c\u5e94\u7528\u573a\u666f\uff08\u9690\u79c1\u4ea4\u6613\u3001\u53ef\u9a8c\u8bc1\u8ba1\u7b97\u3001\u53ef\u6269\u5c55\u6027\u805a\u5408\uff09\u4e2d\u9009\u62e9\u4e0e\u4f18\u5316\u8bc1\u660e\u7cfb\u7edf\u7684\u64cd\u4f5c\u6027\u6d1e\u89c1\uff0c\u5f3a\u8c03\u5b9e\u73b0\u7ec6\u8282\u548c\u8fd0\u884c\u73af\u5883\u5bf9\u5b9e\u9645\u6027\u80fd\u7684\u51b3\u5b9a\u6027\u4f5c\u7528\u3002"}}
{"id": "2512.10580", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10580", "abs": "https://arxiv.org/abs/2512.10580", "authors": ["Albert Benveniste", "Benoit Caillaud", "Yahao Chen", "Khalil Ghorbal", "Mathias Malandain"], "title": "Structural Methods for handling mode changes in multimode DAE systems", "comment": "53 pages, 3 figures", "summary": "Hybrid systems are an important concept in Cyber-Physical Systems modeling, for which multiphysics modeling from first principles and the reuse of models from libraries are key. To achieve this, DAEs must be used to specify the dynamics in each discrete state (or mode in our context). This led to the development of DAE-based equational languages supporting multiple modes, of which Modelica is a popular standard. Mode switching can be time- or state-based. Impulsive behaviors can occur at mode changes. While mode changes are well understood in particular physics (e.g., contact mechanics), this is not the case in physics-agnostic paradigms such as Modelica. This situation causes difficulties for the compilation of programs, often requiring users to manually smooth out mode changes. In this paper, we propose a novel approach for the hot restart at mode changes in such paradigms. We propose a mathematical meaning for hot restarts (such a mathematical meaning does not exist in general), as well as a combined structural and impulse analysis for mode changes, generating the hot restart even in the presence of impulses. Our algorithm detects at compile time if the mode change is insufficiently specified, in which case it returns diagnostics information to the user.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u591a\u6a21\u6001 DAE \u57fa\u4e8e\u6a21\u578b\u7684\u8bed\u8a00\uff08\u5982 Modelica\uff09\u4e2d\u5b9e\u73b0\u70ed\u91cd\u542f\u7684\u9762\u5411\u7f16\u8bd1\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u7ed3\u5408\u7ed3\u6784\u4e0e\u51b2\u51fb\u5206\u6790\uff0c\u5728\u5b58\u5728\u51b2\u51fb\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u751f\u6210\u70ed\u91cd\u542f\uff0c\u5e76\u80fd\u5728\u7f16\u8bd1\u65f6\u68c0\u6d4b\u6a21\u5f0f\u5207\u6362\u7684\u5b9a\u4e49\u4e0d\u5145\u5206\u4e4b\u5904\u5e76\u7ed9\u51fa\u8bca\u65ad\u3002", "motivation": "\u5728\u6df7\u5408\u7cfb\u7edf\u7684\u7269\u7406-\u8ba1\u7b97\u6a21\u578b\u4e2d\uff0c\u6a21\u5f0f\u5207\u6362\u4ee5\u53ca\u968f\u4e4b\u4ea7\u751f\u7684\u51b2\u51fb\u884c\u4e3a\u76f4\u63a5\u5f71\u54cd\u4eff\u771f\u4e0e\u4ee3\u7801\u751f\u6210\u7684\u6b63\u786e\u6027\u3002\u73b0\u6709\u7684\u8bed\u8a00\u5bf9\u70ed\u91cd\u542f\u7684\u6570\u5b66\u542b\u4e49\u7f3a\u4e4f\u7edf\u4e00\u5b9a\u4e49\uff0c\u5bfc\u81f4\u9700\u8981\u624b\u5de5\u5e73\u6ed1\u6a21\u5f0f\u5207\u6362\uff0c\u5f71\u54cd\u53ef\u91cd\u590d\u6027\u4e0e\u81ea\u52a8\u5316\u3002", "method": "\u63d0\u51fa\u70ed\u91cd\u542f\u7684\u6570\u5b66\u542b\u4e49\uff1b\u7ed3\u5408\u7ed3\u6784\u5206\u6790\u548c\u51b2\u51fb\u5206\u6790\u7684\u6df7\u5408\u65b9\u6cd5\uff1b\u5f00\u53d1\u5728\u7f16\u8bd1\u65f6\u6267\u884c\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u6a21\u5f0f\u5207\u6362\u4e0d\u5145\u5206\u65f6\u751f\u6210\u8bca\u65ad\u4fe1\u606f\uff0c\u5e76\u5728\u5b58\u5728\u51b2\u51fb\u65f6\u4ecd\u80fd\u4ea7\u751f\u70ed\u91cd\u542f\u3002", "result": "\u7ed9\u51fa\u4e00\u79cd\u5728\u7f16\u8bd1\u671f\u53ef\u6267\u884c\u7684\u5206\u6790\u4e0e\u751f\u6210\u673a\u5236\uff0c\u80fd\u591f\u5728\u5b58\u5728\u51b2\u51fb\u7684\u60c5\u51b5\u4e0b\u6784\u9020\u70ed\u91cd\u542f\u5e76\u8f93\u51fa\u8bca\u65ad\u4fe1\u606f\uff1b\u4e3a paradigm \u5982 Modelica \u7684\u591a\u6a21\u6001 DAE \u7a0b\u5e8f\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u6a21\u5f0f\u5207\u6362\u5904\u7406\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u591a\u6a21\u6001\u7269\u7406-\u8ba1\u7b97\u8bed\u8a00\u4e2d\u7684\u6a21\u5f0f\u5207\u6362\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u70ed\u91cd\u542f\u8bed\u4e49\u4e0e\u53ef\u8bca\u65ad\u7684\u7f16\u8bd1\u671f\u5206\u6790\uff0c\u63d0\u5347\u4e86\u6df7\u5408\u7cfb\u7edf\u5efa\u6a21\u4e0e\u4ee3\u7801\u751f\u6210\u7684\u9c81\u68d2\u6027\u4e0e\u81ea\u52a8\u5316\u7a0b\u5ea6\u3002"}}
{"id": "2512.10029", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.10029", "abs": "https://arxiv.org/abs/2512.10029", "authors": ["Shresta B. Seetharam", "Mohamed Nabeel", "William Melicher"], "title": "Malicious GenAI Chrome Extensions: Unpacking Data Exfiltration and Malicious Behaviours", "comment": "VIRUS BULLETIN CONFERENCE SEPTEMBER 2025", "summary": "The rapid proliferation of AI and GenAI tools has extended to the Chrome Web Store. Cybercriminals are exploiting this trend, deploying malicious Chrome extensions posing as AI tools or impersonating popular GenAI models to target users. These extensions often appear legitimate while secretly exfiltrating sensitive data or redirecting users web traffic to attacker-controlled domains.\n  To examine the impact of this trend on the browser extension ecosystem, we curated a dataset of 5,551 AI-themed extensions released over a nine-month period to the Chrome Web Store. Using a multi-signal detection methodology that combines manifest analysis, domain reputation, and runtime network behavior, supplemented with human review, we identified 154 previously undetected malicious Chrome extensions. Together with extensions known from public threat research disclosures, this resulted in a final set of 341 malicious extensions for analysis. Of these, 29 were GenAI-related, forming the focus of our in-depth analysis and disclosure.\n  We deconstruct representative GenAI cases, including Supersonic AI, DeepSeek AI | Free AI Assistant, and Perplexity Search, to illustrate attacker techniques such as Adversary-in-the-Browser, impersonation, bait-and-switch updates, query hijacking, and redirection. Our findings show that threat actors are leveraging GenAI trends and exploiting browser extension APIs and settings for malicious purposes. This demonstrates that the browser extension threat landscape is directly evolving alongside the rapid adoption of GenAI technologies.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.10043", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10043", "abs": "https://arxiv.org/abs/2512.10043", "authors": ["Jo\u00e3o Lucas Luz Lima Sarcinelli", "Diego Furtado Silva"], "title": "Local LLM Ensembles for Zero-shot Portuguese Named Entity Recognition", "comment": null, "summary": "Large Language Models (LLMs) excel in many Natural Language Processing (NLP) tasks through in-context learning but often under-perform in Named Entity Recognition (NER), especially for lower-resource languages like Portuguese. While open-weight LLMs enable local deployment, no single model dominates all tasks, motivating ensemble approaches. However, existing LLM ensembles focus on text generation or classification, leaving NER under-explored. In this context, this work proposes a novel three-step ensemble pipeline for zero-shot NER using similarly capable, locally run LLMs. Our method outperforms individual LLMs in four out of five Portuguese NER datasets by leveraging a heuristic to select optimal model combinations with minimal annotated data. Moreover, we show that ensembles obtained on different source datasets generally outperform individual LLMs in cross-dataset configurations, potentially eliminating the need for annotated data for the current task. Our work advances scalable, low-resource, and zero-shot NER by effectively combining multiple small LLMs without fine-tuning. Code is available at https://github.com/Joao-Luz/local-llm-ner-ensemble.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4e09\u6b65\u672c\u5730LLM\u96c6\u5408\u65b9\u6cd5\u7528\u4e8e\u96f6\u6837\u672cNER\uff0c\u57285\u4e2a\u8461\u8bed\u6570\u636e\u96c6\u4e0a\u8d85\u8fc7\u5355\u6a21\u578b\uff084/5\uff09\uff0c\u5e76\u5728\u8de8\u6570\u636e\u60c5\u5f62\u5c55\u73b0\u5f3a\u6cdb\u5316\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b3\u8461\u8404\u7259\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684NER\u6027\u80fd\u4e0d\u8db3\u95ee\u9898\uff0c\u5229\u7528\u672c\u5730\u53ef\u90e8\u7f72\u7684\u5f00\u6e90/\u5f00\u6743\u91cdLLM\uff0c\u901a\u8fc7\u96c6\u6210\u63d0\u5347NER\u80fd\u529b\uff0c\u540c\u65f6\u907f\u514d\u5bf9\u6570\u636e\u8fdb\u884c\u5927\u89c4\u6a21\u5fae\u8c03\u3002", "method": "\u6784\u5efa\u4e09\u6b65\u96c6\u5408\u7ba1\u7ebf\uff1a\u9009\u62e9\u76f8\u4f3c\u80fd\u529b\u7684\u672c\u5730LLMs\u3001\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u6a21\u578b\u7ec4\u5408\u9009\u62e9\u3001\u5728\u6781\u5c11\u6807\u6ce8\u6570\u636e\u4e0b\u8fdb\u884c\u65e0\u5fae\u8c03\u7684\u96f6\u6837\u672cNER\uff0c\u4e14\u5728\u4e0d\u540c\u6e90\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3/\u8bc4\u4f30\u4ee5\u5b9e\u73b0\u8de8\u6570\u636e\u6cdb\u5316\u3002", "result": "\u57284/5\u4e2a\u8461\u8404\u7259NER\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u5355\u4e00LLM\uff1b\u4e0d\u540c\u6e90\u6570\u636e\u96c6\u7684\u96c6\u6210\u5728\u8de8\u6570\u636e\u8bbe\u7f6e\u4e2d\u901a\u5e38\u4f18\u4e8e\u5355\u6a21\u578b\uff0c\u51cf\u5c11\u5bf9\u76ee\u6807\u4efb\u52a1\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002", "conclusion": "\u63d0\u51fa\u53ef\u6269\u5c55\u3001\u4f4e\u8d44\u6e90\u3001\u96f6\u6837\u672cNER\u7684\u4e00\u79cd\u6709\u6548\u4e09\u6b65\u672c\u5730LLM\u96c6\u6210\u7b56\u7565\uff0c\u4e14\u4ee3\u7801\u5f00\u6e90\uff0c\u5229\u4e8e\u672c\u5730\u90e8\u7f72\u4e0e\u65e0\u6807\u6ce8\u6570\u636e\u60c5\u5f62\u3002"}}
{"id": "2512.10752", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10752", "abs": "https://arxiv.org/abs/2512.10752", "authors": ["Yufei Wang", "Qiang Li", "Hongli Liu", "Ying Zhang", "Jingran Lin"], "title": "Symbol-Level Precoding for Integrated Sensing and Covert Communication", "comment": "IEEE Journal on Selected Areas in Communications", "summary": "Integrated sensing and communication (ISAC) systems have emerged as a promising solution to improve spectrum efficiency and enable functional convergence. However, ensuring secure information transmission while maintaining high-quality sensing performance remains a significant challenge. In this paper, we investigate an integrated sensing and covert communication (ISCC) system, in which a base station (BS) simultaneously serves multiple downlink users and senses malicious targets that may act as both potential eavesdroppers (Eves) and wardens. We propose a novel symbol-level precoding (SLP)-based waveform design for ISCC that achieves covert communication intrinsically, without requiring additional transmission resources such as artificial noise. The proposed design integrates symbol shaping to enhance reliability for legitimate users and noise shaping to obscure transmission activities from the targets. For imperfect channel state information (CSI), the framework incorporates bounded uncertainty models for user channels and target angles, yielding a more robust design. The resulting ISCC waveform optimization problem is non-convex; to address this, we develop a low-complexity proximal distance algorithm (PDA) with closed-form updates under both PSK and QAM modulations. Simulation results demonstrate that the proposed method achieves superior covertness and sensing-communication performance with negligible degradation compared to traditional beamforming and conventional SLP approaches without noise-shaping mechanisms.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7b26\u53f7\u7ea7\u9884\u7f16\u7801\u7684ISCC\u6ce2\u5f62\u8bbe\u8ba1\uff0c\u901a\u8fc7\u7b26\u53f7\u6574\u5f62\u63d0\u5347\u5408\u6cd5\u7528\u6237\u53ef\u9760\u6027\u3001\u566a\u58f0\u6574\u5f62\u9690\u85cf\u4f20\u8f93\u6d3b\u52a8\uff0c\u4e14\u5728CSI\u4e0d\u5b8c\u5907\u4e0b\u5177\u6709\u9c81\u68d2\u6027\u3002\u4f7f\u7528\u4f4e\u590d\u6742\u5ea6\u7684Proximal Distance Algorithm\uff08PDA\uff09\u5728PSK/QAM\u4e0b\u5b9e\u73b0\u975e\u51f8\u4f18\u5316\uff0c\u7ed3\u679c\u663e\u793a\u5728\u9690\u853d\u6027\u3001\u611f\u77e5\u4e0e\u901a\u4fe1\u6027\u80fd\u4e4b\u95f4\u5b9e\u73b0\u826f\u597d\u6298\u8877\uff0c\u4f18\u4e8e\u4f20\u7edf\u6ce2\u675f\u8d4b\u5f62\u4e0e\u65e0\u566a\u58f0\u6574\u5f62\u7684SLP\u65b9\u6cd5\u3002", "motivation": "\u5728\u7efc\u5408\u611f\u77e5\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u573a\u666f\u4e2d\uff0c\u9700\u540c\u65f6\u5b9e\u73b0\u5b89\u5168\uff08\u9690\u853d\uff09\u4f20\u8f93\u4e0e\u9ad8\u8d28\u91cf\u611f\u77e5\u6027\u80fd\u3002\u76ee\u6807\u65e2\u53ef\u80fd\u662f\u7a83\u542c\u8005\u53c8\u53ef\u80fd\u662f\u8b66\u6212\u8005\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5728\u4e0d\u589e\u52a0\u989d\u5916\u8d44\u6e90\uff08\u5982\u4eba\u9020\u566a\u58f0\uff09\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5185\u751f\u9690\u853d\u4f20\u8f93\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u6ce2\u5f62\u8bbe\u8ba1\u6765\u540c\u65f6\u63d0\u5347\u611f\u77e5\u4e0e\u901a\u4fe1\u7684\u9c81\u68d2\u6027\u4e0e\u4fdd\u5bc6\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7b26\u53f7\u7ea7\u9884\u7f16\u7801\uff08SLP\uff09\u4e3a\u6838\u5fc3\u7684ISCC\u6ce2\u5f62\u8bbe\u8ba1\uff0c\u5c06\u7b26\u53f7\u6210\u5f62\u7528\u4e8e\u63d0\u5347\u5408\u6cd5\u7528\u6237\u7684\u53ef\u9760\u6027\uff0c\u540c\u65f6\u901a\u8fc7\u566a\u58f0\u6574\u5f62\u63a9\u76d6\u4f20\u8f93\u6d3b\u52a8\uff1b\u5728\u7528\u6237\u4fe1\u9053\u548c\u76ee\u6807\u89d2\u5ea6\u5b58\u5728\u754c\u5b9a\u4e0d\u786e\u5b9a\u6027\u65f6\u5efa\u7acb bounded-uncertainty \u6a21\u578b\uff0c\u8fdb\u884c\u9c81\u68d2\u4f18\u5316\uff1b\u5c06\u975e\u51f8\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u884c\u7684\u4f4e\u590d\u6742\u5ea6 Proximal Distance Algorithm\uff08PDA\uff09\uff0c\u5e76\u7ed9\u51fa PSK \u4e0e QAM \u6a21\u5f0f\u4e0b\u7684\u95ed\u5f0f\u66f4\u65b0\u3002", "result": "\u4eff\u771f\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u5728\u9690\u853d\u6027\u3001\u611f\u77e5\u548c\u901a\u4fe1\u6027\u80fd\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6ce2\u675f\u8d4b\u5f62\u53ca\u666e\u901aSLP\u65b9\u6cd5\uff0c\u4e14\u5728\u4e0d\u4f7f\u7528\u989d\u5916\u8d44\u6e90\uff08\u5982\u4eba\u9020\u566a\u58f0\uff09\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u4e86\u6781\u5c0f\u7684\u6027\u80fd\u635f\u5931\u3002", "conclusion": "\u63d0\u51fa\u7684ISCC-PDA\u6846\u67b6\u5b9e\u73b0\u4e86\u672c\u8d28\u9690\u853d\u901a\u4fe1\u4e0e\u591a\u7528\u6237\u4e0b\u884c\u670d\u52a1\u7684\u7edf\u4e00\u8bbe\u8ba1\uff0c\u517c\u987e\u611f\u77e5\u6027\u80fd\uff0c\u5e76\u5bf9CSI\u4e0d\u5b8c\u5907\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4e14\u5177\u6709\u4f4e\u590d\u6742\u5ea6\u3001\u6613\u4e8e\u5b9e\u73b0\u7684\u4f18\u70b9\u3002"}}
{"id": "2512.10598", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10598", "abs": "https://arxiv.org/abs/2512.10598", "authors": ["Bowoo Jang", "Jun Heo", "Yong Bae Park", "Dong-Yeop Na"], "title": "NWP-based Atmospheric Refractivity Modeling and Fast & Stable Non-uniform Plane Wave Ray-Tracing Simulations for LEO Link Analysis", "comment": null, "summary": "Existing low-Earth-orbit (LEO) communication link analyses face two main challenges: (1) limited accuracy of 3D atmospheric refractivity reconstructed from sparsely sampled radiosonde data, and (2) numerical instability in previous non-uniform plane-wave ray-tracing algorithms (i.e., underflow under standard double precision), where non-uniform plane waves inevitably arise at complex-valued dielectric interfaces, is caused by extremely small atmospheric loss terms. To address these issues, we reconstruct a high-resolution 3D complex-valued refractivity model using numerical weather prediction data, and develop a fast and numerically stable non-uniform plane-wave ray tracer. The method remains stable in double precision and delivers a 24-fold speedup over high-precision benchmarks. Comparisons show that boresight-error deviations and path-loss differences between the rigorous method and the uniform-plane-wave approximation remain negligible, even under heavy precipitation. Although rays in a lossy atmosphere experience different phase- and attenuation-direction vectors-forming non-uniform plane waves-the resulting effective attenuation along the path is nearly identical to that predicted by the uniform-plane-wave model. These findings justify the continued use of uniform-plane-wave ray tracing in practical LEO link analyses.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u9ad8\u4fdd\u771f\u5ea6\u7684\u4e09\u7ef4\u590d\u4ecb\u7535\u5e38\u6570\u91cd\u5efa\u4e0e\u66f4\u5feb\u66f4\u7a33\u7684\u975e\u5747\u5300\u5e73\u9762\u6ce2\u5c04\u7ebf\u8ffd\u8e2a\u7b97\u6cd5\uff0c\u5e76\u5728\u53cc\u7cbe\u5ea6\u4e0b\u5b9e\u73b0\u7a33\u5b9a\u6027\u4e0e\u663e\u8457\u52a0\u901f", "motivation": "\u73b0\u6709LEO\u94fe\u8def\u5206\u6790\u5728\u4e24\u65b9\u9762\u53d7\u9650\uff1a\u4e00\u662f\u7531\u7a00\u758f\u7684\u9ad8\u7a7a\u6c14\u8c61\u89c2\u6d4b\uff08 radiosonde\uff09\u6240\u5bfc\u81f4\u7684\u4e09\u7ef4\u5927\u6c14\u6298\u5c04\u7387\u91cd\u5efa\u7cbe\u5ea6\u4e0d\u8db3\uff1b\u4e8c\u662f\u4ee5\u5f80\u7684\u975e\u5747\u5300\u5e73\u9762\u6ce2\u5c04\u7ebf\u8ffd\u8e2a\u5728\u590d\u6742\u754c\u9762\u5904\u6613\u51fa\u73b0\u6570\u503c\u4e0b\u6ea2\uff0c\u5bfc\u81f4\u6570\u503c\u4e0d\u7a33\u5b9a\uff0c\u5f71\u54cd\u7814\u7a76\u7684\u53ef\u9760\u6027", "method": "\u4f7f\u7528\u6570\u503c\u5929\u6c14\u9884\u62a5\uff08NWP\uff09\u6570\u636e\u91cd\u5efa\u9ad8\u5206\u8fa8\u7387\u7684\u4e09\u7ef4\u590d\u4ecb\u7535\u5e38\u6570\u573a\uff1b\u5f00\u53d1\u5feb\u901f\u4e14\u6570\u503c\u7a33\u5b9a\u7684\u975e\u5747\u5300\u5e73\u9762\u6ce2\u5c04\u7ebf\u8ffd\u8e2a\u7b97\u6cd5\uff0c\u5728\u53cc\u7cbe\u5ea6\u4e0b\u4fdd\u6301\u7a33\u5b9a\uff0c\u5e76\u5b9e\u73b0\u5bf9\u9ad8\u7cbe\u5ea6\u57fa\u51c6\u768424\u500d\u52a0\u901f", "result": "\u4e0e\u4e25\u683c\u7684\u975e\u5747\u5300\u5e73\u9762\u6ce2\u6a21\u578b\u76f8\u6bd4\uff0c\u5bfc\u5411\u5b54\u5f84\u8bef\u5dee\uff08boresight\uff09\u548c\u8def\u5f84\u635f\u8017\u5728\u91cd\u5ea6\u964d\u6c34\u60c5\u5f62\u4e0b\u5dee\u5f02\u4ecd\u7136\u6781\u5c0f\uff1b\u5728\u6709\u635f\u5927\u6c14\u4e2d\uff0c\u867d\u7136\u5c04\u7ebf\u5f62\u6210\u975e\u5747\u5300\u5e73\u9762\u6ce2\uff0c\u4f46\u6cbf\u8def\u5f84\u7684\u6709\u6548\u8870\u51cf\u4e0e\u7edf\u4e00\u5e73\u9762\u6ce2\u6a21\u578b\u9884\u6d4b\u51e0\u4e4e\u4e00\u81f4", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301\u5728\u5b9e\u9645LEO\u94fe\u8def\u5206\u6790\u4e2d\u6301\u7eed\u4f7f\u7528\u7edf\u4e00\u5e73\u9762\u6ce2\u5c04\u7ebf\u8ffd\u8e2a\u65b9\u6cd5\uff0c\u56e0\u4e3a\u5b83\u5728\u6570\u503c\u7a33\u5b9a\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u53d6\u5f97\u4e86\u4e0e\u4e25\u683c\u65b9\u6cd5\u76f8\u8fd1\u7684\u7ed3\u679c\u3002"}}
{"id": "2512.10639", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10639", "abs": "https://arxiv.org/abs/2512.10639", "authors": ["Lucas T. B. Mendes", "Alessandro V. M. Oliveira"], "title": "Codeshare agreements between airlines: literature review with the aid of artificial intelligence", "comment": null, "summary": "Codeshare agreements are contracts that allow two or more airlines to share seats on the same flight. These agreements, which are widespread in commercial aviation as a response to highly competitive environments, have enabled the expansion of airline networks without additional costs or risks for the companies involved. The literature presents ambiguous effects associated with the practice, with evidence of increased supply and reduced prices in situations of route complementarity, while also pointing to anti-competitive impacts in markets where companies act as competitors. A review of scientific production over time, including theoretical contributions and case studies, is essential to understand the evolution of these agreements and their implications, especially in the Brazilian context, marked by its own characteristics and particular regulatory history. Thus, this article reviews the literature on codesharing, with an emphasis on the Brazilian market, and uses the Litmaps computational tool, based on artificial intelligence techniques, to support the contextual analysis of publications through their citation relationships. The ultimate goal is to identify and evaluate the main evidence accumulated over decades on the effects of these agreements in Brazil. The joint analysis of the contributions allows us to outline the current state of knowledge, characterize specificities observed in the Brazilian market, and identify gaps that may guide future studies.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4ee3\u7801\u5171\u4eab\u534f\u8bae\u7684\u6587\u732e\u8fdb\u884c\u7efc\u8ff0\uff0c\u805a\u7126\u5df4\u897f\u5e02\u573a\uff0c\u68b3\u7406\u5176\u5bf9\u822a\u7ebf\u4f9b\u7ed9\u4e0e\u4ef7\u683c\u7684\u6f5c\u5728\u5f71\u54cd\u53ca\u76d1\u7ba1\u80cc\u666f\uff0c\u4f7f\u7528Litmaps\u7b49\u8ba1\u7b97\u5de5\u5177\u5206\u6790\u5f15\u6587\u5173\u7cfb\uff0c\u65e8\u5728\u63ed\u793a\u957f\u671f\u8bc1\u636e\u3001\u7279\u5b9a\u5e02\u573a\u7279\u5f81\u53ca\u672a\u6765\u7814\u7a76\u7a7a\u767d\u3002", "motivation": "\u7406\u89e3\u4ee3\u7801\u5171\u4eab\u5728\u7ade\u4e89\u4e0e\u534f\u540c\u4e2d\u7684\u4f5c\u7528\u53ca\u5176\u6f14\u5316\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u72ec\u7279\u76d1\u7ba1\u5386\u53f2\u7684\u5df4\u897f\u5e02\u573a\uff0c\u5e2e\u52a9\u5b66\u672f\u754c\u4e0e\u76d1\u7ba1\u8005\u628a\u63e1\u7814\u7a76\u65b9\u5411\u4e0e\u653f\u7b56\u542b\u4e49\u3002", "method": "\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u7ed3\u5408\u7406\u8bba\u4e0e\u6848\u4f8b\u7814\u7a76\uff1b\u4ee5Litmaps\u4f5c\u4e3a\u8ba1\u7b97\u5de5\u5177\u5206\u6790\u51fa\u7248\u7269\u4e4b\u95f4\u7684\u5f15\u6587\u5173\u7cfb\uff0c\u5e76\u805a\u7126\u5df4\u897f\u5e02\u573a\u7684\u8bc1\u636e\u4e0e\u7279\u5f81\u3002", "result": "\u603b\u7ed3\u4e86\u73b0\u6709\u7814\u7a76\u5728\u4f9b\u7ed9\u3001\u4ef7\u683c\u3001\u7ade\u4e89\u6548\u5e94\u4e0a\u7684\u4e0d\u4e00\u81f4\u7ed3\u8bba\uff1b\u68b3\u7406\u4e86\u5df4\u897f\u5e02\u573a\u7684\u7279\u6b8a\u6027\u4e0e\u76d1\u7ba1\u80cc\u666f\uff1b\u8bc6\u522b\u51fa\u7814\u7a76\u7a7a\u767d\u4e0e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u5bf9\u4ee3\u7801\u5171\u4eab\u7684\u77e5\u8bc6\u72b6\u6001\u8fdb\u884c\u5b9a\u6027\u68b3\u7406\uff0c\u5f3a\u8c03\u5df4\u897f\u5e02\u573a\u7684\u72ec\u7279\u6027\u4e0e\u8bc1\u636e\u7f3a\u53e3\uff0c\u547c\u5401\u672a\u6765\u5728\u76d1\u7ba1\u3001\u5e02\u573a\u7ed3\u6784\u4e0e\u5168\u7403\u6bd4\u8f83\u65b9\u9762\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2512.10104", "categories": ["cs.CR", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.10104", "abs": "https://arxiv.org/abs/2512.10104", "authors": ["Najmul Hassan", "Prashanth BusiReddyGari", "Haitao Zhao", "Yihao Ren", "Jinsheng Xu", "Shaohu Zhang"], "title": "LLM-PEA: Leveraging Large Language Models Against Phishing Email Attacks", "comment": "7 pages", "summary": "Email phishing is one of the most prevalent and globally consequential vectors of cyber intrusion. As systems increasingly deploy Large Language Models (LLMs) applications, these systems face evolving phishing email threats that exploit their fundamental architectures. Current LLMs require substantial hardening before deployment in email security systems, particularly against coordinated multi-vector attacks that exploit architectural vulnerabilities. This paper proposes LLMPEA, an LLM-based framework to detect phishing email attacks across multiple attack vectors, including prompt injection, text refinement, and multilingual attacks. We evaluate three frontier LLMs (e.g., GPT-4o, Claude Sonnet 4, and Grok-3) and comprehensive prompting design to assess their feasibility, robustness, and limitations against phishing email attacks. Our empirical analysis reveals that LLMs can detect the phishing email over 90% accuracy while we also highlight that LLM-based phishing email detection systems could be exploited by adversarial attack, prompt injection, and multilingual attacks. Our findings provide critical insights for LLM-based phishing detection in real-world settings where attackers exploit multiple vulnerabilities in combination.", "AI": {"tldr": "\u63d0\u51fa LLMPEA \u6846\u67b6\u7528\u4e8e\u8de8\u591a\u5411\u653b\u51fb\u7684\u9493\u9c7c\u90ae\u4ef6\u68c0\u6d4b\uff0c\u5b9e\u9a8c\u8868\u660e\u9ad8\u8fbe90%+\u51c6\u786e\u7387\uff0c\u4f46\u4e5f\u66b4\u9732\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u3001\u63d0\u793a\u6ce8\u5165\u4e0e\u591a\u8bed\u8a00\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u968f\u7740\u7cfb\u7edf\u90e8\u7f72LLMs\u7684\u90ae\u4ef6\u5b89\u5168\u5e94\u7528\uff0c\u9493\u9c7c\u653b\u51fb\u5728\u591a\u79cd\u5411\u91cf\u4e0a\u5229\u7528\u67b6\u6784\u8106\u5f31\u6027\uff0c\u8feb\u5207\u9700\u8981\u5728\u591a\u5411\u5411\u91cf\u4e0b\u7684\u9c81\u68d2\u68c0\u6d4b\u4e0e\u9632\u5fa1\u7b56\u7565\u3002", "method": "\u8bbe\u8ba1\u5e76\u8bc4\u4f30 LLMPEA \u6846\u67b6\uff0c\u4f7f\u7528\u4e09\u79cd\u524d\u6cbfLLM\uff08GPT-4o\u3001Claude Sonnet 4\u3001Grok-3\uff09\u53ca\u5168\u9762\u7684\u63d0\u793a\u8bbe\u8ba1\uff0c\u6d4b\u8bd5\u8de8\u63d0\u793a\u3001\u6587\u672c\u6539\u5199\u3001\u591a\u8bed\u8a00\u7b49\u591a\u5411\u91cf\u653b\u51fb\uff0c\u5bf9\u68c0\u6d4b\u53ef\u884c\u6027\u3001\u9c81\u68d2\u6027\u4e0e\u5c40\u9650\u6027\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0cLLMs \u80fd\u4ee5\u8d85\u8fc790%\u51c6\u786e\u7387\u68c0\u6d4b\u9493\u9c7c\u90ae\u4ef6\uff0c\u4f46\u4e5f\u53d1\u73b0\u53ef\u88ab\u5bf9\u6297\u653b\u51fb\u3001\u63d0\u793a\u6ce8\u5165\u548c\u591a\u8bed\u8a00\u653b\u51fb\u6240\u5229\u7528\uff0c\u9700\u8981\u8c28\u614e\u90e8\u7f72\u3002", "conclusion": "LLM \u57fa\u4e8e\u9493\u9c7c\u68c0\u6d4b\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u5f3a\u5316\u5bf9\u6297\u6027\u9632\u5fa1\u3001\u63d0\u793a\u8bbe\u8ba1\u4e0e\u7cfb\u7edf\u7ea7\u5b89\u5168\u6027\uff0c\u4ee5\u5b9e\u73b0\u73b0\u5b9e\u4e16\u754c\u7684\u53ef\u9760\u90e8\u7f72\u3002"}}
{"id": "2512.10051", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10051", "abs": "https://arxiv.org/abs/2512.10051", "authors": ["Moulik Gupta", "Achyut Mani Tripathi"], "title": "DB2-TransF: All You Need Is Learnable Daubechies Wavelets for Time Series Forecasting", "comment": null, "summary": "Time series forecasting requires models that can efficiently capture complex temporal dependencies, especially in large-scale and high-dimensional settings. While Transformer-based architectures excel at modeling long-range dependencies, their quadratic computational complexity poses limitations on scalability and adaptability. To overcome these challenges, we introduce DB2-TransF, a novel Transformer-inspired architecture that replaces the self-attention mechanism with a learnable Daubechies wavelet coefficient layer. This wavelet-based module efficiently captures multi-scale local and global patterns and enhances the modeling of correlations across multiple time series for the time series forecasting task. Extensive experiments on 13 standard forecasting benchmarks demonstrate that DB2-TransF achieves comparable or superior predictive accuracy to conventional Transformers, while substantially reducing memory usage for the time series forecasting task. The obtained experimental results position DB2-TransF as a scalable and resource-efficient framework for advanced time series forecasting. Our code is available at https://github.com/SteadySurfdom/DB2-TransF", "AI": {"tldr": "\u5f15\u5165\u53ef\u5b66\u4e60Daubechies\u5c0f\u6ce2\u7cfb\u6570\u5c42\u7684DB2-TransF\uff0c\u66ff\u4ee3\u81ea\u6ce8\u610f\u529b\u4ee5\u63d0\u5347\u5927\u89c4\u6a21\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u6548\u7387\uff1b\u572813\u4e2a\u57fa\u51c6\u4e0a\u4e0eTransformer\u76f8\u5f53/\u66f4\u4f18\uff0c\u4e14\u663e\u8457\u964d\u4f4e\u5185\u5b58\u4f7f\u7528\u3002", "motivation": "Transformer\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5bf9\u81ea\u6ce8\u610f\u529b\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\u9650\u5236\u4e86\u5728\u5927\u89c4\u6a21\u548c\u9ad8\u7ef4\u573a\u666f\u4e2d\u7684\u53ef\u6269\u5c55\u6027\uff1b\u9700\u8981\u4e00\u79cd\u80fd\u6709\u6548\u6355\u83b7\u591a\u5c3a\u5ea6\u6a21\u5f0f\u4e0e\u8de8\u5e8f\u5217\u76f8\u5173\u6027\u7684\u9ad8\u6548\u5efa\u6a21\u65b9\u5f0f\u3002", "method": "\u63d0\u51faDB2-TransF\uff0c\u8fd9\u662f\u4e00\u79cdTransformer\u542f\u53d1\u7684\u67b6\u6784\uff0c\u5c06\u81ea\u6ce8\u610f\u529b\u66ff\u6362\u4e3a\u53ef\u5b66\u4e60\u7684Daubechies\u5c0f\u6ce2\u7cfb\u6570\u5c42\uff0c\u7528\u4e8e\u9ad8\u6548\u5730\u6355\u6349\u591a\u5c3a\u5ea6\u672c\u5730\u4e0e\u5168\u5c40\u6a21\u5f0f\u53ca\u8de8\u65f6\u95f4\u5e8f\u5217\u7684\u76f8\u5173\u6027\u3002", "result": "\u572813\u4e2a\u6807\u51c6\u9884\u6d4b\u57fa\u51c6\u4e0a\uff0cDB2-TransF\u5b9e\u73b0\u4e86\u4e0e\u5e38\u89c4Transformer\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u7684\u5185\u5b58\u5f00\u9500\u3002", "conclusion": "DB2-TransF\u4e3a\u9ad8\u7ea7\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u8d44\u6e90\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u5177\u5907\u4e0eTransformer\u7ade\u4e89\u7684\u51c6\u786e\u6027\u4e0e\u66f4\u4f4e\u7684\u8d44\u6e90\u9700\u6c42\u3002\u4ee3\u7801\u53ef\u5728GitHub\u83b7\u53d6\u3002"}}
{"id": "2512.10829", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10829", "abs": "https://arxiv.org/abs/2512.10829", "authors": ["Vitor G. P. Curtarelli"], "title": "Comparative analysis of WNG-DF compromising beamformers", "comment": null, "summary": "This work studies beamformers designed to achieve multiple characteristics simultaneously, specifically those compromising white-noise gain and directivity factor. We compare methods explicitly designed for these joint features against those obtained by combining specific single-task beamformers. Through simulations, we demonstrate that the robust superdirective and the tunable beamformers yield the best results among those studied. Notably, these two methods produced nearly identical outputs across all evaluated metrics. These two are also more practical, continuously compromising between the two objectives.", "AI": {"tldr": "\u5bf9\u591a\u76ee\u6807\u6ce2\u675f\u5f62\u6210\u7684\u6bd4\u8f83\u7814\u7a76\uff1a\u5728\u517c\u987e\u767d\u566a\u58f0\u589e\u76ca\u4e0e\u6307\u5411\u6027\u56e0\u5b50\u7684\u524d\u63d0\u4e0b\uff0c\u6bd4\u8f83\u4e13\u95e8\u4e3a\u8054\u5408\u76ee\u6807\u8bbe\u8ba1\u7684\u6ce2\u675f\u5f62\u6210\u5668\u4e0e\u901a\u8fc7\u7ec4\u5408\u5355\u4efb\u52a1\u6ce2\u675f\u5f62\u6210\u5668\u5f97\u5230\u7684\u65b9\u6848\uff0c\u7ed3\u679c\u663e\u793a\u9c81\u68d2\u8d85\u6307\u5411\u6027\u548c\u53ef\u8c03\u6ce2\u675f\u5f62\u6210\u5668\u5728\u6027\u80fd\u4e0a\u6700\u4f73\u4e14\u8f93\u51fa\u5728\u5404\u8bc4\u4f30\u6307\u6807\u4e0a\u51e0\u4e4e\u4e00\u81f4\uff0c\u4e14\u66f4\u5177\u5b9e\u7528\u6027\uff0c\u80fd\u5728\u4e24\u76ee\u6807\u4e4b\u95f4\u6301\u7eed\u6298\u8877\u3002", "motivation": "\u63a2\u7d22\u540c\u65f6\u5b9e\u73b0\u767d\u566a\u58f0\u589e\u76ca\u4e0e\u6307\u5411\u6027\u7b49\u591a\u76ee\u6807\u7684\u6ce2\u675f\u5f62\u6210\u5668\u8bbe\u8ba1\uff0c\u5e76\u8bc4\u4f30\u4e13\u95e8\u7684\u8054\u5408\u8bbe\u8ba1\u65b9\u6cd5\u4e0e\u901a\u8fc7\u7ec4\u5408\u5355\u4efb\u52a1\u6ce2\u675f\u5f62\u6210\u5668\u5f97\u5230\u7684\u65b9\u6848\u4e4b\u95f4\u7684\u6027\u80fd\u4e0e\u5b9e\u9645\u53ef\u7528\u6027\u3002", "method": "\u901a\u8fc7\u4eff\u771f\u5bf9\u6bd4\uff1a\u6bd4\u8f83\u4e3a\u8fd9\u4e24\u9879\u8054\u5408\u7279\u5f81\u8bbe\u8ba1\u7684\u6ce2\u675f\u5f62\u6210\u65b9\u6cd5\u4e0e\u901a\u8fc7\u7ec4\u5408\u7279\u5b9a\u5355\u4efb\u52a1\u6ce2\u675f\u5f62\u6210\u5668\u5f97\u5230\u7684\u65b9\u6848\u7684\u6027\u80fd\uff1b\u91cd\u70b9\u5206\u6790\u9c81\u68d2\u8d85\u6307\u5411\u6027\u4e0e\u53ef\u8c03\u6ce2\u675f\u5f62\u6210\u5668\u7684\u8868\u73b0\u4e0e\u8f93\u51fa\u4e00\u81f4\u6027\u3002", "result": "\u9c81\u68d2\u8d85\u6307\u5411\u6027\u4e0e\u53ef\u8c03\u6ce2\u675f\u5f62\u6210\u5668\u5728\u6240\u7814\u7a76\u7684\u65b9\u6848\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4e14\u5728\u6240\u6709\u8bc4\u4f30\u6307\u6807\u4e0a\u8f93\u51fa\u51e0\u4e4e\u76f8\u540c\uff1b\u8fd9\u4e24\u79cd\u65b9\u6cd5\u66f4\u5177\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u80fd\u591f\u5728\u4e24\u76ee\u6807\u4e4b\u95f4\u6301\u7eed\u6298\u8877\u3002", "conclusion": "\u4e13\u95e8\u4e3a\u8054\u5408\u76ee\u6807\u8bbe\u8ba1\u7684\u9c81\u68d2\u8d85\u6307\u5411\u6027\u4e0e\u53ef\u8c03\u6ce2\u675f\u5f62\u6210\u5668\u5728\u672c\u7814\u7a76\u4e2d\u80dc\u51fa\uff0c\u4e14\u63d0\u4f9b\u8fde\u7eed\u53ef\u63a7\u7684\u6743\u8861\uff0c\u9002\u5408\u4f5c\u4e3a\u517c\u987e\u767d\u566a\u58f0\u589e\u76ca\u4e0e\u6307\u5411\u6027\u7684\u5b9e\u7528\u89e3\u3002"}}
{"id": "2512.10657", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10657", "abs": "https://arxiv.org/abs/2512.10657", "authors": ["Seth Siriya", "Tobias M. Wolff", "Victor G. Lopez", "Matthias A. M\u00fcller"], "title": "Estimating Hormone Concentrations in the Pituitary-Thyroid Feedback Loop from Irregularly Sampled Measurements", "comment": "8 pages; This work has been submitted to IFAC for possible publication", "summary": "Model-based control techniques have recently been investigated for the recommendation of medication dosages to address thyroid diseases. These techniques often rely on knowledge of internal hormone concentrations that cannot be measured from blood samples. Moreover, the measurable concentrations are typically only obtainable at irregular sampling times. In this work, we empirically verify a notion of sample-based detectability that accounts for irregular sampling of the measurable concentrations on two pituitary-thyroid loop models representing patients with hypo- and hyperthyroidism, respectively, and include the internal concentrations as states. We then implement sample-based moving horizon estimation for the models, and test its performance on virtual patients across a range of sampling schemes. Our study shows robust stability of the estimator across all scenarios, and that more frequent sampling leads to less estimation error in the presence of model uncertainty and misreported dosages.", "AI": {"tldr": "\u5728\u7532\u72b6\u817a\u75be\u75c5\u836f\u7269\u5242\u91cf\u7684\u6a21\u578b\u9a71\u52a8\u63a7\u5236\u4e2d\uff0c\u7814\u7a76\u5728\u4e0d\u53ef\u89c2\u6d4b\u5185\u90e8\u6fc0\u7d20\u4e0e\u4e0d\u89c4\u5219\u91c7\u6837\u6761\u4ef6\u4e0b\uff0c\u57fa\u4e8e\u6837\u672c\u7684\u79fb\u52a8\u9884\u6d4b\u4f30\u8ba1\uff08MHE\uff09\u5bf9 pituitary-thyroid \u5faa\u73af\u6a21\u578b\u7684\u9c81\u68d2\u6027\u4e0e\u4f30\u8ba1\u8bef\u5dee\u8fdb\u884c\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u66f4\u9ad8\u91c7\u6837\u9891\u7387\u53ef\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4e0e\u5242\u91cf\u8bef\u62a5\u60c5\u5f62\u4e0b\u964d\u4f4e\u4f30\u8ba1\u8bef\u5dee\u4e14\u4f30\u8ba1\u7a33\u5b9a\u3002", "motivation": "\u89e3\u51b3\u5185\u90e8\u6fc0\u7d20\u6d53\u5ea6\u4e0d\u53ef\u76f4\u63a5\u6d4b\u91cf\u4e14\u8840\u6837\u6d4b\u91cf\u7684\u91c7\u6837\u65f6\u70b9\u4e0d\u89c4\u5219\u7684\u95ee\u9898\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u836f\u7269\u5242\u91cf\u7684\u66f4\u7cbe\u51c6\u63a7\u5236\uff0c\u63d0\u5347\u4e2a\u4f53\u5316\u6cbb\u7597\u7684\u5b89\u5168\u6027\u4e0e\u6709\u6548\u6027\u3002", "method": "\u6784\u5efa\u4e24\u79cd\u4ee3\u8868\u6027 hypo- \u4e0e hyperthyroidism \u7684 pituitary-thyroid \u5faa\u73af\u6a21\u578b\uff0c\u5c06\u5185\u90e8\u6d53\u5ea6\u4f5c\u4e3a\u72b6\u6001\u53d8\u91cf\uff1b\u63d0\u51fa\u6837\u672c\u57fa\u53ef\u68c0\u6d4b\u6027\u6982\u5ff5\u4ee5\u9002\u5e94\u4e0d\u89c4\u5219\u91c7\u6837\uff1b\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u6837\u672c\u57fa\u79fb\u52a8\u9884\u6d4b\u4f30\u8ba1\uff08MHE\uff09\uff0c\u5bf9\u865a\u62df\u60a3\u8005\u5728\u4e0d\u540c\u91c7\u6837\u65b9\u6848\u4e0b\u8fdb\u884c\u4eff\u771f\u4e0e\u8bc4\u4f30\u3002", "result": "\u5728\u6240\u6709\u573a\u666f\u4e2d\uff0c\u4f30\u8ba1\u5668\u8868\u73b0\u51fa\u9c81\u68d2\u7a33\u5b9a\u6027\uff1b\u66f4\u9ad8\u7684\u91c7\u6837\u9891\u7387\u964d\u4f4e\u4e86\u4f30\u8ba1\u8bef\u5dee\uff0c\u4e14\u5728\u5b58\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u548c\u5242\u91cf\u8bef\u62a5\u7684\u6761\u4ef6\u4e0b\u4ecd\u4fdd\u6301\u826f\u597d\u6027\u80fd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8bc1\u660e\u4e86\u5728\u4e0d\u89c4\u5219\u62bd\u6837\u4e0e\u4e0d\u53ef\u76f4\u63a5\u89c2\u6d4b\u72b6\u6001\u4e0b\uff0c\u6837\u672c\u57fa MHE \u5177\u6709\u826f\u597d\u9c81\u68d2\u6027\u548c\u53ef\u884c\u6027\uff0c\u53ef\u7528\u4e8e\u7532\u72b6\u817a\u75be\u75c5\u7684\u4e2a\u6027\u5316\u836f\u7269\u5242\u91cf\u63a7\u5236\uff1b\u672a\u6765\u5de5\u4f5c\u53ef\u8fdb\u4e00\u6b65\u5728\u771f\u5b9e\u60a3\u8005\u6570\u636e\u4e0a\u8fdb\u884c\u9a8c\u8bc1\uff0c\u589e\u5f3a\u5bf9\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u5904\u7406\uff0c\u5e76\u4f18\u5316\u5b9e\u65f6\u5b9e\u73b0\u7684\u8ba1\u7b97\u6027\u80fd\u3002"}}
{"id": "2512.10056", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10056", "abs": "https://arxiv.org/abs/2512.10056", "authors": ["Alireza Namazi", "Amirreza Dolatpour Fathkouhi", "Heman Shakeri"], "title": "Mitigating Exposure Bias in Risk-Aware Time Series Forecasting with Soft Tokens", "comment": null, "summary": "Autoregressive forecasting is central to predictive control in diabetes and hemodynamic management, where different operating zones carry different clinical risks. Standard models trained with teacher forcing suffer from exposure bias, yielding unstable multi-step forecasts for closed-loop use. We introduce Soft-Token Trajectory Forecasting (SoTra), which propagates continuous probability distributions (``soft tokens'') to mitigate exposure bias and learn calibrated, uncertainty-aware trajectories. A risk-aware decoding module then minimizes expected clinical harm. In glucose forecasting, SoTra reduces average zone-based risk by 18\\%; in blood-pressure forecasting, it lowers effective clinical risk by approximately 15\\%. These improvements support its use in safety-critical predictive control.", "AI": {"tldr": "SoTra introduces Soft-Token Trajectory Forecasting to mitigate exposure bias in autoregressive medical forecasting, enabling uncertainty-aware, risk-minimized predictions; demonstrates 18% reduction in zone-based risk for glucose forecasting and ~15% reduction in effective clinical risk for blood pressure forecasting.", "motivation": "Standard teacher-forcing autoregressive models suffer from exposure bias, leading to unstable multi-step forecasts in safety-critical predictive control settings like diabetes and hemodynamic management. There is a need for calibrated uncertainty-aware trajectory forecasting and risk-aware control to minimize clinical harm.", "method": "SoTra propagates continuous probability distributions (soft tokens) to mitigate exposure bias and learn calibrated trajectories. A risk-aware decoding module then minimizes expected clinical harm during forecasting.", "result": "In glucose forecasting, SoTra reduces average zone-based risk by 18%; in blood-pressure forecasting, it lowers effective clinical risk by ~15%.", "conclusion": "SoTra provides calibrated, uncertainty-aware trajectory forecasting with a risk-aware decoding mechanism, improving safety and applicability of autoregressive predictive control in safety-critical medical contexts."}}
{"id": "2512.10832", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10832", "abs": "https://arxiv.org/abs/2512.10832", "authors": ["Karel P\u00e4rlin", "Aaron Byman", "Tommi Meril\u00e4inen", "Taneli Riihonen"], "title": "A Variable Step Sizes Frequency Offsets-Compensated Least Mean Squares Algorithm", "comment": "Submitted to an IEEE journal", "summary": "Frequency offsets-compensated least mean squares (FO-LMS) algorithm is a generic method for estimating a wireless channel under carrier and sampling frequency offsets when the transmitted signal is beforehand known to the receiver. The algorithm iteratively and explicitly adjusts its estimates of the channel and frequency offsets using stochastic gradient descent-based rules and the step sizes of these rules determine the learning rate and stability of the algorithm. Within the stability conditions, the choice of step sizes reflects a trade-off between the algorithm's ability to react to changes in the channel and the ability to minimize misadjustments caused by noise. This paper provides theoretical expressions to predict and optimize the tracking and misadjusment errors of FO-LMS when estimating channels and frequency offsets with known time-varying characteristics. This work also proposes a method to adjust the FO-LMS's step sizes based on the algorithm's performance when the time-varying characteristics are not known, which is more often the case in practice. Accuracy of the expressions and performance of the proposed variable step sizes algorithm are studied through simulations.", "AI": {"tldr": "FO-LMS\u662f\u4e00\u79cd\u5728\u8f7d\u6ce2\u4e0e\u91c7\u6837\u9891\u504f\u5b58\u5728\u65f6\u5bf9\u4fe1\u9053\u8fdb\u884c\u4f30\u8ba1\u7684\u901a\u7528\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u6b65\u957f\u4ee5\u5e73\u8861\u8ddf\u8e2a\u80fd\u529b\u4e0e\u6297\u566a\u58f0\u7684\u7a33\u5065\u6027\u3002", "motivation": "\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\uff0c\u4fe1\u9053\u548c\u9891\u504f\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u9700\u8981\u9c81\u68d2\u4e14\u81ea\u9002\u5e94\u7684\u4f30\u8ba1\u7b97\u6cd5\u6765\u4fdd\u6301\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u9891\u504f\u8865\u507f\u7684LMS\u6846\u67b6\uff0c\u901a\u8fc7\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u8fed\u4ee3\u66f4\u65b0\u4fe1\u9053\u548c\u9891\u504f\u4f30\u8ba1\uff1b\u63a8\u5bfc\u7a33\u5b9a\u6027\u6761\u4ef6\u53ca\u5b66\u4e60\u7387\u5bf9\u8ddf\u8e2a\u8bef\u5dee\u548c\u5931\u914d\u8bef\u5dee\u7684\u7406\u8bba\u8868\u8fbe\uff1b\u63d0\u51fa\u5728\u65f6\u53d8\u7279\u6027\u672a\u77e5\u65f6\u7684\u81ea\u9002\u5e94\u6b65\u957f\u8c03\u6574\u7b56\u7565\uff1b\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u7406\u8bba\u8868\u8fbe\u4e0e\u81ea\u9002\u5e94\u6b65\u957f\u7684\u6709\u6548\u6027\u3002", "result": "\u7ed9\u51fa\u8ddf\u8e2a\u8bef\u5dee\u4e0e\u5931\u914d\u8bef\u5dee\u7684\u7406\u8bba\u8868\u8fbe\u5f0f\uff1b\u81ea\u9002\u5e94\u6b65\u957f\u63d0\u5347\u5728\u672a\u77e5\u65f6\u53d8\u7279\u6027\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u6536\u655b\u6027\uff1b\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u7406\u8bba\u9884\u6d4b\u4e0e\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u5728\u5b58\u5728\u65f6\u53d8\u4fe1\u9053\u548c\u9891\u504f\u7684\u65e0\u7ebf\u573a\u666f\u4e2d\uff0cFO-LMS\u53ef\u901a\u8fc7\u81ea\u9002\u5e94\u6b65\u957f\u5b9e\u73b0\u66f4\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u4fe1\u9053\u4e0e\u9891\u504f\u4f30\u8ba1\uff0c\u5c24\u5176\u5728\u65f6\u53d8\u7279\u6027\u672a\u77e5\u65f6\u4ecd\u80fd\u4fdd\u6301\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2512.10684", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10684", "abs": "https://arxiv.org/abs/2512.10684", "authors": ["Shaopeng Hu", "Shaowen Miao", "Jan Komenda", "Zhiwu Li"], "title": "Active prognosis and diagnosis of modular discrete-event systems", "comment": null, "summary": "This paper addresses the verification and enforcement of prognosability and diagnosability for discreteevent systems (DESs) modeled by deterministic finite automata. We establish the equivalence between prognosability (respectively, diagnosability) and pre-normality over a subset of the non-faulty language (respectively, a suffix of the faulty language). We then demonstrate the existence of supremal prognosable (respectively, diagnosable) and normal sublanguages. Furthermore, an algorithm is then designed to compute the supremal controllable, normal, and prognosable (respectively, diagnosable) sublanguages. Since DESs are typically composed of multiple components operating in parallel, pure local supervisors are generally insufficient, as prognosability and diagnosability are global properties of a system. Given the limited work on enforcing prognosability or diagnosability in modular DESs, where these properties are enforced through local supervisors, this paper leverages a refined version of pre-normality to compute modular supervisors for local subsystems. The resulting closed-loop system is shown to be globally controllable, normal, and prognosable/ diagnosable. Examples are provided to illustrate the proposed method.", "AI": {"tldr": "\u63d0\u51fa\u5728\u79bb\u6563\u4e8b\u4ef6\u7cfb\u7edf(DES)\u4e2d\u5bf9\u9884\u77e5\u6027(prognosability)\u4e0e\u8bca\u65ad\u6027(diagnosability)\u8fdb\u884c\u9a8c\u8bc1\u4e0e\u5f3a\u5236\uff0c\u5efa\u7acb\u4e86\u4e0e\u5728\u5b50\u96c6\u4e0d\u826f\u8bed\u8a00\u4e0a\u7684\u524d\u5f52\u4e00\u6027(pre-normality)\u7b49\u4ef7\u7684\u5173\u7cfb\uff0c\u8bc1\u660e\u5b58\u5728\u6781\u5927\u53ef\u63a7\u7684\u3001\u6b63\u5e38\u7684\u3001\u4e14\u5177\u9884\u77e5\u6027/\u8bca\u65ad\u6027\u7684\u8bed\u8a00\u5b50\u8bed\u8a00\uff0c\u5e76\u7ed9\u51fa\u8ba1\u7b97\u6781\u5927\u5b50\u8bed\u8a00\u7684\u7b97\u6cd5\uff1b\u8fd8\u5c06\u8be5\u6846\u67b6\u6269\u5c55\u81f3\u6a21\u5757\u5316DES\uff0c\u501f\u52a9\u6539\u8fdb\u7684\u524d\u5f52\u4e00\u6027\u5b9e\u73b0\u5c40\u90e8\u5b50\u7cfb\u7edf\u7684\u5168\u5c40\u4e00\u81f4\u6027\u63a7\u5236\u4e0e\u8bca\u65ad\u6027\u4fdd\u8bc1\u3002", "motivation": "\u5728\u590d\u6742\u7684\u79bb\u6563\u4e8b\u4ef6\u7cfb\u7edf\u4e2d\uff0c\u5c3d\u65e9\u4e14\u53ef\u9760\u5730\u9884\u6d4b\u548c\u8bca\u65ad\u7cfb\u7edf\u6545\u969c\u5bf9\u4fdd\u969c\u5b89\u5168\u6027\u548c\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u5de5\u4f5c\u5728\u6a21\u5757\u5316\u7cfb\u7edf\u4e2d\u96be\u4ee5\u5b9e\u73b0\u5168\u5c40\u6027\u8d28\u7684\u9884\u77e5\u6027/\u8bca\u65ad\u6027\uff0c\u56e0\u6b64\u9700\u8981\u7406\u8bba\u7b49\u4ef7\u6027\u3001\u6781\u5927\u5b50\u8bed\u8a00\u7684\u5b58\u5728\u6027\u4ee5\u53ca\u53ef\u8ba1\u7b97\u7b97\u6cd5\u6765\u5b9e\u73b0\u5bf9\u5355\u5143\u53ca\u6a21\u5757\u7684\u53ef\u63a7\u3001\u6b63\u5e38\u4e0e\u9884\u77e5/\u8bca\u65ad\u5b50\u8bed\u8a00\u7684\u6784\u9020\u4e0e enforcement\u3002", "method": "\u5efa\u7acb\u9884\u77e5\u6027/\u8bca\u65ad\u6027\u4e0e\u524d\u5f52\u4e00\u6027\u4e4b\u95f4\u7684\u7b49\u4ef7\u6027\uff08\u5206\u522b\u5728\u975e\u6545\u969c\u8bed\u8a00\u5b50\u96c6\u548c\u6545\u969c\u8bed\u8a00\u540e\u7f00\u4e0a\uff09\uff1b\u8bc1\u660e\u5b58\u5728\u6781\u5927\u53ef\u63a7\u3001\u6b63\u5e38\u4e14\u9884\u77e5\u6027/\u8bca\u65ad\u6027\u7684\u5b50\u8bed\u8a00\u53ca\u5176\u5b58\u5728\u6027\uff1b\u8bbe\u8ba1\u7b97\u6cd5\u8ba1\u7b97\u8fd9\u4e9b\u6781\u5927\u5b50\u8bed\u8a00\uff0c\u5e76\u5c06\u65b9\u6cd5\u63a8\u5e7f\u5230\u6a21\u5757\u5316DES\uff0c\u901a\u8fc7\u6539\u8fdb\u7684\u524d\u5f52\u4e00\u6027\u5b9e\u73b0\u5c40\u90e8\u5b50\u7cfb\u7edf\u7684\u5168\u5c40\u53ef\u63a7\u3001\u6b63\u5e38\u4e0e\u9884\u77e5\u6027/\u8bca\u65ad\u6027\uff1b\u7ed9\u51fa\u5b9e\u4f8b\u4ee5\u8bf4\u660e\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u4e0a\u7ed9\u51fa\u9884\u77e5\u6027\u4e0e\u8bca\u65ad\u6027\u7684\u7b49\u4ef7\u6027\u3001\u6781\u5927\u5b50\u8bed\u8a00\u7684\u5b58\u5728\u6027\u548c\u53ef\u8ba1\u7b97\u6027\uff0c\u4ee5\u53ca\u6a21\u5757\u5316\u7cfb\u7edf\u4e2d\u5c40\u90e8\u63a7\u5236\u5668\u5728\u5168\u5c40\u5c42\u9762\u5b9e\u73b0\u53ef\u63a7\u3001\u6b63\u5e38\u548c\u9884\u77e5/\u8bca\u65ad\u6027\u7684\u7ed3\u8bba\uff1b\u63d0\u4f9b\u4e86\u7528\u4e8e\u5b9e\u73b0\u7684\u7b97\u6cd5\u5e76\u901a\u8fc7\u793a\u4f8b\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u5728\u5355\u4f53\u53ca\u6a21\u5757\u5316DES\u4e2d\u5f3a\u5236\u5b9e\u73b0\u9884\u77e5\u6027\u4e0e\u8bca\u65ad\u6027\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u7406\u8bba\u57fa\u7840\u548c\u53ef\u6267\u884c\u7b97\u6cd5\uff0c\u786e\u4fdd\u95ed\u73af\u7cfb\u7edf\u5728\u5168\u5c40\u5c42\u9762\u5177\u5907\u53ef\u63a7\u3001\u6b63\u5e38\u4ee5\u53ca\u9884\u77e5\u6027/\u8bca\u65ad\u6027\uff0c\u5e76\u5bf9\u540e\u7eed\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u5177\u6709\u6f5c\u5728\u73b0\u5b9e\u610f\u4e49\u3002"}}
{"id": "2512.10185", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.10185", "abs": "https://arxiv.org/abs/2512.10185", "authors": ["Yangkun Wang", "Jingbo Shang"], "title": "Watermarks for Language Models via Probabilistic Automata", "comment": null, "summary": "A recent watermarking scheme for language models achieves distortion-free embedding and robustness to edit-distance attacks. However, it suffers from limited generation diversity and high detection overhead. In parallel, recent research has focused on undetectability, a property ensuring that watermarks remain difficult for adversaries to detect and spoof. In this work, we introduce a new class of watermarking schemes constructed through probabilistic automata. We present two instantiations: (i) a practical scheme with exponential generation diversity and computational efficiency, and (ii) a theoretical construction with formal undetectability guarantees under cryptographic assumptions. Extensive experiments on LLaMA-3B and Mistral-7B validate the superior performance of our scheme in terms of robustness and efficiency.", "AI": {"tldr": "\u901a\u8fc7\u6982\u7387\u81ea\u52a8\u673a\u6784\u5efa\u7684\u65b0\u578b\u6c34\u5370\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u5931\u771f\u5d4c\u5165\u3001\u5bf9\u6297\u7f16\u8f91\u8ddd\u79bb\u653b\u51fb\u7684\u9c81\u68d2\u6027\u7b49\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u4f9b\u5b9e\u8df5\u4e0e\u7406\u8bba\u4e24\u79cd\u5b9e\u73b0\uff0c\u5b9e\u9a8c\u8868\u660e\u5728LLaMA-3B\u53caMistral-7B\u4e0a\u5177\u6709\u8f83\u9ad8\u7684\u751f\u6210\u591a\u6837\u6027\u548c\u68c0\u6d4b\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u6c34\u5370\u65b9\u6848\u5728\u5d4c\u5165\u5931\u771f\u3001\u9c81\u68d2\u6027\u4e0e\u751f\u6210\u591a\u6837\u6027\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u4e14\u68c0\u6d4b\u6210\u672c\u9ad8/\u96be\u4ee5\u5b9e\u73b0\u4e0d\u53ef\u68c0\u6d4b\u6027\u3002\u9700\u8981\u4e00\u79cd\u5728\u591a\u6837\u6027\u3001\u6548\u7387\u548c\u4e0d\u53ef\u68c0\u6d4b\u6027\u4e4b\u95f4\u66f4\u5e73\u8861\u7684\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u6982\u7387\u81ea\u52a8\u673a\u6784\u9020\u6c34\u5370\u65b9\u6848\uff0c\u63d0\u51fa\u4e24\u79cd\u5b9e\u73b0\uff1a1) \u5b9e\u7528\u578b\uff0c\u5177\u6709\u6307\u6570\u7ea7\u7684\u751f\u6210\u591a\u6837\u6027\u4e14\u8ba1\u7b97\u9ad8\u6548\uff1b2) \u7406\u8bba\u578b\uff0c\u5728\u5bc6\u7801\u5b66\u5047\u8bbe\u4e0b\u63d0\u4f9b\u5f62\u5f0f\u5316\u7684\u4e0d\u53ef\u68c0\u6d4b\u6027\u4fdd\u8bc1\u3002\u901a\u8fc7\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982 LLaMA-3B\u3001Mistral-7B\uff09\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5728\u9c81\u68d2\u6027\u4e0e\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u5177\u6709\u6781\u9ad8\u7684\u751f\u6210\u591a\u6837\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u7406\u8bba\u4fdd\u8bc1\u5728\u67d0\u4e9b\u5047\u8bbe\u4e0b\u6210\u7acb\uff0c\u5b9e\u9a8c\u7ed3\u679c\u652f\u6301\u5176\u5728\u5b9e\u9645\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7c7b\u6c34\u5370\u65b9\u6848\uff0c\u517c\u5177\u4e0d\u53ef\u68c0\u6d4b\u6027\u8bc1\u660e\u4e0e\u5b9e\u8df5\u6027\u80fd\uff0c\u53ef\u663e\u8457\u63d0\u9ad8\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\u4e0e\u5e94\u7528\u573a\u666f\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2512.10833", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10833", "abs": "https://arxiv.org/abs/2512.10833", "authors": ["Karel P\u00e4rlin", "Aaron Byman", "Tommi Meril\u00e4inen", "Taneli Riihonen"], "title": "Decision Feedback-Aided Known-Interference Cancellation", "comment": "Submitted to an IEEE journal", "summary": "Known-interference cancellation (KIC) in combination with cooperative jamming can be used to provide covertness and security to wireless communications at the physical layer. However, since the signal of interest (SI) of a wireless communication system acts as estimation noise, i.e., interference, to KIC, the SI limits the extent to which the known interference (KI) can be canceled and that in turn limits the throughput of the wireless communication system that is being hidden or secured. In this letter, we analyze a decision feedback-aided known-interference cancellation (DF-KIC) structure in which both the KI and SI are canceled iteratively and successively. Measurement results demonstrate that introducing decision feedback to KIC improves its KI cancellation capability and hence increases the wireless communication system's useful throughput, albeit at the expense of a higher computational load.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u51b3\u7b56\u53cd\u9988\u8f85\u52a9\u7684\u5df2\u77e5\u5e72\u6270\u6d88\u9664\uff08DF-KIC\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u5730\u540c\u65f6\u6d88\u9664KI\u548cSI\uff0c\u63d0\u5347KI\u6d88\u9664\u80fd\u529b\u548c\u7cfb\u7edf\u541e\u5410\uff0c\u4f46\u589e\u52a0\u8ba1\u7b97\u8d1f\u8f7d\u3002", "motivation": "\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\uff0cKI\u82e5\u8981\u88ab\u6709\u6548\u6d88\u9664\uff0cSI\u4f1a\u4f5c\u4e3a\u4f30\u8ba1\u566a\u58f0\u5e72\u6270KI\uff0c\u9650\u5236\u53ef\u6d88\u9664\u5e72\u6270\u7684\u7a0b\u5ea6\uff0c\u4ece\u800c\u964d\u4f4e\u9690\u85cf/\u5b89\u5168\u4f20\u8f93\u7684\u541e\u5410\u6f5c\u529b\uff0c\u9700\u8981\u6539\u8fdb\u7684\u5e72\u6270\u6291\u5236\u673a\u5236\u3002", "method": "\u63d0\u51faDF-KIC\u7ed3\u6784\uff0c\u5229\u7528\u51b3\u7b56\u53cd\u9988\u9010\u6b65\u3001\u8fed\u4ee3\u5730\u540c\u65f6\u5bf9KI\u548cSI\u8fdb\u884c\u6d88\u9664\uff0c\u4f7fKI\u6d88\u9664\u80fd\u529b\u4e0eSI\u5e72\u6270\u76f8\u4e92\u914d\u5408\uff0c\u63d0\u5347\u6574\u4f53\u6027\u80fd\u3002", "result": "\u6d4b\u91cf\u7ed3\u679c\u8868\u660e\uff0c\u5f15\u5165\u51b3\u7b56\u53cd\u9988\u53ef\u663e\u8457\u63d0\u9ad8KI\u6d88\u9664\u80fd\u529b\u548c\u6709\u7528\u541e\u5410\u91cf\uff0c\u4f46\u4f34\u968f\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u63d0\u9ad8\u3002", "conclusion": "DF-KIC\u5728\u5e73\u8861\u5e72\u6270\u6d88\u9664\u548c\u8ba1\u7b97\u6210\u672c\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u53ef\u5728\u5408\u9002\u5b9e\u73b0\u6761\u4ef6\u4e0b\u63d0\u5347\u9690\u853d\u901a\u4fe1\u7cfb\u7edf\u7684\u541e\u5410\u3002"}}
{"id": "2512.10738", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.10738", "abs": "https://arxiv.org/abs/2512.10738", "authors": ["Lukas Vogel", "Andrea Carron", "Eleftherios E. Vlahakis", "Dimos V. Dimarogonas"], "title": "Distribution-Free Stochastic MPC for Joint-in-Time Chance-Constrained Linear Systems", "comment": null, "summary": "This work presents a stochastic model predictive control (MPC) framework for linear systems subject to joint-in-time chance constraints under unknown disturbance distributions. Unlike existing stochastic MPC formulations that rely on parametric or Gaussian assumptions or require expensive offline computations, the proposed method leverages conformal prediction (CP) as a streamlined tool to construct finite-sample confidence regions for the system's stochastic error trajectories with minimal computational effort. These regions enable the relaxation of probabilistic constraints while providing formal guarantees. By employing an indirect feedback mechanism and a probabilistic set-based formulation, we prove recursive feasibility of the relaxed optimization problem and establish chance constraint satisfaction in closed-loop. Furthermore, we extend the approach to the more general output feedback setting with unknown measurement noise distributions. Given available noise samples, we establish satisfaction of the joint chance constraints and recursive feasibility via output measurements alone. Numerical examples demonstrate the effectiveness and advantages of the proposed method compared to existing approaches.", "AI": {"tldr": "\u5c06 conformal prediction \u5e94\u7528\u4e8e\u968f\u673a\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff0c\u5229\u7528\u6709\u9650\u6837\u672c\u8bef\u5dee\u533a\u57df\u6765\u653e\u5bbd\u8054\u5408\u65f6\u7ea6\u675f\u5e76\u63d0\u4f9b\u5f62\u5f0f\u4fdd\u8bc1\uff0c\u540c\u65f6\u5728\u672a\u77e5\u6270\u52a8\u5206\u5e03\u548c\u566a\u58f0\u5206\u5e03\u4e0b\u5b9e\u73b0\u9012\u5f52\u53ef\u884c\u6027\u4e0e\u95ed\u73af\u7ea6\u675f\u6ee1\u8db3\uff0c\u4e14\u53ef\u6269\u5c55\u5230\u8f93\u51fa\u53cd\u9988\u3002", "motivation": "\u73b0\u6709\u968f\u673aMPC\u5f80\u5f80\u4f9d\u8d56\u53c2\u6570\u5316\u3001\u9ad8\u65af\u5047\u8bbe\u6216\u79bb\u7ebf\u8ba1\u7b97\uff0c\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u4f4e\u8ba1\u7b97\u6210\u672c\u3001\u5177\u6709\u5f62\u5f0f\u4fdd\u969c\u7684\u5bf9\u672a\u77e5\u6270\u52a8\u5206\u5e03\u7684\u9c81\u68d2\u6027\u5904\u7406\u65b9\u6cd5\uff0c\u63d0\u5347\u5bf9\u8054\u5408\u65f6\u7ea6\u675f\u7684\u53ef\u63a7\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "\u901a\u8fc7 conformal prediction \u6784\u5efa\u7cfb\u7edf\u968f\u673a\u8bef\u5dee\u8f68\u8ff9\u7684\u6709\u9650\u6837\u672c\u7f6e\u4fe1\u533a\u57df\uff0c\u5c06\u6982\u7387\u7ea6\u675f\u8f6c\u5316\u4e3a\u4ee5\u7f6e\u4fe1\u96c6\u4e3a\u57fa\u7840\u7684\u6982\u7387\u96c6\u5408\u4f18\u5316\u95ee\u9898\uff1b\u91c7\u7528 indirect feedback \u4e0e\u6982\u7387\u96c6\u5408\u5f62\u6210\u7684\u9012\u5f52\u53ef\u884c\u6027\u5206\u6790\uff1b\u62d3\u5c55\u5230\u8f93\u51fa\u53cd\u9988\u60c5\u5f62\uff0c\u5728\u6709\u566a\u58f0\u6837\u672c\u65f6\u4ecd\u80fd\u4fdd\u8bc1\u7ea6\u675f\u6ee1\u8db3\u548c\u9012\u5f52\u53ef\u884c\u6027\u3002", "result": "\u8bc1\u660e\u653e\u5bbd\u540e\u7684\u4f18\u5316\u95ee\u9898\u5728\u95ed\u73af\u4e0b\u5177\u6709\u9012\u5f52\u53ef\u884c\u6027\uff0c\u5e76\u6ee1\u8db3\u8054\u5408\u6982\u7387\u7ea6\u675f\uff1b\u6570\u503c\u793a\u4f8b\u663e\u793a\u76f8\u8f83\u73b0\u6709\u65b9\u6cd5\u5728\u6709\u6548\u6027\u4e0e\u8ba1\u7b97\u6210\u672c\u4e0a\u7684\u4f18\u52bf\u3002", "conclusion": "\u57fa\u4e8e CP \u7684\u6846\u67b6\u4e3a\u672a\u77e5\u6270\u52a8\u5206\u5e03\u4e0b\u7684\u7ebf\u6027\u7cfb\u7edf\u63d0\u4f9b\u4e00\u4e2a\u8f7b\u91cf\u3001\u5e26\u5f62\u5f0f\u4fdd\u8bc1\u7684\u8054\u5408\u65f6\u7ea6\u675f\u5904\u7406\u601d\u8def\uff0c\u4e14\u53ef\u6269\u5c55\u81f3\u8f93\u51fa\u53cd\u9988\u573a\u666f\u3002"}}
{"id": "2512.10098", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10098", "abs": "https://arxiv.org/abs/2512.10098", "authors": ["Midhat Urooj", "Ayan Banerjee", "Farhat Shaikh", "Kuntal Thakur", "Sandeep Gupta"], "title": "MedXAI: A Retrieval-Augmented and Self-Verifying Framework for Knowledge-Guided Medical Image Analysis", "comment": "https://cmsworkshops.com/Asilomar2025/Papers/Uploads/FinalPapers/Original/1527/20251130102314_899554_1527.pdf", "summary": "Accurate and interpretable image-based diagnosis remains a fundamental challenge in medical AI, particularly un- der domain shifts and rare-class conditions. Deep learning mod- els often struggle with real-world distribution changes, exhibit bias against infrequent pathologies, and lack the transparency required for deployment in safety-critical clinical environments. We introduce MedXAI (An Explainable Framework for Med- ical Imaging Classification), a unified expert knowledge based framework that integrates deep vision models with clinician- derived expert knowledge to improve generalization, reduce rare- class bias, and provide human-understandable explanations by localizing the relevant diagnostic features rather than relying on technical post-hoc methods (e.g., Saliency Maps, LIME). We evaluate MedXAI across heterogeneous modalities on two challenging tasks: (i) Seizure Onset Zone localization from resting-state fMRI, and (ii) Diabetic Retinopathy grading. Ex periments on ten multicenter datasets show consistent gains, including a 3% improvement in cross-domain generalization and a 10% improvmnet in F1 score of rare class, substantially outperforming strong deep learning baselines. Ablations confirm that the symbolic components act as effective clinical priors and regularizers, improving robustness under distribution shift. MedXAI delivers clinically aligned explanations while achieving superior in-domain and cross-domain performance, particularly for rare diseases in multimodal medical AI.", "AI": {"tldr": "\u4e00\u4e2a\u7edf\u4e00\u7684\u53ef\u89e3\u91ca\u6846\u67b6 MedXAI\uff0c\u5c06\u4e34\u5e8a\u4e13\u5bb6\u77e5\u8bc6\u4e0e\u6df1\u5ea6\u89c6\u89c9\u6a21\u578b\u7ed3\u5408\uff0c\u4ee5\u63d0\u5347\u8de8\u57df\u6cdb\u5316\u3001\u7f13\u89e3\u7a00\u6709\u75c5\u79cd\u504f\u5dee\uff0c\u5e76\u63d0\u4f9b\u5c40\u90e8\u5316\u7684\u8bca\u65ad\u7279\u5f81\u89e3\u91ca\uff1b\u5728\u591a\u6a21\u6001\u4efb\u52a1\uff08\u9759\u606f\u6001fMRI\u7684\u53d1\u4f5c\u533a\u5b9a\u4f4d\u3001\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\u5206\u7ea7\uff09\u4e0a\u7ecf\u8fc7\u5341\u4e2a\u591a\u4e2d\u5fc3\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u63d0\u5347\u8de8\u57df\u6cdb\u5316\u7ea63%\u3001\u7a00\u6709\u7c7b\u522bF1\u63d0\u5347\u7ea610%\uff0c\u5e76\u901a\u8fc7\u7b26\u53f7\u7ec4\u4ef6\u4f5c\u4e3a\u4e34\u5e8a\u5148\u9a8c\u63d0\u5347\u9c81\u68d2\u6027\u548c\u89e3\u91ca\u4e00\u81f4\u6027\u3002", "motivation": "\u5728\u533b\u5b66AI\u4e2d\uff0c\u6a21\u578b\u9762\u5bf9\u57df\u8fc1\u79fb\u548c\u7a00\u6709\u75c5\u79cd\u65f6\u5f80\u5f80\u8868\u73b0\u4e0b\u964d\uff0c\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u96be\u4ee5\u5728\u5b89\u5168\u5173\u952e\u7684\u4e34\u5e8a\u73af\u5883\u4e2d\u90e8\u7f72\u3002\u73b0\u6709\u7684\u540e\u9a8c\u89e3\u91ca\u65b9\u6cd5\uff08\u5982Saliency\u3001LIME\uff09\u53ef\u80fd\u4e0d\u5177\u4e34\u5e8a\u53ef\u7406\u89e3\u6027\u6216\u4e0d\u7a33\u5b9a\u3002\u9700\u8981\u4e00\u4e2a\u5c06\u4e13\u5bb6\u77e5\u8bc6\u878d\u5165\u6a21\u578b\u4e14\u53ef\u89e3\u91ca\u3001\u9c81\u68d2\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa MedXAI\uff0c\u6574\u5408\u6df1\u5ea6\u89c6\u89c9\u6a21\u578b\u4e0e\u57fa\u4e8e\u4e13\u5bb6\u77e5\u8bc6\u7684\u7b26\u53f7\u7ec4\u4ef6\uff0c\u4f5c\u4e3a\u4e34\u5e8a\u5148\u9a8c\u548c\u6b63\u5219\u5316\u9879\uff1b\u901a\u8fc7\u5bf9\u8bca\u65ad\u7279\u5f81\u7684\u5c40\u90e8\u5316\u6765\u63d0\u4f9b\u89e3\u91ca\uff1b\u5b9e\u73b0\u591a\u6a21\u6001\u5b66\u4e60\uff0c\u8bc4\u4f30\u5728\u9759\u606f\u6001fMRI\u7684Seizure Onset Zone\u5b9a\u4f4d\u548c\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\u5206\u7ea7\u4e24\u4e2a\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u548c\u89e3\u91ca\u4e00\u81f4\u6027\u3002", "result": "\u5728\u5341\u4e2a\u591a\u4e2d\u5fc3\u6570\u636e\u96c6\u4e0a\uff0c\u8de8\u57df\u6cdb\u5316\u63d0\u5347\u7ea63%\uff0c\u7a00\u6709\u7c7b\u522b\u7684F1\u63d0\u5347\u7ea610%\uff1b\u6bd4\u5f3a\u57fa\u7ebf\u6a21\u578b\u5177\u6709\u663e\u8457\u4f18\u52bf\uff1b\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u7b26\u53f7\u7ec4\u4ef6\u4f5c\u4e3a\u4e34\u5e8a\u5148\u9a8c\u548c\u6b63\u5219\u5316\u5668\u63d0\u9ad8\u4e86\u5206\u5e03\u5916\u9c81\u68d2\u6027\u3002", "conclusion": "MedXAI\u5728\u4e34\u5e8a\u76f8\u5173\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8de8\u57df\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u5c24\u5176\u5728\u591a\u6a21\u6001\u533b\u5b66AI\u4e2d\u7684\u7a00\u6709\u75be\u75c5\u573a\u666f\uff0c\u63d0\u4f9b\u4e86\u4e0e\u4e34\u5e8a\u9700\u6c42\u5bf9\u9f50\u7684\u89e3\u91ca\u3002"}}
{"id": "2512.10879", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10879", "abs": "https://arxiv.org/abs/2512.10879", "authors": ["Sauradeep Dey", "Musa Furkan Keskin", "Dario Tagliaferri", "Gonzalo Seco-Granados", "Mikko Valkama", "Henk Wymeersch"], "title": "POLO: Phase-Only Localization in Uplink Distributed MIMO Systems", "comment": null, "summary": "We propose a low-complexity localization framework for uplink distributed MIMO (D-MIMO) systems, targeting the challenge of minimizing the highly spiky maximum-likelihood (ML) cost function that arises in sparsely deployed phasecoherent access points (APs) with narrowband transmission. In such systems, ML-based localization typically relies on dense grid search, incurring prohibitive computational complexity. To address this, we introduce phase-only localization (POLO), an approach that leverages differential carrier-phase measurements from selected APs to generate a compact set of candidate user positions. The ML cost function is then evaluated only at these candidates, reducing complexity significantly. A key challenge is to devise an AP selection mechanism that reduces the number of candidate points while maintaining reliable coverage. We propose two variants: POLO-I, which selects three APs to provide closed-form candidate positions with low computational cost, and POLO-II, which selects four APs using an alternative strategy that enhances coverage at marginally higher runtime. Comprehensive analytical and simulation results show that POLO achieves a favorable coverage-complexity trade-off, reducing cost by orders of magnitude relative to exhaustive grid search with only marginal loss in coverage. By characterizing this tradeoff under diverse AP configurations, we also provide practical guidelines for selecting between POLO-I and POLO-II depending on latency and coverage requirements.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.10841", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10841", "abs": "https://arxiv.org/abs/2512.10841", "authors": ["Mohammad Mirtaba", "Juan Augusto Paredes Salazar", "Daning Huang", "Ankit Goel"], "title": "Low-Order $\\mathcal{H}_2 / \\mathcal{H}_\\infty$ Controller Design for Aeroelastic Vibration Suppression", "comment": "To be presented in the 2026 Scitech Forum", "summary": "This paper presents an $\\mathcal{H}_2 / \\mathcal{H}_\\infty$ minimization-based output-feedback controller for active aeroelastic vibration suppression in a cantilevered beam. First, a nonlinear structural model incorporating moderate deflection and aerodynamic loading is derived and discretized using the finite element method (FEM). Then, a low-order linear model is identified from random gaussian input response data from the FEM model to synthesize an output-feedback controller using the $\\mathcal{H}_2 / \\mathcal{H}_\\infty$ framework. A frequency-weighted dynamic filter is introduced to emphasize disturbance frequencies of interest, enabling the controller to target dominant vibration modes. Simulation results demonstrate the effectiveness of the proposed technique for vibration suppression and study its robustness to system parameter variations, including actuator placement.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.10296", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10296", "abs": "https://arxiv.org/abs/2512.10296", "authors": ["Md Nahid Hasan Shuvo", "Moinul Hossain", "Anik Mallik", "Jeffrey Twigg", "Fikadu Dagefu"], "title": "FLARE: A Wireless Side-Channel Fingerprinting Attack on Federated Learning", "comment": "This paper has been accepted for publication in IEEE INFOCOM 2026 - IEEE Conference on Computer Communications", "summary": "Federated Learning (FL) enables collaborative model training across distributed devices while safeguarding data and user privacy. However, FL remains susceptible to privacy threats that can compromise data via direct means. That said, indirectly compromising the confidentiality of the FL model architecture (e.g., a convolutional neural network (CNN) or a recurrent neural network (RNN)) on a client device by an outsider remains unexplored. If leaked, this information can enable next-level attacks tailored to the architecture. This paper proposes a novel side-channel fingerprinting attack, leveraging flow-level and packet-level statistics of encrypted wireless traffic from an FL client to infer its deep learning model architecture. We name it FLARE, a fingerprinting framework based on FL Architecture REconnaissance. Evaluation across various CNN and RNN variants-including pre-trained and custom models trained over IEEE 802.11 Wi-Fi-shows that FLARE achieves over 98% F1-score in closed-world and up to 91% in open-world scenarios. These results reveal that CNN and RNN models leak distinguishable traffic patterns, enabling architecture fingerprinting even under realistic FL settings with hardware, software, and data heterogeneity. To our knowledge, this is the first work to fingerprint FL model architectures by sniffing encrypted wireless traffic, exposing a critical side-channel vulnerability in current FL systems.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.10117", "categories": ["cs.LG", "cs.AI", "cs.RO", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10117", "abs": "https://arxiv.org/abs/2512.10117", "authors": ["Sangli Teng", "Hang Liu", "Jingyu Song", "Koushil Sreenath"], "title": "CHyLL: Learning Continuous Neural Representations of Hybrid Systems", "comment": null, "summary": "Learning the flows of hybrid systems that have both continuous and discrete time dynamics is challenging. The existing method learns the dynamics in each discrete mode, which suffers from the combination of mode switching and discontinuities in the flows. In this work, we propose CHyLL (Continuous Hybrid System Learning in Latent Space), which learns a continuous neural representation of a hybrid system without trajectory segmentation, event functions, or mode switching. The key insight of CHyLL is that the reset map glues the state space at the guard surface, reformulating the state space as a piecewise smooth quotient manifold where the flow becomes spatially continuous. Building upon these insights and the embedding theorems grounded in differential topology, CHyLL concurrently learns a singularity-free neural embedding in a higher-dimensional space and the continuous flow in it. We showcase that CHyLL can accurately predict the flow of hybrid systems with superior accuracy and identify the topological invariants of the hybrid systems. Finally, we apply CHyLL to the stochastic optimal control problem.", "AI": {"tldr": "CHyLL learns a continuous neural representation of hybrid systems in latent space without trajectory segmentation or explicit mode switching, by gluing the state space at guard surfaces via the reset map to form a piecewise smooth quotient manifold where the flow is continuous; it jointly learns a higher-dimensional embedding and the continuous flow, enabling accurate prediction, extraction of topological invariants, and application to stochastic optimal control.", "motivation": "Learning the flows of hybrid systems with both continuous and discrete time dynamics is challenging due to mode switching and discontinuities in the flows; existing methods rely on trajectory segmentation by mode, which struggles with switching and discontinuities.", "method": "CHyLL constructs a continuous neural embedding in a latent space using the reset map to glue state space at the guard surface, reformulating the state space as a piecewise smooth quotient manifold; based on embedding theorems, it concurrently learns a singularity-free neural embedding and the continuous flow in the embedding space, avoiding segmentation, event functions, and mode switching.", "result": "The approach achieves accurate flow prediction and can identify the topological invariants of hybrid systems; it is also extended to stochastic optimal control problems.", "conclusion": "CHyLL provides a unified continuous representation for hybrid systems, enabling accurate flow prediction and topological insights while bypassing explicit mode segmentation and event handling; it demonstrates potential for stochastic control applications."}}
{"id": "2512.10361", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.10361", "abs": "https://arxiv.org/abs/2512.10361", "authors": ["Wei Shao", "Najmeh Nazari", "Behnam Omidi", "Setareh Rafatirad", "Houman Homayoun", "Khaled N. Khasawneh", "Chongzhou Fang"], "title": "Bit of a Close Talker: A Practical Guide to Serverless Cloud Co-Location Attacks", "comment": "In the proceedings of Network and Distributed System Security (NDSS) Symposium 2026", "summary": "Serverless computing has revolutionized cloud computing by offering an efficient and cost-effective way for users to develop and deploy applications without managing infrastructure details. However, serverless cloud users remain vulnerable to various types of attacks, including micro-architectural side-channel attacks. These attacks typically rely on the physical co-location of victim and attacker instances, and attackers will need to exploit cloud schedulers to achieve co-location with victims. Therefore, it is crucial to study vulnerabilities in serverless cloud schedulers and assess the security of different serverless scheduling algorithms. This study addresses the gap in understanding and constructing co-location attacks in serverless clouds. We present a comprehensive methodology to uncover exploitable features in serverless scheduling algorithms and devise strategies for constructing co-location attacks through normal user interfaces. In our experiments, we successfully reveal exploitable vulnerabilities and achieve instance co-location on prevalent open-source infrastructures and Microsoft Azure Functions. We also present a mitigation strategy to defend against co-location attacks in serverless clouds. Our work highlights critical areas for security enhancements in current cloud schedulers, offering insights to fortify serverless computing environments against potential co-location attacks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u670d\u52a1\u7aef\u65e0\u670d\u52a1\u5668\u4e91\u8c03\u5ea6\u5668\u7684\u5171\u5b9a\u4f4d\u653b\u51fb\u7684\u7814\u7a76\u6846\u67b6\uff0c\u65e8\u5728\u63ed\u793a\u53ef\u88ab\u6ee5\u7528\u7684\u7279\u5f81\u5e76\u901a\u8fc7\u6b63\u5e38\u7528\u6237\u63a5\u53e3\u6784\u9020\u5171\u5b9a\u4f4d\u653b\u51fb\uff0c\u540c\u65f6\u7ed9\u51fa\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u5728\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u5e7f\u6cdb\u90e8\u7f72\u7684\u80cc\u666f\u4e0b\uff0c\u8c03\u5ea6\u5668\u7684\u5b89\u5168\u6027\u6210\u4e3a\u5173\u952e\u95ee\u9898\u3002\u5171\u5b9a\u4f4d\u653b\u51fb\u53ef\u5229\u7528\u7269\u7406\u5171\u5904\u548c\u8c03\u5ea6\u5668\u884c\u4e3a\u6cc4\u9732\u654f\u611f\u4fe1\u606f\uff0c\u56e0\u6b64\u9700\u8981\u7406\u89e3\u548c\u8bc4\u4f30\u73b0\u6709\u8c03\u5ea6\u7b97\u6cd5\u7684\u5b89\u5168\u6027\u4ee5\u9632\u6b62\u6f5c\u5728\u653b\u51fb\u3002", "method": "\u63d0\u51fa\u4e00\u5957\u8986\u76d6\u4ece\u7279\u5f81\u6316\u6398\u5230\u653b\u51fb\u6784\u9020\u7684\u7efc\u5408\u65b9\u6cd5\u5b66\uff0c\u5229\u7528\u6b63\u5e38\u7528\u6237\u754c\u9762\u8fdb\u884c\u5171\u5b9a\u4f4d\u653b\u51fb\u7684\u5b9e\u73b0\uff0c\u4e14\u5728\u5f00\u6e90\u5b9e\u73b0\u4e0e\u5fae\u8f6f Azure Functions \u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u4ee5\u63ed\u793a\u53ef\u5229\u7528\u7684\u6f0f\u6d1e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5b58\u5728\u53ef\u5229\u7528\u7684\u8106\u5f31\u6027\uff0c\u80fd\u591f\u5728\u4e3b\u6d41\u5f00\u6e90\u57fa\u7840\u8bbe\u65bd\u548c Azure Functions \u4e0a\u5b9e\u73b0\u5b9e\u4f8b\u5171\u5b9a\u4f4d\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u7f13\u89e3\u7b56\u7565\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5f3a\u8c03\u4e86\u670d\u52a1\u5668\u65e0\u670d\u52a1\u5668\u4e91\u8c03\u5ea6\u5668\u7684\u5b89\u5168\u8584\u5f31\u70b9\uff0c\u4e3a\u4eca\u540e\u5b89\u5168\u589e\u5f3a\u548c\u9632\u5fa1\u5171\u5b9a\u4f4d\u653b\u51fb\u63d0\u4f9b\u4e86\u65b9\u5411\uff0c\u4f46\u9700\u8981\u5728\u66f4\u5e7f\u6cdb\u7684\u73af\u5883\u548c\u957f\u671f\u8bc4\u4f30\u4e2d\u9a8c\u8bc1\u7f13\u89e3\u7b56\u7565\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.10133", "categories": ["cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.10133", "abs": "https://arxiv.org/abs/2512.10133", "authors": ["Gabriel F. A. Bastos", "Jugurta Montalv\u00e3o"], "title": "Partitioning the Sample Space for a More Precise Shannon Entropy Estimation", "comment": "The manuscript contains 6 pages and 10 figures. It has been accepted for International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA 2026)", "summary": "Reliable data-driven estimation of Shannon entropy from small data sets, where the number of examples is potentially smaller than the number of possible outcomes, is a critical matter in several applications. In this paper, we introduce a discrete entropy estimator, where we use the decomposability property in combination with estimations of the missing mass and the number of unseen outcomes to compensate for the negative bias induced by them. Experimental results show that the proposed method outperforms some classical estimators in undersampled regimes, and performs comparably with some well-established state-of-the-art estimators.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u79bb\u6563\u9999\u519c\u71b5\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u4f30\u8ba1\u7f3a\u5931\u8d28\u91cf\u4e0e\u672a\u89c1\u7ed3\u679c\u6570\u91cf\u6765\u62b5\u6d88\u504f\u5dee\uff0c\u5728\u6837\u672c\u4e0d\u8db3\u60c5\u51b5\u4e0b\u4f18\u4e8e\u7ecf\u5178\u4f30\u8ba1\u5668\uff0c\u5e76\u4e0e\u524d\u6cbf\u65b9\u6cd5\u76f8\u5f53\u3002", "motivation": "\u5728\u5c0f\u6570\u636e\u60c5\u5883\u4e0b\uff0c\u6837\u672c\u6570\u53ef\u80fd\u5c0f\u4e8e\u53ef\u80fd\u8f93\u51fa\u7c7b\u522b\u6570\uff0c\u4f20\u7edf\u7ecf\u9a8c\u4f30\u8ba1\u5f80\u5f80\u4f1a\u4ea7\u751f\u8f83\u5927\u504f\u5dee\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u65e0\u504f\u6216\u4f4e\u504f\u501a\u7684\u71b5\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u53ef\u5206\u89e3\u6027(decomposability)\u5c5e\u6027\uff0c\u5e76\u5bf9\u7f3a\u5931\u8d28\u91cf(missing mass)\u548c\u672a\u89c1\u7ed3\u679c\u6570\u91cf(unseen outcomes)\u8fdb\u884c\u4f30\u8ba1\uff0c\u4ee5\u8865\u507f\u7531\u672a\u89c2\u6d4b\u4e8b\u4ef6\u5f15\u8d77\u7684\u8d1f\u504f\u5dee\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6b20\u91c7\u6837\uff08\u5c0f\u6837\u672c\uff09\u6761\u4ef6\u4e0b\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u90e8\u5206\u7ecf\u5178 estimators\uff0c\u4e14\u4e0e\u4e00\u4e9b\u516c\u8ba4\u7684\u72b6\u6001\u2011of\u2011the\u2011art estimators\u76f8\u5f53\u3002", "conclusion": "\u7ed9\u51fa\u4e86\u4e00\u79cd\u5728\u5c0f\u6570\u636e\u4e0b\u66f4\u53ef\u9760\u7684\u79bb\u6563\u9999\u519c\u71b5\u4f30\u8ba1\u7b56\u7565\uff0c\u80fd\u591f\u6709\u6548\u7f13\u89e3\u672a\u89c2\u6d4b\u4e8b\u4ef6\u5e26\u6765\u7684\u504f\u5dee\u3002"}}
{"id": "2512.10141", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10141", "abs": "https://arxiv.org/abs/2512.10141", "authors": ["Sarwan Ali", "Taslim Murad", "Imdadullah Khan"], "title": "Sequence-to-Image Transformation for Sequence Classification Using Rips Complex Construction and Chaos Game Representation", "comment": null, "summary": "Traditional feature engineering approaches for molecular sequence classification suffer from sparsity issues and computational complexity, while deep learning models often underperform on tabular biological data. This paper introduces a novel topological approach that transforms molecular sequences into images by combining Chaos Game Representation (CGR) with Rips complex construction from algebraic topology. Our method maps sequence elements to 2D coordinates via CGR, computes pairwise distances, and constructs Rips complexes to capture both local structural and global topological features. We provide formal guarantees on representation uniqueness, topological stability, and information preservation. Extensive experiments on anticancer peptide datasets demonstrate superior performance over vector-based, sequence language models, and existing image-based methods, achieving 86.8\\% and 94.5\\% accuracy on breast and lung cancer datasets, respectively. The topological representation preserves critical sequence information while enabling effective utilization of vision-based deep learning architectures for molecular sequence analysis.", "AI": {"tldr": "\u901a\u8fc7CGR\u5c06\u5206\u5b50\u5e8f\u5217\u6620\u5c04\u4e3a\u4e8c\u7ef4\u5750\u6807\uff0c\u6784\u5efaRips\u590d\u5f62\u63d0\u53d6\u62d3\u6251\u7279\u5f81\uff0c\u5f62\u6210\u7a33\u5b9a\u7684\u56fe\u50cf\u5316\u8868\u793a\uff0c\u5e76\u5728\u6297\u764c\u80bd\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u5bf9\u4e73\u817a\u764c\u548c\u80ba\u764c\u6570\u636e\u7684\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u7279\u5f81\u5de5\u7a0b\u5728\u7a00\u758f\u6027\u548c\u8ba1\u7b97\u590d\u6742\u6027\u4e0a\u7684\u4e0d\u8db3\uff0c\u4ee5\u53ca\u6df1\u5ea6\u5b66\u4e60\u5728\u8868\u683c\u751f\u7269\u6570\u636e\u4e0a\u7684\u6b20\u4f73\u8868\u73b0\uff0c\u63d0\u4f9b\u4e00\u79cd\u4fdd\u7559\u4fe1\u606f\u4e14\u53ef\u4e0e\u89c6\u89c9\u6a21\u578b\u7ed3\u5408\u7684\u65b0\u8868\u5f81\u3002", "method": "\u5c06\u5e8f\u5217\u5143\u7d20\u6620\u5c04\u5230\u4e8c\u7ef4CGR\u5750\u6807\uff0c\u8ba1\u7b97\u4e24\u4e24\u8ddd\u79bb\uff0c\u6784\u5efaRips\u590d\u5f62\u4ee5\u6355\u6349\u5c40\u90e8\u7ed3\u6784\u4e0e\u5168\u5c40\u62d3\u6251\uff0c\u7ed9\u51fa\u8868\u793a\u552f\u4e00\u6027\u3001\u62d3\u6251\u7a33\u5b9a\u6027\u548c\u4fe1\u606f\u4fdd\u7559\u6027\u7684\u5f62\u5f0f\u4fdd\u8bc1\u3002", "result": "\u5728\u6297\u764c\u80bd\u6570\u636e\u96c6\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0c\u8d85\u8fc7\u5411\u91cf\u5316\u3001\u5e8f\u5217\u8bed\u8a00\u6a21\u578b\u53ca\u73b0\u6709\u57fa\u4e8e\u56fe\u50cf\u7684\u65b9\u6cd5\uff0c\u4e73\u817a\u6570\u636e\u96c686.8%\uff0c\u80ba\u764c\u6570\u636e\u96c694.5%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u62d3\u6251\u8868\u5f81\u517c\u5bb9\u89c6\u89c9\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u4fdd\u6301\u5173\u952e\u5e8f\u5217\u4fe1\u606f\uff0c\u63d0\u5347\u5206\u5b50\u5e8f\u5217\u5206\u6790\u7684\u6548\u679c\u3002"}}
{"id": "2512.10426", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.10426", "abs": "https://arxiv.org/abs/2512.10426", "authors": ["N Mangala", "Murtaza Rangwala", "S Aishwarya", "B Eswara Reddy", "Rajkumar Buyya", "KR Venugopal", "SS Iyengar", "LM Patnaik"], "title": "Differential Privacy for Secure Machine Learning in Healthcare IoT-Cloud Systems", "comment": null, "summary": "Healthcare has become exceptionally sophisticated, as wearables and connected medical devices are revolutionising remote patient monitoring, emergency response, medication management, diagnosis, and predictive and prescriptive analytics. Internet of Things and Cloud computing integrated systems (IoT-Cloud) facilitate sensing, automation, and processing for these healthcare applications. While real-time response is crucial for alleviating patient emergencies, protecting patient privacy is extremely important in data-driven healthcare. In this paper, we propose a multi-layer IoT, Edge and Cloud architecture to enhance the speed of response for emergency healthcare by distributing tasks based on response criticality and permanence of storage. Privacy of patient data is assured by proposing a Differential Privacy framework across several machine learning models such as K-means, Logistic Regression, Random Forest and Naive Bayes. We establish a comprehensive threat model identifying three adversary classes and evaluate Laplace, Gaussian, and hybrid noise mechanisms across varying privacy budgets, with supervised algorithms achieving up to 86% accuracy. The proposed hybrid Laplace-Gaussian noise mechanism with adaptive budget allocation provides a balanced approach, offering moderate tails and better privacy-utility trade-offs for both low and high dimension datasets. At the practical threshold of $\\varepsilon = 5.0$, supervised algorithms achieve 82-84% accuracy while reducing attribute inference attacks by up to 18% and data reconstruction correlation by 70%. Blockchain security further ensures trusted communication through time-stamping, traceability, and immutability for analytics applications. Edge computing demonstrates 8$\\times$ latency reduction for emergency scenarios, validating the hierarchical architecture for time-critical operations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u5c42\u7269\u8054\u7f51-\u8fb9\u7f18\u4e91\u67b6\u6784\uff0c\u7ed3\u5408\u5dee\u5206\u9690\u79c1\u4e0e\u6df7\u5408\u566a\u58f0\u673a\u5236\u4ee5\u63d0\u5347\u6025\u6551\u573a\u666f\u4e0b\u7684\u54cd\u5e94\u901f\u5ea6\u4e0e\u9690\u79c1\u4fdd\u62a4\uff0c\u540c\u65f6\u901a\u8fc7\u533a\u5757\u94fe\u786e\u4fdd\u5b89\u5168\u901a\u4fe1\uff0c\u8fb9\u7f18\u8ba1\u7b97\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u533b\u7597\u4fdd\u5065\u6570\u636e\u9a71\u52a8\u5e94\u7528\u5bf9\u5b9e\u65f6\u6027\u4e0e\u9690\u79c1\u4fdd\u62a4\u63d0\u51fa\u66f4\u9ad8\u8981\u6c42\u3002\u73b0\u6709\u7cfb\u7edf\u5728\u7d27\u6025\u54cd\u5e94\u548c\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u5728\u67b6\u6784\u5206\u5c42\u3001\u9690\u79c1\u673a\u5236\u4e0e\u5b89\u5168\u901a\u4fe1\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u7684\u6743\u8861\u3002", "method": "\u8bbe\u8ba1\u591a\u5c42IoT-Edge-Cloud\u67b6\u6784\uff0c\u4f9d\u636e\u54cd\u5e94\u6027\u548c\u5b58\u50a8\u6301\u7eed\u6027\u5bf9\u4efb\u52a1\u8fdb\u884c\u5206\u914d\uff1b\u63d0\u51fa\u5dee\u5206\u9690\u79c1\u6846\u67b6\u8986\u76d6K-means\u3001\u903b\u8f91\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u3001\u6734\u7d20\u8d1d\u53f6\u65af\u7b49\u6a21\u578b\uff0c\u6bd4\u8f83Laplace\u3001Gaussian\u53ca\u6df7\u5408\u566a\u58f0\u673a\u5236\uff0c\u5e76\u7ed9\u51fa\u81ea\u9002\u5e94\u9884\u7b97\u5206\u914d\u7684\u6df7\u5408Laplace-Gaussian\u566a\u58f0\u7b56\u7565\uff1b\u6784\u5efa\u5a01\u80c1\u6a21\u578b\u5e76\u8bc4\u4f30\u5728\u4e0d\u540c\u9690\u79c1\u9884\u7b97\u4e0b\u7684\u653b\u51fb\u62b5\u6297\uff08\u5982\u5c5e\u6027\u63a8\u65ad\u548c\u6570\u636e\u91cd\u6784\uff09\uff0c\u5728\u03b5=5.0\u65f6\u76d1\u7763\u5b66\u4e60\u7b97\u6cd5 achieves 82-84%\u7684\u51c6\u786e\u7387\u5e76\u51cf\u5c11\u5c5e\u6027\u63a8\u65ad\u653b\u51fb18%\u53ca\u6570\u636e\u91cd\u6784\u76f8\u5173\u602770%\uff1b\u5f15\u5165\u533a\u5757\u94fe\u5b9e\u73b0\u65f6\u95f4\u6233\u3001\u53ef\u8ffd\u6eaf\u6027\u4e0e\u4e0d\u53ef\u7be1\u6539\u6027\uff0c\u786e\u4fdd\u5206\u6790\u5e94\u7528\u7684\u53ef\u4fe1\u901a\u4fe1\uff1b\u5728\u8fb9\u7f18\u8ba1\u7b97\u5b9e\u73b08\u500d\u5ef6\u8fdf\u964d\u4f4e\uff0c\u9a8c\u8bc1\u8be5\u5206\u5c42\u67b6\u6784\u5728\u65f6\u95f4\u654f\u611f\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u3002", "result": "\u76d1\u7763\u5b66\u4e60\u7b97\u6cd5\u5728\u591a\u79cd\u9690\u79c1\u566a\u58f0\u673a\u5236\u4e0b\u6700\u9ad8\u53ef\u8fbe\u7ea686%\u51c6\u786e\u7387\uff1b\u5728\u03b5=5.0\u65f6\u51c6\u786e\u7387\u7ea682-84%\uff1b\u5c5e\u6027\u63a8\u65ad\u653b\u51fb\u964d\u4f4e\u81f318%\u4ee5\u4e0b\uff0c\u6570\u636e\u91cd\u6784\u76f8\u5173\u6027\u964d\u4f4e\u7ea670%\uff1b\u8fb9\u7f18\u8ba1\u7b97\u5e26\u6765\u7ea68\u00d7\u7684\u5ef6\u8fdf\u964d\u4f4e\uff0c\u63d0\u5347\u6025\u6551\u573a\u666f\u7684\u5b9e\u65f6\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u591a\u5c42IoT-Edge-Cloud\u4e0e\u5dee\u5206\u9690\u79c1\u76f8\u7ed3\u5408\u7684\u67b6\u6784\uff0c\u5728\u63d0\u5347\u6025\u6551\u573a\u666f\u54cd\u5e94\u901f\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u5e73\u8861\uff1b\u6df7\u5408\u62c9\u666e\u62c9\u65af-\u9ad8\u65af\u566a\u58f0\u53ca\u81ea\u9002\u5e94\u9884\u7b97\u5206\u914d\u63d0\u5347\u9690\u79c1\u4fdd\u62a4\u4e0e\u6570\u636e\u6709\u6548\u6027\u4e4b\u95f4\u7684\u6298\u4e2d\uff0c\u533a\u5757\u94fe\u4e0e\u8fb9\u7f18\u8ba1\u7b97\u8fdb\u4e00\u6b65\u589e\u5f3a\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u4e0e\u5b9e\u65f6\u6027\u3002"}}
{"id": "2512.10147", "categories": ["cs.LG", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2512.10147", "abs": "https://arxiv.org/abs/2512.10147", "authors": ["Sarwan Ali", "Taslim Murad"], "title": "Murmur2Vec: A Hashing Based Solution For Embedding Generation Of COVID-19 Spike Sequences", "comment": null, "summary": "Early detection and characterization of coronavirus disease (COVID-19), caused by SARS-CoV-2, remain critical for effective clinical response and public-health planning. The global availability of large-scale viral sequence data presents significant opportunities for computational analysis; however, existing approaches face notable limitations. Phylogenetic tree-based methods are computationally intensive and do not scale efficiently to today's multi-million-sequence datasets. Similarly, current embedding-based techniques often rely on aligned sequences or exhibit suboptimal predictive performance and high runtime costs, creating barriers to practical large-scale analysis. In this study, we focus on the most prevalent SARS-CoV-2 lineages associated with the spike protein region and introduce a scalable embedding method that leverages hashing to generate compact, low-dimensional representations of spike sequences. These embeddings are subsequently used to train a variety of machine learning models for supervised lineage classification. We conduct an extensive evaluation comparing our approach with multiple baseline and state-of-the-art biological sequence embedding methods across diverse metrics. Our results demonstrate that the proposed embeddings offer substantial improvements in efficiency, achieving up to 86.4\\% classification accuracy while reducing embedding generation time by as much as 99.81\\%. This highlights the method's potential as a fast, effective, and scalable solution for large-scale viral sequence analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u54c8\u5e0c\u7684\u4f4e\u7ef4\u5d4c\u5165\u6765\u8868\u793a\u523a\u7a81\u86cb\u767d\u5e8f\u5217\uff0c\u7528\u4e8e\u5927\u89c4\u6a21SARS-CoV-2\u8c31\u7cfb\u5206\u7c7b\uff0c\u663e\u8457\u63d0\u5347\u6548\u7387\u548c\u4fdd\u6301\u8f83\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u6811\u72b6\u6cd5\u96be\u4ee5\u6269\u5c55\u5230\u591a\u767e\u4e07\u5e8f\u5217\u7684\u6570\u636e\u96c6\uff1b\u73b0\u6709\u5d4c\u5165\u6cd5\u8981\u4e48\u9700\u8981\u5bf9\u9f50\u3001\u8981\u4e48\u9884\u6d4b\u6027\u80fd\u548c\u8fd0\u884c\u6210\u672c\u4e0d\u8db3\u4ee5\u652f\u6491\u5927\u89c4\u6a21\u5206\u6790\u3002\u4e3a\u5b9e\u73b0\u5bf9 spike \u533a\u57df\u7684\u5feb\u901f\u3001\u53ef\u6269\u5c55\u7684\u8c31\u7cfb\u5206\u7c7b\uff0c\u9700\u8981\u65b0\u7684\u5d4c\u5165\u7b56\u7565\u3002", "method": "\u805a\u7126\u6700\u5e38\u89c1\u7684\u51e0\u4e2aSARS-CoV-2\u8c31\u7cfb\u7684 spike \u533a\u57df\uff0c\u63d0\u51fa\u57fa\u4e8e\u54c8\u5e0c\u7684\u7d27\u51d1\u8868\u793a\uff0c\u5e76\u7528\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u6709\u76d1\u7763\u7684\u8c31\u7cfb\u5206\u7c7b\u3002\u4e0e\u57fa\u7ebf\u548c\u524d\u6cbf\u5d4c\u5165\u65b9\u6cd5\u5728\u591a\u9879\u6307\u6807\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u6bd4\u8f83\u3002", "result": "\u5d4c\u5165\u751f\u6210\u65f6\u95f4\u53ef\u964d\u4f4e\u591a\u8fbe99.81%\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u6700\u9ad8\u53ef\u8fbe86.4%\uff0c\u5728\u6548\u7387\u548c\u6027\u80fd\u4e4b\u95f4\u5b9e\u73b0\u663e\u8457\u6298\u8877\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5927\u89c4\u6a21\u75c5\u6bd2\u5e8f\u5217\u5206\u6790\u63d0\u4f9b\u5feb\u901f\u3001\u6709\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u5408\u5927\u89c4\u6a21\u8c31\u7cfb\u76d1\u6d4b\u4e0e\u516c\u5171\u536b\u751f\u5e94\u7528\u3002"}}
{"id": "2512.10470", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.10470", "abs": "https://arxiv.org/abs/2512.10470", "authors": ["Kaleb Bacztub", "Braden Vester", "Matteo Hodge", "Liulseged Abate"], "title": "Stealth and Evasion in Rogue AP Attacks: An Analysis of Modern Detection and Bypass Techniques", "comment": "5 pages, 3 figures, experimental paper", "summary": "Wireless networks act as the backbone of modern digital connectivity, making them a primary target for cyber adversaries. Rogue Access Point attacks, specifically the Evil Twin variant, enable attackers to clone legitimate wireless network identifiers to deceive users into connecting. Once a connection is established, the adversary can intercept traffic and harvest sensitive credentials. While modern defensive architectures often employ Network Intrusion Detection Systems (NIDS) to identify malicious activity, the effectiveness of these systems against Layer 2 wireless threats remains a subject of critical inquiry. This project aimed to design a stealth-capable Rogue AP and evaluate its detectability against Suricata, an open-source NIDS/IPS. The methodology initially focused on a hardware-based deployment using Raspberry Pi platforms but transitioned to a virtualized environment due to severe system compatibility issues. Using Wifipumpkin3, the research team successfully deployed a captive portal that harvested user credentials from connected devices. However, the Suricata NIDS failed to flag the attack, highlighting a significant blind spot in traditional intrusion detection regarding wireless management frame attacks. This paper details the construction of the attack, the evasion techniques employed, and the limitations of current NIDS solutions in detecting localized wireless threats", "AI": {"tldr": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u79cd\u9690\u853d\u7684Rogue AP/ Evil Twin\u653b\u51fb\uff0c\u5e76\u8bc4\u4f30\u4e86\u73b0\u6709NIDS\uff08\u5982Suricata\uff09\u5bf92\u5c42\u65e0\u7ebf\u5a01\u80c1\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793a\u5bf9\u65e0\u7ebf\u7ba1\u7406\u5e27\u653b\u51fb\u5b58\u5728\u663e\u8457\u76f2\u533a\u3002", "motivation": "\u586b\u8865\u5bf9Layer-2\u65e0\u7ebf\u5a01\u80c1\u68c0\u6d4b\u4e0d\u8db3\u7684\u5b66\u672f\u7a7a\u767d\uff0c\u8bc4\u4f30\u4e3b\u6d41\u5f00\u6e90NIDS\u5728\u73b0\u5b9e\u65e0\u7ebf\u653b\u51fb\u573a\u666f\u4e2d\u7684\u68c0\u6d4b\u80fd\u529b\u4e0e\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u5bf9\u9632\u5fa1\u67b6\u6784\u7684\u6539\u8fdb\u9700\u6c42\u3002", "method": "\u521d\u59cb\u5728\u6811\u8393\u6d3e\u7b49\u786c\u4ef6\u5e73\u53f0\u8fdb\u884c\u90e8\u7f72\uff0c\u56e0\u517c\u5bb9\u6027\u95ee\u9898\u8f6c\u4e3a\u865a\u62df\u5316\u73af\u5883\uff1b\u4f7f\u7528Wifipumpkin3\u6784\u5efa captive portal\u4ee5\u52ab\u6301\u548c\u6536\u96c6\u8bbe\u5907\u51ed\u8bc1\uff1b\u5bf9\u653b\u51fb\u8fc7\u7a0b\u8fdb\u884c\u5efa\u6a21\u5e76\u5728Suricata\u73af\u5883\u4e2d\u6d4b\u8bd5\u68c0\u6d4b\u6548\u679c\uff0c\u5206\u6790\u56de\u907f\u624b\u6bb5\u4e0e\u7cfb\u7edf\u5c40\u9650\u3002", "result": "Suricata\u672a\u80fd\u8bc6\u522b\u653b\u51fb\u6d41\u91cf\uff0c\u66b4\u9732\u4e86\u73b0\u6709\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u5728\u65e0\u7ebf\u7ba1\u7406\u5e27\u653b\u51fb\u65b9\u9762\u7684\u660e\u663e\u76f2\u533a\uff1b\u7814\u7a76\u8be6\u7ec6\u63cf\u8ff0\u4e86\u653b\u51fb\u6784\u5efa\u3001\u89c4\u907f\u6280\u672f\u53caNIDS\u5728\u5c40\u90e8\u65e0\u7ebf\u5a01\u80c1\u68c0\u6d4b\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "conclusion": "\u5f53\u524dNIDS\u5bf9\u65e0\u7ebf\u5c42\u9762\u5a01\u80c1\u7684\u68c0\u6d4b\u80fd\u529b\u4e0d\u8db3\uff0c\u9700\u8981\u5728\u65e0\u7ebf\u8bbf\u95ee\u70b9\u5c42\u9762\u3001\u7ba1\u7406\u5e27\u5f02\u5e38\u68c0\u6d4b\u4ee5\u53ca\u66f4\u8d34\u8fd1\u65e0\u7ebf\u653b\u51fb\u573a\u666f\u7684\u7efc\u5408\u9632\u5fa1\u7b56\u7565\u65b9\u9762\u8fdb\u884c\u6539\u8fdb\u3002"}}
{"id": "2512.10485", "categories": ["cs.CR", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.10485", "abs": "https://arxiv.org/abs/2512.10485", "authors": ["Chaomeng Lu", "Bert Lagaisse"], "title": "From Lab to Reality: A Practical Evaluation of Deep Learning Models and LLMs for Vulnerability Detection", "comment": null, "summary": "Vulnerability detection methods based on deep learning (DL) have shown strong performance on benchmark datasets, yet their real-world effectiveness remains underexplored. Recent work suggests that both graph neural network (GNN)-based and transformer-based models, including large language models (LLMs), yield promising results when evaluated on curated benchmark datasets. These datasets are typically characterized by consistent data distributions and heuristic or partially noisy labels. In this study, we systematically evaluate two representative DL models-ReVeal and LineVul-across four representative datasets: Juliet, Devign, BigVul, and ICVul. Each model is trained independently on each respective dataset, and their code representations are analyzed using t-SNE to uncover vulnerability related patterns. To assess realistic applicability, we deploy these models along with four pretrained LLMs, Claude 3.5 Sonnet, GPT-o3-mini, GPT-4o, and GPT-5 on a curated dataset, VentiVul, comprising 20 recently (May 2025) fixed vulnerabilities from the Linux kernel. Our experiments reveal that current models struggle to distinguish vulnerable from non-vulnerable code in representation space and generalize poorly across datasets with differing distributions. When evaluated on VentiVul, our newly constructed time-wise out-of-distribution dataset, performance drops sharply, with most models failing to detect vulnerabilities reliably. These results expose a persistent gap between academic benchmarks and real-world deployment, emphasizing the value of our deployment-oriented evaluation framework and the need for more robust code representations and higher-quality datasets.", "AI": {"tldr": "\u57fa\u4e8eDL\u7684\u6f0f\u6d1e\u68c0\u6d4b\u5728\u57fa\u51c6\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bf9\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u5374\u7f3a\u4e4f\u9c81\u68d2\u6027\uff1b\u901a\u8fc7\u90e8\u7f72\u5bfc\u5411\u7684\u8bc4\u4f30\u6846\u67b6\u63ed\u793a\u5b66\u672f\u57fa\u51c6\u4e0e\u5b9e\u9645\u573a\u666f\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709GNN/Transformer/LLM\u5728\u6574\u9f50\u4e14\u5e26\u566a\u58f0\u6807\u6ce8\u7684\u57fa\u51c6\u6570\u636e\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5bf9\u5177\u6709\u4e0d\u540c\u5206\u5e03\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u4e0d\u8db3\uff0c\u4e9f\u9700\u90e8\u7f72\u5bfc\u5411\u7684\u8bc4\u4f30\u4e0e\u66f4\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u4e24\u79cd\u4ee3\u8868\u6027DL\u6a21\u578bReVeal\u548cLineVul\uff0c\u5728\u56db\u4e2a\u6570\u636e\u96c6\uff08Juliet\u3001Devign\u3001BigVul\u3001ICVul\uff09\u4e0a\u72ec\u7acb\u8bad\u7ec3\uff1b\u5bf9\u4ee3\u7801\u8868\u793a\u8fdb\u884ct-SNE\u5206\u6790\u4ee5\u63ed\u793a\u6f0f\u6d1e\u76f8\u5173\u6a21\u5f0f\uff1b\u5728VentiVul\uff08\u5305\u542b20\u4e2a\u6700\u8fd1\u7684Linux\u5185\u6838\u6f0f\u6d1e\uff09\u4e0a\uff0c\u7ed3\u5408\u56db\u4e2a\u9884\u8bad\u7ec3LLM\uff08Claude 3.5 Sonnet\u3001GPT-o3-mini\u3001GPT-4o\u3001GPT-5\uff09\u8fdb\u884c\u90e8\u7f72\u8bc4\u4f30\uff0c\u8fdb\u884c\u65f6\u5e8f\u5206\u5e03\u5916\u7684\u8bc4\u4f30\u3002", "result": "\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\uff0c\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u5c06\u6f0f\u6d1e\u4e0e\u975e\u6f0f\u6d1e\u533a\u5206\u5f00\u6765\uff1b\u8de8\u6570\u636e\u96c6\u7684\u6cdb\u5316\u6027\u5dee\uff1b\u5728VentiVul\u4e0a\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u5927\u591a\u6570\u6a21\u578b\u65e0\u6cd5\u53ef\u9760\u68c0\u6d4b\u6f0f\u6d1e\u3002", "conclusion": "\u5b66\u672f\u57fa\u51c6\u4e0e\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u4e4b\u95f4\u5b58\u5728\u6301\u7eed\u6027\u5dee\u8ddd\uff1b\u9700\u8981\u9762\u5411\u90e8\u7f72\u7684\u8bc4\u4f30\u6846\u67b6\u3001\u66f4\u52a0\u9c81\u68d2\u7684\u4ee3\u7801\u8868\u5f81\uff0c\u4ee5\u53ca\u66f4\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\u6765\u63d0\u5347\u5b9e\u7528\u6027\u3002"}}
{"id": "2512.10178", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.10178", "abs": "https://arxiv.org/abs/2512.10178", "authors": ["Keito Inoshita", "Xiaokang Zhou", "Akira Kawai", "Katsutoshi Yada"], "title": "CIEGAD: Cluster-Conditioned Interpolative and Extrapolative Framework for Geometry-Aware and Domain-Aligned Data Augmentation", "comment": null, "summary": "In practical deep learning deployment, the scarcity of data and the imbalance of label distributions often lead to semantically uncovered regions within the real-world data distribution, hindering model training and causing misclassification near class boundaries as well as unstable behaviors in peripheral areas. Although recent large language models (LLMs) show promise for data augmentation, an integrated framework that simultaneously achieves directional control of generation, domain alignment, and quality control has not yet been fully established. To address these challenges, we propose a Cluster-conditioned Interpolative and Extrapolative framework for Geometry-Aware and Domain-aligned data augmentation (CIEGAD), which systematically complements both in-distribution and out-of-distribution semantically uncovered regions. CIEGAD constructs domain profiles through cluster conditioning, allocates generation with a hierarchical frequency-geometric allocation integrating class frequency and geometric indicators, and finely controls generation directions via the coexistence of interpolative and extrapolative synthesis. It further performs quality control through geometry-constrained filtering combined with an LLM-as-a-Judge mechanism. Experiments on multiple classification tasks demonstrate that CIEGAD effectively extends the periphery of real-world data distributions while maintaining high alignment between generated and real-world data as well as semantic diversity. In particular, for long-tailed and multi-class classification tasks, CIEGAD consistently improves F1 and recall, validating the triple harmony of distributional consistency, diversity, and quality. These results indicate that CIEGAD serves as a practically oriented data augmentation framework that complements underrepresented regions while preserving alignment with real-world data.", "AI": {"tldr": "CIEGAD is a cluster-conditioned interpolative/extrapolative data augmentation framework that uses cluster-based domain profiles, a hierarchical frequency-geometric allocation scheme, and interpolative/extrapolative synthesis with geometry-constrained filtering and an LLM-based judge to expand the peripheral regions of real-world data while maintaining alignment, diversity, and quality, yielding improved F1/recall on long-tailed and multi-class tasks.", "motivation": "In practical deep learning deployment, data scarcity and label imbalance create semantically uncovered regions in real-world distributions, causing misclassification near class boundaries and unstable behavior in peripheral areas. Although LLMs show promise for data augmentation, there is no integrated framework that simultaneously provides directional control of generation, domain alignment, and quality control.", "method": "CIEGAD constructs domain profiles via cluster conditioning, employs a hierarchical frequency-geometric allocation that blends class frequency and geometric indicators to allocate generation, enables both interpolative (within-domain) and extrapolative (toward distribution periphery) synthesis for controlled directionality, and applies geometry-constrained filtering together with an LLM-as-a-Judge mechanism for quality control.", "result": "Experiments across multiple classification tasks show that CIEGAD expands the semantically uncovered peripheral regions while preserving alignment with real data and maintaining semantic diversity. In long-tailed and multi-class settings, it consistently improves F1 and recall, demonstrating distributional consistency, diversity, and quality.", "conclusion": "CIEGAD provides a practically oriented data augmentation framework that complements underrepresented regions in real-world distributions without sacrificing alignment, enabling more robust performance in diverse classification scenarios."}}
{"id": "2512.10600", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10600", "abs": "https://arxiv.org/abs/2512.10600", "authors": ["Han Yang", "Shaofeng Li", "Tian Dong", "Xiangyu Xu", "Guangchi Liu", "Zhen Ling"], "title": "Authority Backdoor: A Certifiable Backdoor Mechanism for Authoring DNNs", "comment": "Accepted to AAAI 2026 (Main Track). Code is available at: https://github.com/PlayerYangh/Authority-Trigger", "summary": "Deep Neural Networks (DNNs), as valuable intellectual property, face unauthorized use. Existing protections, such as digital watermarking, are largely passive; they provide only post-hoc ownership verification and cannot actively prevent the illicit use of a stolen model. This work proposes a proactive protection scheme, dubbed ``Authority Backdoor,\" which embeds access constraints directly into the model. In particular, the scheme utilizes a backdoor learning framework to intrinsically lock a model's utility, such that it performs normally only in the presence of a specific trigger (e.g., a hardware fingerprint). But in its absence, the DNN's performance degrades to be useless. To further enhance the security of the proposed authority scheme, the certifiable robustness is integrated to prevent an adaptive attacker from removing the implanted backdoor. The resulting framework establishes a secure authority mechanism for DNNs, combining access control with certifiable robustness against adversarial attacks. Extensive experiments on diverse architectures and datasets validate the effectiveness and certifiable robustness of the proposed framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3b\u52a8\u5f0f\u6743\u5a01\u4fdd\u62a4\u65b9\u6848 Authority Backdoor\uff0c\u901a\u8fc7\u5728\u6a21\u578b\u5185\u90e8\u690d\u5165\u8bbf\u95ee\u7ea6\u675f\uff0c\u4f7f\u6a21\u578b\u4ec5\u5728\u7279\u5b9a\u89e6\u53d1\u5668\u5b58\u5728\u65f6\u624d\u6b63\u5e38\u5de5\u4f5c\uff1b\u5728\u7f3a\u5931\u89e6\u53d1\u5668\u65f6\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u4ee5\u9632\u6b62\u76d7\u7528\uff0c\u4e14\u7ed3\u5408\u53ef\u8bc1\u5b9e\u9c81\u68d2\u6027\u4ee5\u9632\u6b62\u81ea\u9002\u5e94\u653b\u51fb\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u4e0e\u9c81\u68d2\u6027\u3002", "motivation": "\u4e3aDNNs\u7684\u77e5\u8bc6\u4ea7\u6743\u63d0\u4f9b\u4e3b\u52a8\u4fdd\u62a4\uff0c\u5f25\u8865\u73b0\u6709\u6570\u5b57\u6c34\u5370\u7b49\u88ab\u52a8\u4fdd\u62a4\u53ea\u80fd\u4e8b\u540e\u9a8c\u8bc1\u7684\u4e0d\u8db3\uff0c\u907f\u514d\u6a21\u578b\u88ab\u672a\u6388\u6743\u4f7f\u7528\u3002", "method": "\u901a\u8fc7\u80cc\u95e8\u5b66\u4e60\u6846\u67b6\u5728\u6a21\u578b\u4e2d\u5d4c\u5165\u8bbf\u95ee\u7ea6\u675f\uff0c\u4f7f\u6a21\u578b\u5728\u7279\u5b9a\u89e6\u53d1\u5668\uff08\u5982\u786c\u4ef6\u6307\u7eb9\uff09\u5b58\u5728\u65f6\u624d\u5177\u5907\u6b63\u5e38\u529f\u80fd\uff0c\u82e5\u89e6\u53d1\u5668\u7f3a\u5931\u5219\u6027\u80fd\u964d\u7ea7\uff0c\u540c\u65f6\u5f15\u5165\u53ef\u8bc1\u5b9e\u9c81\u68d2\u6027\u4ee5\u62b5\u6297\u79fb\u9664\u80cc\u95e8\u7684\u81ea\u9002\u5e94\u653b\u51fb\u3002", "result": "\u5728\u591a\u79cd\u67b6\u6784\u548c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u5b9e\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u4e0e\u53ef\u8bc1\u5b9e\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u8bbf\u95ee\u63a7\u5236\u4e0e\u53ef\u8bc1\u5b9e\u9c81\u68d2\u6027\u7ed3\u5408\uff0c\u63d0\u4f9b\u4e00\u79cd\u5b89\u5168\u7684DNN\u6743\u5a01\u673a\u5236\uff0c\u6709\u671b\u89e3\u51b3DNN\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u4e2d\u7684\u4e3b\u52a8\u9632\u62a4\u9700\u6c42\u3002"}}
{"id": "2512.10187", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10187", "abs": "https://arxiv.org/abs/2512.10187", "authors": ["Mantas Baksys", "Stefan Zetzsche", "Olivier Bouissou"], "title": "MiniF2F-Dafny: LLM-Guided Mathematical Theorem Proving via Auto-Active Verification", "comment": null, "summary": "We present miniF2F-Dafny, the first translation of the mathematical reasoning benchmark miniF2F to an automated theorem prover: Dafny. Previously, the benchmark existed only in interactive theorem provers (Lean, Isabelle, HOL Light, Metamath). We find that Dafny's automation verifies 99/244 (40.6%) of the test set and 109/244 (44.7%) of the validation set with empty proofs--requiring no manual proof steps. For problems where empty proofs fail, we evaluate 12 off-the-shelf LLMs on providing proof hints. The best model we test achieves 55.7% pass@4 success rate employing iterative error correction. These preliminary results highlight an effective division of labor: LLMs provide high-level guidance while automation handles low-level details. Our benchmark can be found on GitHub at http://github.com/dafny-lang/miniF2F .", "AI": {"tldr": "\u9996\u6b21\u5c06 miniF2F \u6570\u5b66\u63a8\u7406\u57fa\u51c6\u8f6c\u8bd1\u4e3a Dafny \u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\uff0c\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u534f\u540c\u6f5c\u529b\u3002", "motivation": "\u63a2\u7d22\u5c06\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4ece\u4e92\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\u6269\u5c55\u5230\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u53ef\u884c\u6027\uff0c\u4ee5\u8bc4\u4f30 Dafny \u7684\u81ea\u52a8\u5316\u6c34\u5e73\u53ca\u4e0e LLM \u7684\u534f\u540c\u8fb9\u754c\u3002", "method": "\u5c06 miniF2F \u8bd1\u672c\u63d0\u4ea4\u7ed9 Dafny \u81ea\u52a8\u8bc1\u660e\uff0c\u7edf\u8ba1\u901a\u8fc7\u7387\uff1b\u5bf9\u65e0\u6cd5\u7528\u7a7a\u8bc1\u660e\u5b8c\u6210\u7684\u95ee\u9898\uff0c\u8bc4\u4f3012\u4e2a\u73b0\u6210\u7684 LLM \u63d0\u4f9b\u8bc1\u660e\u63d0\u793a\uff0c\u7ed3\u5408\u8fed\u4ee3\u9519\u8bef\u7ea0\u6b63\u63d0\u5347\u901a\u8fc7\u7387\u3002", "result": "Dafny \u81ea\u52a8\u5316\u5728\u6d4b\u8bd5\u96c6 99/244\uff0840.6%\uff09\u548c\u9a8c\u8bc1\u96c6 109/244\uff0844.7%\uff09\u5b9e\u73b0\u7a7a\u8bc1\u660e\u901a\u8fc7\uff1b\u5bf9\u4e8e\u7a7a\u8bc1\u660e\u5931\u8d25\u7684\u95ee\u9898\uff0c12 \u4e2a LLM \u7684\u6700\u4f73\u6a21\u578b\u5728\u8fed\u4ee3\u7ea0\u9519\u4e0b\u5b9e\u73b0 55.7% \u7684 pass@4\uff1b\u62a5\u544a\u4e86\u4eba\u673a\u5206\u5de5\u7684\u6709\u6548\u6027\uff1aLLMs \u63d0\u4f9b\u9ad8\u5c42\u6b21\u6307\u5bfc\uff0c\u81ea\u52a8\u5316\u5904\u7406\u4f4e\u5c42\u6b21\u7ec6\u8282\u3002", "conclusion": "\u8be5\u57fa\u51c6\u53ef\u4e3a\u8bc4\u4f30\u81ea\u52a8\u8bc1\u660e\u5668\u4e0e\u63d0\u793a\u5de5\u7a0b\u7684\u534f\u540c\u63d0\u4f9b\u57fa\u7ebf\uff0cGitHub \u4e0a\u7684\u5b9e\u73b0\u53ef\u4f9b\u590d\u73b0\u4e0e\u6269\u5c55\u3002"}}
{"id": "2512.10636", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.10636", "abs": "https://arxiv.org/abs/2512.10636", "authors": ["David-Alexandre Guiraud", "Andrea Tundis", "Marc Winstel"], "title": "Objectives and Design Principles in Offline Payments with Central Bank Digital Currency (CBDC)", "comment": "22 pages main body, 31 pages overall; 7 tables", "summary": "In this work, fundamental design principles for a central bank digital currency (CBDC) with an offline functionality and corresponding counter measures are discussed. We identify three major objectives for any such CBDC proposal:(i) Access Control Security - protection of a user's funds against unauthorized access by other users; (ii) Security against Depositor's Misbehavior - preservation of the integrity of an environment (potentially the wallet) against misbehavior of its owner (for example, double-spending), and (iii) Privacy by Design - ensuring privacy is embedded into the system architecture. Our central conclusion is the alignment of the objectives to concrete design elements as countermeasures, whereas certain objectives and countermeasures have no or minimal interferences with each other. For example, we work out that the integrity of a user's wallet and, accordingly, the prevention of double-spending race attacks should be addressed through the adoption and integration of \\textit{secure hardware} within a CBDC system.", "AI": {"tldr": "\u63d0\u51fa\u79bb\u7ebf\u529f\u80fd\u7684CBDC\u8bbe\u8ba1\u539f\u5219\u53ca\u5bf9\u7b56\uff0c\u805a\u7126\u8bbf\u95ee\u63a7\u5236\u5b89\u5168\u3001\u5b58\u6b3e\u4eba\u884c\u4e3a\u5b89\u5168\u548c\u9690\u79c1\u4fdd\u62a4\u4e09\u5927\u76ee\u6807\uff0c\u5e76\u5c06\u5b83\u4eec\u6620\u5c04\u5230\u5177\u4f53\u5bf9\u7b56\uff1b\u8ba4\u4e3a\u5728\u7cfb\u7edf\u4e2d\u5f15\u5165\u5b89\u5168\u786c\u4ef6\u6709\u52a9\u4e8e\u9632\u6b62\u53cc\u82b1\u7b49\u653b\u51fb\u3002", "motivation": "\u5728\u79bb\u7ebf\u6a21\u5f0f\u4e0b\u4fdd\u6301\u8d44\u91d1\u5b89\u5168\u3001\u94b1\u5305\u5b8c\u6574\u6027\u4e0e\u7528\u6237\u9690\u79c1\uff0c\u540c\u65f6\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u592e\u884c\u6570\u5b57\u8d27\u5e01\u6846\u67b6\u3002", "method": "\u4ee5\u6982\u5ff5\u5206\u6790\u4e3a\u4e3b\uff0c\u8bc6\u522b\u4e09\u5927\u76ee\u6807\u5e76\u5c06\u5176\u4e0e\u53ef\u6267\u884c\u7684\u8bbe\u8ba1\u8981\u7d20/\u5bf9\u7b56\u5bf9\u5e94\uff0c\u8ba8\u8bba\u4e0d\u540c\u76ee\u6807\u95f4\u7684\u76f8\u4e92\u5e72\u6270\u6027\u53ca\u6f5c\u5728\u5b9e\u73b0\u8def\u5f84\uff08\u5982\u5b89\u5168\u786c\u4ef6\u7684\u5e94\u7528\uff09\u3002", "result": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u8bbe\u8ba1\u6846\u67b6\uff0c\u4e09\u5927\u76ee\u6807\u53ef\u901a\u8fc7\u7279\u5b9a\u5bf9\u7b56\u5b9e\u73b0\uff0c\u67d0\u4e9b\u76ee\u6807\u4e0e\u5bf9\u7b56\u4e4b\u95f4\u57fa\u672c\u4e0d\u51b2\u7a81\uff1b\u4ee5\u5b89\u5168\u786c\u4ef6\u5b9e\u73b0\u94b1\u5305\u5b8c\u6574\u6027\u3001\u9632\u6b62\u53cc\u82b1\u4e3a\u4f8b\u3002", "conclusion": "\u5c06\u79bb\u7ebfCBDC\u7684\u8bbe\u8ba1\u8981\u7d20\u4e0e\u5bf9\u7b56\u6574\u5408\uff0c\u5f62\u6210\u4e00\u81f4\u7684\u5b9e\u73b0\u8def\u5f84\uff0c\u5b89\u5168\u786c\u4ef6\u88ab\u89c6\u4e3a\u5b9e\u73b0\u6838\u5fc3\u673a\u5236\u4e4b\u4e00\u3002"}}
{"id": "2512.10224", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.10224", "abs": "https://arxiv.org/abs/2512.10224", "authors": ["Ragja Palakkadavath", "Hung Le", "Thanh Nguyen-Tang", "Svetha Venkatesh", "Sunil Gupta"], "title": "Federated Domain Generalization with Latent Space Inversion", "comment": "Accepted at ICDM 2025", "summary": "Federated domain generalization (FedDG) addresses distribution shifts among clients in a federated learning framework. FedDG methods aggregate the parameters of locally trained client models to form a global model that generalizes to unseen clients while preserving data privacy. While improving the generalization capability of the global model, many existing approaches in FedDG jeopardize privacy by sharing statistics of client data between themselves. Our solution addresses this problem by contributing new ways to perform local client training and model aggregation. To improve local client training, we enforce (domain) invariance across local models with the help of a novel technique, \\textbf{latent space inversion}, which enables better client privacy. When clients are not \\emph{i.i.d}, aggregating their local models may discard certain local adaptations. To overcome this, we propose an \\textbf{important weight} aggregation strategy to prioritize parameters that significantly influence predictions of local models during aggregation. Our extensive experiments show that our approach achieves superior results over state-of-the-art methods with less communication overhead.", "AI": {"tldr": "FedDG framework with privacy-aware training and aggregation: latent space inversion for domain-invariant local learning and important weight aggregation to preserve local adaptation, achieving better generalization to unseen clients with less communication.", "motivation": "Federated domain generalization must handle distribution shifts across clients while preserving data privacy. Existing FedDG methods often share statistics or model updates that can leak information; a privacy-preserving approach with efficient communication is desirable.", "method": "Proposes latent space inversion to enforce domain invariance during local training, reducing private information leakage. Introduces important weight aggregation to emphasize parameters that significantly influence local predictions, mitigating loss of local adaptation when client data are non-i.i.d. The framework aggregates locally trained models with privacy-aware techniques to form a global model.", "result": "Extensive experiments show superior performance compared to state-of-the-art FedDG methods and lower communication overhead.", "conclusion": "The approach improves generalization to unseen clients and preserves privacy while reducing communication, offering a practical and effective FedDG solution."}}
{"id": "2512.10653", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10653", "abs": "https://arxiv.org/abs/2512.10653", "authors": ["Daniyar Kurmankhojayev", "Andrei Shadrikov", "Dmitrii Gordin", "Mikhail Shkorin", "Danijar Gabdullin", "Aigerim Kambetbayeva", "Kanat Kuatov"], "title": "Virtual camera detection: Catching video injection attacks in remote biometric systems", "comment": null, "summary": "Face anti-spoofing (FAS) is a vital component of remote biometric authentication systems based on facial recognition, increasingly used across web-based applications. Among emerging threats, video injection attacks -- facilitated by technologies such as deepfakes and virtual camera software -- pose significant challenges to system integrity. While virtual camera detection (VCD) has shown potential as a countermeasure, existing literature offers limited insight into its practical implementation and evaluation. This study introduces a machine learning-based approach to VCD, with a focus on its design and validation. The model is trained on metadata collected during sessions with authentic users. Empirical results demonstrate its effectiveness in identifying video injection attempts and reducing the risk of malicious users bypassing FAS systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4f1a\u8bdd\u5143\u6570\u636e\u7684\u673a\u5668\u5b66\u4e60\u865a\u62df\u6444\u50cf\u5934\u68c0\u6d4b\uff08VCD\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u9762\u90e8\u9632\u6b3a\u8bc8\u4e2d\u7684\u89c6\u9891\u6ce8\u5165\u653b\u51fb\u8bc6\u522b\u80fd\u529b\u3002", "motivation": "\u89c6\u9891\u6ce8\u5165\u653b\u51fb\uff08\u5982\u6df1\u5ea6\u4f2a\u9020\u548c\u865a\u62df\u6444\u50cf\u5934\uff09\u5bf9\u9762\u90e8\u8bc6\u522b\u7cfb\u7edf\u7684\u5b8c\u6574\u6027\u6784\u6210\u65b0\u5a01\u80c1\uff0c\u800c\u73b0\u6709VCD\u7814\u7a76\u5728\u5b9e\u7528\u6027\u8bc4\u4f30\u65b9\u9762\u4e0d\u8db3\u3002", "method": "\u5728\u771f\u5b9e\u7528\u6237\u4f1a\u8bdd\u4e2d\u6536\u96c6\u7684\u5143\u6570\u636e\u4e0a\u8bad\u7ec3ML\u6a21\u578b\uff0c\u7528\u4e8eVCD\uff0c\u8bbe\u8ba1\u5e76\u9a8c\u8bc1\u8be5\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4ece\u8ba4\u8bc1\u7528\u6237\u7684\u4f1a\u8bdd\u5143\u6570\u636e\u4e2d\u5b66\u4e60\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\u8be5VCD\u65b9\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u89c6\u9891\u6ce8\u5165\u5c1d\u8bd5\uff0c\u964d\u4f4e\u7ed5\u8fc7FAS\u7cfb\u7edf\u7684\u98ce\u9669\u3002", "conclusion": "\u57fa\u4e8e\u5143\u6570\u636e\u7684ML-VCD\u4e3a\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u89c6\u9891\u6ce8\u5165\u653b\u51fb\u9632\u62a4\u63d0\u4f9b\u4e00\u79cd\u53ef\u884c\u3001\u6613\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9700\u8fdb\u4e00\u6b65\u5728\u591a\u573a\u666f\u4e0e\u4e0d\u540c\u786c\u4ef6\u4e0a\u8bc4\u4f30\u4e0e\u786e\u4fdd\u9690\u79c1\u5408\u89c4\u3002"}}
{"id": "2512.10229", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10229", "abs": "https://arxiv.org/abs/2512.10229", "authors": ["Jun Seo", "Hyeokjun Choe", "Seohui Bae", "Soyeon Park", "Wonbin Ahn", "Taeyoon Lim", "Junhyuk Kang", "Sangjun Han", "Jaehoon Lee", "Dongwan Kang", "Minjae Kim", "Sungdong Yoo", "Soonyoung Lee"], "title": "Adaptive Information Routing for Multimodal Time Series Forecasting", "comment": null, "summary": "Time series forecasting is a critical task for artificial intelligence with numerous real-world applications. Traditional approaches primarily rely on historical time series data to predict the future values. However, in practical scenarios, this is often insufficient for accurate predictions due to the limited information available. To address this challenge, multimodal time series forecasting methods which incorporate additional data modalities, mainly text data, alongside time series data have been explored. In this work, we introduce the Adaptive Information Routing (AIR) framework, a novel approach for multimodal time series forecasting. Unlike existing methods that treat text data on par with time series data as interchangeable auxiliary features for forecasting, AIR leverages text information to dynamically guide the time series model by controlling how and to what extent multivariate time series information should be combined. We also present a text-refinement pipeline that employs a large language model to convert raw text data into a form suitable for multimodal forecasting, and we introduce a benchmark that facilitates multimodal forecasting experiments based on this pipeline. Experiment results with the real world market data such as crude oil price and exchange rates demonstrate that AIR effectively modulates the behavior of the time series model using textual inputs, significantly enhancing forecasting accuracy in various time series forecasting tasks.", "AI": {"tldr": "\u63d0\u51fa Adaptive Information Routing (AIR) \u6846\u67b6\uff0c\u7528\u6587\u672c\u4fe1\u606f\u52a8\u6001\u5f15\u5bfc\u65f6\u5e8f\u6a21\u578b\u5728\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8fdb\u884c\u4fe1\u606f\u8def\u7531\u4e0e\u878d\u5408\uff1b\u5e76\u7ed3\u5408\u6587\u672c\u7cbe\u70bc\u7ba1\u7ebf\u4e0e\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5b9e\u8bc1\u8868\u660e\u5728\u771f\u5b9e\u5e02\u573a\u6570\u636e\u4e0a\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4ec5\u9760\u5386\u53f2\u65f6\u95f4\u5e8f\u5217\u4fe1\u606f\u5f80\u5f80\u4e0d\u8db3\u4ee5\u83b7\u5f97\u9ad8\u8d28\u91cf\u9884\u6d4b\uff0c\u9700\u8981\u5f15\u5165\u6587\u672c\u7b49\u6a21\u6001\u4fe1\u606f\u6765\u589e\u5f3a\u9884\u6d4b\u80fd\u529b\uff1b\u4f20\u7edf\u591a\u6a21\u6001\u65b9\u6cd5\u5c06\u6587\u672c\u4e0e\u65f6\u95f4\u5e8f\u5217\u540c\u7b49\u5bf9\u5f85\uff0c\u7f3a\u4e4f\u5bf9\u4fe1\u606f\u5982\u4f55\u88ab\u878d\u5408\u548c\u8def\u7531\u7684\u53ef\u63a7\u6027\u3002", "method": "\u63d0\u51fa AIR \u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u8def\u7531\u673a\u5236\u57fa\u4e8e\u6587\u672c\u4fe1\u606f\u52a8\u6001\u51b3\u5b9a\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u4fe1\u606f\u7684\u878d\u5408\u65b9\u5f0f\u4e0e\u6743\u91cd\uff1b\u6784\u5efa\u6587\u672c\u7cbe\u70bc\u6d41\u6c34\u7ebf\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u539f\u59cb\u6587\u672c\u8f6c\u6362\u4e3a\u9002\u7528\u4e8e\u591a\u6a21\u6001\u9884\u6d4b\u7684\u8868\u793a\uff1b\u63d0\u4f9b\u4e00\u4e2a\u652f\u6301\u591a\u6a21\u6001 forecasting \u7814\u7a76\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u5e02\u573a\u6570\u636e\uff08\u5982\u539f\u6cb9\u4ef7\u683c\u3001\u6c47\u7387\uff09\u4e0a\uff0cAIR \u80fd\u901a\u8fc7\u6587\u672c\u4fe1\u606f\u8c03\u63a7\u65f6\u5e8f\u6a21\u578b\u884c\u4e3a\uff0c\u663e\u8457\u63d0\u5347\u591a\u79cd\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u7684\u51c6\u786e\u5ea6\u3002", "conclusion": "AIR \u4e3a\u591a\u6a21\u6001\u65f6\u5e8f\u9884\u6d4b\u5f15\u5165\u53ef\u63a7\u7684\u4fe1\u606f\u8def\u7531\u673a\u5236\uff0c\u6709\u6548\u5229\u7528\u6587\u672c\u4fe1\u606f\u7684\u5f15\u5bfc\u4f5c\u7528\uff0c\u63d0\u5347\u6a21\u578b\u7684\u7075\u6d3b\u6027\u548c\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u7814\u7a76\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u6846\u67b6\u3002"}}
{"id": "2512.10667", "categories": ["cs.CR", "cs.DC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.10667", "abs": "https://arxiv.org/abs/2512.10667", "authors": ["Damilare Peter Oyinloye", "Mohd Sameen Chishti", "Jingyue Li"], "title": "A Proof of Success and Reward Distribution Protocol for Multi-bridge Architecture in Cross-chain Communication", "comment": null, "summary": "Single-bridge blockchain solutions enable cross-chain communication. However, they are associated with centralization and single-point-of-failure risks. This paper proposes Proof of Success and Reward Distribution (PSCRD), a novel multi-bridge response coordination and incentive distribution protocol designed to address the challenges. PSCRD introduces a fair reward distribution system that equitably distributes the transfer fee among participating bridges, incentivizing honest behavior and sustained commitment. The purpose is to encourage bridge participation for higher decentralization and lower single-point-of-failure risks. The mathematical analysis and simulation results validate the effectiveness of PSCRD using two key metrics: the Gini index, which demonstrates a progressive improvement in the fairness of the reward distribution as new bridge groups joined the network; and the Nakamoto coefficient, which shows a significant improvement in decentralization over time. These findings highlight that PSCRD provides a more resilient and secure cross-chain bridge system without substantially increasing user costs.", "AI": {"tldr": "PSCRD \u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6865\u54cd\u5e94\u534f\u8c03\u4e0e\u5956\u52b1\u5206\u914d\u534f\u8bae\uff0c\u7528\u4ee5\u63d0\u5347\u8de8\u94fe\u6865\u7684\u53bb\u4e2d\u5fc3\u5316\u4e0e\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7528\u6237\u6210\u672c\u3002", "motivation": "\u89e3\u51b3\u5355\u6865\u8de8\u94fe\u65b9\u6848\u7684\u4e2d\u5fc3\u5316\u548c\u5355\u70b9\u6545\u969c\u98ce\u9669\uff0c\u901a\u8fc7\u516c\u5e73\u7684\u5956\u52b1\u5206\u914d\u6fc0\u52b1\u6865\u53c2\u4e0e\u3002", "method": "\u63d0\u51fa Proof of Success and Reward Distribution (PSCRD) \u6846\u67b6\uff0c\u8bbe\u8ba1\u591a\u6865\u534f\u540c\u54cd\u5e94\u4e0e\u6fc0\u52b1\u5206\u914d\u7b97\u6cd5\uff0c\u7ed3\u5408\u7406\u8bba\u5206\u6790\u4e0e\u4eff\u771f\u8bc4\u4f30\u3002", "result": "\u4eff\u771f\u548c\u5206\u6790\u663e\u793a\uff1aGini \u6307\u6570\u968f\u65b0\u6865\u52a0\u5165\u9010\u6b65\u4e0b\u964d\uff0c\u5956\u52b1\u5206\u914d\u66f4\u516c\u5e73\uff1bNakamoto \u7cfb\u6570\u968f\u65f6\u95f4\u63d0\u9ad8\uff0c\u53bb\u4e2d\u5fc3\u5316\u663e\u8457\u63d0\u5347\uff1b\u7528\u6237\u6210\u672c\u672a\u663e\u8457\u589e\u52a0\u3002", "conclusion": "PSCRD \u63d0\u4f9b\u66f4\u5177\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u7684\u8de8\u94fe\u6865\u4f53\u7cfb\uff0c\u964d\u4f4e\u5355\u70b9\u6545\u969c\u98ce\u9669\u5e76\u63d0\u9ad8\u53bb\u4e2d\u5fc3\u5316\u7a0b\u5ea6\u3002"}}
{"id": "2512.10258", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10258", "abs": "https://arxiv.org/abs/2512.10258", "authors": ["Duo Wang", "Xinming Wang", "Chao Wang", "Xiaowei Yue", "Jianguo Wu"], "title": "R^2-HGP: A Double-Regularized Gaussian Process for Heterogeneous Transfer Learning", "comment": "17 pages, 9 figures. Under review for IEEE TPAMI", "summary": "Multi-output Gaussian process (MGP) models have attracted significant attention for their flexibility and uncertainty-quantification capabilities, and have been widely adopted in multi-source transfer learning scenarios due to their ability to capture inter-task correlations. However, they still face several challenges in transfer learning. First, the input spaces of the source and target domains are often heterogeneous, which makes direct knowledge transfer difficult. Second, potential prior knowledge and physical information are typically ignored during heterogeneous transfer, hampering the utilization of domain-specific insights and leading to unstable mappings. Third, inappropriate information sharing among target and sources can easily lead to negative transfer. Traditional models fail to address these issues in a unified way. To overcome these limitations, this paper proposes a Double-Regularized Heterogeneous Gaussian Process framework (R^2-HGP). Specifically, a trainable prior probability mapping model is first proposed to align the heterogeneous input domains. The resulting aligned inputs are treated as latent variables, upon which a multi-source transfer GP model is constructed and the entire structure is integrated into a novel conditional variational autoencoder (CVAE) based framework. Physical insights is further incorporated as a regularization term to ensure that the alignment results adhere to known physical knowledge. Next, within the multi-source transfer GP model, a sparsity penalty is imposed on the transfer coefficients, enabling the model to adaptively select the most informative source outputs and suppress negative transfer. Extensive simulations and real-world engineering case studies validate the effectiveness of our R^2-HGP, demonstrating consistent superiority over state-of-the-art benchmarks across diverse evaluation metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53cc\u6b63\u5219\u5316\u5f02\u6784\u9ad8\u65af\u8fc7\u7a0b\uff08R^2-HGP\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u6e90\u8f6c\u79fb\u5b66\u4e60\u3002\u901a\u8fc7\u53ef\u8bad\u7ec3\u7684\u5148\u9a8c\u6620\u5c04\u5bf9\u5f02\u8d28\u8f93\u5165\u8fdb\u884c\u5bf9\u9f50\uff0c\u5c06\u5bf9\u9f50\u540e\u7684\u8f93\u5165\u4f5c\u4e3a\u6f5c\u53d8\u91cf\uff0c\u6784\u5efa\u591a\u6e90\u8f6c\u79fb GP\uff0c\u5e76\u5728CVAE\u6846\u67b6\u4e2d\u6574\u5408\uff1b\u5f15\u5165\u7269\u7406\u77e5\u8bc6\u6b63\u5219\u5316\u4ee5\u7ea6\u675f\u5bf9\u9f50\uff0c\u5e76\u5bf9\u4f20\u8f93\u7cfb\u6570\u8fdb\u884c\u7a00\u758f\u60e9\u7f5a\u4ee5\u6291\u5236\u8d1f\u8fc1\u79fb\u3002\u901a\u8fc7\u5927\u91cf\u4eff\u771f\u548c\u5de5\u7a0b\u6848\u4f8b\u9a8c\u8bc1\u5176\u5728\u591a\u6e90\u8f6c\u79fb\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u6e90/\u76ee\u6807\u57df\u8f93\u5165\u7a7a\u95f4\u5f02\u8d28\u6027\u3001\u5728\u5f02\u6784\u8f6c\u79fb\u4e2d\u672a\u5145\u5206\u5229\u7528\u5148\u9a8c\u77e5\u8bc6/\u7269\u7406\u4fe1\u606f\u3001\u4ee5\u53ca\u4fe1\u606f\u5171\u4eab\u4e0d\u5f53\u5bfc\u81f4\u7684\u8d1f\u8fc1\u79fb\uff0c\u8fd9\u662f\u4f20\u7edf\u591a\u8f93\u51fa\u9ad8\u65af\u8fc7\u7a0b\u5728\u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u540c\u65f6\u89e3\u51b3\u8fd9\u4e09\u7c7b\u95ee\u9898\u3002", "method": "1) \u63d0\u51fa\u53ef\u8bad\u7ec3\u7684\u5148\u9a8c\u6982\u7387\u6620\u5c04\u6a21\u578b\u4ee5\u5bf9\u9f50\u5f02\u8d28\u8f93\u5165\u57df\uff1b2) \u5c06\u5bf9\u9f50\u540e\u7684\u8f93\u5165\u89c6\u4e3a\u6f5c\u53d8\u91cf\uff0c\u6784\u5efa\u591a\u6e90\u8f6c\u79fb\u9ad8\u65af\u8fc7\u7a0b\uff1b3) \u5c06\u6574\u4e2a\u7ed3\u6784\u96c6\u6210\u5230\u57fa\u4e8e\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08CVAE\uff09\u7684\u6846\u67b6\u4e2d\uff1b4) \u5c06\u7269\u7406\u6d1e\u89c1\u4f5c\u4e3a\u6b63\u5219\u5316\u9879\u7eb3\u5165\uff0c\u4ee5\u786e\u4fdd\u5bf9\u9f50\u7b26\u5408\u7269\u7406\u77e5\u8bc6\uff1b5) \u5728\u591a\u6e90\u8f6c\u79fbGP\u6a21\u578b\u4e2d\u5bf9\u4f20\u8f93\u7cfb\u6570\u65bd\u52a0\u7a00\u758f\u60e9\u7f5a\uff0c\u4ee5\u81ea\u9002\u5e94\u9009\u62e9\u6700\u6709\u4fe1\u606f\u7684\u6e90\u8f93\u51fa\u5e76\u6291\u5236\u8d1f\u8fc1\u79fb\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u4eff\u771f\u548c\u5b9e\u9645\u5de5\u7a0b\u6848\u4f8b\u7814\u7a76\uff0cR^2-HGP\u5728\u591a\u6e90\u8f6c\u79fb\u5b66\u4e60\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u5bf9\u6bd4\u57fa\u51c6\u7684\u663e\u8457\u4f18\u52bf\uff0c\u5728\u591a\u79cd\u8bc4\u4f30\u6307\u6807\u4e0a\u5b9e\u73b0\u4e00\u81f4\u7684\u6539\u8fdb\u3002", "conclusion": "R^2-HGP\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u80fd\u591f\u89e3\u51b3\u8f93\u5165\u5f02\u8d28\u6027\u3001\u5148\u9a8c/\u7269\u7406\u4fe1\u606f\u878d\u5165\u4ee5\u53ca\u8d1f\u8fc1\u79fb\u7b49\u6838\u5fc3\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\u5177\u5907\u7a33\u5b9a\u4e14\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u5177\u5907\u8f83\u597d\u7684\u6cdb\u5316\u4e0e\u53ef\u89e3\u91ca\u6027\u6f5c\u529b\u3002"}}
{"id": "2512.10732", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.10732", "abs": "https://arxiv.org/abs/2512.10732", "authors": ["Matthieu Bettinger", "Sonia Ben Mokhtar", "Pascal Felber", "Etienne Rivi\u00e8re", "Valerio Schiavoni", "Anthony Simonet-Boulogne"], "title": "TriHaRd: Higher Resilience for TEE Trusted Time", "comment": "2026 45th IEEE International Conference on Computer Communications (INFOCOM)", "summary": "Accurately measuring time passing is critical for many applications. However, in Trusted Execution Environments (TEEs) such as Intel SGX, the time source is outside the Trusted Computing Base: a malicious host can manipulate the TEE's notion of time, jumping in time or affecting perceived time speed. Previous work (Triad) proposes protocols for TEEs to maintain a trustworthy time source by building a cluster of TEEs that collaborate with each other and with a remote Time Authority to maintain a continuous notion of passing time. However, such approaches still allow an attacker to control the operating system and arbitrarily manipulate their own TEE's perceived clock speed. An attacker can even propagate faster passage of time to honest machines participating in Triad's trusted time protocol, causing them to skip to timestamps arbitrarily far in the future. We propose TriHaRd, a TEE trusted time protocol achieving high resilience against clock speed and offset manipulations, notably through Byzantine-resilient clock updates and consistency checks. We empirically show that TriHaRd mitigates known attacks against Triad.", "AI": {"tldr": "TriHaRd is a more robust TEE time protocol that fixes Triad's vulnerabilities by introducing Byzantine-resilient clock updates and consistency checks to resist clock-speed and offset manipulation.", "motivation": "Accurate and trustworthy time is essential for TEEs, but time sources are exposed to a potentially malicious host. Triad's design can be exploited to speed up or distort time propagation, compromising security. There is a need for a resilient time protocol that tolerates Byzantine behaviors and maintains consistent time across TEEs.", "method": "Design and propose TriHaRd, a time-keeping protocol for TEEs that employs Byzantine-resilient clock updates and cross-TEE consistency checks. It builds on a cluster of TEEs and an external Time Authority to ensure a continuous and trustworthy notion of time, even under adversarial conditions.", "result": "Empirical evaluation shows that TriHaRd mitigates known attacks against Triad, demonstrating improved resilience to clock-speed and offset manipulations and preventing adversaries from propagating fast time to honest participants.", "conclusion": "TriHaRd provides higher resilience to clock manipulation in TEEs, delivering more reliable and consistent time across a network of TEEs compared to Triad."}}
{"id": "2512.10308", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10308", "abs": "https://arxiv.org/abs/2512.10308", "authors": ["Vasiliki Stoumpou", "Maciej Tysarowski", "Talhat Azemi", "Jawad Haider", "Howard L. Haronian", "Robert C. Hagberg", "Dimitris Bertsimas"], "title": "An Interpretable AI Tool for SAVR vs TAVR in Low to Intermediate Risk Patients with Severe Aortic Stenosis", "comment": null, "summary": "Background. Treatment selection for low to intermediate risk patients with severe aortic stenosis between surgical (SAVR) and transcatheter (TAVR) aortic valve replacement remains variable in clinical practice, driven by patient heterogeneity and institutional preferences. While existing models predict postprocedural risk, there is a lack of interpretable, individualized treatment recommendations that directly optimize long-term outcomes.\n  Methods. We introduce an interpretable prescriptive framework that integrates prognostic matching, counterfactual outcome modeling, and an Optimal Policy Tree (OPT) to recommend the treatment minimizing expected 5-year mortality. Using data from Hartford Hospital and St. Vincent's Hospital, we emulate randomization via prognostic matching and sample weighting and estimate counterfactual mortality under both SAVR and TAVR. The policy model, trained on these counterfactual predictions, partitions patients into clinically coherent subgroups and prescribes the treatment associated with lower estimated risk.\n  Findings. If the OPT prescriptions are applied, counterfactual evaluation showed an estimated reduction in 5-year mortality of 20.3\\% in Hartford and 13.8\\% in St. Vincent's relative to real-life prescriptions, showing promising generalizability to unseen data from a different institution. The learned decision boundaries aligned with real-world outcomes and clinical observations.\n  Interpretation. Our interpretable prescriptive framework is, to the best of our knowledge, the first to provide transparent, data-driven recommendations for TAVR versus SAVR that improve estimated long-term outcomes both in an internal and external cohort, while remaining clinically grounded and contributing toward a more systematic and evidence-based approach to precision medicine in structural heart disease.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u5904\u65b9\u6846\u67b6\uff0c\u7528 prognostic matching\u3001counterfactual \u9884\u6d4b\u4e0e\u6700\u4f18\u7b56\u7565\u6811\uff08OPT\uff09\u5728 SAVR \u4e0e TAVR \u4e4b\u95f4\u4e3a\u4f4e\u81f3\u4e2d\u7b49\u98ce\u9669\u60a3\u8005\u7ed9\u51fa\u957f\u671f\uff085 \u5e74\uff09\u7ed3\u5c40\u7684\u4e2a\u4f53\u5316\u6cbb\u7597\u5efa\u8bae\uff0c\u8bc4\u4f30\u663e\u793a\u82e5\u6309 OPT \u5904\u65b9\uff0c5 \u5e74\u6b7b\u4ea1\u7387\u76f8\u5bf9\u771f\u5b9e\u5904\u65b9\u4e0b\u964d\u663e\u8457\uff0c\u5177\u8de8\u673a\u6784\u6cdb\u5316\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u4ec5\u6709\u9884\u6d4b\u4e2a\u4f53\u98ce\u9669\u7684\u6a21\u578b\uff0c\u7f3a\u4e4f\u76f4\u63a5\u4f18\u5316\u957f\u671f\u7ed3\u5c40\u3001\u4e14\u5177\u6709\u53ef\u89e3\u91ca\u6027\u7684\u4e2a\u4f53\u5316\u6cbb\u7597\u63a8\u8350\uff1b\u672c\u7814\u7a76\u65e8\u5728\u63d0\u4f9b\u900f\u660e\u4e14\u6570\u636e\u9a71\u52a8\u7684 TAVR/SAVR \u9009\u62e9\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u957f\u671f\u751f\u5b58\u83b7\u76ca\u3002", "method": "\u5728 Hartford Hospital \u4e0e St. Vincent's Hospital \u7684\u6570\u636e\u4e0a\uff0c\u5229\u7528 prognostic matching \u548c\u6837\u672c\u52a0\u6743\u6765\u8fd1\u4f3c\u968f\u673a\u5316\uff0c\u5e76\u4f30\u8ba1\u5728 SAVR \u4e0e TAVR \u4e0b\u7684\u53cd\u4e8b\u5b9e\u6b7b\u4ea1\u7387\u3002\u968f\u540e\u4ee5\u53cd\u4e8b\u5b9e\u9884\u6d4b\u8bad\u7ec3 Optimal Policy Tree\uff0c\u8f93\u51fa\u5c06\u60a3\u8005\u5206\u533a\u5e76\u7ed9\u51fa\u964d\u4f4e\u957f\u671f\u6b7b\u4ea1\u98ce\u9669\u7684\u6cbb\u7597\u9009\u62e9\u3002", "result": "OPT \u5904\u65b9\u5e94\u7528\u540e\uff0c Hartford \u6570\u636e\u96c6\u76f8\u5bf9\u771f\u5b9e\u5904\u65b9\u7684 5 \u5e74\u6b7b\u4ea1\u7387\u4e0b\u964d\u7ea6 20.3%\uff1b St. Vincent's \u6570\u636e\u96c6\u4e0b\u964d\u7ea6 13.8%\u3002\u7ed3\u679c\u4e0e\u5916\u90e8\u6570\u636e\u7684\u4e00\u81f4\u6027\u63d0\u793a\u6a21\u578b\u5177\u5907\u4e00\u5b9a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u5206\u6790\u6846\u67b6\u9996\u6b21\u5728 TAVR \u4e0e SAVR \u7684\u6bd4\u8f83\u4e2d\u63d0\u4f9b\u900f\u660e\u3001\u6570\u636e\u9a71\u52a8\u7684\u957f\u671f\u7ed3\u5c40\u4f18\u5316\u5efa\u8bae\uff0c\u5177\u6709\u8de8\u673a\u6784\u9002\u7528\u6027\u5e76\u6709\u52a9\u4e8e\u7ed3\u6784\u5fc3\u810f\u75c5\u7684\u7cbe\u51c6\u533b\u7597\u5b9e\u8df5\u3002"}}
{"id": "2512.10341", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10341", "abs": "https://arxiv.org/abs/2512.10341", "authors": ["Vinoth Punniyamoorthy", "Ashok Gadi Parthi", "Mayilsamy Palanigounder", "Ravi Kiran Kodali", "Bikesh Kumar", "Kabilan Kannan"], "title": "A Privacy-Preserving Cloud Architecture for Distributed Machine Learning at Scale", "comment": null, "summary": "Distributed machine learning systems require strong privacy guarantees, verifiable compliance, and scalable deploy- ment across heterogeneous and multi-cloud environments. This work introduces a cloud-native privacy-preserving architecture that integrates federated learning, differential privacy, zero- knowledge compliance proofs, and adaptive governance powered by reinforcement learning. The framework supports secure model training and inference without centralizing sensitive data, while enabling cryptographically verifiable policy enforcement across institutions and cloud platforms. A full prototype deployed across hybrid Kubernetes clusters demonstrates reduced membership- inference risk, consistent enforcement of formal privacy budgets, and stable model performance under differential privacy. Ex- perimental evaluation across multi-institution workloads shows that the architecture maintains utility with minimal overhead while providing continuous, risk-aware governance. The pro- posed framework establishes a practical foundation for deploying trustworthy and compliant distributed machine learning systems at scale.", "AI": {"tldr": "\u4e91\u539f\u751f\u9690\u79c1\u4fdd\u62a4\u67b6\u6784\uff0c\u878d\u5408\u8054\u90a6\u5b66\u4e60\u3001\u5dee\u5206\u9690\u79c1\u3001\u96f6\u77e5\u8bc6\u5408\u89c4\u8bc1\u660e\u4e0e\u5f3a\u5316\u5b66\u4e60\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u6cbb\u7406\uff0c\u5728\u6df7\u5408Kubernetes\u73af\u5883\u4e0b\u5b9e\u73b0\u5b89\u5168\u8bad\u7ec3/\u63a8\u7406\u3001\u53ef\u9a8c\u8bc1\u7684\u7b56\u7565\u6267\u884c\uff0c\u4ee5\u53ca\u4f4e\u5f00\u9500\u7684\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u573a\u666f\u4e2d\uff0c\u9700\u8981\u5f3a\u9690\u79c1\u4fdd\u62a4\u3001\u53ef\u9a8c\u8bc1\u7684\u5408\u89c4\u6027\u4ee5\u53ca\u8de8\u591a\u4e91/\u6df7\u5408\u4e91\u73af\u5883\u7684\u53ef\u6269\u5c55\u90e8\u7f72\uff0c\u907f\u514d\u96c6\u4e2d\u5316\u6570\u636e\u5e76\u63d0\u5347\u6cbb\u7406\u80fd\u529b\u3002", "method": "\u5c06\u8054\u90a6\u5b66\u4e60\u3001\u5dee\u5206\u9690\u79c1\u3001\u96f6\u77e5\u8bc6\u8bc1\u660e\u7528\u4e8e\u5408\u89c4\u6027\u8bc1\u660e\uff0c\u4ee5\u53ca\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u6cbb\u7406\u7ed3\u5408\u4e91\u539f\u751f\u67b6\u6784\uff0c\u5f00\u53d1\u4e00\u4e2a\u53ef\u5728\u6df7\u5408Kubernetes\u96c6\u7fa4\u4e2d\u90e8\u7f72\u7684\u539f\u578b\uff0c\u5b9e\u73b0\u5b89\u5168\u8bad\u7ec3\u4e0e\u63a8\u7406\u3001\u65e0\u9700\u96c6\u4e2d\u6570\u636e\u3001\u5e76\u63d0\u4f9b\u53ef\u5bc6\u7801\u5b66\u9a8c\u8bc1\u7684\u7b56\u7565\u5f3a\u5236\u6267\u884c\u3002", "result": "\u539f\u578b\u5c55\u793a\u4e86\u5bf9\u6210\u5458\u8eab\u4efd\u63a8\u65ad\u98ce\u9669\u7684\u964d\u4f4e\u3001\u9690\u79c1\u9884\u7b97\u7684\u4e00\u81f4\u5f3a\u5236\u6267\u884c\u3001\u5728\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u4e0b\u6a21\u578b\u6027\u80fd\u7684\u7a33\u5b9a\uff0c\u4ee5\u53ca\u591a\u673a\u6784\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u5b9e\u7528\u6027\u548c\u4f4e\u5f00\u9500\uff1b\u5b9e\u9a8c\u8868\u660e\u5728\u6301\u7eed\u7684\u98ce\u9669\u611f\u77e5\u6cbb\u7406\u4e0b\uff0c\u5de5\u5177\u5177\u5907\u826f\u597d\u53ef\u6269\u5c55\u6027\u4e0e\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5728\u5927\u89c4\u6a21\u3001\u53ef\u4fe1\u4efb\u4e14\u5408\u89c4\u7684\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u90e8\u7f72\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5207\u5b9e\u53ef\u884c\u7684\u57fa\u7840\uff0c\u4fc3\u8fdb\u8de8\u673a\u6784\u4e0e\u591a\u4e91\u73af\u5883\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u4e0e\u6cbb\u7406\u80fd\u529b\u3002"}}
{"id": "2512.10365", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.10365", "abs": "https://arxiv.org/abs/2512.10365", "authors": ["Hangyu Mao", "Guangting Dong", "Zhicheng Dou"], "title": "GPG: Generalized Policy Gradient Theorem for Transformer-based Policies", "comment": null, "summary": "We present the Generalized Policy Gradient (GPG) Theorem, specifically designed for Transformer-based policies. Notably, we demonstrate that both standard Policy Gradient Theorem and GRPO emerge as special cases within our GPG framework. Furthermore, we explore its practical applications in training Large Language Models (LLMs), offering new insights into efficient policy optimization.", "AI": {"tldr": "Generalized Policy Gradient (GPG) \u4f5c\u4e3a\u9762\u5411 Transformer \u7b56\u7565\u7684\u7edf\u4e00\u68af\u5ea6\u6846\u67b6\uff0c\u8868\u660e\u6807\u51c6 Policy Gradient Theorem \u4e0e GRPO \u5df2\u4f5c\u4e3a\u7279\u4f8b\u5305\u542b\u5176\u4e2d\uff0c\u5e76\u63a2\u8ba8\u5176\u5728\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u4e0e\u6548\u7387\u63d0\u5347\u7684\u6f5c\u529b\u3002", "motivation": "\u4e3a Transformer \u57fa\u7840\u7684\u7b56\u7565\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u4e14\u53ef\u6269\u5c55\u7684\u68af\u5ea6\u4f18\u5316\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u73b0\u6709\u7684 Policy Gradient \u4e0e GRPO \u7edf\u4e00\u5728 GPG \u4e0b\uff0c\u5e76\u4e3a\u5728 LLM \u8bad\u7ec3\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u7b56\u7565\u4f18\u5316\u63d0\u4f9b\u7406\u8bba\u652f\u6491\u3002", "method": "\u63a8\u5bfc\u5e76\u5efa\u7acb GPG \u5b9a\u7406\uff0c\u4f7f\u5176\u5728 Transformer \u7b56\u7565\u4e0b\u6210\u7acb\uff1b\u8bc1\u660e\u6807\u51c6 Policy Gradient Theorem \u4e0e GRPO \u4e24\u8005\u53ef\u4ee5\u4ece GPG \u63a8\u5bfc\u51fa\u6210\u4e3a\u7279\u4f8b\uff1b\u8ba8\u8bba\u5c06 GPG \u5e94\u7528\u4e8e LLM \u8bad\u7ec3\u4e2d\u7684\u5177\u4f53\u505a\u6cd5\u4e0e\u4f18\u5316\u8def\u5f84\uff0c\u5f3a\u8c03\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u7ed3\u5408\u3002", "result": "\u4ece\u7406\u8bba\u5c42\u9762\u5b9e\u73b0\u4e86\u5bf9\u6807\u51c6 PG \u548c GRPO \u7684\u7edf\u4e00\uff1a\u4e24\u8005\u5728 GPG \u6846\u67b6\u4e0b\u4e3a\u540c\u4e00\u68af\u5ea6\u4f18\u5316\u4f53\u7cfb\u7684\u7279\u4f8b\uff1b\u5728\u5b9e\u8df5\u5c42\u9762\u63ed\u793a\u4e86\u5c06 GPG \u5e94\u7528\u4e8e Transformer/LLM \u7b56\u7565\u4f18\u5316\u7684\u6f5c\u5728\u4f18\u52bf\u4e0e\u5e94\u7528\u573a\u666f\uff0c\u63d0\u4f9b\u5bf9\u9ad8\u6548\u7b56\u7565\u4f18\u5316\u7684\u65b0\u89c1\u89e3\u3002", "conclusion": "GPG \u4e3a Transformer \u57fa\u7840\u7684\u7b56\u7565\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u3001\u53ef\u6269\u5c55\u7684\u7406\u8bba\u6846\u67b6\uff0c\u80fd\u591f\u5c06\u6807\u51c6\u7b56\u7565\u68af\u5ea6\u548c GRPO \u4ee5\u53ca\u672a\u6765\u7684\u68af\u5ea6\u65b9\u6cd5\u7eb3\u5165\u540c\u4e00\u4f53\u7cfb\uff0c\u63a8\u52a8\u5728 LLM \u8bad\u7ec3\u4e2d\u7684\u66f4\u9ad8\u6548\u3001\u7cfb\u7edf\u5316\u7684\u7b56\u7565\u4f18\u5316\u4e0e\u5b9e\u8df5\u3002"}}
{"id": "2512.10390", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.class-ph"], "pdf": "https://arxiv.org/pdf/2512.10390", "abs": "https://arxiv.org/abs/2512.10390", "authors": ["Vijay Prakash S"], "title": "Fitting magnetization data using continued fraction of straight lines", "comment": "17 pages, 12 figures, 4 tables", "summary": "Magnetization of a ferromagnetic substance in response to an externally applied magnetic field increases with the strength of the field. This is because at the microscopic level, magnetic moments in certain regions or domains of the substance increasingly align with the applied field, while the amount of misaligned domains decreases. The alignment of such magnetic domains with an applied magnetic field forms the physical basis for the nonlinearity of magnetization. In this paper, the nonlinear function is approximated as a combination of continued fraction of straight lines. The resulting fit is used to interpret the nonlinear behavior in both growing and shrinking magnetic domains. The continued fraction of straight lines used here is an algebraic expression which can be used to estimate parameters using nonlinear regression.", "AI": {"tldr": "\u7528\u7ee7\u7eed\u5206\u6570\uff08continued fraction\uff09\u8fd1\u4f3c ferromagnetic M(H) \u7684\u975e\u7ebf\u6027\u54cd\u5e94\uff0c\u5e76\u901a\u8fc7\u975e\u7ebf\u6027\u56de\u5f52\u4f30\u8ba1\u6a21\u578b\u53c2\u6570\uff1b\u8be5\u65b9\u6cd5\u89e3\u91ca\u57df\u7684\u751f\u957f\u4e0e\u6536\u7f29\u5bf9\u78c1\u5316\u66f2\u7ebf\u7684\u5f71\u54cd\u3002", "motivation": "\u78c1\u5316\u5f3a\u5ea6\u5bf9\u5916\u52a0\u78c1\u573a\u5448\u73b0\u975e\u7ebf\u6027\uff0c\u4f20\u7edf\u6a21\u578b\u96be\u4ee5\u7075\u6d3b\u62df\u5408\u5b9e\u9a8c\u6570\u636e\u3002\u7528\u76f4\u7ebf\u7684\u7ee7\u7eed\u5206\u6570\u4f5c\u4e3a\u4ee3\u6570\u8868\u8fbe\u5f0f\uff0c\u63d0\u4f9b\u4e00\u79cd\u53ef\u89e3\u6790\u4e14\u53ef\u7528\u4e8e\u53c2\u6570\u4f30\u8ba1\u7684\u62df\u5408\u5de5\u5177\u3002", "method": "\u5c06\u975e\u7ebf\u6027\u51fd\u6570\u8fd1\u4f3c\u4e3a\u76f4\u7ebf\u7684\u7ee7\u7eed\u5206\u6570\u5f62\u5f0f\uff0c\u4f7f\u7528\u975e\u7ebf\u6027\u56de\u5f52\u62df\u5408\u78c1\u5316\u5f3a\u5ea6\u4e0e\u78c1\u573a\u7684\u5173\u7cfb\uff1b\u901a\u8fc7\u62df\u5408\u53c2\u6570\u89e3\u91ca\u78c1\u57df\u7684\u751f\u957f\u4e0e\u6536\u7f29\u8fc7\u7a0b\u3002", "result": "\u6240\u5f97\u5230\u7684\u62df\u5408\u80fd\u6355\u6349\u975e\u7ebf\u6027\u7279\u5f81\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u7684\u53c2\u6570\uff0c\u4fbf\u4e8e\u89e3\u91ca\u57df\u7684\u6f14\u5316\uff1b\u7ee7\u7eed\u5206\u6570\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ee3\u6570\u53ef\u7528\u7684\u8868\u8fbe\u5f0f\uff0c\u4fbf\u4e8e\u53c2\u6570\u4f30\u8ba1\u3002", "conclusion": "\u76f4\u7ebf\u7ee7\u7eed\u5206\u6570\u662f\u5efa\u6a21\u94c1\u78c1\u6750\u6599\u975e\u7ebf\u6027\u78c1\u5316\u54cd\u5e94\u7684\u53ef\u884c\u5de5\u5177\uff0c\u80fd\u591f\u63d0\u4f9b\u57df\u52a8\u529b\u5b66\u53c2\u6570\u5e76\u5177\u6709\u8ba1\u7b97\u4e0a\u7684\u4fbf\u5229\u3002"}}
{"id": "2512.10492", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10492", "abs": "https://arxiv.org/abs/2512.10492", "authors": ["Jiaxi Wu", "Tiantian Zhang", "Yuxing Wang", "Yongzhe Chang", "Xueqian Wang"], "title": "UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning", "comment": null, "summary": "Robust adversarial reinforcement learning has emerged as an effective paradigm for training agents to handle uncertain disturbance in real environments, with critical applications in sequential decision-making domains such as autonomous driving and robotic control. Within this paradigm, agent training is typically formulated as a zero-sum Markov game between a protagonist and an adversary to enhance policy robustness. However, the trainable nature of the adversary inevitably induces non-stationarity in the learning dynamics, leading to exacerbated training instability and convergence difficulties, particularly in high-dimensional complex environments. In this paper, we propose a novel approach, Uncertainty-Aware Critic Ensemble for robust adversarial Reinforcement learning (UACER), which consists of two strategies: 1) Diversified critic ensemble: a diverse set of K critic networks is exploited in parallel to stabilize Q-value estimation rather than conventional single-critic architectures for both variance reduction and robustness enhancement. 2) Time-varying Decay Uncertainty (TDU) mechanism: advancing beyond simple linear combinations, we develop a variance-derived Q-value aggregation strategy that explicitly incorporates epistemic uncertainty to dynamically regulate the exploration-exploitation trade-off while simultaneously stabilizing the training process. Comprehensive experiments across several MuJoCo control problems validate the superior effectiveness of UACER, outperforming state-of-the-art methods in terms of overall performance, stability, and efficiency.", "AI": {"tldr": "", "motivation": "", "method": "", "result": "", "conclusion": ""}}
{"id": "2512.10510", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10510", "abs": "https://arxiv.org/abs/2512.10510", "authors": ["Chihyeon Song", "Jaewoo Lee", "Jinkyoo Park"], "title": "Adaptive Replay Buffer for Offline-to-Online Reinforcement Learning", "comment": "15 pages, 3 figures, 7 tables", "summary": "Offline-to-Online Reinforcement Learning (O2O RL) faces a critical dilemma in balancing the use of a fixed offline dataset with newly collected online experiences. Standard methods, often relying on a fixed data-mixing ratio, struggle to manage the trade-off between early learning stability and asymptotic performance. To overcome this, we introduce the Adaptive Replay Buffer (ARB), a novel approach that dynamically prioritizes data sampling based on a lightweight metric we call 'on-policyness'. Unlike prior methods that rely on complex learning procedures or fixed ratios, ARB is designed to be learning-free and simple to implement, seamlessly integrating into existing O2O RL algorithms. It assesses how closely collected trajectories align with the current policy's behavior and assigns a proportional sampling weight to each transition within that trajectory. This strategy effectively leverages offline data for initial stability while progressively focusing learning on the most relevant, high-rewarding online experiences. Our extensive experiments on D4RL benchmarks demonstrate that ARB consistently mitigates early performance degradation and significantly improves the final performance of various O2O RL algorithms, highlighting the importance of an adaptive, behavior-aware replay buffer design.", "AI": {"tldr": "\u63d0\u51fa\u4e86 Adaptive Replay Buffer (ARB)\uff0c\u901a\u8fc7\u5bf9\u6bcf\u6761\u8f68\u8ff9\u5185\u7684\u8f6c\u79fb\u8d4b\u4e88\u57fa\u4e8e\u201con-policyness\u201d\u7684\u91c7\u6837\u6743\u91cd\uff0c\u5b9e\u73b0\u5bf9\u79bb\u7ebf\u6570\u636e\u7684\u81ea\u9002\u5e94\u5229\u7528\u3002ARB \u662f\u5b66\u4e60\u65e0\u5173\u3001\u5b9e\u73b0\u7b80\u5355\u7684\u7f13\u51b2\u533a\u8bbe\u8ba1\uff0c\u80fd\u591f\u65e0\u7f1d\u5d4c\u5165\u73b0\u6709\u7684 O2O RL \u7b97\u6cd5\u4e2d\uff0c\u4ee5\u63d0\u5347\u65e9\u671f\u7a33\u5b9a\u6027\u5e76\u6539\u5584\u6700\u7ec8\u6027\u80fd\u3002", "motivation": "\u79bb\u7ebf\u6570\u636e\u96c6\u56fa\u5b9a\u4e0e\u5728\u7ebf\u65b0\u7ecf\u9a8c\u4e4b\u95f4\u7684\u6743\u8861\u662f O2O RL \u7684\u6838\u5fc3\u6311\u6218\u3002\u56fa\u5b9a\u7684\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\u5728\u65e9\u671f\u5b66\u4e60\u7a33\u5b9a\u6027\u4e0e\u6e10\u8fd1\u6027\u80fd\u4e4b\u95f4\u96be\u4ee5\u517c\u987e\uff1b\u9700\u8981\u4e00\u79cd\u65e0\u9700\u590d\u6742\u5b66\u4e60\u8fc7\u7a0b\u3001\u53ef\u5b66\u4e60\u6027\u4f4e\u4e14\u80fd\u81ea\u9002\u5e94\u8c03\u6574\u6570\u636e\u5229\u7528\u7684\u7b56\u7565\u3002", "method": "ARB \u901a\u8fc7\u4e00\u4e2a\u8f7b\u91cf\u5ea6\u91cf\u201con-policyness\u201d\u6765\u8bc4\u4f30 collected trajectories \u4e0e\u5f53\u524d\u7b56\u7565\u884c\u4e3a\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u636e\u6b64\u4e3a\u8f68\u8ff9\u4e2d\u6bcf\u4e2a\u8f6c\u79fb\u5206\u914d\u6bd4\u4f8b\u91c7\u6837\u6743\u91cd\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9 offline \u548c online \u6570\u636e\u7684\u81ea\u9002\u5e94\u5229\u7528\u3002\u8be5\u65b9\u6cd5\u4e3a\u5b66\u4e60\u65e0\u5173\u3001\u6613\u4e8e\u5b9e\u73b0\u7684\u7f13\u51b2\u533a\u8bbe\u8ba1\uff0c\u80fd\u591f\u65e0\u7f1d\u878d\u5165\u73b0\u6709\u7684 O2O RL \u7b97\u6cd5\u3002", "result": "\u5728 D4RL \u57fa\u51c6\u5b9e\u9a8c\u4e2d\uff0cARB \u7a33\u5b9a\u7f13\u89e3\u4e86\u65e9\u671f\u6027\u80fd\u4e0b\u964d\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u591a\u79cd O2O RL \u7b97\u6cd5\u7684\u6700\u7ec8\u6027\u80fd\uff0c\u8868\u660e\u81ea\u9002\u5e94\u3001\u57fa\u4e8e\u884c\u4e3a\u7684\u56de\u653e\u7f13\u51b2\u8bbe\u8ba1\u5177\u6709\u91cd\u8981\u610f\u4e49\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u4ee5\u884c\u4e3a\u4e3a\u5bfc\u5411\u7684\u81ea\u9002\u5e94\u56de\u653e\u7f13\u51b2\u5728 O2O RL \u4e2d\u7684\u4f5c\u7528\uff0cARB \u7684\u5b66\u4e60\u65e0\u5173\u7279\u6027\u4f7f\u5176\u6613\u4e8e\u666e\u904d\u91c7\u7528\uff0c\u5177\u5907\u63d0\u5347\u65e9\u671f\u7a33\u5b9a\u6027\u4e0e\u6700\u7ec8\u8868\u73b0\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.10522", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10522", "abs": "https://arxiv.org/abs/2512.10522", "authors": ["Zahra Rahiminasab", "Michael Yuhas", "Arvind Easwaran"], "title": "Disentangled and Distilled Encoder for Out-of-Distribution Reasoning with Rademacher Guarantees", "comment": null, "summary": "Recently, the disentangled latent space of a variational autoencoder (VAE) has been used to reason about multi-label out-of-distribution (OOD) test samples that are derived from different distributions than training samples. Disentangled latent space means having one-to-many maps between latent dimensions and generative factors or important characteristics of an image. This paper proposes a disentangled distilled encoder (DDE) framework to decrease the OOD reasoner size for deployment on resource-constrained devices while preserving disentanglement. DDE formalizes student-teacher distillation for model compression as a constrained optimization problem while preserving disentanglement with disentanglement constraints. Theoretical guarantees for disentanglement during distillation based on Rademacher complexity are established. The approach is evaluated empirically by deploying the compressed model on an NVIDIA", "AI": {"tldr": "\u63d0\u51fa disentangled distilled encoder (DDE) \u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u751f-\u6559\u5e08\u84b8\u998f\u5728\u538b\u7f29\u6a21\u578b\u7684\u540c\u65f6\u4fdd\u6301\u6f5c\u5728\u7a7a\u95f4\u7684\u89e3\u8026\u6027\uff0c\u5e76\u7ed9\u51fa\u57fa\u4e8e Rademacher \u590d\u6742\u5ea6\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u591a\u6807\u7b7e OOD \u63a8\u7406\u3002", "motivation": "\u89e3\u51b3\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u5bf9\u89e3\u8026\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u84b8\u998f\u4ee5\u4fdd\u6301\u591a\u6807\u7b7e OOD \u63a8\u7406\u80fd\u529b\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u6f5c\u5728\u56e0\u5b50\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5c06\u84b8\u998f\u95ee\u9898\u5efa\u6a21\u4e3a\u5e26\u89e3\u8026\u7ea6\u675f\u7684\u53d7\u9650\u4f18\u5316\uff1b\u7ed3\u5408\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u7684\u6f5c\u5728\u7a7a\u95f4\u548c\u89e3\u8026\u56e0\u5b50\uff1b\u5f15\u5165\u89e3\u8026\u6027\u7ea6\u675f\uff1b\u7ed9\u51fa\u57fa\u4e8e Rademacher \u590d\u6742\u5ea6\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u7406\u8bba\u4e0a\u63d0\u4f9b\u5bf9\u89e3\u8026\u6027\u7684\u4fdd\u6301\u4fdd\u8bc1\uff1b\u5728\u5b9e\u9645\u90e8\u7f72\uff08\u5982\u5728 NVIDIA \u7aef\uff09\u5bf9\u538b\u7f29\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u538b\u7f29\u540e\u7684 DDE \u80fd\u7ef4\u6301\u89e3\u8026\u6027\u5e76\u4fdd\u6301\u5bf9\u591a\u6807\u7b7e OOD \u63a8\u7406\u7684\u80fd\u529b\u3002", "conclusion": "DDE \u4e3a\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u591a\u6807\u7b7e OOD \u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u5408\u84b8\u998f\u4e0e\u89e3\u8026\u7ea6\u675f\u7684\u6709\u6548\u6846\u67b6\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u84b8\u998f\u5728\u4fdd\u6301\u89e3\u8026\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2512.10524", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.10524", "abs": "https://arxiv.org/abs/2512.10524", "authors": ["Sai Bharath Chandra Gutha", "Ricardo Vinuesa", "Hossein Azizpour"], "title": "Mode-Seeking for Inverse Problems with Diffusion Models", "comment": null, "summary": "A pre-trained unconditional diffusion model, combined with posterior sampling or maximum a posteriori (MAP) estimation techniques, can solve arbitrary inverse problems without task-specific training or fine-tuning. However, existing posterior sampling and MAP estimation methods often rely on modeling approximations and can be computationally demanding. In this work, we propose the variational mode-seeking loss (VML), which, when minimized during each reverse diffusion step, guides the generated sample towards the MAP estimate. VML arises from a novel perspective of minimizing the Kullback-Leibler (KL) divergence between the diffusion posterior $p(\\mathbf{x}_0|\\mathbf{x}_t)$ and the measurement posterior $p(\\mathbf{x}_0|\\mathbf{y})$, where $\\mathbf{y}$ denotes the measurement. Importantly, for linear inverse problems, VML can be analytically derived and need not be approximated. Based on further theoretical insights, we propose VML-MAP, an empirically effective algorithm for solving inverse problems, and validate its efficacy over existing methods in both performance and computational time, through extensive experiments on diverse image-restoration tasks across multiple datasets.", "AI": {"tldr": "\u5f15\u5165\u53d8\u5206\u6a21\u5f0f\u641c\u7d22\u635f\u5931\uff08VML\uff09\uff0c\u5728\u6bcf\u4e2a\u53bb\u6269\u6563\u6b65\u9aa4\u4e2d\u5f15\u5bfc\u91c7\u6837\u5411\u6700\u5927\u540e\u9a8c\u4f30\u8ba1\uff08MAP\uff09\u6536\u655b\u3002\u5bf9\u7ebf\u6027\u9006\u95ee\u9898\uff0cVML\u53ef\u89e3\u6790\u63a8\u5bfc\uff1b\u57fa\u4e8eVML\uff0c\u63d0\u51faVML-MAP\u7b97\u6cd5\uff0c\u5728\u591a\u6570\u636e\u96c6\u7684\u56fe\u50cf\u91cd\u5efa\u4efb\u52a1\u4e2d\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u65f6\u95f4\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u9006\u95ee\u9898\u65b9\u6cd5\u5728\u540e\u9a8c\u91c7\u6837\u4e0eMAP\u4f30\u8ba1\u4e2d\u5bf9\u5efa\u6a21\u8fd1\u4f3c\u7684\u4f9d\u8d56\u4ee5\u53ca\u9ad8\u8ba1\u7b97\u6210\u672c\uff0c\u5bfb\u6c42\u4e00\u4e2a\u7406\u8bba\u4e0a\u66f4\u7a33\u5065\u4e14\u9ad8\u6548\u7684\u4f18\u5316\u6846\u67b6\u3002", "method": "\u4ece\u6269\u6563\u540e\u9a8cp(x0|xt)\u4e0e\u6d4b\u91cf\u540e\u9a8cp(x0|y)\u4e4b\u95f4\u7684KL\u6563\u5ea6\u51fa\u53d1\uff0c\u63a8\u5bfc\u51faVML\u5e76\u5728\u6bcf\u4e00\u6b65\u7684\u9006\u6269\u6563\u4e2d\u6700\u5c0f\u5316\uff0c\u6307\u5f15\u6837\u672c\u671d\u5411MAP\u3002\u5bf9\u4e8e\u7ebf\u6027\u9006\u95ee\u9898\uff0cVML\u53ef\u89e3\u6790\u63a8\u5bfc\uff0c\u65e0\u9700\u8fd1\u4f3c\u3002\u8fdb\u4e00\u6b65\u63d0\u51faVMMAP\u7b97\u6cd5\uff0c\u5c06VML\u5e94\u7528\u4e8e\u5b9e\u9645\u9006\u95ee\u9898\u6c42\u89e3\u5e76\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u56fe\u50cf\u53bb\u566a/\u4fee\u590d\u7b49\u9006\u95ee\u9898\u7684\u5b9e\u9a8c\uff0cVML-VMAP\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u65f6\u95f4\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u540e\u9a8c\u91c7\u6837/MAP\u65b9\u6cd5\uff0c\u5177\u6709\u8f83\u5f3a\u7684\u666e\u9002\u6027\u4e0e\u5b9e\u7528\u6027\u3002", "conclusion": "VML\u4e3a\u5229\u7528\u65e0\u6761\u4ef6\u6269\u6563\u6a21\u578b\u89e3\u51b3\u9006\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u7406\u8bba\u652f\u6491\u4e14\u9ad8\u6548\u7684\u6846\u67b6\uff0cVML-MAP\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u5c55\u73b0\u51fa\u826f\u597d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2512.10547", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10547", "abs": "https://arxiv.org/abs/2512.10547", "authors": ["Qingsen Ma", "Dianyun Wang", "Jiaming Lyu", "Yaoye Wang", "Lechen Ning", "Sujie Zhu", "Zhenbo Xu", "Liuyu Xiang", "Huining Li", "Huijia Wu", "Zhaofeng He"], "title": "Unlocking the Address Book: Dissecting the Sparse Semantic Structure of LLM Key-Value Caches via Sparse Autoencoders", "comment": null, "summary": "The Key-Value (KV) cache is the primary memory bottleneck in long-context Large Language Models, yet it is typically treated as an opaque numerical tensor. In this work, we propose \\textbf{STA-Attention}, a framework that utilizes Top-K Sparse Autoencoders (SAEs) to decompose the KV cache into interpretable ``semantic atoms.'' Unlike standard $L_1$-regularized SAEs, our Top-K approach eliminates shrinkage bias, preserving the precise dot-product geometry required for attention. Our analysis uncovers a fundamental \\textbf{Key-Value Asymmetry}: while Key vectors serve as highly sparse routers dominated by a ``Semantic Elbow,'' deep Value vectors carry dense content payloads requiring a larger budget. Based on this structure, we introduce a Dual-Budget Strategy that selectively preserves the most informative semantic components while filtering representational noise. Experiments on Yi-6B, Mistral-7B, Qwen2.5-32B, and others show that our semantic reconstructions maintain perplexity and zero-shot performance comparable to the original models, effectively bridging the gap between mechanistic interpretability and faithful attention modeling.", "AI": {"tldr": "\u63d0\u51fa STA-Attention \u6846\u67b6\uff0c\u5229\u7528 Top-K \u7a00\u758f\u81ea\u7f16\u7801\u5668\u5c06 KV \u7f13\u5b58\u5206\u89e3\u4e3a\u53ef\u89e3\u91ca\u7684\u201c\u8bed\u4e49\u539f\u5b50\u201d\uff0c\u63ed\u793a Key-Value \u7684\u4e0d\u5bf9\u79f0\u6027\uff0c\u5e76\u63d0\u51fa Dual-Budget \u7b56\u7565\uff0c\u5728\u591a\u79cd\u5927\u6a21\u578b\u4e0a\u5b9e\u73b0\u5bf9\u539f\u6a21\u578b\u56f0\u60d1\u5ea6\u548c\u96f6-shot \u8868\u73b0\u7684\u8fd1\u4f3c\u4fdd\u6301\uff0c\u540c\u65f6\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u4e0e\u6ce8\u610f\u529b\u5efa\u6a21\u7684\u7cbe\u5ea6\u3002", "motivation": "KV \u7f13\u5b58\u662f\u957f\u4e0a\u4e0b\u6587\u5927\u6a21\u578b\u7684\u4e3b\u8981\u5185\u5b58\u74f6\u9888\uff0c\u4f46\u901a\u5e38\u88ab\u89c6\u4e3a\u4e00\u4e2a\u4e0d\u900f\u660e\u7684\u6570\u503c\u5f20\u91cf\uff0c\u9700\u8981\u673a\u5236\u7406\u89e3\u548c\u6548\u7387\u63d0\u5347\u3002", "method": "\u91c7\u7528 Top-K \u7a00\u758f\u81ea\u7f16\u7801\u5668\u6765\u89e3\u8026 KV \u7f13\u5b58\uff0c\u907f\u514d L1 \u6b63\u5219\u5316\u5e26\u6765\u7684\u6536\u7f29\u504f\u5dee\uff0c\u62bd\u53d6\u53ef\u89e3\u91ca\u7684\u8bed\u4e49\u539f\u5b50\uff1b\u5206\u6790 Key \u4e0e Value \u5411\u91cf\u7684\u4e0d\u540c\u5206\u5e03\uff0c\u53d1\u73b0 Key \u5411\u91cf\u66f4\u7a00\u758f\u4e14\u7531\u201c\u8bed\u4e49\u8098\u90e8\u201d\u652f\u914d\uff0cValue \u5411\u91cf\u5bc6\u96c6\u4e14\u627f\u8f7d\u5185\u5bb9\uff1b\u63d0\u51fa Dual-Budget \u7b56\u7565\uff0c\u9009\u62e9\u6027\u4fdd\u7559\u6700\u5177\u4fe1\u606f\u91cf\u7684\u8bed\u4e49\u6210\u5206\uff0c\u6ee4\u9664\u566a\u58f0\uff0c\u907f\u514d\u7834\u574f\u70b9\u79ef\u51e0\u4f55\u5173\u7cfb\u3002", "result": "\u5728 Yi-6B\u3001Mistral-7B\u3001Qwen2.5-32B \u7b49\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8bed\u4e49\u91cd\u6784\u80fd\u7ef4\u6301\u4e0e\u539f\u6a21\u578b\u76f8\u8fd1\u7684 perplexity \u548c\u96f6-shot \u80fd\u529b\uff0c\u8fbe\u5230\u53ef\u89e3\u91ca\u6027\u548c\u6ce8\u610f\u529b\u5efa\u6a21\u4e4b\u95f4\u7684\u6865\u63a5\u3002", "conclusion": "STA-Attention \u4e3a\u5c06\u53ef\u89e3\u91ca\u6027\u4e0e\u51c6\u786e\u7684\u6ce8\u610f\u529b\u5efa\u6a21\u7ed3\u5408\u8d77\u6765\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u8def\u5f84\uff0cKey-Value \u4e0d\u5bf9\u79f0\u6027\u4e0e Dual-Budget \u7b56\u7565\u662f\u5176\u6838\u5fc3\u53d1\u73b0\uff0c\u5177\u6709\u6f5c\u5728\u51cf\u7f13\u5185\u5b58\u538b\u529b\u4e0e\u63d0\u5347\u6a21\u578b\u7406\u89e3\u6027\u7684\u610f\u4e49\u3002"}}
{"id": "2512.10573", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10573", "abs": "https://arxiv.org/abs/2512.10573", "authors": ["Yi Huang", "Qingyun Sun", "Yisen Gao", "Haonan Yuan", "Xingcheng Fu", "Jianxin Li"], "title": "Is the Information Bottleneck Robust Enough? Towards Label-Noise Resistant Information Bottleneck Learning", "comment": "Accepted by the Main Technical Track of the 40th Annual AAAI Conference on Artificial Intelligence (AAAI-2026)", "summary": "The Information Bottleneck (IB) principle facilitates effective representation learning by preserving label-relevant information while compressing irrelevant information. However, its strong reliance on accurate labels makes it inherently vulnerable to label noise, prevalent in real-world scenarios, resulting in significant performance degradation and overfitting. To address this issue, we propose LaT-IB, a novel Label-Noise ResistanT Information Bottleneck method which introduces a \"Minimal-Sufficient-Clean\" (MSC) criterion. Instantiated as a mutual information regularizer to retain task-relevant information while discarding noise, MSC addresses standard IB's vulnerability to noisy label supervision. To achieve this, LaT-IB employs a noise-aware latent disentanglement that decomposes the latent representation into components aligned with to the clean label space and the noise space. Theoretically, we first derive mutual information bounds for each component of our objective including prediction, compression, and disentanglement, and moreover prove that optimizing it encourages representations invariant to input noise and separates clean and noisy label information. Furthermore, we design a three-phase training framework: Warmup, Knowledge Injection and Robust Training, to progressively guide the model toward noise-resistant representations. Extensive experiments demonstrate that LaT-IB achieves superior robustness and efficiency under label noise, significantly enhancing robustness and applicability in real-world scenarios with label noise.", "AI": {"tldr": "\u63d0\u51fa LaT-IB\uff1a\u4e00\u4e2a\u5bf9\u6807\u7b7e\u566a\u58f0\u9c81\u68d2\u7684 Information Bottleneck \u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5145\u5206\u6e05\u6d01 MSC \u7ea6\u675f\u5b9e\u73b0\u5bf9\u6e05\u6d01\u6807\u7b7e\u7684\u4fe1\u606f\u4fdd\u7559\u4e0e\u566a\u58f0\u4fe1\u606f\u6291\u5236\uff0c\u5e76\u901a\u8fc7\u566a\u58f0\u611f\u77e5\u7684\u6f5c\u5728\u89e3\u8026\u548c\u4e09\u9636\u6bb5\u8bad\u7ec3\u63d0\u5347\u9c81\u68d2\u6027\u3002", "motivation": "IB \u4f9d\u8d56\u51c6\u786e\u6807\u7b7e\uff0c\u6613\u53d7\u6807\u7b7e\u566a\u58f0\u5f71\u54cd\u800c\u4ea7\u751f\u8fc7\u62df\u5408\u548c\u6027\u80fd\u4e0b\u964d\u3002\u73b0\u5b9e\u573a\u666f\u5b58\u5728\u6807\u7b7e\u566a\u58f0\uff0c\u9700\u8981\u5728\u4fdd\u7559\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u4e0e\u6291\u5236\u566a\u58f0\u4e4b\u95f4\u5efa\u7acb\u9c81\u68d2\u673a\u5236\u3002", "method": "\u5f15\u5165 MSC \u4f5c\u4e3a\u4e92\u4fe1\u606f\u6b63\u5219\uff0c\u5206\u89e3\u6f5c\u5728\u8868\u793a\u4e3a\u6e05\u6d01\u6807\u7b7e\u7a7a\u95f4\u4e0e\u566a\u58f0\u7a7a\u95f4\uff0c\u63a8\u5bfc\u9884\u6d4b\u3001\u538b\u7f29\u3001\u89e3\u8026\u4e09\u8005\u7684\u4e92\u4fe1\u606f\u754c\u9650\uff1b\u63d0\u51fa\u566a\u58f0\u611f\u77e5\u7684\u6f5c\u5728\u89e3\u8026\u7b56\u7565\uff1b\u8bbe\u8ba1\u4e09\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1aWarmup\u3001Knowledge Injection\u3001Robust Training\u3002", "result": "\u7406\u8bba\u4e0a\u7ed9\u51fa\u5404\u7ec4\u6210\u90e8\u5206\u7684\u4e92\u4fe1\u606f\u754c\u9650\uff0c\u8bc1\u660e\u4f18\u5316\u53ef\u83b7\u5f97\u5bf9\u8f93\u5165\u566a\u58f0\u4e0d\u53d8\u6027\u53ca\u6e05\u6d01/\u566a\u58f0\u6807\u7b7e\u4fe1\u606f\u7684\u5206\u79bb\uff1b\u5728\u591a\u6570\u636e\u96c6/\u8bbe\u7f6e\u4e0b\u5c55\u73b0\u5bf9\u6807\u7b7e\u566a\u58f0\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\u63d0\u5347\u3002", "conclusion": "MSC \u7ea6\u675f\u4e0e\u4e09\u9636\u6bb5\u8bad\u7ec3\u5171\u540c\u63d0\u5347\u5bf9\u6807\u7b7e\u566a\u58f0\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u4f9b\u4e00\u79cd\u53ef\u6cdb\u5316\u7684\u566a\u58f0\u9c81\u68d2\u4fe1\u606f\u74f6\u9888\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u5e26\u566a\u6807\u7b7e\u5b66\u4e60\u3002"}}
{"id": "2512.10601", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10601", "abs": "https://arxiv.org/abs/2512.10601", "authors": ["Akhil Agnihotri"], "title": "Multi-Objective Reward and Preference Optimization: Theory and Algorithms", "comment": "PhD thesis", "summary": "This thesis develops theoretical frameworks and algorithms that advance constrained reinforcement learning (RL) across control, preference learning, and alignment of large language models. The first contribution addresses constrained Markov Decision Processes (CMDPs) under the average-cost criterion through the Average-Constrained Policy Optimization (ACPO) algorithm. ACPO integrates sensitivity analysis with trust-region updates to ensure stable constraint handling, achieving state-of-the-art empirical performance with theoretical guarantees. Constrained RL is then extended to finite-horizon settings via e-COP, the first policy optimization method for episodic CMDPs. Built on an episodic policy difference lemma, e-COP offers provable performance, simplicity, and scalability in safety-critical environments. The thesis then investigates reinforcement learning from human preferences. warmPref-PS introduces a posterior sampling strategy for linear bandits that integrates offline preference data from heterogeneous raters into online learning. Explicit modeling of rater competence yields substantial regret reduction and more efficient data collection for RLHF. The PSPL algorithm further advances preference-based RL by jointly sampling reward models and transition dynamics from pairwise trajectory comparisons, providing Bayesian simple-regret guarantees and robust empirical identification of optimal policies. The final contribution applies these methods to large-scale model alignment. A multi-objective constrained optimization view yields MOPO, an iterative algorithm with closed-form updates that scales to multi-billion-parameter language models and remains robust across alignment settings. Collectively, the thesis unifies constrained RL across average-cost, episodic, and preference-driven paradigms, delivering theoretical advances and practical tools for safe and aligned decision-making.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e00\u7ec4\u8de8\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4e0e\u504f\u597d\u5b66\u4e60\u7b97\u6cd5\uff08ACPO\u3001e-COP\u3001warmPref-PS\u3001PSPL\u3001MOPO\uff09\uff0c\u8986\u76d6\u5e73\u5747\u6210\u672c\u3001\u6709\u9650\u65f6\u57df\u4e0e\u504f\u597d\u9a71\u52a8\u573a\u666f\uff0c\u4e26\u5c06\u5176\u5e94\u7528\u4e8e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\uff0c\u5177\u5907\u7406\u8bba\u4fdd\u8bc1\u4e0e\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5728\u63a7\u5236\u3001\u504f\u597d\u6574\u5408\u548c\u6a21\u578b\u5bf9\u9f50\u7b49\u9886\u57df\uff0c\u5b58\u5728\u5bf9\u7ea6\u675f\u9075\u5faa\u3001\u6570\u636e\u5f02\u8d28\u6027\u504f\u597d\u548c\u5927\u6a21\u578b\u53ef\u6269\u5c55\u6027\u7684\u6311\u6218\uff1b\u9700\u8981\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u4e0e\u5b9e\u7528\u7b97\u6cd5\u4ee5\u786e\u4fdd\u5b89\u5168\u3001\u7a33\u5065\u548c\u9ad8\u6548\u5b66\u4e60\u3002", "method": "- ACPO\uff1a\u5728\u5e73\u5747\u6210\u672c CMDP \u4e2d\u7ed3\u5408\u654f\u611f\u6027\u5206\u6790\u4e0e\u4fe1\u4efb\u57df\u66f4\u65b0\uff0c\u5b9e\u73b0\u7a33\u5065\u7ea6\u675f\u5904\u7406\u5e76\u5177\u5907\u7406\u8bba\u4fdd\u8bc1\u3002 \n- e-COP\uff1a\u57fa\u4e8e episodic policy difference lemma \u7684\u7b56\u7565\u4f18\u5316\uff0c\u9002\u7528\u4e8e episodic CMDP\uff0c\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6027\u80fd\u3001\u6613\u5b9e\u73b0\u3001\u53ef\u6269\u5c55\u3002 \n- warmPref-PS\uff1a\u5f15\u5165\u540e\u9a8c\u91c7\u6837\u7b56\u7565\uff0c\u6574\u5408\u6765\u81ea\u5f02\u8d28\u8bc4\u8005\u7684\u79bb\u7ebf\u504f\u597d\u6570\u636e\u3001\u5bf9\u8bc4\u8005\u80fd\u529b\u5efa\u6a21\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4e\u540e\u9a8c- regrets \u5e76\u63d0\u5347\u6570\u636e\u6536\u96c6\u6548\u7387\u3002 \n- PSPL\uff1a\u901a\u8fc7\u4ece\u5bf9\u6bd4\u8f68\u8ff9\u4e2d\u8054\u5408\u91c7\u6837\u5956\u52b1\u6a21\u578b\u4e0e\u8f6c\u79fb\u52a8\u529b\u5b66\uff0c\u7ed9\u51fa\u8d1d\u53f6\u65af\u7b80\u5355\u540e\u6094\u754c\u9650\uff0c\u9c81\u68d2\u8bc6\u522b\u6700\u4f18\u7b56\u7565\u3002 \n- MOPO\uff1a\u5728\u591a\u76ee\u6807\u7ea6\u675f\u4f18\u5316\u89c6\u89d2\u4e0b\u7684\u8fed\u4ee3\u7b97\u6cd5\uff0c\u5177\u6709\u95ed\u5f0f\u66f4\u65b0\uff0c\u80fd\u6269\u5c55\u5230\u4ebf\u7ea7\u53c2\u6570\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u9c81\u68d2\u6027\u5f3a\u3002", "result": "\u5728\u7406\u8bba\u4e0a\u63d0\u4f9b\u6536\u655b\u6027\u3001\u7a33\u5065\u6027\u7b49 guarantees\uff0c\u5b9e\u9a8c\u4e0a\u8fbe\u5230 state-of-the-art\uff0c\u8986\u76d6\u4ece\u5e73\u5747\u6210\u672c\u5230 episodic \u4e0e\u504f\u597d\u9a71\u52a8\u573a\u666f\uff0c\u4e14\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u81f3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff1b\u5e76\u5bf9\u5b89\u5168\u6027\u548c\u5bf9\u9f50\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u7ea6\u675f RL \u7684\u5e73\u5747\u6210\u672c\u3001 episodic\u3001\u504f\u597d\u9a71\u52a8\u4e09\u4e2a\u8303\u5f0f\uff0c\u8bba\u6587\u4e3a\u5b89\u5168\u4e0e\u5bf9\u9f50\u7684\u51b3\u7b56\u63d0\u4f9b\u7406\u8bba\u4e0e\u5de5\u5177\u7684\u7efc\u5408\u6846\u67b6\u3002"}}
{"id": "2512.10633", "categories": ["cs.LG", "cs.SI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.10633", "abs": "https://arxiv.org/abs/2512.10633", "authors": ["C. Bosco", "U. Minora", "D. de Rigo", "J. Pingsdorf", "R. Cortinovis"], "title": "Supporting Migration Policies with Forecasts: Illegal Border Crossings in Europe through a Mixed Approach", "comment": "17 pages, 6 figures, 2 tables + supplementary material with 20 pages, 21 figures, 2 tables", "summary": "This paper presents a mixed-methodology to forecast illegal border crossings in Europe across five key migratory routes, with a one-year time horizon. The methodology integrates machine learning techniques with qualitative insights from migration experts. This approach aims at improving the predictive capacity of data-driven models through the inclusion of a human-assessed covariate, an innovation that addresses challenges posed by sudden shifts in migration patterns and limitations in traditional datasets. The proposed methodology responds directly to the forecasting needs outlined in the EU Pact on Migration and Asylum, supporting the Asylum and Migration Management Regulation (AMMR). It is designed to provide policy-relevant forecasts that inform strategic decisions, early warning systems, and solidarity mechanisms among EU Member States. By joining data-driven modeling with expert judgment, this work aligns with existing academic recommendations and introduces a novel operational tool tailored for EU migration governance. The methodology is tested and validated with known data to demonstrate its applicability and reliability in migration-related policy context.", "AI": {"tldr": "\u6df7\u5408\u65b9\u6cd5\u8bba\uff1a\u5c06\u673a\u5668\u5b66\u4e60\u4e0e\u4e13\u5bb6\u5b9a\u6027\u5224\u65ad\u76f8\u7ed3\u5408\uff0c\u9488\u5bf9\u6b27\u6d32\u4e94\u6761\u4e3b\u8981\u8fc1\u5f99\u8def\u7ebf\uff0c\u9884\u6d4b\u4e00\u5e74\u5185\u975e\u6cd5\u8d8a\u5883\uff0c\u610f\u5728\u63d0\u5347\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u5e94\u5bf9\u8fc1\u5f99\u6a21\u5f0f\u7684\u7a81\u7136\u53d8\u5316\u548c\u4f20\u7edf\u6570\u636e\u96c6\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u5bf9EU\u300a\u79fb\u6c11\u4e0e\u5e87\u62a4\u6846\u67b6\u534f\u5b9a\u300b\u7b49\u653f\u7b56\u7684\u524d\u77bb\u6027\u3001\u653f\u7b56\u76f8\u5173\u7684\u9884\u6d4b\uff0c\u4ee5\u652f\u6301\u65e9\u671f\u9884\u8b66\u548c\u6210\u5458\u56fd\u56e2\u7ed3\u3002", "method": "\u5c06\u673a\u5668\u5b66\u4e60\u4e0e\u8fc1\u79fb\u4e13\u5bb6\u7684\u5b9a\u6027\u89c1\u89e3\u4f5c\u4e3a\u534f\u53d8\u91cf\u6574\u5408\u8fdb\u6a21\u578b\uff1b\u8986\u76d6\u4e94\u6761\u8def\u7ebf\uff0c\u65f6\u95f4\u89c6\u7a97\u4e3a\u4e00\u5e74\uff1b\u5e76\u5bf9\u5df2\u77e5\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u4e0e\u5df2\u77e5\u6570\u636e\u7684\u8026\u5408\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u65b9\u6cd5\u5728\u8fc1\u5f99\u6cbb\u7406\u80cc\u666f\u4e0b\u7684\u9002\u7528\u6027\u548c\u53ef\u9760\u6027\uff0c\u4f46\u672a\u5728\u6458\u8981\u4e2d\u7ed9\u51fa\u5177\u4f53\u6307\u6807\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0e\u73b0\u6709\u5b66\u672f\u5efa\u8bae\u4fdd\u6301\u4e00\u81f4\uff0c\u63d0\u4f9b\u4e00\u4e2a\u9762\u5411EU\u8fc1\u5f99\u6cbb\u7406\u7684\u521b\u65b0\u6027\u64cd\u4f5c\u5de5\u5177\uff0c\u80fd\u591f\u63d0\u5347\u653f\u7b56\u76f8\u5173\u7684\u9884\u6d4b\u4e0e\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2512.10656", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10656", "abs": "https://arxiv.org/abs/2512.10656", "authors": ["L\u00e9a Bohbot", "Cyril Letrouit", "Gabriel Peyr\u00e9", "Fran\u00e7ois-Xavier Vialard"], "title": "Token Sample Complexity of Attention", "comment": null, "summary": "As context windows in large language models continue to expand, it is essential to characterize how attention behaves at extreme sequence lengths. We introduce token-sample complexity: the rate at which attention computed on $n$ tokens converges to its infinite-token limit. We estimate finite-$n$ convergence bounds at two levels: pointwise uniform convergence of the attention map, and convergence of moments for the transformed token distribution. For compactly supported (and more generally sub-Gaussian) distributions, our first result shows that the attention map converges uniformly on a ball of radius $R$ at rate $C(R)/\\sqrt{n}$, where $C(R)$ grows exponentially with $R$. For large $R$, this estimate loses practical value, and our second result addresses this issue by establishing convergence rates for the moments of the transformed distribution (the token output of the attention layer). In this case, the rate is $C'(R)/n^\u03b2$ with $\u03b2<\\tfrac{1}{2}$, and $C'(R)$ depends polynomially on the size of the support of the distribution. The exponent $\u03b2$ depends on the attention geometry and the spectral properties of the tokens distribution. We also examine the regime in which the attention parameter tends to infinity and the softmax approaches a hardmax, and in this setting, we establish a logarithmic rate of convergence. Experiments on synthetic Gaussian data and real BERT models on Wikipedia text confirm our predictions.", "AI": {"tldr": "\u7814\u7a76\u5728\u6781\u957f\u7684\u4e0a\u4e0b\u6587\u4e0b\u5206\u6790\u6ce8\u610f\u529b\u7684\u6536\u655b\u6027\uff0c\u63d0\u51fa\u4e24\u7ea7\u6536\u655b\u754c\uff1a\u5bf9\u6ce8\u610f\u529b\u6620\u5c04\u7684\u70b9\u6001\u7edf\u4e00\u6536\u655b\u5728\u534a\u5f84R\u7684\u7403\u5185\u4ee5\u901f\u7387C(R)/sqrt(n)\u6536\u655b\uff08C(R)\u968fR\u6307\u6570\u589e\u957f\uff09\uff0c\u4ee5\u53ca\u5bf9\u53d8\u6362\u540e\u5206\u5e03\u7684\u77e9\u7684\u6536\u655b\u4ee5\u901f\u7387C'(R)/n^\u03b2\u6536\u655b\uff0c\u03b2<1/2\u4e14C'(R)\u4e0e\u652f\u6491\u89c4\u6a21\u591a\u9879\u5f0f\u76f8\u5173\uff1b\u5728softmax\u8d8b\u8fd1hardmax\u7684\u6781\u9650\u4e0b\u7ed9\u51fa\u5bf9\u6570\u6536\u655b\uff1b\u5e76\u901a\u8fc7\u9ad8\u65af\u6570\u636e\u548cBERT\u5728\u7ef4\u57fa\u767e\u79d1\u6587\u672c\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u968f\u7740\u4e0a\u4e0b\u6587\u7a97\u53e3\u7684\u6269\u5c55\uff0c\u9700\u8981\u5b9a\u91cf\u4e86\u89e3\u6ce8\u610f\u529b\u5728\u6781\u957f\u5e8f\u5217\u4e0a\u7684\u884c\u4e3a\uff0c\u7ed9\u51fa\u7406\u8bba\u6536\u655b\u754c\u5e76\u9a8c\u8bc1\u662f\u5426\u968f\u5e8f\u5217\u957f\u5ea6\u8d8b\u4e8e\u65e0\u9650\u800c\u6536\u655b\u3002", "method": "\u5bf9\u6ce8\u610f\u529b\u6620\u5c04\u5728\u4e24\u5c42\u7ea7\u8fdb\u884c\u6536\u655b\u5206\u6790\uff1a1) \u5728\u7d27\u652f\u6491\uff08\u6216\u5b50\u9ad8\u65af\uff09\u5206\u5e03\u4e0b\uff0c\u70b9\u6001\u7edf\u4e00\u6536\u655b\u5728\u534a\u5f84R\u7403\u5185\uff0c\u901f\u7387\u4e3aC(R)/sqrt(n)\uff0c\u5176\u4e2dC(R)\u968fR\u6307\u6570\u589e\u957f\uff1b2) \u8f6c\u6362\u540e\u7684\u5206\u5e03\u77e9\u7684\u6536\u655b\uff0c\u901f\u7387\u4e3aC'(R)/n^\u03b2\uff0c\u03b2<1/2\uff0cC'(R)\u4e0e\u5206\u5e03\u652f\u6491\u5927\u5c0f\u7684\u591a\u9879\u5f0f\u5173\u7cfb\uff0c\u03b2\u7531\u6ce8\u610f\u529b\u51e0\u4f55\u548c\u5206\u5e03\u7684\u8c31\u6027\u8d28\u51b3\u5b9a\uff1b\u53e6\u5916\u8003\u5bdfsoftmax\u8d8b\u5411hardmax\u7684\u6781\u9650\uff0c\u7ed9\u51fa\u5bf9\u6570\u6536\u655b\uff1b\u5e76\u7ed9\u51fa\u5bf9\u5408\u6210\u9ad8\u65af\u6570\u636e\u4e0eBERT\u5728\u7ef4\u57fa\u6587\u672c\u4e0a\u7684\u5b9e\u9a8c\u3002", "result": "\u7ed3\u8bba\u5305\u62ec\uff1a\u5728\u7d27\u652f\u6491\u6216\u5b50\u9ad8\u65af\u5206\u5e03\u4e0b\uff0c\u6ce8\u610f\u529b\u56fe\u5bf9n\u7684\u6536\u655b\u901f\u7387\u4e3a2\u76841/2\u6b21\u65b9\uff0c\u4e14\u968fR\u589e\u5927\u6536\u655b\u754c\u6076\u5316\uff1b\u5173\u4e8e\u77e9\u7684\u6536\u655b\uff0c\u7ed9\u51fan^\u03b2\uff08\u03b2<1/2\uff09\u6536\u655b\uff0c\u7cfb\u6570\u968fR\u4e0e\u652f\u6491\u89c4\u6a21\u591a\u9879\u5f0f\u76f8\u5173\uff1b\u8f6f\u6700\u5927\u6781\u9650\u4e0b\u6536\u655b\u4e3a\u5bf9\u6570\u7ea7\uff1b\u5b9e\u9a8c\u7ed3\u679c\u652f\u6301\u7406\u8bba\u9884\u6d4b\u3002", "conclusion": "\u7406\u8bba\u63ed\u793a\u6781\u957f\u4e0a\u4e0b\u6587\u4e0b\u6ce8\u610f\u529b\u7684\u6536\u655b\u7279\u6027\u53ca\u5176\u4f9d\u8d56\u56e0\u7d20\uff08R\u3001\u5206\u5e03\u652f\u6491\u3001\u8c31\u6027\u8d28\u3001\u6ce8\u610f\u529b\u51e0\u4f55\uff09\uff0c\u5e76\u6307\u51fa\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u6536\u655b\u53ef\u80fd\u8f83\u6162\uff0c\u9700\u8981\u5728\u6a21\u578b\u8bbe\u8ba1\u4e2d\u6743\u8861\uff1b\u5b9e\u9a8c\u5728\u5408\u6210\u9ad8\u65af\u6570\u636e\u4e0eBERT\u7ef4\u57fa\u6587\u672c\u4e0a\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u6536\u655b\u8d8b\u52bf\u3002"}}
{"id": "2512.10659", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10659", "abs": "https://arxiv.org/abs/2512.10659", "authors": ["Tommaso Amico", "Pernille Matthews", "Lena Krieger", "Arthur Zimek", "Ira Assent"], "title": "DCFO Additional Material", "comment": null, "summary": "Outlier detection identifies data points that significantly deviate from the majority of the data distribution. Explaining outliers is crucial for understanding the underlying factors that contribute to their detection, validating their significance, and identifying potential biases or errors. Effective explanations provide actionable insights, facilitating preventive measures to avoid similar outliers in the future. Counterfactual explanations clarify why specific data points are classified as outliers by identifying minimal changes required to alter their prediction. Although valuable, most existing counterfactual explanation methods overlook the unique challenges posed by outlier detection, and fail to target classical, widely adopted outlier detection algorithms. Local Outlier Factor (LOF) is one the most popular unsupervised outlier detection methods, quantifying outlierness through relative local density. Despite LOF's widespread use across diverse applications, it lacks interpretability. To address this limitation, we introduce Density-based Counterfactuals for Outliers (DCFO), a novel method specifically designed to generate counterfactual explanations for LOF. DCFO partitions the data space into regions where LOF behaves smoothly, enabling efficient gradient-based optimisation. Extensive experimental validation on 50 OpenML datasets demonstrates that DCFO consistently outperforms benchmarked competitors, offering superior proximity and validity of generated counterfactuals.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5bc6\u5ea6\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08DCFO\uff09\u6765\u4e3a\u5c40\u90e8\u5f02\u5e38\u56e0\u5b50 LOF \u751f\u6210\u5bf9\u5f02\u5e38\u70b9\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u3002\u901a\u8fc7\u5c06\u6570\u636e\u7a7a\u95f4\u5212\u5206\u4e3a LOF \u884c\u4e3a\u5e73\u6ed1\u7684\u533a\u57df\u5e76\u8fdb\u884c\u68af\u5ea6\u4f18\u5316\uff0c\u5b9e\u9a8c\u8868\u660e DCFO \u5728 50 \u4e2a OpenML \u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5177\u6709\u66f4\u597d\u7684\u8fd1\u7aef\u6027\u548c\u6709\u6548\u6027\u3002", "motivation": "LOF \u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff1b\u73b0\u6709\u53cd\u4e8b\u5b9e\u65b9\u6cd5\u591a\u672a\u9488\u5bf9\u7ecf\u5178\u7684\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\uff0c\u96be\u4ee5\u63d0\u4f9b\u9488\u5bf9\u6027\u4e14\u53ef\u64cd\u4f5c\u7684\u89e3\u91ca\u3002\u9700\u8981\u53ef\u7528\u4e8e\u6392\u9664\u504f\u5dee\u3001\u9a8c\u8bc1\u91cd\u8981\u6027\u5e76\u63d0\u4f9b\u9632\u8303\u63aa\u65bd\u7684\u89e3\u91ca\u3002", "method": "\u63d0\u51fa DCFO\uff0c\u5229\u7528\u5bc6\u5ea6\u57fa\u7840\u601d\u60f3\u5c06\u6570\u636e\u7a7a\u95f4\u5212\u5206\u6210 LOF \u884c\u4e3a\u5e73\u6ed1\u7684\u533a\u57df\uff0c\u8fdb\u800c\u5728\u8fd9\u4e9b\u533a\u57df\u5185\u5e94\u7528\u68af\u5ea6\u4f18\u5316\u751f\u6210\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u4ee5\u63d0\u9ad8\u89e3\u91ca\u7684\u53ef\u64cd\u4f5c\u6027\u4e0e\u7a33\u5b9a\u6027\u3002", "result": "\u5728 50 \u4efd OpenML \u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u663e\u793a\uff0cDCFO \u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u751f\u6210\u7684\u53cd\u4e8b\u5b9e\u5728\u8ddd\u79bb\u8fd1\u4f3c\u6027\uff08proximality\uff09\u548c\u6709\u6548\u6027\uff08validity\uff09\u65b9\u9762\u5747\u6709\u63d0\u5347\u3002", "conclusion": "DCFO \u6709\u6548\u586b\u8865 LOF \u7684\u53ef\u89e3\u91ca\u6027\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u9762\u5411\u7ecf\u5178\u5bc6\u5ea6\u578b\u68c0\u6d4b\u5668\u7684\u9ad8\u6548\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\uff0c\u5177\u6709\u826f\u597d\u7684\u5b9e\u7528\u6027\u548c\u6f5c\u5728\u7684\u63a8\u5e7f\u6027\u3002"}}
{"id": "2512.10669", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10669", "abs": "https://arxiv.org/abs/2512.10669", "authors": ["Lingjing Kong", "Shaoan Xie", "Yang Jiao", "Yetian Chen", "Yanhui Guo", "Simone Shao", "Yan Gao", "Guangyi Chen", "Kun Zhang"], "title": "Learning by Analogy: A Causal Framework for Composition Generalization", "comment": null, "summary": "Compositional generalization -- the ability to understand and generate novel combinations of learned concepts -- enables models to extend their capabilities beyond limited experiences. While effective, the data structures and principles that enable this crucial capability remain poorly understood. We propose that compositional generalization fundamentally requires decomposing high-level concepts into basic, low-level concepts that can be recombined across similar contexts, similar to how humans draw analogies between concepts. For example, someone who has never seen a peacock eating rice can envision this scene by relating it to their previous observations of a chicken eating rice.\n  In this work, we formalize these intuitive processes using principles of causal modularity and minimal changes. We introduce a hierarchical data-generating process that naturally encodes different levels of concepts and their interaction mechanisms. Theoretically, we demonstrate that this approach enables compositional generalization supporting complex relations between composed concepts, advancing beyond prior work that assumes simpler interactions like additive effects. Critically, we also prove that this latent hierarchical structure is provably recoverable (identifiable) from observable data like text-image pairs, a necessary step for learning such a generative process. To validate our theory, we apply insights from our theoretical framework and achieve significant improvements on benchmark datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u6a21\u5757\u5316\u7684\u5c42\u6b21\u751f\u6210\u8fc7\u7a0b\u6a21\u578b\uff0c\u80fd\u591f\u5b9e\u73b0\u6210\u5206\u5f0f\u6cdb\u5316\uff0c\u5e76\u4e14\u53ef\u4ece\u53ef\u89c2\u6d4b\u6570\u636e\uff08\u6587\u672c-\u56fe\u50cf\u5bf9\uff09\u4e2d\u53ef\u8bc6\u522b\u5730\u6062\u590d\u6f5c\u5728\u5c42\u6b21\u7ed3\u6784\uff1b\u7406\u8bba\u6027\u8bc1\u660e\u4e0e\u5b9e\u8bc1\u90fd\u663e\u793a\u51fa\u5bf9\u590d\u6742\u5173\u7cfb\u7684\u6cdb\u5316\u80fd\u529b\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u7684\u6210\u5206\u5f0f\u6cdb\u5316\u7814\u7a76\u5bf9\u652f\u6491\u673a\u5236\u7684\u7406\u89e3\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u5bf9\u6570\u636e\u7ed3\u6784\u548c\u539f\u7406\u7684\u6e05\u6670\u754c\u5b9a\u3002\u4f5c\u8005\u4e3b\u5f20\u5c06\u9ad8\u5c42\u6982\u5ff5\u5206\u89e3\u4e3a\u4f4e\u5c42\u6982\u5ff5\u5e76\u5728\u76f8\u4f3c\u60c5\u5883\u4e0b\u91cd\u65b0\u7ec4\u5408\uff0c\u4eff\u7167\u4eba\u7c7b\u7c7b\u6bd4\u7684\u65b9\u5f0f\u6765\u5b9e\u73b0\u6cdb\u5316\uff1b\u8bc6\u522b\u6027\uff08identifiability\uff09\u662f\u5b66\u4e60\u6b64\u7c7b\u751f\u6210\u8fc7\u7a0b\u7684\u5173\u952e\u524d\u63d0\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5c42\u6b21\u5316\u7684\u6570\u636e\u751f\u6210\u8fc7\u7a0b\uff0c\u7f16\u7801\u4e0d\u540c\u5c42\u6b21\u7684\u6982\u5ff5\u53ca\u5176\u76f8\u4e92\u4f5c\u7528\u673a\u5236\uff0c\u5e76\u4ee5\u56e0\u679c\u6a21\u5757\u5316\u4e0e\u6700\u5c0f\u6539\u53d8\u539f\u5219\u4e3a\u6838\u5fc3\uff1b\u7406\u8bba\u8bc1\u660e\u8be5\u6846\u67b6\u4e0b\u7684\u6f5c\u5728\u5c42\u6b21\u7ed3\u6784\u5728\u53ef\u89c2\u6d4b\u6570\u636e\u4e0a\u662f\u53ef\u8fa8\u8bc6\u7684\uff08identifiable\uff09\uff0c\u4e14\u80fd\u591f\u5b9e\u73b0\u6bd4\u4ec5\u4f9d\u8d56\u7ebf\u6027\u3001\u52a0\u6027\u5047\u8bbe\u66f4\u4e30\u5bcc\u7684\u6210\u5206\u95f4\u5173\u7cfb\u7684\u7ec4\u5408\u6cdb\u5316\uff1b\u5e76\u5728\u6587\u672c-\u56fe\u50cf\u5bf9\u7b49\u53ef\u89c2\u6d4b\u6570\u636e\u4e0a\u8fdb\u884c\u53ef\u9a8c\u8bc1\u6027\u5206\u6790\u3002", "result": "\u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5728\u590d\u6742\u6982\u5ff5\u5173\u7cfb\u4e0b\u7684\u6210\u5206\u5316\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u7ed9\u51fa\u6f5c\u5728\u5c42\u6b21\u7ed3\u6784\u7684\u53ef\u8fa8\u8bc6\u6027\u8bc1\u660e\uff1b\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u57fa\u4e8e\u7406\u8bba\u6846\u67b6\u5f97\u5230\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6210\u5206\u5f0f\u6cdb\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u4e0e\u65b9\u6cd5\u8def\u5f84\uff0c\u5c55\u793a\u4e86\u53ef\u8fa8\u8bc6\u7684\u6f5c\u5728\u5c42\u6b21\u7ed3\u6784\u5982\u4f55\u5e2e\u52a9\u5b66\u4e60\u66f4\u590d\u6742\u7684\u6982\u5ff5\u7ec4\u5408\uff0c\u5e76\u5728\u5b9e\u8bc1\u8bc4\u4f30\u4e2d\u53d6\u5f97\u8fdb\u5c55\u3002"}}
{"id": "2512.10701", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10701", "abs": "https://arxiv.org/abs/2512.10701", "authors": ["Mostafa Anoosha", "Zeinab Dehghani", "Kuniko Paxton", "Koorosh Aslansefat", "Dhavalkumar Thakker"], "title": "HybridVFL: Disentangled Feature Learning for Edge-Enabled Vertical Federated Multimodal Classification", "comment": "6 pages, 2 figures, 1 table. Accepted at UCC '25 (IEEE/ACM 18th International Conference on Utility and Cloud Computing), December 1-4, 2025, Nantes, France. DOI to be activated upon final publication", "summary": "Vertical Federated Learning (VFL) offers a privacy-preserving paradigm for Edge AI scenarios like mobile health diagnostics, where sensitive multimodal data reside on distributed, resource-constrained devices. Yet, standard VFL systems often suffer performance limitations due to simplistic feature fusion. This paper introduces HybridVFL, a novel framework designed to overcome this bottleneck by employing client-side feature disentanglement paired with a server-side cross-modal transformer for context-aware fusion. Through systematic evaluation on the multimodal HAM10000 skin lesion dataset, we demonstrate that HybridVFL significantly outperforms standard federated baselines, validating the criticality of advanced fusion mechanisms in robust, privacy-preserving systems.", "AI": {"tldr": "HybridVFL \u901a\u8fc7\u5728\u5ba2\u6237\u7aef\u8fdb\u884c\u7279\u5f81\u89e3\u8026\u3001\u5728\u670d\u52a1\u5668\u7aef\u91c7\u7528\u8de8\u6a21\u6001\u53d8\u6362\u5668\u8fdb\u884c\u4e0a\u4e0b\u6587\u611f\u77e5\u878d\u5408\uff0c\u663e\u8457\u63d0\u5347\u5782\u76f4\u8054\u90a6\u5b66\u4e60\u5728\u591a\u6a21\u6001\u76ae\u80a4\u75c5\u53d8\u6570\u636e\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5782\u76f4\u8054\u90a6\u5b66\u4e60\uff08VFL\uff09\u591a\u91c7\u7528\u7b80\u5355\u7684\u7279\u5f81\u878d\u5408\uff0c\u96be\u4ee5\u5145\u5206\u5229\u7528\u591a\u6a21\u6001\u4fe1\u606f\u4e14\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u573a\u666f\u4e0b\u6027\u80fd\u53d7\u9650\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u878d\u5408\u7b56\u7565\u4ee5\u63d0\u5347\u6548\u679c\u5e76\u4fdd\u6301\u9690\u79c1\u3002", "method": "\u5728\u5ba2\u6237\u7aef\u6267\u884c\u7279\u5f81\u89e3\u8026\u4ee5\u4fdd\u62a4\u9690\u79c1\u5e76\u63d0\u5347\u53ef\u63a7\u4fe1\u606f\u7684\u5229\u7528\uff0c\u5728\u670d\u52a1\u5668\u7aef\u5f15\u5165\u8de8\u6a21\u6001 Transformer \u8fdb\u884c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6a21\u6001\u878d\u5408\u4e0e\u5206\u7c7b\uff0c\u901a\u8fc7\u5bf9 HAM10000 \u6570\u636e\u96c6\u7684\u7cfb\u7edf\u8bc4\u4f30\u9a8c\u8bc1\u6027\u80fd\u63d0\u5347\u3002", "result": "\u76f8\u8f83\u4e8e\u6807\u51c6\u8054\u90a6\u57fa\u7ebf\uff0cHybridVFL \u5728\u591a\u6a21\u6001\u76ae\u80a4\u75c5\u53d8\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u663e\u793a\u51fa\u5148\u8fdb\u878d\u5408\u673a\u5236\u5728\u9c81\u68d2\u6027\u4e0e\u9690\u79c1\u4fdd\u62a4\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u5c06\u7279\u5f81\u89e3\u8026\u4e0e\u8de8\u6a21\u6001 Transformer \u878d\u5408\u5e94\u7528\u4e8eVFL\u80fd\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u8fb9\u7f18AI\u573a\u666f\u7684\u6027\u80fd\u4e0e\u9690\u79c1\u4fdd\u62a4\uff0cHybridVFL\u4e3a\u6b64\u7c7b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.10720", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10720", "abs": "https://arxiv.org/abs/2512.10720", "authors": ["Lingjing Kong", "Shaoan Xie", "Guangyi Chen", "Yuewen Sun", "Xiangchen Song", "Eric P. Xing", "Kun Zhang"], "title": "Beyond the Black Box: Identifiable Interpretation and Control in Generative Models via Causal Minimality", "comment": null, "summary": "Deep generative models, while revolutionizing fields like image and text generation, largely operate as opaque black boxes, hindering human understanding, control, and alignment. While methods like sparse autoencoders (SAEs) show remarkable empirical success, they often lack theoretical guarantees, risking subjective insights. Our primary objective is to establish a principled foundation for interpretable generative models. We demonstrate that the principle of causal minimality -- favoring the simplest causal explanation -- can endow the latent representations of diffusion vision and autoregressive language models with clear causal interpretation and robust, component-wise identifiable control. We introduce a novel theoretical framework for hierarchical selection models, where higher-level concepts emerge from the constrained composition of lower-level variables, better capturing the complex dependencies in data generation. Under theoretically derived minimality conditions (manifesting as sparsity or compression constraints), we show that learned representations can be equivalent to the true latent variables of the data-generating process. Empirically, applying these constraints to leading generative models allows us to extract their innate hierarchical concept graphs, offering fresh insights into their internal knowledge organization. Furthermore, these causally grounded concepts serve as levers for fine-grained model steering, paving the way for transparent, reliable systems.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.10723", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10723", "abs": "https://arxiv.org/abs/2512.10723", "authors": ["Hao Tang", "Hao Chen", "Chao Li"], "title": "Generalized Spherical Neural Operators: Green's Function Formulation", "comment": null, "summary": "Neural operators offer powerful approaches for solving parametric partial differential equations, but extending them to spherical domains remains challenging due to the need to preserve intrinsic geometry while avoiding distortions that break rotational consistency. Existing spherical operators rely on rotational equivariance but often lack the flexibility for real-world complexity. We propose a general operator-design framework based on the designable spherical Green's function and its harmonic expansion, establishing a solid operator-theoretic foundation for spherical learning. Based on this, we propose an absolute and relative position-dependent Green's function that enables flexible balance of equivariance and invariance for real-world modeling. The resulting operator, Green's-function Spherical Neural Operator (GSNO) with a novel spectral learning method, can adapt to anisotropic, constraint-rich systems while retaining spectral efficiency. To exploit GSNO, we develop GSHNet, a hierarchical architecture that combines multi-scale spectral modeling with spherical up-down sampling, enhancing global feature representation. Evaluations on diffusion MRI, shallow water dynamics, and global weather forecasting, GSNO and GSHNet consistently outperform state-of-the-art methods. Our results position GSNO as a principled and general framework for spherical operator learning, bridging rigorous theory with real-world complexity.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.10735", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10735", "abs": "https://arxiv.org/abs/2512.10735", "authors": ["Lin Du", "Lu Bai", "Jincheng Li", "Lixin Cui", "Hangyuan Du", "Lichi Zhang", "Yuting Chen", "Zhao Li"], "title": "LGAN: An Efficient High-Order Graph Neural Network via the Line Graph Aggregation", "comment": null, "summary": "Graph Neural Networks (GNNs) have emerged as a dominant paradigm for graph classification. Specifically, most existing GNNs mainly rely on the message passing strategy between neighbor nodes, where the expressivity is limited by the 1-dimensional Weisfeiler-Lehman (1-WL) test. Although a number of k-WL-based GNNs have been proposed to overcome this limitation, their computational cost increases rapidly with k, significantly restricting the practical applicability. Moreover, since the k-WL models mainly operate on node tuples, these k-WL-based GNNs cannot retain fine-grained node- or edge-level semantics required by attribution methods (e.g., Integrated Gradients), leading to the less interpretable problem. To overcome the above shortcomings, in this paper, we propose a novel Line Graph Aggregation Network (LGAN), that constructs a line graph from the induced subgraph centered at each node to perform the higher-order aggregation. We theoretically prove that the LGAN not only possesses the greater expressive power than the 2-WL under injective aggregation assumptions, but also has lower time complexity. Empirical evaluations on benchmarks demonstrate that the LGAN outperforms state-of-the-art k-WL-based GNNs, while offering better interpretability.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.10805", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.10805", "abs": "https://arxiv.org/abs/2512.10805", "authors": ["Akshay Kulkarni", "Tsui-Wei Weng", "Vivek Narayanaswamy", "Shusen Liu", "Wesam A. Sakla", "Kowshik Thopalli"], "title": "Interpretable and Steerable Concept Bottleneck Sparse Autoencoders", "comment": null, "summary": "Sparse autoencoders (SAEs) promise a unified approach for mechanistic interpretability, concept discovery, and model steering in LLMs and LVLMs. However, realizing this potential requires that the learned features be both interpretable and steerable. To that end, we introduce two new computationally inexpensive interpretability and steerability metrics and conduct a systematic analysis on LVLMs. Our analysis uncovers two observations; (i) a majority of SAE neurons exhibit either low interpretability or low steerability or both, rendering them ineffective for downstream use; and (ii) due to the unsupervised nature of SAEs, user-desired concepts are often absent in the learned dictionary, thus limiting their practical utility. To address these limitations, we propose Concept Bottleneck Sparse Autoencoders (CB-SAE) - a novel post-hoc framework that prunes low-utility neurons and augments the latent space with a lightweight concept bottleneck aligned to a user-defined concept set. The resulting CB-SAE improves interpretability by +32.1% and steerability by +14.5% across LVLMs and image generation tasks. We will make our code and model weights available.", "AI": {"tldr": "\u63d0\u51fa\u4e86 CB-SAE\uff1a\u901a\u8fc7\u88c1\u526a\u4f4e\u6548\u795e\u7ecf\u5143\u5e76\u5f15\u5165\u6982\u5ff5\u74f6\u9888\uff0c\u63d0\u5347 LVLMs \u7684\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u64cd\u63a7\u6027\uff1b\u5728\u5206\u6790\u4e2d\u53d1\u73b0\u591a\u6570 SAE \u795e\u7ecf\u5143\u8981\u4e48\u53ef\u89e3\u91ca\u6027\u4f4e\uff0c\u8981\u4e48\u53ef\u63a7\u6027\u4f4e\uff0c\u4e14\u65e0\u76d1\u7763\u5b66\u4e60\u5bfc\u81f4\u7528\u6237\u6982\u5ff5\u7f3a\u5931\uff1b\u7ed3\u679c\u663e\u793a\u53ef\u89e3\u91ca\u6027\u63d0\u534732.1%\u3001\u53ef\u64cd\u63a7\u6027\u63d0\u534714.5%\uff1b\u8ba1\u5212\u516c\u5f00\u4ee3\u7801\u4e0e\u6743\u91cd\u3002", "motivation": "\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5728\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u64cd\u63a7\u6027\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u5b9e\u9645\u8868\u73b0\u53d7\u9650\uff0c\u56e0\u4e3a\u5927\u591a\u6570\u795e\u7ecf\u5143\u4e0d\u53ef\u89e3\u91ca\u6216\u4e0d\u53ef\u63a7\uff0c\u4e14\u65e0\u76d1\u7763\u5b66\u4e60\u96be\u4ee5\u8986\u76d6\u7528\u6237\u5e0c\u671b\u7684\u6982\u5ff5\uff1b\u9700\u8981\u4e00\u4e2a\u4f4e\u6210\u672c\u7684\u540e\u5904\u7406\u6846\u67b6\u6765\u5bf9\u9f50\u6982\u5ff5\u5e76\u63d0\u5347\u53ef\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u8f7b\u91cf\u7ea7\u53ef\u89e3\u91ca\u6027\u4e0e\u53ef\u64cd\u63a7\u6027\u5ea6\u91cf\uff1b\u5bf9 LVLM \u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff1b\u63d0\u51fa CB-SAE\uff1a\u540e\u5904\u7406\u88c1\u526a\u4f4e\u6548\u795e\u7ecf\u5143\uff0c\u5e76\u5728\u6f5c\u5728\u7a7a\u95f4\u589e\u52a0\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u6982\u5ff5\u74f6\u9888\uff0c\u4f7f\u4e4b\u4e0e\u7528\u6237\u5b9a\u4e49\u7684\u6982\u5ff5\u96c6\u5bf9\u9f50\u3002", "result": "\u5728\u5206\u6790\u4e2d\u53d1\u73b0\u591a\u6570 SAE \u795e\u7ecf\u5143\u8981\u4e48\u53ef\u89e3\u91ca\u6027\u4f4e\uff0c\u8981\u4e48\u53ef\u64cd\u63a7\u6027\u4f4e\uff1bCB-SAE \u80fd\u5728 LVLMs \u548c\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\u5c06\u53ef\u89e3\u91ca\u6027\u63d0\u5347\u7ea632.1%\u3001\u53ef\u64cd\u63a7\u6027\u63d0\u5347\u7ea614.5%\u3002", "conclusion": "CB-SAE \u663e\u8457\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u64cd\u63a7\u6027\uff0c\u5e76\u901a\u8fc7\u540e\u5904\u7406\u88c1\u526a\u4e0e\u6982\u5ff5\u74f6\u9888\u5bf9\u9f50\u63d0\u5347\u5b9e\u7528\u6027\uff1b\u8ba1\u5212\u516c\u5f00\u4ee3\u7801\u548c\u6743\u91cd\u4ee5\u4fbf\u590d\u73b0\u3002"}}
{"id": "2512.10857", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.10857", "abs": "https://arxiv.org/abs/2512.10857", "authors": ["Chirag Modi", "Jiequn Han", "Eric Vanden-Eijnden", "Joan Bruna"], "title": "Generative Modeling from Black-box Corruptions via Self-Consistent Stochastic Interpolants", "comment": null, "summary": "Transport-based methods have emerged as a leading paradigm for building generative models from large, clean datasets. However, in many scientific and engineering domains, clean data are often unavailable: instead, we only observe measurements corrupted through a noisy, ill-conditioned channel. A generative model for the original data thus requires solving an inverse problem at the level of distributions. In this work, we introduce a novel approach to this task based on Stochastic Interpolants: we iteratively update a transport map between corrupted and clean data samples using only access to the corrupted dataset as well as black box access to the corruption channel. Under appropriate conditions, this iterative procedure converges towards a self-consistent transport map that effectively inverts the corruption channel, thus enabling a generative model for the clean data. We refer to the resulting method as the self-consistent stochastic interpolant (SCSI). It (i) is computationally efficient compared to variational alternatives, (ii) highly flexible, handling arbitrary nonlinear forward models with only black-box access, and (iii) enjoys theoretical guarantees. We demonstrate superior performance on inverse problems in natural image processing and scientific reconstruction, and establish convergence guarantees of the scheme under appropriate assumptions.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u4e00\u81f4\u968f\u673a\u63d2\u503c\u5668\uff08SCSI\uff09\uff0c\u901a\u8fc7\u5728\u53d7\u635f\u6570\u636e\u4e0e\u6e05\u6d01\u6570\u636e\u4e4b\u95f4\u8fed\u4ee3\u66f4\u65b0\u8fd0\u8f93\u6620\u5c04\uff0c\u5728\u4ec5\u6709\u53d7\u635f\u6570\u636e\u548c\u9ed1\u7bb1\u524d\u5411\u6a21\u578b\u7684\u6761\u4ef6\u4e0b\u5b9e\u73b0\u5bf9\u6c61\u67d3\u901a\u9053\u7684\u53cd\u6f14\uff0c\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u5e76\u5177\u5907\u8f83\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u5728\u5f88\u591a\u79d1\u5b66/\u5de5\u7a0b\u9886\u57df\uff0c\u6e05\u6d01\u6570\u636e\u96be\u4ee5\u83b7\u5f97\uff0c\u53ea\u80fd\u83b7\u53d6\u88ab\u5608\u6742\u901a\u9053\u6c61\u67d3\u7684\u89c2\u6d4b\uff1b\u9700\u8981\u5728\u5206\u5e03\u5c42\u9762\u89e3\u51b3\u9006\u95ee\u9898\uff0c\u5e76\u6784\u5efa\u6e05\u6d01\u6570\u636e\u7684\u751f\u6210\u6a21\u578b\u3002\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u4f9d\u8d56\u4e8e\u6d01\u51c0\u6570\u636e\u6216\u590d\u6742\u7684\u53d8\u5206\u63a8\u7406\uff0c\u96be\u4ee5\u9ad8\u6548\u6216\u7075\u6d3b\u5904\u7406\u5f3a\u975e\u7ebf\u6027\u524d\u5411\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u968f\u673a\u63d2\u503c\u7684\u8fd0\u8f93\u66f4\u65b0\uff0c\u8fed\u4ee3\u5730\u66f4\u65b0\u53d7\u635f\u6837\u672c\u5230\u6e05\u6d01\u6837\u672c\u4e4b\u95f4\u7684\u8fd0\u8f93\u6620\u5c04\uff0c\u4e14\u4ec5\u9700\u8981\u8bbf\u95ee\u53d7\u635f\u6570\u636e\u548c\u5bf9\u524d\u5411\u901a\u9053\u7684\u9ed1\u7bb1\u8bbf\u95ee\u3002\u8be5\u8fc7\u7a0b\u5f62\u6210\u81ea\u4e00\u81f4\u7684\u8fd0\u8f93\u6620\u5c04\uff0c\u6536\u655b\u540e\u5b9e\u73b0\u5bf9\u6c61\u67d3\u901a\u9053\u7684\u53cd\u6f14\uff0c\u5f62\u6210\u81ea\u4e00\u81f4\u968f\u673a\u63d2\u503c\u5668\uff08SCSI\uff09\u3002", "result": "\u5728\u81ea\u7136\u56fe\u50cf\u5904\u7406\u548c\u79d1\u5b66\u91cd\u5efa\u7684\u9006\u95ee\u9898\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff1b\u76f8\u8f83\u4e8e\u53d8\u5206\u65b9\u6cd5\uff0c\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\uff1b\u5bf9\u4efb\u610f\u975e\u7ebf\u6027\u524d\u5411\u6a21\u578b\u5177\u5907\u826f\u597d\u9002\u5e94\u6027\uff1b\u5728\u9002\u5f53\u5047\u8bbe\u4e0b\u7ed9\u51fa\u6536\u655b\u6027\u4fdd\u8bc1\u3002", "conclusion": "SCSI\u4e3a\u5728\u4ec5\u6709\u53d7\u635f\u89c2\u6d4b\u4e0b\u7684\u6e05\u6d01\u6570\u636e\u751f\u6210\u5efa\u6a21\u63d0\u4f9b\u4e00\u4e2a\u7406\u8bba\u4e0a\u6709\u4fdd\u969c\u3001\u8ba1\u7b97\u9ad8\u6548\u3001\u7075\u6d3b\u9002\u5e94\u590d\u6742\u524d\u5411\u6a21\u578b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u5206\u5e03\u5c42\u9762\u7684\u9006\u95ee\u9898\u5efa\u6a21\u3002"}}
{"id": "2512.10858", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10858", "abs": "https://arxiv.org/abs/2512.10858", "authors": ["Dimitri von R\u00fctte", "Janis Fluri", "Omead Pooladzandi", "Bernhard Sch\u00f6lkopf", "Thomas Hofmann", "Antonio Orvieto"], "title": "Scaling Behavior of Discrete Diffusion Language Models", "comment": null, "summary": "Modern LLM pre-training consumes vast amounts of compute and training data, making the scaling behavior, or scaling laws, of different models a key distinguishing factor. Discrete diffusion language models (DLMs) have been proposed as an alternative to autoregressive language models (ALMs). However, their scaling behavior has not yet been fully explored, with prior work suggesting that they require more data and compute to match the performance of ALMs.\n  We study the scaling behavior of DLMs on different noise types by smoothly interpolating between masked and uniform diffusion while paying close attention to crucial hyperparameters such as batch size and learning rate. Our experiments reveal that the scaling behavior of DLMs strongly depends on the noise type and is considerably different from ALMs. While all noise types converge to similar loss values in compute-bound scaling, we find that uniform diffusion requires more parameters and less data for compute-efficient training compared to masked diffusion, making them a promising candidate in data-bound settings. We scale our uniform diffusion model up to 10B parameters trained for $10^{22}$ FLOPs, confirming the predicted scaling behavior and making it the largest publicly known uniform diffusion model to date.", "AI": {"tldr": "DLMs \u7684\u7f29\u653e\u884c\u4e3a\u5f3a\u70c8\u4f9d\u8d56\u566a\u58f0\u7c7b\u578b\uff0c\u4e0e ALMs \u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u7edf\u4e00\u6269\u6563\u5728\u53ef\u8ba1\u7b97\u8d44\u6e90\u7ea6\u675f\u4e0b\u9700\u8981\u66f4\u591a\u53c2\u6570\u4f46\u5bf9\u6570\u636e\u9700\u6c42\u8f83\u4f4e\uff0c\u4e14\u5728\u6570\u636e\u53d7\u9650\u573a\u666f\u4e2d\u5177\u6709\u6f5c\u5728\u4f18\u52bf\uff1b\u5728\u8fbe\u5230 10B \u53c2\u6570\u30011e22 FLOPs \u7684\u89c4\u6a21\u4e0b\uff0c\u7edf\u4e00\u6269\u6563\u6a21\u578b\u7684 scaling \u884c\u4e3a\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u662f\u516c\u5f00\u53ef\u7528\u7684\u6700\u5927\u7684\u7edf\u4e00\u6269\u6563\u6a21\u578b\u4e4b\u4e00\u3002", "motivation": "\u63a2\u7a76\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u566a\u58f0\u7c7b\u578b\u4e0b\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u5e76\u5c06\u5176\u4e0e\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u7684\u7f29\u653e\u89c4\u5f8b\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u5224\u65ad\u4e0d\u540c\u566a\u58f0\u548c\u8bad\u7ec3\u8d85\u53c2\u6570\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u5728\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u4e0a\u7684\u6548\u7387\u3002", "method": "\u901a\u8fc7\u5728\u63a9\u7801\u6269\u6563\u4e0e\u5747\u5300\u6269\u6563\u4e4b\u95f4\u8fdb\u884c\u5e73\u6ed1\u63d2\u503c\uff0c\u7814\u7a76\u4e0d\u540c\u566a\u58f0\u7c7b\u578b\u5bf9 DLM \u7f29\u653e\u884c\u4e3a\u7684\u5f71\u54cd\uff1b\u5173\u6ce8\u6279\u91cf\u5927\u5c0f\u3001\u5b66\u4e60\u7387\u7b49\u5173\u952e\u8d85\u53c2\u6570\uff1b\u5c06\u6a21\u578b\u89c4\u6a21\u6269\u5c55\u81f3 10B \u53c2\u6570\uff0c\u5e76\u5728 10^22 FLOPs \u6761\u4ef6\u4e0b\u8bad\u7ec3\uff0c\u9a8c\u8bc1\u9884\u6d4b\u7684\u7f29\u653e\u89c4\u5f8b\u3002", "result": "\u4e0d\u540c\u566a\u58f0\u7c7b\u578b\u5bfc\u81f4 DLM \u7684\u7f29\u653e\u884c\u4e3a\u663e\u8457\u4e0d\u540c\uff1b\u5728 compute-bound\uff08\u8ba1\u7b97\u53d7\u9650\uff09\u60c5\u5f62\u4e0b\uff0c\u4e0d\u540c\u566a\u58f0\u7c7b\u578b\u7684\u6700\u7ec8\u635f\u5931\u8d8b\u4e8e\u76f8\u8fd1\uff1b\u4e0e\u63a9\u7801\u6269\u6563\u76f8\u6bd4\uff0c\u5747\u5300\u6269\u6563\u9700\u8981\u66f4\u591a\u53c2\u6570\u3001\u800c\u6570\u636e\u9700\u6c42\u8f83\u5c11\uff0c\u56e0\u800c\u5728\u6570\u636e\u53d7\u9650\u7684\u8bad\u7ec3\u573a\u666f\u4e2d\u5177\u6709\u4f18\u52bf\uff1b\u5df2\u5c06\u5747\u5300\u6269\u6563\u6a21\u578b\u6269\u5c55\u81f3 100 \u4ebf\u53c2\u6570\uff0c\u8fbe\u5230 10^22 FLOPs\uff0c\u9a8c\u8bc1\u4e86\u5176\u7f29\u653e\u89c4\u5f8b\uff0c\u4e14\u6210\u4e3a\u516c\u5f00\u53ef\u7528\u7684\u6700\u5927\u89c4\u6a21\u5747\u5300\u6269\u6563\u6a21\u578b\u3002", "conclusion": "DLM \u7684\u7f29\u653e\u89c4\u5f8b\u4e0e ALM \u5b58\u5728\u672c\u8d28\u5dee\u5f02\uff0c\u566a\u58f0\u7c7b\u578b\u662f\u51b3\u5b9a\u6027\u56e0\u7d20\u3002\u5747\u5300\u6269\u6563\u5728\u6570\u636e\u4e0d\u8db3\u65f6\u66f4\u5177\u53c2\u6570\u4f9d\u8d56\u6027\u548c\u6570\u636e\u6548\u7387\uff0c\u662f\u6570\u636e\u53d7\u9650\u573a\u666f\u7684\u6709\u529b\u5019\u9009\uff1b\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u5bf9\u9ad8\u53c2\u6570\u91cf\u3001/\u5927\u89c4\u6a21\u8bad\u7ec3\u7684\u5b9e\u9645\u8bc1\u5b9e\uff0c\u4fc3\u8fdb\u5bf9\u79bb\u6563\u6269\u6563\u65b9\u6cd5\u7684\u7406\u89e3\u4e0e\u5e94\u7528\u3002"}}
