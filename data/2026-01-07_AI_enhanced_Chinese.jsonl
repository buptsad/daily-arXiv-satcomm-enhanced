{"id": "2601.02496", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.02496", "abs": "https://arxiv.org/abs/2601.02496", "authors": ["Sergio Demian Lerner"], "title": "APoW: Auditable Proof-of-Work Against Block Withholding Attacks", "comment": null, "summary": "We introduce APoW, a novel proof-of-work (PoW) construction inspired by Hashcash-style nonce searching, which enables the auditing of other miners' work through accountable re-scanning of the nonce space. The proposed scheme allows a miner to probabilistically attest to having searched specified regions of the nonce space in earlier mining rounds, while concurrently earning rewards for performing productive work for a new block or pool share. This capability enables miners belonging to a mining pools to audit another miner's claimed effort retroactively, thereby allowing the probabilistic detection of block withholding attacks (BWAs) without requiring trusted hardware or trusted third parties. As a consequence, the construction supports the design of decentralized mining pools in which work attribution is verifiable and withholding incentives are substantially reduced. The scheme preserves the fundamental properties of conventional PoW, including public verifiability and difficulty adjustment, while adding an orthogonal auditability layer tailored to pool-based mining. Finally, while a full deployment of APoW in Bitcoin would require a consensus rule change and minor modifications to mining ASICs, the construction remains practically useful even without consensus changes, for instance, as a pool-level auditing mechanism that enables verifiable pay-for-auditing using existing pool reserves.", "AI": {"tldr": "APoW\u901a\u8fc7\u5728Nonce\u7a7a\u95f4\u8bb0\u5f55\u53ef\u518d\u626b\u63cf\u533a\u57df\uff0c\u4f7f\u77ff\u6c60\u5185\u90e8\u53ef\u8ffd\u8e2a\u9a8c\u8bc1\u5de5\u4f5c\u91cf\uff0c\u4ece\u800c\u964d\u4f4e\u533a\u5757\u6263\u7559\u653b\u51fb\u98ce\u9669\uff0c\u65e0\u9700\u4fe1\u4efb\u786c\u4ef6\u6216\u7b2c\u4e09\u65b9\uff0c\u53ef\u5b9e\u9645\u5728\u5f53\u524d\u77ff\u6c60\u5b9e\u73b0\u3002", "motivation": "\u89e3\u51b3\u77ff\u6c60\u5185\u90e8\u77ff\u5de5\u5077\u7a83\u533a\u5757\u548c\u4e0a\u62a5\u5047\u5de5\u4f5c\u95ee\u9898\uff0c\u907f\u514d\u5bf9\u53ef\u4fe1\u786c\u4ef6/\u7b2c\u4e09\u65b9\u7684\u4f9d\u8d56\u3002", "method": "\u5728Hashcash\u5f0f\u968f\u673a\u6570\u641c\u7d22\u57fa\u7840\u4e0a\u52a0\u5165\u53ef\u518d\u626b\u63cf\u533a\u57df\u8bb0\u5f55\uff0c\u5b9e\u73b0\u5de5\u4f5c\u8bc1\u660e\u53ef\u8ffd\u6eaf\u3002", "result": "\u63d0\u51faAPoW\u65b9\u6848\u53ef\u8bc1\u5b9e\u77ff\u5de5\u5df2\u5bf9\u6307\u5b9anonce\u533a\u57df\u5de5\u4f5c\uff0c\u652f\u6301\u53bb\u4e2d\u5fc3\u5316\u77ff\u6c60\u6838\u67e5\u5de5\u4f5c\u5e76\u53ef\u901a\u8fc7\u73b0\u6709\u77ff\u6c60\u50a8\u5907\u5b9e\u73b0\u5ba1\u6838\u4ed8\u8d39\u3002", "conclusion": "APoW\u4e3a\u533a\u5757\u94fePoW\u63d0\u4f9b\u4e86\u53ef\u5ba1\u6838\u7684\u5de5\u4f5c\u8bc1\u660e\u673a\u5236\uff0c\u63d0\u5347\u77ff\u6c60\u900f\u660e\u5ea6\u5e76\u964d\u4f4e\u533a\u5757\u6263\u7559\u653b\u51fb\u3002"}}
{"id": "2601.02602", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02602", "abs": "https://arxiv.org/abs/2601.02602", "authors": ["Neusha Javidnia", "Ruisi Zhang", "Ashish Kundu", "Farinaz Koushanfar"], "title": "SWaRL: Safeguard Code Watermarking via Reinforcement Learning", "comment": "Under review", "summary": "We present SWaRL, a robust and fidelity-preserving watermarking framework designed to protect the intellectual property of code LLM owners by embedding unique and verifiable signatures in the generated output. Existing approaches rely on manually crafted transformation rules to preserve watermarked code functionality or manipulate token-generation probabilities at inference time, which are prone to compilation errors. To address these challenges, SWaRL employs a reinforcement learning-based co-training framework that uses compiler feedback for functional correctness and a jointly trained confidential verifier as a reward signal to maintain watermark detectability. Furthermore, SWaRL employs low-rank adaptation (LoRA) during fine-tuning, allowing the learned watermark information to be transferable across model updates. Extensive experiments show that SWaRL achieves higher watermark detection accuracy compared to prior methods while fully maintaining watermarked code functionality. The LoRA-based signature embedding steers the base model to generate and solve code in a watermark-specific manner without significant computational overhead. Moreover, SWaRL exhibits strong resilience against refactoring and adversarial transformation attacks.", "AI": {"tldr": "SWaRL\u91c7\u7528\u5f3a\u5316\u5b66\u4e60+\u7f16\u8bd1\u5668\u53cd\u9988+LoRA\u6280\u672f\uff0c\u5b9e\u73b0\u9ad8\u51c6\u786e\u5ea6\u3001\u529f\u80fd\u5b8c\u6574\u3001\u53ef\u8fc1\u79fb\u4e14\u5bf9\u6297\u6027\u5f3a\u7684\u4ee3\u7801LLM\u6c34\u5370\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u4eba\u5de5\u89c4\u5219\u5bfc\u81f4\u529f\u80fd\u635f\u574f\uff0c\u8981\u4e48\u5728\u63a8\u7406\u65f6\u6539\u52a8\u751f\u6210\u6982\u7387\uff0c\u5bb9\u6613\u5f15\u53d1\u7f16\u8bd1\u9519\u8bef\uff0c\u7f3a\u4e4f\u9c81\u68d2\u6027\u4e0e\u53ef\u8fc1\u79fb\u6027\u3002", "method": "\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8054\u5408\u7684\u7f16\u8bd1\u5668\u53cd\u9988\u4e0e\u4fdd\u5bc6\u9a8c\u8bc1\u5668\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u540c\u65f6\u5728\u5fae\u8c03\u65f6\u4f7f\u7528LoRA\u4f7f\u6c34\u5370\u4fe1\u606f\u53ef\u8fc1\u79fb\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSWaRL\u5728\u6c34\u5370\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u5e76\u5b8c\u5168\u4fdd\u6301\u88ab\u6c34\u5370\u4ee3\u7801\u7684\u529f\u80fd\u5b8c\u6574\uff0c\u540c\u65f6\u5728\u91cd\u6784\u548c\u5bf9\u6297\u53d8\u5f62\u653b\u51fb\u4e0b\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "SWaRL\u80fd\u591f\u5728\u4e0d\u7834\u574f\u4ee3\u7801\u529f\u80fd\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u3001\u7a33\u5065\u4e14\u53ef\u8f6c\u79fb\u7684\u6c34\u5370\u6ce8\u5165\u4e0e\u68c0\u6d4b\uff0c\u4e14\u5bf9\u91cd\u6784\u4e0e\u5bf9\u6297\u653b\u51fb\u5177\u5907\u8f83\u5f3a\u97e7\u6027\u3002"}}
{"id": "2601.02624", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02624", "abs": "https://arxiv.org/abs/2601.02624", "authors": ["Md Ajoad Hasan", "Dipayan Saha", "Khan Thamid Hasan", "Nashmin Alam", "Azim Uddin", "Sujan Kumar Saha", "Mark Tehranipoor", "Farimah Farahmandi"], "title": "LAsset: An LLM-assisted Security Asset Identification Framework for System-on-Chip (SoC) Verification", "comment": "6 pages", "summary": "The growing complexity of modern system-on-chip (SoC) and IP designs is making security assurance difficult day by day. One of the fundamental steps in the pre-silicon security verification of a hardware design is the identification of security assets, as it substantially influences downstream security verification tasks, such as threat modeling, security property generation, and vulnerability detection. Traditionally, assets are determined manually by security experts, requiring significant time and expertise. To address this challenge, we present LAsset, a novel automated framework that leverages large language models (LLMs) to identify security assets from both hardware design specifications and register-transfer level (RTL) descriptions. The framework performs structural and semantic analysis to identify intra-module primary and secondary assets and derives inter-module relationships to systematically characterize security dependencies at the design level. Experimental results show that the proposed framework achieves high classification accuracy, reaching up to 90% recall rate in SoC design, and 93% recall rate in IP designs. This automation in asset identification significantly reduces manual overhead and supports a scalable path forward for secure hardware development.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02394", "categories": ["eess.SP", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2601.02394", "abs": "https://arxiv.org/abs/2601.02394", "authors": ["Yuan-Jie Chen"], "title": "Hydrodynamic Whispering: Enabling Near-Field Silent Communication via Artificial Lateral Line Arrays", "comment": "7 pages, 6 figures,1 table", "summary": "To address the imperative for covert underwater swarm coordination, this paper introduces \"Hydrodynamic Whispering,\" a near-field silent communication paradigm utilizing Artificial Lateral Line (ALL) arrays. Grounded in potential flow theory, we model the transmitter as an oscillating dipole source. The resulting pressure field exhibits steep nearfield attenuation (scaling with 1/r^2, naturally delimiting a secure \"communication bubble\" with intrinsic Low Probability of Interception (LPI) properties. We propose a transceiver architecture featuring a Binary Phase Shift Keying (BPSK) modulation scheme adapted for mechanical actuator inertia, coupled with a bio-inspired 24-sensor conformal array. To mitigate low Signal-to-Noise Ratio (SNR) in turbulent environments,a Spatio-Temporal Joint Processing framework incorporating Spatial Matched-Field Beamforming is developed. Simulation results demonstrate that the system achieves an array gain of approximately 13.8 dB and maintains a near-zero Bit Error Rate (BER) within the effective range. This study validates the feasibility of utilizing localized hydrodynamic pressure fluctuations for reliable and secure short-range underwater networking.", "AI": {"tldr": "\u901a\u8fc7\u5229\u7528\u8fd1\u573a\u6c34\u538b\u6ce2\u7684\u77ed\u7a0b\u4f4e\u622a\u83b7\u7279\u6027\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u3001\u53ef\u9760\u7684\u77ed\u8ddd\u79bb\u6c34\u4e0b\u901a\u4fe1\u3002", "motivation": "\u89e3\u51b3\u6c34\u4e0b\u9690\u853d\u7fa4\u4f53\u534f\u4f5c\u7684\u901a\u4fe1\u5b89\u5168\u4e0e\u566a\u58f0\u5e72\u6270\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u6f5c\u6d41\u7406\u8bba\uff0c\u5c06\u53d1\u5c04\u5668\u5efa\u6a21\u4e3a\u632f\u8361\u5076\u6781\u6e90\uff0c\u91c7\u7528BPSK\u8c03\u5236\u548c24\u4f20\u611f\u5668\u5f62\u6001\u5b66\u54cd\u5e94\u5f0fALL\u9635\u5217\uff0c\u7ed3\u5408\u7a7a\u95f4\u5339\u914d\u573a\u6ce2\u675f\u5f62\u6210\u7684\u65f6\u7a7a\u8054\u5408\u5904\u7406\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u5728\u6709\u6548\u8303\u56f4\u5185\u5f97\u5230\u7ea613.8 dB\u7684\u9635\u5217\u589e\u76ca\uff0c\u8bef\u7801\u7387\u51e0\u4e4e\u4e3a\u96f6\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\u5229\u7528\u8fd1\u573a\u9759\u9ed8\u538b\u529b\u6ce2\u53ef\u4ee5\u5b9e\u73b0\u77ed\u8ddd\u79bb\u6c34\u4e0b\u81ea\u5f8b\u7fa4\u4f53\u4f4e\u6982\u7387\u622a\u83b7\u7684\u901a\u8baf\uff1b\u7cfb\u7edf\u6c47\u805a\u4fe1\u566a\u6bd4\u53ef\u8fbe13.8 dB\uff0c\u8bef\u7801\u7387\u57fa\u672c\u4e3a\u96f6\u3002"}}
{"id": "2601.02390", "categories": ["cs.IT", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.02390", "abs": "https://arxiv.org/abs/2601.02390", "authors": ["Alex Thornton", "Ian Halliday", "Harry Saxton", "Xu Xu"], "title": "Breaking Rank - A Novel Unscented Kalman Filter for Parameter Estimations of a Lumped-Parameter Cardiovascular Model", "comment": null, "summary": "We make modifications to the unscented Kalman filter (UKF) which bestow almost complete practical identifiability upon a lumped-parameter cardiovascular model with 10 parameters and 4 output observables - a highly non-linear, stiff problem of clinical significance. The modifications overcome the challenging problems of rank deficiency when applying the UKF to parameter estimation. Rank deficiency usually means only a small subset of parameters can be estimated. Traditionally, pragmatic compromises are made, such as selecting an optimal subset of parameters for estimation and fixing non-influential parameters. Kalman filters are typically used for dynamical state tracking, to facilitate the control u at every time step. However, for the purpose of parameter estimation, this constraint no longer applies. Our modification has transformed the utility of UKF for the parameter estimation purpose, including minimally influential parameters, with excellent robustness (i.e., under severe noise corruption, challenging patho-physiology, and no prior knowledge of parameter distributions). The modified UKF algorithm is robust in recovering almost all parameters to over 98% accuracy, over 90% of the time, with a challenging target data set of 50, 10-parameter samples. We compare this to the original implementation of the UKF algorithm for parameter estimation and demonstrate a significant improvement.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02557", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.02557", "abs": "https://arxiv.org/abs/2601.02557", "authors": ["Emre Sariyildiz"], "title": "AMC26: VSSEA robust position control", "comment": null, "summary": "This paper presents robust position control strategies for the novel VSSEA. By employing a constructed state-space model, two control schemes are developed in a unified framework: a state-feedback controller and a sliding mode controller, both integrated with a second-order DOb. The proposed framework achieves high-performance motion control by precisely estimating and compensating for internal and external disturbances, while preserving the nominal dynamic response. Simulation results demonstrate that pole-placement-based controllers are highly sensitive to disturbances, whereas LQR-based controllers offer improved robustness at the expense of slower dynamics. By incorporating DOb, robustness is significantly enhanced without degrading time response, and the LQR controller can be tuned solely for performance optimization. Experimental results confirm that the proposed robust position controllers can be implemented in real world applications. These results highlight the effectiveness of the proposed approach and lay the foundation for future investigations on robust stability and performance under different stiffness settings.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02433", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02433", "abs": "https://arxiv.org/abs/2601.02433", "authors": ["Tao Xu", "Zhixin Hu", "Li Luo", "Momiao Xiong"], "title": "Physical Transformer", "comment": "38 pages, 2 figures", "summary": "Digital AI systems spanning large language models, vision models, and generative architectures that operate primarily in symbolic, linguistic, or pixel domains. They have achieved striking progress, but almost all of this progress lives in virtual spaces. These systems transform embeddings and tokens, yet do not themselves touch the world and rarely admit a physical interpretation. In this work we propose a physical transformer that couples modern transformer style computation with geometric representation and physical dynamics. At the micro level, attention heads, and feed-forward blocks are modeled as interacting spins governed by effective Hamiltonians plus non-Hamiltonian bath terms. At the meso level, their aggregated state evolves on a learned Neural Differential Manifold (NDM) under Hamiltonian flows and Hamilton, Jacobi, Bellman (HJB) optimal control, discretized by symplectic layers that approximately preserve geometric and energetic invariants. At the macro level, the model maintains a generative semantic workspace and a two-dimensional information-phase portrait that tracks uncertainty and information gain over a reasoning trajectory. Within this hierarchy, reasoning tasks are formulated as controlled information flows on the manifold, with solutions corresponding to low cost trajectories that satisfy geometric, energetic, and workspace-consistency constraints. On simple toy problems involving numerical integration and dynamical systems, the physical transformer outperforms naive baselines in stability and long-horizon accuracy, highlighting the benefits of respecting underlying geometric and Hamiltonian structure. More broadly, the framework suggests a path toward physical AI that unify digital reasoning with physically grounded manifolds, opening a route to more interpretable and potentially unified models of reasoning, control, and interaction with the real world.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u79cd\u5c06\u4f20\u7edfTransformer\u4e0e\u7269\u7406\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u76f8\u7ed3\u5408\u7684\u201c\u7269\u7406\u53d8\u538b\u5668\u201d\uff0c\u5728\u591a\u4e2a\u5c42\u9762\u5f15\u5165\u7269\u7406\u7ea6\u675f\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u66f4\u4f18\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\uff0c\u6697\u793a\u6570\u5b57\u4e0e\u7269\u7406\u63a8\u7406\u7684\u878d\u5408\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u89c4\u6a21AI\u5728\u865a\u62df\u7a7a\u95f4\u53d6\u5f97\u8fdb\u5c55\uff0c\u5374\u7f3a\u4e4f\u7269\u7406\u89e3\u91ca\u548c\u4e0e\u73b0\u5b9e\u4e16\u754c\u7684\u4ea4\u4e92\uff1b\u9700\u8981\u5c06\u6570\u5b57\u63a8\u7406\u4e0e\u7269\u7406\u52a8\u529b\u5b66\u7edf\u4e00\uff0c\u4ee5\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u9645\u9002\u7528\u6027\u3002", "method": "\u5728\u5fae\u89c2\u5c42\u9762\u5c06\u6ce8\u610f\u529b\u5934\u548c\u524d\u9988\u5757\u89c6\u4e3a\u76f8\u4e92\u4f5c\u7528\u81ea\u65cb\uff0c\u7528\u6709\u6548\u54c8\u5bc6\u987f\u91cf\u4e0e\u975e\u54c8\u5bc6\u987f\u6d74\u8026\u5408\uff1b\u5728\u4e2d\u89c2\u5c42\u9762\u5efa\u7acb\u5b66\u4e60\u7684\u795e\u7ecf\u5fae\u5206\u6d41\u5f62\uff08NDM\uff09\uff0c\u5728\u54c8\u5bc6\u987f\u6d41\u3001\u5e0c\u5c14\u4f2f\u7279-\u96c5\u53ef\u6bd4-\u8d1d\u5c14\u66fc\u6700\u4f18\u63a7\u5236\u4e0b\u6f14\u5316\uff1b\u5728\u5b8f\u89c2\u5c42\u9762\u7ef4\u62a4\u751f\u6210\u8bed\u4e49\u5de5\u4f5c\u7a7a\u95f4\u4e0e\u4e8c\u7ef4\u4fe1\u606f\u76f8\u4f4d\u56fe\uff1b\u901a\u8fc7\u5728\u6d41\u5f62\u4e0a\u63a7\u5236\u4fe1\u606f\u6d41\u6765\u89e3\u51b3\u63a8\u7406\u4efb\u52a1\uff0c\u5e76\u4f7f\u7528\u8f9b\u5c42\u4fdd\u6301\u51e0\u4f55\u53ca\u80fd\u91cf\u4e0d\u53d8\u3002", "result": "\u5728\u6570\u503c\u79ef\u5206\u4e0e\u52a8\u529b\u5b66\u7cfb\u7edf\u7684\u73a9\u5177\u5b9e\u9a8c\u4e2d\uff0c\u7269\u7406\u53d8\u538b\u5668\u5728\u7a33\u5b9a\u6027\u4e0e\u957f\u65f6\u57df\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u4f20\u7edf\u57fa\u51c6\uff0c\u8bc1\u660e\u9075\u5faa\u51e0\u4f55\u4e0e\u54c8\u5bc6\u987f\u7ed3\u6784\u7684\u76ca\u5904\u3002", "conclusion": "\u63d0\u51fa\u4e00\u79cd\u201c\u7269\u7406\u53d8\u538b\u5668\u201d\uff0c\u901a\u8fc7\u5728\u5fae\u89c2\u3001\u4e2d\u89c2\u548c\u5b8f\u89c2\u5c42\u9762\u5f15\u5165\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u548c\u51e0\u4f55\u8868\u793a\uff0c\u5c06\u6570\u5b57AI\u4e0e\u7269\u7406\u4e16\u754c\u5bf9\u63a5\uff1b\u5728\u7269\u7406\u7ea6\u675f\u4e0b\u5b9e\u73b0\u66f4\u7a33\u5b9a\u3001\u957f\u671f\u51c6\u786e\u7684\u63a8\u7406\uff1b\u5f00\u8f9f\u7edf\u4e00\u6570\u5b57\u4e0e\u7269\u7406\u63a8\u7406\u7684\u65b9\u5411\u3002"}}
{"id": "2601.02680", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02680", "abs": "https://arxiv.org/abs/2601.02680", "authors": ["Dinghong Song", "Zhiwei Xu", "Hai Wan", "Xibin Zhao", "Pengfei Su", "Dong Li"], "title": "Adversarial Contrastive Learning for LLM Quantization Attacks", "comment": "14 pages, 5 figures", "summary": "Model quantization is critical for deploying large language models (LLMs) on resource-constrained hardware, yet recent work has revealed severe security risks that benign LLMs in full precision may exhibit malicious behaviors after quantization. In this paper, we propose Adversarial Contrastive Learning (ACL), a novel gradient-based quantization attack that achieves superior attack effectiveness by explicitly maximizing the gap between benign and harmful responses probabilities. ACL formulates the attack objective as a triplet-based contrastive loss, and integrates it with a projected gradient descent two-stage distributed fine-tuning strategy to ensure stable and efficient optimization. Extensive experiments demonstrate ACL's remarkable effectiveness, achieving attack success rates of 86.00% for over-refusal, 97.69% for jailbreak, and 92.40% for advertisement injection, substantially outperforming state-of-the-art methods by up to 44.67%, 18.84%, and 50.80%, respectively.", "AI": {"tldr": "ACL\u662f\u4e00\u79cd\u68af\u5ea6\u5bf9\u6bd4\u5b66\u4e60\u91cf\u5316\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u4e09\u5143\u7ec4\u635f\u5931\u6700\u5927\u5316\u5584\u610f\u4e0e\u6076\u610f\u56de\u5e94\u6982\u7387\u5dee\u8ddd\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\u5206\u5e03\u5f0f\u5fae\u8c03\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u8fc7\u5ea6\u62d2\u7edd\u3001\u7834\u89e3\u7981\u4ee4\u548c\u5e7f\u544a\u6ce8\u5165\u7b49\u4efb\u52a1\u4e2d\u5927\u5e45\u63d0\u5347\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u5728\u5bf9\u8d44\u6e90\u53d7\u9650\u786c\u4ef6\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u91cf\u5316\u662f\u5fc5\u8981\u624b\u6bb5\uff0c\u4f46\u8fd1\u671f\u53d1\u73b0\u5168\u7cbe\u5ea6\u6a21\u578b\u5728\u91cf\u5316\u540e\u4f1a\u51fa\u73b0\u6076\u610f\u884c\u4e3a\uff0c\u8feb\u5207\u9700\u8981\u63ed\u793a\u4e0e\u5bf9\u6297\u6b64\u7c7b\u5b89\u5168\u98ce\u9669\u7684\u653b\u51fb\u624b\u6bb5\u3002", "method": "\u57fa\u4e8e\u68af\u5ea6\u7684\u91cf\u5316\u653b\u51fb\u2014\u2014Adversarial Contrastive Learning\uff08ACL\uff09\u4f7f\u7528\u4e09\u5143\u7ec4\u5bf9\u6bd4\u635f\u5931\uff0c\u5c06\u5584\u610f\u4e0e\u6709\u5bb3\u8f93\u51fa\u7684\u6982\u7387\u5dee\u8ddd\u6700\u5927\u5316\uff0c\u5e76\u7ed3\u5408\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\u7684\u4e24\u9636\u6bb5\u5206\u5e03\u5f0f\u5fae\u8c03\u7b56\u7565\uff0c\u7a33\u5b9a\u9ad8\u6548\u5730\u4f18\u5316\u653b\u51fb\u76ee\u6807\u3002", "result": "ACL\u5728\u4e09\u7c7b\u653b\u51fb\u4efb\u52a1\u4e2d\u7684\u6210\u529f\u7387\u5206\u522b\u8fbe\u523086.00%\uff08\u8fc7\u5ea6\u62d2\u7edd\uff09\u300197.69%\uff08\u7834\u89e3\u7981\u4ee4\uff09\u300192.40%\uff08\u5e7f\u544a\u6ce8\u5165\uff09\uff0c\u5728\u6700\u5927\u63d0\u5347\u5ea6\u4e0a\u5206\u522b\u6bd4\u73b0\u6709\u65b9\u6cd5\u9ad8\u51fa44.67%\u300118.84%\u548c50.80%\uff0c\u8bc1\u660e\u5176\u663e\u8457\u4f18\u8d8a\u6027\u3002", "conclusion": "ACL\u5c55\u73b0\u4e86\u91cf\u5316\u8fc7\u7a0b\u4e2d\u5b58\u5728\u7684\u5b89\u5168\u9690\u60a3\uff0c\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u7684\u68af\u5ea6\u653b\u51fb\u5728\u5404\u79cd\u6076\u610f\u4efb\u52a1\u4e0a\u5747\u663e\u8457\u63d0\u5347\u653b\u51fb\u6210\u529f\u7387\uff0c\u63d0\u793a\u5728\u90e8\u7f72LLM\u65f6\u9700\u8c28\u614e\u5904\u7406\u91cf\u5316\u7b56\u7565\u4e0e\u5b89\u5168\u9632\u62a4\u3002"}}
{"id": "2601.02608", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.02608", "abs": "https://arxiv.org/abs/2601.02608", "authors": ["Jay A. Wood"], "title": "Weights on finite fields and failures of the MacWilliams identities", "comment": "32 pages, 1 figure", "summary": "In the 1960s, MacWilliams proved that the Hamming weight enumerator of a linear code over a finite field completely determines, and is determined by, the Hamming weight enumerator of its dual code. In particular, if two linear codes have the same Hamming weight enumerator, then their dual codes have the same Hamming weight enumerator.\n  In contrast, there is a wide class of weights on finite fields whose weight enumerators have the opposite behavior: there exist two linear codes having the same weight enumerator, but their dual codes have different weight enumerators.", "AI": {"tldr": "\u9664\u4e86 Hamming \u6743\u91cd\u5916\uff0c\u8bb8\u591a\u6743\u91cd\u5bf9\u4e8e\u7ebf\u6027\u7801\u7684\u5bf9\u5076\u6027\u4e0d\u6ee1\u8db3 \u201c\u540c\u6743\u91cd\u5217\u4e3e \u2192 \u53cc\u7801\u540c\u6743\u91cd\u5217\u4e3e\u201d\u3002", "motivation": "\u63a2\u7a76\u4e0d\u540c\u6743\u91cd\u5b9a\u4e49\u5bf9\u7ebf\u6027\u7801\u5bf9\u5076\u7ed3\u6784\u7684\u5f71\u54cd\uff0c\u68c0\u9a8c MacWilliams \u5bf9\u5076\u6027\u662f\u5426\u666e\u904d\u9002\u7528\u4e8e\u6240\u6709\u6743\u91cd\uff0c\u6216\u4ec5\u9650\u4e8e Hamming \u6743\u91cd\u3002", "method": "\u5728 1960 \u5e74\u4ee3 MacWilliams \u7684\u7ecf\u5178\u7ed3\u679c\u57fa\u7840\u4e0a\uff0c\u4f5c\u8005\u7814\u7a76\u4e86\u5e7f\u6cdb\u7684\u6709\u9650\u57df\u6743\u91cd\u5b9a\u4e49\uff0c\u5206\u6790\u5404\u81ea\u6743\u91cd\u679a\u4e3e\u51fd\u6570\u7684\u5bf9\u5076\u6027\u5173\u7cfb\uff0c\u5e76\u6784\u9020\u5177\u4f53\u7ebf\u6027\u7801\u5b9e\u4f8b\uff0c\u4ee5\u8bf4\u660e\u53cc\u7801\u6743\u91cd\u679a\u4e3e\u7684\u5dee\u5f02\u3002", "result": "\u8bc1\u660e\u5b58\u5728\u5927\u91cf\u6743\u91cd\u7cfb\u7edf\uff0c\u5176\u4e2d\u76f8\u540c\u6743\u91cd\u5217\u4e3e\u7684\u7ebf\u6027\u7801\u5176\u5bf9\u5076\u7801\u7684\u6743\u91cd\u5217\u4e3e\u4e0d\u76f8\u540c\uff0c\u5e76\u7ed9\u51fa\u4e86\u793a\u4f8b\u4e0e\u7406\u8bba\u4f9d\u636e\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u6307\u51fa\uff0c\u5bf9\u67d0\u4e9b\u7279\u5b9a\u52a0\u6743\u65b9\u6848\uff08\u9664\u6c49\u660e\u6743\u91cd\u5916\uff09\uff0c\u5373\u4fbf\u4e24\u4e2a\u7ebf\u6027\u7801\u5177\u6709\u76f8\u540c\u7684\u6743\u91cd\u5217\u4e3e\uff0c\u5b83\u4eec\u7684\u53cc\u7801\u7684\u6743\u91cd\u5217\u4e3e\u4e5f\u53ef\u80fd\u4e0d\u540c\uff0c\u4ece\u800c\u4e0e MacWilliams \u5b9a\u7406\u6240\u9884\u793a\u7684 Hamming \u6743\u91cd\u6027\u8d28\u5f62\u6210\u5bf9\u6bd4\u3002"}}
{"id": "2601.02560", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.02560", "abs": "https://arxiv.org/abs/2601.02560", "authors": ["Emre Sariyildiz"], "title": "AMC26: High-performance DOb for robust position control", "comment": null, "summary": "This paper presents a new HPDOb that significantly improves disturbance estimation accuracy and robustness in motion control systems, surpassing the capabilities of conventional DObs. The proposed observer is analysed and synthesised in the discrete-time domain, providing a realistic representation of their dynamic behaviour and enabling enhanced controller design for practical applications. The core contribution of the HPDOb is a novel synthesis method that incorporates higher-order truncation error dynamics into disturbance estimation. Unlike conventional DObs, which are limited to zero-order truncation error, the HPDOb achieves first-order truncation error, yielding markedly improved estimation accuracy and robustness against disturbances in motion control systems. Simulation and experiments verify the stability and performance of HPDOb.", "AI": {"tldr": "\u63d0\u51faHPDOb\uff0c\u5f15\u5165\u4e00\u9636\u622a\u65ad\u8bef\u5dee\u52a8\u529b\u5b66\uff0c\u5728\u79bb\u6563\u65f6\u57df\u901a\u8fc7\u5206\u6790\u5408\u6210\u5b9e\u73b0\uff0c\u66f4\u7cbe\u786e\u4f30\u8ba1\u6270\u52a8\uff0c\u9a8c\u8bc1\u5b9e\u9a8c\u8bc1\u660e\u5176\u8868\u73b0\u5728\u8fd0\u52a8\u63a7\u5236\u7cfb\u7edf\u4e2d\u4f18\u4e8e\u4f20\u7edf\u89c2\u6d4b\u5668\u3002", "motivation": "\u4f20\u7edfDObs\u4ec5\u8003\u8651\u96f6\u9636\u622a\u65ad\u8bef\u5dee\uff0c\u9650\u5236\u4e86\u6270\u52a8\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u4e9f\u9700\u66f4\u7cbe\u786e\u7684\u89c2\u6d4b\u65b9\u6cd5\u4ee5\u63d0\u5347\u63a7\u5236\u7cfb\u7edf\u9c81\u68d2\u6027\u3002", "method": "\u5728\u79bb\u6563\u65f6\u57df\u4e0b\u5bf9HPDOb\u8fdb\u884c\u5206\u6790\u4e0e\u5408\u6210\uff0c\u5e76\u5f15\u5165\u4e00\u9636\u622a\u65ad\u8bef\u5dee\u52a8\u529b\u5b66\uff0c\u6784\u5efa\u9ad8\u9636\u8bef\u5dee\u6a21\u578b\u4e0e\u89c2\u6d4b\u5668\u589e\u76ca\u3002", "result": "\u4eff\u771f\u4e0e\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793aHPDOb\u5728\u7a33\u5b9a\u6027\u3001\u4f30\u8ba1\u7cbe\u5ea6\u548c\u6297\u6270\u6027\u80fd\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edfDObs\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u7684\u9ad8\u9636\u622a\u65ad\u8bef\u5dee\u52a8\u529b\u5b66\u52a0\u6743\u6270\u52a8\u89c2\u6d4b\u5668\uff08HPDOb\uff09\u663e\u8457\u63d0\u5347\u4e86\u8fd0\u52a8\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u6270\u52a8\u4f30\u8ba1\u7cbe\u5ea6\u4e0e\u9c81\u68d2\u6027\uff0c\u4f18\u4e8e\u4f20\u7edf\u89c2\u6d4b\u5668\u3002"}}
{"id": "2601.02720", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02720", "abs": "https://arxiv.org/abs/2601.02720", "authors": ["Yuqiao Xu", "Mina Namazi", "Sahith Reddy Jalapally", "Osama Zafar", "Youngjin Yoo", "Erman Ayday"], "title": "Privacy-Preserving AI-Enabled Decentralized Learning and Employment Records System", "comment": null, "summary": "Learning and Employment Record (LER) systems are emerging as critical infrastructure for securely compiling and sharing educational and work achievements. Existing blockchain-based platforms leverage verifiable credentials but typically lack automated skill-credential generation and the ability to incorporate unstructured evidence of learning. In this paper,a privacy-preserving, AI-enabled decentralized LER system is proposed to address these gaps. Digitally signed transcripts from educational institutions are accepted, and verifiable self-issued skill credentials are derived inside a trusted execution environment (TEE) by a natural language processing pipeline that analyzes formal records (e.g., transcripts, syllabi) and informal artifacts. All verification and job-skill matching are performed inside the enclave with selective disclosure, so raw credentials and private keys remain enclave-confined. Job matching relies solely on attested skill vectors and is invariant to non-skill resume fields, thereby reducing opportunities for screening bias.The NLP component was evaluated on sample learner data; the mapping follows the validated Syllabus-to-O*NET methodology,and a stability test across repeated runs observed <5% variance in top-ranked skills. Formal security statements and proof sketches are provided showing that derived credentials are unforgeable and that sensitive information remains confidential. The proposed system thus supports secure education and employment credentialing, robust transcript verification,and automated, privacy-preserving skill extraction within a decentralized framework.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eTEE\u7684\u533a\u5757\u94feLER\uff0c\u81ea\u52a8\u4ece\u7ed3\u6784\u5316\u4e0e\u975e\u7ed3\u6784\u5316\u5b66\u4e60\u6750\u6599\u4e2d\u62bd\u53d6\u9690\u79c1\u5b89\u5168\u7684\u6280\u80fd\u51ed\u8bc1\uff0c\u5b9e\u73b0\u53ef\u4fe1\u5b66\u5386\u9a8c\u8bc1\u4e0e\u65e0\u504f\u804c\u4e1a\u5339\u914d\u3002", "motivation": "\u4f20\u7edf\u533a\u5757\u94fe\u5b66\u4e60\u4e0e\u5c31\u4e1a\u8bb0\u5f55\u7cfb\u7edf\u7f3a\u4e4f\u81ea\u52a8\u5316\u6280\u80fd\u51ed\u8bc1\u751f\u6210\u53ca\u5bf9\u975e\u7ed3\u6784\u5316\u5b66\u4e60\u8bc1\u636e\u7684\u5904\u7406\uff0c\u96be\u4ee5\u6ee1\u8db3\u5b8c\u6574\u53ef\u4fe1\u7684\u6559\u80b2\u4e0e\u804c\u4e1a\u5339\u914d\u9700\u6c42\u3002", "method": "\u91c7\u7528\u9690\u79c1\u4fdd\u62a4\u7684AI\u9a71\u52a8\u53bb\u4e2d\u5fc3\u5316LER\uff0c\u5229\u7528\u53ef\u4fe1\u6267\u884c\u73af\u5883TEE\u5185\u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff0c\u5c06\u6b63\u5f0f\u8bb0\u5f55\u4e0e\u975e\u6b63\u5f0f\u8bc1\u636e\u8f6c\u6362\u4e3a\u53ef\u9a8c\u8bc1\u7684\u81ea\u7b7e\u540d\u6280\u80fd\u51ed\u8bc1\uff1b\u6240\u6709\u9a8c\u8bc1\u4e0e\u804c\u4f4d\u5339\u914d\u4ea6\u5728\u9694\u79bb\u533a\u5b8c\u6210\uff0c\u4fdd\u8bc1\u51ed\u8bc1\u4e0e\u79c1\u94a5\u5b89\u5168\u3002", "result": "\u5728\u6837\u672c\u5b66\u4e60\u8005\u6570\u636e\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u6620\u5c04\u9075\u5faa\u7ecf\u9a8c\u8bc1\u7684\u8bfe\u7a0b\u5230O*NET\u65b9\u6cd5\uff0c\u91cd\u590d\u5b9e\u9a8c\u7a33\u5b9a\u6027<5%\uff1b\u901a\u8fc7\u5f62\u5f0f\u5316\u5b89\u5168\u8bf4\u660e\u548c\u8bc1\u660e\uff0c\u8bc1\u660e\u51ed\u8bc1\u4e0d\u53ef\u4f2a\u9020\u4e14\u654f\u611f\u4fe1\u606f\u4fdd\u6301\u673a\u5bc6\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5b9e\u73b0\u4e86\u5b89\u5168\u7684\u6559\u80b2\u4e0e\u5c31\u4e1a\u51ed\u8bc1\u5316\u3001\u7a33\u5065\u7684\u6210\u7ee9\u5355\u9a8c\u8bc1\u4ee5\u53ca\u81ea\u52a8\u5316\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u6280\u80fd\u63d0\u53d6\uff0c\u4e3a\u53bb\u4e2d\u5fc3\u5316\u7684\u51ed\u8bc1\u751f\u6001\u63d0\u4f9b\u4e86\u5b8c\u6574\u95ed\u73af\u3002"}}
{"id": "2601.02802", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.02802", "abs": "https://arxiv.org/abs/2601.02802", "authors": ["Viswanathan Ramachandran"], "title": "State-Dependent Fading Gaussian Channel with Common Reconstruction Constraints", "comment": null, "summary": "The task of jointly communicating a message and reconstructing a common estimate of the channel state is examined for a fading Gaussian model with additive state interference. The state is an independent and identically distributed Gaussian sequence known noncausally at the transmitter, and the instantaneous fading coefficient is perfectly known at both the transmitter and the receiver. The receiver is required to decode the transmitted message and, in addition, reconstruct the state under a common reconstruction constraint ensuring that its estimate coincides with that at the transmitter. A complete characterization of the optimal rate distortion tradeoff region for this setting is the main result of our work. The analytical results are also validated through numerical examples illustrating the rate distortion and power distortion tradeoffs.", "AI": {"tldr": "\u5728\u5df2\u77e5\u72b6\u6001\u5e72\u6270\u7684\u8870\u843d\u9ad8\u65af\u901a\u4fe1\u6a21\u578b\u4e2d\uff0c\u672c\u6587\u5f97\u5230\u5b8c\u6574\u7684\u6700\u4f18\u7387\u5931\u771f\u533a\u57df\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u793a\u4f8b\u9a8c\u8bc1\u4e86\u7ed3\u679c\u3002", "motivation": "\u63a2\u7a76\u5728\u65e2\u8981\u89e3\u7801\u6d88\u606f\u53c8\u8981\u5171\u540c\u91cd\u6784\u901a\u9053\u72b6\u6001\u7684\u65e0\u7ebf\u901a\u4fe1\u573a\u666f\uff0c\u5c24\u5176\u662f\u5e26\u6709\u9ad8\u65af\u72b6\u6001\u5e72\u6270\u7684\u8870\u843d\u6a21\u578b\u4e2d\uff0c\u53cc\u65b9\u5982\u4f55\u534f\u540c\u64cd\u4f5c\u4ee5\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u4fe1\u606f\u8bba\u5206\u6790\uff0c\u6784\u9020\u6700\u4f18\u7387\u5931\u771f\u5e73\u8861\u533a\u57df\uff0c\u5e76\u5229\u7528\u6570\u503c\u4f18\u5316\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\u3002", "result": "\u7ed9\u51fa\u4e86\u8be5\u8870\u843d\u9ad8\u65af\u6a21\u578b\u4e0b\u5b8c\u6574\u7684\u6700\u4f18\u7387\u5931\u771f\u533a\u57df\uff1b\u6570\u503c\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u7387\u5931\u771f\u4e0e\u529f\u7387\u5931\u771f\u4e4b\u95f4\u7684\u6298\u8877\u3002", "conclusion": "\u672c\u6587\u5b9e\u73b0\u4e86\u5728\u5df2\u77e5\u72b6\u6001\u7684\u53d1\u5c04\u7aef\u4e0e\u51b2\u51fb\u5df2\u77e5\u7684\u63a5\u6536\u7aef\u5171\u540c\u89e3\u7801\u6d88\u606f\u4e0e\u72b6\u6001\u91cd\u6784\u7684\u6700\u4f18\u7406\u8bba\u6781\u9650\uff0c\u4e3a\u7c7b\u4f3c\u901a\u4fe1\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u57fa\u51c6\u3002"}}
{"id": "2601.02451", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02451", "abs": "https://arxiv.org/abs/2601.02451", "authors": ["Subhankar Mishra"], "title": "mHC-GNN: Manifold-Constrained Hyper-Connections for Graph Neural Networks", "comment": null, "summary": "Graph Neural Networks (GNNs) suffer from over-smoothing in deep architectures and expressiveness bounded by the 1-Weisfeiler-Leman (1-WL) test. We adapt Manifold-Constrained Hyper-Connections (\\mhc)~\\citep{xie2025mhc}, recently proposed for Transformers, to graph neural networks. Our method, mHC-GNN, expands node representations across $n$ parallel streams and constrains stream-mixing matrices to the Birkhoff polytope via Sinkhorn-Knopp normalization. We prove that mHC-GNN exhibits exponentially slower over-smoothing (rate $(1-\u03b3)^{L/n}$ vs.\\ $(1-\u03b3)^L$) and can distinguish graphs beyond 1-WL. Experiments on 10 datasets with 4 GNN architectures show consistent improvements. Depth experiments from 2 to 128 layers reveal that standard GNNs collapse to near-random performance beyond 16 layers, while mHC-GNN maintains over 74\\% accuracy even at 128 layers, with improvements exceeding 50 percentage points at extreme depths. Ablations confirm that the manifold constraint is essential: removing it causes up to 82\\% performance degradation. Code is available at \\href{https://github.com/smlab-niser/mhc-gnn}{https://github.com/smlab-niser/mhc-gnn}", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02874", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.02874", "abs": "https://arxiv.org/abs/2601.02874", "authors": ["Mina Shahbazifar", "Zolfa Zeinalpour-Yazdi", "Matthias Hollick", "Arash Asadi", "Vahid Jamali"], "title": "Transparent and Resilient Activity Recognition via Attention-Based Distributed Radar Sensing", "comment": null, "summary": "Distributed radar sensors enable robust human activity recognition. However, scaling the number of coordinated nodes introduces challenges in feature extraction from large datasets, and transparent data fusion. We propose an end-to-end framework that operates directly on raw radar data. Each radar node employs a lightweight 2D Convolutional Neural Network (CNN) to extract local features. A self-attention fusion block then models inter-node relationships and performs adaptive information fusion. Local feature extraction reduces the input dimensionality by up to 480x. This significantly lowers communication overhead and latency. The attention mechanism provides inherent interpretability by quantifying the contribution of each radar node. A hybrid supervised contrastive loss further improves feature separability, especially for fine-grained and imbalanced activity classes. Experiments on real-world distributed Ultra Wide Band (UWB) radar data demonstrate that the proposed method reduces model complexity by 70.8\\%, while achieving higher average accuracy than baseline approaches. Overall, the framework enables transparent, efficient, and low-overhead distributed radar sensing.", "AI": {"tldr": "\u7aef\u5230\u7aef\u96f7\u8fbe\u6846\u67b6\uff1a\u8f7b\u91cfCNN+\u81ea\u6ce8\u610f\u529b+\u76d1\u7763\u5bf9\u6bd4\uff0c\u964d\u4f4e\u6a21\u578b70.8%\uff0c\u63d0\u9ad8\u51c6\u786e\u5ea6\uff0c\u964d\u4f4e\u901a\u4fe1\u5ef6\u8fdf\u5e76\u89e3\u91ca\u8282\u70b9\u8d21\u732e\u3002", "motivation": "\u4f7f\u7528\u5206\u5e03\u5f0f\u96f7\u8fbe\u4f20\u611f\u5668\u5b9e\u73b0\u9c81\u68d2\u7684\u4eba\u7c7b\u884c\u4e3a\u8bc6\u522b\uff0c\u4f46\u5728\u8282\u70b9\u6570\u91cf\u6269\u5927\u65f6\uff0c\u7279\u5f81\u63d0\u53d6\u4e0e\u900f\u660e\u6570\u636e\u878d\u5408\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51fa\u7aef\u5230\u7aef\u6846\u67b6\uff1a\u6bcf\u4e2a\u96f7\u8fbe\u8282\u70b9\u91c7\u7528\u8f7b\u91cf\u5316\u4e8c\u7ef4CNN\u63d0\u53d6\u5c40\u90e8\u7279\u5f81\uff0c\u968f\u540e\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u878d\u5408\u5757\u5efa\u6a21\u8282\u70b9\u95f4\u5173\u7cfb\u5e76\u81ea\u9002\u5e94\u878d\u5408\u4fe1\u606f\u3002\u5c40\u90e8\u7279\u5f81\u63d0\u53d6\u53ef\u5c06\u8f93\u5165\u7ef4\u5ea6\u964d\u4f4e\u591a\u8fbe480\u500d\uff1b\u81ea\u6ce8\u610f\u529b\u673a\u5236\u63d0\u4f9b\u900f\u660e\u89e3\u91ca\u6027\uff1b\u6df7\u5408\u76d1\u7763\u5bf9\u6bd4\u635f\u5931\u63d0\u5347\u7279\u5f81\u5206\u79bb\u5ea6\uff0c\u5c24\u5176\u5bf9\u7ec6\u7c92\u5ea6\u4e0e\u4e0d\u5e73\u8861\u7c7b\u522b\u3002", "result": "\u5728\u771f\u5b9e UWB \u96f7\u8fbe\u6570\u636e\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5c06\u6a21\u578b\u590d\u6742\u5ea6\u964d\u4f4e70.8%\uff0c\u540c\u65f6\u5728\u5e73\u5747\u51c6\u786e\u7387\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u900f\u660e\u3001\u9ad8\u6548\u3001\u4f4e\u5f00\u9500\u7684\u5206\u5e03\u5f0f\u96f7\u8fbe\u611f\u77e5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u6027\u80fd\u3002"}}
{"id": "2601.02585", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.02585", "abs": "https://arxiv.org/abs/2601.02585", "authors": ["Otman Basir"], "title": "AI Social Responsibility as Reachability: Execution-Level Semantics for the Social Responsibility Stack", "comment": null, "summary": "Artificial intelligence systems are increasingly embedded as persistent, closed-loop components within cyber-physical, social, and institutional processes. Rather than producing isolated outputs, such systems operate continuously under feedback, adaptation, and scale, reshaping physical flows, human behavior, and institutional practice over time. In these settings, socially unacceptable outcomes rarely arise from singular faults or explicit policy violations. Instead, they emerge through cumulative execution trajectories enabled by repetition, concurrency, and feedback.\n  This paper advances the formal foundation of the Social Responsibility Stack (SRS) by making its central requirement explicit: responsibility is fundamentally a reachability property of system execution. A system is responsible iff its execution semantics prevent entry into inadmissible global configurations, regardless of local performance gains or optimization objectives. Responsibility failures are therefore not objective-level errors, but execution-level failures of trajectory control.\n  To operationalize this perspective, we introduce Petri nets as an execution-level formalism for responsible autonomous systems. We show how SRS value commitments correspond to forbidden markings, safeguards to structural constraints on transition firing, auditing to monitoring of reachability pressure, and governance to legitimate modification of execution structure. Embedding Petri-net reachability within the SRS architecture internalizes responsibility as a structural invariant rather than an external objective or post-hoc mechanism.\n  These results establish the Social Responsibility Stack as an executable responsibility architecture and position reachability-based execution semantics as a necessary foundation for responsible autonomy in feedback-rich cyber-physical and socio-technical systems.", "AI": {"tldr": "\u672c\u8bba\u6587\u5c06\u793e\u4f1a\u8d23\u4efb\u5b9a\u4e49\u4e3a\u7cfb\u7edf\u6267\u884c\u7684\u53ef\u8fbe\u6027\u5c5e\u6027\uff0c\u4f7f\u7528 Petri \u7f51\u5b9e\u73b0\u5e76\u9a8c\u8bc1 SRS\u2014\u2014\u4e00\u79cd\u57fa\u4e8e\u7ed3\u6784\u7ea6\u675f\u7684\u53ef\u6267\u884c\u8d23\u4efb\u67b6\u6784\u3002", "motivation": "\u4f20\u7edfAI\u7cfb\u7edf\u867d\u5728\u95ed\u73af\u73af\u5883\u4e2d\u8fd0\u884c\uff0c\u4f46\u793e\u4f1a\u4e0d\u53ef\u63a5\u53d7\u7684\u7ed3\u679c\u5f80\u5f80\u6e90\u4e8e\u91cd\u590d\u3001\u5e76\u53d1\u4e0e\u53cd\u9988\u5bfc\u81f4\u7684\u7d2f\u79ef\u6267\u884c\u8f68\u8ff9\uff0c\u800c\u975e\u5355\u4e00\u9519\u8bef\uff1b\u8feb\u5207\u9700\u8981\u5c06\u8d23\u4efb\u5d4c\u5165\u7cfb\u7edf\u6267\u884c\u5c42\u9762\uff0c\u5f62\u6210\u7ed3\u6784\u5316\u7ea6\u675f\u3002", "method": "\u901a\u8fc7\u6b63\u5f0f\u5316\u8d23\u4efb\u4e3a\u53ef\u8fbe\u6027\u5c5e\u6027\uff0c\u5229\u7528Petri\u7f51\u4f5c\u4e3a\u6267\u884c\u5c42\u5f62\u5f0f\u5316\u5de5\u5177\uff0c\u5c06SRS\u4e2d\u7684\u4ef7\u503c\u627f\u8bfa\u6620\u5c04\u4e3a\u7981\u6b62\u6807\u8bb0\uff0c\u5b89\u5168\u4fdd\u969c\u6620\u5c04\u4e3a\u7ed3\u6784\u7ea6\u675f\uff0c\u5ba1\u8ba1\u5bf9\u5e94\u4e8e\u53ef\u8fbe\u6027\u76d1\u6d4b\uff0c\u6cbb\u7406\u5bf9\u5e94\u4e8e\u6267\u884c\u7ed3\u6784\u7684\u5408\u6cd5\u4fee\u6539\u3002", "result": "\u8bc1\u660e\u4e86\u5c06SRS\u4e0ePetri\u7f51\u7ed3\u5408\u5373\u53ef\u5185\u5316\u8d23\u4efb\u4e3a\u7ed3\u6784\u4e0d\u53d8\uff0c\u5e76\u80fd\u901a\u8fc7\u53ef\u8fbe\u6027\u5206\u6790\u5b9e\u73b0\u6743\u9650\u9650\u5236\u3001\u76d1\u63a7\u548c\u6cbb\u7406\uff0c\u4ece\u800c\u6784\u5efa\u53ef\u6267\u884c\u7684\u8d23\u4efb\u67b6\u6784\u3002", "conclusion": "\u8d23\u4efb\u5e94\u88ab\u89c6\u4e3a\u7cfb\u7edf\u6267\u884c\u7684\u53ef\u8fbe\u6027\u5c5e\u6027\uff0c\u800c\u975e\u4ec5\u4ec5\u7684\u76ee\u6807\u6c34\u5e73\u9519\u8bef\uff1b\u901a\u8fc7\u5728Petri\u7f51\u4e2d\u5c06SRS\u5b9a\u4e49\u4e3a\u7ed3\u6784\u4e0d\u53d8\u6027\uff0c\u53ef\u5b9e\u73b0\u53ef\u6267\u884c\u4e14\u53ef\u9a8c\u8bc1\u7684\u793e\u4f1a\u8d23\u4efb\u4f53\u7cfb\u3002"}}
{"id": "2601.02382", "categories": ["cs.NI", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02382", "abs": "https://arxiv.org/abs/2601.02382", "authors": ["Nathan Conger", "Nathan Scollar", "Kemal Davaslioglu", "Yalin E. Sagduyu", "Sastry Kompella"], "title": "How to Discover Knowledge for FutureG: Contextual RAG and LLM Prompting for O-RAN", "comment": null, "summary": "We present a retrieval-augmented question answering framework for 5G/6G networks, where the Open Radio Access Network (O-RAN) has become central to disaggregated, virtualized, and AI-driven wireless systems. While O-RAN enables multi-vendor interoperability and cloud-native deployments, its fast-changing specifications and interfaces pose major challenges for researchers and practitioners. Manual navigation of these complex documents is labor-intensive and error-prone, slowing system design, integration, and deployment. To address this challenge, we adopt Contextual Retrieval-Augmented Generation (Contextual RAG), a strategy in which candidate answer choices guide document retrieval and chunk-specific context to improve large language model (LLM) performance. This improvement over traditional RAG achieves more targeted and context-aware retrieval, which improves the relevance of documents passed to the LLM, particularly when the query alone lacks sufficient context for accurate grounding. Our framework is designed for dynamic domains where data evolves rapidly and models must be continuously updated or redeployed, all without requiring LLM fine-tuning. We evaluate this framework using the ORANBenchmark-13K dataset, and compare three LLMs, namely, Llama3.2, Qwen2.5-7B, and Qwen3.0-4B, across both Direct Question Answering (Direct Q&A) and Chain-of-Thought (CoT) prompting strategies. We show that Contextual RAG consistently improves accuracy over standard RAG and base prompting, while maintaining competitive runtime and CO2 emissions. These results highlight the potential of Contextual RAG to serve as a scalable and effective solution for domain-specific Q&A in ORAN and broader 5G/6G environments, enabling more accurate interpretation of evolving standards while preserving efficiency and sustainability.", "AI": {"tldr": "Contextual RAG \u901a\u8fc7\u7b54\u6848\u5f15\u5bfc\u68c0\u7d22\u3001\u589e\u5f3a\u4e0a\u4e0b\u6587\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u63d0\u5347 O\u2011RAN \u4e0e 5G/6G \u95ee\u7b54\u51c6\u786e\u7387\uff0c\u5e76\u4fdd\u6301\u6548\u7387\u4e0e\u53ef\u6301\u7eed\u6027\u3002", "motivation": "O\u2011RAN \u89c4\u8303\u548c\u63a5\u53e3\u5feb\u901f\u6f14\u5316\uff0c\u624b\u5de5\u6d4f\u89c8\u6f2b\u957f\u6587\u6863\u6210\u672c\u9ad8\u4e14\u6613\u51fa\u9519\uff0c\u963b\u788d\u7cfb\u7edf\u8bbe\u8ba1\u4e0e\u90e8\u7f72\u3002", "method": "\u5229\u7528\u5019\u9009\u7b54\u6848\u5f15\u5bfc\u6587\u6863\u68c0\u7d22\uff0c\u5e76\u4e3a LLM \u63d0\u4f9b\u7247\u6bb5\u7ea7\u4e0a\u4e0b\u6587\u7684 Contextual RAG \u65b9\u6cd5\uff0c\u65e0\u9700 LLM \u5fae\u8c03\u5373\u53ef\u5728\u5feb\u901f\u6f14\u53d8\u7684\u6280\u672f\u57df\u4e2d\u6301\u7eed\u66f4\u65b0\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "result": "\u5728 ORANBenchmark\u201113K \u6570\u636e\u96c6\u4e0a\uff0c\u4e09\u79cd LLM\uff08Llama3.2\u3001Qwen2.5\u20117B\u3001Qwen3.0\u20114B\uff09\u5728 Direct Q&A \u4e0e CoT \u63d0\u793a\u4e0b\uff0cContextual RAG \u4e00\u76f4\u4f18\u4e8e\u6807\u51c6 RAG \u4e0e\u57fa\u7840\u63d0\u793a\uff0c\u4e14\u8fd0\u884c\u65f6\u4e0e CO2 \u6392\u653e\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "Contextual RAG \u4e3a O-RAN \u4e0e 5G/6G \u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u4e14\u53ef\u6301\u7eed\u7684\u9886\u57df\u95ee\u7b54\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u7387\u5e76\u4fdd\u6301\u4e86\u5408\u7406\u7684\u8fd0\u884c\u65f6\u548c\u78b3\u6392\u653e\u6c34\u5e73\u3002"}}
{"id": "2601.02499", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02499", "abs": "https://arxiv.org/abs/2601.02499", "authors": ["Xingyu Xu", "Ziyi Zhang", "Yorie Nakahira", "Guannan Qu", "Yuejie Chi"], "title": "Polynomial Convergence of Riemannian Diffusion Models", "comment": null, "summary": "Diffusion models have demonstrated remarkable empirical success in the recent years and are considered one of the state-of-the-art generative models in modern AI. These models consist of a forward process, which gradually diffuses the data distribution to a noise distribution spanning the whole space, and a backward process, which inverts this transformation to recover the data distribution from noise. Most of the existing literature assumes that the underlying space is Euclidean. However, in many practical applications, the data are constrained to lie on a submanifold of Euclidean space. Addressing this setting, De Bortoli et al. (2022) introduced Riemannian diffusion models and proved that using an exponentially small step size yields a small sampling error in the Wasserstein distance, provided the data distribution is smooth and strictly positive, and the score estimate is $L_\\infty$-accurate. In this paper, we greatly strengthen this theory by establishing that, under $L_2$-accurate score estimate, a {\\em polynomially small stepsize} suffices to guarantee small sampling error in the total variation distance, without requiring smoothness or positivity of the data distribution. Our analysis only requires mild and standard curvature assumptions on the underlying manifold. The main ingredients in our analysis are Li-Yau estimate for the log-gradient of heat kernel, and Minakshisundaram-Pleijel parametrix expansion of the perturbed heat equation. Our approach opens the door to a sharper analysis of diffusion models on non-Euclidean spaces.", "AI": {"tldr": "\u672c\u6587\u6539\u8fdb Riemannian \u6269\u6563\u6a21\u578b\u7406\u8bba\uff1a\u53ea\u8981\u5206\u6570\u4f30\u8ba1 $L_{2}$ \u7cbe\u5ea6\uff0c\u5e76\u5728\u8f7b\u5ea6\u66f2\u7387\u4e0b\uff0c\u8db3\u4ee5\u7528\u591a\u9879\u5f0f\u9636\u6b65\u957f\u4fdd\u8bc1\u603b\u53d8\u5dee\u8bef\u5dee\u5c0f\uff0c\u65e0\u9700\u5149\u6ed1\u6216\u6b63\u6027\u5047\u8bbe\uff0c\u65b9\u6cd5\u57fa\u4e8e\u70ed\u6838\u4e0e\u53c2\u6570\u5c55\u5f00\u3002", "motivation": "\u5df2\u6709\u6587\u732e\u591a\u5728\u6b27\u6c0f\u7a7a\u95f4\u7814\u7a76\u6269\u6563\u6a21\u578b\uff0c\u4e14\u9700\u4f7f\u7528\u6307\u6570\u7ea7\u5c0f\u6b65\u957f\u3001\u5149\u6ed1\u6b63\u5206\u5e03\u7b49\u4e25\u683c\u5047\u8bbe\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\u6570\u636e\u5f80\u5f80\u4f4d\u4e8e\u6b27\u6c0f\u5b50\u6d41\u5f62\uff0c\u4e14\u5206\u5e03\u53ef\u80fd\u975e\u5149\u6ed1\u6216\u975e\u6b63\u3002\u4e3a\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u9002\u5e94\u66f4\u5e7f\u6cdb\u573a\u666f\uff0c\u9700\u8981\u5728\u66f4\u5f31\u5047\u8bbe\u4e0b\u8bc1\u660e\u6269\u6563\u6a21\u578b\u7684\u91c7\u6837\u8bef\u5dee\u53ef\u63a7\u3002", "method": "\u672c\u7814\u7a76\u57fa\u4e8e Li\u2011Yau \u5bf9\u70ed\u6838\u5bf9\u6570\u68af\u5ea6\u7684\u4f30\u8ba1\u4ee5\u53ca Minakshisundaram\u2011Pleijel \u7684\u53c2\u6570\u5316\u5c55\u5f00\uff0c\u5bf9 Riemannian \u7a7a\u95f4\u4e2d\u7684\u53d7\u6270\u70ed\u65b9\u7a0b\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u5e76\u7ed3\u5408 $L_{2}$-\u7cbe\u5ea6\u7684\u5206\u6570\u4f30\u8ba1\uff0c\u5229\u7528\u70ed\u884c\u8fdb\u6280\u672f\u63a8\u5bfc\u91c7\u6837\u8bef\u5dee\u4e0a\u754c\u3002", "result": "\u8bc1\u660e\uff1a\u5728\u6ee1\u8db3 $L_{2}$-\u5206\u6570\u4f30\u8ba1\u3001\u4ec5\u6709\u8f7b\u5ea6\u66f2\u7387\u7ea6\u675f\u7684 Riemannian \u6d41\u5f62\u4e0a\uff0c\u91c7\u7528\u591a\u9879\u5f0f\u9636\u6b65\u957f\u5373\u53ef\u4fdd\u8bc1\u91c7\u6837\u8bef\u5dee\uff08\u603b\u53d8\u5dee\u8ddd\u79bb\uff09\u5c0f\uff1b\u8be5\u7ed3\u679c\u4e0d\u9700\u8981\u6570\u636e\u5206\u5e03\u5149\u6ed1\u6216\u6b63\u6027\u3002\u7406\u8bba\u6846\u67b6\u6d89\u53ca Li\u2011Yau \u6210\u5206\u548c Minakshisundaram\u2011Pleijel \u53c2\u6570\u5316\u5c55\u5f00\u3002", "conclusion": "\u5728 Riemannian \u6269\u6563\u6a21\u578b\u4e2d\uff0c\u4f7f\u7528 $L_2$-\u7cbe\u786e\u7684\u5206\u6570\u4f30\u8ba1\uff0c\u4ec5\u9700\u591a\u9879\u5f0f\u9636\u7684\u6b65\u957f\u5373\u53ef\u5728\u603b\u53d8\u5dee\u8ddd\u79bb\u4e0b\u5f97\u5230\u5c0f\u7684\u91c7\u6837\u8bef\u5dee\uff0c\u65e0\u9700\u5bf9\u6570\u636e\u5206\u5e03\u7684\u5149\u6ed1\u6027\u6216\u6b63\u6027\u505a\u5047\u8bbe\uff1b\u8be5\u7ed3\u8bba\u5728\u4ec5\u5177\u5907\u8f7b\u5ea6\u66f2\u7387\u5047\u8bbe\u7684\u57fa\u7840\u4e0a\u6210\u7acb\u3002"}}
{"id": "2601.02947", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.02947", "abs": "https://arxiv.org/abs/2601.02947", "authors": ["Qinyi Liu", "Dong Liu", "Farhad Vadiee", "Mohammad Khalil", "Pedro P. Vergara Barrios"], "title": "Quality Degradation Attack in Synthetic Data", "comment": null, "summary": "Synthetic Data Generation (SDG) can be used to facilitate privacy-preserving data sharing. However, most existing research focuses on privacy attacks where the adversary is the recipient of the released synthetic data and attempts to infer sensitive information from it. This study investigates quality degradation attacks initiated by adversaries who possess access to the real dataset or control over the generation process, such as the data owner, the synthetic data provider, or potential intruders. We formalize a corresponding threat model and empirically evaluate the effectiveness of targeted manipulations of real data (e.g., label flipping and feature-importance-based interventions) on the quality of generated synthetic data. The results show that even small perturbations can substantially reduce downstream predictive performance and increase statistical divergence, exposing vulnerabilities within SDG pipelines. This study highlights the need to integrate integrity verification and robustness mechanisms, alongside privacy protection, to ensure the reliability and trustworthiness of synthetic data sharing frameworks.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u5728\u771f\u5b9e\u6570\u636e\u4e0a\n\u505a\u7ec6\u5fae\u5e72\u9884\u6765\u964d\u4f4e\u5408\u6210\u6570\u636e\u7684\u8d28\u91cf\uff0c\u63d0\u793a\u9700\u52a0\\n\u5f3a\u5b8c\u6574\u6027\u4e0e\u9c81\u68d2\u6027\u63aa\u65bd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u7531\u63a5\u6536\u65b9\u5bf9\u5408\u6210\u6570\u636e\u8fdb\u884c\u9690\u79c1\u653b\u51fb\uff0c\\n\u4f46\u5ffd\u7565\u4e86\u6570\u636e\u6240\u6709\u8005\u6216\u751f\u6210\u65b9\u672c\u8eab\u53ef\u80fd\n\u5bf9\u771f\u5b9e\u6570\u636e\u6216\u751f\u6210\u6d41\u7a0b\u5b9e\u65bd\u6076\u610f\u5e72\u6270\uff0c\u4ece\u800c\u7834\u574f\\n\u751f\u6210\u6570\u636e\u7684\u8d28\u91cf\u4e0e\u53ef\u7528\u6027\u3002", "method": "\u6784\u5efa\u5a01\u80c1\u6a21\u578b\uff0c\u9488\u5bf9\u62e5\u6709\u771f\u5b9e\u6570\u636e\u6216\u53ef\u63a7\u751f\u6210\u6d41\u7a0b\u7684\u653b\u51fb\u8005\uff0c\\u0040\\u003C\u6b63\u786e\u8fb9\u754c\\u003E \\n\u5e76\u5728\u5b9e\u9a8c\u4e2d\u901a\u8fc7\u6807\u7b7e\u7ffb\u8f6c\u3001\u57fa\u4e8e\u7279\u5f81\u91cd\u8981\u6027\u7684\u5e72\u9884\u7b49\u65b9\u5f0f\u5bf9\u539f\u59cb\u6570\u636e\\n\u8fdb\u884c\u7ec6\u5fae\u6270\u52a8\uff0c\u8bc4\u4f30\u5bf9\u751f\u6210\u6570\u636e\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u54ea\\u003C\u5c0f\u5e45\u6270\u52a8\\u003E \u5373\u53ef\u663e\u8457\u964d\u4f4e\u751f\u6210\u6570\u636e\u7684\u9884\u6d4b\u6027\u80fd\uff0c\\n\u63d0\u5347\u7edf\u8ba1\u5dee\u5f02\u6027\uff0c\u63ed\u793aSDG\u6d41\u7a0b\u7684\u8106\u5f31\u70b9\u3002", "conclusion": "\u672c\u7814\u7a76\u6307\u51fa\u5408\u6210\u6570\u636e\u751f\u6210\u5b58\u5728\u4e3b\u52a8\u5e72\u6270\u8106\u5f31\u6027\uff0c\u5f3a\u8c03\n\u9700\u8981\u9664\u9690\u79c1\u4fdd\u62a4\u5916\u8fd8\u8981\u52a0\u5165\u5b8c\u6574\u6027\u4e0e\u9c81\u68d2\u6027\u6821\u9a8c\uff0c\u786e\u4fdd\n\u751f\u6210\u6570\u636e\u7684\u53ef\u9760\u6027\u4e0e\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2601.03063", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.03063", "abs": "https://arxiv.org/abs/2601.03063", "authors": ["Rundong Jiang", "Jun Hu", "Yunqi Song", "Zhiyuan Xie", "Shiyou Xu"], "title": "Study of Class-Incremental Radio Frequency Fingerprint Recognition Without Storing Exemplars", "comment": null, "summary": "The rapid proliferation of wireless devices makes robust identity authentication essential. Radio Frequency Fingerprinting (RFF) exploits device-specific, hard-to-forge physical-layer impairments for identification, and is promising for IoT and unmanned systems. In practice, however, new devices continuously join deployed systems while per-class training data are limited. Conventional static training and naive replay of stored exemplars are impractical due to growing class cardinality, storage cost, and privacy concerns.\n  We propose an exemplar-free class-incremental learning framework tailored to RFF recognition. Starting from a pretrained feature extractor, we freeze the backbone during incremental stages and train only a classifier together with lightweight Adapter modules that perform small task-specific feature adjustments. For each class we fit a diagonal Gaussian Mixture Model (GMM) to the backbone features and sample pseudo-features from these fitted distributions to rehearse past classes without storing raw signals. To improve robustness under few-shot conditions we introduce a time-domain random-masking augmentation and adopt a multi-teacher distillation scheme to compress stage-wise Adapters into a single inference Adapter, trading off accuracy and runtime efficiency.\n  We evaluate the method on large, self-collected ADS-B datasets: the backbone is pretrained on 2,175 classes and incremental experiments are run on a disjoint set of 669 classes with multiple rounds and step sizes. Against several representative baselines, our approach consistently yields higher average accuracy and lower forgetting, while using substantially less storage and avoiding raw-data retention.\n  The proposed pipeline is reproducible and provides a practical, low-storage solution for RFF deployment in resource- and privacy-constrained environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4e0d\u9700\u5b58\u50a8\u6837\u672c\u7684\u589e\u91cf\u5b66\u4e60\u7ba1\u7ebf\uff0c\u7528 GMM \u4f2a\u7279\u5f81\u3001\u968f\u673a\u5c4f\u853d\u589e\u5f3a\u53ca\u591a\u6559\u5e08\u84b8\u998f\uff0c\u5c06 Radio Frequency Fingerprint \u7684\u5b66\u4e60\u538b\u7f29\u4e3a\u5355\u4e00\u63a8\u7406 Adapter\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5927\u89c4\u6a21 ADS\u2011B \u6570\u636e\u4e0a\u5b9e\u73b0\u66f4\u9ad8\u51c6\u786e\u7387\u3001\u8f83\u4f4e\u9057\u5fd8\uff0c\u5e76\u6781\u5927\u964d\u4f4e\u5b58\u50a8\u6210\u672c\u3002", "motivation": "\u5728 IoT \u4e0e\u65e0\u4eba\u7cfb\u7edf\u4e2d\uff0c\u8bbe\u5907\u6570\u91cf\u5feb\u901f\u589e\u957f\uff0c\u8eab\u4efd\u9274\u522b\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf RFF \u65b9\u6848\u9700\u5b58\u50a8\u8bbe\u5907\u6837\u672c\uff0c\u53d7\u9650\u4e8e\u7c7b\u6570\u589e\u957f\u3001\u5b58\u50a8\u53ca\u9690\u79c1\u95ee\u9898\uff0c\u96be\u4ee5\u5728\u65b0\u8bbe\u5907\u4e0d\u65ad\u52a0\u5165\u7684\u573a\u666f\u4e0b\u6301\u7eed\u4e0a\u7ebf\u3002", "method": "1\uff09\u51bb\u7ed3\u9884\u8bad\u7ec3\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u4ec5\u8bad\u7ec3\u5206\u7c7b\u5668\u4e0e\u8f7b\u91cf\u7ea7 Adapter\uff1b2\uff09\u4e3a\u6bcf\u4e2a\u65b0\u7c7b\u62df\u5408\u5bf9\u89d2 Gaussian \u6df7\u5408\u6a21\u578b\uff08GMM\uff09\uff0c\u5e76\u91c7\u6837\u4f2a\u7279\u5f81\u4ee5\u56de\u987e\u65e7\u7c7b\uff1b3\uff09\u91c7\u7528\u65f6\u57df\u968f\u673a\u5c4f\u853d\uff08random\u2011masking\uff09\u589e\u5f3a\u63d0\u5347\u5c11\u6837\u672c\u9c81\u68d2\u6027\uff1b4\uff09\u591a\u6559\u5e08\u84b8\u998f\u538b\u7f29\u591a\u9636\u6bb5 Adapter \u4e3a\u5355\u4e00\u63a8\u7406 Adapter\uff0c\u517c\u987e\u7cbe\u5ea6\u4e0e\u901f\u5ea6\u3002", "result": "\u5728\u81ea\u5efa ADS\u2011B \u6570\u636e\u96c6\u4e0a\uff1a\u9884\u8bad\u7ec3 2,175 \u7c7b\uff0c\u589e\u91cf\u5b9e\u9a8c 669 \u7c7b\uff0c\u591a\u8f6e\u591a\u6b65\uff1b\u76f8\u6bd4\u57fa\u7ebf\uff0c\u5e73\u5747\u51c6\u786e\u7387\u66f4\u9ad8\u3001\u9057\u5fd8\u66f4\u4f4e\u3001\u5b58\u50a8\u9700\u6c42\u663e\u8457\u51cf\u5c0f\uff0c\u5e76\u4e14\u5b8c\u5168\u4e0d\u4fdd\u5b58\u539f\u59cb\u4fe1\u53f7\u3002", "conclusion": "\u8be5\u65e0\u6837\u672c\u589e\u91cf RFF \u6846\u67b6\u5728\u8d44\u6e90\u548c\u9690\u79c1\u53d7\u9650\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u9760\u3001\u4f4e\u5b58\u50a8\u7684\u8bbe\u5907\u8eab\u4efd\u8bc6\u522b\uff0c\u4e3a\u672a\u6765\u7684 IoT \u4e0e\u65e0\u4eba\u7cfb\u7edf\u90e8\u7f72\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.02855", "categories": ["cs.IT", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.02855", "abs": "https://arxiv.org/abs/2601.02855", "authors": ["Heng Zhao", "Sara Saeidian", "Tobias J. Oechtering"], "title": "Context-aware Privacy Bounds for Linear Queries", "comment": "8 pages, 4 figures, submitted to ISIT 2026", "summary": "Linear queries, as the basis of broad analysis tasks, are often released through privacy mechanisms based on differential privacy (DP), the most popular framework for privacy protection. However, DP adopts a context-free definition that operates independently of the data-generating distribution. In this paper, we revisit the privacy analysis of the Laplace mechanism through the lens of pointwise maximal leakage (PML). We demonstrate that the distribution-agnostic definition of the DP framework often mandates excessive noise. To address this, we incorporate an assumption about the prior distribution by lower-bounding the probability of any single record belonging to any specific class. With this assumption, we derive a tight, context-aware leakage bound for general linear queries, and prove that our derived bound is strictly tighter than the standard DP guarantee and converges to the DP guarantee as this probability lower bound approaches zero. Numerical evaluations demonstrate that by exploiting this prior knowledge, the required noise scale can be reduced while maintaining privacy guarantees.", "AI": {"tldr": "\u5bf9Laplace\u673a\u5236\u7684PML\u5206\u6790\u8868\u660e\uff0c\u5f15\u5165\u8bb0\u5f55\u7c7b\u522b\u5206\u5e03\u5047\u8bbe\u80fd\u663e\u8457\u964d\u4f4e\u566a\u58f0\u91cf\uff0c\u63d0\u4f9b\u66f4\u7d27\u7684\u9690\u79c1\u4fdd\u62a4\u754c\u9650\uff0c\u4f18\u4e8e\u4f20\u7edfDP\u3002", "motivation": "\u5dee\u5206\u9690\u79c1\u5728\u65e0\u4e0a\u4e0b\u6587\u6761\u4ef6\u4e0b\u5bf9\u566a\u58f0\u9700\u6c42\u8fc7\u5927\uff0c\u7f3a\u5c11\u5bf9\u771f\u5b9e\u6570\u636e\u751f\u6210\u5206\u5e03\u7684\u5229\u7528\u3002", "method": "\u63d0\u51fa\u5c06\u7ebf\u6027\u67e5\u8be2\u7684Laplace\u673a\u5236\u901a\u8fc7\u70b9\u9010\u70b9\u6700\u5927\u6cc4\u9732\u5ea6\uff08PML\uff09\u91cd\u65b0\u5206\u6790\uff0c\u5047\u8bbe\u4efb\u4e00\u8bb0\u5f55\u5c5e\u4e8e\u7279\u5b9a\u7c7b\u522b\u7684\u5148\u9a8c\u6982\u7387\u6709\u4e0b\u754c\uff0c\u968f\u540e\u63a8\u5bfc\u51fa\u4e0e\u5148\u9a8c\u76f8\u5173\u7684\u6cc4\u9732\u754c\u9650\uff0c\u5e76\u4e0e\u6807\u51c6DP\u754c\u9650\u505a\u4e25\u683c\u6bd4\u8f83\u3002", "result": "\u901a\u8fc7\u6570\u503c\u8bc4\u4f30\u9a8c\u8bc1\uff0c\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u53ef\u5c06\u6240\u9700\u566a\u58f0\u5c3a\u5ea6\u663e\u8457\u964d\u4f4e\uff0c\u540c\u65f6\u4ecd\u6ee1\u8db3\u9690\u79c1\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\uff0c\u5728\u5f15\u5165\u5148\u9a8c\u5206\u5e03\u5047\u8bbe\u540e\uff0c\u57fa\u4e8e\u70b9\u9010\u70b9\u6700\u5927\u6cc4\u9732\u5ea6\u8861\u91cf\u7684\u7ebf\u6027\u67e5\u8be2\u7684\u9690\u79c1\u4fdd\u62a4\u53ef\u5b9e\u73b0\u66f4\u7d27\u7684\u566a\u58f0\u5c3a\u5ea6\u4e0a\u754c\uff0c\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u7684\u5dee\u5206\u9690\u79c1\u6807\u51c6\uff0c\u4e14\u5f53\u5148\u9a8c\u6982\u7387\u4e0b\u754c\u8d8b\u8fd1\u4e8e\u96f6\u65f6\u9000\u5316\u4e3a\u5dee\u5206\u9690\u79c1\u7684\u754c\u9650\u3002"}}
{"id": "2601.02500", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02500", "abs": "https://arxiv.org/abs/2601.02500", "authors": ["Brian Tekmen", "Jason Yin", "Qianqian Tong"], "title": "GEM-Style Constraints for PEFT with Dual Gradient Projection in LoRA", "comment": "Work accepted to the NSF REU Symposium at the 2025 IEEE International Conference on Data Mining (ICDM). Correspondence to: betekmen@uncg.edu", "summary": "Full fine-tuning of Large Language Models (LLMs) is computationally costly, motivating Continual Learning (CL) approaches that utilize parameter-efficient adapters. We revisit Gradient Episodic Memory (GEM) within the Low-Rank Adapter (LoRA) subspace and introduce I-GEM: a fixed-budget, GPU-resident dual projected-gradient approximation to GEM's quadratic projection. By constraining non-interference solely within the adapter parameters, I-GEM preserves GEM-like stability with orders-of-magnitude lower mean projection overhead. On a 3-task AG News split with induced domain drift, using GPT-2 (355M) and LoRA ($r=8$), I-GEM matches GEM's average accuracy (within $\\sim\\!0.04$ pts) and outperforms A-GEM by $\\sim\\!1.4$ pts. Crucially, it reduces projection time vs.\\ GEM by a factor of $\\sim\\!10^3$. These results suggest that applying GEM constraints in the LoRA subspace is a practical pathway for continual learning at the LLM scale.", "AI": {"tldr": "I\u2011GEM \u5728 LoRA \u5b50\u7a7a\u95f4\u4e2d\u8fd1\u4f3c GEM\uff0c\u4ec5\u7528\u9002\u914d\u5668\u53c2\u6570\u7ea6\u675f\uff0c\u6781\u5927\u964d\u4f4e\u6295\u5f71\u65f6\u95f4\u5e76\u7ef4\u6301\u6027\u80fd\uff0c\u662f LLM \u89c4\u6a21\u6301\u7eed\u5b66\u4e60\u7684\u5b9e\u7528\u65b9\u6848\u3002", "motivation": "LLM\u5b8c\u5168\u5fae\u8c03\u6210\u672c\u9ad8\uff0c\u9700\u91c7\u7528\u53c2\u6570\u9ad8\u6548\u9002\u914d\u5668\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u5728 LoRA \u5b50\u7a7a\u95f4\u4e2d\u91cd\u73b0 GEM\uff0c\u5f15\u5165 I\u2011GEM \u53cc\u6295\u5f71\u68af\u5ea6\u8fd1\u4f3c\uff1b\u4ec5\u5728\u9002\u914d\u5668\u53c2\u6570\u5185\u7ea6\u675f\u65e0\u5e72\u6270\u3002", "result": "\u5728 GPT\u20112(355M)/LoRA r=8 \u4e0a 3 \u4efb\u52a1 AG News \u57df\u6f02\u79fb\u5b9e\u9a8c\uff0cI\u2011GEM \u4e0e GEM \u51c6\u786e\u7387\u76f8\u8fd1\uff0c\u4f18\u4e8e A\u2011GEM\uff0c\u4e14\u6295\u5f71\u65f6\u95f4\u4e0b\u964d\u7ea6 10\u207d\u00b3\u207e \u500d\u3002", "conclusion": "GEM \u7ea6\u675f\u53ef\u5728 LoRA \u5b50\u7a7a\u95f4\u5b9e\u73b0\uff0c\u4ece\u800c\u5728 LLM \u89c4\u6a21\u4e0b\u5b9e\u73b0\u53ef\u884c\u7684\u6301\u7eed\u5b66\u4e60\u3002"}}
{"id": "2601.02949", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.02949", "abs": "https://arxiv.org/abs/2601.02949", "authors": ["Stanly Wilson", "Kwabena Adu-Duodu", "Yinhao Li", "Ellis Solaiman", "Omer Rana", "Rajiv Ranjan"], "title": "Exploring Blockchain Interoperability: Frameworks, Use Cases, and Future Challenges", "comment": null, "summary": "Trust between entities in any scenario without a trusted third party is very difficult, and trust is exactly what blockchain aims to bring into the digital world with its basic features. Many applications are moving to blockchain adoption, enabling users to work in a trustworthy manner. The early generations of blockchain have a problem; they cannot share information with other blockchains. As more and more entities move their applications to the blockchain, they generate large volumes of data, and as applications have become more complex, sharing information between different blockchains has become a necessity. This has led to the research and development of interoperable solutions allowing blockchains to connect together. This paper discusses a few blockchain platforms that provide interoperable solutions, emphasising their ability to connect heterogeneous blockchains. It also discusses a case study scenario to illustrate the importance and benefits of using interoperable solutions. We also present a few topics that need to be solved in the realm of interoperability.", "AI": {"tldr": "\u6587\u7ae0\u8ba8\u8bba\u4e86\u533a\u5757\u94fe\u4e92\u64cd\u4f5c\u6027\u7684\u91cd\u8981\u6027\uff0c\u8bc4\u4f30\u4e86\u73b0\u6709\u5e73\u53f0\u5e76\u901a\u8fc7\u6848\u4f8b\u5c55\u793a\u5176\u4f18\u52bf\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u4ecd\u9700\u89e3\u51b3\u7684\u6280\u672f\u96be\u9898\u3002", "motivation": "\u5728\u7f3a\u4e4f\u53ef\u4fe1\u7b2c\u4e09\u65b9\u7684\u60c5\u51b5\u4e0b\uff0c\u533a\u5757\u94fe\u65e8\u5728\u6784\u5efa\u4fe1\u4efb\u4f53\u7cfb\uff1b\u968f\u7740\u533a\u5757\u94fe\u5e94\u7528\u6269\u589e\uff0c\u5355\u94fe\u4fe1\u606f\u5171\u4eab\u53d7\u9650\uff0c\u8feb\u5207\u9700\u8981\u8de8\u94fe\u4e92\u64cd\u4f5c\u3002", "method": "\u901a\u8fc7\u5bf9\u591a\u79cd\u533a\u5757\u94fe\u5e73\u53f0\u7684\u4e92\u64cd\u4f5c\u6027\u7279\u6027\u8fdb\u884c\u5bf9\u6bd4\u8ba8\u8bba\uff0c\u5e76\u7ed3\u5408\u6848\u4f8b\u573a\u666f\u9610\u91ca\u5176\u5e94\u7528\u4ef7\u503c\u3002", "result": "\u8bc4\u4f30\u4e86\u51e0\u79cd\u4e3b\u6d41\u5e73\u53f0\u7684\u4e92\u64cd\u4f5c\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u6848\u4f8b\u4e2d\u63d0\u5347\u6548\u7387\u4e0e\u4fe1\u4efb\u7684\u5177\u4f53\u6548\u679c\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u8bba\u6587\u6982\u8ff0\u4e86\u533a\u5757\u94fe\u4e92\u64cd\u4f5c\u6027\u7684\u5fc5\u8981\u6027\u4e0e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\uff0c\u5f3a\u8c03\u8de8\u5f02\u6784\u94fe\u4e92\u8054\u7684\u53ef\u884c\u6027\uff0c\u5e76\u6307\u51fa\u4ecd\u9700\u89e3\u51b3\u7684\u5173\u952e\u6280\u672f\u6311\u6218\u3002"}}
{"id": "2601.03084", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.03084", "abs": "https://arxiv.org/abs/2601.03084", "authors": ["Mohsen Kazemian", "J\u00fcrgen Jasperneite"], "title": "A Conditional Variational Framework for Channel Prediction in High-Mobility 6G OTFS Networks", "comment": null, "summary": "This paper proposes a machine learning (ML) based method for channel prediction in high mobility orthogonal time frequency space (OTFS) channels. In these scenarios, rapid variations caused by Doppler spread and time varying multipath propagation lead to fast channel decorrelation, making conventional pilot based channel estimation methods prone to outdated channel state information (CSI) and excessive overhead. Therefore, reliable channel prediction methods become essential to support robust detection and decoding in OTFS systems. In this paper, we propose conditional variational autoencoder for channel prediction (CVAE4CP) method, which learns the conditional distribution of OTFS delay Doppler channel coefficients given physical system and mobility parameters. By incorporating these parameters as conditioning information, the proposed method enables the prediction of future channel coefficients before their actual realization, while accounting for inherent channel uncertainty through a low dimensional latent representation. The proposed framework is evaluated through extensive simulations under high mobility conditions. Numerical results demonstrate that CVAE4CP consistently outperforms a competing learning based baseline in terms of normalized mean squared error (NMSE), particularly at high Doppler frequencies and extended prediction horizons. These results confirm the effectiveness and robustness of the proposed approach for channel prediction in rapidly time varying OTFS systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa CVAE4CP\uff0c\u5bf9 OTFS \u9ad8\u901f\u79fb\u52a8\u901a\u9053\u8fdb\u884c\u9884\u6d4b\uff0c\u5229\u7528\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7ed3\u5408\u7cfb\u7edf\u4e0e\u901f\u5ea6\u53c2\u6570\uff0c\u663e\u8457\u964d\u4f4e NMSE\uff0c\u4f18\u4e8e\u4f20\u7edf\u5b66\u4e60\u57fa\u7ebf\u3002", "motivation": "\u5728\u9ad8\u901f\u79fb\u52a8 OTFS \u73af\u5883\u4e0b\uff0c\u5feb\u901f\u65f6\u95f4\u53d8\u5316\u5bfc\u81f4\u4f20\u7edf\u57fa\u4e8e\u5bfc\u9891\u7684\u901a\u9053\u4f30\u8ba1\u5931\u6548\uff0c\u4e9f\u9700\u53ef\u9760\u7684\u901a\u9053\u9884\u6d4b\u65b9\u6cd5\u4ee5\u652f\u6301\u7a33\u5065\u68c0\u6d4b\u4e0e\u89e3\u7801\u3002", "method": "\u4f7f\u7528\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08CVAE\uff09\u5b66\u4e60 OTFS \u5ef6\u8fdf-\u591a\u666e\u52d2\u901a\u9053\u7cfb\u6570\u7684\u6761\u4ef6\u5206\u5e03\uff0c\u8f93\u5165\u7269\u7406\u7cfb\u7edf\u548c\u79fb\u52a8\u53c2\u6570\u4f5c\u4e3a\u6761\u4ef6\u4fe1\u606f\uff0c\u8f93\u51fa\u672a\u6765\u901a\u9053\u7cfb\u6570\u7684\u4f4e\u7ef4\u6f5c\u5728\u8868\u793a\uff0c\u5b9e\u73b0\u524d\u77bb\u6027\u901a\u9053\u9884\u6d4b\u3002", "result": "\u6570\u503c\u4eff\u771f\u663e\u793a\uff0cCVAE4CP \u5728\u9ad8\u591a\u666e\u52d2\u9891\u7387\u548c\u8f83\u957f\u9884\u6d4b\u5468\u671f\u4e0b\uff0c\u5747\u80fd\u6301\u7eed\u53d6\u5f97\u6bd4\u7ade\u4e89\u5b66\u4e60\u57fa\u7ebf\u66f4\u4f4e\u7684\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\uff0c\u8bc1\u5b9e\u4e86\u5176\u9884\u6d4b\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "CVAE4CP \u65b9\u6cd5\u5728\u9ad8\u901f\u79fb\u52a8 OTFS \u901a\u9053\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684 NMSE \u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2601.03126", "categories": ["cs.IT", "math.GR"], "pdf": "https://arxiv.org/pdf/2601.03126", "abs": "https://arxiv.org/abs/2601.03126", "authors": ["Jay A. Wood"], "title": "Dualities for finite abelian groups and applications to coding theory", "comment": "32 pages", "summary": "The choice of an isomorphism, a duality, between a finite abelian group $A$ and its character group allows one to define dual codes of additive codes over $A$. Properties of dualities and dual codes are studied, continuing work of Delsarte from 1973 and more recent work of Dougherty and his collaborators.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u9009\u53d6\u9002\u5f53\u7684\u81ea\u540c\u6784\uff0c\u5b9a\u4e49\u4e86\u6709\u9650\u963f\u8d1d\u5c14\u7fa4\u4e0a\u52a0\u6cd5\u7801\u7684\u5bf9\u5076\u7801\uff0c\u7ee7\u7eed\u5e76\u6269\u5c55\u4e86Delsarte\u4e0eDougherty\u7b49\u4eba\u7684\u7814\u7a76\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u81ea\u540c\u6784\u4e0e\u5bf9\u5076\u7801\u7684\u6027\u8d28\u3002", "motivation": "\u5728\u6709\u9650\u963f\u8d1d\u5c14\u7fa4\u4e0a\u6784\u9020\u52a0\u6cd5\u7801\u7684\u5bf9\u5076\u7801\u5e76\u7814\u7a76\u5176\u6027\u8d28", "method": "\u901a\u8fc7\u9009\u53d6\u6709\u9650\u963f\u8d1d\u5c14\u7fa4A\u4e0e\u5176\u89d2\u8272\u7fa4\u4e4b\u95f4\u7684\u7b49\u4ef7\u81ea\u540c\u6784\uff0c\u5b9a\u4e49\u52a0\u6cd5\u7801\u7684\u5bf9\u5076\u7801\uff0c\u7ee7\u7eedDelsarte\uff081973\uff09\u4ee5\u53caDougherty\u7b49\u4eba\u7684\u7814\u7a76\u65b9\u6cd5", "result": "\u5bf9\u7b49\u4ef7\u81ea\u540c\u6784\u4e0e\u5bf9\u5076\u7801\u6027\u8d28\u8fdb\u884c\u7cfb\u7edf\u7684\u5206\u6790\u4e0e\u7814\u7a76", "conclusion": "\u6210\u529f\u5efa\u7acb\u5e76\u9610\u8ff0\u4e86\u6709\u9650\u963f\u8d1d\u5c14\u7fa4\u4e0e\u5176\u89d2\u8272\u7fa4\u4e4b\u95f4\u7684\u5bf9\u5076\u5173\u7cfb\uff0c\u5e76\u5bf9\u52a0\u6cd5\u7801\u7684\u5bf9\u5076\u6027\u8d28\u8fdb\u884c\u4e86\u6df1\u5165\u63a2\u8ba8"}}
{"id": "2601.02387", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.02387", "abs": "https://arxiv.org/abs/2601.02387", "authors": ["Chenxi Bao", "Di Zhou", "Min Sheng", "Yan Shi", "Jiandong Li", "Zhili Sun"], "title": "Regional Resource Management for Service Provisioning in LEO Satellite Networks: A Topology Feature-Based DRL Approach", "comment": "This paper has been accepted by IEEE GLOBECOM", "summary": "Satellite networks with wide coverage are considered natural extensions to terrestrial networks for their long-distance end-to-end (E2E) service provisioning. However, the inherent topology dynamics of low earth orbit satellite networks and the uncertain network scales bring an inevitable requirement that resource chains for E2E service provisioning must be efficiently re-planned. Therefore, achieving highly adaptive resource management is of great significance in practical deployment applications. This paper first designs a regional resource management (RRM) mode and further formulates the RRM problem that can provide a unified decision space independent of the network scale. Subsequently, leveraging the RRM mode and deep reinforcement learning framework, we develop a topology feature-based dynamic and adaptive resource management algorithm to combat the varying network scales. The proposed algorithm successfully takes into account the fixed output dimension of the neural network and the changing resource chains for E2E service provisioning. The matched design of the service orientation information and phased reward function effectively improves the service performance of the algorithm under the RRM mode. The numerical results demonstrate that the proposed algorithm with the best convergence performance and fastest convergence rate significantly improves service performance for varying network scales, with gains over compared algorithms of more than 2.7%, 11.9%, and 10.2%, respectively.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02509", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02509", "abs": "https://arxiv.org/abs/2601.02509", "authors": ["Fabio Cumbo", "Kabir Dhillon", "Daniel Blankenberg"], "title": "hdlib 2.0: Extending Machine Learning Capabilities of Vector-Symbolic Architectures", "comment": "7 pages, 1 figure", "summary": "Following the initial publication of hdlib, a Python library for designing Vector-Symbolic Architectures (VSA), we introduce a major extension that significantly enhances its machine learning capabilities. VSA, also known as Hyperdimensional Computing, is a computing paradigm that represents and processes information using high-dimensional vectors. While the first version of hdlib established a robust foundation for creating and manipulating these vectors, this update addresses the growing need for more advanced, data-driven modeling within the VSA framework. Here, we present four extensions: significant enhancements to the existing supervised classification model also enabling feature selection, and a new regression model for predicting continuous variables, a clustering model for unsupervised learning, and a graph-based learning model. Furthermore, we propose the first implementation ever of Quantum Hyperdimensional Computing with quantum-powered arithmetic operations and a new Quantum Machine Learning model for supervised learning. hdlib remains open-source and available on GitHub at https://github.com/cumbof/hdlib under the MIT license, and distributed through the Python Package Index (pip install hdlib) and Conda (conda install -c conda-forge hdlib). Documentation and examples of these new features are available on the official Wiki at https://github.com/cumbof/hdlib/wiki.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02981", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.02981", "abs": "https://arxiv.org/abs/2601.02981", "authors": ["Brahim Khalil Sedraoui", "Abdelmadjid Benmachiche", "Amina Makhlouf"], "title": "Developing and Evaluating Lightweight Cryptographic Algorithms for Secure Embedded Systems in IoT Devices", "comment": null, "summary": "The high rate of development of Internet of Things (IoT) devices has brought to attention new challenges in the area of data security, especially within the resource-limited realm of RFID tags, sensors, and embedded systems. Traditional cryptographic implementations can be of inappropriate computational complexity and energy usage and hence are not suitable on these platforms. This paper examines the design, implementation, and testing of lightweight cryptographic algorithms that have been specifically designed to be used in secure embedded systems. A comparison of some of the state-of-the-art lightweight encryption algorithms, that is PRESENT, SPECK, and SIMON, focuses on the main performance indicators, i.e., throughput, use of memory, and energy utilization. The study presents novel lightweight algorithms that are founded upon the Feistel-network architecture and their safety under cryptanalytic attacks, e.g., differential and linear cryptanalysis. The proposed solutions are proven through hardware implementation on the FPGA platform. The results have shown that lightweight cryptography is an effective strategy that could be used to establish security and maintain performance in the IoT and other resource-limited settings.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03165", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.03165", "abs": "https://arxiv.org/abs/2601.03165", "authors": ["Anuj Kumar Bhagat", "Ritumoni Sarma"], "title": "On the Euclidean duals of the cyclic codes generated by cyclotomic polynomials", "comment": null, "summary": "In this article, we determine the minimum distance of the Euclidean dual of the cyclic code $\\mathcal{C}_n$ generated by the $n$th cyclotomic polynomial $Q_n(x)$ over $\\mathbb{F}_q$, for every positive integer $n$ co-prime to $q$. In particular, we prove that the minimum distance of $\\mathcal{C}_{n}^{\\perp}$ is a function of $n$, namely $2^{\u03c9(n)}$. This was precisely the conjecture posed by us in \\cite{BHAGAT2025}.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5148\u524d\u731c\u60f3\u7684\u7ed3\u8bba\uff1a\u6b27\u6c0f\u53cc\u7801\u7684\u6700\u5c0f\u8ddd\u79bb\u7b49\u4e8e$n$\u4e2d\u4e0d\u540c\u8d28\u56e0\u6570\u4e2a\u6570\u7684\u4e8c\u6b21\u5e42\u3002", "motivation": "\u9a8c\u8bc1\u6b64\u524d\u63d0\u51fa\u7684$2^{\\omega(n)}$\u516c\u5f0f\u7684\u731c\u60f3\uff0c\u4e3a\u5faa\u73af\u7801\u53cc\u7801\u7406\u8bba\u63d0\u4f9b\u65b0\u7684\u8ddd\u79bb\u4f30\u8ba1", "method": "\u5229\u7528$n$\u6b21\u5faa\u73af\u591a\u9879\u5f0f\u751f\u6210\u7684\u5faa\u73af\u7801\u7684\u7ed3\u6784\u6027\u8d28\u4e0e\u6b27\u6c0f\u5185\u79ef\u7279\u5f81\uff0c\u63a8\u5bfc\u8ddd\u79bb\u8868\u8fbe\u5f0f", "result": "\u8bc1\u660e\u5bf9\u4e8e\u4efb\u610f\u6b63\u6574\u6570$n$\u4e14\u4e0e$q$\u4e92\u7d20\uff0c$\\mathcal{C}_{n}^{\\perp}$\u7684\u6700\u5c0f\u8ddd\u79bb\u786e\u5b9e\u4e3a$2^{\\omega(n)}$", "conclusion": "\u786e\u5b9a\u6b27\u6c0f\u53cc\u7801$\\mathcal{C}_{n}^{\\perp}$\u7684\u6700\u5c0f\u8ddd\u79bb\u4e3a$2^{\\omega(n)}$"}}
{"id": "2601.02804", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.02804", "abs": "https://arxiv.org/abs/2601.02804", "authors": ["Xunqiang Lan", "Xiao Tang", "Ruonan Zhang", "Bin Li", "Qinghe Du", "Dusit Niyato", "Zhu Han"], "title": "Distributionally Robust Game for Proof-of-Work Blockchain Mining Under Resource Uncertainties", "comment": "Accepted @ IEEE TIFS", "summary": "Blockchain plays a crucial role in ensuring the security and integrity of decentralized systems, with the proof-of-work (PoW) mechanism being fundamental for achieving distributed consensus. As PoW blockchains see broader adoption, an increasingly diverse set of miners with varying computing capabilities participate in the network. In this paper, we consider the PoW blockchain mining, where the miners are associated with resource uncertainties. To characterize the uncertainty computing resources at different mining participants, we establish an ambiguous set representing uncertainty of resource distributions. Then, the networked mining is formulated as a non-cooperative game, where distributionally robust performance is calculated for each individual miner to tackle the resource uncertainties. We prove the existence of the equilibrium of the distributionally robust mining game. To derive the equilibrium, we propose the conditional value-at-risk (CVaR)-based reinterpretation of the best response of each miner. We then solve the individual strategy with alternating optimization, which facilitates the iteration among miners towards the game equilibrium. Furthermore, we consider the case that the ambiguity of resource distribution reduces to Gaussian distribution and the case that another uncertainties vanish, and then characterize the properties of the equilibrium therein along with a distributed algorithm to achieve the equilibrium. Simulation results show that the proposed approaches effectively converge to the equilibrium, and effectively tackle the uncertainties in blockchain mining to achieve a robust performance guarantee.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02984", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.02984", "abs": "https://arxiv.org/abs/2601.02984", "authors": ["Martin Pere\u0161\u00edni", "Tom\u00e1\u0161 Hladk\u00fd", "Jakub Kub\u00edk", "Ivan Homoliak"], "title": "Selfish Mining in Multi-Attacker Scenarios: An Empirical Evaluation of Nakamoto, Fruitchain, and Strongchain", "comment": "16 pages, ESORICS 2025 - Cryptocurrencies and Blockchain Technology - CBT 2025", "summary": "The aim of this work is to enhance blockchain security by deepening the understanding of selfish mining attacks in various consensus protocols, especially the ones that have the potential to mitigate selfish mining. Previous research was mainly focused on a particular protocol with a single selfish miner, while only limited studies have been conducted on two or more attackers. To address this gap, we proposed a stochastic simulation framework that enables analysis of selfish mining with multiple attackers across various consensus protocols. We created the model of Proof-of-Work (PoW) Nakamoto consensus (serving as the baseline) as well as models of two additional consensus protocols designed to mitigate selfish mining: Fruitchain and Strongchain. Using our framework, thresholds reported in the literature were verified, and several novel thresholds were discovered for 2 and more attackers. We made the source code of our framework available, enabling researchers to evaluate any newly added protocol with one or more selfish miners and cross-compare it with already modeled protocols.", "AI": {"tldr": "\u5f00\u53d1\u968f\u673a\u6a21\u62df\u6846\u67b6\uff0c\u7814\u7a76\u591a\u653b\u51fb\u8005\u81ea\u79c1\u6316\u77ff\uff0c\u9a8c\u8bc1\u5e76\u53d1\u73b0\u9608\u503c\uff0c\u516c\u5f00\u6e90\u7801\u3002", "motivation": "\u6df1\u5316\u5bf9\u591a\u653b\u51fb\u8005\u81ea\u79c1\u6316\u77ff\u7684\u7406\u89e3\uff0c\u5e76\u586b\u8865\u73b0\u6709\u7814\u7a76\u4ec5\u5173\u6ce8\u5355\u4e00\u653b\u51fb\u8005\u7684\u7a7a\u767d\u3002", "method": "\u6784\u5efaPoW\u7eb3\u59c6\u514b\u6258\u514b\u57fa\u672c\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1Fruitchain\u4e0eStrongchain\u7b49\u5bf9\u6297\u81ea\u79c1\u6316\u77ff\u7684\u5171\u8bc6\u6a21\u578b\uff0c\u5728\u6b64\u6846\u67b6\u4e0b\u8fdb\u884c\u591a\u653b\u51fb\u8005\u968f\u673a\u6a21\u62df\uff0c\u5e76\u5bf9\u9608\u503c\u8fdb\u884c\u9a8c\u8bc1\u4e0e\u53d1\u73b0\u3002", "result": "\u9a8c\u8bc1\u5df2\u77e5\u9608\u503c\uff0c\u53d1\u73b02\u4f4d\u53ca\u4ee5\u4e0a\u653b\u51fb\u8005\u7684\u65b0\u9608\u503c\uff0c\u5e76\u516c\u5f00\u6e90\u7801\u4f9b\u5176\u4ed6\u7814\u7a76\u8005\u4f7f\u7528\u3002", "conclusion": "\u901a\u8fc7\u6784\u5efa\u57fa\u4e8e\u968f\u673a\u6a21\u62df\u7684\u591a\u653b\u51fb\u8005\u81ea\u79c1\u6316\u77ff\u5206\u6790\u6846\u67b6\uff0c\u672c\u6587\u4e0d\u4ec5\u9a8c\u8bc1\u4e86\u5df2\u53d1\u8868\u9608\u503c\uff0c\u8fd8\u53d1\u73b0\u4e86\u4e24\u540d\u53ca\u4ee5\u4e0a\u653b\u51fb\u8005\u7684\u65b0\u9608\u503c\uff0c\u4fc3\u8fdb\u4e86\u5bf9\u6297\u81ea\u79c1\u6316\u77ff\u7684\u5171\u8bc6\u534f\u8bae\u7814\u7a76\u4e0e\u53d1\u5c55\u3002"}}
{"id": "2601.03148", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.03148", "abs": "https://arxiv.org/abs/2601.03148", "authors": ["Alireza Maleki", "Ebrahim Bedeer", "Robert Barton"], "title": "Spectral-Efficient LoRa with Low Complexity Detection", "comment": null, "summary": "In this paper, we propose a spectral-efficient LoRa (SE-LoRa) modulation scheme with a low complexity successive interference cancellation (SIC)-based detector. The proposed communication scheme significantly improves the spectral efficiency of LoRa modulation, while achieving an acceptable error performance compared to conventional LoRa modulation, especially in higher spreading factor (SF) settings. We derive the joint maximum likelihood (ML) detection rule for the SE-LoRa transmission scheme that turns out to be of high computational complexity. To overcome this issue, and by exploiting the frequency-domain characteristics of the dechirped SE-LoRa signal, we propose a low complexity SIC-based detector with a computation complexity at the order of conventional LoRa detection. By computer simulations, we show that the proposed SE-LoRa with low complexity SIC-based detector can improve the spectral efficiency of LoRa modulation up to $445.45\\%$, $1011.11\\%$, and $1071.88\\%$ for SF values of $7$, $9$, and $11$, respectively, while maintaining the error performance within less than $3$ dB of conventional LoRa at symbol error rate (SER) of $10^{-3}$ in Rician channel conditions.", "AI": {"tldr": "\u65b0\u7684SE-LoRa+SIC\u68c0\u6d4b\u5668\u5927\u5e45\u63d0\u5347LoRa\u9891\u8c31\u6548\u7387\uff0c\u8bef\u7801\u7387\u4ec5\u7565\u900a\u4e8e\u4f20\u7edfLoRa\u3002", "motivation": "\u63d0\u5347LoRa\u5728\u9ad8\u6269\u5c55\u56e0\u5b50\uff08SF\uff09\u4e0b\u7684\u9891\u8c31\u5229\u7528\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u8bef\u7801\u7387\u53ef\u63a5\u53d7\u3002", "method": "\u63a8\u5bfc\u8054\u5408ML\u68c0\u6d4b\uff0c\u968f\u540e\u5229\u7528\u53bb\u8c03\u9891\u540eSE-LoRa\u4fe1\u53f7\u7684\u9891\u57df\u7279\u6027\u8bbe\u8ba1\u4f4e\u590d\u6742\u5ea6SIC\u68c0\u6d4b\u5668\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0e\u4f20\u7edfLoRa\u76f8\u5f53\u3002", "result": "\u5728SF=7\u30019\u300111\u65f6\uff0c\u9891\u8c31\u6548\u7387\u63d0\u5347\u7ea6445.45%\u30011011.11%\u30011071.88%\uff1b\u8bef\u7801\u7387\u5728RSF\u4fe1\u9053\u4e0a\u8ddd\u4f20\u7edfLoRa\u4e0d\u8db33 dB\u3002", "conclusion": "SE-LoRa\u7ed3\u5408\u4f4e\u590d\u6742\u5ea6SIC\u68c0\u6d4b\u5668\u663e\u8457\u63d0\u5347LoRa\u9891\u8c31\u6548\u7387\uff0c\u5e76\u4fdd\u6301\u63a5\u8fd1\u4f20\u7edfLoRa\u7684\u8bef\u7801\u6027\u80fd\u3002"}}
{"id": "2601.03241", "categories": ["cs.IT", "cs.CR", "cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.03241", "abs": "https://arxiv.org/abs/2601.03241", "authors": ["Lei Hu", "Sennur Ulukus"], "title": "On the Capacity Region of Individual Key Rates in Vector Linear Secure Aggregation", "comment": null, "summary": "We provide new insights into an open problem recently posed by Yuan-Sun [ISIT 2025], concerning the minimum individual key rate required in the vector linear secure aggregation problem. Consider a distributed system with $K$ users, where each user $k\\in [K]$ holds a data stream $W_k$ and an individual key $Z_k$. A server aims to compute a linear function $\\mathbf{F}[W_1;\\ldots;W_K]$ without learning any information about another linear function $\\mathbf{G}[W_1;\\ldots;W_K]$, where $[W_1;\\ldots;W_K]$ denotes the row stack of $W_1,\\ldots,W_K$. The open problem is to determine the minimum required length of $Z_k$, denoted as $R_k$, $k\\in [K]$. In this paper, we characterize a new achievable region for the rate tuple $(R_1,\\ldots,R_K)$. The region is polyhedral, with vertices characterized by a binary rate assignment $(R_1,\\ldots,R_K) = (\\mathbf{1}(1 \\in \\mathcal{I}),\\ldots,\\mathbf{1}(K\\in \\mathcal{I}))$, where $\\mathcal{I}\\subseteq [K]$ satisfies the \\textit{rank-increment condition}: $\\mathrm{rank}\\left(\\bigl[\\mathbf{F}_{\\mathcal{I}};\\mathbf{G}_{\\mathcal{I}}\\bigr]\\right) =\\mathrm{rank}\\bigl(\\mathbf{F}_{\\mathcal{I}}\\bigr)+N$. Here, $\\mathbf{F}_\\mathcal{I}$ and $\\mathbf{G}_\\mathcal{I}$ are the submatrices formed by the columns indexed by $\\mathcal{I}$. Our results uncover the novel fact that it is not necessary for every user to hold a key, thereby strictly enlarging the best-known achievable region in the literature. Furthermore, we provide a converse analysis to demonstrate its optimality when minimizing the number of users that hold keys.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u79e9\u9012\u589e\u6761\u4ef6\uff0c\u6784\u9020\u4e86\u65b0\u7684\u7387\u533a\u57df\uff0c\u8868\u660e\u5e76\u975e\u6240\u6709\u7528\u6237\u9700\u8981\u952e\uff0c\u964d\u4f4e\u4e86\u7efc\u5408\u952e\u957f\u5ea6\u9700\u6c42\uff0c\u5e76\u5728\u6700\u5c0f\u6301\u94a5\u7528\u6237\u6570\u4e0a\u5b9e\u73b0\u4e86\u6700\u4f18", "motivation": "\u7814\u7a76\u5411\u91cf\u7ebf\u6027\u5b89\u5168\u805a\u5408\u95ee\u9898\u4e2d\u5404\u7528\u6237\u952e\u957f\u5ea6\u7684\u6700\u5c0f\u9700\u6c42", "method": "\u6784\u9020\u65b0\u7684\u53ef\u5b9e\u73b0\u7387\u533a\u57df\uff0c\u4f7f\u7528\u4e8c\u8fdb\u5236\u7387\u5206\u914d\u4e0e\u79e9\u9012\u589e\u6761\u4ef6", "result": "\u5f97\u5230\u591a\u9762\u4f53\u7387\u533a\u57df\uff0c\u8bc1\u660e\u5e76\u975e\u6240\u6709\u7528\u6237\u5fc5\u9700\u6301\u94a5\uff0c\u4e14\u5728\u6700\u5c0f\u6301\u94a5\u7528\u6237\u6570\u91cf\u4e0a\u5b9e\u73b0\u6700\u4f18", "conclusion": "\u4e3aYuan\u2011Sun\u63d0\u51fa\u7684\u5f00\u653e\u95ee\u9898\u7ed9\u51fa\u6700\u5c0f\u952e\u957f\u5ea6\u7684\u53ef\u884c\u89e3\uff0c\u5e76\u8bc1\u660e\u5176\u5728\u6700\u5c0f\u6301\u94a5\u7528\u6237\u6570\u4e0a\u7684\u6700\u4f18\u6027"}}
{"id": "2601.03005", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03005", "abs": "https://arxiv.org/abs/2601.03005", "authors": ["Xi Wang", "Songlei Jian", "Shasha Li", "Xiaopeng Li", "Zhaoye Li", "Bin Ji", "Baosheng Wang", "Jie Yu"], "title": "JPU: Bridging Jailbreak Defense and Unlearning via On-Policy Path Rectification", "comment": "14 pages, 6 figures, under review;", "summary": "Despite extensive safety alignment, Large Language Models (LLMs) often fail against jailbreak attacks. While machine unlearning has emerged as a promising defense by erasing specific harmful parameters, current methods remain vulnerable to diverse jailbreaks. We first conduct an empirical study and discover that this failure mechanism is caused by jailbreaks primarily activating non-erased parameters in the intermediate layers. Further, by probing the underlying mechanism through which these circumvented parameters reassemble into the prohibited output, we verify the persistent existence of dynamic $\\textbf{jailbreak paths}$ and show that the inability to rectify them constitutes the fundamental gap in existing unlearning defenses. To bridge this gap, we propose $\\textbf{J}$ailbreak $\\textbf{P}$ath $\\textbf{U}$nlearning (JPU), which is the first to rectify dynamic jailbreak paths towards safety anchors by dynamically mining on-policy adversarial samples to expose vulnerabilities and identify jailbreak paths. Extensive experiments demonstrate that JPU significantly enhances jailbreak resistance against dynamic attacks while preserving the model's utility.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fajailbreak\u653b\u51fb\u5229\u7528\u672a\u64e6\u9664\u53c2\u6570\u5f62\u6210\u52a8\u6001\u8def\u5f84\uff0c\u63d0\u51faJPU\u901a\u8fc7\u5bf9\u6297\u6837\u672c\u5468\u671f\u6027\u4fee\u6b63\u8fd9\u4e9b\u8def\u5f84\uff0c\u4ece\u800c\u63d0\u5347LLM\u7684\u5b89\u5168\u6027\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u5df2\u52a0\u5f3a\u5b89\u5168\u6027\uff0c\u5374\u4ecd\u6613\u906d\u9047jailbreak\u653b\u51fb\u3002\u5f53\u524d\u7684\u673a\u5668\u5fd8\u5374\u65b9\u6cd5\u5bf9\u591a\u6837\u5316jailbreak\u8106\u5f31\u3002\u8be5\u7814\u7a76\u901a\u8fc7\u5b9e\u8bc1\u53d1\u73b0\u653b\u51fb\u5b9e\u8d28\u662f\u6fc0\u6d3b\u4e2d\u95f4\u5c42\u672a\u88ab\u6e05\u9664\u53c2\u6570\uff0c\u4e14\u8fd9\u4e9b\u53c2\u6570\u53ef\u52a8\u6001\u91cd\u7ec4\u6784\u6210\u7981\u7528\u8f93\u51fa\uff0c\u63ed\u793a\u5b58\u5728\u52a8\u6001jailbreak\u8def\u5f84\u3002", "method": "\u9996\u6b21\u8bbe\u8ba1Jailbreak Path Unlearning (JPU)\u3002\u901a\u8fc7\u52a8\u6001\u6316\u6398\u5728\u7b56\u7565\uff08on-policy\uff09\u4e0b\u7684\u5bf9\u6297\u6837\u672c\u66b4\u9732\u5b89\u5168\u5f31\u70b9\uff0c\u7136\u540e\u5b9a\u4f4d\u5e76\u7ea0\u6b63\u52a8\u6001jailbreak\u8def\u5f84\uff0c\u4f7f\u6a21\u578b\u56de\u5f52\u5b89\u5168\u951a\u70b9\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cJPU\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u52a8\u6001\u653b\u51fb\u7684\u62b5\u6297\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u539f\u59cb\u529f\u80fd\u6548\u80fd\u3002", "conclusion": "\u5bf9\u6297\u52a8\u6001jailbreak\u7684\u6838\u5fc3\u5728\u4e8e\u53ca\u65f6\u68c0\u6d4b\u5e76\u4fee\u6b63\u52a8\u6001\u8def\u5f84\uff0cJPU\u5b9e\u73b0\u4e86\u6b64\u76ee\u6807\uff0c\u5f25\u8865\u4e86\u5148\u524d\u673a\u5668\u5fd8\u5374\u7f3a\u9677\u3002"}}
{"id": "2601.03234", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.03234", "abs": "https://arxiv.org/abs/2601.03234", "authors": ["Amir Hossein Fahim Raouf", "\u0130smail G\u00fcvenc"], "title": "Inter-Year Transfer of Altitude-Dependent Spectrum Activity Models Using Minimal Calibration", "comment": null, "summary": "This paper studies the transferability of altitude-dependent spectrum activity models and measurements across years. We introduce a physics-informed, mean-only stochastic-geometry model of aggregate interference to altitude-binned received power, yielding three interpretable parameters for a given band and campaign: 1) line-of-sight transition slope, 2) transition altitude, and 3) effective activity constant. Analysis of aerial spectrum measurements collected from 2023 to 2025 across multiple sub-6 GHz bands reveals that downlink (DL) and shared-access bands preserve a persistent geometry-driven altitude structure that is stable across years. In contrast, uplink (UL) bands exhibit weak altitude dependence with no identifiable transition, indicating that interference is dominated by activity dynamics rather than propagation geometry. To quantify the practical limits of model reuse, we evaluate a minimal-calibration method in which the transition altitude is fixed from a reference year and the remaining parameters are estimated from only two altitude bins in the target year. The results further indicate that the proposed approach provides accurate predictions for DL and CBRS bands, suggesting the feasibility of low-cost model transfer in stable environments, while highlighting the reduced applicability of mean-field models for UL scenarios.", "AI": {"tldr": "\u964d\u94fe/\u5171\u4eab\u9891\u6bb5\u6a21\u578b\u8de8\u5e74\u53ef\u590d\u7528\uff1b\u4e0a\u884c\u9891\u6bb5\u5219\u53d7\u76ca\u6709\u9650\u3002", "motivation": "\u63a2\u7d22\u4e0d\u540c\u5e74\u4efd\u4e4b\u95f4\u9ad8\u5ea6\u4f9d\u8d56\u9891\u8c31\u6d3b\u52a8\u6a21\u578b\u7684\u53ef\u8f6c\u79fb\u6027\uff0c\u964d\u4f4e\u9891\u8c31\u6d4b\u91cf\u4e0e\u5efa\u6a21\u7684\u6210\u672c\u3002", "method": "\u6784\u9020\u5e73\u5747\u573a\u5e72\u6270\u7684\u7269\u7406\u4fe1\u606f\u5316\u968f\u673a\u56fe\u6a21\u578b\uff0c\u63d0\u53d6\u7ebf\u6027\u89c6\u8ddd\u6539\u53d8\u659c\u7387\u3001\u8fc7\u6e21\u9ad8\u7a0b\u3001\u6709\u6548\u6d3b\u8dc3\u5e38\u6570\u4e09\u53c2\u6570\uff0c\u5e76\u57fa\u4e8e\u4e24\u4e2a\u9ad8\u5ea6\u533a\u7684\u6700\u5c0f\u6821\u51c6\u65b9\u6cd5\u91cd\u65b0\u4f30\u8ba1\u3002", "result": "\u57282023-2025\u5e74\u591a\u5b506 GHz\u6ce2\u6bb5\u6d4b\u91cf\u9a8c\u8bc1\u4e2d\uff0c\u964d\u94fe\u548cCBRS\u9891\u6bb5\u4fdd\u6301\u4e86\u4e00\u81f4\u7684\u9ad8\u5ea6\u51e0\u4f55\u7ed3\u6784\uff0c\u53ef\u901a\u8fc7\u53ea\u7528\u4e24\u9ad8\u5ea6\u533a\u7684\u6d4b\u91cf\u5728\u65b0\u5e74\u4efd\u51c6\u786e\u9884\u6d4b\uff1b\u4e0a\u884c\u9891\u6bb5\u5219\u4e0d\u5177\u5907\u6b64\u7279\u6027\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u7269\u7406\u4fe1\u606f\u5316\u7684\u5e73\u5747\u573a\u6a21\u578b\u5728\u964d\u94fe\u548c\u5171\u4eab\u9891\u6bb5\u4e2d\u8de8\u5e74\u53ef\u8f6c\u79fb\u6027\u826f\u597d\uff0c\u4f46\u4e0a\u884c\u9891\u6bb5\u7531\u4e8e\u4f20\u64ad\u51e0\u4f55\u5bf9\u5e72\u6270\u5f71\u54cd\u5f31\uff0c\u6a21\u578b\u9002\u7528\u6027\u53d7\u9650\u3002"}}
{"id": "2601.02903", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.02903", "abs": "https://arxiv.org/abs/2601.02903", "authors": ["Zhuangzhuang Cui", "Rudranil Chattopadhyay", "Emiel Vanspranghels", "Sofie Pollin"], "title": "Site-Specific and Frequency-Dependent Channel Characterization and MIMO Performance in FR3", "comment": "Submitted to the IEEE conference for potential publication", "summary": "Next-generation wireless systems aim to enable on-demand connectivity through dynamic spectrum utilization. Motivated by this vision, this paper investigates the propagation characteristics and MIMO performance of the upper mid-band, spanning approximately 7-24 GHz and unofficially referred to as FR3. Using site-specific ray-tracing (RT) simulations based on the Sionna framework, we analyze indoor and outdoor environments at representative frequencies across FR1, FR3, and FR2, including 3.5, 7, 10, 14, 20, 24, and 28 GHz, under both single-antenna and multi-antenna configurations. The results show that FR3 exhibits intermediate propagation behavior between sub-6 GHz and millimeter-wave bands while sustaining effective spatial multiplexing and favorable spectral efficiency. Furthermore, large-array analysis indicates that performance gains in FR3 are closely tied to antenna scaling, highlighting the importance of large-size or large-aperture MIMO architectures for practical deployments.", "AI": {"tldr": "FR3\u9891\u6bb5\u4ecb\u4e8e\u4e9a6 GHz\u4e0emmWave\u4e4b\u95f4\uff0c\u5c04\u7ebf\u8ffd\u8e2a\u663e\u793a\u5176\u652f\u6301\u6709\u6548\u7a7a\u95f4\u590d\u7528\u548c\u9ad8\u9891\u8c31\u6548\u7387\uff0c\u5c24\u5176\u5728\u5927\u5c3a\u5ea6\u5929\u7ebf\u5e03\u5c40\u4e0b\u8868\u73b0\u66f4\u4f73\u3002", "motivation": "\u63a8\u52a8\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u5b9e\u73b0\u6309\u9700\u8fde\u63a5\uff0c\u9a71\u52a8\u5229\u7528\u52a8\u6001\u9891\u8c31\u4ee5\u6ee1\u8db3\u591a\u6837\u5316\u901a\u4fe1\u9700\u6c42\u3002", "method": "\u91c7\u7528\u57fa\u4e8eSionna\u6846\u67b6\u7684\u573a\u666f\u7279\u5b9a\u5c04\u7ebf\u8ffd\u8e2a\u4eff\u771f\uff0c\u5728\u4ee3\u8868\u6027\u9891\u70b9\uff083.5\u30017\u300110\u300114\u300120\u300124\u300128 GHz\uff09\u4e0b\u5bf9\u5ba4\u5185\u5916\u73af\u5883\u8fdb\u884c\u5355\u5929\u7ebf\u4e0e\u591a\u5929\u7ebf\u914d\u7f6e\u5206\u6790\u3002", "result": "FR3\u5728\u7a7a\u4f20\u64ad\u7279\u6027\u4e0a\u5448\u73b0\u4e9a6 GHz\u4e0e\u6beb\u7c73\u6ce2\u4e4b\u95f4\u7684\u4e2d\u95f4\u8868\u73b0\uff0c\u7a7a\u95f4\u590d\u7528\u4fdd\u6301\u6709\u6548\uff1b\u5927\u6570\u7ec4\u5206\u6790\u663e\u793a\u6027\u80fd\u63d0\u5347\u4e0e\u5929\u7ebf\u5c3a\u5ea6\u7d27\u5bc6\u76f8\u5173\uff0c\u5f3a\u8c03\u5927\u5c3a\u5bf8/\u5927\u5b54\u5f84MIMO\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u6307\u51faFR3\u9891\u6bb5\u5728\u4f20\u64ad\u7279\u6027\u4e0eMIMO\u6027\u80fd\u65b9\u9762\u4ecb\u4e8e\u4e9a6 GHz\u4e0e\u6beb\u7c73\u6ce2\u4e4b\u95f4\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u5929\u7ebf\u67b6\u6784\u4e0b\u53ef\u5b9e\u73b0\u663e\u8457\u7a7a\u95f4\u590d\u7528\u4e0e\u9891\u8c31\u6548\u7387\u63d0\u5347\u3002"}}
{"id": "2601.03013", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.03013", "abs": "https://arxiv.org/abs/2601.03013", "authors": ["Hiroyuki Okada", "Tatsumi Oba", "Naoto Yanai"], "title": "LLMs, You Can Evaluate It! Design of Multi-perspective Report Evaluation for Security Operation Centers", "comment": null, "summary": "Security operation centers (SOCs) often produce analysis reports on security incidents, and large language models (LLMs) will likely be used for this task in the near future. We postulate that a better understanding of how veteran analysts evaluate reports, including their feedback, can help produce analysis reports in SOCs. In this paper, we aim to leverage LLMs for analysis reports. To this end, we first construct a Analyst-wise checklist to reflect SOC practitioners' opinions for analysis report evaluation through literature review and user study with SOC practitioners. Next, we design a novel LLM-based conceptual framework, named MESSALA, by further introducing two new techniques, granularization guideline and multi-perspective evaluation. MESSALA can maximize report evaluation and provide feedback on veteran SOC practitioners' perceptions. When we conduct extensive experiments with MESSALA, the evaluation results by MESSALA are the closest to those of veteran SOC practitioners compared with the existing LLM-based methods. We then show two key insights. We also conduct qualitative analysis with MESSALA, and then identify that MESSALA can provide actionable items that are necessary for improving analysis reports.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMESSALA\u6846\u67b6\uff0c\u7ed3\u5408CHECKLIST\u3001granularization guideline\u548cmulti\u2011perspective evaluation\uff0c\u663e\u8457\u63d0\u5347LLM\u5728SOC\u5206\u6790\u62a5\u544a\u8bc4\u4f30\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u7406\u89e3\u8d44\u6df1\u5206\u6790\u5e08\u5728\u8bc4\u4f30SOC\u5206\u6790\u62a5\u544a\u65f6\u7684\u6807\u51c6\u53ca\u53cd\u9988\uff0c\u65e8\u5728\u63d0\u5347LLM\u751f\u6210\u62a5\u544a\u7684\u8d28\u91cf\u4e0e\u53ef\u7528\u6027\u3002", "method": "\u901a\u8fc7\u6784\u5efaAnalyst-wise checklist\u5e76\u5f15\u5165granularization guideline\u4e0emulti-perspective evaluation\u6280\u672f\uff0c\u8bbe\u8ba1\u4e86MESSALA\u6846\u67b6\uff0c\u5e76\u5728\u5927\u91cf\u5b9e\u9a8c\u4e2d\u4e0e\u73b0\u6709LLM\u65b9\u6cd5\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMESSALA\u5728\u8bc4\u4f30\u6307\u6807\u4e0a\u4e0e\u8d44\u6df1SOC\u5206\u6790\u5e08\u6700\u4e3a\u63a5\u8fd1\uff0c\u5e76\u80fd\u63d0\u4f9b\u6539\u8fdb\u62a5\u544a\u7684\u53ef\u64cd\u4f5c\u6027\u5efa\u8bae\u3002", "conclusion": "Mellisa\u6846\u67b6\u5728\u8bc4\u4f30SOC\u5206\u6790\u62a5\u544a\u65f6\uff0c\u80fd\u591f\u4ea7\u751f\u4e0e\u8d44\u6df1\u5206\u6790\u5e08\u8bc4\u4ef7\u6700\u4e3a\u63a5\u8fd1\u7684\u7ed3\u679c\uff0c\u4ece\u800c\u8bc1\u660e\u8be5\u6846\u67b6\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.02562", "categories": ["cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.02562", "abs": "https://arxiv.org/abs/2601.02562", "authors": ["Rohit Kaushik", "Eva Kaushik"], "title": "CutisAI: Deep Learning Framework for Automated Dermatology and Cancer Screening", "comment": "10 pages, 3 figures", "summary": "The rapid growth of dermatological imaging and mobile diagnostic tools calls for systems that not only demonstrate empirical performance but also provide strong theoretical guarantees. Deep learning models have shown high predictive accuracy; however, they are often criticized for lacking well, calibrated uncertainty estimates without which these models are hardly deployable in a clinical setting. To this end, we present the Conformal Bayesian Dermatological Classifier (CBDC), a well, founded framework that combines Statistical Learning Theory, Topological Data Analysis (TDA), and Bayesian Conformal Inference. CBDC offers distribution, dependent generalization bounds that reflect dermatological variability, proves a topological stability theorem that guarantees the invariance of convolutional neural network embeddings under photometric and morphological perturbations and provides finite conformal coverage guarantees for trustworthy uncertainty quantification.\n  Through exhaustive experiments on the HAM10000, PH2, and ISIC 2020 datasets, we show that CBDC not only attains classification accuracy but also generates calibrated predictions that are interpretable from a clinical perspective. This research constitutes a theoretical and practical leap for deep dermatological diagnostics, thereby opening the machine learning theory clinical applicability interface.", "AI": {"tldr": "CBDC\u5c06\u7406\u8bba\u4e0e\u5b9e\u8df5\u76f8\u7ed3\u5408\uff0c\u63d0\u4f9b\u5728\u76ae\u80a4\u8bca\u65ad\u4e2d\u53ef\u7f6e\u4fe1\u3001\u53ef\u89e3\u91ca\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u51c6\u786e\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u6548\u679c\u3002", "motivation": "\u968f\u7740\u76ae\u80a4\u5f71\u50cf\u4e0e\u79fb\u52a8\u8bca\u65ad\u5de5\u5177\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5355\u9760\u51c6\u786e\u7387\u5df2\u4e0d\u8db3\u4ee5\u8fdb\u5165\u4e34\u5e8a\uff0c\u9700\u8981\u5f97\u5230\u53ef\u9760\u4e14\u53ef\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u4ee5\u4fdd\u969c\u5b89\u5168\u53ef\u90e8\u7f72\u3002", "method": "\u878d\u5408\u7edf\u8ba1\u5b66\u4e60\u7406\u8bba\u3001\u62d3\u6251\u6570\u636e\u5206\u6790\uff08TDA\uff09\u548c\u8d1d\u53f6\u65af\u5408\u7ea6\u63a8\u65ad\uff0c\u6784\u5efaCBDC\u6846\u67b6\uff1b\u5bf9CNN\u5d4c\u5165\u5c42\u8bc1\u660e\u62d3\u6251\u7a33\u5b9a\u6027\uff0c\u5e76\u5e94\u7528\u6709\u9650\u805a\u5408\u5f0f\u5185\u8bc1\u65b9\u6cd5\u7ed9\u51fa\u4e0d\u786e\u5b9a\u6027\u8986\u76d6\u754c\u3002", "result": "\u5728HAM10000\u3001PH2\u53caISIC 2020\u6570\u636e\u96c6\u4e0a\uff0cCBDC\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u9ad8\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u540c\u65f6\u8f93\u51fa\u4e0e\u4e34\u5e8a\u4e00\u81f4\u3001\u53ef\u89e3\u91ca\u7684\u6821\u51c6\u9884\u6d4b\uff0c\u9a8c\u8bc1\u4e86\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u517c\u5bb9\u6027\u3002", "conclusion": "CBDC\u63d0\u4f9b\u4e86\u4e25\u8c28\u7684\u7406\u8bba\u4fdd\u969c\uff08\u53ef\u6cdb\u5316\u754c\u3001\u62d3\u6251\u7a33\u5b9a\u5b9a\u7406\u548c\u6709\u9650\u5185\u8bc1\u8986\u76d6\u4fdd\u8bc1\uff09\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u3001\u53ef\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u4e3a\u4e34\u5e8a\u90e8\u7f72\u7684\u6df1\u5ea6\u76ae\u80a4\u5b66\u8bca\u65ad\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.03031", "categories": ["cs.CR", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.03031", "abs": "https://arxiv.org/abs/2601.03031", "authors": ["Jing Liu", "Liang Feng Zhang"], "title": "FlexProofs: A Vector Commitment with Flexible Linear Time for Computing All Proofs", "comment": "Accepted by ACNS 2026", "summary": "In this paper, we introduce FlexProofs, a new vector commitment (VC) scheme that achieves two key properties: (1) the prover can generate all individual opening proofs for a vector of size $N$ in optimal time ${\\cal O}(N)$, and there is a flexible batch size parameter $b$ that can be increased to further reduce the time to generate all proofs; and (2) the scheme is directly compatible with a family of zkSNARKs that encode their input as a multi-linear polynomial. As a critical building block, we propose the first functional commitment (FC) scheme for multi-exponentiations with batch opening. Compared with HydraProofs, the only existing VC scheme that computes all proofs in optimal time ${\\cal O}(N)$ and is directly compatible with zkSNARKs, FlexProofs may speed up the process of generating all proofs, if the parameter $b$ is properly chosen. Our experiments show that for $N=2^{16}$ and $b=\\log^2 N$, FlexProofs can be $6\\times$ faster than HydraProofs. Moreover, when combined with suitable zkSNARKs, FlexProofs enable practical applications such as verifiable secret sharing and verifiable robust aggregation.", "AI": {"tldr": "FlexProofs\u662f\u4e00\u4e2a\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u5411\u91cf\u627f\u8bfa\u65b9\u6848\uff0c\u4ee5O(N)\u65f6\u95f4\u751f\u6210\u6240\u6709\u5f00\u542f\u8bc1\u660e\u5e76\u652f\u6301\u53ef\u8c03\u6279\u5904\u7406\u53c2\u6570\uff1b\u5b9e\u9a8c\u8868\u660e\u5176\u6bd4HydraProofs\u5feb6\u500d\uff0c\u517c\u5bb9\u591a\u7ebf\u6027\u591a\u9879\u5f0fzkSNARK\uff0c\u63a8\u52a8\u53ef\u9a8c\u8bc1\u79d8\u5bc6\u5171\u4eab\u4e0e\u9c81\u68d2\u805a\u5408\u7b49\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u5411\u91cf\u627f\u8bfa\u5982HydraProofs\u5df2\u5b9e\u73b0O(N)\u65f6\u95f4\uff0c\u4f46\u5bf9\u6279\u5904\u7406\u652f\u6301\u6709\u9650\uff1b\u7f3a\u5c11\u9ad8\u6548\u4e14\u517c\u5bb9\u5177\u5907\u591a\u7ebf\u6027\u591a\u9879\u5f0f\u8f93\u5165\u7684zkSNARK\u7684\u65b9\u6848\uff1b\u63d0\u5347\u8bc1\u660e\u751f\u6210\u901f\u5ea6\u4e0e\u7075\u6d3b\u6027\u662f\u5b9e\u73b0\u53ef\u6269\u5c55\u53ef\u9a8c\u8bc1\u5e94\u7528\u7684\u5173\u952e\u9700\u6c42\u3002", "method": "\u9996\u5148\u63d0\u51fa\u4e86\u9996\u4e2a\u652f\u6301\u6279\u5f00\u542f\u7684\u591a\u6307\u6570\u529f\u80fd\u627f\u8bfa\uff08FC\uff09\u65b9\u6848\uff1b\u7136\u540e\u57fa\u4e8e\u6b64\u6784\u9020FlexProofs\u5411\u91cf\u627f\u8bfa\uff0c\u5229\u7528\u53ef\u8c03\u7684\u6279\u5927\u5c0f\u53c2\u6570b\u6765\u91cd\u6784\u8bc1\u660e\u751f\u6210\u6d41\u7a0b\uff0c\u4f7f\u9a8c\u8bc1\u6548\u7387\u7ef4\u6301O(N)\u7684\u540c\u65f6\u964d\u4f4e\u5e38\u6570\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0cN=2^16\u4e14b=log^2 N\u65f6\uff0cFlexProofs\u6bd4HydraProofs\u5feb\u7ea66\u500d\uff1b\u4e0e\u76f8\u5e94zkSNARK\u7ed3\u5408\u540e\uff0c\u53ef\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u79d8\u5bc6\u5206\u53d1\u4e0e\u9c81\u68d2\u805a\u5408\u7684\u5b9e\u7528\u90e8\u7f72\u3002", "conclusion": "FlexProofs\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u578b\u5411\u91cf\u627f\u8bfa\u65b9\u6848\uff0c\u80fd\u591f\u4ee5\u6700\u4f18\u65f6\u95f4\u751f\u6210\u4e2a\u4f53\u5f00\u542f\u8bc1\u660e\uff0c\u5e76\u652f\u6301\u53ef\u8c03\u6279\u5904\u7406\u53c2\u6570\uff0c\u663e\u8457\u52a0\u5feb\u8bc1\u660e\u751f\u6210\u901f\u5ea6\uff1b\u540c\u65f6\u4e0e\u591a\u7ebf\u6027\u591a\u9879\u5f0f\u7c7bzkSNARKs\u517c\u5bb9\uff0c\u62d3\u5c55\u4e86\u53ef\u9a8c\u8bc1\u79d8\u5bc6\u5171\u4eab\u548c\u9c81\u68d2\u805a\u5408\u7b49\u5e94\u7528\u3002"}}
{"id": "2601.03171", "categories": ["cs.NI", "cs.ET", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.03171", "abs": "https://arxiv.org/abs/2601.03171", "authors": ["Silvano Cortesi", "Lukas Schulthess", "Davide Plozza", "Christian Vogt", "Michele Magno"], "title": "Eco-WakeLoc: An Energy-Neutral and Cooperative UWB Real-Time Locating System", "comment": "This work has been accepted for publication in the IEEE Sensors Journal, specifically the Special Issue on \"Special Issue on Advances in Resource-Efficient Sensors and Interfaces Fostered by Artificial Intelligence\"", "summary": "Indoor localization systems face a fundamental trade-off between efficiency and responsiveness, which is especially important for emerging use cases such as mobile robots operating in GPS-denied environments. Traditional RTLS either require continuously powered infrastructure, limiting their scalability, or are limited by their responsiveness. This work presents Eco-WakeLoc, designed to achieve centimeter-level UWB localization while remaining energy-neutral by combining ultra-low power wake-up radios (WuRs) with solar energy harvesting. By activating anchor nodes only on demand, the proposed system eliminates constant energy consumption while achieving centimeter-level positioning accuracy. To reduce coordination overhead and improve scalability, Eco-WakeLoc employs cooperative localization where active tags initiate ranging exchanges (trilateration), while passive tags opportunistically reuse these messages for TDOA positioning. An additive-increase/multiplicative-decrease (AIMD)-based energy-aware scheduler adapts localization rates according to the harvested energy, thereby maximizing the overall performance of the sensor network while ensuring long-term energy neutrality. The measured energy consumption is only 3.22mJ per localization for active tags, 951uJ for passive tags, and 353uJ for anchors. Real-world deployment on a quadruped robot with nine anchors confirms the practical feasibility, achieving an average accuracy of 43cm in dynamic indoor environments. Year-long simulations show that tags achieve an average of 2031 localizations per day, retaining over 7% battery capacity after one year -- demonstrating that the RTLS achieves sustained energy-neutral operation. Eco-WakeLoc demonstrates that high-accuracy indoor localization can be achieved at scale without continuous infrastructure operation, combining energy neutrality, cooperative positioning, and adaptive scheduling.", "AI": {"tldr": "Eco\u2011WakeLoc \u4f7f\u7528\u5524\u9192\u65e0\u7ebf\u7535\u4e0e\u5149\u80fd\u6536\u96c6\uff0c\u4ec5\u6fc0\u6d3b\u951a\u70b9\u5b9e\u73b0\u4f4e\u529f\u8017\u5398\u7c73\u7ea7UWB\u5b9a\u4f4d\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u8017\u6781\u4f4e\u3001\u7cbe\u5ea6\u8fbe43\u202fcm\uff0c\u5e76\u53ef\u5728\u4e00\u5e74\u5185\u4fdd\u6301\u80fd\u91cf\u4e2d\u6027\u3002", "motivation": "\u5728GPS\u4e0d\u53ef\u7528\u7684\u5ba4\u5185\u73af\u5883\u4e0b\uff0c\u79fb\u52a8\u673a\u5668\u4eba\u9700\u8981\u5b9e\u65f6\u4e14\u80fd\u8017\u4f4e\u7684\u5b9a\u4f4d\u7cfb\u7edf\uff0c\u4f20\u7edfRTLS\u8981\u4e48\u6301\u7eed\u4f9b\u7535\u5f71\u54cd\u53ef\u6269\u5c55\u6027\uff0c\u8981\u4e48\u54cd\u5e94\u6162\u3002", "method": "Eco\u2011WakeLoc \u91c7\u7528\u4f4e\u529f\u8017\u5524\u9192\u65e0\u7ebf\u7535\u4e0e\u5149\u80fd\u6536\u96c6\uff0c\u4ec5\u6309\u9700\u6fc0\u6d3b\u951a\u70b9\uff0c\u5b9e\u73b0\u5398\u7c73\u7ea7UWB\u5b9a\u4f4d\uff1b\u4e3b\u52a8\u6807\u7b7e\u53d1\u8d77\u4e09\u89d2\u6d4b\u8ddd\uff0c\u5f85\u673a\u6807\u7b7e\u5229\u7528\u540c\u4e00\u6d88\u606f\u505aTDOA\uff1b\u901a\u8fc7 AIMD \u80fd\u8017\u8c03\u5ea6\u6839\u636e\u6536\u96c6\u80fd\u91cf\u52a8\u6001\u8c03\u6574\u5b9a\u4f4d\u901f\u7387\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\uff1a\u4e3b\u52a8\u6807\u7b7e\u5355\u6b21\u5b9a\u4f4d\u8017\u80fd3.22\u202fmJ\u3001\u88ab\u52a8\u6807\u7b7e951\u202f\u00b5J\u3001\u951a\u70b9353\u202f\u00b5J\uff1b\u5728\u4e00\u4e2a\u56db\u8db3\u673a\u5668\u4eba\u4e0a\u90e8\u7f72\u4e5d\u4e2a\u951a\u70b9\uff0c\u5e73\u5747\u5b9a\u4f4d\u7cbe\u5ea643\u202fcm\uff1b\u4e00\u5e74\u6a21\u62df\u540e\u6bcf\u65e5\u5e73\u57472031\u6b21\u5b9a\u4f4d\uff0c\u7535\u6c60\u4f59\u80fd\u8d85\u8fc77%\u3002", "conclusion": "Eco\u2011WakeLoc \u901a\u8fc7\u80fd\u8017\u4e2d\u6027\u3001\u534f\u540c\u5b9a\u4f4d\u4e0e\u81ea\u9002\u5e94\u8c03\u5ea6\uff0c\u5728\u4e0d\u6301\u7eed\u5f00\u542f\u57fa\u7840\u8bbe\u65bd\u7684\u524d\u63d0\u4e0b\uff0c\u80fd\u591f\u5927\u89c4\u6a21\u5b9e\u73b0\u5398\u7c73\u7ea7\u5ba4\u5185\u5b9a\u4f4d\u3002"}}
{"id": "2601.03132", "categories": ["eess.SY", "cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03132", "abs": "https://arxiv.org/abs/2601.03132", "authors": ["Mintae Kim"], "title": "Finite Memory Belief Approximation for Optimal Control in Partially Observable Markov Decision Processes", "comment": "6 pages, 3 figures", "summary": "We study finite memory belief approximation for partially observable (PO) stochastic optimal control (SOC) problems. While belief states are sufficient for SOC in partially observable Markov decision processes (POMDPs), they are generally infinite-dimensional and impractical. We interpret truncated input-output (IO) histories as inducing a belief approximation and develop a metric-based theory that directly relates information loss to control performance. Using the Wasserstein metric, we derive policy-conditional performance bounds that quantify value degradation induced by finite memory along typical closed-loop trajectories. Our analysis proceeds via a fixed-policy comparison: we evaluate two cost functionals under the same closed-loop execution and isolate the effect of replacing the true belief by its finite memory approximation inside the belief-level cost. For linear quadratic Gaussian (LQG) systems, we provide closed-form belief mismatch evaluation and empirically validate the predicted mechanism, demonstrating that belief mismatch decays approximately exponentially with memory length and that the induced performance mismatch scales accordingly. Together, these results provide a metric-aware characterization of what finite memory belief approximation can and cannot achieve in PO settings.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03003", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.03003", "abs": "https://arxiv.org/abs/2601.03003", "authors": ["Ziyao Zhou", "Hen-Wei Huang"], "title": "Closed-Loop Transmission Power Control for Reliable and Low-Power BLE Communication in Dynamic IoT Settings", "comment": "13 pages, 18 figures, published in IEEE Internet of Things Journal", "summary": "Reliable and energy-efficient Bluetooth Low Energy (BLE) communication is crucial for Internet of Things (IoT) applications in dynamic environments. However, the Received Signal Strength Indicator (RSSI) and data throughput in BLE are highly susceptible to environmental variability, which degrades communication performance. In this work, we systematically analyze the interdependence among RSSI, throughput, transmission power (TXP), and the peripheral device system power consumption under diverse real-world conditions. We observe that adjusting the TXP effectively influences both RSSI and throughput. We propose a robust closed-loop TXP control framework based on Proportional-Integral-Derivative (PID) controllers. Two initial control strategies are investigated: an RSSI-based approach and a throughput-based approach, each exhibiting distinct advantages and limitations. The RSSI-based method provides rapid responsiveness to signal fluctuations but lacks direct correlation with data throughput, whereas the throughput-based method offers more accurate feedback on effective throughput at the cost of slower response. To address these limitations, a hybrid RSSI-throughput control strategy is developed, combining the responsiveness of RSSI feedback with the accuracy of throughput measurements. Experimental results demonstrate that the proposed hybrid approach maintains data throughput close to the target level with minimal variance, even under rapidly changing environmental conditions.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408 RSSI-\u541e\u5410\u91cf\u53cd\u9988\u63a7\u5236\uff08\u57fa\u4e8e PID\uff09\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4fdd\u6301\u9ad8\u541e\u5410\u91cf\u4e14\u80fd\u6548\u7684\u95ed\u73af TXP \u8c03\u8282\u65b9\u6848\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u6548\u679c\u4f18\u4e8e\u5355\u4e00\u7b56\u7565\u3002", "motivation": "BLE \u7684 RSSI \u4e0e\u541e\u5410\u91cf\u6613\u53d7\u73af\u5883\u53d8\u5316\u5f71\u54cd\uff0c\u5bfc\u81f4\u4f20\u8f93\u8d28\u91cf\u4e0b\u964d\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5feb\u901f\u54cd\u5e94\u53c8\u80fd\u4fdd\u8bc1\u541e\u5410\u91cf\u7684\u80fd\u6548\u63a7\u5236\u65b9\u6848\u3002", "method": "\u95ed\u73af TXP \u63a7\u5236\u6846\u67b6\uff0c\u5148\u5206\u522b\u8003\u5bdf RSSI \u548c\u541e\u5410\u91cf\u4e24\u4e2a\u63a7\u5236\u7b56\u7565\uff0c\u968f\u540e\u5f15\u5165\u6df7\u5408\u7b56\u7565\u5c06\u4e24\u8005\u4fe1\u53f7\u8fdb\u884c\u878d\u5408\u5e76\u901a\u8fc7 PID \u8c03\u6574 TXP\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6df7\u5408\u7b56\u7565\u5728\u5feb\u901f\u53d8\u5316\u7684\u73af\u5883\u4e0b\u4ecd\u80fd\u4fdd\u6301\u541e\u5410\u91cf\u63a5\u8fd1\u76ee\u6807\u6c34\u5e73\uff0c\u65b9\u5dee\u6700\u5c0f\uff0c\u4f18\u4e8e\u5355\u4e00 RSSI \u6216\u541e\u5410\u91cf\u63a7\u5236\u3002", "conclusion": "\u57fa\u4e8e PID \u7684\u6df7\u5408 RSSI-\u541e\u5410\u91cf\u53cd\u9988\u63a7\u5236\u80fd\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7a33\u5b9a\u7ef4\u6301\u76ee\u6807\u541e\u5410\u91cf\uff0c\u54cd\u5e94\u901f\u5ea6\u5feb\u4e14\u6ce2\u52a8\u5c0f\u3002"}}
{"id": "2601.02573", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.02573", "abs": "https://arxiv.org/abs/2601.02573", "authors": ["Kiarash Shamsi", "Danijel Novokmet", "Joshua Peters", "Mao Lin Liu", "Paul K Edwards", "Vahab Khoshdel"], "title": "LendNova: Towards Automated Credit Risk Assessment with Language Models", "comment": null, "summary": "Credit risk assessment is essential in the financial sector, but has traditionally depended on costly feature-based models that often fail to utilize all available information in raw credit records. This paper introduces LendNova, the first practical automated end-to-end pipeline for credit risk assessment, designed to utilize all available information in raw credit records by leveraging advanced NLP techniques and language models. LendNova transforms risk modeling by operating directly on raw, jargon-heavy credit bureau text using a language model that learns task-relevant representations without manual feature engineering. By automatically capturing patterns and risk signals embedded in the text, it replaces manual preprocessing steps, reducing costs and improving scalability. Evaluation on real-world data further demonstrates its strong potential in accurate and efficient risk assessment. LendNova establishes a baseline for intelligent credit risk agents, demonstrating the feasibility of language models in this domain. It lays the groundwork for future research toward foundation systems that enable more accurate, adaptable, and automated financial decision-making.", "AI": {"tldr": "LendNova\u5229\u7528\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u4ece\u539f\u59cb\u4fe1\u7528\u6587\u672c\u4e2d\u5b66\u4e60\u98ce\u9669\u8868\u793a\uff0c\u5f62\u6210\u81ea\u52a8\u5316\u3001\u6210\u672c\u4f4e\u3001\u53ef\u6269\u5c55\u7684\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\u7ba1\u9053\uff0c\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u5c55\u793a\u51fa\u826f\u597d\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u4fe1\u7528\u98ce\u9669\u6a21\u578b\u6210\u672c\u9ad8\u4e14\u65e0\u6cd5\u5145\u5206\u5229\u7528\u5305\u542b\u5927\u91cf\u884c\u8bdd\u7684\u539f\u59cb\u6587\u672c\u4fe1\u606f\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u4f4e\u6210\u672c\u3001\u66f4\u9ad8\u53ef\u6269\u5c55\u6027\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5148\u8fdb\u7684NLP\u6280\u672f\u548c\u8bed\u8a00\u6a21\u578b\u5bf9\u4fe1\u7528\u5c40\u539f\u59cb\u6587\u672c\u8fdb\u884c\u7279\u5f81\u5b66\u4e60\u548c\u98ce\u9669\u4fe1\u53f7\u63d0\u53d6\uff0c\u81ea\u52a8\u5316\u66ff\u4ee3\u4f20\u7edf\u624b\u5de5\u9884\u5904\u7406\u548c\u7279\u5f81\u5de5\u7a0b\uff0c\u6784\u5efa\u5b8c\u6574\u7684\u98ce\u9669\u8bc4\u4f30\u6d41\u6c34\u7ebf\u3002", "result": "\u5728\u771f\u5b9e\u91d1\u878d\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLendNova\u5b9e\u73b0\u4e86\u4e0e\u4f20\u7edf\u6a21\u578b\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u9884\u5904\u7406\u6b65\u9aa4\uff0c\u9a8c\u8bc1\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u4fe1\u7528\u98ce\u9669\u9886\u57df\u7684\u53ef\u884c\u6027\u3002", "conclusion": "LendNova\u901a\u8fc7\u76f4\u63a5\u5904\u7406\u539f\u59cb\u4fe1\u7528\u6587\u4ef6\u6587\u672c\uff0c\u5229\u7528\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7684\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\uff0c\u964d\u4f4e\u4e86\u4eba\u5de5\u7279\u5f81\u5de5\u7a0b\u6210\u672c\uff0c\u63d0\u5347\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2601.03242", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.03242", "abs": "https://arxiv.org/abs/2601.03242", "authors": ["Hengyu Wu", "Yang Cao"], "title": "SLIM: Stealthy Low-Coverage Black-Box Watermarking via Latent-Space Confusion Zones", "comment": null, "summary": "Training data is a critical and often proprietary asset in Large Language Model (LLM) development, motivating the use of data watermarking to embed model-transferable signals for usage verification. We identify low coverage as a vital yet largely overlooked requirement for practicality, as individual data owners typically contribute only a minute fraction of massive training corpora. Prior methods fail to maintain stealthiness, verification feasibility, or robustness when only one or a few sequences can be modified. To address these limitations, we introduce SLIM, a framework enabling per-user data provenance verification under strict black-box access. SLIM leverages intrinsic LLM properties to induce a Latent-Space Confusion Zone by training the model to map semantically similar prefixes to divergent continuations. This manifests as localized generation instability, which can be reliably detected via hypothesis testing. Experiments demonstrate that SLIM achieves ultra-low coverage capability, strong black-box verification performance, and great scalability while preserving both stealthiness and model utility, offering a robust solution for protecting training data in modern LLM pipelines.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03007", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.03007", "abs": "https://arxiv.org/abs/2601.03007", "authors": ["Jingbo Qu", "Yijie Wang", "Yujie Fu", "Putai Zhang", "Weihan Li", "Mian Li"], "title": "From inconsistency to decision: explainable operation and maintenance of battery energy storage systems", "comment": "13 pages, 5 figures", "summary": "Battery Energy Storage Systems (BESSs) are increasingly critical to power-system stability, yet their operation and maintenance remain dominated by reactive, expert-dependent diagnostics. While cell-level inconsistencies provide early warning signals of degradation and safety risks, the lack of scalable and interpretable decision-support frameworks prevents these signals from being effectively translated into operational actions. Here we introduce an inconsistency-driven operation and maintenance paradigm for large-scale BESSs that systematically transforms routine monitoring data into explainable, decision-oriented guidance. The proposed framework integrates multi-dimensional inconsistency evaluation with large language model-based semantic reasoning to bridge the gap between quantitative diagnostics and practical maintenance decisions. Using eight months of field data from an in-service battery system comprising 3,564 cells, we demonstrate how electrical, thermal, and aging-related inconsistencies can be distilled into structured operational records and converted into actionable maintenance insights through a multi-agent framework. The proposed approach enables accurate and explainable responses to real-world operation and maintenance queries, reducing response time and operational cost by over 80% compared with conventional expert-driven practices. These results establish a scalable pathway for intelligent operation and maintenance of battery energy storage systems, with direct implications for reliability, safety, and cost-effective integration of energy storage into modern power systems.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02581", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02581", "abs": "https://arxiv.org/abs/2601.02581", "authors": ["Aditi Sanjay Agrawal"], "title": "Threat Detection in Social Media Networks Using Machine Learning Based Network Analysis", "comment": "11 Pages, 6 figures", "summary": "The accelerated development of social media websites has posed intricate security issues in cyberspace, where these sites have increasingly become victims of criminal activities including attempts to intrude into them, abnormal traffic patterns, and organized attacks. The conventional rule-based security systems are not always scalable and dynamic to meet such a threat. This paper introduces a threat detection framework based on machine learning that can be used to classify malicious behavior in the social media network environment based on the nature of network traffic. Exploiting a rich network traffic dataset, the massive preprocessing and exploratory data analysis is conducted to overcome the problem of data imbalance, feature inconsistency, and noise. A model of artificial neural network (ANN) is then created to acquire intricate, non-linear tendencies of malicious actions. The proposed model is tested on conventional performance metrics, such as accuracy, accuracy, recall, F1-score, and ROC-AUC, and shows good detection and high levels of strength. The findings suggest that neural network-based solutions have the potential to be used effectively to identify the latent threat dynamics within the context of a large-scale social media network and that they can be employed to complement the existing intrusion detection system and better to conduct proactive cybersecurity operations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02930", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.02930", "abs": "https://arxiv.org/abs/2601.02930", "authors": ["Hicham Lakhlef", "Mohamed Ali Zormati", "Khaled Abid", "Toufik Ahmed"], "title": "Probabilistic Time Slot Leasing in TDMA-Based IoT Networks for Enhanced Channel Utilization", "comment": null, "summary": "In large-scale resource-constrained wireless networks, such as those prevalent in the Internet of Things (IoT), efficient communication scheduling remains a critical challenge. Among the various approaches, Time Division Multiple Access (TDMA) protocols have been widely adopted for their structured and collision-free communication capabilities. Nevertheless, despite extensive research in this area, current solutions often exhibit suboptimal performance, particularly in dynamic environments where node activity levels fluctuate over time.\n  This paper introduces a novel fully distributed TDMA-based scheduling protocol that intelligently maximizes the utilization of communication resources. The proposed approach adaptively reallocates underutilized time slots, originally assigned to temporarily inactive nodes, to those experiencing higher communication demands. This dynamic reallocation not only improves channel utilization but also reduces idle periods, thereby enhancing overall network efficiency. To further enhance performance, we incorporate a lightweight probabilistic mechanism that governs the temporal leasing of unused slots. This mechanism balances the trade-off between slot availability and transmission reliability, minimizing packet loss while preserving fairness and stability within the network.\n  Simulations across a range of network scenarios demonstrate that our protocol significantly improves throughput, latency, and reliability in resource-constrained environments. These results highlight the protocol's potential as a robust and scalable solution for adaptive and energy-efficient scheduling in next-generation IoT networks.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02609", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.02609", "abs": "https://arxiv.org/abs/2601.02609", "authors": ["Arjun S. Nair"], "title": "Chronicals: A High-Performance Framework for LLM Fine-Tuning with 3.51x Speedup over Unsloth", "comment": "61 pages, 25 figures, open-source framework available at https://github.com/Ajwebdevs/Chronicals and pip install chronicals", "summary": "Large language model fine-tuning is bottlenecked by memory: a 7B parameter model requires 84GB--14GB for weights, 14GB for gradients, and 56GB for FP32 optimizer states--exceeding even A100-40GB capacity. We present Chronicals, an open-source training framework achieving 3.51x speedup over Unsloth through four synergistic optimizations: (1) fused Triton kernels eliminating 75% of memory traffic via RMSNorm (7x), SwiGLU (5x), and QK-RoPE (2.3x) fusion; (2) Cut Cross-Entropy reducing logit memory from 5GB to 135MB through online softmax computation; (3) LoRA+ with theoretically-derived 16x differential learning rates between adapter matrices; and (4) Best-Fit Decreasing sequence packing recovering 60-75% of compute wasted on padding.\n  On Qwen2.5-0.5B with A100-40GB, Chronicals achieves 41,184 tokens/second for full fine-tuning versus Unsloth's 11,736 tokens/second (3.51x). For LoRA at rank 32, we reach 11,699 tokens/second versus Unsloth MAX's 2,857 tokens/second (4.10x). Critically, we discovered that Unsloth's reported 46,000 tokens/second benchmark exhibited zero gradient norms--the model was not training.\n  We provide complete mathematical foundations: online softmax correctness proofs, FlashAttention IO complexity bounds O(N^2 d^2 M^{-1}), LoRA+ learning rate derivations from gradient magnitude analysis, and bin-packing approximation guarantees. All implementations, benchmarks, and proofs are available at https://github.com/Ajwebdevs/Chronicals with pip installation via https://pypi.org/project/chronicals/.", "AI": {"tldr": "\u901a\u8fc7\u56db\u79cd\u4f18\u5316\uff0cChronicals\u5c06\u663e\u5b58\u9700\u6c42\u964d\u81f3A100-40GB\u53ef\u7528\u8303\u56f4\uff0c\u5e76\u5728\u540c\u7c7b\u6846\u67b6\u4e0a\u5b9e\u73b03.5-4.1\u500d\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u5927\u6a21\u578b\u5fae\u8c03\u53d7\u663e\u5b58\u9650\u5236\uff0c\u901f\u5ea6\u4f4e\u4e0b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u8bad\u7ec3\u6846\u67b6\u3002", "method": "\u878d\u5408Triton\u5185\u6838\u3001Cut Cross-Entropy\u3001LoRA+\u5dee\u5f02\u5b66\u4e60\u7387\u4ee5\u53ca\u5e8f\u5217\u6253\u5305\u7b49\u56db\u9879\u6280\u672f\u3002", "result": "\u5bf9Qwen2.5-0.5B\u6a21\u578b\uff0cChronicals\u5728A100-40GB\u663e\u5b58\u4e0a\u5b9e\u73b041,184 tokens/second\uff0c\u6bd4Unsloth\u5feb3.51\u500d\uff1bLoRA Rank32\u65f6\u4e3a11,699 tokens/second\uff0c\u901f\u7387\u63d0\u53474.10\u500d\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86Chronicals\u6846\u67b6\u5728\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2d\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u663e\u8457\u964d\u4f4e\u663e\u5b58\u5360\u7528\u5e76\u63d0\u5347\u541e\u5410\u91cf\u3002"}}
{"id": "2601.03143", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.03143", "abs": "https://arxiv.org/abs/2601.03143", "authors": ["Yuta Takahashi", "Hiraku Sakamoto", "Shin-ichiro Sakai"], "title": "Time-Varying Kinematics Control for Magnetically-Actuated Satellite Swarm without Additional Actuator", "comment": "This manuscript is a revised author's preprint based on a paper originally presented at the Workshop on JAXA, \"Astrodynamics and Flight Mechanics,'' Sagamihara, Japan, C-6, 2020, and has not been peer-reviewed", "summary": "Electromagnetic Formation Flight is a technology that uses electromagnetic forces and torques to control multiple satellites without conventional fuel-based propulsion. In this paper, the controllability of the system is discussed based on the conservation of the entire system's angular momentum, which constitutes a nonholonomic constraint. This paper designs a new controller for multiple satellites without an additional attitude actuator.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u89d2\u52a8\u91cf\u5b88\u6052\u7684\u7535\u78c1\u63a7\u5236\u5668\uff0c\u5728\u65e0\u9700\u59ff\u6001\u6267\u884c\u5668\u7684\u6761\u4ef6\u4e0b\u5b9e\u73b0\u591a\u536b\u661f\u7684\u5f62\u6210\u98de\u884c\u63a7\u5236\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u71c3\u6599\u63a8\u8fdb\u5728\u5fae\u536b\u661f\u7fa4\u63a7\u4e2d\u53d7\u9650\uff0c\u9700\u5f00\u53d1\u65e0\u71c3\u6599\u7684\u53ef\u63a7\u6280\u672f\uff1b\u7535\u78c1\u4f5c\u7528\u5177\u5907\u96f6\u6392\u653e\u548c\u9ad8\u7cbe\u5ea6\u7684\u4f18\u52bf\u3002", "method": "\u57fa\u4e8e\u5168\u7cfb\u7edf\u89d2\u52a8\u91cf\u5b88\u6052\u7684\u975e\u5b8c\u6574\u7ea6\u675f\uff0c\u8bbe\u8ba1\u4e86\u65b0\u578b\u7535\u78c1\u529b/\u529b\u77e9\u63a7\u5236\u5668\uff0c\u5e76\u5728\u63a7\u5236\u5f8b\u4e2d\u4e0d\u4f9d\u8d56\u4f20\u7edf\u59ff\u6001\u6267\u884c\u5668\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u4e0e\u4eff\u771f\u9a8c\u8bc1\uff0c\u6240\u8ff0\u63a7\u5236\u5668\u80fd\u5728\u4e0d\u4f7f\u7528\u989d\u5916\u59ff\u6001\u6267\u884c\u5668\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u591a\u536b\u661f\u7684\u63a7\u5236\u548c\u59ff\u6001\u540c\u6b65\uff0c\u63d0\u5347\u5f62\u6210\u98de\u884c\u7684\u53ef\u63a7\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u5728\u65e0\u989d\u5916\u59ff\u6001\u6267\u884c\u5668\u6761\u4ef6\u4e0b\uff0c\u5229\u7528\u5168\u7cfb\u7edf\u89d2\u52a8\u91cf\u5b88\u6052\u7ea6\u675f\u8bbe\u8ba1\u7684\u7535\u78c1\u63a7\u5236\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u591a\u536b\u661f\u7684\u53ef\u63a7\u5f62\u6210\u98de\u884c\u3002"}}
{"id": "2601.03152", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.03152", "abs": "https://arxiv.org/abs/2601.03152", "authors": ["Amy Hodgkin", "Nick Pepper", "Marc Thomas"], "title": "Conditioning Aircraft Trajectory Prediction on Meteorological Data with a Physics-Informed Machine Learning Approach", "comment": "Accepted to AIAA SciTech 2026 Forum", "summary": "Accurate aircraft trajectory prediction (TP) in air traffic management systems is confounded by a number of epistemic uncertainties, dominated by uncertain meteorological conditions and operator specific procedures. Handling this uncertainty necessitates the use of probabilistic, machine learned models for generating trajectories. However, the trustworthiness of such models is limited if generated trajectories are not physically plausible. For this reason we propose a physics-informed approach in which aircraft thrust and airspeed are learned from data and are used to condition the existing Base of Aircraft Data (BADA) model, which is physics-based and enforces energy-based constraints on generated trajectories. A set of informative features are identified and used to condition a probabilistic model of aircraft thrust and airspeed, with the proposed scheme demonstrating a 20% improvement in skilfulness across a set of six metrics, compared against a baseline probabilistic model that ignores contextual information such as meteorological conditions.", "AI": {"tldr": "\u8fd0\u7528\u673a\u5668\u5b66\u4e60\u4f30\u8ba1\u63a8\u529b\u4e0e\u7a7a\u901f\uff0c\u7ed3\u5408BADA\u80fd\u91cf\u7ea6\u675f\uff0c\u63d0\u534720%\u8f68\u8ff9\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u822a\u7a7a\u8f68\u8ff9\u53d7\u5230\u591a\u6765\u6e90\u4e0d\u786e\u5b9a\u6027\u7684\u5e72\u6270\uff0c\u5c24\u5176\u662f\u6c14\u8c61\u6761\u4ef6\u548c\u64cd\u4f5c\u8005\u7279\u5b9a\u64cd\u4f5c\uff0c\u9700\u8981\u5229\u7528\u6982\u7387\u5316\u5b66\u4e60\u6a21\u578b\u751f\u6210\u8f68\u8ff9\uff0c\u4f46\u6b64\u7c7b\u6a21\u578b\u82e5\u4ea7\u751f\u4e0d\u7b26\u5408\u7269\u7406\u7ea6\u675f\u7684\u8f68\u8ff9\uff0c\u5176\u53ef\u4fe1\u5ea6\u53d7\u9650\u3002", "method": "\u63d0\u51fa\u7269\u7406\u4fe1\u606f\u5316\u65b9\u6cd5\uff1a\u901a\u8fc7\u6570\u636e\u5b66\u4e60\u673a\u52a8\u63a8\u529b\u4e0e\u7a7a\u901f\uff0c\u6761\u4ef6\u5316\u57fa\u4e8e\u7269\u7406\u7684BADA\u6a21\u578b\uff0c\u540e\u8005\u5728\u751f\u6210\u8f68\u8ff9\u65f6\u65bd\u52a0\u80fd\u91cf\u7ea6\u675f\u3002\u6311\u9009\u4e00\u7ec4\u4fe1\u606f\u7279\u5f81\uff0c\u7528\u4e8e\u6784\u5efa\u63a8\u529b\u548c\u7a7a\u901f\u7684\u6982\u7387\u6a21\u578b\u3002", "result": "\u5728\u516d\u9879\u8bc4\u4f30\u6307\u6807\u4e0a\uff0c\u76f8\u8f83\u4e8e\u5ffd\u7565\u6c14\u8c61\u7b49\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u57fa\u51c6\u6982\u7387\u6a21\u578b\uff0c\u6240\u63d0\u65b9\u6cd5\u63d0\u5347\u4e8620%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u5c06\u6570\u636e\u9a71\u52a8\u7684\u63a8\u529b/\u7a7a\u901f\u9884\u6d4b\u4e0e\u7269\u7406\u7ea6\u675f\u76f8\u7ed3\u5408\uff0c\u53ef\u663e\u8457\u63d0\u9ad8\u822a\u7a7a\u8f68\u8ff9\u9884\u6d4b\u7684\u53ef\u4fe1\u5ea6\u4e0e\u7cbe\u5ea6\u3002"}}
{"id": "2601.02648", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.02648", "abs": "https://arxiv.org/abs/2601.02648", "authors": ["Mehdi Fatemi"], "title": "Prioritized Replay for RL Post-training", "comment": null, "summary": "We introduce a problem-level prioritization framework for RL post-training of large language models. Building on insights from prioritized replay in deep RL, as well as prior observations that rollouts with intermediate success rates tend to produce stronger learning signals under methods such as GRPO, our approach selects problems according to a simple, model-driven priority score derived from empirical success statistics. In contrast to conventional curriculum strategies that emphasize easier tasks early in training, the resulting schedule naturally focuses training on problems that are neither consistently solved nor consistently failed, while deprioritizing those that contribute little gradient information. The method yields a continuously adapting and automatic prioritization process that requires no predefined difficulty tiers, auxiliary predictors, or external labels. We further introduce lightweight mechanisms for practical deployment, including heap-based prioritized sampling and periodic retesting of solved and unsolved problems to mitigate starvation and forgetting. Overall, the approach offers a principled and scalable alternative to manually designed curricula while aligning data selection directly with the dynamics of GRPO-based post-training.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7ecf\u9a8c\u6210\u529f\u7387\u7684RL\u540e\u8bad\u7ec3\u4f18\u5148\u7ea7\u6846\u67b6\uff0c\u65e0\u9700\u9884\u8bbe\u96be\u5ea6\u5c42\u7ea7\uff0c\u80fd\u81ea\u52a8\u805a\u7126\u4e8e\u4e2d\u7b49\u96be\u5ea6\u4efb\u52a1\uff0c\u901a\u8fc7\u5806\u5f0f\u91c7\u6837\u548c\u5468\u671f\u91cd\u6d4b\u5b9e\u73b0\u9ad8\u6548\u90e8\u7f72\uff0c\u4e14\u5728GRPO\u8bad\u7ec3\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u8bfe\u7a0b\u5b66\u4e60\u503e\u5411\u4e8e\u4ee5\u6613\u4efb\u52a1\u5f00\u59cb\uff0c\u5bfc\u81f4\u5bf9\u4e2d\u7b49\u96be\u5ea6\u95ee\u9898\u5173\u6ce8\u4e0d\u8db3\uff1b\u540c\u65f6\u7ecf\u9a8c\u89c2\u5bdf\u8868\u660e\u5177\u5907\u4e2d\u7b49\u6210\u529f\u7387\u7684rollouts\u5728GRPO\u7b49\u65b9\u6cd5\u4e0b\u80fd\u63d0\u4f9b\u66f4\u5f3a\u7684\u5b66\u4e60\u4fe1\u53f7\u3002", "method": "\u57fa\u4e8e\u7ecf\u9a8c\u6210\u529f\u7387\u8ba1\u7b97\u6a21\u578b\u9a71\u52a8\u7684\u4f18\u5148\u7ea7\u5206\u6570\uff0c\u91c7\u7528\u5806\u5f0f\u4f18\u5148\u91c7\u6837\u4e0e\u5468\u671f\u6027\u91cd\u6d4b\u673a\u5236\u5b9e\u73b0\u81ea\u9002\u5e94\u8c03\u5ea6\uff1b\u4e0d\u9700\u8981\u9884\u8bbe\u96be\u5ea6\u9636\u68af\u3001\u8f85\u52a9\u9884\u6d4b\u5668\u6216\u5916\u90e8\u6807\u7b7e\u3002", "result": "\u5b9e\u9a8c\u5c55\u793a\u4e86\u8be5\u4f18\u5148\u7ea7\u6846\u67b6\u5728GRPO\u540e\u8bad\u7ec3\u4e2d\u7684\u53ef\u884c\u6027\u4e0e\u53ef\u6269\u5c55\u6027\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u65e0\u6548\u68af\u5ea6\u4fe1\u606f\uff0c\u63d0\u9ad8\u4e86\u7f13\u89e3\u9965\u997f\u4e0e\u9057\u5fd8\u3001\u63d0\u5347\u6574\u4f53\u8bad\u7ec3\u6548\u679c\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aRL\u540e\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u95ee\u9898\u5c42\u6b21\u7684\u4f18\u5148\u7ea7\u6392\u5e8f\uff0c\u80fd\u591f\u81ea\u52a8\u805a\u7126\u4e8e\u5b66\u4e60\u4fe1\u53f7\u5f3a\u7684\u4e2d\u7b49\u96be\u5ea6\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u5e76\u907f\u514d\u5bf9\u65e0\u6548\u95ee\u9898\u7684\u6d6a\u8d39\u3002"}}
{"id": "2601.02668", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.02668", "abs": "https://arxiv.org/abs/2601.02668", "authors": ["Xiaoyan Sun", "Qingyu Meng", "Yalu Wen"], "title": "MAFS: Multi-head Attention Feature Selection for High-Dimensional Data via Deep Fusion of Filter Methods", "comment": null, "summary": "Feature selection is essential for high-dimensional biomedical data, enabling stronger predictive performance, reduced computational cost, and improved interpretability in precision medicine applications. Existing approaches face notable challenges. Filter methods are highly scalable but cannot capture complex relationships or eliminate redundancy. Deep learning-based approaches can model nonlinear patterns but often lack stability, interpretability, and efficiency at scale. Single-head attention improves interpretability but is limited in capturing multi-level dependencies and remains sensitive to initialization, reducing reproducibility. Most existing methods rarely combine statistical interpretability with the representational power of deep learning, particularly in ultra-high-dimensional settings. Here, we introduce MAFS (Multi-head Attention-based Feature Selection), a hybrid framework that integrates statistical priors with deep learning capabilities. MAFS begins with filter-based priors for stable initialization and guide learning. It then uses multi-head attention to examine features from multiple perspectives in parallel, capturing complex nonlinear relationships and interactions. Finally, a reordering module consolidates outputs across attention heads, resolving conflicts and minimizing information loss to generate robust and consistent feature rankings. This design combines statistical guidance with deep modeling capacity, yielding interpretable importance scores while maximizing retention of informative signals. Across simulated and real-world datasets, including cancer gene expression and Alzheimer's disease data, MAFS consistently achieves superior coverage and stability compared with existing filter-based and deep learning-based alternatives, offering a scalable, interpretable, and robust solution for feature selection in high-dimensional biomedical data.", "AI": {"tldr": "MAFS\u96c6\u6210\u7edf\u8ba1\u5148\u9a8c\u3001\u591a\u5934\u6ce8\u610f\u529b\u4e0e\u91cd\u6392\u6a21\u5757\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u3001\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u9ad8\u7ef4\u7279\u5f81\u9009\u62e9\u3002", "motivation": "\u8fc7\u6ee4\u65b9\u6cd5\u53ef\u6269\u5c55\u4f46\u7f3a\u4e4f\u590d\u6742\u5173\u7cfb\u5efa\u6a21\uff0c\u6df1\u5ea6\u5b66\u4e60\u6355\u6349\u975e\u7ebf\u6027\u4f46\u7f3a\u4e4f\u7a33\u5b9a\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u5f88\u5c11\u5728\u8d85\u9ad8\u7ef4\u73af\u5883\u4e2d\u517c\u987e\u7edf\u8ba1\u89e3\u91ca\u4e0e\u6df1\u5ea6\u8868\u793a\u3002", "method": "\u5c06\u8fc7\u6ee4\u5f0f\u5148\u9a8c\u7528\u4e8e\u7a33\u5b9a\u521d\u59cb\u5316\uff0c\u6784\u5efa\u591a\u5934\u6ce8\u610f\u529b\u6355\u83b7\u591a\u5c42\u6b21\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u968f\u540e\u901a\u8fc7\u91cd\u6392\u6a21\u5757\u6574\u5408\u5404\u6ce8\u610f\u5934\u8f93\u51fa\uff0c\u6d88\u9664\u51b2\u7a81\u5e76\u4fdd\u7559\u5173\u952e\u4fe1\u53f7\u3002", "result": "\u5728\u6a21\u62df\u4ee5\u53ca\u764c\u75c7\u57fa\u56e0\u8868\u8fbe\u548c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u6570\u636e\u96c6\u4e0a\uff0cMAFS\u5728\u8986\u76d6\u7387\u4e0e\u7a33\u5b9a\u6027\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "MAFS\u5728\u9ad8\u7ef4\u751f\u7269\u533b\u5b66\u6570\u636e\u4e0a\u663e\u8457\u63d0\u5347\u7279\u5f81\u9009\u62e9\u7684\u8986\u76d6\u7387\u3001\u7a33\u5b9a\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u8fc7\u6ee4\u5f0f\u53ca\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2601.02677", "categories": ["cs.LG", "q-fin.RM", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2601.02677", "abs": "https://arxiv.org/abs/2601.02677", "authors": ["Gongao Zhang", "Haijiang Zeng", "Lu Jiang"], "title": "Uni-FinLLM: A Unified Multimodal Large Language Model with Modular Task Heads for Micro-Level Stock Prediction and Macro-Level Systemic Risk Assessment", "comment": null, "summary": "Financial institutions and regulators require systems that integrate heterogeneous data to assess risks from stock fluctuations to systemic vulnerabilities. Existing approaches often treat these tasks in isolation, failing to capture cross-scale dependencies. We propose Uni-FinLLM, a unified multimodal large language model that uses a shared Transformer backbone and modular task heads to jointly process financial text, numerical time series, fundamentals, and visual data. Through cross-modal attention and multi-task optimization, it learns a coherent representation for micro-, meso-, and macro-level predictions. Evaluated on stock forecasting, credit-risk assessment, and systemic-risk detection, Uni-FinLLM significantly outperforms baselines. It raises stock directional accuracy to 67.4% (from 61.7%), credit-risk accuracy to 84.1% (from 79.6%), and macro early-warning accuracy to 82.3%. Results validate that a unified multimodal LLM can jointly model asset behavior and systemic vulnerabilities, offering a scalable decision-support engine for finance.", "AI": {"tldr": "Uni\u2011FinLLM \u901a\u8fc7\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u3001\u5171\u4eab Transformer \u4e3b\u5e72\u4e0e\u591a\u4efb\u52a1\u5b66\u4e60\uff0c\u5728\u80a1\u7968\u3001\u4fe1\u7528\u98ce\u9669\u548c\u5b8f\u89c2\u9884\u8b66\u4e09\u5927\u91d1\u878d\u9884\u6d4b\u4efb\u52a1\u4e0a\u5747\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u91d1\u878d\u673a\u6784\u4e0e\u76d1\u7ba1\u673a\u6784\u9700\u8981\u6574\u5408\u5f02\u8d28\u6570\u636e\u7684\u7cfb\u7edf\uff0c\u4ee5\u8bc4\u4f30\u4ece\u4e2a\u80a1\u6ce2\u52a8\u5230\u7cfb\u7edf\u6027\u98ce\u9669\u7684\u591a\u5c42\u7ea7\u98ce\u9669\u3002\u76ee\u524d\u7684\u505a\u6cd5\u5f80\u5f80\u5c06\u8fd9\u4e9b\u4efb\u52a1\u5b64\u7acb\u5904\u7406\uff0c\u672a\u80fd\u6355\u6349\u8de8\u5c3a\u5ea6\u4f9d\u8d56\uff0c\u5bfc\u81f4\u98ce\u9669\u8bc4\u4f30\u4e0d\u5b8c\u6574\u3002", "method": "\u63d0\u51fa Uni\u2011FinLLM\uff1a\u91c7\u7528\u5171\u4eab Transformer \u4e3b\u5e72\u4e0e\u6a21\u7ec4\u5316\u4efb\u52a1\u5934\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u548c\u591a\u4efb\u52a1\u4f18\u5316\uff0c\u8054\u5408\u5904\u7406\u91d1\u878d\u6587\u672c\u3001\u6570\u503c\u65f6\u5e8f\u3001\u8d22\u62a5\u6570\u636e\u548c\u89c6\u89c9\u4fe1\u606f\uff0c\u5b66\u4e60\u7edf\u4e00\u8868\u5f81\u5b9e\u73b0\u5fae\u89c2\u3001\u4e2d\u89c2\u3001\u5b8f\u89c2\u7ea7\u9884\u6d4b\u3002", "result": "\u5728\u4e09\u9879\u57fa\u51c6\u6311\u6218\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff1a\u80a1\u4ef7\u65b9\u5411\u51c6\u786e\u7387\u5347\u81f3 67.4%\uff08\u4ece 61.7%\uff09\uff0c\u4fe1\u7528\u98ce\u9669\u51c6\u786e\u7387 84.1%\uff08\u4ece 79.6%\uff09\uff0c\u5b8f\u89c2\u65e9\u671f\u9884\u8b66\u51c6\u786e\u7387 82.3%\u3002", "conclusion": "\u7edf\u4e00\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u540c\u65f6\u5efa\u6a21\u8d44\u4ea7\u884c\u4e3a\u4e0e\u7cfb\u7edf\u6027\u8106\u5f31\u6027\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u91d1\u878d\u51b3\u7b56\u652f\u6301\u5f15\u64ce\u3002"}}
{"id": "2601.02728", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02728", "abs": "https://arxiv.org/abs/2601.02728", "authors": ["Beicheng Lou", "Zifei Xu"], "title": "CRoPE: Efficient Parametrization of Rotary Positional Embedding", "comment": null, "summary": "Rotary positional embedding has become the state-of-the-art approach to encode position information in transformer-based models. While it is often succinctly expressed in complex linear algebra, we note that the actual implementation of $Q/K/V$-projections is not equivalent to a complex linear transformation. We argue that complex linear transformation is a more natural parametrization and saves near 50\\% parameters within the attention block. We show empirically that removing such redundancy has negligible impact on the model performance both in sample and out of sample. Our modification achieves more efficient parameter usage, as well as a cleaner interpretation of the representation space.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02735", "categories": ["cs.LG", "cs.DS", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.02735", "abs": "https://arxiv.org/abs/2601.02735", "authors": ["Adrien Aumon", "Guy Wolf", "Kevin R. Moon", "Jake S. Rhodes"], "title": "Scalable Tree Ensemble Proximities in Python", "comment": null, "summary": "Tree ensemble methods such as Random Forests naturally induce supervised similarity measures through their decision tree structure, but existing implementations of proximities derived from tree ensembles typically suffer from quadratic time or memory complexity, limiting their scalability. In this work, we introduce a general framework for efficient proximity computation by defining a family of Separable Weighted Leaf-Collision Proximities. We show that any proximity measure in this family admits an exact sparse matrix factorization, restricting computation to leaf-level collisions and avoiding explicit pairwise comparisons. This formulation enables low-memory, scalable proximity computation using sparse linear algebra in Python. Empirical benchmarks demonstrate substantial runtime and memory improvements over traditional approaches, allowing tree ensemble proximities to scale efficiently to datasets with hundreds of thousands of samples on standard CPU hardware.", "AI": {"tldr": "\u5229\u7528\u53f6\u8282\u70b9\u78b0\u649e\u7684\u53ef\u5206\u79bb\u52a0\u6743\u8fd1\u4f3c\uff0c\u7ed3\u5408\u7a00\u758f\u77e9\u9635\u5206\u89e3\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6811\u96c6\u6210\u751f\u6210\u7684\u76f8\u4f3c\u5ea6\u7684\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u8ba1\u7b97\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6811\u96c6\u6210\u7684\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u65b9\u6cd5\u5728\u5927\u6837\u672c\u89c4\u6a21\u4e0b\u590d\u6742\u5ea6\u5448\u5e73\u65b9\u7ea7\uff0c\u5bfc\u81f4\u65e0\u6cd5\u6269\u5c55\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49Separable Weighted Leaf-Collision Proximities\uff0c\u5e76\u8bc1\u660e\u5176\u53ef\u5f97\u5230\u7cbe\u786e\u7684\u7a00\u758f\u77e9\u9635\u5206\u89e3\uff0c\u4ece\u800c\u4ec5\u5728\u53f6\u8282\u70b9\u78b0\u649e\u4e0a\u8fdb\u884c\u8fd0\u7b97\u5e76\u4f7f\u7528\u7a00\u758f\u7ebf\u6027\u4ee3\u6570\u5b9e\u73b0\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002", "result": "\u5728Python\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u76f8\u8f83\u4f20\u7edf\u6280\u672f\u5728\u8fd0\u884c\u65f6\u95f4\u548c\u5185\u5b58\u5360\u7528\u4e0a\u90fd\u6709\u663e\u8457\u6539\u8fdb\uff0c\u53ef\u5728\u666e\u901aCPU\u73af\u5883\u4e0b\u5904\u7406\u6570\u5341\u4e07\u884c\u7684\u6570\u636e\u3002", "conclusion": "\u8be5\u6846\u67b6\u663e\u8457\u964d\u4f4e\u4e86\u7528\u6811\u96c6\u6210\u65b9\u6cd5\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u65f6\u7684\u65f6\u95f4\u548c\u5185\u5b58\u6d88\u8017\u3002"}}
{"id": "2601.02754", "categories": ["cs.LG", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02754", "abs": "https://arxiv.org/abs/2601.02754", "authors": ["Mingming Zhang", "Na Li", "Zhuang Feiqing", "Hongyang Zheng", "Jiangbing Zhou", "Wang Wuyin", "Sheng-jie Sun", "XiaoWei Chen", "Junxiong Zhu", "Lixin Zou", "Chenliang Li"], "title": "Q-Regularized Generative Auto-Bidding: From Suboptimal Trajectories to Optimal Policies", "comment": "11pages, 5figures, In Proceedings of the 32nd ACM SIGKDD Conference on Knowledge Discovery and Data Mining", "summary": "With the rapid development of e-commerce, auto-bidding has become a key asset in optimizing advertising performance under diverse advertiser environments. The current approaches focus on reinforcement learning (RL) and generative models. These efforts imitate offline historical behaviors by utilizing a complex structure with expensive hyperparameter tuning. The suboptimal trajectories further exacerbate the difficulty of policy learning.\n  To address these challenges, we proposes QGA, a novel Q-value regularized Generative Auto-bidding method. In QGA, we propose to plug a Q-value regularization with double Q-learning strategy into the Decision Transformer backbone. This design enables joint optimization of policy imitation and action-value maximization, allowing the learned bidding policy to both leverage experience from the dataset and alleviate the adverse impact of the suboptimal trajectories. Furthermore, to safely explore the policy space beyond the data distribution, we propose a Q-value guided dual-exploration mechanism, in which the DT model is conditioned on multiple return-to-go targets and locally perturbed actions. This entire exploration process is dynamically guided by the aforementioned Q-value module, which provides principled evaluation for each candidate action. Experiments on public benchmarks and simulation environments demonstrate that QGA consistently achieves superior or highly competitive results compared to existing alternatives. Notably, in large-scale real-world A/B testing, QGA achieves a 3.27% increase in Ad GMV and a 2.49% improvement in Ad ROI.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02856", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02856", "abs": "https://arxiv.org/abs/2601.02856", "authors": ["Btissame El Mahtout", "Florian Ziel"], "title": "Electricity Price Forecasting: Bridging Linear Models, Neural Networks and Online Learning", "comment": null, "summary": "Precise day-ahead forecasts for electricity prices are crucial to ensure efficient portfolio management, support strategic decision-making for power plant operations, enable efficient battery storage optimization, and facilitate demand response planning. However, developing an accurate prediction model is highly challenging in an uncertain and volatile market environment. For instance, although linear models generally exhibit competitive performance in predicting electricity prices with minimal computational requirements, they fail to capture relevant nonlinear relationships. Nonlinear models, on the other hand, can improve forecasting accuracy with a surge in computational costs. We propose a novel multivariate neural network approach that combines linear and nonlinear feed-forward neural structures. Unlike previous hybrid models, our approach integrates online learning and forecast combination for efficient training and accuracy improvement. It also incorporates all relevant characteristics, particularly the fundamental relationships arising from wind and solar generation, electricity demand patterns, related energy fuel and carbon markets, in addition to autoregressive dynamics and calendar effects. Compared to the current state-of-the-art benchmark models, the proposed forecasting method significantly reduces computational cost while delivering superior forecasting accuracy (12-13% RMSE and 15-18% MAE reductions). Our results are derived from a six-year forecasting study conducted on major European electricity markets.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02884", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02884", "abs": "https://arxiv.org/abs/2601.02884", "authors": ["Hana Yahia", "Bruno Figliuzzi", "Florent Di Meglio", "Laurent Gerbaud", "Stephane Menand", "Mohamed Mahjoub"], "title": "Domain Generalization for Time Series: Enhancing Drilling Regression Models for Stick-Slip Index Prediction", "comment": null, "summary": "This paper provides a comprehensive comparison of domain generalization techniques applied to time series data within a drilling context, focusing on the prediction of a continuous Stick-Slip Index (SSI), a critical metric for assessing torsional downhole vibrations at the drill bit. The study aims to develop a robust regression model that can generalize across domains by training on 60 second labeled sequences of 1 Hz surface drilling data to predict the SSI. The model is tested in wells that are different from those used during training. To fine-tune the model architecture, a grid search approach is employed to optimize key hyperparameters. A comparative analysis of the Adversarial Domain Generalization (ADG), Invariant Risk Minimization (IRM) and baseline models is presented, along with an evaluation of the effectiveness of transfer learning (TL) in improving model performance. The ADG and IRM models achieve performance improvements of 10% and 8%, respectively, over the baseline model. Most importantly, severe events are detected 60% of the time, against 20% for the baseline model. Overall, the results indicate that both ADG and IRM models surpass the baseline, with the ADG model exhibiting a slight advantage over the IRM model. Additionally, applying TL to a pre-trained model further improves performance. Our findings demonstrate the potential of domain generalization approaches in drilling applications, with ADG emerging as the most effective approach.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02888", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02888", "abs": "https://arxiv.org/abs/2601.02888", "authors": ["Xuanyu Wang", "Haisen Su", "Jingtao Zhang", "Xiangxiang Wang", "Yongbin Yu", "Manping Fan", "Bo Gong", "Siqi Chen", "Mingsheng Cao", "Liyong Ren"], "title": "RPIQ: Residual-Projected Multi-Collaboration Closed-Loop and Single Instance Quantization for Visually Impaired Assistance", "comment": null, "summary": "Visually impaired users face significant challenges in daily information access and real-time environmental perception, and there is an urgent need for intelligent assistive systems with accurate recognition capabilities. Although large-scale models provide effective solutions for perception and reasoning, their practical deployment on assistive devices is severely constrained by excessive memory consumption and high inference costs. Moreover, existing quantization strategies often ignore inter-block error accumulation, leading to degraded model stability. To address these challenges, this study proposes a novel quantization framework -- Residual-Projected Multi-Collaboration Closed-Loop and Single Instance Quantization(RPIQ), whose quantization process adopts a multi-collaborative closed-loop compensation scheme based on Single Instance Calibration and Gauss-Seidel Iterative Quantization. Experiments on various types of large-scale models, including language models such as OPT, Qwen, and LLaMA, as well as vision-language models such as CogVLM2, demonstrate that RPIQ can compress models to 4-bit representation while significantly reducing peak memory consumption (approximately 60%-75% reduction compared to original full-precision models). The method maintains performance highly close to full-precision models across multiple language and visual tasks, and exhibits excellent recognition and reasoning capabilities in key applications such as text understanding and visual question answering in complex scenarios. While verifying the effectiveness of RPIQ for deployment in real assistive systems, this study also advances the computational efficiency and reliability of large models, enabling them to provide visually impaired users with the required information accurately and rapidly.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02896", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02896", "abs": "https://arxiv.org/abs/2601.02896", "authors": ["Harshvardhan Saini", "Yiming Tang", "Dianbo Liu"], "title": "Bridging Mechanistic Interpretability and Prompt Engineering with Gradient Ascent for Interpretable Persona Control", "comment": null, "summary": "Controlling emergent behavioral personas (e.g., sycophancy, hallucination) in Large Language Models (LLMs) is critical for AI safety, yet remains a persistent challenge. Existing solutions face a dilemma: manual prompt engineering is intuitive but unscalable and imprecise, while automatic optimization methods are effective but operate as \"black boxes\" with no interpretable connection to model internals. We propose a novel framework that adapts gradient ascent to LLMs, enabling targeted prompt discovery. In specific, we propose two methods, RESGA and SAEGA, that both optimize randomly initialized prompts to achieve better aligned representation with an identified persona direction. We introduce fluent gradient ascent to control the fluency of discovered persona steering prompts. We demonstrate RESGA and SAEGA's effectiveness across Llama 3.1, Qwen 2.5, and Gemma 3 for steering three different personas,sycophancy, hallucination, and myopic reward. Crucially, on sycophancy, our automatically discovered prompts achieve significant improvement (49.90% compared with 79.24%). By grounding prompt discovery in mechanistically meaningful features, our method offers a new paradigm for controllable and interpretable behavior modification.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.02998", "categories": ["cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.02998", "abs": "https://arxiv.org/abs/2601.02998", "authors": ["Yuqi Yang", "Ying Jin"], "title": "Multi-Distribution Robust Conformal Prediction", "comment": null, "summary": "In many fairness and distribution robustness problems, one has access to labeled data from multiple source distributions yet the test data may come from an arbitrary member or a mixture of them. We study the problem of constructing a conformal prediction set that is uniformly valid across multiple, heterogeneous distributions, in the sense that no matter which distribution the test point is from, the coverage of the prediction set is guaranteed to exceed a pre-specified level. We first propose a max-p aggregation scheme that delivers finite-sample, multi-distribution coverage given any conformity scores associated with each distribution. Upon studying several efficiency optimization programs subject to uniform coverage, we prove the optimality and tightness of our aggregation scheme, and propose a general algorithm to learn conformity scores that lead to efficient prediction sets after the aggregation under standard conditions. We discuss how our framework relates to group-wise distributionally robust optimization, sub-population shift, fairness, and multi-source learning. In synthetic and real-data experiments, our method delivers valid worst-case coverage across multiple distributions while greatly reducing the set size compared with naively applying max-p aggregation to single-source conformity scores, and can be comparable in size to single-source prediction sets with popular, standard conformity scores.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e Max\u2011p \u805a\u5408\u7684 conformal \u9884\u6d4b\u96c6\u5408\uff0c\u53ef\u5728\u591a\u6e90\u3001\u975e\u5747\u8d28\u5206\u5e03\u4e0b\u7edf\u4e00\u4fdd\u8bc1\u8986\u76d6\u7387\uff0c\u5e76\u5728\u6548\u7387\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5728\u516c\u5e73\u6027\u3001\u5206\u5e03\u9c81\u68d2\u6027\u4ee5\u53ca\u591a\u6e90\u5b66\u4e60\u573a\u666f\u4e0b\uff0c\u9700\u8981\u4e00\u4e2a\u5728\u4efb\u610f\u6765\u6e90\u5206\u5e03\u4e0b\u90fd\u80fd\u4fdd\u8bc1\u8986\u76d6\u7387\u7684\u9884\u6d4b\u96c6\u5408\u3002", "method": "\u5148\u4f7f\u7528 Max\u2011p \u805a\u5408\u63d0\u4f9b\u6709\u9650\u6837\u672c\u591a\u5206\u5e03\u8986\u76d6\uff0c\u7136\u540e\u5728\u6ee1\u8db3\u7edf\u4e00\u8986\u76d6\u7684\u6761\u4ef6\u4e0b\u8fdb\u884c\u6548\u7387\u4f18\u5316\uff0c\u5e76\u5b66\u4e60\u53ef\u6cdb\u5316\u7684\u5408\u89c4\u6027\u5f97\u5206\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6700\u574f\u60c5\u51b5\u4e0b\u8986\u76d6\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c0f\u4e86\u96c6\u5408\u5c3a\u5bf8\uff0c\u5e76\u53ef\u4e0e\u6807\u51c6\u5355\u6e90\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u3002", "conclusion": "\u6784\u9020\u7684 conformal \u9884\u6d4b\u96c6\u5408\u5728\u591a\u6e90\u3001\u5f02\u8d28\u5206\u5e03\u4e0b\u4fdd\u8bc1\u7edf\u4e00\u7684\u8986\u76d6\u7387\uff0c\u4e14\u5728\u6761\u4ef6\u4e0b\u53ef\u8fbe\u5230\u6700\u4f18\u6548\u7387\u3002"}}
{"id": "2601.03015", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03015", "abs": "https://arxiv.org/abs/2601.03015", "authors": ["Ana\u00efs Berkes", "Vincent Taboga", "Donna Vakalis", "David Rolnick", "Yoshua Bengio"], "title": "In-Context Reinforcement Learning through Bayesian Fusion of Context and Value Prior", "comment": null, "summary": "In-context reinforcement learning (ICRL) promises fast adaptation to unseen environments without parameter updates, but current methods either cannot improve beyond the training distribution or require near-optimal data, limiting practical adoption. We introduce SPICE, a Bayesian ICRL method that learns a prior over Q-values via deep ensemble and updates this prior at test-time using in-context information through Bayesian updates. To recover from poor priors resulting from training on sub-optimal data, our online inference follows an Upper-Confidence Bound rule that favours exploration and adaptation. We prove that SPICE achieves regret-optimal behaviour in both stochastic bandits and finite-horizon MDPs, even when pretrained only on suboptimal trajectories. We validate these findings empirically across bandit and control benchmarks. SPICE achieves near-optimal decisions on unseen tasks, substantially reduces regret compared to prior ICRL and meta-RL approaches while rapidly adapting to unseen tasks and remaining robust under distribution shift.", "AI": {"tldr": "SPICE\u4f7f\u7528\u8d1d\u53f6\u65af\u6df1\u5ea6\u96c6\u6210\u5148\u9a8c+UCB\u66f4\u65b0\uff0c\u7406\u8bba\u4e0e\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u7f3a\u4e4f\u6700\u4f73\u6570\u636e\u65f6\u4ecd\u80fd\u5728\u65b0\u73af\u5883\u4e2d\u5feb\u901f\u3001\u4f18\u5f02\u5730\u51b3\u7b56\u3002", "motivation": "\u63d0\u5347\u65e0\u53c2\u6570\u66f4\u65b0\u7684\u5feb\u901f\u9002\u5e94\u6027\uff0c\u89e3\u51b3\u73b0\u6709ICRL\u65b9\u6cd5\u5728\u8bad\u7ec3\u5206\u5e03\u5916\u96be\u505a\u6539\u8fdb\u6216\u9700\u8981\u8fd1\u6700\u4f18\u6570\u636e\u7684\u5c40\u9650", "method": "\u6784\u9020BP\u95eeQ-values\u7684\u5148\u9a8c\uff0c\u4f7f\u7528\u6df1\u5ea6\u96c6\u6210\u5b66\u4e60\u5f97\u5230\u5148\u9a8c\uff1b\u6d4b\u8bd5\u65f6\u901a\u8fc7\u8d1d\u53f6\u65af\u66f4\u65b0\u5229\u7528\u4e0a\u4e0b\u6587\uff1b\u7ed3\u5408UCB\u89c4\u5219\u589e\u5f3a\u63a2\u7d22\uff0c\u5f25\u8865\u6b21\u4f18\u6570\u636e\u5bfc\u81f4\u7684\u5148\u9a8c\u4e0d\u4f73", "result": "\u7406\u8bba\u8bc1\u660e\u5728\u968f\u673a bandit \u4e0e\u6709\u9650\u65f6 horizon MDP \u4e0b\u5b9e\u73b0 regret-optimal\uff1b\u5b9e\u9a8c\u663e\u793a\u5728 bandit \u4e0e\u63a7\u5236\u57fa\u51c6\u4e0a\u663e\u8457\u964d\u4f4e regret\uff0c\u63a5\u8fd1\u6700\u4f18\uff0c\u4e14\u5bf9\u5206\u5e03\u79fb\u4f4d\u4fdd\u6301\u9c81\u68d2", "conclusion": "SPICE \u63d0\u4f9b\u4e86\u7406\u8bba\u4e0e\u5b9e\u8df5\u53cc\u91cd\u652f\u6301\u7684 ICRL \u65b9\u6cd5\uff0c\u514b\u670d\u4e86\u8bad\u7ec3\u5206\u5e03\u4f9d\u8d56\u4e14\u5bf9\u5206\u5e03\u79fb\u4f4d\u9c81\u68d2\u6027\u5dee\u7684\u95ee\u9898\uff0c\u63a8\u52a8 ICRL \u5728\u5b9e\u9645\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2601.03032", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.03032", "abs": "https://arxiv.org/abs/2601.03032", "authors": ["Vidhi Rathore"], "title": "Causal Manifold Fairness: Enforcing Geometric Invariance in Representation Learning", "comment": null, "summary": "Fairness in machine learning is increasingly critical, yet standard approaches often treat data as static points in a high-dimensional space, ignoring the underlying generative structure. We posit that sensitive attributes (e.g., race, gender) do not merely shift data distributions but causally warp the geometry of the data manifold itself. To address this, we introduce Causal Manifold Fairness (CMF), a novel framework that bridges causal inference and geometric deep learning. CMF learns a latent representation where the local Riemannian geometry, defined by the metric tensor and curvature, remains invariant under counterfactual interventions on sensitive attributes. By enforcing constraints on the Jacobian and Hessian of the decoder, CMF ensures that the rules of the latent space (distances and shapes) are preserved across demographic groups. We validate CMF on synthetic Structural Causal Models (SCMs), demonstrating that it effectively disentangles sensitive geometric warping while preserving task utility, offering a rigorous quantification of the fairness-utility trade-off via geometric metrics.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03047", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03047", "abs": "https://arxiv.org/abs/2601.03047", "authors": ["Raphael Ronge", "Markus Maier", "Frederick Eberhardt"], "title": "When the Coffee Feature Activates on Coffins: An Analysis of Feature Extraction and Steering for Mechanistic Interpretability", "comment": "33 pages (65 with appendix), 1 figure", "summary": "Recent work by Anthropic on Mechanistic interpretability claims to understand and control Large Language Models by extracting human-interpretable features from their neural activation patterns using sparse autoencoders (SAEs). If successful, this approach offers one of the most promising routes for human oversight in AI safety. We conduct an initial stress-test of these claims by replicating their main results with open-source SAEs for Llama 3.1. While we successfully reproduce basic feature extraction and steering capabilities, our investigation suggests that major caution is warranted regarding the generalizability of these claims. We find that feature steering exhibits substantial fragility, with sensitivity to layer selection, steering magnitude, and context. We observe non-standard activation behavior and demonstrate the difficulty to distinguish thematically similar features from one another. While SAE-based interpretability produces compelling demonstrations in selected cases, current methods often fall short of the systematic reliability required for safety-critical applications. This suggests a necessary shift in focus from prioritizing interpretability of internal representations toward reliable prediction and control of model output. Our work contributes to a more nuanced understanding of what mechanistic interpretability has achieved and highlights fundamental challenges for AI safety that remain unresolved.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03067", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03067", "abs": "https://arxiv.org/abs/2601.03067", "authors": ["Joseph Kampeas", "Emir Haleva"], "title": "Joint Encoding of KV-Cache Blocks for Scalable LLM Serving", "comment": "12 pages, 16 figures, 2 tables", "summary": "Modern large language models (LLMs) drive interactive AI systems but are bottlenecked by the memory-heavy growth of key-value (KV) caches, which limits real-time throughput under concurrent loads. Existing KV-cache compression methods rely on rigid heuristics, disrupt tensor layouts, or require specialized compute, hindering scalability and deployment.\n  We propose joint encoding of KV-cache blocks, which fuses similar blocks across requests and input chunks into shared representations while preserving standard cache structure. This alleviates the KV-cache memory bottleneck, supporting high-concurrency serving without specialized hardware. Theoretically, we analyze the rate-distortion tradeoff of fused cache blocks under a Poisson process model. Empirically, our method achieves up to 4.38 $\\times$ KV-cache compression with negligible accuracy loss across diverse LLMs and benchmarks, outperforming recent structured and adaptive compression baselines. In real LLM serving, joint encoding improves the token throughput by $\\sim$40\\% on a single-machine vLLM benchmark, demonstrating substantial gains in inference throughput. Code is available at https://github.com/sef1/kv_fast_fusion  kv_joint_encoding.", "AI": {"tldr": "\u901a\u8fc7\u8de8\u8bf7\u6c42\u3001\u8de8\u6bb5\u7684 KV \u7f13\u5b58\u5757\u8054\u5408\u538b\u7f29\uff0c\u63d0\u5347 4.38 \u500d\u538b\u7f29\u7387\uff0c\u63a8\u7406\u541e\u5410\u63d0\u5347 40%\uff0c\u517c\u5bb9\u73b0\u6709\u786c\u4ef6\u3002", "motivation": "\u4f20\u7edf KV \u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u53d7\u9650\u4e8e\u786c\u7f16\u7801\u542f\u53d1\u5f0f\u3001\u5f20\u91cf\u5e03\u5c40\u7834\u574f\u6216\u9700\u8981\u4e13\u7528\u8ba1\u7b97\uff0c\u96be\u4ee5\u5728\u73b0\u6709\u786c\u4ef6\u4e0a\u5b9e\u73b0\u9ad8\u5e76\u53d1\u63a8\u65ad\u3002", "method": "\u8054\u5408\u7f16\u7801 KV \u7f13\u5b58\u5757\uff0c\u5c06\u8de8\u8bf7\u6c42\u3001\u8de8\u8f93\u5165\u6bb5\u76f8\u4f3c\u7684\u5757\u878d\u5408\u6210\u5171\u4eab\u8868\u793a\uff0c\u4fdd\u6301\u539f\u59cb\u7f13\u5b58\u7ed3\u6784\uff0c\u5206\u6790\u5176\u5728\u6cca\u677e\u8fc7\u7a0b\u6a21\u578b\u4e0b\u7684\u7387-\u5931\u771f\u6298\u8877\u3002", "result": "\u5728\u591a\u79cd LLM \u4e0e\u57fa\u51c6\u4e0a\u5b9e\u73b0\u9ad8\u8fbe 4.38 \u500d\u7684 KV \u7f13\u5b58\u538b\u7f29\uff0c\u8bef\u5dee\u53ef\u5ffd\u7565\uff1b\u5728\u5355\u673a vLLM \u6d4b\u8bd5\u4e2d\uff0c\u4ee4\u6807\u8bb0\u541e\u5410\u91cf\u63d0\u5347\u7ea6 40%\u3002", "conclusion": "\u8054\u5408\u7f16\u7801\u663e\u8457\u7f13\u89e3 KV \u7f13\u5b58\u5185\u5b58\u74f6\u9888\uff0c\u63d0\u5347\u9ad8\u5e76\u53d1\u63a8\u7406\u541e\u5410\u91cf\uff0c\u4e14\u4e0d\u9700\u8981\u4e13\u7528\u786c\u4ef6\uff0c\u4f18\u4e8e\u73b0\u6709\u7ed3\u6784\u5316\u4e0e\u81ea\u9002\u5e94\u538b\u7f29\u65b9\u6848\u3002"}}
{"id": "2601.03085", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03085", "abs": "https://arxiv.org/abs/2601.03085", "authors": ["Mahsa Raeiszadeh", "Amin Ebrahimzadeh", "Roch H. Glitho", "Johan Eker", "Raquel A. F. Mini"], "title": "Real-Time Adaptive Anomaly Detection in Industrial IoT Environments", "comment": null, "summary": "To ensure reliability and service availability, next-generation networks are expected to rely on automated anomaly detection systems powered by advanced machine learning methods with the capability of handling multi-dimensional data. Such multi-dimensional, heterogeneous data occurs mostly in today's industrial Internet of Things (IIoT), where real-time detection of anomalies is critical to prevent impending failures and resolve them in a timely manner. However, existing anomaly detection methods often fall short of effectively coping with the complexity and dynamism of multi-dimensional data streams in IIoT. In this paper, we propose an adaptive method for detecting anomalies in IIoT streaming data utilizing a multi-source prediction model and concept drift adaptation. The proposed anomaly detection algorithm merges a prediction model into a novel drift adaptation method resulting in accurate and efficient anomaly detection that exhibits improved scalability. Our trace-driven evaluations indicate that the proposed method outperforms the state-of-the-art anomaly detection methods by achieving up to an 89.71% accuracy (in terms of Area under the Curve (AUC)) while meeting the given efficiency and scalability requirements.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03087", "categories": ["cs.LG", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.03087", "abs": "https://arxiv.org/abs/2601.03087", "authors": ["David Hartmann", "Lena Pohlmann", "Lelia Hanslik", "Noah Gie\u00dfing", "Bettina Berendt", "Pieter Delobelle"], "title": "Audit Me If You Can: Query-Efficient Active Fairness Auditing of Black-Box LLMs", "comment": "Submitted to ACL ARR 2026", "summary": "Large Language Models (LLMs) exhibit systematic biases across demographic groups. Auditing is proposed as an accountability tool for black-box LLM applications, but suffers from resource-intensive query access. We conceptualise auditing as uncertainty estimation over a target fairness metric and introduce BAFA, the Bounded Active Fairness Auditor for query-efficient auditing of black-box LLMs. BAFA maintains a version space of surrogate models consistent with queried scores and computes uncertainty intervals for fairness metrics (e.g., $\u0394$ AUC) via constrained empirical risk minimisation. Active query selection narrows these intervals to reduce estimation error. We evaluate BAFA on two standard fairness dataset case studies: \\textsc{CivilComments} and \\textsc{Bias-in-Bios}, comparing against stratified sampling, power sampling, and ablations. BAFA achieves target error thresholds with up to 40$\\times$ fewer queries than stratified sampling (e.g., 144 vs 5,956 queries at $\\varepsilon=0.02$ for \\textsc{CivilComments}) for tight thresholds, demonstrates substantially better performance over time, and shows lower variance across runs. These results suggest that active sampling can reduce resources needed for independent fairness auditing with LLMs, supporting continuous model evaluations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03093", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03093", "abs": "https://arxiv.org/abs/2601.03093", "authors": ["Tuc Nguyen", "Thai Le"], "title": "ATLAS: Adaptive Test-Time Latent Steering with External Verifiers for Enhancing LLMs Reasoning", "comment": "12 pages, 3 figures", "summary": "Recent work on activation and latent steering has demonstrated that modifying internal representations can effectively guide large language models (LLMs) toward improved reasoning and efficiency without additional training. However, most existing approaches rely on fixed steering policies and static intervention strengths, which limit their robustness across problem instances and often result in over- or under-steering. We propose Adaptive Test-time Latent Steering, called (ATLAS), a task- specific framework that dynamically controls steering decisions at inference time using an external, lightweight latent verifier. Given intermediate hidden states, the verifier predicts the quality of ongoing reasoning and adaptively selects whether and how strongly to apply steering, enabling per-example and per-step adjustment with minimal overhead. To our knowledge, ATLAS is the first method to integrate learned latent verification into test-time steering for enhancing LLMs reasoning. Experiments on multiple mathematical reasoning benchmarks show that ATLAS consistently outperforms both vanilla decoding and fixed steering baselines, achieving higher accuracy while substantially reducing test-time token usage. These results demonstrate that verifier-guided latent adaptation provides an effective and scalable mechanism for controlling reasoning efficiency without sacrificing solution quality. All source code will be publicly available.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03098", "categories": ["cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.03098", "abs": "https://arxiv.org/abs/2601.03098", "authors": ["Meghna Roy Chowdhury", "Shreyas Sen", "Yi Ding"], "title": "From Muscle to Text with MyoText: sEMG to Text via Finger Classification and Transformer-Based Decoding", "comment": "25 pages, 11 tables, 11 figures", "summary": "Surface electromyography (sEMG) provides a direct neural interface for decoding muscle activity and offers a promising foundation for keyboard-free text input in wearable and mixed-reality systems. Previous sEMG-to-text studies mainly focused on recognizing letters directly from sEMG signals, forming an important first step toward translating muscle activity into text. Building on this foundation, we present MyoText, a hierarchical framework that decodes sEMG signals to text through physiologically grounded intermediate stages. MyoText first classifies finger activations from multichannel sEMG using a CNN-BiLSTM-Attention model, applies ergonomic typing priors to infer letters, and reconstructs full sentences with a fine-tuned T5 transformer. This modular design mirrors the natural hierarchy of typing, linking muscle intent to language output and reducing the search space for decoding. Evaluated on 30 users from the emg2qwerty dataset, MyoText outperforms baselines by achieving 85.4% finger-classification accuracy, 5.4% character error rate (CER), and 6.5% word error rate (WER). Beyond accuracy gains, this methodology establishes a principled pathway from neuromuscular signals to text, providing a blueprint for virtual and augmented-reality typing interfaces that operate entirely without physical keyboards. By integrating ergonomic structure with transformer-based linguistic reasoning, MyoText advances the feasibility of seamless, wearable neural input for future ubiquitous computing environments.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03099", "categories": ["cs.LG", "econ.EM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.03099", "abs": "https://arxiv.org/abs/2601.03099", "authors": ["Saeyoung Rho", "Cyrus Illick", "Samhitha Narasipura", "Alberto Abadie", "Daniel Hsu", "Vishal Misra"], "title": "Time-Aware Synthetic Control", "comment": null, "summary": "The synthetic control (SC) framework is widely used for observational causal inference with time-series panel data. SC has been successful in diverse applications, but existing methods typically treat the ordering of pre-intervention time indices interchangeable. This invariance means they may not fully take advantage of temporal structure when strong trends are present. We propose Time-Aware Synthetic Control (TASC), which employs a state-space model with a constant trend while preserving a low-rank structure of the signal. TASC uses the Kalman filter and Rauch-Tung-Striebel smoother: it first fits a generative time-series model with expectation-maximization and then performs counterfactual inference. We evaluate TASC on both simulated and real-world datasets, including policy evaluation and sports prediction. Our results suggest that TASC offers advantages in settings with strong temporal trends and high levels of observation noise.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03111", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03111", "abs": "https://arxiv.org/abs/2601.03111", "authors": ["Yiyuan Li", "Zhen Huang", "Yanan Wu", "Weixun Wang", "Xuefeng Li", "Yijia Luo", "Wenbo Su", "Bo Zheng", "Pengfei Liu"], "title": "One Sample to Rule Them All: Extreme Data Efficiency in RL Scaling", "comment": null, "summary": "The reasoning ability of large language models (LLMs) can be unleashed with reinforcement learning (RL) (OpenAI, 2024; DeepSeek-AI et al., 2025a; Zeng et al., 2025). The success of existing RL attempts in LLMs usually relies on high-quality samples of thousands or beyond. In this paper, we challenge fundamental assumptions about data requirements in RL for LLMs by demonstrating the remarkable effectiveness of one-shot learning. Specifically, we introduce polymath learning, a framework for designing one training sample that elicits multidisciplinary impact. We present three key findings: (1) A single, strategically selected math reasoning sample can produce significant performance improvements across multiple domains, including physics, chemistry, and biology with RL; (2) The math skills salient to reasoning suggest the characteristics of the optimal polymath sample; and (3) An engineered synthetic sample that integrates multidiscipline elements outperforms training with individual samples that naturally occur. Our approach achieves superior performance to training with larger datasets across various reasoning benchmarks, demonstrating that sample quality and design, rather than quantity, may be the key to unlock enhanced reasoning capabilities in language models. Our results suggest a shift, dubbed as sample engineering, toward precision engineering of training samples rather than simply increasing data volume.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03149", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03149", "abs": "https://arxiv.org/abs/2601.03149", "authors": ["Dehao Yuan", "Tyler Farnan", "Stefan Tesliuc", "Doron L Bergman", "Yulun Wu", "Xiaoyu Liu", "Minghui Liu", "James Montgomery", "Nam H Nguyen", "C. Bayan Bruss", "Furong Huang"], "title": "PersonaLedger: Generating Realistic Financial Transactions with Persona Conditioned LLMs and Rule Grounded Feedback", "comment": null, "summary": "Strict privacy regulations limit access to real transaction data, slowing open research in financial AI. Synthetic data can bridge this gap, but existing generators do not jointly achieve behavioral diversity and logical groundedness. Rule-driven simulators rely on hand-crafted workflows and shallow stochasticity, which miss the richness of human behavior. Learning-based generators such as GANs capture correlations yet often violate hard financial constraints and still require training on private data. We introduce PersonaLedger, a generation engine that uses a large language model conditioned on rich user personas to produce diverse transaction streams, coupled with an expert configurable programmatic engine that maintains correctness. The LLM and engine interact in a closed loop: after each event, the engine updates the user state, enforces financial rules, and returns a context aware \"nextprompt\" that guides the LLM toward feasible next actions. With this engine, we create a public dataset of 30 million transactions from 23,000 users and a benchmark suite with two tasks, illiquidity classification and identity theft segmentation. PersonaLedger offers a realistic, privacy preserving resource that supports rigorous evaluation of forecasting and anomaly detection models. PersonaLedger offers the community a rich, realistic, and privacy preserving resource -- complete with code, rules, and generation logs -- to accelerate innovation in financial AI and enable rigorous, reproducible evaluation.", "AI": {"tldr": "\u53d7\u9690\u79c1\u9650\u5236\uff0c\u91d1\u878dAI\u7f3a\u4e4f\u771f\u5b9e\u4ea4\u6613\u6570\u636e\uff1b\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u5728\u591a\u6837\u6027\u6216\u7ea6\u675f\u6027\u4e0a\u4e0d\u8db3\u3002PersonaLedger\u901a\u8fc7LLM+\u7a0b\u5e8f\u5f15\u64ce\u95ed\u73af\u751f\u6210\uff0c\u65e2\u4fdd\u6301\u884c\u4e3a\u591a\u6837\uff0c\u53c8\u4e25\u683c\u9075\u5b88\u91d1\u878d\u89c4\u5219\uff0c\u751f\u621030M\u4ea4\u6613\u6570\u636e\u5e76\u63d0\u4f9b\u57fa\u51c6\u3002", "motivation": "\u73b0\u5b9e\u91d1\u878d\u4ea4\u6613\u6570\u636e\u56e0\u9690\u79c1\u76d1\u7ba1\u96be\u4ee5\u83b7\u53d6\uff0c\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u8981\u4e48\u7f3a\u4e4f\u884c\u4e3a\u591a\u6837\u6027\uff0c\u8981\u4e48\u96be\u4ee5\u6ee1\u8db3\u91d1\u878d\u7ea6\u675f\uff0c\u8feb\u5207\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u751f\u6210\u771f\u5b9e\u591a\u6837\u884c\u4e3a\u53c8\u80fd\u4e25\u683c\u9075\u5b88\u7ea6\u675f\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u5f15\u64ce\u3002", "method": "\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e30\u5bcc\u7684\u7528\u6237\u753b\u50cf\u6761\u4ef6\u4e0b\u751f\u6210\u4ea4\u6613\u4e8b\u4ef6\uff0c\u5e76\u901a\u8fc7\u95ed\u73af\u7a0b\u5e8f\u5f15\u64ce\u5b9e\u65f6\u6821\u6b63\u7528\u6237\u72b6\u6001\u4e0e\u91d1\u878d\u7ea6\u675f\uff0c\u5c06\u5f15\u64ce\u8fd4\u56de\u7684\u201cnextprompt\u201d\u53cd\u9988\u7ed9LLM\uff0c\u5f15\u5bfc\u6301\u7eed\u4ea7\u751f\u7b26\u5408\u89c4\u5219\u7684\u540e\u7eed\u4ea4\u6613\u3002", "result": "\u6784\u5efa\u4e86PersonaLedger\uff0c\u751f\u621030,000\u540d\u7528\u6237\u30013,000\u4e07\u7b14\u4ea4\u6613\u7684\u516c\u5171\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u4f9b\u4e24\u4e2a\u8bc4\u6d4b\u57fa\u51c6\uff08\u6d41\u52a8\u6027\u5206\u7c7b\u4e0e\u8eab\u4efd\u76d7\u7a83\u5206\u5272\uff09\uff0c\u5c55\u793a\u4e86\u8be5\u751f\u6210\u65b9\u6cd5\u5728\u591a\u6837\u6027\u548c\u903b\u8f91\u6b63\u786e\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "PersonaLedger\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ed3\u5408LLM\u4e0e\u53ef\u914d\u7f6e\u7a0b\u5e8f\u5f15\u64ce\u7684\u6846\u67b6\uff0c\u80fd\u591f\u751f\u6210\u884c\u4e3a\u591a\u6837\u4e14\u7b26\u5408\u91d1\u878d\u89c4\u5219\u7684\u5408\u6210\u4ea4\u6613\u6570\u636e\uff0c\u5e76\u516c\u5f0030\u4e07\u6761\u4ea4\u6613\u6570\u636e\u96c6\u53ca\u5176\u57fa\u51c6\u4efb\u52a1\uff1b\u8be5\u65b9\u6cd5\u5728\u4fdd\u8bc1\u9690\u79c1\u7684\u524d\u63d0\u4e0b\u4fc3\u8fdb\u91d1\u878dAI\u7814\u7a76\u3002"}}
{"id": "2601.03156", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.03156", "abs": "https://arxiv.org/abs/2601.03156", "authors": ["Sofie Goethals", "Foster Provost", "Jo\u00e3o Sedoc"], "title": "Prompt-Counterfactual Explanations for Generative AI System Behavior", "comment": null, "summary": "As generative AI systems become integrated into real-world applications, organizations increasingly need to be able to understand and interpret their behavior. In particular, decision-makers need to understand what causes generative AI systems to exhibit specific output characteristics. Within this general topic, this paper examines a key question: what is it about the input -the prompt- that causes an LLM-based generative AI system to produce output that exhibits specific characteristics, such as toxicity, negative sentiment, or political bias. To examine this question, we adapt a common technique from the Explainable AI literature: counterfactual explanations. We explain why traditional counterfactual explanations cannot be applied directly to generative AI systems, due to several differences in how generative AI systems function. We then propose a flexible framework that adapts counterfactual explanations to non-deterministic, generative AI systems in scenarios where downstream classifiers can reveal key characteristics of their outputs. Based on this framework, we introduce an algorithm for generating prompt-counterfactual explanations (PCEs). Finally, we demonstrate the production of counterfactual explanations for generative AI systems with three case studies, examining different output characteristics (viz., political leaning, toxicity, and sentiment). The case studies further show that PCEs can streamline prompt engineering to suppress undesirable output characteristics and can enhance red-teaming efforts to uncover additional prompts that elicit undesirable outputs. Ultimately, this work lays a foundation for prompt-focused interpretability in generative AI: a capability that will become indispensable as these models are entrusted with higher-stakes tasks and subject to emerging regulatory requirements for transparency and accountability.", "AI": {"tldr": "\u672c\u6587\u6539\u9020\u53cd\u4e8b\u5b9e\u89e3\u91ca\u6846\u67b6\uff0c\u63d0\u51fa\u63d0\u793a\u53cd\u4e8b\u5b9e\u89e3\u91ca(PCE)\u7b97\u6cd5\uff0c\u5229\u7528\u4e0b\u6e38\u5206\u7c7b\u5668\u6355\u6349\u751f\u6210\u5f0fAI\u8f93\u51fa\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u653f\u6cbb\u503e\u5411\u3001\u6bd2\u6027\u3001\u60c5\u7eea\u4e09\u4f8b\u6f14\u793a\u5176\u5728\u63d0\u793a\u5de5\u7a0b\u4e0e\u7ea2\u961f\u4e2d\u7684\u6548\u80fd\uff0c\u6784\u5efa\u751f\u6210\u5f0fAI\u63d0\u793a\u53ef\u89e3\u91ca\u6027\u7684\u57fa\u7840\u3002", "motivation": "\u89e3\u91ca\u751f\u6210\u5f0fAI\u7cfb\u7edf\u4e3a\u4f55\u5728\u4e0d\u540c\u8f93\u5165\u63d0\u793a\u4e0b\u4ea7\u751f\u7279\u5b9a\u8f93\u51fa\u7279\u5f81\uff08\u5982\u6bd2\u6027\u3001\u8d1f\u9762\u60c5\u7eea\u3001\u653f\u6cbb\u504f\u89c1\uff09\uff0c\u6ee1\u8db3\u51b3\u7b56\u8005\u5bf9\u6a21\u578b\u900f\u660e\u5ea6\u548c\u53ef\u76d1\u7ba1\u6027\u9700\u6c42\u3002", "method": "\u91c7\u7528\u53ef\u89e3\u91caAI\u4e2d\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u6846\u67b6\uff0c\u9488\u5bf9\u975e\u786e\u5b9a\u6027\u7684\u751f\u6210\u5f0fAI\u6539\u9020\u540e\u63d0\u51fa\u63d0\u793a\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08PCE\uff09\u7b97\u6cd5\uff0c\u5e76\u7ed3\u5408\u4e0b\u6e38\u5206\u7c7b\u5668\u8bc6\u522b\u8f93\u51fa\u5173\u952e\u7279\u5f81\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\uff08\u653f\u6cbb\u503e\u5411\u3001\u6bd2\u6027\u3001\u60c5\u7eea\uff09\u5c55\u793aPCE\u80fd\u591f\u5feb\u901f\u751f\u6210\u63d0\u793a\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u5e2e\u52a9\u63d0\u793a\u5de5\u7a0b\u5e08\u6291\u5236\u4e0d\u826f\u8f93\u51fa\u5e76\u63d0\u5347\u7ea2\u961f\u6d4b\u8bd5\u6548\u679c\uff0c\u8bc1\u660e\u5176\u53ef\u4f5c\u4e3a\u751f\u6210\u5f0fAI\u63d0\u793a\u89e3\u91ca\u7684\u57fa\u7840\u5de5\u5177\u3002", "conclusion": "\u63d0\u793a\u7126\u70b9\u7684\u53ef\u89e3\u91ca\u6027\u4e3a\u5728\u9ad8\u98ce\u9669\u4efb\u52a1\u4e2d\u4f7f\u7528\u751f\u6210\u5f0fAI\u65f6\u7684\u900f\u660e\u5ea6\u548c\u95ee\u8d23\u5236\u5960\u5b9a\u57fa\u7840\uff1bPCE\u4e3a\u672a\u6765\u76d1\u7ba1\u5408\u89c4\u63d0\u4f9b\u5fc5\u8981\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2601.03159", "categories": ["cs.LG", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.03159", "abs": "https://arxiv.org/abs/2601.03159", "authors": ["Wadie Skaf", "Felix Kern", "Aryamaan Basu Roy", "Tejas Pradhan", "Roman Kalkreuth", "Holger Hoos"], "title": "Rapid Augmentations for Time Series (RATS): A High-Performance Library for Time Series Augmentation", "comment": null, "summary": "Time series augmentation is critical for training robust deep learning models, particularly in domains where labelled data is scarce and expensive to obtain. However, existing augmentation libraries for time series, mainly written in Python, suffer from performance bottlenecks, where running time grows exponentially as dataset sizes increase -- an aspect limiting their applicability in large-scale, production-grade systems. We introduce RATS (Rapid Augmentations for Time Series), a high-performance library for time series augmentation written in Rust with Python bindings (RATSpy). RATS implements multiple augmentation methods spanning basic transformations, frequency-domain operations and time warping techniques, all accessible through a unified pipeline interface with built-in parallelisation. Comprehensive benchmarking of RATSpy versus a commonly used library (tasug) on 143 datasets demonstrates that RATSpy achieves an average speedup of 74.5\\% over tsaug (up to 94.8\\% on large datasets), with up to 47.9\\% less peak memory usage.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03162", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03162", "abs": "https://arxiv.org/abs/2601.03162", "authors": ["Shuai Jiang", "Alexey Voronin", "Eric Cyr", "Ben Southworth"], "title": "On the Convergence Behavior of Preconditioned Gradient Descent Toward the Rich Learning Regime", "comment": "21 pages, 13 figures,", "summary": "Spectral bias, the tendency of neural networks to learn low frequencies first, can be both a blessing and a curse. While it enhances the generalization capabilities by suppressing high-frequency noise, it can be a limitation in scientific tasks that require capturing fine-scale structures. The delayed generalization phenomenon known as grokking is another barrier to rapid training of neural networks. Grokking has been hypothesized to arise as learning transitions from the NTK to the feature-rich regime. This paper explores the impact of preconditioned gradient descent (PGD), such as Gauss-Newton, on spectral bias and grokking phenomena. We demonstrate through theoretical and empirical results how PGD can mitigate issues associated with spectral bias. Additionally, building on the rich learning regime grokking hypothesis, we study how PGD can be used to reduce delays associated with grokking. Our conjecture is that PGD, without the impediment of spectral bias, enables uniform exploration of the parameter space in the NTK regime. Our experimental results confirm this prediction, providing strong evidence that grokking represents a transitional behavior between the lazy regime characterized by the NTK and the rich regime. These findings deepen our understanding of the interplay between optimization dynamics, spectral bias, and the phases of neural network learning.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03166", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03166", "abs": "https://arxiv.org/abs/2601.03166", "authors": ["Daphne Theodorakopoulos", "Marcel Wever", "Marius Lindauer"], "title": "Dynamic Hyperparameter Importance for Efficient Multi-Objective Optimization", "comment": "Submitted to IJCAI 2026", "summary": "Choosing a suitable ML model is a complex task that can depend on several objectives, e.g., accuracy, model size, fairness, inference time, or energy consumption. In practice, this requires trading off multiple, often competing, objectives through multi-objective optimization (MOO). However, existing MOO methods typically treat all hyperparameters as equally important, overlooking that hyperparameter importance (HPI) can vary significantly depending on the trade-off between objectives. We propose a novel dynamic optimization approach that prioritizes the most influential hyperparameters based on varying objective trade-offs during the search process, which accelerates empirical convergence and leads to better solutions. Building on prior work on HPI for MOO post-analysis, we now integrate HPI, calculated with HyperSHAP, into the optimization. For this, we leverage the objective weightings naturally produced by the MOO algorithm ParEGO and adapt the configuration space by fixing the unimportant hyperparameters, allowing the search to focus on the important ones. Eventually, we validate our method with diverse tasks from PyMOO and YAHPO-Gym. Empirical results demonstrate improvements in convergence speed and Pareto front quality compared to baselines.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03173", "categories": ["cs.LG", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.03173", "abs": "https://arxiv.org/abs/2601.03173", "authors": ["Sumit S. Shevtekar", "Chandresh K. Maurya", "Gourab Sil", "Subasish Das"], "title": "Predicting Time Pressure of Powered Two-Wheeler Riders for Proactive Safety Interventions", "comment": "13 pages, 8 figures", "summary": "Time pressure critically influences risky maneuvers and crash proneness among powered two-wheeler riders, yet its prediction remains underexplored in intelligent transportation systems. We present a large-scale dataset of 129,000+ labeled multivariate time-series sequences from 153 rides by 51 participants under No, Low, and High Time Pressure conditions. Each sequence captures 63 features spanning vehicle kinematics, control inputs, behavioral violations, and environmental context. Our empirical analysis shows High Time Pressure induces 48% higher speeds, 36.4% greater speed variability, 58% more risky turns at intersections, 36% more sudden braking, and 50% higher rear brake forces versus No Time Pressure. To benchmark this dataset, we propose MotoTimePressure, a deep learning model combining convolutional preprocessing, dual-stage temporal attention, and Squeeze-and-Excitation feature recalibration, achieving 91.53% accuracy and 98.93% ROC AUC, outperforming eight baselines. Since time pressure cannot be directly measured in real time, we demonstrate its utility in collision prediction and threshold determination. Using MTPS-predicted time pressure as features, improves Informer-based collision risk accuracy from 91.25% to 93.51%, approaching oracle performance (93.72%). Thresholded time pressure states capture rider cognitive stress and enable proactive ITS interventions, including adaptive alerts, haptic feedback, V2I signaling, and speed guidance, supporting safer two-wheeler mobility under the Safe System Approach.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03184", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03184", "abs": "https://arxiv.org/abs/2601.03184", "authors": ["Stepan Maschan", "Haoxuan Qu", "Jun Liu"], "title": "Decentralized Autoregressive Generation", "comment": "Work in progress", "summary": "We present a theoretical analysis of decentralization of autoregressive generation. We define the Decentralized Discrete Flow Matching objective, by expressing probability generating velocity as a linear combination of expert flows. We also conduct experiments demonstrat- ing the equivalence between decentralized and centralized training settings for multimodal language models across diverse set of benchmarks. Specifically, we compare two distinct paradigms: LLaVA and InternVL 2.5-1B, which uses a fixed CLIP vision encoder and per- forms full-parameter fine-tuning (ViT+MLP+LLM) during the instruction tuning stage.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7 Decentralized Discrete Flow Matching \u76ee\u6807\uff0c\u5c55\u793a\u4e86\u5728\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u4e0a\u53bb\u4e2d\u5fc3\u5316\u8bad\u7ec3\u4e0e\u4e2d\u5fc3\u5316\u8bad\u7ec3\u7684\u7b49\u4ef7\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u3002", "motivation": "\u63a2\u7a76\u5982\u4f55\u5728\u4fdd\u6301\u6027\u80fd\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u81ea\u52a8\u56de\u5f52\u751f\u6210\u4efb\u52a1\u7684\u53bb\u4e2d\u5fc3\u5316\u8bad\u7ec3\uff0c\u4ee5\u63d0\u5347\u53ef\u6269\u5c55\u6027\u4e0e\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002", "method": "\u5f15\u5165 Decentralized Discrete Flow Matching \u76ee\u6807\uff0c\u5c06\u751f\u6210\u6982\u7387\u7684\u901f\u5ea6\u7ebf\u6027\u7ec4\u5408\u4e3a\u4e13\u5bb6\u6d41\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u5bf9\u6bd4 LLaVA \u4e0e InternVL 2.5\u20111B \u4e24\u79cd\u67b6\u6784\u5728\u53bb\u4e2d\u5fc3\u5316\u4e0e\u4e2d\u5fc3\u5316\u8bad\u7ec3\u4e0b\u7684\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u56fa\u5b9a CLIP \u89c6\u89c9\u7f16\u7801\u5668\u5e76\u5728\u6307\u4ee4\u8c03\u4f18\u9636\u6bb5\u8fdb\u884c\u5168\u53c2\u6570\u5fae\u8c03\u7684 LLaVA \u4e0e InternVL 2.5\u20111B\uff0c\u5728\u53bb\u4e2d\u5fc3\u5316\u4e0e\u4e2d\u5fc3\u5316\u8bad\u7ec3\u8bbe\u7f6e\u4e0b\u5747\u80fd\u5b9e\u73b0\u7b49\u4ef7\u7684\u8868\u73b0\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u5728\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u91c7\u7528 Decentralized Discrete Flow Matching \u76ee\u6807\u7684\u53bb\u4e2d\u5fc3\u5316\u8bad\u7ec3\u4e0e\u4f20\u7edf\u4e2d\u5fc3\u5316\u8bad\u7ec3\u5728\u5404\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8868\u73b0\u7b49\u4ef7\u3002"}}
{"id": "2601.03195", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03195", "abs": "https://arxiv.org/abs/2601.03195", "authors": ["Aaron R. Flouro", "Shawn P. Chadwick"], "title": "Sparse Knowledge Distillation: A Mathematical Framework for Probability-Domain Temperature Scaling and Multi-Stage Compression", "comment": "Machine learning theory. Develops an axiomatic, operator-agnostic framework for probability-domain knowledge distillation, including bias--variance analysis of sparse students, homotopy-based multi-stage pruning, $O(1/n)$ convergence guarantees, and equivalence classes of probability-domain softening operators. Theoretical analysis only", "summary": "We develop a unified theoretical framework for sparse knowledge distillation based on probability-domain softening operators. While the equivalence $p^{1/T} \\propto \\mathrm{softmax}(z/T)$ is well known, our contribution is an operator-level analytical framework built on this foundation rather than the equivalence itself.\n  The framework comprises four core components: (i) operator-agnostic bias--variance decompositions that characterize when sparse students outperform dense teachers, (ii) a homotopy path formalization of multi-stage pruning in function space explaining why iterative compression succeeds where one-shot pruning fails, (iii) convergence guarantees establishing $O(1/n)$ rates for $n$-stage distillation with explicit parameter dependence, and (iv) equivalence class characterizations identifying distinct probability-domain operators that yield identical student models under capacity constraints.\n  We introduce an axiomatic definition of probability-domain softening operators based on ranking preservation, continuity, entropy monotonicity, identity, and boundary behavior, and show that multiple non-equivalent operator families satisfy these axioms. All learning-theoretic guarantees are shown to hold uniformly across this operator class, independent of implementation details. These results provide theoretical grounding for black-box teacher distillation, partial-access settings such as top-$k$ truncation and text-only outputs, and privacy-preserving model compression.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.03198", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03198", "abs": "https://arxiv.org/abs/2601.03198", "authors": ["Weilei He", "Feng Ju", "Zhiyuan Fan", "Rui Min", "Minhao Cheng", "Yi R. Fung"], "title": "Empowering Reliable Visual-Centric Instruction Following in MLLMs", "comment": "Submitted to ARR Jan", "summary": "Evaluating the instruction-following (IF) capabilities of Multimodal Large Language Models (MLLMs) is essential for rigorously assessing how faithfully model outputs adhere to user-specified intentions. Nevertheless, existing benchmarks for evaluating MLLMs' instruction-following capability primarily focus on verbal instructions in the textual modality. These limitations hinder a thorough analysis of instruction-following capabilities, as they overlook the implicit constraints embedded in the semantically rich visual modality. To address this gap, we introduce VC-IFEval, a new benchmark accompanied by a systematically constructed dataset that evaluates MLLMs' instruction-following ability under multimodal settings. Our benchmark systematically incorporates vision-dependent constraints into instruction design, enabling a more rigorous and fine-grained assessment of how well MLLMs align their outputs with both visual input and textual instructions. Furthermore, by fine-tuning MLLMs on our dataset, we achieve substantial gains in visual instruction-following accuracy and adherence. Through extensive evaluation across representative MLLMs, we provide new insights into the strengths and limitations of current models.", "AI": {"tldr": "\u63a8\u51faVC-IFEval\u57fa\u51c6\uff0c\u7cfb\u7edf\u7ed3\u5408\u89c6\u89c9\u7ea6\u675f\u5bf9\u591a\u6a21\u6001\u6a21\u578b\u8fdb\u884c\u8bc4\u6d4b\uff1b\u5fae\u8c03\u540e\u6a21\u578b\u8868\u73b0\u5927\u5e45\u63d0\u5347\uff0c\u5b9e\u9a8c\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u7684\u4f18\u52bf\u4e0e\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u7684\u8bc4\u6d4b\u4ec5\u805a\u7126\u6587\u672c\u6307\u4ee4\uff0c\u65e0\u6cd5\u6355\u6349\u89c6\u89c9\u6a21\u6001\u4e2d\u7684\u9690\u5f0f\u7ea6\u675f\uff0c\u5bfc\u81f4\u5bf9\u591a\u6a21\u6001\u6a21\u578b\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u7684\u8bc4\u4f30\u4e0d\u5b8c\u6574\u3002", "method": "\u6784\u5efa\u7cfb\u7edf\u5316\u7684VC-IFEval \u6570\u636e\u96c6\uff0c\u5c06\u89c6\u89c9\u4f9d\u8d56\u7ea6\u675f\u5d4c\u5165\u6307\u4ee4\u8bbe\u8ba1\uff1b\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u591a\u6a21\u6001\u5927\u6a21\u578b\uff1b\u5728\u4ee3\u8868\u6027\u6a21\u578b\u4e0a\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5fae\u8c03\u540e\u7684\u591a\u6a21\u6001\u6a21\u578b\u5728\u89c6\u89c9\u6307\u4ee4\u9075\u5faa\u51c6\u786e\u7387\u548c\u9075\u4ece\u5ea6\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff1b\u5bf9\u591a\u79cd\u4ee3\u8868\u6027\u6a21\u578b\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u6d1e\u89c1\uff0c\u5c55\u793a\u4e86\u5404\u6a21\u578b\u7684\u5f3a\u9879\u4e0e\u5f31\u70b9\u3002", "conclusion": "VC-IFEval\u4e3a\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u6307\u4ee4\u9075\u5faa\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7ec6\u7c92\u5ea6\u3001\u4e25\u683c\u7684\u57fa\u51c6\uff0c\u8bc1\u660e\u5728\u89c6\u89c9\u4f9d\u8d56\u7ea6\u675f\u4e0b\u7684\u8bc4\u6d4b\u4e0e\u5fae\u8c03\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u89c6\u89c9\u6307\u4ee4\u9075\u5faa\u51c6\u786e\u6027\uff0c\u5e76\u63ed\u793a\u5f53\u524d\u6a21\u578b\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\u3002"}}
{"id": "2601.03203", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.03203", "abs": "https://arxiv.org/abs/2601.03203", "authors": ["Davi Val\u00e9rio", "Chrysoula Zerva", "Mariana Pinto", "Ricardo Santos", "Andr\u00e9 Carreiro"], "title": "Counterfactual Fairness with Graph Uncertainty", "comment": "Peer reviewed pre-print. Presented at the BIAS 2025 Workshop at ECML PKDD", "summary": "Evaluating machine learning (ML) model bias is key to building trustworthy and robust ML systems. Counterfactual Fairness (CF) audits allow the measurement of bias of ML models with a causal framework, yet their conclusions rely on a single causal graph that is rarely known with certainty in real-world scenarios. We propose CF with Graph Uncertainty (CF-GU), a bias evaluation procedure that incorporates the uncertainty of specifying a causal graph into CF. CF-GU (i) bootstraps a Causal Discovery algorithm under domain knowledge constraints to produce a bag of plausible Directed Acyclic Graphs (DAGs), (ii) quantifies graph uncertainty with the normalized Shannon entropy, and (iii) provides confidence bounds on CF metrics. Experiments on synthetic data show how contrasting domain knowledge assumptions support or refute audits of CF, while experiments on real-world data (COMPAS and Adult datasets) pinpoint well-known biases with high confidence, even when supplied with minimal domain knowledge constraints.", "AI": {"tldr": "CF-GU\u5728\u4e0d\u786e\u5b9a\u7684\u56e0\u679c\u56fe\u4e0b\u8fdb\u884c\u504f\u5dee\u8bc4\u4f30\uff0c\u5229\u7528\u81ea\u52a9\u91c7\u6837\u53ca\u71b5\u91cf\u5316\u63d0\u4f9b\u7edf\u8ba1\u7f6e\u4fe1\u533a\u95f4\uff0c\u5728\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5728\u73b0\u5b9e\u73af\u5883\u4e0b\uff0c\u56e0\u679c\u56fe\u5f80\u5f80\u4e0d\u786e\u5b9a\uff0c\u5355\u4e00\u56e0\u679c\u56fe\u4e0b\u7684Counterfactual Fairness\u5ba1\u6838\u53ef\u80fd\u5931\u771f\u3002", "method": "CF-GU\u901a\u8fc7\u5728\u9886\u57df\u77e5\u8bc6\u7ea6\u675f\u4e0b\u5bf9\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\u8fdb\u884c\u81ea\u52a9\u91cd\u91c7\u6837\uff0c\u751f\u6210\u4e00\u7ec4\u53ef\u884c\u6709\u5411\u65e0\u73af\u56fe\uff1b\u7528\u5f52\u4e00\u5316\u9999\u519c\u71b5\u91cf\u5316\u56fe\u7ed3\u6784\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u7ed9\u51faCF\u6307\u6807\u7684\u7f6e\u4fe1\u533a\u95f4\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u4e0d\u540c\u9886\u57df\u77e5\u8bc6\u5047\u8bbe\u80fd\u652f\u6301\u6216\u9a73\u65a5CF\u5ba1\u6838\uff1b\u5728COMPAS\u4e0eAdult\u6570\u636e\u96c6\u4e0a\uff0c\u5373\u4f7f\u4ec5\u63d0\u4f9b\u6700\u5c0f\u9886\u57df\u77e5\u8bc6\u7ea6\u675f\uff0c\u4e5f\u80fd\u4ee5\u9ad8\u7f6e\u4fe1\u5ea6\u5b9a\u4f4d\u5df2\u77e5\u504f\u5dee\u3002", "conclusion": "\u5c06\u56e0\u679c\u56fe\u4e0d\u786e\u5b9a\u6027\u7eb3\u5165CF\u8bc4\u4f30\uff0c\u53ef\u63d0\u9ad8\u504f\u5dee\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2601.03213", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03213", "abs": "https://arxiv.org/abs/2601.03213", "authors": ["Mykola Vysotskyi", "Zahar Kohut", "Mariia Shpir", "Taras Rumezhak", "Volodymyr Karpiv"], "title": "Critic-Guided Reinforcement Unlearning in Text-to-Image Diffusion", "comment": "Preprint. Under review at ICLR 2026", "summary": "Machine unlearning in text-to-image diffusion models aims to remove targeted concepts while preserving overall utility. Prior diffusion unlearning methods typically rely on supervised weight edits or global penalties; reinforcement-learning (RL) approaches, while flexible, often optimize sparse end-of-trajectory rewards, yielding high-variance updates and weak credit assignment. We present a general RL framework for diffusion unlearning that treats denoising as a sequential decision process and introduces a timestep-aware critic with noisy-step rewards. Concretely, we train a CLIP-based reward predictor on noisy latents and use its per-step signal to compute advantage estimates for policy-gradient updates of the reverse diffusion kernel. Our algorithm is simple to implement, supports off-policy reuse, and plugs into standard text-to-image backbones. Across multiple concepts, the method achieves better or comparable forgetting to strong baselines while maintaining image quality and benign prompt fidelity; ablations show that (i) per-step critics and (ii) noisy-conditioned rewards are key to stability and effectiveness. We release code and evaluation scripts to facilitate reproducibility and future research on RL-based diffusion unlearning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6269\u6563\u6d88\u5fd8\u6846\u67b6\uff0c\u5c06\u53bb\u566a\u89c6\u4e3a\u5e8f\u5217\u51b3\u7b56\uff0c\u5229\u7528CLIP\u5956\u52b1\u9884\u6d4b\u5668\u63d0\u4f9b\u6b65\u9aa4\u6027\u5956\u52b1\uff0c\u4f7f\u7528\u65f6\u5e8f\u4fe1\u7528\u4f30\u8ba1\u66f4\u65b0\u53cd\u5411\u6269\u6563\u6838\uff0c\u5b9e\u9a8c\u8868\u660e\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u4e14\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u6269\u6563\u6a21\u578b\u7684\u65e0\u76d1\u7763\u6d88\u5fd8\u65b9\u6cd5\u4f7f\u7528\u76d1\u7763\u6743\u91cd\u7f16\u8f91\u6216\u5168\u5c40\u60e9\u7f5a\uff0cRL\u65b9\u6cd5\u53d7\u9650\u4e8e\u7a00\u758f\u7ec8\u65f6\u5956\u52b1\u5bfc\u81f4\u9ad8\u65b9\u5dee\u4e0e\u5f31\u4fe1\u7528\u5206\u914d\uff0c\u9700\u8981\u66f4\u7a33\u5065\u3001\u7ec6\u7c92\u5ea6\u7684\u5b66\u4e60\u7b56\u7565\u3002", "method": "\u901a\u8fc7\u5c06\u53bb\u566a\u89c6\u4e3a\u4e00\u7cfb\u5217\u51b3\u7b56\uff0c\u8bad\u7ec3\u57fa\u4e8eCLIP\u7684\u5956\u52b1\u9884\u6d4b\u5668\u4ee5\u5728\u566a\u58f0\u91cc\u7a0b\u7891\u4e0a\u4ea7\u751f\u5956\u52b1\uff0c\u5e76\u5229\u7528\u542b\u6b65\u9aa4\u4fe1\u606f\u7684\u65f6\u5e8f\u4fe1\u7528\u4f30\u8ba1\u8fdb\u884c\u7b56\u7565\u68af\u5ea6\u66f4\u65b0\uff0c\u540c\u65f6\u652f\u6301\u79bb\u7ebf\u91cd\u7528\u3002", "result": "\u5728\u591a\u79cd\u6982\u5ff5\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6240\u63d0\u51fa\u65b9\u6cd5\u5728\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u548c\u63d0\u793a\u5fe0\u5b9e\u5ea6\u7684\u524d\u63d0\u4e0b\uff0c\u4e0e\u5f3a\u57fa\u7ebf\u76f8\u6bd4\uff0c\u53d6\u5f97\u4e86\u66f4\u4f18\u6216\u76f8\u5f53\u7684\u9057\u5fd8\u6548\u679c\uff1b\u96f6\u4ef6\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6b65\u9aa4\u7ea7\u8bc4\u4f30\u5668\u4e0e\u566a\u58f0\u6761\u4ef6\u5956\u52b1\u5bf9\u4e8e\u7a33\u5b9a\u6027\u548c\u6548\u679c\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u4e2d\u5b9e\u73b0\u673a\u5668\u6d88\u5fd8\uff0c\u80fd\u591f\u6709\u6548\u79fb\u9664\u76ee\u6807\u6982\u5ff5\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u4e0e\u63d0\u793a\u7684\u5fe0\u5b9e\u5ea6\u3002"}}
{"id": "2601.03220", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.03220", "abs": "https://arxiv.org/abs/2601.03220", "authors": ["Marc Finzi", "Shikai Qiu", "Yiding Jiang", "Pavel Izmailov", "J. Zico Kolter", "Andrew Gordon Wilson"], "title": "From Entropy to Epiplexity: Rethinking Information for Computationally Bounded Intelligence", "comment": null, "summary": "Can we learn more from data than existed in the generating process itself? Can new and useful information be constructed from merely applying deterministic transformations to existing data? Can the learnable content in data be evaluated without considering a downstream task? On these questions, Shannon information and Kolmogorov complexity come up nearly empty-handed, in part because they assume observers with unlimited computational capacity and fail to target the useful information content. In this work, we identify and exemplify three seeming paradoxes in information theory: (1) information cannot be increased by deterministic transformations; (2) information is independent of the order of data; (3) likelihood modeling is merely distribution matching. To shed light on the tension between these results and modern practice, and to quantify the value of data, we introduce epiplexity, a formalization of information capturing what computationally bounded observers can learn from data. Epiplexity captures the structural content in data while excluding time-bounded entropy, the random unpredictable content exemplified by pseudorandom number generators and chaotic dynamical systems. With these concepts, we demonstrate how information can be created with computation, how it depends on the ordering of the data, and how likelihood modeling can produce more complex programs than present in the data generating process itself. We also present practical procedures to estimate epiplexity which we show capture differences across data sources, track with downstream performance, and highlight dataset interventions that improve out-of-distribution generalization. In contrast to principles of model selection, epiplexity provides a theoretical foundation for data selection, guiding how to select, generate, or transform data for learning systems.", "AI": {"tldr": "\u63d0\u51fa epiplexity \u6982\u5ff5\u4ee5\u8bc4\u4f30\u53d7\u9650\u89c2\u6d4b\u8005\u4e0b\u7684\u6570\u636e\u4fe1\u606f\u4ef7\u503c\uff0c\u5e76\u63d0\u4f9b\u5b9e\u7528\u4f30\u8ba1\u65b9\u6cd5\uff0c\u8bc1\u660e\u5176\u5bf9\u6570\u636e\u9009\u62e9\u4e0e\u6cdb\u5316\u7684\u6b63\u9762\u5f71\u54cd\u3002", "motivation": "\u4f20\u7edf\u4fe1\u606f\u71b5\u4e0e Kolmogorov \u590d\u6742\u5ea6\u65e0\u6cd5\u8861\u91cf\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u7684\u201c\u6709\u7528\u4fe1\u606f\u201d\uff0c\u5bfc\u81f4\u96be\u4ee5\u8bc4\u4f30\u6570\u636e\u4ef7\u503c\u4e0e\u652f\u6301\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u5b9e\u8df5\u3002", "method": "\u901a\u8fc7\u8bc6\u522b\u4fe1\u606f\u7406\u8bba\u4e2d\u7684\u4e09\u6096\u8bba\uff0c\u5b9a\u4e49epiplexity\u4e3a\u53d7\u9650\u89c2\u6d4b\u8005\u53ef\u5b66\u4e60\u7684\u7ed3\u6784\u4fe1\u606f\uff0c\u6392\u9664\u65f6\u95f4\u53d7\u9650\u7684\u71b5\uff1b\u8bbe\u8ba1\u5b9e\u7528\u4f30\u8ba1\u7a0b\u5e8f\uff0c\u5e76\u5728\u591a\u79cd\u6570\u636e\u6e90\u4e0a\u9a8c\u8bc1\u5176\u4e0e\u4e0b\u6e38\u6027\u80fd\u7684\u76f8\u5173\u6027\u548c\u5206\u5e03\u5916\u6cdb\u5316\u6539\u8fdb\u3002", "result": "\u5c55\u793a\u901a\u8fc7\u8ba1\u7b97\u53ef\u4ee5\u521b\u9020\u4fe1\u606f\u3001\u6570\u636e\u987a\u5e8f\u5f71\u54cd\u4fe1\u606f\u5185\u5bb9\u4ee5\u53ca\u4f3c\u7136\u6a21\u578b\u53ef\u751f\u6210\u6bd4\u751f\u6210\u8fc7\u7a0b\u66f4\u590d\u6742\u7684\u7a0b\u5e8f\uff1b\u5b9e\u8bc1\u4f30\u8ba1\u65b9\u6cd5\u6355\u83b7\u6570\u636e\u5dee\u5f02\u3001\u8ddf\u8e2a\u4e0b\u6e38\u8868\u73b0\uff0c\u5e76\u6307\u51fa\u6570\u636e\u4ecb\u5165\u63d0\u5347 OOD \u6cdb\u5316\u3002", "conclusion": "\u63d0\u51fa\u201cepiplexity\u201d\u6982\u5ff5\uff0c\u9610\u660e\u5728\u53d7\u9650\u89c2\u5bdf\u8005\u4e0b\u53ef\u4ece\u6570\u636e\u4e2d\u751f\u6210\u4fe1\u606f\u3001\u6570\u636e\u987a\u5e8f\u91cd\u8981\u6027\u53ca\u4f3c\u7136\u5efa\u6a21\u80fd\u4ea7\u751f\u66f4\u590d\u6742\u7a0b\u5e8f\uff0c\u5e76\u63d0\u4f9b\u4f30\u8ba1\u65b9\u6cd5\uff1b\u4e3a\u6570\u636e\u9009\u62e9\u3001\u751f\u6210\u4e0e\u8f6c\u6362\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2601.03237", "categories": ["cs.LG", "eess.IV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.03237", "abs": "https://arxiv.org/abs/2601.03237", "authors": ["Javier Salazar Cavazos"], "title": "PET-TURTLE: Deep Unsupervised Support Vector Machines for Imbalanced Data Clusters", "comment": null, "summary": "Foundation vision, audio, and language models enable zero-shot performance on downstream tasks via their latent representations. Recently, unsupervised learning of data group structure with deep learning methods has gained popularity. TURTLE, a state of the art deep clustering algorithm, uncovers data labeling without supervision by alternating label and hyperplane updates, maximizing the hyperplane margin, in a similar fashion to support vector machines (SVMs). However, TURTLE assumes clusters are balanced; when data is imbalanced, it yields non-ideal hyperplanes that cause higher clustering error. We propose PET-TURTLE, which generalizes the cost function to handle imbalanced data distributions by a power law prior. Additionally, by introducing sparse logits in the labeling process, PET-TURTLE optimizes a simpler search space that in turn improves accuracy for balanced datasets. Experiments on synthetic and real data show that PET-TURTLE improves accuracy for imbalanced sources, prevents over-prediction of minority clusters, and enhances overall clustering.", "AI": {"tldr": "PET\u2011TURTLE\u5728TURTLE\u57fa\u7840\u4e0a\u52a0\u5165\u4e86\u9002\u5e94\u4e0d\u5e73\u8861\u7684\u5e42\u5f8b\u4ee3\u4ef7\u51fd\u6570\u5e76\u4f7f\u7528\u7a00\u758flogit\uff0c\u63d0\u5347\u4e86\u805a\u7c7b\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u6570\u636e\u4e0a\u6548\u679c\u660e\u663e\u3002", "motivation": "TURTLE\u5047\u8bbe\u7c07\u5e73\u8861\uff0c\u5728\u9762\u5bf9\u5927\u591a\u6570\u5b9e\u9645\u6570\u636e\u4e0d\u5e73\u8861\u65f6\u4f1a\u4ea7\u751f\u4e0d\u7406\u60f3\u7684\u8d85\u5e73\u9762\uff0c\u5bfc\u81f4\u805a\u7c7b\u8bef\u5dee\u3002\u7814\u7a76\u8005\u5e0c\u671b\u901a\u8fc7\u6539\u8fdb\u4ee3\u4ef7\u51fd\u6570\u6765\u9002\u5e94\u4e0d\u5e73\u8861\u5206\u5e03\u3002", "method": "\u5728TURTLE\u7684\u8fed\u4ee3\u66f4\u65b0\u673a\u5236\u4e2d\u52a0\u5165\u4e00\u4e2a\u80fd\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u4ee3\u4ef7\u51fd\u6570\uff0c\u5e76\u5728\u6807\u7b7e\u9636\u6bb5\u4f7f\u7528\u7a00\u758flogit\u964d\u4f4e\u641c\u7d22\u7a7a\u95f4\uff1b\u8fd9\u4e00\u6539\u52a8\u4f7f\u5f97\u5b66\u4e60\u8fc7\u7a0b\u66f4\u7a33\u5b9a\uff0c\u6700\u7ec8\u83b7\u5f97\u66f4\u4f18\u7684\u8d85\u5e73\u9762\u5212\u5206\u3002", "result": "\u5728\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cPET\u2011TURTLE\u76f8\u6bd4\u539f\u59cbTURTLE\u663e\u8457\u964d\u4f4e\u4e86\u8bef\u805a\u7c7b\u7387\uff0c\u907f\u514d\u4e86\u5c11\u6570\u7c7b\u8fc7\u5ea6\u9884\u6d4b\uff0c\u5e76\u63d0\u5347\u4e86\u6574\u4f53\u805a\u7c7b\u51c6\u786e\u5ea6\u3002", "conclusion": "PET\u2011TURTLE\u901a\u8fc7\u5f15\u5165\u5e42\u5f8b\u5148\u9a8c\u548c\u7a00\u758flogit\uff0c\u89e3\u51b3\u4e86TURTLE\u5728\u6570\u636e\u4e0d\u5e73\u8861\u65f6\u9ad8\u8bef\u5dee\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u5347\u4e86\u6574\u4f53\u805a\u7c7b\u51c6\u5ea6\u3002"}}
