{"id": "2511.14284", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.14284", "abs": "https://arxiv.org/abs/2511.14284", "authors": ["Ran Tamir", "Nir Weinberger", "Albert Guill\u00e9n i F\u00e0bregas"], "title": "DNA Storage in the Short Molecule Regime", "comment": null, "summary": "We study the amount of reliable information that can be stored in a DNA-based storage system composed of short DNA molecules. In this regime, Shomorony and Heckel (2022) put forward a conjecture on the scaling of the number of information bits that can be reliably stored. In this paper, we complete the proof of this conjecture. We analyze a random-coding scheme in which each codeword is obtained by quantizing a randomly generated probability mass function drawn from the probability simplex. By analyzing the optimal maximum-likelihood decoder, we derive an achievability bound that matches a recently established converse bound across the entire short-molecule regime. We also propose a second coding scheme, which operates with significantly lower computational complexity but achieves the optimal scaling, except for a specific range of very short molecules.", "AI": {"tldr": "\u5b8c\u6210\u5bf9\u4e00\u4e2a\u5173\u4e8e\u5728\u77ed\u5206\u5b50DNA\u5b58\u50a8\u7cfb\u7edf\u4e2d\u53ef\u53ef\u9760\u5b58\u50a8\u4fe1\u606f\u91cf\u968f\u89c4\u6a21\u7684\u7f29\u653e\u7684 conjecture \u7684\u8bc1\u660e\u3002\u901a\u8fc7\u5bf9\u6bcf\u4e2a\u7801\u5b57\u8fdb\u884c\u91cf\u5316\u7684\u968f\u673a\u751f\u6210\u6982\u7387\u8d28\u91cf\u51fd\u6570\u7684\u968f\u673a\u7f16\u7801\u65b9\u6848\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u5bf9\u6700\u4f18\u5316\u6700\u5927\u4f3c\u7136\u89e3\u7801\u5668\u63a8\u5bfc\u51fa\u53ef\u5b9e\u73b0\u6027\u754c\uff0c\u4e14\u8be5\u754c\u4e0e\u6700\u8fd1\u5efa\u7acb\u7684\u53cd\u4f8b\u754c\u5728\u6574\u4e2a\u77ed\u5206\u5b50\u533a\u57df\u90fd\u4e00\u81f4\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u7b2c\u4e8c\u79cd\u4f4e\u590d\u6742\u5ea6\u7684\u7f16\u7801\u65b9\u6848\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u6700\u4f18\u7f29\u653e\uff0c\u552f\u4e00\u5728\u975e\u5e38\u77ed\u7684\u5206\u5b50\u8303\u56f4\u5185\u7684\u67d0\u4e9b\u60c5\u5f62\u4f8b\u5916\u3002", "motivation": "\u9610\u660e\u5728\u77ed\u5206\u5b50DNA\u5b58\u50a8\u7cfb\u7edf\u4e2d\u53ef\u53ef\u9760\u5b58\u50a8\u4fe1\u606f\u7684\u6781\u9650\u7f29\u653e\u89c4\u5f8b\uff0c\u5b8c\u6210 Shomorony \u4e0e Heckel (2022) \u5173\u4e8e\u8be5\u9886\u57df\u7684\u731c\u60f3\uff0c\u5efa\u7acb\u7f16\u7801-\u89e3\u7801\u7b56\u7565\u7684\u53ef\u5b9e\u73b0\u6027\u754c\u5e76\u4e0e\u5bf9\u7acb\u754c\u76f8\u5339\u914d\u3002", "method": "\u4f7f\u7528\u4ece\u6982\u7387\u7b80\u5355\u5f62\u4e2d\u968f\u673a\u62bd\u53d6\u7684\u6982\u7387\u8d28\u91cf\u51fd\u6570\u91cf\u5316\u540e\u5f97\u5230\u7684\u7801\u5b57\u8fdb\u884c\u968f\u673a\u7f16\u7801\uff1b\u5bf9\u6700\u4f18\u7684\u6700\u5927\u4f3c\u7136\u89e3\u7801\u5668\u8fdb\u884c\u5206\u6790\u4ee5\u63a8\u5bfc\u53ef\u5b9e\u73b0\u6027\u754c\uff0c\u5e76\u63d0\u51fa\u7b2c\u4e8c\u79cd\u8ba1\u7b97\u590d\u6742\u5ea6\u663e\u8457\u964d\u4f4e\u7684\u7f16\u7801\u65b9\u6848\u3002", "result": "\u7ed9\u51fa\u53ef\u5b9e\u73b0\u6027\u754c\uff0c\u4e0e\u6700\u8fd1\u5efa\u7acb\u7684\u5bf9\u7acb\u754c\u5728\u6574\u500b\u77ed\u5206\u5b50\u533a\u95f4\u76f8\u5339\u914d\uff1b\u5e76\u63d0\u51fa\u7b2c\u4e8c\u79cd\u4f4e\u590d\u6742\u5ea6\u65b9\u6848\uff0c\u5728\u9664\u4e86\u6781\u77ed\u5206\u5b50\u7684\u7279\u5b9a\u8303\u56f4\u5916\u5b9e\u73b0\u6700\u4f18\u7f29\u653e\u3002", "conclusion": "\u8bba\u6587\u89e3\u51b3\u4e86\u5173\u4e8e\u77ed\u5206\u5b50DNA\u5b58\u50a8\u4e2d\u4fe1\u606f\u91cf\u7f29\u653e\u7684\u731c\u60f3\uff0c\u8bc1\u660e\u4e86\u4e24\u79cd\u7f16\u7801\u65b9\u6848\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u2013\u6027\u80fd\u6743\u8861\u4e0b\u5b9e\u73b0\u4e86\u6700\u4f18\u6216\u8fd1\u4f3c\u6700\u4f18\u7684\u7f29\u653e\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0a\u7684\u6781\u9650\u4e0e\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2511.14444", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.14444", "abs": "https://arxiv.org/abs/2511.14444", "authors": ["Zhou Li", "Xiang Zhang", "Yizhou Zhao", "Haiqiang Chen", "Jihao Fan", "Giuseppe Caire"], "title": "The Capacity of Collusion-Resilient Decentralized Secure Aggregation with Groupwise Keys", "comment": "13 pages, 2 pages", "summary": "This paper investigates the information-theoretic decentralized secure aggregation (DSA) problem under practical groupwise secret keys and collusion resilience. In DSA, $K$ users are interconnected through error-free broadcast channels. Each user holds a private input and aims to compute the sum of all other users' inputs, while satisfying the security constraint that no user, even when colluding with up to $T$ other users, can infer any information about the inputs beyond the recovered sum. To ensure security, users are equipped with secret keys to mask their inputs. Motivated by recent advances in efficient group-based key generation protocols, we consider the symmetric groupwise key setting, where every subset of $G$ users shares a group key that is independent of all other group keys. The problem is challenging because the recovery and security constraints must hold simultaneously for all users, and the structural constraints on the secret keys limit the flexibility of key correlations. We characterize the optimal rate region consisting of all achievable pairs of per-user broadcast communication rate and groupwise key rate. In particular, we show that DSA with groupwise keys is infeasible when $G=1$ or $G\\ge K-T$. Otherwise, when $2\\le G<K-T$, to securely compute one symbol of the desired sum, each user must broadcast at least one symbol, and each group key must contain at least $(K-T-2)/\\binom{K-T-1}{G}$ independent symbols. Our results establish the fundamental limits of DSA with groupwise keys and provide design insights for communication- and key-efficient secure aggregation in decentralized learning systems.", "AI": {"tldr": "\u5728\u57fa\u4e8e\u7ec4\u5bc6\u94a5\u7684\u53bb\u4e2d\u5fc3\u5316\u5b89\u5168\u805a\u5408\uff08DSA\uff09\u4e2d\uff0c\u7ed9\u51fa\u53ef\u8fbe\u7684\u5e7f\u64ad\u7387\u4e0e\u7ec4\u5bc6\u94a5\u7387\u7684\u6700\u4f18\u533a\u57df\uff1b\u5f53G=1\u6216G\u2265K\u2212T\u65f6\u4e0d\u53ef\u884c\uff1b\u4e14\u57282\u2264G<K\u2212T\u65f6\uff0c\u4e3a\u5b89\u5168\u8ba1\u7b97\u6bcf\u7528\u6237\u81f3\u5c11\u5e7f\u64ad\u4e00\u4e2a\u7b26\u53f7\uff0c\u4e14\u6bcf\u4e2a\u7ec4\u5bc6\u94a5\u81f3\u5c11\u542b\u6709(K\u2212T\u22122)/C(K\u2212T\u22121,G)\u4e2a\u72ec\u7acb\u7b26\u53f7\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u5b66\u4e60\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u805a\u5408\u95ee\u9898\uff0c\u7ed3\u5408\u4fe1\u606f\u8bba\u5b89\u5168\u7ea6\u675f\u4e0e\u7ec4\u5bc6\u94a5\u7ed3\u6784\uff0c\u7814\u7a76\u5728\u5b9e\u9645\u7ec4\u5bc6\u94a5\u8bbe\u7f6e\u4e0b\u7684\u6700\u5c0f\u901a\u4fe1\u4e0e\u5bc6\u94a5\u5f00\u9500\u3002", "method": "\u57fa\u4e8e\u4fe1\u606f\u8bba\u5206\u6790\uff0c\u63a8\u5bfc\u6700\u4f18\u7387\u533a\u57df\u3002\u901a\u8fc7\u5bf9\u6062\u590d\u6027\u4e0e\u5b89\u5168\u6027\u7ea6\u675f\u7684\u5e76\u884c\u8003\u8651\uff0c\u7ed9\u51faG\u7684\u5206\u6bb5\u53ef\u884c\u6027\u4e0e\u4e0b\u754c\u3002", "result": "\u7ed9\u51fa\u53ef\u8fbe\u5230\u7684\u6700\u4f18\u5e7f\u64ad\u7387\u4e0e\u7ec4\u5bc6\u94a5\u7387\u7684\u533a\u57df\u754c\u9650\uff1bG=1\u6216G\u2265K\u2212T\u4e0d\u53ef\u884c\uff1b\u5bf9\u4e8e2\u2264G<K\u2212T\uff0c\u7ed9\u51fa\u6bcf\u7528\u6237\u6700\u5c11\u5e7f\u64ad\u7b26\u53f7\u6570\u548c\u6bcf\u7ec4\u5bc6\u94a5\u6700\u5c11\u72ec\u7acb\u7b26\u53f7\u6570\u7684\u5177\u4f53\u4e0b\u754c\u3002", "conclusion": "\u63ed\u793a\u5e26\u7ec4\u5bc6\u94a5\u7684DSA\u7684\u57fa\u672c\u6781\u9650\uff0c\u4e3a\u5728\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u4e2d\u7684\u5b89\u5168\u805a\u5408\u8bbe\u8ba1\u63d0\u4f9b\u901a\u4fe1\u4e0e\u5bc6\u94a5\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u6307\u5357\u3002"}}
{"id": "2511.13746", "categories": ["eess.SY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13746", "abs": "https://arxiv.org/abs/2511.13746", "authors": ["Juntang Yang", "Mohamed Khalil Ben-Larbi"], "title": "Deep reinforcement learning-based spacecraft attitude control with pointing keep-out constraint", "comment": null, "summary": "This paper implements deep reinforcement learning (DRL) for spacecraft reorientation control with a single pointing keep-out zone. The Soft Actor-Critic (SAC) algorithm is adopted to handle continuous state and action space. A new state representation is designed to explicitly include a compact representation of the attitude constraint zone. The reward function is formulated to achieve the control objective while enforcing the attitude constraint. A curriculum learning approach is used for the agent training. Simulation results demonstrate the effectiveness of the proposed DRL-based method for spacecraft pointing-constrained attitude control.", "AI": {"tldr": "\u7528 Soft Actor-Critic (SAC) \u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff0c\u7ed3\u5408\u5bf9\u6297\u7ea6\u675f\u6001\u8868\u793a\u4e0e\u8bfe\u7a0b\u5b66\u4e60\uff0c\u5728\u5355\u4e00\u6307\u5411\u4fdd\u6301\u533a\u7684\u592a\u7a7a\u98de\u884c\u5668\u59ff\u6001\u63a7\u5236\u4e2d\u5b9e\u73b0\u53d7\u7ea6\u675f\u7684\u6307\u5411\u63a7\u5236\uff1b\u5728\u4eff\u771f\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u592a\u7a7a\u98de\u884c\u5668\u59ff\u6001\u63a7\u5236\u4e2d\uff0c\u9700\u540c\u65f6\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u8ddf\u8e2a\u548c\u907f\u5f00\u7981\u6b62\u6307\u5411\u533a\u7684\u7ea6\u675f\uff0c\u4e14\u63a7\u5236\u8f93\u5165\u4e3a\u8fde\u7eed\u91cf\uff0c\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u7ea6\u675f\u4e0e\u9ad8\u7ef4\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u65f6\u6709\u96be\u5ea6\u3002\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff0c\u5c24\u5176\u662f SAC\uff0c\u80fd\u5728\u65e0\u6a21\u578b\u6216\u5f31\u6a21\u578b\u7684\u60c5\u5f62\u4e0b\u5b66\u4e60\u7b56\u7565\uff1b\u901a\u8fc7\u5728\u72b6\u6001\u4e2d\u663e\u5f0f\u7f16\u7801\u7ea6\u675f\u533a\u57df\u5e76\u5728\u5956\u52b1\u4e2d\u5f3a\u5316\u7ea6\u675f\u6ee1\u8db3\uff0c\u53ef\u5b9e\u73b0\u53d7\u7ea6\u675f\u7684\u59ff\u6001\u63a7\u5236\uff1b\u7ea7\u8fdb\u5b66\u4e60\uff08\u8bfe\u7a0b\u5b66\u4e60\uff09\u6709\u52a9\u4e8e\u7a33\u5b9a\u8bad\u7ec3\u4e0e\u63d0\u5347\u6536\u655b\u6027\u3002", "method": "\u91c7\u7528 Soft Actor-Critic (SAC) \u8fdb\u884c\u8fde\u7eed\u72b6\u6001-\u52a8\u4f5c\u63a7\u5236\uff1b\u8bbe\u8ba1\u72b6\u6001\u8868\u793a\uff0c\u4f7f\u5176\u663e\u5f0f\u5305\u542b\u59ff\u6001\u7ea6\u675f\u533a\u7684\u7d27\u51d1\u8868\u793a\uff1b\u5c06\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u4e3a\u5728\u5b8c\u6210\u63a7\u5236\u76ee\u6807\u7684\u540c\u65f6\u5f3a\u5236\u6ee1\u8db3\u59ff\u6001\u7ea6\u675f\uff1b\u91c7\u7528\u8bfe\u7a0b\u5b66\u4e60\u5bf9\u667a\u80fd\u4f53\u8fdb\u884c\u5206\u9636\u6bb5\u8bad\u7ec3\u4ee5\u63d0\u9ad8\u6536\u655b\u6027\u4e0e\u9c81\u68d2\u6027\uff1b\u5728\u5355\u4e00\u4fdd\u6301\u533a\u7684\u4eff\u771f\u73af\u5883\u4e2d\u9a8c\u8bc1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u57fa\u4e8e DRL \u7684\u65b9\u6cd5\u5728\u5b9e\u73b0\u6307\u5411\u63a7\u5236\u76ee\u6807\u7684\u540c\u65f6\uff0c\u80fd\u6709\u6548\u6ee1\u8db3\u59ff\u6001\u7ea6\u675f\u3002", "conclusion": "\u5728\u5305\u542b\u5355\u4e00\u6307\u5411\u4fdd\u6301\u533a\u7684\u592a\u7a7a\u98de\u884c\u5668\u59ff\u6001\u63a7\u5236\u573a\u666f\u4e2d\uff0c\u57fa\u4e8e SAC \u7684 DRL \u65b9\u6cd5\uff0c\u7ed3\u5408\u7ea6\u675f\u611f\u77e5\u7684\u72b6\u6001\u8868\u793a\u4e0e\u8bfe\u7a0b\u5b66\u4e60\uff0c\u662f\u4e00\u79cd\u53ef\u884c\u4e14\u6709\u6548\u7684\u65e0\u6a21\u578b/\u4f4e\u4f9d\u8d56\u7684\u63a7\u5236\u7b56\u7565\u3002"}}
{"id": "2511.14480", "categories": ["cs.IT", "math.CO"], "pdf": "https://arxiv.org/pdf/2511.14480", "abs": "https://arxiv.org/abs/2511.14480", "authors": ["Ananda Chakraborty"], "title": "Monimial Matrix Analogue of Yoshida's theorem", "comment": null, "summary": "In this paper, we study variants of weight enumerators of linear codes over $\\mathbb{F}_q$. We generalize the concept of average complete joint weight enumerators of two linear codes over $\\mathbb{F}_q$. We also give its MacWilliams type identities. Then we establish a monomial analogue of Yoshida's theorem for this average complete joint weight enumerators. Finally, we present the generalized representation for average of $g$-fold complete joint weight enumerators for $\\mathbb{F}_q$-linear codes and establish a monomial matrix analogue of Yoshida's theorem for average $g$-fold complete joint weight enumerators.", "AI": {"tldr": "\u672c\u5de5\u4f5c\u5c06\u6709\u9650\u57df\u7ebf\u6027\u7801\u7684\u6743\u679a\u4e3e\u91cf\u6269\u5c55\u5230\u4e8c\u8005\u53cag\u91cd\u7684\u5e73\u5747\u5b8c\u6574\u8054\u5408\u6743\u679a\u4e3e\u91cf\uff0c\u7ed9\u51faMacWilliams\u578b\u6052\u7b49\u5f0f\uff0c\u5e76\u5728\u5355\u53d8\u91cf/\u5355\u77e9\u9635\u6846\u67b6\u4e0b\u83b7\u5f97Yoshida\u5b9a\u7406\u7684\u591a\u9879\u5f0f\u7b49\u4ef7\u4ee5\u53ca\u5bf9g\u91cd\u60c5\u5f62\u7684\u5e7f\u4e49\u8868\u793a\u3002", "motivation": "\u65e8\u5728\u5c06\u7ecf\u5178\u7684\u6743\u679a\u4e3e\u7406\u8bba\u6269\u5c55\u81f3\u8de8\u8d8a\u591a\u4e2a\u7ebf\u6027\u7801\u7684\u5e73\u5747\u8054\u5408\u5206\u5e03\uff0c\u7edf\u4e00\u5e76\u63a8\u5e7fMacWilliams\u578b\u6052\u7b49\u5f0f\u548cYoshida\u578b\u5b9a\u7406\uff0c\u4ee5\u4fbf\u5206\u6790\u591a\u4e2a\u7801\u4e4b\u95f4\u7684\u8054\u5408\u6743\u5206\u5e03\u3002", "method": "1) \u7ed9\u51fa\u4e8c\u4e2aF_q\u7ebf\u6027\u7801\u7684\u5e73\u5747\u5b8c\u6574\u8054\u5408\u6743\u679a\u4e3e\u91cf\u7684\u5b9a\u4e49\uff1b2) \u63a8\u5bfc\u5176MacWilliams\u578b\u6052\u7b49\u5f0f\uff1b3) \u5efa\u7acb\u8be5\u5e73\u5747\u91cf\u7684\u5355\u9879\u5f0f(Yoshida)\u5b9a\u7406\u4e4b\u540c\u6784\uff08monomial analogue\uff09\uff1b4) \u4e00\u822c\u5316\u5230\u5bf9\u4efb\u610f\u6574\u6570g\u7684\u5e73\u5747g\u91cd\u5b8c\u6574\u8054\u5408\u6743\u679a\u4e3e\u91cf\uff0c\u7ed9\u51fa\u5176\u5e7f\u4e49\u8868\u793a\u5e76\u7ed9\u51fa\u5355\u9879\u77e9\u9635 analogue\u7684Yoshida\u578b\u5b9a\u7406\u3002", "result": "\u83b7\u5f97\u4e8c\u7801\u53ca\u591a\u7801\u7684\u5e73\u5747\u5b8c\u6574\u8054\u5408\u6743\u679a\u4e3e\u91cf\u7684MacWilliams\u578b\u6052\u7b49\u5f0f\uff0c\u7ed9\u51fa\u5355\u9879\u5f0f_Yoshida_\u5b9a\u7406\u7684\u7b49\u4ef7\u5f62\u5f0f\uff0c\u5e76\u5bf9g\u91cd\u60c5\u5f62\u7ed9\u51fa\u5e7f\u4e49\u8868\u793a\u4e0e\u5355\u9879\u77e9\u9635\u7248\u672c\u7684Yoshida\u5b9a\u7406\u3002", "conclusion": "\u4e3a\u591a\u7801\u7684\u6743\u679a\u4e3e\u91cf\u63d0\u4f9b\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u7ecf\u5178MacWilliams\u4e0eYoshida\u5b9a\u7406\u5728\u5e73\u5747\u8054\u5408\u60c5\u5f62\u4e0b\u7684\u9002\u7528\u6027\uff0c\u5e76\u4e3a\u5206\u6790\u591a\u7801\u7684\u8054\u5408\u6743\u5206\u5e03\u63d0\u4f9b\u5de5\u5177\u3002"}}
{"id": "2511.13770", "categories": ["eess.SY", "cs.GT", "cs.MA", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.13770", "abs": "https://arxiv.org/abs/2511.13770", "authors": ["Jaehan Im", "Daniel Delahaye", "David Fridovich-Keil", "Ufuk Topcu"], "title": "Game-theoretic Decentralized Coordination for Airspace Sector Overload Mitigation", "comment": null, "summary": "Decentralized air traffic management systems offer a scalable alternative to centralized control, but often assume high levels of cooperation. In practice, such assumptions frequently break down since airspace sectors operate independently and prioritize local objectives. We address the problem of sector overload in decentralized air traffic management by proposing a mechanism that models self-interested behaviors based on best response dynamics. Each sector adjusts the departure times of flights under its control to reduce its own congestion, without any shared decision making. A tunable cooperativeness factor models the degree to which each sector is willing to reduce overload in other sectors. We prove that the proposed mechanism satisfies a potential game structure, ensuring that best response dynamics converge to a pure Nash equilibrium, under a mild restriction. In addition, we identify a sufficient condition under which an overload-free solution corresponds to a global minimizer of the potential function. Numerical experiments using 24 hours of European flight data demonstrate that the proposed algorithm substantially reduces overload even with only minimal cooperation between sectors, while maintaining scalability and matching the solution quality of centralized solvers.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6700\u4f73\u54cd\u5e94\u52a8\u6001\u7684\u53bb\u4e2d\u5fc3\u5316\u7a7a\u57df\u4ea4\u901a\u7ba1\u7406\u673a\u5236\uff0c\u5141\u8bb8\u5404\u533a\u57df\u72ec\u7acb\u8c03\u6574\u822a\u73ed\u8d77\u98de\u65f6\u95f4\u4ee5\u964d\u4f4e\u81ea\u8eab\u62e5\u5835\uff0c\u5e76\u5f15\u5165\u53ef\u8c03\u534f\u4f5c\u7cfb\u6570\u4ee5\u8861\u91cf\u5bf9\u5176\u4ed6\u533a\u57df\u7684\u8ba9\u6b65\u3002\u901a\u8fc7\u8bc1\u660e\u5b58\u5728\u6f5c\u5728\u535a\u5f08\u7ed3\u6784\uff0c\u6700\u4f73\u54cd\u5e94\u52a8\u4f5c\u4e3a\u6536\u655b\u5230\u7eaf\u7eb3\u4ec0\u5747\u8861\u63d0\u4f9b\u4e86\u5145\u5206\u6761\u4ef6\uff0c\u4e14\u5728\u7ed9\u5b9a\u6761\u4ef6\u4e0b\u8fc7\u8f7d\u4e3a\u96f6\u89e3\u53ef\u4f7f\u6f5c\u5728\u51fd\u6570\u8fbe\u5230\u5168\u5c40\u6700\u5c0f\u3002\u6570\u503c\u5b9e\u9a8c\u57fa\u4e8e\u6b27\u6d3224\u5c0f\u65f6\u822a\u73ed\u6570\u636e\u8868\u660e\uff0c\u5373\u4f7f\u534f\u4f5c\u6781\u4f4e\uff0c\u7b97\u6cd5\u4e5f\u80fd\u663e\u8457\u964d\u4f4e\u62e5\u5835\uff0c\u4e14\u5177\u53ef\u6269\u5c55\u6027\u4e14\u4e0e\u96c6\u4e2d\u6c42\u89e3\u5668\u7684\u89e3\u8d28\u91cf\u76f8\u5f53\u3002", "motivation": "\u5728\u53bb\u4e2d\u5fc3\u5316\u7684\u7a7a\u57df\u4ea4\u901a\u7ba1\u7406\u4e2d\uff0c\u73b0\u5b9e\u5e38\u6001\u4e0b\u5404\u533a\u57df\u72ec\u7acb\u4f18\u5316\u3001\u7f3a\u4e4f\u5145\u5206\u534f\u4f5c\u4f1a\u5bfc\u81f4\u7cfb\u7edf\u6574\u4f53\u62e5\u5835\u4e0e\u6027\u80fd\u4e0b\u964d\u3002\u672c\u7814\u7a76\u5bfb\u6c42\u5728\u81ea\u5229\u884c\u4e3a\u9a71\u52a8\u7684\u524d\u63d0\u4e0b\uff0c\u4ecd\u53ef\u5b9e\u73b0\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u63d0\u5347\u3002", "method": "\u5efa\u7acb\u4ee5\u6700\u4f73\u54cd\u5e94\u4e3a\u57fa\u7840\u7684\u81ea\u5229\u884c\u4e3a\u6a21\u578b\uff0c\u52a0\u5165\u4e00\u4e2a\u53ef\u8c03\u7684\u534f\u4f5c\u7cfb\u6570\u6765\u63cf\u8ff0\u5404\u533a\u57df\u5728\u964d\u4f4e\u81ea\u8eab\u62e5\u5835\u7684\u540c\u65f6\u5bf9\u5176\u4ed6\u533a\u57df\u7684\u8ba9\u6b65\u7a0b\u5ea6\uff1b\u8bc1\u660e\u8be5\u673a\u5236\u5177\u5907\u6f5c\u5728\u535a\u5f08\u7ed3\u6784\uff0c\u6700\u4f73\u54cd\u5e94\u8fed\u4ee3\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u6536\u655b\u5230\u7eaf\u7eb3\u4ec0\u5747\u8861\uff1b\u7ed9\u51fa\u4e00\u4e2a\u5145\u5206\u6761\u4ef6\uff0c\u786e\u4fdd\u4e0d\u5b58\u5728\u8fc7\u8f7d\u65f6\u7684\u89e3\u540c\u65f6\u662f\u6f5c\u5728\u51fd\u6570\u7684\u5168\u5c40\u6700\u5c0f\u70b9\u3002\u901a\u8fc7\u5bf9\u6b27\u6d32\u822a\u73ed\u6570\u636e\u7684\u6570\u503c\u5b9e\u9a8c\u8bc4\u4f30\u7b97\u6cd5\u5728\u6700\u5c0f\u534f\u4f5c\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u4ec5\u6709\u6709\u9650\u7a0b\u5ea6\u7684\u8de8\u533a\u57df\u5408\u4f5c\uff0c\u6240\u63d0\u7b97\u6cd5\u4e5f\u80fd\u663e\u8457\u964d\u4f4e\u533a\u57df\u62e5\u5835\uff0c\u5e76\u4fdd\u6301\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\uff1b\u5176\u89e3\u8d28\u91cf\u4e0e\u96c6\u4e2d\u6c42\u89e3\u5668\u76f8\u5f53\uff0c\u63a5\u8fd1\u6700\u4f18\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8bc1\u660e\u4e86\u5728\u53bb\u4e2d\u5fc3\u5316\u7684\u7a7a\u57df\u4ea4\u901a\u7ba1\u7406\u6846\u67b6\u5185\uff0c\u57fa\u4e8e\u81ea\u5229\u884c\u4e3a\u7684\u6700\u4f73\u54cd\u5e94\u673a\u5236\u4ecd\u53ef\u5b9e\u73b0\u63a5\u8fd1\u5168\u5c40\u6700\u4f18\u7684\u7cfb\u7edf\u6027\u80fd\uff0c\u4e14\u901a\u8fc7\u6f5c\u5728\u535a\u5f08\u7ed3\u6784\u786e\u4fdd\u6536\u655b\u6027\uff0c\u4e3a\u8bbe\u8ba1\u5177\u5907\u5c40\u90e8\u81ea\u6cbb\u4e0e\u5168\u5c40\u6027\u80fd\u6298\u4e2d\u673a\u5236\u7684\u7a7a\u57df\u7ba1\u7406\u63d0\u4f9b\u7406\u8bba\u4e0e\u5b9e\u8bc1\u652f\u6301\u3002"}}
{"id": "2511.14457", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.14457", "abs": "https://arxiv.org/abs/2511.14457", "authors": ["Michael Gundall", "Jan Herbst", "Robin M\u00fcller", "Hans D. Schotten"], "title": "Benchmarking OpenWiFiSync on ESP32: Towards Cost-Effective Wireless Time Synchronization", "comment": null, "summary": "Wireless time synchronization of mobile devices is a key enabler for numerous Industry 4.0 applications, such as coordinated and synchronized tasks or the generation of high-precision timestamps for machine learning or artificial intelligence algorithms. Traditional wireline clock synchronization protocols, however, cannot achieve the performance in wireless environments without significant modifications. To address this challenge, we make use of the Reference Broadcast Infrastructure Synchronization protocol, which leverages the broadcast nature of wireless communications and remains both non-invasive and standard-compliant. We implement and validate this protocol on a low-cost testbed using ESP32 modules and a commercial Wi-Fi access point. To support further research and development, we release our implementation as open-source software under the GNU General Public License Version 3 license via the OpenWifiSync project on GitHub.\n  Our results demonstrate that synchronization accuracies within +/-30 microseconds are achievable using energy-efficient and affordable hardware, making this approach suitable for a wide range of use cases.", "AI": {"tldr": "\u901a\u8fc7\u53c2\u8003\u5e7f\u64ad\u57fa\u7840\u8bbe\u65bd\u540c\u6b65\uff08RBIS\uff09\u5728\u65e0\u7ebf\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u65f6\u95f4\u540c\u6b65\uff0c\u5b9e\u73b0\u4e86 +/-30 \u5fae\u79d2\u7684\u540c\u6b65\u7cbe\u5ea6\uff0c\u4f7f\u7528\u4f4e\u6210\u672c\u786c\u4ef6\uff08ESP32\uff09\u4e0e\u5546\u4e1a Wi-Fi \u63a5\u5165\u70b9\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5e76\u4ee5 OpenWifiSync \u9879\u76ee\u4ee5 GPLv3 \u8bb8\u53ef\u8bc1\u5f00\u6e90\u3002", "motivation": "\u89e3\u51b3\u65e0\u7ebf\u73af\u5883\u4e2d\u4f20\u7edf\u6709\u7ebf\u65f6\u949f\u540c\u6b65\u534f\u8bae\u5728\u6027\u80fd\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u6ee1\u8db3\u5de5\u4e1a4.0\u5bf9\u534f\u8c03\u4efb\u52a1\u4e0e\u9ad8\u7cbe\u5ea6\u65f6\u95f4\u6233\u7684\u9700\u6c42\uff0c\u540c\u65f6\u5229\u7528\u65e0\u7ebf\u901a\u4fe1\u7684\u5e7f\u64ad\u7279\u6027\u5b9e\u73b0\u975e\u4fb5\u5165\u5f0f\u3001\u6807\u51c6\u517c\u5bb9\u7684\u540c\u6b65\u3002", "method": "\u91c7\u7528 RBIS \u534f\u8bae\uff0c\u57fa\u4e8e\u65e0\u7ebf\u5e7f\u64ad\u7684\u7279\u6027\u8fdb\u884c\u65f6\u95f4\u540c\u6b65\u3002\u4f7f\u7528\u4f4e\u6210\u672c\u6d4b\u8bd5\u53f0\uff08ESP32 \u6a21\u5757\uff09\u548c\u5546\u7528 Wi-Fi \u8bbf\u95ee\u70b9\u8fdb\u884c\u5b9e\u73b0\u4e0e\u9a8c\u8bc1\uff0c\u5e76\u5c06\u5b9e\u73b0\u5f00\u6e90\u53d1\u5e03\uff08GNU GPLv3\uff0cOpenWifiSync\uff0cGitHub\uff09\u3002", "result": "\u5728\u80fd\u8017\u53cb\u597d\u4e14\u6210\u672c\u8f83\u4f4e\u7684\u786c\u4ef6\u4e0a\u5b9e\u73b0\u4e86 +/-30 \u5fae\u79d2\u7684\u540c\u6b65\u7cbe\u5ea6\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\u3002", "conclusion": "RBIS + \u5f00\u6e90\u5b9e\u73b0\u4e3a\u65e0\u7ebf\u65f6\u95f4\u540c\u6b65\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u3001\u6613\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6ee1\u8db3\u5de5\u4e1a4.0 \u7684\u591a\u6837\u5316\u65f6\u5e8f\u9700\u6c42\u3002"}}
{"id": "2511.13729", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13729", "abs": "https://arxiv.org/abs/2511.13729", "authors": ["Huseyin Goksu"], "title": "DualLaguerreNet: A Decoupled Spectral Filter GNN and the Uncovering of the Flexibility-Stability Trade-off", "comment": null, "summary": "Graph Neural Networks (GNNs) based on spectral filters, such as the Adaptive Orthogonal Polynomial Filter (AOPF) class (e.g., LaguerreNet), have shown promise in unifying the solutions for heterophily and over-smoothing. However, these single-filter models suffer from a \"compromise\" problem, as their single adaptive parameter (e.g., alpha) must learn a suboptimal, averaged response across the entire graph spectrum. In this paper, we propose DualLaguerreNet, a novel GNN architecture that solves this by introducing \"Decoupled Spectral Flexibility.\" DualLaguerreNet splits the graph Laplacian into two operators, L_low (low-frequency) and L_high (high-frequency), and learns two independent, adaptive Laguerre polynomial filters, parameterized by alpha_1 and alpha_2, respectively. This work, however, uncovers a deeper finding. While our experiments show DualLaguerreNet's flexibility allows it to achieve state-of-the-art results on complex heterophilic tasks (outperforming LaguerreNet), it simultaneously underperforms on simpler, homophilic tasks. We identify this as a fundamental \"Flexibility-Stability Trade-off\". The increased parameterization (2x filter parameters and 2x model parameters) leads to overfitting on simple tasks, demonstrating that the \"compromise\" of simpler models acts as a crucial regularizer. This paper presents a new SOTA architecture for heterophily while providing a critical analysis of the bias-variance trade-off inherent in adaptive GNN filter design.", "AI": {"tldr": "DualLaguerreNet decouples spectral filters into low/high frequency components, enabling two independent adaptive Laguerre filters, improving heterophily performance but risking overfitting on homophily due to a flexibility-stability trade-off.", "motivation": "Tackle the compromise of single adaptive spectral filters that average responses across the graph spectrum, aiming to better handle heterophily and over-smoothing while understanding the bias-variance implications.", "method": "Split the graph Laplacian into L_low and L_high, learn two separate adaptive Laguerre polynomial filters with parameters alpha_1 and alpha_2, effectively doubling filter and model parameters.", "result": "Achieves state-of-the-art results on complex heterophilic tasks (outperforming LaguerreNet) but underperforms on simple homophilic tasks, indicating overfitting and a flexibility-stability trade-off.", "conclusion": "Proposes a heterophily-focused SOTA architecture while highlighting the inherent bias-variance trade-off in adaptive GNN filter design; simpler models may act as a useful regularizer for homophily tasks."}}
{"id": "2511.14524", "categories": ["cs.IT", "cs.CR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.14524", "abs": "https://arxiv.org/abs/2511.14524", "authors": ["Venkat Chandar", "Aslan Tchamkerten", "Shashank Vatedka"], "title": "Compression with Privacy-Preserving Random Access", "comment": null, "summary": "It is shown that an i.i.d. binary source sequence $X_1, \\ldots, X_n$ can be losslessly compressed at any rate above entropy such that the individual decoding of any $X_i$ reveals \\emph{no} information about the other bits $\\{X_j : j \\neq i\\}$.", "AI": {"tldr": "\u5b58\u5728\u4e00\u79cd\u65e0\u635f\u538b\u7f29\u65b9\u6848\uff0c\u5728\u7801\u7387\u7565\u9ad8\u4e8e\u6e90\u71b5\u65f6\uff0c\u53ef\u4ee5\u5bf9\u4efb\u610f Xi \u8fdb\u884c\u5355\u72ec\u89e3\u7801\u800c\u4e0d\u6cc4\u9732\u5176\u4ed6\u4f4d\u7684\u4fe1\u606f\u3002", "motivation": "\u7814\u7a76\u65e0\u635f\u538b\u7f29\u4e0e\u9010\u4f4d\u9690\u79c1\u7684\u517c\u5bb9\u6027\u53ca\u6781\u9650\uff0c\u6ee1\u8db3\u5728\u4e0d\u589e\u52a0\u5916\u90e8\u5bc6\u94a5\u7684\u524d\u63d0\u4e0b\u5bf9\u5355\u6bd4\u7279\u7684\u4fe1\u606f\u6cc4\u9732\u6700\u5c0f\u5316\u3002", "method": "\u901a\u8fc7\u968f\u673a\u5206\u7bb1/\u968f\u673a\u7f16\u7801\u3001\u5178\u578b\u6027\u3001\u72ec\u7acb\u6027\u7ea6\u675f\u7b49\u4fe1\u606f\u8bba\u6280\u672f\uff0c\u6784\u9020\u7801\u5b57\u5e76\u8bc1\u660e\u5b58\u5728\u6ee1\u8db3 I(X_{-i}; Xi decoded) = 0 \u7684\u65b9\u6848\uff0c\u5728 r > H(X) \u65f6\u53ef\u5b9e\u73b0\u3002", "result": "\u8bc1\u660e\u5b58\u5728\u8fd9\u6837\u7684\u7f16\u7801\uff0c\u968f\u7740\u6837\u672c\u91cf\u8d8b\u8fd1\u65e0\u7a77\u5927\uff0c\u9010\u4f4d\u9690\u79c1\u5c5e\u6027\u6210\u7acb\uff1b\u65e0\u635f\u6027\u548c\u9690\u79c1\u6027\u5e76\u5b58\u3002", "conclusion": "\u8be5\u7ed3\u679c\u63ed\u793a\u65e0\u635f\u538b\u7f29\u4e0e\u9010\u4f4d\u9690\u79c1\u4e4b\u95f4\u7684\u517c\u5bb9\u6027\uff0c\u5e76\u4e3a\u9690\u79c1\u4fdd\u62a4\u7684\u65e0\u635f\u6570\u636e\u4f20\u8f93\u548c\u5206\u5e03\u5f0f\u7f16\u7801\u4e2d\u7684\u4fe1\u606f\u6cc4\u6f0f\u63a7\u5236\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\uff1b\u4f46\u5b9e\u9645\u5b9e\u73b0\u4e0e\u6269\u5c55\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2511.13785", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13785", "abs": "https://arxiv.org/abs/2511.13785", "authors": ["Federico Taschin", "Ozan K. Tonguz"], "title": "Quantifying Distribution Shift in Traffic Signal Control with Histogram-Based GEH Distance", "comment": null, "summary": "Traffic signal control algorithms are vulnerable to distribution shift, where performance degrades under traffic conditions that differ from those seen during design or training. This paper introduces a principled approach to quantify distribution shift by representing traffic scenarios as demand histograms and comparing them with a GEH-based distance function. The method is policy-independent, interpretable, and leverages a widely used traffic engineering statistic. We validate the approach on 20 simulated scenarios using both a NEMA actuated controller and a reinforcement learning controller (FRAP++). Results show that larger scenario distances consistently correspond to increased travel time and reduced throughput, with particularly strong explanatory power for learning-based control. Overall, this method can predict performance degradation under distribution shift better than previously published techniques. These findings highlight the utility of the proposed framework for benchmarking, training regime design, and monitoring in adaptive traffic signal control.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4ee5\u9700\u6c42\u76f4\u65b9\u56fe\u4e0eGEH\u8ddd\u79bb\u8861\u91cf\u5206\u5e03\u504f\u79fb\u7684\u65e0\u7b56\u7565\u4f9d\u8d56\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u9884\u6d4b\u5206\u5e03\u504f\u79fb\u5bf9\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u5bf9\u5b66\u4e60\u578b\u63a7\u5236\u5177\u6709\u663e\u8457\u89e3\u91ca\u529b\u3002", "motivation": "\u5206\u5e03\u504f\u79fb\u4f1a\u5bfc\u81f4\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u4e00\u79cd\u53ef\u89e3\u91ca\u3001\u4e0e\u4ea4\u901a\u5de5\u7a0b\u7edf\u8ba1\u91cf\u517c\u5bb9\u7684\u91cf\u5316\u65b9\u6cd5\u6765\u9884\u6d4b\u5e76\u76d1\u63a7\u8fd9\u79cd\u4e0b\u964d\u3002", "method": "\u5c06\u4ea4\u901a\u573a\u666f\u8868\u793a\u4e3a\u9700\u6c42\u76f4\u65b9\u56fe\uff0c\u4f7f\u7528GEH\u8ddd\u79bb\u91cf\u5316\u5206\u5e03\u5dee\u5f02\uff0c\u65b9\u6cd5\u72ec\u7acb\u4e8e\u63a7\u5236\u7b56\u7565\uff0c\u6613\u4e8e\u89e3\u91ca\u3002", "result": "\u572820\u4e2a\u4eff\u771f\u573a\u666f\u4e2d\uff0c\u4f7f\u7528NEMA\u7535\u63a7\u4e0eFRAP++\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\u8fdb\u884c\u8bc4\u4f30\u3002\u573a\u666f\u8ddd\u79bb\u8d8a\u5927\uff0c\u4e0e\u65c5\u884c\u65f6\u95f4\u589e\u52a0\u3001\u541e\u5410\u91cf\u4e0b\u964d\u76f8\u5173\uff0c\u4e14\u5bf9\u5b66\u4e60\u578b\u63a7\u5236\u5177\u6709\u66f4\u5f3a\u7684\u89e3\u91ca\u529b\uff1b\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u5206\u5e03\u504f\u79fb\u5f15\u53d1\u7684\u6027\u80fd\u4e0b\u964d\u65b9\u9762\u4f18\u4e8e\u5148\u524d\u6280\u672f\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u7528\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u3001\u8bad\u7ec3 regime \u8bbe\u8ba1\u4e0e\u81ea\u9002\u5e94\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u7684\u76d1\u63a7\uff0c\u5e2e\u52a9\u5728\u5206\u5e03\u504f\u79fb\u6761\u4ef6\u4e0b\u66f4\u597d\u5730\u9884\u6d4b\u4e0e\u7f13\u89e3\u6027\u80fd\u4e0b\u964d\u3002"}}
{"id": "2511.13741", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13741", "abs": "https://arxiv.org/abs/2511.13741", "authors": ["Silin Zhou", "Yao Chen", "Shuo Shang", "Lisi Chen", "Bingsheng He", "Ryosuke Shibasaki"], "title": "Blurred Encoding for Trajectory Representation Learning", "comment": "This paper is accepted by KDD2025(Feb. Cycle)", "summary": "Trajectory representation learning (TRL) maps trajectories to vector embeddings and facilitates tasks such as trajectory classification and similarity search. State-of-the-art (SOTA) TRL methods transform raw GPS trajectories to grid or road trajectories to capture high-level travel semantics, i.e., regions and roads. However, they lose fine-grained spatial-temporal details as multiple GPS points are grouped into a single grid cell or road segment. To tackle this problem, we propose the BLUrred Encoding method, dubbed BLUE, which gradually reduces the precision of GPS coordinates to create hierarchical patches with multiple levels. The low-level patches are small and preserve fine-grained spatial-temporal details, while the high-level patches are large and capture overall travel patterns. To complement different patch levels with each other, our BLUE is an encoder-decoder model with a pyramid structure. At each patch level, a Transformer is used to learn the trajectory embedding at the current level, while pooling prepares inputs for the higher level in the encoder, and up-resolution provides guidance for the lower level in the decoder. BLUE is trained using the trajectory reconstruction task with the MSE loss. We compare BLUE with 8 SOTA TRL methods for 3 downstream tasks, the results show that BLUE consistently achieves higher accuracy than all baselines, outperforming the best-performing baselines by an average of 30.90%. Our code is available at https://github.com/slzhou-xy/BLUE.", "AI": {"tldr": "BLUE \u5c06 GPS \u5750\u6807\u901a\u8fc7\u9010\u6b65\u964d\u4f4e\u7cbe\u5ea6\u5f62\u6210\u591a\u5c42\u5206\u5c42\u8865\u4e01\uff0c\u5728\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7684\u91d1\u5b57\u5854\u7ed3\u6784\u4e2d\u7528 Transformer \u5b66\u4e60\u4e0d\u540c\u5c42\u7684\u8f68\u8ff9\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7\u91cd\u6784\u4efb\u52a1\u8fdb\u884c\u81ea\u76d1\u7763\u8bad\u7ec3\uff0c\u4ece\u800c\u5728\u591a\u9879\u4e0b\u6e38\u4efb\u52a1\u4e0a\u8d85\u8d8a SOTA\u3002", "motivation": "\u73b0\u6709\u7684 SOTA TRL \u65b9\u6cd5\u5c06\u8f68\u8ff9\u7b80\u5316\u4e3a\u7f51\u683c\u6216\u9053\u8def\u6bb5\uff0c\u4e22\u5931\u7ec6\u7c92\u5ea6\u7684\u65f6\u7a7a\u4fe1\u606f\uff0c\u8feb\u5207\u9700\u8981\u5728\u4e0d\u540c\u7c92\u5ea6\u95f4\u6709\u6548\u878d\u5408\u5e76\u4fdd\u6301\u7ec6\u7c92\u5ea6\u4fe1\u606f\u4ee5\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u3002", "method": "\u5f15\u5165 BLUE\uff08BLUrred Encoding\uff09\u3002\u901a\u8fc7\u9010\u6b65\u964d\u4f4e GPS \u5750\u6807\u7cbe\u5ea6\u751f\u6210\u591a\u5c42\u5206\u5c42\u8865\u4e01\uff1b\u5728\u6bcf\u4e2a\u8865\u4e01\u5c42\u4f7f\u7528 Transformer \u5b66\u4e60\u5f53\u524d\u5c42\u7684\u8f68\u8ff9\u5d4c\u5165\u3002\u7f16\u7801\u5668\u901a\u8fc7\u6c60\u5316\u5c06\u4fe1\u606f\u4e0a\u91c7\u6837\u81f3\u9ad8\u5c42\uff0c\u89e3\u7801\u5668\u901a\u8fc7\u4e0a\u91c7\u6837\u5411\u4f4e\u5c42\u63d0\u4f9b\u6307\u5bfc\u3002\u6574\u4e2a\u6a21\u578b\u4ee5\u8f68\u8ff9\u91cd\u6784\u4e3a\u76ee\u6807\uff0c\u4f7f\u7528 MSE \u635f\u5931\u8fdb\u884c\u8bad\u7ec3\uff0c\u4e14\u5177\u5907 Pyramid \u7ed3\u6784\u4ee5\u5b9e\u73b0\u591a\u5c42\u534f\u540c\u5b66\u4e60\u3002", "result": "\u5728\u5bf9\u6bd4\u7684 3 \u9879\u4e0b\u6e38\u4efb\u52a1\u4e2d\uff0cBLUE \u76f8\u5bf9\u4e8e 8 \u79cd SOTA TRL \u65b9\u6cd5\u5747\u8868\u73b0\u66f4\u597d\uff0c\u5e73\u5747\u9886\u5148\u7ea6 30.90%\u3002\u4ee3\u7801\u53ef\u516c\u5f00\u83b7\u53d6\u3002", "conclusion": "BLUE \u901a\u8fc7\u5728\u4e0d\u540c\u7c92\u5ea6\u7684\u5206\u5c42\u8865\u4e01\u4e4b\u95f4\u8fdb\u884c\u534f\u540c\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u540c\u65f6\u4fdd\u7559\u7ec6\u7c92\u5ea6\u7ec6\u8282\u4e0e\u6355\u6349\u5168\u5c40\u6a21\u5f0f\u7684\u8f68\u8ff9\u8868\u793a\uff0c\u63d0\u5347\u4e86\u591a\u4efb\u52a1\u4e0b\u7684\u6027\u80fd\u3002"}}
{"id": "2511.13771", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13771", "abs": "https://arxiv.org/abs/2511.13771", "authors": ["Shaowei Guan", "Yu Zhai", "Zhengyu Zhang", "Yanze Wang", "Hin Chi Kwok"], "title": "ExplainableGuard: Interpretable Adversarial Defense for Large Language Models Using Chain-of-Thought Reasoning", "comment": "9 pages, 2 figures", "summary": "Large Language Models (LLMs) are increasingly vulnerable to adversarial attacks that can subtly manipulate their outputs. While various defense mechanisms have been proposed, many operate as black boxes, lacking transparency in their decision-making. This paper introduces ExplainableGuard, an interpretable adversarial defense framework leveraging the chain-of-thought (CoT) reasoning capabilities of DeepSeek-Reasoner. Our approach not only detects and neutralizes adversarial perturbations in text but also provides step-by-step explanations for each defense action. We demonstrate how tailored CoT prompts guide the LLM to perform a multi-faceted analysis (character, word, structural, and semantic) and generate a purified output along with a human-readable justification. Preliminary results on the GLUE Benchmark and IMDB Movie Reviews dataset show promising defense efficacy. Additionally, a human evaluation study reveals that ExplainableGuard's explanations outperform ablated variants in clarity, specificity, and actionability, with a 72.5% deployability-trust rating, underscoring its potential for more trustworthy LLM deployments.", "AI": {"tldr": "\u63d0\u51fa ExplainableGuard\uff0c\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u5bf9\u6297\u6027\u9632\u5fa1\u6846\u67b6\uff0c\u5229\u7528\u8fde\u9501\u63a8\u7406(CoT)\u6765\u68c0\u6d4b\u3001\u6d88\u9664\u6587\u672c\u6270\u52a8\u5e76\u7ed9\u51fa\u9010\u6b65\u89e3\u91ca\uff1b\u521d\u6b65\u5728 GLUE \u4e0e IMDB \u6570\u636e\u96c6\u663e\u793a\u6709\u6548\u6027\uff0c\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u89e3\u91ca\u66f4\u6e05\u6670\u3001\u5177\u4f53\u3001\u53ef\u6267\u884c\uff0c.deployability-trust \u4e3a 72.5%\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u65e5\u76ca\u8106\u5f31\uff0c\u73b0\u6709\u9632\u5fa1\u591a\u6570\u4e3a\u9ed1\u7bb1\uff0c\u7f3a\u4e4f\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u53ef\u89e3\u91ca\u7684\u9632\u5fa1\u673a\u5236\u6765\u63d0\u5347\u4fe1\u4efb\u3002", "method": "\u901a\u8fc7\u5b9a\u5236\u7684\u8fde\u9501\u63a8\u7406(CoT)\u63d0\u793a\uff0c\u5229\u7528 DeepSeek-Reasoner \u8fdb\u884c\u591a\u7ef4\u5206\u6790\uff08\u5b57\u7b26\u3001\u8bcd\u3001\u7ed3\u6784\u3001\u8bed\u4e49\uff09\uff0c\u5728\u7ed9\u51fa\u51c0\u5316\u540e\u8f93\u51fa\u7684\u540c\u65f6\u63d0\u4f9b\u4eba\u7c7b\u53ef\u8bfb\u7684\u9632\u5fa1\u7406\u7531\u3002", "result": "\u5728 GLUE \u57fa\u51c6\u548c IMDB \u5f71\u8bc4\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u6709\u5e0c\u671b\u7684\u9632\u5fa1\u6548\u679c\uff1b\u5e76\u4e14\u4eba\u7c7b\u8bc4\u4f30\u8868\u660e ExplainableGuard \u7684\u89e3\u91ca\u5728\u6e05\u6670\u5ea6\u3001\u5177\u4f53\u6027\u548c\u53ef\u64cd\u4f5c\u6027\u65b9\u9762\u4f18\u4e8e\u5220\u9664\u5f0f\u5bf9\u6bd4\uff0c\u5177\u5907 72.5% \u7684\u53ef\u90e8\u7f72\u6027\u4fe1\u4efb\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u4e00\u79cd\u66f4\u53ef\u4fe1\u7684 LLM \u90e8\u7f72\u8def\u5f84\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u5bf9\u6297\u9632\u5fa1\u63d0\u5347\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u5ea6\uff0c\u5efa\u8bae\u8fdb\u4e00\u6b65\u6269\u5c55\u8bc4\u4f30\u4e0e\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2511.13730", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13730", "abs": "https://arxiv.org/abs/2511.13730", "authors": ["Huseyin Goksu"], "title": "GegenbauerNet: Finding the Optimal Compromise in the GNN Flexibility-Stability Trade-off", "comment": null, "summary": "Spectral Graph Neural Networks (GNNs) operating in the canonical [-1, 1] domain (like ChebyNet and its adaptive generalization, L-JacobiNet) face a fundamental Flexibility-Stability Trade-off. Our previous work revealed a critical puzzle: the 2-parameter adaptive L-JacobiNet often suffered from high variance and was surprisingly outperformed by the 0-parameter, stabilized-static S-JacobiNet. This suggested that stabilization was more critical than adaptation in this domain. In this paper, we propose \\textbf{GegenbauerNet}, a novel GNN filter based on the Gegenbauer polynomials, to find the Optimal Compromise in this trade-off. By enforcing symmetry (alpha=beta) but allowing a single shape parameter (lambda) to be learned, GegenbauerNet limits flexibility (variance) while escaping the fixed bias of S-JacobiNet. We demonstrate that GegenbauerNet (1-parameter) achieves superior performance in the key local filtering regime (K=2 on heterophilic graphs) where overfitting is minimal, validating the hypothesis that a controlled, symmetric degree of freedom is optimal. Furthermore, our comprehensive K-ablation study across homophilic and heterophilic graphs, using 7 diverse datasets, clarifies the domain's behavior: the fully adaptive L-JacobiNet maintains the highest performance on high-K filtering tasks, showing the value of maximum flexibility when regularization is managed. This study provides crucial design principles for GNN developers, showing that in the [-1, 1] spectral domain, the optimal filter depends critically on the target locality (K) and the acceptable level of design bias.", "AI": {"tldr": "GegenbauerNet\u5728[-1,1]\u57df\u4e2d\u63d0\u51fa\u4e00\u9636\u5bf9\u79f0\u3001\u5355\u53c2\u91cf\u7684Gegenbauer\u6ee4\u6ce2\u5668\u4ee5\u5728\u7075\u6d3b\u6027\u4e0e\u7a33\u5b9a\u6027\u4e4b\u95f4\u53d6\u5f97\u6298\u4e2d\uff1b\u5728K=2\u7684\u5c40\u90e8\u6ee4\u6ce2\u548c\u5f02\u8d28\u6027\u56fe\u4e0a\u8868\u73b0\u4f18\u4e8e0/2\u53c2\u6570\u6a21\u578b\uff0c\u8868\u660e\u53d7\u63a7\u7684\u5bf9\u79f0\u81ea\u7531\u5ea6\u5728\u67d0\u4e9b\u573a\u666f\u6700\u4f18\u3002", "motivation": "\u89e3\u51b3\u5728[-1,1]\u8c31\u57df\u4e0b\u7684\u7075\u6d3b\u6027-\u7a33\u5b9a\u6027\u6743\u8861\u95ee\u9898\u3002\u524d\u5e8f\u5de5\u4f5c\u8868\u660e2\u53c2\u6570\u7684\u81ea\u9002\u5e94L-JacobiNet\u6613\u4ea7\u751f\u9ad8\u65b9\u5dee\uff0c\u5728\u67d0\u4e9b\u573a\u666f\u751a\u81f3\u52a3\u4e8e0\u53c2\u6570\u3001\u7a33\u5b9a\u7684S-JacobiNet\uff0c\u9700\u5bfb\u627e\u5408\u9002\u7684\u6298\u4e2d\u7b56\u7565\u3002", "method": "\u63d0\u51faGegenbauerNet\uff0c\u5229\u7528Gegenbauer\u591a\u9879\u5f0f\u6784\u9020\u6ee4\u6ce2\u5668\uff0c\u5f3a\u5236\u5bf9\u79f0\uff08alpha=beta\uff09\uff0c\u4ec5\u5b66\u4e60\u4e00\u4e2a\u5f62\u72b6\u53c2\u6570lambda\uff0c\u4ece\u800c\u9650\u5236\u7075\u6d3b\u6027\u4ee5\u964d\u4f4e\u65b9\u5dee\uff0c\u540c\u65f6\u907f\u514d\u5b8c\u5168\u56fa\u5b9a\u7684S-JacobiNet\u504f\u7f6e\u3002\u901a\u8fc7K=2\u7684\u5c40\u90e8\u6ee4\u6ce2\u3001\u5f02\u8d28\u6027\u56fe\u7684\u5b9e\u9a8c\uff0c\u4ee5\u53ca\u8de87\u4e2a\u6570\u636e\u96c6\u7684K\u6d88\u878d\u7814\u7a76\uff0c\u6bd4\u8f83\u5168\u81ea\u9002\u5e94L-JacobiNet\u4e0e\u5176\u4ed6\u57fa\u7ebf\u3002", "result": "\u5728\u5173\u952e\u5c40\u90e8\u6ee4\u6ce2\u573a\u666f\uff08K=2\uff09\u548c\u5f02\u8d28\u6027\u56fe\u4e0a\uff0c1\u53c2\u6570\u7684GegenbauerNet\u5b9e\u73b0\u4e86\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u7684\u6027\u80fd\uff0c\u8868\u660e\u53d7\u63a7\u7684\u5bf9\u79f0\u81ea\u7531\u5ea6\u5728\u8be5\u533a\u57df\u66f4\u6709\u5229\uff1b\u800c\u5728\u9ad8K\u6ee4\u6ce2\u4efb\u52a1\u4e2d\uff0c\u5b8c\u5168\u81ea\u9002\u5e94\u7684L-JacobiNet\u4ecd\u5448\u73b0\u6700\u9ad8\u6027\u80fd\uff0c\u4f53\u73b0\u6700\u5927\u7075\u6d3b\u6027\u5728\u53ef\u63a7\u6b63\u5219\u5316\u4e0b\u7684\u4ef7\u503c\u3002", "conclusion": "\u5728[-1,1]\u8c31\u57df\u4e2d\uff0c\u6700\u4f18\u6ee4\u6ce2\u5668\u9700\u4f9d\u636e\u76ee\u6807\u5c40\u90e8\u6027K\u53ca\u53ef\u63a5\u53d7\u7684\u8bbe\u8ba1\u504f\u7f6e\u6765\u9009\u62e9\u3002GegenbauerNet\u63d0\u4f9b\u7684\u8bbe\u8ba1\u539f\u5219\u662f\uff1a\u5bf9\u79f0\u6027\u7ea6\u675f\u4e0e\u5355\u81ea\u7531\u5ea6\u7684\u6298\u4e2d\uff0c\u5728\u4f4e\u81f3\u4e2d\u7b49K\u7684\u573a\u666f\u4e0b\u5f80\u5f80\u4f18\u4e8e\u9ad8\u5ea6\u81ea\u9002\u5e94\u7684\u65b9\u6848\uff1b\u800c\u9ad8K\u573a\u666f\u5219\u53ef\u80fd\u9700\u8981\u66f4\u9ad8\u7684\u7075\u6d3b\u6027\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002"}}
{"id": "2511.14051", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.14051", "abs": "https://arxiv.org/abs/2511.14051", "authors": ["Xiang Chen", "Ming-Min Zhao", "An Liu", "Min Li", "Qingjiang Shi", "Min-Jian Zhao"], "title": "Cross-Sparsity-Enabled Multipath Perception via Structured Bayesian Inference for Multi-Target Estimation", "comment": "13 pages, 9 figures", "summary": "In this paper, we investigate a multi-target sensing system in multipath environment, where inter-target scattering gives rise to first-order reflected paths whose angles of departure (AoDs) and angles of arrival (AoAs) coincide with the direct-path angles of different targets. Unlike other multipath components, these first-order paths carry structural information that can be exploited as additional prior knowledge for target direction estimation. To exploit this property, we construct a sparse representation of the multi-target sensing channel and propose a novel cross sparsity structure under a three-layer hierarchical structured (3LHS) prior model, which leverages the first-order paths to enhance the prior probability of the direct paths and thereby improve the estimation accuracy. Building on this model, we propose a structured fast turbo variational Bayesian inference (SF-TVBI) algorithm, which integrates an efficient message-passing strategy to enable tractable probabilistic exchange within the cross sparsity, and a two-timescale update scheme to reduce the update frequency of the high-dimensional sparse vector. Simulation results demonstrate that leveraging the proposed cross sparsity structure is able to improve the target angle estimation accuracy substantially, and the SF-TVBI algorithm achieves estimation performance comparable to that of the Turbo-VBI, but with lower computational complexity.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u5c42\u5c42\u6b21\u7ed3\u6784\u7684\u8de8\u7a00\u758f\u5148\u9a8c\uff083LHS\uff09\u5e76\u7ed3\u5408\u7ed3\u6784\u5316\u5feb\u901f\u6da1\u8f6e\u53d8\u5206\u8d1d\u53f6\u65af\u63a8\u65ad\uff08SF-TVBI\uff09\uff0c\u5728\u591a\u5f84\u73af\u5883\u4e2d\u5229\u7528\u7b2c\u4e00\u9636\u6563\u5c04\u8def\u5f84\u7684\u7ed3\u6784\u4fe1\u606f\u63d0\u5347\u591a\u76ee\u6807\u89d2\u5ea6\u4f30\u8ba1\u7684\u7cbe\u5ea6\uff0c\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u4f4e\u4e8eTurbo-VBI\uff0c\u6027\u80fd\u76f8\u8fd1\u3002", "motivation": "\u5728\u591a\u76ee\u6807\u3001\u591a\u5f84\u573a\u666f\u4e2d\uff0c\u7b2c\u4e00\u9636\u6563\u5c04\u8def\u5f84\u7684\u5230\u8fbe/\u53d1\u5c04\u89d2\u4e0e\u76f4\u63a5\u8def\u5f84\u7684\u89d2\u5ea6\u76f8\u5339\u914d\uff0c\u643a\u5e26\u53ef\u7528\u7684\u5148\u9a8c\u7ed3\u6784\u4fe1\u606f\uff1b\u901a\u8fc7\u8de8\u7a00\u758f\u5efa\u6a21\u548c\u9ad8\u6548\u63a8\u65ad\u6765\u63d0\u5347\u89d2\u5ea6\u4f30\u8ba1\u7684\u9c81\u68d2\u6027\u4e0e\u7cbe\u5ea6\u3002", "method": "\u63d0\u51fa3LHS\u8de8\u7a00\u758f\u5148\u9a8c\u6a21\u578b\u6765\u5bf9\u591a\u76ee\u6807\u611f\u77e5\u4fe1\u9053\u8fdb\u884c\u7a00\u758f\u8868\u793a\uff1b\u8bbe\u8ba1\u7ed3\u6784\u5316\u5feb\u901f turbo \u53d8\u5206\u8d1d\u53f6\u65af\u63a8\u65ad\uff08SF-TVBI\uff09\uff0c\u7ed3\u5408\u6d88\u606f\u4f20\u9012\u5b9e\u73b0\u8de8\u7a00\u758f\u5185\u90e8\u7684\u6982\u7387\u4ea4\u6362\uff0c\u5e76\u5f15\u5165\u4e24\u65f6\u5c3a\u5ea6\u66f4\u65b0\u4ee5\u51cf\u5c11\u9ad8\u7ef4\u7a00\u758f\u5411\u91cf\u7684\u66f4\u65b0\u9891\u7387\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u5229\u7528\u8de8\u7a00\u758f\u7ed3\u6784\u53ef\u663e\u8457\u63d0\u5347\u76ee\u6807\u89d2\u5ea6\u4f30\u8ba1\u7cbe\u5ea6\uff1bSF-TVBI\u5728\u6027\u80fd\u4e0a\u4e0eTurbo-VBI\u76f8\u8fd1\u4f46\u5177\u6709\u66f4\u4f4e\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u57fa\u4e8e3LHS\u8de8\u7a00\u758f\u5148\u9a8c\u7684SF-TVBI\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u4e14\u7cbe\u786e\u7684\u63a8\u65ad\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u590d\u6742\u591a\u5f84\u73af\u5883\u4e2d\u7684\u591a\u76ee\u6807\u89d2\u5ea6\u4f30\u8ba1\u4e0e\u5b9a\u4f4d\u4efb\u52a1\u3002"}}
{"id": "2511.14467", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.14467", "abs": "https://arxiv.org/abs/2511.14467", "authors": ["Heng Zhao", "Ruoyu Wang", "Tianhang Zheng", "Qi Li", "Bo Lv", "Yuyi Wang", "Wenliang Du"], "title": "From Topology to Behavioral Semantics: Enhancing BGP Security by Understanding BGP's Language with LLMs", "comment": "18 pages, 10 figures", "summary": "The trust-based nature of Border Gateway Protocol (BGP) makes it vulnerable to disruptions like prefix hijacking and misconfigurations, threatening routing stability. Traditional detection relies on manual inspection with limited scalability. Machine/Deep Learning (M/DL) approaches automate detection but suffer from suboptimal precision, limited generalizability, and high retraining costs. This is because existing methods focus on topological structures rather than comprehensive semantic characteristics of Autonomous Systems (ASes), often misinterpreting functionally similar but topologically distant ASes.\n  To address this, we propose BGPShield, an anomaly detection framework built on LLM embeddings that captures the Behavior Portrait and Routing Policy Rationale of each AS beyond topology, such as operational scale and global role. We propose a segment-wise aggregation scheme to transform AS descriptions into LLM representations without information loss, and a lightweight contrastive reduction network to compress them into a semantic-consistent version. Using these representations, our AR-DTW algorithm aligns and accumulates semantic distances to reveal behavioral inconsistencies. Evaluated on 16 real-world datasets, BGPShield detects 100% of verified anomalies with a false discovery rate below 5%. Notably, the employed LLMs were released prior to evaluation events, verifying generalizability. Furthermore, BGPShield constructs representations for unseen ASes within one second, significantly outperforming BEAM which demands costly retraining (averaging 65 hours).", "AI": {"tldr": "BGPShield: an anomaly detection framework using LLM embeddings to capture semantic behavior of ASes for BGP anomaly detection; achieves 100% anomaly detection with FDR<5%, fast unseen AS embedding, and outperforms BEAM.", "motivation": "To overcome MDL-based detection methods that over-rely on topological features and suffer from poor precision, limited generalizability, and high retraining costs; aim to incorporate semantic characteristics of Autonomous Systems (ASes) and improve scalability.", "method": "Develop BGPShield with segment-wise aggregation to convert AS descriptions into LLM representations; apply a lightweight contrastive reduction network to obtain semantic-consistent embeddings; use AR-DTW to align semantic distances and reveal behavioral inconsistencies; evaluate on 16 real-world datasets.", "result": "BGPShield detects 100% of verified anomalies with a false discovery rate below 5%; LLMs used were released before evaluation, supporting generalizability; unseen AS representations can be constructed within 1 second, outperforming BEAM which requires about 65 hours of retraining.", "conclusion": "Semantic-aware, LLM-based representations of AS behavior improve BGP anomaly detection, offering fast adaptation to unseen ASes and better scalability, with strong empirical results across real-world datasets."}}
{"id": "2511.13777", "categories": ["cs.CR", "math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.13777", "abs": "https://arxiv.org/abs/2511.13777", "authors": ["Pierre-Olivier Goffard", "Hansjoerg Albrecher", "Jean-Pierre Fouque"], "title": "Hashpower allocation in Pay-per-Share blockchain mining pools", "comment": null, "summary": "Mining blocks in a blockchain using the \\textit{Proof-of-Work} consensus protocol involves significant risk, as network participants face continuous operational costs while earning infrequent capital gains upon successfully mining a block. A common risk mitigation strategy is to join a mining pool, which combines the computing resources of multiple miners to provide a more stable income. This article examines a Pay-per-Share (PPS) reward system, where the pool manager can adjust both the share difficulty and the management fee. Using a simplified wealth model for miners, we explore how miners should allocate their computing resources among different mining pools, considering the trade-off between risk transfer to the manager and management fees.", "AI": {"tldr": "\u5728\u5de5\u4f5c\u91cf\u8bc1\u660e\u533a\u5757\u94fe\u7684PPS\u5956\u52b1\u7cfb\u7edf\u4e2d\uff0c\u7814\u7a76\u77ff\u5de5\u5982\u4f55\u5728\u591a\u4e2a\u77ff\u6c60\u95f4\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u6743\u8861\u628a\u98ce\u9669\u8f6c\u79fb\u7ed9\u77ff\u6c60\u7ba1\u7406\u8005\u4e0e\u652f\u4ed8\u7ba1\u7406\u8d39\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u89e3\u91ca\u77ff\u5de5\u4e3a\u4f55\u53c2\u4e0e\u77ff\u6c60\u53caPPS\u673a\u5236\u4e0b\u7ba1\u7406\u8d39\u4e0e\u96be\u5ea6\u8c03\u6574\u5bf9\u6536\u5165\u98ce\u9669\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u7b80\u5316\u7684\u8d22\u5bcc\u6a21\u578b\uff0c\u5206\u6790\u77ff\u5de5\u5728\u4e0d\u540c\u77ff\u6c60\u4e4b\u95f4\u7684\u8d44\u6e90\u5206\u914d\u51b3\u7b56\uff0c\u8003\u5bdf\u53ef\u8c03\u7684\u5206\u4eab\u96be\u5ea6\u548c\u7ba1\u7406\u8d39\u5bf9\u6700\u4f18\u7b56\u7565\u7684\u5f71\u54cd\u3002", "result": "\u63ed\u793a\u5728\u8003\u8651\u98ce\u9669\u8f6c\u79fb\u4e0e\u7ba1\u7406\u8d39\u7684\u524d\u63d0\u4e0b\uff0c\u77ff\u5de5\u7684\u8d44\u6e90\u5206\u914d\u7b56\u7565\u5982\u4f55\u968f\u53c2\u6570\u53d8\u5316\u800c\u53d8\u5316\uff0c\u63d0\u4f9b\u5bf9PPS\u7cfb\u7edf\u4e2d\u98ce\u9669\u5206\u62c5\u7684\u5b9a\u91cf\u76f4\u89c9\u3002", "conclusion": "\u5bf9PPS\u4e0b\u7684\u98ce\u9669\u5206\u62c5\u4e0e\u5b9a\u4ef7\u673a\u5236\u6709\u521d\u6b65\u8ba4\u8bc6\uff0c\u6307\u51fa\u672a\u6765\u7814\u7a76\u5e94\u7eb3\u5165\u66f4\u771f\u5b9e\u7684\u6536\u76ca\u5206\u5e03\u548c\u5e02\u573a\u52a8\u6001\u7b49\u56e0\u7d20\u3002"}}
{"id": "2511.14056", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.DG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.14056", "abs": "https://arxiv.org/abs/2511.14056", "authors": ["Marios Papamichals", "Regina Ruane"], "title": "Radial Compensation: Stable and Semantically Decoupled Generative Models on Riemannian Manifolds", "comment": "This is the first version of the paper", "summary": "Generative models on curved spaces rely on charts to map Euclidean spaces to manifolds. Exponential maps preserve geodesics but have stiff, radius-dependent Jacobians, while volume-preserving charts maintain densities but distort geodesic distances. Both approaches entangle curvature with model parameters, inflating gradient variance. In high-dimensional latent normalizing flows, the wrapped exponential prior can stretch radii far beyond the curvature scale, leading to poor test likelihoods and stiff solvers. We introduce Radial Compensation (RC), an information-geometric method that selects the base density in the tangent space so that the likelihood depends only on geodesic distance from a pole, decoupling parameter semantics from curvature. RC lets radial parameters retain their usual meaning in geodesic units, while the chart can be tuned as a numerical preconditioner. We extend RC to manifolds with known geodesic polar volume and show that RC is the only construction for geodesic-radial likelihoods with curvature-invariant Fisher information. We derive the Balanced-Exponential (bExp) chart family, balancing volume distortion and geodesic error. Under RC, all bExp settings preserve the same manifold density and Fisher information, with smaller dial values reducing gradient variance and flow cost. Empirically, RC yields stable generative models across densities, VAEs, flows on images and graphs, and protein models. RC improves likelihoods, restores clean geodesic radii, and prevents radius blow-ups in high-dimensional flows, making RC-bExp a robust default for likelihood-trained generative models on manifolds.", "AI": {"tldr": "\u63d0\u51fa Radial Compensation (RC) \u4e0e Balanced-Exponential (bExp) \u7684\u51e0\u4f55\u56fe\u8868\u6846\u67b6\uff0c\u5728\u66f2\u9762\u4e0a\u7684\u751f\u6210\u6a21\u578b\u4e2d\u89e3\u8026\u66f2\u7387\u4e0e\u6a21\u578b\u53c2\u6570\uff0c\u63d0\u5347\u7a33\u5b9a\u6027\u3001\u4f3c\u7136\u548c\u8ba1\u7b97\u6548\u7387\uff0cRC-bExp \u6210\u4e3a\u66f2\u9762\u4e0a Likelihood-trained \u6a21\u578b\u7684\u9ed8\u8ba4\u9c81\u68d2\u65b9\u6848\u3002", "motivation": "\u66f2\u7ebf\u66f2\u7387\u4e0e\u6a21\u578b\u53c2\u6570\u7684\u8026\u5408\u4f1a\u653e\u5927\u68af\u5ea6\u65b9\u5dee\uff1b\u6307\u6570\u6620\u5c04\u7684\u96c5\u53ef\u6bd4\u968f\u534a\u5f84\u6ce2\u52a8\u4e14\u96be\u4ee5\u63a7\uff1b\u4f53\u79ef\u4fdd\u6301\u7684\u56fe\u8868\u4f1a\u626d\u66f2\u6d4b\u5730\u8ddd\u79bb\uff1b\u9ad8\u7ef4\u6f5c\u53d8\u91cf\u6d41\u4e2d\u7684\u5305\u88f9\u6307\u6570\u5148\u9a8c\u5728\u66f2\u7387\u5c3a\u5ea6\u4e4b\u5916\u62c9\u4f38\u534a\u5f84\uff0c\u5bfc\u81f4\u4f3c\u7136\u4e0b\u964d\u4e0e\u6c42\u89e3\u56f0\u96be\u3002\u9700\u8981\u4e00\u79cd\u66f2\u7387\u4e0d\u53d8\u3001\u53c2\u6570\u8bed\u4e49\u89e3\u8026\u7684\u51e0\u4f55\u65b9\u6cd5\u3002", "method": "\u4ece\u4fe1\u606f\u51e0\u4f55\u51fa\u53d1\uff0cRC \u901a\u8fc7\u5728\u5207\u7a7a\u95f4\u9009\u53d6\u57fa\u5bc6\u5ea6\u4f7f\u4f3c\u7136\u4ec5\u4f9d\u8d56\u4e8e\u4ece\u67d0\u6781\u70b9\u7684\u6d4b\u5730\u8ddd\u79bb\uff0c\u4ece\u800c\u5c06\u53c2\u6570\u610f\u4e49\u4e0e\u66f2\u7387\u89e3\u8026\uff1b\u5c06 RC \u6269\u5c55\u5230\u5177\u5907\u5df2\u77e5\u6d4b\u5730\u6781\u5730\u4f53\u79ef\u7684\u6d41\u5f62\uff1b\u63d0\u51fa Balanced-Exponential\uff08bExp\uff09\u56fe\u65cf\uff0c\u5e73\u8861\u4f53\u79ef\u5931\u771f\u4e0e\u6d4b\u5730\u8bef\u5dee\uff1b\u5728 RC \u6761\u4ef6\u4e0b\uff0c\u6240\u6709 bExp \u8bbe\u7f6e\u4fdd\u6301\u76f8\u540c\u7684\u6d41\u5f62\u5bc6\u5ea6\u4e0e Fisher \u4fe1\u606f\uff0c\u8f83\u5c0f\u7684\u8c03\u8282\u503c\u964d\u4f4e\u68af\u5ea6\u65b9\u5dee\u4e0e\u6d41\u6210\u672c\u3002", "result": "\u5728\u5bc6\u5ea6\u51fd\u6570\u3001VAE\u3001\u56fe\u50cf/\u56fe\u4e0a\u7684\u6d41\u3001\u86cb\u767d\u8d28\u6a21\u578b\u7b49\u573a\u666f\u4e2d\u5b9e\u73b0\u7a33\u5b9a\u6027\u63d0\u5347\uff1b\u63d0\u9ad8\u4f3c\u7136\u3001\u6062\u590d\u5e72\u51c0\u7684\u6d4b\u5730\u534a\u5f84\u3001\u907f\u514d\u9ad8\u7ef4\u6d41\u4e2d\u7684\u534a\u5f84\u53d1\u6563\uff1bRC \u4e0e bExp \u63d0\u4f9b\u66f2\u9762\u4e0a\u4f3c\u7136\u8bad\u7ec3\u7684\u7a33\u5065\u9ed8\u8ba4\u3002", "conclusion": "RC \u63d0\u4f9b\u66f2\u7387\u4e0d\u53d8\u3001\u53c2\u6570\u8bed\u4e49\u89e3\u8026\u7684\u6846\u67b6\uff0c\u4f7f\u5f84\u5411\u53c2\u6570\u5728\u6d4b\u5730\u5355\u4f4d\u4e0b\u4fdd\u6301\u76f4\u89c2\u542b\u4e49\uff0c\u66f2\u7ebf\u7684\u6570\u503c\u9884\u6761\u4ef6\u53ef\u901a\u8fc7\u56fe\u8868\u8c03\u8282\uff1bbExp \u5728\u540c\u4e00\u6d41\u5f62\u4e0b\u7b49\u4ef7\u5730\u4fdd\u7559\u5bc6\u5ea6\u4e0e Fisher \u4fe1\u606f\uff0c\u4f46\u901a\u8fc7\u8f83\u5c0f\u7684\u8c03\u53c2\u5b9e\u73b0\u66f4\u4f4e\u68af\u5ea6\u65b9\u5dee\u4e0e\u66f4\u4f4e\u8ba1\u7b97\u6210\u672c\uff1b\u5728\u56fe\u50cf\u3001\u56fe\u3001\u86cb\u767d\u8d28\u7b49\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e RC-bExp \u4e3a\u6982\u7387\u5efa\u6a21\u5728\u66f2\u9762\u4e0a\u7684\u5f3a\u5065\u9ed8\u8ba4\u3002"}}
{"id": "2511.13750", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13750", "abs": "https://arxiv.org/abs/2511.13750", "authors": ["E. Zhixuan Zeng", "Yuhao Chen", "Alexander Wong"], "title": "SCALEX: Scalable Concept and Latent Exploration for Diffusion Models", "comment": null, "summary": "Image generation models frequently encode social biases, including stereotypes tied to gender, race, and profession. Existing methods for analyzing these biases in diffusion models either focus narrowly on predefined categories or depend on manual interpretation of latent directions. These constraints limit scalability and hinder the discovery of subtle or unanticipated patterns.\n  We introduce SCALEX, a framework for scalable and automated exploration of diffusion model latent spaces. SCALEX extracts semantically meaningful directions from H-space using only natural language prompts, enabling zero-shot interpretation without retraining or labelling. This allows systematic comparison across arbitrary concepts and large-scale discovery of internal model associations. We show that SCALEX detects gender bias in profession prompts, ranks semantic alignment across identity descriptors, and reveals clustered conceptual structure without supervision. By linking prompts to latent directions directly, SCALEX makes bias analysis in diffusion models more scalable, interpretable, and extensible than prior approaches.", "AI": {"tldr": "SCALEX \u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u5728\u6269\u6563\u6a21\u578b\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u96f6\u76d1\u7763\u7684\u65b9\u5411\u63a2\u7d22\uff0c\u63ed\u793a\u6027\u522b/\u804c\u4e1a\u7b49\u504f\u89c1\u53ca\u6982\u5ff5\u7ed3\u6784\uff0c\u4e14\u4e0d\u9700\u8981\u518d\u8bad\u7ec3\u6216\u4eba\u5de5\u6807\u6ce8\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u504f\u89c1\u5206\u6790\u5de5\u5177\u8981\u4e48\u5c40\u9650\u4e8e\u9884\u5b9a\u4e49\u7c7b\u522b\uff0c\u8981\u4e48\u4f9d\u8d56\u4e8e\u624b\u5de5\u89e3\u91ca\u7684\u6f5c\u5728\u65b9\u5411\uff0c\u96be\u4ee5\u6269\u5c55\u5e76\u53d1\u73b0\u9690\u6027\u6216\u610f\u5916\u6a21\u5f0f\u3002\u9700\u8981\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u81ea\u52a8\u5316\u4e14\u53ef\u53d1\u73b0\u65b0\u6a21\u5f0f\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "SCALEX \u4ec5\u5229\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u4ece H-\u7a7a\u95f4\u62bd\u53d6\u8bed\u4e49\u5316\u65b9\u5411\uff0c\u5b9e\u73b0\u96f6\u76d1\u7763\u89e3\u91ca\uff1b\u65e0\u9700\u518d\u8bad\u7ec3\u6216\u6807\u6ce8\uff0c\u5c06\u63d0\u793a\u6620\u5c04\u5230\u6f5c\u5728\u65b9\u5411\uff0c\u4fbf\u4e8e\u8de8\u4efb\u610f\u6982\u5ff5\u7684\u6bd4\u8f83\u4e0e\u5927\u89c4\u6a21\u53d1\u73b0\u3002", "result": "SCALEX \u80fd\u5728\u804c\u4e1a\u63d0\u793a\u4e2d\u53d1\u73b0\u6027\u522b\u504f\u89c1\uff0c\u6309\u8eab\u4efd\u63cf\u8ff0\u5bf9\u8bed\u4e49\u5bf9\u9f50\u8fdb\u884c\u6392\u5e8f\uff0c\u5e76\u63ed\u793a\u65e0\u76d1\u7763\u7684\u7c07\u72b6\u6982\u5ff5\u7ed3\u6784\uff0c\u63d0\u5347\u504f\u89c1\u5206\u6790\u7684\u53ef\u6269\u5c55\u6027\u3001\u53ef\u89e3\u91ca\u6027\u4e0e\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cSCALEX \u4f7f\u6269\u6563\u6a21\u578b\u7684\u504f\u89c1\u5206\u6790\u66f4\u52a0\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u62d3\u5c55\uff0c\u964d\u4f4e\u4e86\u5bf9\u5148\u9a8c\u7c7b\u522b\u548c\u4eba\u5de5\u6807\u6ce8\u7684\u4f9d\u8d56\u3002"}}
{"id": "2511.13781", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.13781", "abs": "https://arxiv.org/abs/2511.13781", "authors": ["Warda Usman", "Yixin Zou", "Daniel Zappala"], "title": "Human-Centered Threat Modeling in Practice: Lessons, Challenges, and Paths Forward", "comment": null, "summary": "Human-centered threat modeling (HCTM) is an emerging area within security and privacy research that focuses on how people define and navigate threats in various social, cultural, and technological contexts. While researchers increasingly approach threat modeling from a human-centered perspective, little is known about how they prepare for and engage with HCTM in practice. In this work, we conduct 23 semi-structured interviews with researchers to examine the state of HCTM, including how researchers design studies, elicit threats, and navigate values, constraints, and long-term goals. We find that HCTM is not a prescriptive process but a set of evolving practices shaped by relationships with participants, disciplinary backgrounds, and institutional structures. Researchers approach threat modeling through sustained groundwork and participant-centered inquiry, guided by values such as care, justice, and autonomy. They also face challenges including emotional strain, ethical dilemmas, and structural barriers that complicate efforts to translate findings into real-world impact. We conclude by identifying opportunities to advance HCTM through shared infrastructure, broader recognition of diverse contributions, and stronger mechanisms for translating findings into policy, design, and societal change.", "AI": {"tldr": "HCTM \u662f\u4e00\u79cd\u975e\u89c4\u5b9a\u6027\u7684\u3001\u7531\u5173\u7cfb\u3001\u4ef7\u503c\u89c2\u4e0e\u5236\u5ea6\u5171\u540c\u5851\u9020\u7684\u6f14\u8fdb\u6027\u5b9e\u8df5\uff1b\u901a\u8fc723\u540d\u7814\u7a76\u8005\u7684\u8bbf\u8c08\u63ed\u793a\u5176\u8bbe\u8ba1\u7814\u7a76\u3001\u5a01\u80c1\u63d0\u53d6\u548c\u4ef7\u503c\u53d6\u5411\u7684\u505a\u6cd5\uff0c\u4ee5\u53ca\u60c5\u611f\u538b\u529b\u4e0e\u7ed3\u6784\u6027\u969c\u788d\u5bf9\u843d\u5730\u7684\u5236\u7ea6\uff1b\u672a\u6765\u9700\u8981\u5171\u7528\u57fa\u7840\u8bbe\u65bd\u3001\u6269\u5927\u591a\u6837\u6027\u8d21\u732e\u7684\u8ba4\u53ef\uff0c\u5e76\u5efa\u7acb\u5c06\u7814\u7a76\u7ed3\u679c\u8f6c\u5316\u4e3a\u653f\u7b56\u3001\u8bbe\u8ba1\u548c\u793e\u4f1a\u53d8\u9769\u7684\u673a\u5236\u3002", "motivation": "\u4e86\u89e3\u7814\u7a76\u8005\u5728\u5b9e\u8df5\u4e2d\u5982\u4f55\u51c6\u5907\u548c\u53c2\u4e0e\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u5a01\u80c1\u5efa\u6a21\uff0c\u68b3\u7406\u7814\u7a76\u8bbe\u8ba1\u3001\u5a01\u80c1\u83b7\u53d6\u3001\u4ef7\u503c\u89c2\u4e0e\u957f\u671f\u76ee\u6807\u7684\u6743\u8861\u3002", "method": "\u91c7\u7528\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u7684\u5b9a\u6027\u7814\u7a76\uff0c\u517123\u540d\u53c2\u4e0eHCTM\u7814\u7a76\u7684\u5b66\u8005\uff0c\u8fdb\u884c\u4e3b\u9898\u5206\u6790\u4ee5\u63ed\u793a\u505a\u6cd5\u3001\u6311\u6218\u4e0e\u673a\u4f1a\u3002", "result": "\u53d1\u73b0HCTM\u5e76\u975e\u4e00\u4e2a\u7ebf\u6027\u3001\u53ef\u64cd\u4f5c\u7684\u89c4\u7a0b\uff0c\u800c\u662f\u4e00\u7ec4\u968f\u65f6\u95f4\u6f14\u53d8\u7684\u5b9e\u8df5\uff0c\u53d7\u7814\u7a76\u5bf9\u8c61\u5173\u7cfb\u3001\u5b66\u79d1\u80cc\u666f\u4e0e\u5236\u5ea6\u7ed3\u6784\u5f71\u54cd\uff1b\u4ee5\u5173\u6000\u3001\u6b63\u4e49\u3001\u81ea\u6cbb\u7b49\u4ef7\u503c\u5f15\u5bfc\u6301\u7eed\u7684\u57fa\u7840\u5de5\u4f5c\u4e0e\u4ee5\u53c2\u4e0e\u8005\u4e3a\u4e2d\u5fc3\u7684\u63a2\u8be2\uff1b\u540c\u65f6\u9762\u4e34\u60c5\u611f\u538b\u529b\u3001\u4f26\u7406\u56f0\u5883\u548c\u7ed3\u6784\u6027\u969c\u788d\uff0c\u8fd9\u4e9b\u56e0\u7d20\u963b\u788d\u7814\u7a76\u53d1\u73b0\u7684\u5b9e\u9645\u8fd0\u8425\u4e0e\u793e\u4f1a\u5f71\u54cd\u7684\u8f6c\u5316\u3002", "conclusion": "\u901a\u8fc7\u642d\u5efa\u5171\u7528\u57fa\u7840\u8bbe\u65bd\u3001\u63d0\u5347\u5bf9\u591a\u6837\u8d21\u732e\u7684\u8ba4\u53ef\u5ea6\u3001\u4ee5\u53ca\u5efa\u7acb\u5c06\u53d1\u73b0\u8f6c\u5316\u4e3a\u653f\u7b56\u3001\u8bbe\u8ba1\u4e0e\u793e\u4f1a\u53d8\u9769\u7684\u673a\u5236\uff0c\u63a8\u52a8HCTM\u5411\u66f4\u5177\u7cfb\u7edf\u6027\u548c\u793e\u4f1a\u6027\u5f71\u54cd\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2511.13861", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.13861", "abs": "https://arxiv.org/abs/2511.13861", "authors": ["Linhan Fang", "Jesus Silva-Rodriguez", "Xingpeng Li"], "title": "Data-Driven EV Charging Load Profile Estimation and Typical EV Daily Load Dataset Generation", "comment": null, "summary": "Widespread electric vehicle (EV) adoption introduces new challenges for distribution grids due to large, localized load increases, stochastic charging behavior, and limited data availability. This paper proposes two data-driven methods to estimate residential EV charging profiles using real-world customer meter data from CenterPoint Energy serving the Houston area. The first approach applies a least-squares estimation to extract average charging rates by comparing aggregated EV and non-EV meter data, enabling a statistical method for starting and ending charge times. The second method isolates EV load from meter profiles and applies a kernel density estimation (KDE) to develop a probabilistic charging model. Both methods produce a distinct \"u-shaped\" daily charging profile, with most charging occurring overnight. The validated profiles offer a scalable tool for utilities to better anticipate EV-driven demand increases and support proactive grid planning.", "AI": {"tldr": "\u4f7f\u7528\u4e24\u79cd\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u57fa\u4e8e\u5c45\u4f4f\u7528\u6237\u8868\u8ba1\u6570\u636e\u4f30\u8ba1\u5bb6\u5ead\u5145\u7535\u8f6e\u5ed3\uff1b\u57fa\u4e8e\u6700\u5c0f\u4e8c\u4e58\u6cd5\u7684\u5e73\u5747\u5145\u7535\u901f\u7387\u63d0\u53d6\u548c\u8d77\u6b62\u65f6\u95f4\u63a8\u65ad\uff1b\u4ee5\u53ca\u57fa\u4e8eKDE\u7684\u6982\u7387\u5145\u7535\u6a21\u578b\uff1b\u4e24\u79cd\u65b9\u6cd5\u5747\u5f97\u5230\u591c\u95f4\u5145\u7535\u7684u\u5f62\u65e5\u5145\u7535\u66f2\u7ebf\uff0c\u4fbf\u4e8e\u516c\u7528\u4e8b\u4e1a\u8fdb\u884c\u9700\u6c42\u9884\u6d4b\u4e0e\u89c4\u5212\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u8f66\u5e7f\u6cdb\u666e\u53ca\uff0c\u5206\u914d\u7535\u7f51\u9762\u4e34\u5c40\u90e8\u8d1f\u8377\u96c6\u4e2d\u3001\u5145\u7535\u884c\u4e3a\u968f\u673a\u6027\u548c\u6570\u636e\u4e0d\u8db3\u7b49\u6311\u6218\uff0c\u9700\u8981\u53ef\u6269\u5c55\u3001\u6570\u636e\u9a71\u52a8\u7684\u5bb6\u5ead\u5145\u7535\u8f6e\u5ed3\u4f30\u8ba1\u65b9\u6cd5\u4ee5\u652f\u6301\u7f51\u89c4\u5212\u548c\u9700\u6c42\u9884\u6d4b\u3002", "method": "\u65b9\u6cd5\u4e00\uff1a\u901a\u8fc7\u5bf9\u6bd4\u805a\u5408\u7684EV\u4e0e\u975eEV\u8868\u8ba1\u6570\u636e\uff0c\u4f7f\u7528\u6700\u5c0f\u4e8c\u4e58\u4f30\u8ba1\u63d0\u53d6\u5e73\u5747\u5145\u7535\u901f\u7387\u5e76\u63a8\u65ad\u5145\u7535\u7684\u8d77\u59cb\u548c\u7ed3\u675f\u65f6\u95f4\u3002\u65b9\u6cd5\u4e8c\uff1a\u4ece\u8868\u8ba1\u66f2\u7ebf\u4e2d\u5206\u79bbEV\u8d1f\u8377\uff0c\u518d\u5bf9EV\u8d1f\u8377\u5e94\u7528\u6838\u5bc6\u5ea6\u4f30\u8ba1(KDE)\u4ee5\u5efa\u7acb\u6982\u7387\u5145\u7535\u6a21\u578b\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u5747\u751f\u6210\u660e\u663e\u7684\u201cu\u5f62\u201d\u65e5\u5145\u7535\u66f2\u7ebf\uff0c\u5145\u7535\u4e3b\u8981\u53d1\u751f\u5728\u591c\u95f4\u3002\u7ecf\u9a8c\u8bc1\u7684\u8f6e\u5ed3\u53ef\u4e3a\u516c\u7528\u4e8b\u4e1a\u63d0\u4f9b\u53ef\u6269\u5c55\u5de5\u5177\uff0c\u7528\u4e8e\u66f4\u597d\u5730\u9884\u6d4bEV\u9a71\u52a8\u7684\u9700\u6c42\u589e\u52a0\u5e76\u652f\u6301\u4e3b\u52a8\u7f51\u89c4\u5212\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u7684\u5bb6\u5ead\u5145\u7535\u8f6e\u5ed3\u53ef\u5e2e\u52a9\u516c\u7528\u4e8b\u4e1a\u5728\u4e0d\u540c\u60c5\u666f\u4e0b\u8fdb\u884c\u9700\u6c42\u9884\u6d4b\u4e0e\u5bb9\u91cf\u89c4\u5212\uff0c\u4fc3\u8fdbEV\u5bf9\u7535\u7f51\u5f71\u54cd\u7684\u524d\u77bb\u6027\u7ba1\u7406\u3002"}}
{"id": "2511.13789", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13789", "abs": "https://arxiv.org/abs/2511.13789", "authors": ["Haotian Jin", "Yang Li", "Haihui Fan", "Lin Shen", "Xiangfang Li", "Bo Li"], "title": "Uncovering and Aligning Anomalous Attention Heads to Defend Against NLP Backdoor Attacks", "comment": null, "summary": "Backdoor attacks pose a serious threat to the security of large language models (LLMs), causing them to exhibit anomalous behavior under specific trigger conditions. The design of backdoor triggers has evolved from fixed triggers to dynamic or implicit triggers. This increased flexibility in trigger design makes it challenging for defenders to identify their specific forms accurately. Most existing backdoor defense methods are limited to specific types of triggers or rely on an additional clean model for support. To address this issue, we propose a backdoor detection method based on attention similarity, enabling backdoor detection without prior knowledge of the trigger. Our study reveals that models subjected to backdoor attacks exhibit unusually high similarity among attention heads when exposed to triggers. Based on this observation, we propose an attention safety alignment approach combined with head-wise fine-tuning to rectify potentially contaminated attention heads, thereby effectively mitigating the impact of backdoor attacks. Extensive experimental results demonstrate that our method significantly reduces the success rate of backdoor attacks while preserving the model's performance on downstream tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u76f8\u4f3c\u6027\u7684\u540e\u95e8\u68c0\u6d4b\u4e0e\u5bf9\u9f50/\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u4e0d\u9700\u8981\u89e6\u53d1\u77e5\u8bc6\u7684\u524d\u63d0\u4e0b\u68c0\u6d4b\u5e76\u6291\u5236\u540e\u95e8\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u540e\u95e8\u653b\u51fb\u5728\u5927\u6a21\u578b\u4e2d\u65e5\u76ca\u666e\u904d\uff0c\u89e6\u53d1\u5668\u4ece\u56fa\u5b9a\u5316\u5411\u52a8\u6001/\u9690\u5f0f\u6f14\u53d8\uff0c\u589e\u52a0\u4e86\u68c0\u6d4b\u96be\u5ea6\uff1b\u9700\u8981\u65e0\u9700\u89e6\u53d1\u4fe1\u606f\u7684\u68c0\u6d4b\u4e0e\u4fee\u590d\u624b\u6bb5\u3002", "method": "\u57fa\u4e8e\u89c2\u5bdf\u5230\u6a21\u578b\u5728\u542b\u89e6\u53d1\u6837\u672c\u65f6\u6ce8\u610f\u529b\u5934\u4e4b\u95f4\u5448\u73b0\u5f02\u5e38\u9ad8\u76f8\u4f3c\u6027\u7684\u73b0\u8c61\uff0c\u63d0\u51fa\u4e00\u79cd\u6ce8\u610f\u529b\u5b89\u5168\u5bf9\u9f50\u5e76\u901a\u8fc7\u9010\u5934\u5fae\u8c03\u4fee\u590d\u88ab\u6c61\u67d3\u7684\u6ce8\u610f\u529b\u5934\u7684\u65b9\u6cd5\uff0c\u8fbe\u5230\u68c0\u6d4b\u4e0e\u7f13\u89e3\u540e\u95e8\u7684\u76ee\u7684\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u540e\u95e8\u653b\u51fb\u7684\u6210\u529f\u7387\uff0c\u540c\u65f6\u57fa\u672c\u4e0d\u5f71\u54cd\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u89e6\u53d1\u5668\u65e0\u5173\u7684\u540e\u95e8\u68c0\u6d4b\u4e0e\u4fee\u590d\u6846\u67b6\uff0c\u63d0\u5347\u4e86\u5bf9\u52a8\u6001\u89e6\u53d1\u7684\u9c81\u68d2\u6027\u4e0e\u5b89\u5168\u6027\u3002"}}
{"id": "2511.13870", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.13870", "abs": "https://arxiv.org/abs/2511.13870", "authors": ["Zaid Hadach", "Hajar El Hammouti", "El Houcine Bergou", "Adnane Saoud"], "title": "Just Few States are Enough: Randomized Sparse Feedback for Stability of Dynamical Systems", "comment": "To appear in the proceedings of AAAI 2026", "summary": "While classical control theory assumes that the controller has access to measurements of the entire state (or output) at every time instant, this paper investigates a setting where the feedback controller can only access a randomly selected subset of the state vector at each time step. Due to the random sparsification that selects only a subset of the state components at each step, we analyze the stability of the closed-loop system in terms of Asymptotic Mean-Square Stability (AMSS), which ensures that the system state converges to zero in the mean-square sense. We consider the problem of designing both a feedback gain matrix and a measurement sparsification strategy that minimizes the number of state components required for feedback, while ensuring AMSS of the closed-loop system. Interestingly, (1) we provide conditions on the dynamics of the system under which it is possible to find a sparsification strategy, and (2) we propose a Linear Matrix Inequality (LMI) based algorithm that jointly computes a stabilizing gain matrix, and a randomized sparsification strategy that minimizes the expected number of measured state coordinates while preserving the AMSS. Our approach is then extended to the case where the sparsification probabilities vary across the state components. Based on these theoretical findings, we propose an algorithmic procedure to compute the vector of sparsification parameters, along with the corresponding feedback gain matrix. To the best of our knowledge, this is the first study to investigate the stability properties of control systems that rely solely on randomly selected state measurements. Numerical simulations demonstrate that, in some settings, the system achieves comparable performance to full-state feedback while requiring measurements from only $0.3\\%$ of the state coordinates.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u968f\u673a\u7a00\u758f\u6d4b\u91cf\u6761\u4ef6\u4e0b\u7684\u7ebf\u6027\u7cfb\u7edf\u7a33\u5b9a\u6027\u8bbe\u8ba1\u6846\u67b6\uff0c\u7ed3\u5408AMSS\u7a33\u5b9a\u6027\u548cLMIs\uff0c\u8054\u5408\u8bbe\u8ba1\u53cd\u9988\u589e\u76ca\u77e9\u9635\u4e0e\u6d4b\u91cf\u7a00\u758f\u7b56\u7565\uff0c\u4e14\u5141\u8bb8\u6982\u7387\u968f\u72b6\u6001\u5206\u91cf\u53d8\u5316\u3002\u6570\u503c\u7ed3\u679c\u663e\u793a\u5728\u4ec5\u97000.3%\u72b6\u6001\u5206\u91cf\u6d4b\u91cf\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u8fbe\u5230\u63a5\u8fd1\u5168\u72b6\u6001\u53cd\u9988\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6700\u4f18\u63a7\u5236\u548c\u9c81\u68d2\u63a7\u5236\u5e38\u8981\u6c42\u5bf9\u5168\u90e8\u72b6\u6001\u6709\u89c2\u6d4b\u6216\u8f93\u51fa\u6d4b\u91cf\u3002\u672c\u6587\u65e8\u5728\u5728\u6bcf\u4e00\u6b65\u4ec5\u83b7\u5f97\u968f\u673a\u9009\u53d6\u7684\u72b6\u6001\u5206\u91cf\u7684\u60c5\u51b5\u4e0b\u4ecd\u5b9e\u73b0\u95ed\u73af\u7cfb\u7edf\u7684\u5e73\u5747\u5e73\u65b9\u6e10\u8fd1\u7a33\u5b9a\u6027\uff0c\u964d\u4f4e\u89c2\u6d4b\u91cf\u4e0e\u901a\u4fe1\u5f00\u9500\u3002", "method": "\u5c06\u968f\u673a\u7a00\u758f\u6d4b\u91cf\u5f15\u5165\u95ed\u73af\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ebf\u6027\u77e9\u9635\u4e0d\u7b49\u5f0f\uff08LMI\uff09\u6784\u9020\u4e00\u4e2a\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e00\u4e2a\u7a33\u5065/\u7a33\u5b9a\u5316\u7684\u53cd\u9988\u589e\u76ca\u77e9\u9635K\u4ee5\u53ca\u4e00\u4e2a\u968f\u673a\u7a00\u758f\u7b56\u7565\uff08\u5305\u62ec\u7a00\u758f\u6982\u7387\u5411\u91cf\uff09\uff0c\u4ee5\u5728\u671f\u671b\u610f\u4e49\u4e0a\u6700\u5c0f\u5316\u6d4b\u91cf\u7ef4\u5ea6\u540c\u65f6\u4fdd\u8bc1AMSS\u3002\u8fdb\u800c\u63a8\u5e7f\u81f3\u7a00\u758f\u6982\u7387\u968f\u72b6\u6001\u5206\u91cf\u5f02\u8d28\u6027\u7684\u60c5\u5f62\uff0c\u5e76\u7ed9\u51fa\u4e00\u79cd\u8ba1\u7b97\u7a00\u758f\u53c2\u6570\u5411\u91cf\u53ca\u5bf9\u5e94K\u7684\u7b97\u6cd5\u3002", "result": "\u7ed9\u51fa\u7cfb\u7edf\u5728\u4f55\u79cd\u52a8\u6001\u7279\u6027\u4e0b\u53ef\u5b9e\u73b0\u7a00\u758f\u5316\u4ee5\u53ca\u6ee1\u8db3AMSS\u7684\u5145\u8981\u6761\u4ef6\uff1b\u63d0\u51fa\u57fa\u4e8eLMI\u7684\u8054\u5408\u8bbe\u8ba1\u7b97\u6cd5\uff1b\u6269\u5c55\u5230\u53ef\u53d8\u7a00\u758f\u6982\u7387\u573a\u666f\uff1b\u901a\u8fc7\u6570\u503c\u4eff\u771f\uff0c\u663e\u793a\u57280.3%\u6d4b\u91cf\u7684\u60c5\u51b5\u4e0b\u53ef\u83b7\u5f97\u63a5\u8fd1\u5168\u72b6\u6001\u53cd\u9988\u7684\u6027\u80fd\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u5728\u4ec5\u4f9d\u8d56\u968f\u673a\u9009\u62e9\u7684\u72b6\u6001\u89c2\u6d4b\u4e0b\u7684\u63a7\u5236\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0c\u4e3a\u51cf\u5c11\u4f20\u611f\u4e0e\u901a\u4fe1\u5f00\u9500\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u8bbe\u8ba1\u6846\u67b6\uff0c\u5e76\u7ed9\u51fa\u53ef\u6267\u884c\u7684\u8ba1\u7b97\u7a0b\u5e8f\u6765\u5f97\u5230\u7a00\u758f\u53c2\u6570\u5411\u91cf\u4e0e\u5bf9\u5e94\u7684\u53cd\u9988\u589e\u76ca\u3002"}}
{"id": "2511.13753", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.13753", "abs": "https://arxiv.org/abs/2511.13753", "authors": ["Feilong Wang", "Fuqiang Liu"], "title": "Robustness of LLM-enabled vehicle trajectory prediction under data security threats", "comment": "20 pages, 2 figures, 11 tables, working paper", "summary": "The integration of large language models (LLMs) into automated driving systems has opened new possibilities for reasoning and decision-making by transforming complex driving contexts into language-understandable representations. Recent studies demonstrate that fine-tuned LLMs can accurately predict vehicle trajectories and lane-change intentions by gathering and transforming data from surrounding vehicles. However, the robustness of such LLM-based prediction models for safety-critical driving systems remains unexplored, despite the increasing concerns about the trustworthiness of LLMs. This study addresses this gap by conducting a systematic vulnerability analysis of LLM-enabled vehicle trajectory prediction. We propose a one-feature differential evolution attack that perturbs a single kinematic feature of surrounding vehicles within the LLM's input prompts under a black-box setting. Experiments on the highD dataset reveal that even minor, physically plausible perturbations can significantly disrupt model outputs, underscoring the susceptibility of LLM-based predictors to adversarial manipulation. Further analyses reveal a trade-off between accuracy and robustness, examine the failure mechanism, and explore potential mitigation solutions. The findings provide the very first insights into adversarial vulnerabilities of LLM-driven automated vehicle models in the context of vehicular interactions and highlight the need for robustness-oriented design in future LLM-based intelligent transportation systems.", "AI": {"tldr": "LLM\u9a71\u52a8\u7684\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u5b58\u5728\u5bf9\u6297\u6027\u8106\u5f31\u6027\uff1a\u63d0\u51fa\u5355\u4e00\u7279\u5f81\u5dee\u5206\u8fdb\u5316\u653b\u51fb\uff0c\u5728\u9ed1\u76d2\u4e0b\u5bf9\u8f93\u5165\u63d0\u793a\u4e2d\u7684\u5355\u4e00\u8fd0\u52a8\u5b66\u7279\u5f81\u8fdb\u884c\u6270\u52a8\uff0c\u5373\u4f7f\u5fae\u5c0f\u4e14\u7269\u7406\u4e0a\u53ef\u884c\u7684\u6270\u52a8\u4e5f\u80fd\u663e\u8457\u6539\u53d8\u8f93\u51fa\uff1b\u9996\u6b21\u63ed\u793a\u5728\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2dLLM\u9884\u6d4b\u7684\u5b89\u5168\u6027\u4e0e\u9c81\u68d2\u6027\u6311\u6218\u3002", "motivation": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5165\u81ea\u52a8\u9a7e\u9a76\u4ee5\u63d0\u5347\u63a8\u7406\u4e0e\u51b3\u7b56\uff0c\u4f46\u5173\u4e8e\u5176\u9884\u6d4b\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u7684\u7814\u7a76\u5f88\u5c11\u3002\u4e86\u89e3\u5bf9\u6297\u653b\u51fb\u5bf9LLM\u9a71\u52a8\u7684\u8f68\u8ff9\u9884\u6d4b\u7684\u5f71\u54cd\u5bf9\u4e8e\u786e\u4fdd\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5355\u7279\u5f81\u5dee\u5206\u8fdb\u5316\u653b\u51fb\uff08one-feature differential evolution attack\uff09\uff0c\u5728\u9ed1\u7bb1\u8bbe\u7f6e\u4e0b\u5bf9 Surrounding vehicles \u7684\u5355\u4e2a\u8fd0\u52a8\u5b66\u7279\u5f81\u8fdb\u884c\u6270\u52a8\uff0c\u5e76\u5c06\u6270\u52a8\u5f15\u5165LLM\u8f93\u5165\u63d0\u793a\u4e2d\u3002\u57fa\u4e8ehighD\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5206\u6790\u51c6\u786e\u6027\u4e0e\u9c81\u68d2\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u63a2\u7a76\u5931\u8d25\u673a\u5236\uff0c\u5e76\u63a2\u8ba8\u6f5c\u5728\u7f13\u89e3\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5373\u4f7f\u662f\u5fae\u5c0f\u3001\u7269\u7406\u4e0a\u53ef\u884c\u7684\u6270\u52a8\u4e5f\u80fd\u663e\u8457\u5e72\u6270\u6a21\u578b\u8f93\u51fa\uff0c\u63ed\u793aLLM\u9a71\u52a8\u7684\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u5bf9\u5bf9\u6297\u6027\u64cd\u63a7\u7684\u6613\u53d7\u653b\u51fb\u6027\u3002", "conclusion": "\u9996\u6b21\u4ece\u7cfb\u7edf\u5c42\u9762\u63ed\u793aLLM\u9a71\u52a8\u7684\u81ea\u52a8\u9a7e\u9a76\u9884\u6d4b\u5728\u8f66\u8f86\u4ea4\u4e92\u573a\u666f\u4e2d\u7684\u5bf9\u6297\u6027\u8106\u5f31\u6027\uff0c\u5f3a\u8c03\u5728\u672a\u6765\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u9700\u8981\u4f18\u5148\u8003\u8651\u9c81\u68d2\u6027\u4e0e\u5b89\u5168\u6027\u3002"}}
{"id": "2511.13808", "categories": ["cs.CR", "cs.LG", "cs.MS"], "pdf": "https://arxiv.org/pdf/2511.13808", "abs": "https://arxiv.org/abs/2511.13808", "authors": ["Edward Raff", "Ryan R. Curtin", "Derek Everett", "Robert J. Joyce", "James Holt"], "title": "Zipf-Gramming: Scaling Byte N-Grams Up to Production Sized Malware Corpora", "comment": "Published in CIKM 2025", "summary": "A classifier using byte n-grams as features is the only approach we have found fast enough to meet requirements in size (sub 2 MB), speed (multiple GB/s), and latency (sub 10 ms) for deployment in numerous malware detection scenarios. However, we've consistently found that 6-8 grams achieve the best accuracy on our production deployments but have been unable to deploy regularly updated models due to the high cost of finding the top-k most frequent n-grams over terabytes of executable programs. Because the Zipfian distribution well models the distribution of n-grams, we exploit its properties to develop a new top-k n-gram extractor that is up to $35\\times$ faster than the previous best alternative. Using our new Zipf-Gramming algorithm, we are able to scale up our production training set and obtain up to 30\\% improvement in AUC at detecting new malware. We show theoretically and empirically that our approach will select the top-k items with little error and the interplay between theory and engineering required to achieve these results.", "AI": {"tldr": "\u901a\u8fc7 Zipf-Gramming \u7b97\u6cd5\u5feb\u901f\u63d0\u53d6 top-k n-gram\uff0c\u63d0\u5347 malware \u68c0\u6d4b\u7684\u8bad\u7ec3\u89c4\u6a21\u548c AUC\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728 terabytes \u6570\u636e\u91cf\u65f6\u63d0\u53d6 top-k n-grams \u6781\u4e3a\u6162\uff0c\u65e0\u6cd5\u9891\u7e41\u66f4\u65b0\u6a21\u578b\uff0c\u9700\u5728\u5927\u5c0f\u3001\u901f\u5ea6\u3001\u5ef6\u8fdf\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "method": "\u5229\u7528 Zipfian \u5206\u5e03\u7279\u6027\uff0c\u63d0\u51fa Zipf-Gramming \u7684 top-k \u63d0\u53d6\u7b97\u6cd5\uff1b\u7406\u8bba\u4e0e\u7ecf\u9a8c\u5206\u6790\u8868\u660e\u8bef\u5dee\u5c0f\uff1b\u5b9e\u73b0\u4e0e\u751f\u4ea7\u8bad\u7ec3\u7ed3\u5408\uff0c\u83b7\u5f97 35 \u500d\u7684\u52a0\u901f\u3002", "result": "\u6700\u5927\u53ef\u5728\u65b0\u6837\u672c\u68c0\u6d4b\u4e2d\u63d0\u5347 AUC \u7ea6 30%\uff1b\u80fd\u6269\u5c55\u5230\u66f4\u5927\u7684\u8bad\u7ec3\u96c6\u3002", "conclusion": "Zipf-Gramming \u63d0\u4f9b\u9ad8\u6548\u4e14\u51c6\u786e\u7684 top-k \u9009\u62e9\uff0c\u7406\u8bba\u4e0e\u5de5\u7a0b\u5b9e\u73b0\u7684\u7ed3\u5408\u662f\u5173\u952e\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5b9a\u671f\u66f4\u65b0\u5e76\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002"}}
{"id": "2511.13872", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.13872", "abs": "https://arxiv.org/abs/2511.13872", "authors": ["Bukunmi G. Odunlami", "Marcos Netto"], "title": "Dynamic state estimation of hybrid systems: Inverters that switch between grid-following and grid-forming control schemes", "comment": null, "summary": "This paper develops a hybrid system modeling framework for inverters that switch between grid-following and grid-forming control schemes. In particular, such inverters are modeled as hybrid automata with guard conditions on voltage and frequency, and reset maps that maintain consistent phase, frequency, and droop references during mode transitions. The hybrid model is embedded within an extended Kalman filter to assess estimation performance under explicit mode switching. Results show that the proposed framework ensures stable, well-behaved dynamics and improves state estimation, especially near switching instants, compared with smooth continuous models.", "AI": {"tldr": "Hybrid automata model with mode-switching inverters, embedded in an extended Kalman filter for state estimation; shows stable dynamics and improved estimation across switching.", "motivation": "Address stability and estimation challenges in inverter fleets that switch between grid-following and grid-forming modes, especially near mode transitions.", "method": "Model inverters as hybrid automata with guard conditions on voltage/frequency and reset maps for phase, frequency, and droop references; integrate the hybrid model into an extended Kalman filter to evaluate estimation performance during mode switching.", "result": "The hybrid framework yields stable, well-behaved dynamics and improved state estimation, particularly at switching instants, compared with purely smooth continuous models.", "conclusion": "A hybrid modeling plus EKF framework provides robust performance for mode-switching in grid interfacing inverters and enhances estimation accuracy during transitions."}}
{"id": "2511.13755", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13755", "abs": "https://arxiv.org/abs/2511.13755", "authors": ["Zhe Yang", "Wenrui Li", "Hongtao Chen", "Penghong Wang", "Ruiqin Xiong", "Xiaopeng Fan"], "title": "Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement", "comment": null, "summary": "Multimodal learning aims to improve performance by leveraging data from multiple sources. During joint multimodal training, due to modality bias, the advantaged modality often dominates backpropagation, leading to imbalanced optimization. Existing methods still face two problems: First, the long-term dominance of the dominant modality weakens representation-output coupling in the late stages of training, resulting in the accumulation of redundant information. Second, previous methods often directly and uniformly adjust the gradients of the advantaged modality, ignoring the semantics and directionality between modalities. To address these limitations, we propose Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement (RedReg), which is inspired by information bottleneck principle. Specifically, we construct a redundancy phase monitor that uses a joint criterion of effective gain growth rate and redundancy to trigger intervention only when redundancy is high. Furthermore, we design a co-information gating mechanism to estimate the contribution of the current dominant modality based on cross-modal semantics. When the task primarily relies on a single modality, the suppression term is automatically disabled to preserve modality-specific information. Finally, we project the gradient of the dominant modality onto the orthogonal complement of the joint multimodal gradient subspace and suppress the gradient according to redundancy. Experiments show that our method demonstrates superiority among current major methods in most scenarios. Ablation experiments verify the effectiveness of our method. The code is available at https://github.com/xia-zhe/RedReg.git", "AI": {"tldr": "\u63d0\u51fa RedReg \u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u6d4b\u5197\u4f59\u5e76\u5bf9\u4f18\u52bf\u6a21\u6001\u68af\u5ea6\u8fdb\u884c\u6b63\u4ea4\u6295\u5f71\u4e0e\u95e8\u63a7\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u4fe1\u606f\u7684\u5e73\u8861 refined\uff0c\u63d0\u5347\u6574\u4f53\u6027\u80fd\u3002", "motivation": "\u5728\u8054\u5408\u591a\u6a21\u6001\u8bad\u7ec3\u4e2d\uff0c\u6a21\u6001\u504f\u7f6e\u5bfc\u81f4\u4f18\u52bf\u6a21\u6001\u4e3b\u5bfc\u53cd\u5411\u4f20\u64ad\uff0c\u957f\u671f\u4f1a\u524a\u5f31\u8868\u793a-\u8f93\u51fa\u8026\u5408\u5e76\u79ef\u7d2f\u5197\u4f59\u4fe1\u606f\uff1b\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u89e3\u51b3\u5197\u4f59\u957f\u671f\u5360\u4f18\u548c\u8de8\u6a21\u6001\u8bed\u4e49\u4e0e\u65b9\u5411\u6027\u7f3a\u4e4f\u8003\u8651\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement (RedReg)\u3002\u6838\u5fc3\u5305\u62ec\uff1a1) \u5197\u4f59\u9636\u6bb5\u76d1\u63a7\u5668\uff0c\u901a\u8fc7\u6709\u6548\u589e\u76ca\u589e\u957f\u7387\u548c\u5197\u4f59\u7684\u8054\u5408\u6807\u51c6\u5728\u5197\u4f59\u9ad8\u65f6\u89e6\u53d1\u5e72\u9884\uff1b2) \u5171\u540c\u4fe1\u606f\u95e8\u63a7\u673a\u5236\uff0c\u57fa\u4e8e\u8de8\u6a21\u6001\u8bed\u4e49\u4f30\u8ba1\u5f53\u524d\u4e3b\u5bfc\u6a21\u6001\u7684\u8d21\u732e\uff1b\u4efb\u52a1\u82e5\u4e3b\u8981\u4f9d\u8d56\u5355\u4e00\u6a21\u6001\uff0c\u5219\u81ea\u52a8\u7981\u7528\u6291\u5236\u9879\u4ee5\u4fdd\u7559\u6a21\u6001\u7279\u6709\u4fe1\u606f\uff1b3) \u5c06\u4e3b\u5bfc\u6a21\u6001\u68af\u5ea6\u6295\u5f71\u5230\u8054\u5408\u591a\u6a21\u6001\u68af\u5ea6\u5b50\u7a7a\u95f4\u7684\u6b63\u4ea4\u8865\u4e0a\uff0c\u5e76\u4f9d\u636e\u5197\u4f59\u7a0b\u5ea6\u6291\u5236\u68af\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5728\u5927\u591a\u6570\u573a\u666f\u4e0b\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\uff1b\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\uff0c\u5e76\u7ed9\u51fa\u4ee3\u7801\u94fe\u63a5\uff08GitHub\uff09\u3002", "conclusion": "RedReg \u5c06\u4fe1\u606f\u74f6\u9888\u7075\u611f\u878d\u5165\u5197\u4f59\u63a7\u5236\u4e0e\u68af\u5ea6\u65b9\u5411\u6027\u8c03\u8282\uff0c\u5b9e\u73b0\u5bf9\u591a\u6a21\u6001\u4fe1\u606f\u7684\u9ad8\u6548\u5e73\u8861\u4e0e\u7ec6\u7c92\u5ea6\u63a7\u5236\uff0c\u63d0\u5347\u591a\u6a21\u6001\u5b66\u4e60\u7684\u7a33\u5b9a\u6027\u4e0e\u6027\u80fd\u3002"}}
{"id": "2511.13939", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.13939", "abs": "https://arxiv.org/abs/2511.13939", "authors": ["Paul Staat", "Christof Paar", "Swarun Kumar"], "title": "The Battle of Metasurfaces: Understanding Security in Smart Radio Environments", "comment": null, "summary": "Metasurfaces, or Reconfigurable Intelligent Surfaces (RISs), have emerged as a transformative technology for next-generation wireless systems, enabling digitally controlled manipulation of electromagnetic wave propagation. By turning the traditionally passive radio environment into a smart, programmable medium, metasurfaces promise advances in communication and sensing. However, metasurfaces also present a new security frontier: both attackers and defenders can exploit them to alter wireless propagation for their own advantage. While prior security research has primarily explored unilateral metasurface applications - empowering either attackers or defenders - this work investigates symmetric scenarios, where both sides possess comparable metasurface capabilities. Using both theoretical modeling and real-world experiments, we analyze how competing metasurfaces interact for diverse objectives, including signal power and sensing perception. Thereby, we present the first systematic study of context-agnostic metasurface-to-metasurface interactions and their implications for wireless security. Our results reveal that the outcome of metasurface \"battles\" depends on an interplay of timing, placement, algorithmic strategy, and hardware scale. Across multiple case studies in Wi-Fi environments, including wireless jamming, channel obfuscation for sensing and communication, and sensing spoofing, we demonstrate that opposing metasurfaces can substantially or fully negate each other's effects. By undermining previously proposed security and privacy schemes, our findings open new opportunities for designing resilient and high-assurance physical-layer systems in smart radio environments.", "AI": {"tldr": "\u5bf9\u79f0\u6027RIS\u5bf9\u6297\u573a\u666f\u7684\u7cfb\u7edf\u6027\u7814\u7a76\uff0c\u9996\u6b21\u63ed\u793a\u76f8\u5bf9 RIS \u80fd\u529b\u65f6\u7684\u201c\u519b\u4e8b\u5316\u5bf9\u6297\u201d\u5982\u4f55\u5728\u65f6\u5e8f\u3001\u5b9a\u4f4d\u3001\u7b97\u6cd5\u7b56\u7565\u4e0e\u786c\u4ef6\u5c3a\u5ea6\u7b49\u56e0\u7d20\u5f71\u54cd\u4e0b\u76f4\u63a5\u62b5\u6d88\u5bf9\u65b9\u6548\u679c\uff0c\u8fdb\u800c\u5f71\u54cd\u5b89\u5168\u4e0e\u9690\u79c1\u9632\u62a4\u7684\u7269\u7406\u5c42\u8bbe\u8ba1\u3002", "motivation": " metasurfaces/ RIS \u6210\u4e3a\u53ef\u7f16\u7a0b\u65e0\u7ebf\u4f20\u64ad\u7684\u65b0\u524d\u6cbf\uff0c\u5b89\u5168\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff1b\u4e0d\u540c\u4e8e\u4ee5\u5f80\u5355\u5411\u5e94\u7528\u7814\u7a76\uff0c\u672c\u5de5\u4f5c\u805a\u7126\u4e8e\u653b\u51fb\u65b9\u4e0e\u9632\u5b88\u65b9\u90fd\u5177\u5907\u53ef\u6bd4 RIS \u80fd\u529b\u7684\u5bf9\u79f0\u573a\u666f\uff0c\u63ed\u793a\u5176\u5728\u65e0\u7ebf\u5b89\u5168\u4e2d\u7684\u65b0 threat \u4e0e defense \u7684\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u57fa\u4e8e\u7406\u8bba\u5efa\u6a21\u4e0e\u73b0\u5b9e\u73af\u5883\u5b9e\u9a8c\uff0c\u7ed3\u5408Wi-Fi \u573a\u666f\u7684\u591a\u79cd\u6848\u4f8b\uff0c\u5206\u6790\u5bf9\u79f0 RIS \u7684\u5e72\u6270\u3001\u4fe1\u9053\u6df7\u6dc6\u4e0e\u611f\u77e5\u4f2a\u88c5\u7b49\u4efb\u52a1\u4e2d\u7684\u4e92\u52a8\uff0c\u8003\u5bdf\u65f6\u5e8f\u3001\u653e\u7f6e\u4f4d\u7f6e\u3001\u7b97\u6cd5\u7b56\u7565\u3001\u786c\u4ef6\u5c3a\u5ea6\u7b49\u53d8\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u5bf9\u79f0 RIS \u76f8\u4e92\u4f5c\u7528\u53ef\u663e\u8457\u62b5\u6d88\u6216\u5b8c\u5168\u62b5\u6d88\u5bf9\u65b9\u6548\u679c\uff1b\u7ed3\u679c\u53d7\u5230\u65f6\u5e8f\u3001\u653e\u7f6e\u3001\u7b56\u7565\u548c\u786c\u4ef6\u5c3a\u5ea6\u7684\u7efc\u5408\u5f71\u54cd\uff1b\u5728\u591a\u79cdWi-Fi \u60c5\u5883\u4e0b\uff08\u542b\u65e0\u7ebf\u5e72\u6270\u3001\u611f\u77e5/\u901a\u4fe1\u7684\u4fe1\u9053\u6df7\u6dc6\u3001\u611f\u77e5\u6b3a\u9a97\uff09\u5bf9\u65b9 RIS \u80fd\u529b\u80fd\u524a\u5f31\u751a\u81f3\u62b5\u6d88\u5148\u524d\u7684\u5b89\u5168/\u9690\u79c1\u65b9\u6848\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u5173\u4e8e RIS \u4e0e RIS \u4e4b\u95f4\u4e0a\u4e0b\u6587\u65e0\u5173\u4ea4\u4e92\u7684\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\uff0c\u4e3a\u8bbe\u8ba1\u5728\u667a\u80fd\u65e0\u7ebf\u73af\u5883\u4e2d\u66f4\u5177\u9c81\u68d2\u6027\u548c\u9ad8\u4fdd\u969c\u6027\u7684\u7269\u7406\u5c42\u5b89\u5168\u7b56\u7565\u6307\u660e\u65b9\u5411\uff0c\u540c\u65f6\u63d0\u793a\u5728 RIS \u90e8\u7f72\u4e0e\u5bf9\u6297\u4e2d\u9700\u8981\u8003\u8651\u5bf9\u79f0\u6027\u4e0e\u534f\u540c\u9632\u62a4\u3002"}}
{"id": "2511.14104", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.14104", "abs": "https://arxiv.org/abs/2511.14104", "authors": ["Lehuai Xu", "Zirui Lu", "Haoran Yang", "Yina Zhou"], "title": "Lightweight Multi-task CNN for ECG Diagnosis with GRU-Diffusion", "comment": "15 pages, 5 figures", "summary": "With the increasing demand for real-time Electrocardiogram (ECG) classification on edge devices, existing models face challenges of high computational cost and limited accuracy on imbalanced datasets.This paper presents Multi-task DFNet, a lightweight multi-task framework for ECG classification across the MIT-BIH Arrhythmia Database and the PTB Diagnostic ECG Database, enabling efficient task collaboration by dynamically sharing knowledge across tasks, such as arrhythmia detection, myocardial infarction (MI) classification, and other cardiovascular abnormalities. The proposed method integrates GRU-augmented Diffusion, where the GRU is embedded within the diffusion model to capture temporal dependencies better and generate high-quality synthetic signals for imbalanced classes. The experimental results show that Multi-task DFNet achieves 99.72% and 99.89% accuracy on the MIT-BIH dataset and PTB dataset, respectively, with significantly fewer parameters compared to traditional models, making it suitable for deployment on wearable ECG monitors. This work offers a compact and efficient solution for multi-task ECG diagnosis, providing a promising potential for edge healthcare applications on resource-constrained devices.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u591a\u4efb\u52a1\u6846\u67b6 DFNet\uff0c\u7528\u4e8e\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5bf9 ECG \u8fdb\u884c\u5b9e\u65f6\u591a\u4efb\u52a1\u5206\u7c7b\uff0c\u5e76\u901a\u8fc7 GRU \u878d\u5408\u6269\u6563\u6a21\u578b\u6765\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5728 MIT-BIH \u4e0e PTB \u6570\u636e\u96c6\u4e0a\u5747\u53d6\u5f97\u9ad8\u7cbe\u5ea6\u4e14\u53c2\u6570\u91cf\u660e\u663e\u964d\u4f4e\u3002", "motivation": "\u89e3\u51b3\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fdb\u884c\u5b9e\u65f6 ECG \u5206\u7c7b\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u6027\u548c\u5b9e\u65f6\u6027\u9700\u6c42\u3002", "method": "\u63d0\u51fa Multi-task DFNet \u8fd9\u4e00\u8f7b\u91cf\u7ea7\u591a\u4efb\u52a1\u6846\u67b6\uff0c\u652f\u6301\u8de8\u4efb\u52a1\u7684\u77e5\u8bc6\u52a8\u6001\u5171\u4eab\uff1b\u5f15\u5165 GRU \u88c5\u5165\u6269\u6563\u6a21\u578b\u4ee5\u6355\u6349\u65f6\u5e8f\u4f9d\u8d56\u5e76\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5408\u6210\u4fe1\u53f7\u7528\u4e8e\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\uff1b\u6d89\u53ca\u4efb\u52a1\u5305\u62ec\u5fc3\u5f8b\u5931\u5e38\u68c0\u6d4b\u3001\u5fc3\u808c\u6897\u6b7b\uff08MI\uff09\u5206\u7c7b\u53ca\u5176\u4ed6\u5fc3\u8840\u7ba1\u5f02\u5e38\uff1b\u8bc4\u4f30\u5728 MIT-BIH \u548c PTB \u6570\u636e\u5e93\u4e0a\u3002", "result": "\u5728 MIT-BIH \u4e0e PTB \u6570\u636e\u96c6\u4e0a\u5206\u522b\u5b9e\u73b0 99.72% \u548c 99.89% \u7684\u51c6\u786e\u7387\uff1b\u53c2\u6570\u91cf\u663e\u8457\u4f4e\u4e8e\u4f20\u7edf\u6a21\u578b\uff0c\u9002\u5408\u5728\u53ef\u7a7f\u6234 ECG \u76d1\u6d4b\u8bbe\u5907\u4e0a\u90e8\u7f72\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e00\u79cd\u7d27\u51d1\u9ad8\u6548\u7684\u591a\u4efb\u52a1 ECG \u8bca\u65ad\u89e3\u51b3\u65b9\u6848\uff0c\u5bf9\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u7684\u8fb9\u7f18\u533b\u7597\u5e94\u7528\u5177\u6709\u826f\u597d\u524d\u666f\u3002"}}
{"id": "2511.14005", "categories": ["cs.CR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.14005", "abs": "https://arxiv.org/abs/2511.14005", "authors": ["Kaiyuan Hu", "Hong Kang", "Yili Jin", "Junhua Liu", "Chengming Hu", "Haolun Wu", "Xue Liu"], "title": "Privis: Towards Content-Aware Secure Volumetric Video Delivery", "comment": null, "summary": "Volumetric video has emerged as a key paradigm in eXtended Reality (XR) and immersive multimedia because it enables highly interactive, spatially consistent 3D experiences. However, the transport-layer security for such 3D content remains largely unaddressed. Existing volumetric streaming pipelines inherit uniform encryption schemes from 2D video, overlooking the heterogeneous privacy sensitivity of different geometry and the strict motion-to-photon latency constraints of real-time XR.\n  We take an initial step toward content-aware secure volumetric video delivery by introducing Privis, a saliency-guided transport framework that (i) partitions volumetric assets into independent units, (ii) applies lightweight authenticated encryption with adaptive key rotation, and (iii) employs selective traffic shaping to balance confidentiality and low latency. Privis specifies a generalized transport-layer security architecture for volumetric media, defining core abstractions and adaptive protection mechanisms. We further explore a prototype implementation and present initial latency measurements to illustrate feasibility and design tradeoffs, providing early empirical guidance toward future work on real-time, saliency-conditioned secure delivery.", "AI": {"tldr": "Privis: a saliency-guided secure delivery framework for volumetric video that partitions assets, uses adaptive key rotation with lightweight authenticated encryption, and selective traffic shaping to balance confidentiality and latency.", "motivation": "Volumetric video in XR requires real-time, latency-constrained secure transport. Existing encryption schemes borrowed from 2D video ignore heterogeneous privacy sensitivity of 3D geometry and the stringent motion-to-photon latency constraints.", "method": "Introduce Privis, a saliency-guided transport framework that (i) partitions volumetric assets into independent units, (ii) applies lightweight authenticated encryption with adaptive key rotation, and (iii) employs selective traffic shaping. It defines a generalized transport-layer security architecture for volumetric media with adaptable protection mechanisms. A prototype implementation is explored and initial latency measurements are reported to illustrate feasibility and design tradeoffs.", "result": "Preliminary feasibility demonstrated via a prototype and initial latency measurements, providing early empirical guidance on the tradeoffs between confidentiality and latency in saliency-aware secure volumetric delivery.", "conclusion": "Privis offers an initial framework and prototype for content-aware, saliency-guided secure delivery of volumetric video, marking a step toward real-time, saliency-conditioned secure streaming and outlining open questions for future work."}}
{"id": "2511.14110", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14110", "abs": "https://arxiv.org/abs/2511.14110", "authors": ["Sithmini Ranasingha", "Agasthi Haputhanthri", "Hansa Marasinghe", "Nima Wickramasinghe", "Kithmin Wickremasinghe", "Jithangi Wanigasinghe", "Chamira U. S. Edussooriya", "Joshua P. Kulasingham"], "title": "A Patient-Independent Neonatal Seizure Prediction Model Using Reduced Montage EEG and ECG", "comment": "10 pages, 4 figures", "summary": "Neonates are highly susceptible to seizures, often leading to short or long-term neurological impairments. However, clinical manifestations of neonatal seizures are subtle and often lead to misdiagnoses. This increases the risk of prolonged, untreated seizure activity and subsequent brain injury. Continuous video electroencephalogram (cEEG) monitoring is the gold standard for seizure detection. However, this is an expensive evaluation that requires expertise and time. In this study, we propose a convolutional neural network-based model for early prediction of neonatal seizures by distinguishing between interictal and preictal states of the EEG. Our model is patient-independent, enabling generalization across multiple subjects, and utilizes mel-frequency cepstral coefficient matrices extracted from multichannel EEG and electrocardiogram (ECG) signals as input features. Trained and validated on the Helsinki neonatal EEG dataset with 10-fold cross-validation, the proposed model achieved an average accuracy of 97.52%, sensitivity of 98.31%, specificity of 96.39%, and F1-score of 97.95%, enabling accurate seizure prediction up to 30 minutes before onset. The inclusion of ECG alongside EEG improved the F1-score by 1.42%, while the incorporation of an attention mechanism yielded an additional 0.5% improvement. To enhance transparency, we incorporated SHapley Additive exPlanations (SHAP) as an explainable artificial intelligence method to interpret the model and provided localization of seizure focus using scalp plots. The overall results demonstrate the model's potential for minimally supervised deployment in neonatal intensive care units, enabling timely and reliable prediction of neonatal seizures, while demonstrating strong generalization capability across unseen subjects through transfer learning.", "AI": {"tldr": "\u57fa\u4e8eCNN\u7684\u591a\u6a21\u6001EEG/ECG\u7279\u5f81\u7528\u4e8e\u65e9\u671f\u9884\u6d4b\u65b0\u751f\u513f\u766b\u75eb\uff0c\u80fd\u591f\u5728\u53d1\u4f5c\u524d30\u5206\u949f\u5185\u7ed9\u51fa\u9ad8\u51c6\u786e\u5ea6\u8b66\u62a5\u3002", "motivation": "\u65b0\u751f\u513f\u766b\u75eb\u8bca\u65ad\u56f0\u96be\u548c\u5ef6\u8fdf\u6cbb\u7597\u98ce\u9669\u9ad8\uff0c\u73b0\u6709\u7684\u8fde\u7eed\u89c6\u9891\u8111\u7535\u56fe\u76d1\u6d4b\u6210\u672c\u9ad8\u4e14\u9700\u8981\u4e13\u4e1a\u4eba\u5458\uff0c\u9700\u5f00\u53d1\u4f4e\u6210\u672c\u3001\u53ef\u79fb\u690d\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u9884\u6d4b\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u60a3\u8005\u65e0\u5173\u7684CNN\u6a21\u578b\uff0c\u8f93\u5165\u7279\u5f81\u4e3a\u591a\u901a\u9053EEG\u548cECG\u4fe1\u53f7\u7684\u6885\u5c14\u9891\u7387\u5012\u8c31\u7cfb\u6570(MFCC)\u77e9\u9635\uff1b\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\uff1b\u5728Helsinki\u65b0\u751f\u513fEEG\u6570\u636e\u96c6\u4e0a\u8fdb\u884c10\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u8bc4\u4f30\u51c6\u786e\u7387\u3001\u7075\u654f\u5ea6\u3001\u7279\u5f02\u6027\u3001F1\uff1b\u5bf9\u6bd4EEG\u4e0eEEG+ECG\uff0c\u4f7f\u7528SHAP\u8fdb\u884c\u89e3\u91ca\u5e76\u901a\u8fc7\u5934\u76ae\u56fe\u5b9a\u4f4d\u766b\u75eb\u7126\u70b9\uff1b\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u5b9e\u73b0\u5bf9\u672a\u89c1\u53d7\u8bd5\u8005\u7684\u6cdb\u5316\u3002", "result": "\u5e73\u5747\u51c6\u786e\u5ea697.52%\uff0c\u7075\u654f\u5ea698.31%\uff0c\u7279\u5f02\u602796.39%\uff0cF1 97.95%\uff1bEEG+ECG\u4f7fF1\u63d0\u9ad81.42%\uff0c\u6ce8\u610f\u529b\u673a\u5236\u518d\u589e0.5%\uff1b\u80fd\u5728\u53d1\u4f5c\u524d\u957f\u8fbe30\u5206\u949f\u9884\u6d4b\uff1bSHAP\u89e3\u91ca\u589e\u5f3a\u6a21\u578b\u900f\u660e\u5ea6\uff0c\u5934\u76ae\u56fe\u5b9a\u4f4d\u766b\u75eb\u7126\u70b9\uff1b\u5177\u5907\u5bf9\u672a\u89c1\u5bf9\u8c61\u7684\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u65b0\u751f\u513fNICU\u4e2d\u5177\u6709\u6f5c\u5728\u7684\u53ef\u89e3\u91ca\u3001\u4f4e\u76d1\u7763\u90e8\u7f72\u80fd\u529b\uff0c\u4e14\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u5b9e\u73b0\u5bf9\u65b0\u53d7\u8bd5\u8005\u7684\u6cdb\u5316\uff0c\u652f\u6301\u65e9\u671f\u3001\u53ef\u9760\u7684\u766b\u75eb\u9884\u6d4b\u3002"}}
{"id": "2511.13906", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.13906", "abs": "https://arxiv.org/abs/2511.13906", "authors": ["Alejandro Anderson", "Esteban A. Hernandez-Vargas", "Giulia Giordano"], "title": "L-Functions Certify Set Attractivity for Discrete-Time Uncertain Nonlinear Switched Systems", "comment": null, "summary": "We introduce the class of L-functions to certify the attractivity of sets for uncertain nonlinear switched systems in discrete time. The existence of an L-function associated with a set guarantees the robust local attractivity of that set under the system dynamics. We propose a constructive method for obtaining piecewise-continuous L-functions based on contractive sets for the system, and show that the existence of a robust control contractive set for the dynamics implies the existence of an appropriate L-function, and hence the robust local attractivity of the set itself. We illustrate the proposed framework through examples that elucidate the theoretical concepts, and through the case study of a nonlinear switched system modelling antimicrobial resistance, which highlights the relevance of the approach to the analysis of biological systems.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.13757", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13757", "abs": "https://arxiv.org/abs/2511.13757", "authors": ["Xiuding Cai", "Xueyao Wang", "Sen Wang", "Yaoyao Zhu", "Jiao Chen", "Yu Yao"], "title": "VitalBench: A Rigorous Multi-Center Benchmark for Long-Term Vital Sign Prediction in Intraoperative Care", "comment": "Accepted by IEEE Sensors Journal", "summary": "Intraoperative monitoring and prediction of vital signs are critical for ensuring patient safety and improving surgical outcomes. Despite recent advances in deep learning models for medical time-series forecasting, several challenges persist, including the lack of standardized benchmarks, incomplete data, and limited cross-center validation. To address these challenges, we introduce VitalBench, a novel benchmark specifically designed for intraoperative vital sign prediction. VitalBench includes data from over 4,000 surgeries across two independent medical centers, offering three evaluation tracks: complete data, incomplete data, and cross-center generalization. This framework reflects the real-world complexities of clinical practice, minimizing reliance on extensive preprocessing and incorporating masked loss techniques for robust and unbiased model evaluation. By providing a standardized and unified platform for model development and comparison, VitalBench enables researchers to focus on architectural innovation while ensuring consistency in data handling. This work lays the foundation for advancing predictive models for intraoperative vital sign forecasting, ensuring that these models are not only accurate but also robust and adaptable across diverse clinical environments. Our code and data are available at https://github.com/XiudingCai/VitalBench.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.14032", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14032", "abs": "https://arxiv.org/abs/2511.14032", "authors": ["Kunal Mukherjee"], "title": "Location-Dependent Cryptosystem", "comment": null, "summary": "Digital content distribution and proprietary research-driven industries face persistent risks from intellectual property theft and unauthorized redistribution. Conventional encryption schemes such as AES, TDES, ECC, and ElGamal provide strong cryptographic guarantees, but they remain fundamentally agnostic to where decryption takes place.In practice, this means that once a decryption key is leaked or intercepted, any adversary can misuse the key to decrypt the protected content from any location. We present a location-dependent cryptosystem in which the decryption key is not transmitted as human- or machine-readable data, but implicitly encoded in precise time-of-flight differences of ultra-wideband (UWB) data transmission packets. The system leverages precise timing hardware and a custom JMTK protocol to map a SHA-256 hashed AES key onto scheduled transmission timestamps. Only receivers located within a predefined spatial region can observe the packet timings that align with the intended \"time slot\" pattern, enabling them to reconstruct the key and decrypt the secret. Receivers outside the authorized region observe incorrect keys. We implement a complete prototype that encrypts and transmits audio data using our cryptosystem, and only when the receiver is within the authorized data, they are able to decrypt the data. Our evaluation demonstrates that the system (i) removes the need to share decryption passwords electronically or physically, (ii) ensures the decryption key cannot be recovered by the eavesdropper, and (iii) provides a non-trivial spatial tolerance for legitimate users.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5b9a\u4f4d\u7684\u52a0\u5bc6\u7cfb\u7edf\uff0c\u901a\u8fc7\u8d85\u5bbd\u5e26\uff08UWB\uff09\u7684\u7cbe\u786e\u65f6\u5e8f\u5c06\u5bc6\u94a5\u9690\u5f0f\u7f16\u7801\u5728\u4f20\u8f93\u65f6\u95f4\u6233\u4e2d\uff0c\u53ea\u6709\u5728\u6388\u6743\u7269\u7406\u533a\u57df\u5185\u7684\u63a5\u6536\u8005\u624d\u80fd\u91cd\u5efa\u5bc6\u94a5\u5e76\u89e3\u5bc6\uff1b\u7ed9\u51fa\u539f\u578b\u5b9e\u73b0\u4e0e\u8bc4\u4f30\u3002", "motivation": "\u89e3\u51b3\u6570\u5b57\u5185\u5bb9\u5206\u53d1\u4e2d\u7684\u7248\u6743\u4fdd\u62a4\u96be\u9898\uff1a\u4f20\u7edf\u52a0\u5bc6\u5728\u5bc6\u94a5\u6cc4\u9732\u540e\u96be\u4ee5\u963b\u6b62\u5728\u5176\u4ed6\u5730\u70b9\u89e3\u5bc6\uff0c\u9700\u5c06\u89e3\u5bc6\u80fd\u529b\u4e0e\u7269\u7406\u4f4d\u7f6e\u7ed1\u5b9a\uff0c\u907f\u514d\u7535\u5b50/\u7269\u7406\u4f20\u8f93\u5bc6\u94a5\u7684\u98ce\u9669\u3002", "method": "\u5c06 AES \u5bc6\u94a5\u7ecf SHA-256 \u54c8\u5e0c\u540e\u6620\u5c04\u5230\u9884\u5b9a\u7684\u4f20\u8f93\u65f6\u95f4\u6233\u96c6\u5408\uff0c\u901a\u8fc7\u8d85\u5bbd\u5e26\u6570\u636e\u5305\u7684\u7cbe\u786e\u65f6\u5e8f\u4f20\u8f93\uff1b\u5728 JMTK \u534f\u8bae\u4e0b\u8fdb\u884c\u65f6\u95f4\u69fd\u89c2\u6d4b\uff0c\u6388\u6743\u533a\u57df\u5185\u7684\u63a5\u6536\u7aef\u80fd\u91cd\u5efa\u5bc6\u94a5\u5e76\u89e3\u5bc6\uff0c\u672a\u6388\u6743\u533a\u57df\u89c2\u5bdf\u5230\u7684\u5bc6\u94a5\u4e0d\u6b63\u786e\u3002\u5b9e\u73b0\u4e00\u4e2a\u5b8c\u6574\u7684\u539f\u578b\uff0c\u91c7\u7528\u97f3\u9891\u6570\u636e\u7684\u52a0\u5bc6\u4e0e\u4f20\u8f93\u3002", "result": "\u7cfb\u7edf\u7701\u7565\u4e86\u7535\u5b50\u6216\u7269\u7406\u4f20\u8f93\u89e3\u5bc6\u53e3\u4ee4\u7684\u9700\u6c42\uff0c\u907f\u514d\u88ab\u7a83\u542c\u8005\u6062\u590d\u89e3\u5bc6\u94a5\uff0c\u4e14\u5bf9\u5408\u6cd5\u7528\u6237\u63d0\u4f9b\u4e86\u975e\u5f31\u5316\u7684\u7a7a\u95f4\u5bb9\u5fcd\u5ea6\uff1b\u539f\u578b\u6d4b\u8bd5\u663e\u793a\u5728\u6388\u6743\u533a\u57df\u5185\u80fd\u6b63\u786e\u89e3\u5bc6\uff0c\u533a\u57df\u5916\u65e0\u6cd5\u89e3\u5bc6\u3002", "conclusion": "\u5c06\u89e3\u5bc6\u80fd\u529b\u7ed1\u5b9a\u5230\u7269\u7406\u4f4d\u7f6e\u7684\u5b9a\u4f4d\u578b\u52a0\u5bc6\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u80fd\u591f\u7f13\u89e3\u5bc6\u94a5\u5206\u53d1\u5e26\u6765\u7684\u98ce\u9669\uff0c\u4f46\u4f9d\u8d56\u9ad8\u7cbe\u5ea6\u65f6\u5e8f\u786c\u4ef6\u4e0e\u53ef\u9760\u7684\u8fd1\u4f3c\u7a7a\u95f4\u5bb9\u5fcd\uff0c\u5bf9\u90e8\u7f72\u73af\u5883\u6709\u8981\u6c42\u3002"}}
{"id": "2511.13758", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13758", "abs": "https://arxiv.org/abs/2511.13758", "authors": ["Jun-Hyoung Park", "Ho-Jun Song", "Seong-Whan Lee"], "title": "ChemFixer: Correcting Invalid Molecules to Unlock Previously Unseen Chemical Space", "comment": "This is the author's preprint version of the article accepted to IEEE JBHI. Final published version: https://doi.org/10.1109/JBHI.2025.3593825. High-quality PDF (publisher version): https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11106678. Note: Some figures may appear distorted due to arXiv's TeXLive rendering", "summary": "Deep learning-based molecular generation models have shown great potential in efficiently exploring vast chemical spaces by generating potential drug candidates with desired properties. However, these models often produce chemically invalid molecules, which limits the usable scope of the learned chemical space and poses significant challenges for practical applications. To address this issue, we propose ChemFixer, a framework designed to correct invalid molecules into valid ones. ChemFixer is built on a transformer architecture, pre-trained using masking techniques, and fine-tuned on a large-scale dataset of valid/invalid molecular pairs that we constructed. Through comprehensive evaluations across diverse generative models, ChemFixer improved molecular validity while effectively preserving the chemical and biological distributional properties of the original outputs. This indicates that ChemFixer can recover molecules that could not be previously generated, thereby expanding the diversity of potential drug candidates. Furthermore, ChemFixer was effectively applied to a drug-target interaction (DTI) prediction task using limited data, improving the validity of generated ligands and discovering promising ligand-protein pairs. These results suggest that ChemFixer is not only effective in data-limited scenarios, but also extensible to a wide range of downstream tasks. Taken together, ChemFixer shows promise as a practical tool for various stages of deep learning-based drug discovery, enhancing molecular validity and expanding accessible chemical space.", "AI": {"tldr": "ChemFixer \u901a\u8fc7\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u7ea0\u9519\u6846\u67b6\uff0c\u7528\u5bf9\u7167\u7684\u6709\u6548/\u65e0\u6548\u5206\u5b50\u5bf9\u8fdb\u884c\u63a9\u7801\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\uff0c\u7ea0\u6b63\u6df1\u5ea6\u5b66\u4e60\u751f\u6210\u4e2d\u4ea7\u751f\u7684\u65e0\u6548\u5206\u5b50\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u5206\u5b50\u5206\u5e03\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u6709\u6548\u6027\uff0c\u5e76\u6269\u5c55\u6f5c\u5728\u836f\u7269\u7a7a\u95f4\uff0c\u4e14\u9002\u7528\u4e8e\u6570\u636e\u6709\u9650\u573a\u666f\u7684\u4e0b\u6e38\u4efb\u52a1\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u836f\u7269\u5206\u5b50\u751f\u6210\u5e38\u4ea7\u751f\u5316\u5b66\u4e0a\u65e0\u6548\u7684\u5206\u5b50\uff0c\u5bfc\u81f4\u53ef\u7528\u5316\u5b66\u7a7a\u95f4\u53d7\u9650\u3001\u964d\u4f4e\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002\u9700\u8981\u4e00\u4e2a\u80fd\u4fee\u6b63\u65e0\u6548\u5206\u5b50\u3001\u4fdd\u6301\u5316\u5b66\u4e0e\u751f\u7269\u5206\u5e03\u7279\u5f81\u7684\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u8f93\u51fa\u8d28\u91cf\u5e76\u6269\u5927\u6f5c\u5728\u836f\u7269\u5019\u9009\u96c6\u5408\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eTransformer\u7684ChemFixer\u6846\u67b6\uff0c\u5229\u7528\u63a9\u7801\u5316\u9884\u8bad\u7ec3\uff0c\u5e76\u5728\u4e00\u4e2a\u7531\u5927\u91cf\u6709\u6548/\u65e0\u6548\u5206\u5b50\u5bf9\u6784\u6210\u7684\u89c4\u6a21\u5316\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\u3002\u901a\u8fc7\u5bf9\u4e0d\u540c\u751f\u6210\u6a21\u578b\u7684\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u5176\u5728\u7ea0\u6b63\u65e0\u6548\u6027\u540c\u65f6\u5c3d\u91cf\u4fdd\u7559\u539f\u8f93\u51fa\u7684\u5316\u5b66\u4e0e\u751f\u7269\u5206\u5e03\u3002", "result": "ChemFixer\u663e\u8457\u63d0\u5347\u4e86\u591a\u79cd\u751f\u6210\u6a21\u578b\u7684\u5206\u5b50\u6709\u6548\u6027\uff0c\u540c\u65f6\u5728\u4fdd\u6301\u539f\u8f93\u51fa\u5206\u5e03\u7279\u5f81\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u80fd\u591f\u6062\u590d\u6b64\u524d\u65e0\u6cd5\u751f\u6210\u7684\u5206\u5b50\uff0c\u6269\u5c55\u6f5c\u5728\u836f\u7269\u5019\u9009\u7684\u591a\u6837\u6027\u3002\u6b64\u5916\uff0c\u5728DTI\u4efb\u52a1\u4e2d\u5bf9\u6570\u636e\u6709\u9650\u7684\u573a\u666f\u4e5f\u8868\u73b0\u51fa\u826f\u597d\u6548\u679c\uff0c\u63d0\u5347\u751f\u6210\u914d\u4f53\u7684\u6709\u6548\u6027\u5e76\u53d1\u73b0\u6f5c\u5728\u7684\u914d\u4f53-\u86cb\u767d\u5bf9\u3002", "conclusion": "ChemFixer\u4f5c\u4e3a\u4e00\u4e2a\u5b9e\u7528\u5de5\u5177\uff0c\u80fd\u591f\u5728\u836f\u7269\u53d1\u73b0\u7684\u5404\u9636\u6bb5\u63d0\u5347\u5206\u5b50\u6709\u6548\u6027\u5e76\u6269\u5c55\u53ef\u8fbe\u7684\u5316\u5b66\u7a7a\u95f4\uff0c\u4e14\u5177\u5907\u5bf9\u6570\u636e\u6709\u9650\u573a\u666f\u548c\u4e0b\u6e38\u4efb\u52a1\u7684\u826f\u597d\u9002\u5e94\u6027\u3002"}}
{"id": "2511.14045", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.14045", "abs": "https://arxiv.org/abs/2511.14045", "authors": ["Yule Liu", "Heyi Zhang", "Jinyi Zheng", "Zhen Sun", "Zifan Peng", "Tianshuo Cong", "Yilong Yang", "Xinlei He", "Zhuo Ma"], "title": "GRPO Privacy Is at Risk: A Membership Inference Attack Against Reinforcement Learning With Verifiable Rewards", "comment": null, "summary": "Membership inference attacks (MIAs) on large language models (LLMs) pose significant privacy risks across various stages of model training. Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) have brought a profound paradigm shift in LLM training, particularly for complex reasoning tasks. However, the on-policy nature of RLVR introduces a unique privacy leakage pattern: since training relies on self-generated responses without fixed ground-truth outputs, membership inference must now determine whether a given prompt (independent of any specific response) is used during fine-tuning. This creates a threat where leakage arises not from answer memorization.\n  To audit this novel privacy risk, we propose Divergence-in-Behavior Attack (DIBA), the first membership inference framework specifically designed for RLVR. DIBA shifts the focus from memorization to behavioral change, leveraging measurable shifts in model behavior across two axes: advantage-side improvement (e.g., correctness gain) and logit-side divergence (e.g., policy drift). Through comprehensive evaluations, we demonstrate that DIBA significantly outperforms existing baselines, achieving around 0.8 AUC and an order-of-magnitude higher TPR@0.1%FPR. We validate DIBA's superiority across multiple settings--including in-distribution, cross-dataset, cross-algorithm, black-box scenarios, and extensions to vision-language models. Furthermore, our attack remains robust under moderate defensive measures.\n  To the best of our knowledge, this is the first work to systematically analyze privacy vulnerabilities in RLVR, revealing that even in the absence of explicit supervision, training data exposure can be reliably inferred through behavioral traces.", "AI": {"tldr": "\u63d0\u51faDIBA\uff0c\u4e00\u79cd\u9762\u5411RLVR\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff0c\u57fa\u4e8e\u884c\u4e3a\u5dee\u5f02\u800c\u975e\u8bb0\u5fc6\uff0c\u80fd\u5728\u591a\u573a\u666f\u4e2d\u5b9e\u73b0\u9ad8AUC\uff08\u7ea60.8\uff09\u4e0eTPR@0.1%FPR\u7684\u663e\u8457\u63d0\u5347\uff0c\u5e76\u5bf9\u5e38\u89c1\u9632\u5fa1\u5177\u6709\u9c81\u68d2\u6027\u3002", "motivation": "RLVR\u8bad\u7ec3\u7684\u5728\u7b56\u7565\u81ea\u751f\u6210\u6570\u636e\u4e0a\u8fdb\u884c\u5728\u7ebf\u4f18\u5316\uff0c\u5bfc\u81f4\u9690\u79c1\u6cc4\u9732\u7684\u65b0\u578b\u6a21\u5f0f\uff1b\u73b0\u6709MIA\u7814\u7a76\u591a\u805a\u7126\u8bb0\u5fc6\u5316\u63a8\u65ad\uff0c\u7f3a\u4e4f\u5bf9RLVR\u60c5\u5883\u7684\u5ba1\u8ba1\u6846\u67b6\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9\u884c\u4e3a\u53d8\u5316\u7684\u653b\u51fb\u6765\u8bc4\u4f30\u9690\u79c1\u98ce\u9669\u3002", "method": "\u63d0\u51faDIBA\uff08Divergence-in-Behavior Attack\uff09\uff0c\u901a\u8fc7\u8861\u91cf\u4e24\u6761\u884c\u4e3a\u8f74\u6765\u63a8\u65ad\u6210\u5458\u8eab\u4efd\uff1a\u4f18\u52bf\u7aef\u6539\u8fdb\uff08\u5982\u6b63\u786e\u6027\u63d0\u5347\uff09\u4e0e\u5bf9\u6570\u7aef\u5206\u6b67\uff08\u5982\u7b56\u7565\u6f02\u79fb\uff09\u3002\u8be5\u6846\u67b6\u53ef\u5728\u6709\u76d1\u7763/\u65e0\u76d1\u7763\u3001\u5206\u5e03\u5185\u5916\u3001\u8de8\u6570\u636e\u96c6\u3001\u8de8\u7b97\u6cd5\u3001\u9ed1\u76d2\u53ca\u6269\u5c55\u5230\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u7b49\u591a\u79cd setting \u4e0b\u4f7f\u7528\uff0c\u5e76\u5bf9\u4e2d\u7b49\u9632\u5fa1\u5177\u6709\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793aDIBA\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u7ea60.8\u7684AUC\uff0c\u4ee5\u53caTPR@0.1%FPR\u63d0\u5347\u4e00\u4e2a\u91cf\u7ea7\u4ee5\u4e0a\uff1b\u5728\u591a\u573a\u666f\uff08\u5305\u62ec\u5206\u5e03\u5185\u3001\u8de8\u6570\u636e\u96c6\u3001\u8de8\u7b97\u6cd5\u3001\u9ed1\u76d2\u3001Vision-Language\u6a21\u578b\u6269\u5c55\uff09\u5747\u5c55\u73b0\u4f18\u52bf\u3002", "conclusion": "\u9996\u6b21\u7cfb\u7edf\u63ed\u793aRLVR\u573a\u666f\u4e0b\u7684\u9690\u79c1\u8106\u5f31\u6027\uff0c\u5373\u4f7f\u7f3a\u4e4f\u663e\u5f0f\u76d1\u7763\uff0c\u4e5f\u53ef\u901a\u8fc7\u8bad\u7ec3\u884c\u4e3a\u8f68\u8ff9\u63a8\u65ad\u8bad\u7ec3\u6570\u636e\u662f\u5426\u88ab\u7528\u4e8e\u5fae\u8c03\uff0c\u63ed\u793a\u4e86\u5bf9RLVR\u7684\u9690\u79c1\u98ce\u9669\u9700\u8981\u4e13\u95e8\u8bc4\u4f30\u4e0e\u9632\u62a4\u3002"}}
{"id": "2511.13759", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13759", "abs": "https://arxiv.org/abs/2511.13759", "authors": ["Han Wang", "Deyi Ji", "Junyu Lu", "Lanyun Zhu", "Hailong Zhang", "Haiyang Wu", "Liqun Liu", "Peng Shu", "Roy Ka-Wei Lee"], "title": "Multi-Agent VLMs Guided Self-Training with PNU Loss for Low-Resource Offensive Content Detection", "comment": "8 pages, 4 figures, Fortieth AAAI Conference on Artificial Intelligence (AAAI-26)", "summary": "Accurate detection of offensive content on social media demands high-quality labeled data; however, such data is often scarce due to the low prevalence of offensive instances and the high cost of manual annotation. To address this low-resource challenge, we propose a self-training framework that leverages abundant unlabeled data through collaborative pseudo-labeling. Starting with a lightweight classifier trained on limited labeled data, our method iteratively assigns pseudo-labels to unlabeled instances with the support of Multi-Agent Vision-Language Models (MA-VLMs). Un-labeled data on which the classifier and MA-VLMs agree are designated as the Agreed-Unknown set, while conflicting samples form the Disagreed-Unknown set. To enhance label reliability, MA-VLMs simulate dual perspectives, moderator and user, capturing both regulatory and subjective viewpoints. The classifier is optimized using a novel Positive-Negative-Unlabeled (PNU) loss, which jointly exploits labeled, Agreed-Unknown, and Disagreed-Unknown data while mitigating pseudo-label noise. Experiments on benchmark datasets demonstrate that our framework substantially outperforms baselines under limited supervision and approaches the performance of large-scale models", "AI": {"tldr": "\u57fa\u4e8e\u81ea\u8bad\u7ec3\u7684\u534f\u4f5c\u4f2a\u6807\u7b7e\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u4e0e\u6587\u672c\u5206\u7c7b\u5668\u7684\u5171\u8bc6\u6765\u63d0\u5347\u4f4e\u8d44\u6e90\u4e0b\u7684 offensive content \u68c0\u6d4b\uff0c\u63a5\u8fd1\u5927\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e offensive content \u7684\u6807\u6ce8\u7a00\u7f3a\u3001\u4f4e\u53d1\u751f\u7387\u4ee5\u53ca\u9ad8\u6807\u6ce8\u6210\u672c\uff0c\u8feb\u5207\u9700\u8981\u5145\u5206\u5229\u7528\u6d77\u91cf\u672a\u6807\u6ce8\u6570\u636e\uff0c\u964d\u4f4e\u5bf9\u9ad8\u6210\u672c\u6807\u7b7e\u7684\u4f9d\u8d56\u3002", "method": "\u4ece\u4e00\u4e2a\u5c0f\u578b\u6807\u6ce8\u96c6\u8bad\u7ec3\u7684\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u51fa\u53d1\uff0c\u5bf9\u672a\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u8fed\u4ee3\u4f2a\u6807\u7b7e\uff1b\u5206\u7c7b\u5668\u4e0e MA-VLMs \u7684\u8f93\u51fa\u8fdb\u884c\u6bd4\u5bf9\uff0c\u5c06\u672a\u6807\u6ce8\u6570\u636e\u5206\u4e3a Agreed-Unknown\uff08 classifier \u4e0e MA-VLMs \u540c\u610f\u7684\u672a\u77e5\u6807\u7b7e\uff09\u548c Disagreed-Unknown\uff08\u5b58\u5728\u5206\u6b67\u7684\u672a\u77e5\u6837\u672c\uff09\u3002MA-VLMs \u901a\u8fc7 moderator \u4e0e user \u4e24\u4e2a\u89c6\u89d2\u6765\u6a21\u62df\u76d1\u7ba1\u548c\u4e3b\u89c2\u89c2\u70b9\u4ee5\u63d0\u5347\u6807\u7b7e\u53ef\u4fe1\u5ea6\uff1b\u4f7f\u7528\u65b0\u9896\u7684 Positive-Negative-Unlabeled (PNU) \u635f\u5931\uff0c\u8054\u5408\u5229\u7528\u6709\u6807\u7b7e\u6570\u636e\u3001Agreed-Unknown \u4e0e Disagreed-Unknown \u6570\u636e\uff0c\u540c\u65f6\u6291\u5236\u4f2a\u6807\u7b7e\u566a\u58f0\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u4ec5\u6709\u5c11\u91cf\u76d1\u7763\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0c\u672c\u6846\u67b6\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u4e14\u63a5\u8fd1\u5927\u89c4\u6a21\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u534f\u4f5c\u4f2a\u6807\u7b7e\u548c PNU \u635f\u5931\uff0c\u5145\u5206\u5229\u7528\u672a\u6807\u8bb0\u6570\u636e\uff0c\u63d0\u5347\u4f4e\u8d44\u6e90\u6761\u4ef6\u4e0b\u7684 offensive content \u68c0\u6d4b\u6548\u679c\uff0c\u964d\u4f4e\u4f2a\u6807\u7b7e\u566a\u58f0\uff0c\u5177\u6709\u8f83\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.14074", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14074", "abs": "https://arxiv.org/abs/2511.14074", "authors": ["Ajesh Koyatan Chathoth", "Stephen Lee"], "title": "Dynamic Black-box Backdoor Attacks on IoT Sensory Data", "comment": null, "summary": "Sensor data-based recognition systems are widely used in various applications, such as gait-based authentication and human activity recognition (HAR). Modern wearable and smart devices feature various built-in Inertial Measurement Unit (IMU) sensors, and such sensor-based measurements can be fed to a machine learning-based model to train and classify human activities. While deep learning-based models have proven successful in classifying human activity and gestures, they pose various security risks. In our paper, we discuss a novel dynamic trigger-generation technique for performing black-box adversarial attacks on sensor data-based IoT systems. Our empirical analysis shows that the attack is successful on various datasets and classifier models with minimal perturbation on the input data. We also provide a detailed comparative analysis of performance and stealthiness to various other poisoning techniques found in backdoor attacks. We also discuss some adversarial defense mechanisms and their impact on the effectiveness of our trigger-generation technique.", "AI": {"tldr": "\u5bf9\u4f20\u611f\u5668\u6570\u636e\u57fa\u7684\u8bc6\u522b\u7cfb\u7edf\u7684\u9ed1\u7bb1\u5bf9\u6297\u653b\u51fb\u63d0\u51fa\u4e00\u79cd\u52a8\u6001\u89e6\u53d1\u751f\u6210\u6280\u672f\uff0c\u80fd\u4ee5\u6700\u5c0f\u6270\u52a8\u5bf9\u591a\u6570\u636e\u96c6\u548c\u5206\u7c7b\u6a21\u578b\u8fdb\u884c\u653b\u51fb\uff0c\u6bd4\u8f83\u5176\u5b83\u4e2d\u6bd2/\u540e\u95e8\u6280\u672f\u5e76\u8ba8\u8bba\u9632\u5fa1\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u4ee3\u53ef\u7a7f\u6234\u8bbe\u5907\u4e2d\u7684IMU\u4f20\u611f\u5668\u5e7f\u6cdb\u4f7f\u7528\uff0c\u6df1\u5ea6\u5b66\u4e60\u5206\u7c7b\u6a21\u578b\u6613\u53d7\u5bf9\u6297\u653b\u51fb\u548c\u540e\u95e8\u653b\u51fb\u5f71\u54cd\uff0c\u9700\u7406\u89e3\u548c\u8bc4\u4f30\u65b0\u578b\u89e6\u53d1\u7b56\u7565\u53ca\u5176\u9632\u5fa1\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u89e6\u53d1\u751f\u6210\u6280\u672f\u7528\u4e8e\u5bf9\u4f20\u611f\u5668\u6570\u636e\u57faIoT\u7cfb\u7edf\u7684\u9ed1\u7bb1\u5bf9\u6297\u653b\u51fb\uff1b\u5728\u591a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u6bd4\u8f83\u5176\u5728\u6027\u80fd\u4e0e\u9690\u853d\u6027\u65b9\u9762\u4e0e\u5176\u4ed6\u4e2d\u6bd2\u6280\u672f\u7684\u5dee\u5f02\uff0c\u5e76\u63a2\u8ba8\u53ef\u7528\u7684\u9632\u5fa1\u673a\u5236\u53ca\u5176\u6548\u679c\u3002", "result": "\u653b\u51fb\u5728\u5404\u79cd\u6570\u636e\u96c6\u548c\u5206\u7c7b\u6a21\u578b\u4e0a\u4ee5\u6700\u5c0f\u6270\u52a8\u53d6\u5f97\u6210\u529f\uff1b\u5728\u9690\u853d\u6027\u4e0e\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u6216\u7b49\u540c\u4e8e\u5176\u4ed6\u4e2d\u6bd2\u6280\u672f\uff1b\u7ed9\u51fa\u9632\u5fa1\u673a\u5236\u5bf9\u653b\u51fb\u6709\u6548\u6027\u7684\u5f71\u54cd\u5206\u6790\u3002", "conclusion": "\u8be5\u52a8\u6001\u89e6\u53d1\u751f\u6210\u6280\u672f\u8bc1\u5b9e\u4e86\u4f20\u611f\u5668\u6570\u636e\u57faIoT\u7cfb\u7edf\u5728\u9ed1\u7bb1\u5bf9\u6297\u653b\u51fb\u4e0a\u7684\u8106\u5f31\u6027\uff0c\u63d0\u793a\u9700\u8981\u52a0\u5f3a\u9c81\u68d2\u6027\u9632\u5fa1\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\uff0c\u5982\u6269\u5c55\u6570\u636e\u96c6\u3001\u5b9e\u5730\u573a\u666f\u8bc4\u4f30\u548c\u9632\u5fa1\u7b56\u7565\u7684\u7efc\u5408\u8bc4\u4f30\u3002"}}
{"id": "2511.13927", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.13927", "abs": "https://arxiv.org/abs/2511.13927", "authors": ["Timothy Everett Adams", "Steven Dahdah", "James Richard Forbes"], "title": "dkpy: Robust Control with Structured Uncertainty in Python", "comment": "8 pages, 13 figures", "summary": "Models used for control design are, to some degree, uncertain. Model uncertainty must be accounted for to ensure the robustness of the closed-loop system. $\u03bc$-analysis and $\u03bc$-synthesis methods allow for the analysis and design of controllers subject to structured uncertainties. Moreover, these tools can be applied to robust performance problems as they are fundamentally robust control problems with structured uncertainty. The contribution of this paper is dkpy, an open-source Python package for performing robust controller analysis and synthesis for systems subject to structured uncertainty. dkpy also provides tools for performing model uncertainty characterization using data from a set of perturbed systems. The open-source project can be found at https://github.com/decargroup/dkpy.", "AI": {"tldr": "dkpy: an open-source Python package for robust controller analysis and synthesis under structured uncertainties, including uncertainty characterization from data.", "motivation": "Robust control requires accounting for model uncertainty to ensure stability and performance. \u03bc-analysis and \u03bc-synthesis provide a structured framework for analysis and design under uncertainty.", "method": "Implements \u03bc-analysis/synthesis algorithms and tools for uncertainty characterization from perturbed-system data; open-source at GitHub.", "result": "A software package enabling robust analysis and synthesis and data-driven uncertainty characterization for systems with structured uncertainty.", "conclusion": "dkpy lowers the barrier to robust controller design and uncertainty analysis, benefiting researchers and practitioners."}}
{"id": "2511.13760", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.13760", "abs": "https://arxiv.org/abs/2511.13760", "authors": ["Xiao Fan", "Jingyan Jiang", "Zhaoru Chen", "Fanding Huang", "Xiao Chen", "Qinting Jiang", "Bowen Zhang", "Xing Tang", "Zhi Wang"], "title": "MoETTA: Test-Time Adaptation Under Mixed Distribution Shifts with MoE-LayerNorm", "comment": "Accepted by AAAI 2026 Main Technical Track", "summary": "Test-Time adaptation (TTA) has proven effective in mitigating performance drops under single-domain distribution shifts by updating model parameters during inference. However, real-world deployments often involve mixed distribution shifts, where test samples are affected by diverse and potentially conflicting domain factors, posing significant challenges even for SOTA TTA methods. A key limitation in existing approaches is their reliance on a unified adaptation path, which fails to account for the fact that optimal gradient directions can vary significantly across different domains. Moreover, current benchmarks focus only on synthetic or homogeneous shifts, failing to capture the complexity of real-world heterogeneous mixed distribution shifts. To address this, we propose MoETTA, a novel entropy-based TTA framework that integrates the Mixture-of-Experts (MoE) architecture. Rather than enforcing a single parameter update rule for all test samples, MoETTA introduces a set of structurally decoupled experts, enabling adaptation along diverse gradient directions. This design allows the model to better accommodate heterogeneous shifts through flexible and disentangled parameter updates. To simulate realistic deployment conditions, we introduce two new benchmarks: potpourri and potpourri+. While classical settings focus solely on synthetic corruptions, potpourri encompasses a broader range of domain shifts--including natural, artistic, and adversarial distortions--capturing more realistic deployment challenges. Additionally, potpourri+ further includes source-domain samples to evaluate robustness against catastrophic forgetting. Extensive experiments across three mixed distribution shifts settings show that MoETTA consistently outperforms strong baselines, establishing SOTA performance and highlighting the benefit of modeling multiple adaptation directions via expert-level diversity.", "AI": {"tldr": "\u63d0\u51fa MoETTA\uff1a\u57fa\u4e8e\u71b5\u7684 TTA \u6846\u67b6\uff0c\u7ed3\u5408 Mixture-of-Experts \u5b9e\u73b0\u5bf9\u6df7\u5408\u5206\u5e03\u504f\u79fb\u7684\u591a\u65b9\u5411\u81ea\u9002\u5e94\u3002\u5f15\u5165 potpourri \u4e0e potpourri+ \u57fa\u51c6\u4ee5\u6a21\u62df\u73b0\u5b9e\u90e8\u7f72\u573a\u666f\uff0c\u540e\u8005\u8fd8\u5305\u542b\u6e90\u57df\u6570\u636e\u4ee5\u8bc4\u4f30\u9057\u5fd8\u9c81\u68d2\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u4e09\u7c7b\u6df7\u5408\u5206\u5e03\u504f\u79fb\u8bbe\u5b9a\u4e0b\uff0cMoETTA \u8d85\u8d8a\u5f3a\u57fa\u7ebf\uff0c\u8fbe\u5230 SOTA\uff0c\u5e76\u5c55\u793a\u901a\u8fc7\u4e13\u5bb6\u7ea7\u591a\u6837\u6027\u5b9e\u73b0\u4e0d\u540c\u65b9\u5411\u7684\u81ea\u9002\u5e94\u66f4\u65b0\u7684\u4f18\u52bf\u3002", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u6d4b\u8bd5\u6570\u636e\u5f80\u5f80\u5b58\u5728\u591a\u57df\u4e14\u76f8\u4e92\u51b2\u7a81\u7684\u5206\u5e03\u504f\u79fb\uff0c\u5355\u4e00\u8def\u5f84\u7684\u68af\u5ea6\u66f4\u65b0\u5728\u4e0d\u540c\u57df\u4e0a\u672a\u5fc5\u6700\u4f18\uff0c\u73b0\u6709 TTA \u591a\u4e3a\u7edf\u4e00\u9002\u5e94\u8def\u5f84\uff0c\u5ffd\u7565\u4e86\u57df\u95f4\u68af\u5ea6\u65b9\u5411\u7684\u5dee\u5f02\uff0c\u4e14\u8bc4\u4f30\u57fa\u51c6\u4ec5\u9650\u4e8e\u5408\u6210\u6216\u5355\u4e00\u504f\u79fb\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u90e8\u7f72\u7684\u590d\u6742\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u71b5\u57fa TTA \u6846\u67b6 MoETTA\uff0c\u7ed3\u5408 Mixture-of-Experts\uff08MoE\uff09\u67b6\u6784\u3002\u5f15\u5165\u4e00\u7ec4\u7ed3\u6784\u4e0a\u89e3\u8026\u7684\u4e13\u5bb6\u4ee5\u5b9e\u73b0\u5bf9\u4e0d\u540c\u57df\u68af\u5ea6\u65b9\u5411\u7684\u9002\u5e94\uff0c\u4e13\u5bb6\u95f4\u53ef\u5728\u4e0d\u540c\u65b9\u5411\u4e0a\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\u3002\u901a\u8fc7\u71b5\u6216\u95e8\u63a7\u673a\u5236\u5b9e\u73b0\u5bf9\u4e0d\u540c\u6837\u672c\u5206\u914d\u5230\u4e0d\u540c\u4e13\u5bb6\u7684\u7b56\u7565\uff0c\u63d0\u5347\u5bf9\u5f02\u8d28\u504f\u79fb\u7684\u9002\u5e94\u80fd\u529b\u3002\u8bbe\u8ba1\u4e86\u4e24\u5957\u65b0\u57fa\u51c6 potpourri \u4e0e potpourri+\uff0c\u8986\u76d6\u81ea\u7136\u3001\u827a\u672f\u5316\u3001\u5bf9\u6297\u6027\u5931\u771f\u7b49\u591a\u6e90\u504f\u79fb\uff1bpotpourri+ \u8fd8\u5305\u542b\u6e90\u57df\u6837\u672c\u4ee5\u8bc4\u4f30\u707e\u53d8\u9057\u5fd8\u3002", "result": "\u5728\u4e09\u7c7b\u6df7\u5408\u5206\u5e03\u504f\u79fb\u8bbe\u5b9a\u4e0b\uff0cMoETTA \u6301\u7eed\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u8fbe\u5230 SOTA \u6027\u80fd\uff0c\u5e76\u5f3a\u8c03\u901a\u8fc7\u4e13\u5bb6\u7ea7\u591a\u6837\u6027\u5efa\u6a21\u6765\u83b7\u5f97\u591a\u65b9\u5411\u81ea\u9002\u5e94\u7684\u4f18\u52bf\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165 MoE \u53ca\u71b5\u57fa\u95e8\u63a7\u673a\u5236\uff0cMoETTA \u80fd\u66f4\u597d\u5730\u5e94\u5bf9\u5f02\u8d28\u5206\u5e03\u504f\u79fb\u5e76\u964d\u4f4e\u707e\u53d8\u9057\u5fd8\u98ce\u9669\uff0c\u65b0\u7684 potpourri/potpourri+ \u57fa\u51c6\u63d0\u4f9b\u66f4\u63a5\u8fd1\u73b0\u5b9e\u90e8\u7f72\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u591a\u4e13\u5bb6\u534f\u4f5c\u7684\u81ea\u9002\u5e94\u66f4\u65b0\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2511.14088", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14088", "abs": "https://arxiv.org/abs/2511.14088", "authors": ["Adam Caulfield", "Muhammad Wasif Kamran", "N. Asokan"], "title": "Resolving Availability and Run-time Integrity Conflicts in Real-Time Embedded Systems", "comment": null, "summary": "Run-time integrity enforcement in real-time systems presents a fundamental conflict with availability. Existing approaches in real- time systems primarily focus on minimizing the execution-time overhead of monitoring. After a violation is detected, prior works face a trade-off: (1) prioritize availability and allow a compromised system to continue to ensure applications meet their deadlines, or (2) prioritize security by generating a fault to abort all execution. In this work, we propose PAIR, an approach that offers a middle ground between the stark extremes of this trade-off. PAIR monitors real-time tasks for run-time integrity violations and maintains an Availability Region (AR) of all tasks that are safe to continue. When a task causes a violation, PAIR triggers a non-maskable interrupt to kill the task and continue executing a non-violating task within AR. Thus, PAIR ensures only violating tasks are prevented from execution, while granting availability to remaining tasks. With its hardware approach, PAIR does not cause any run-time overhead to the executing tasks, integrates with real-time operating systems (RTOSs), and is affordable to low-end microcontroller units (MCUs) by incurring +2.3% overhead in memory and hardware usage.", "AI": {"tldr": "\u63d0\u51fa PAIR\uff0c\u4e00\u79cd\u5728\u5b9e\u65f6\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u8fd0\u884c\u65f6\u5b8c\u6574\u6027\u4e0e\u53ef\u7528\u6027\u4e4b\u95f4\u6743\u8861\u7684\u786c\u4ef6\u5316\u76d1\u63a7\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ef4\u62a4\u53ef\u7528\u6027\u533a\u57df AR\uff0c\u5728\u4efb\u52a1\u8fdd\u89c4\u65f6\u901a\u8fc7\u4e0d\u53ef\u5c4f\u853d\u4e2d\u65ad\u5c06\u5176\u7ec8\u6b62\uff0c\u5176\u4f59\u4efb\u52a1\u4fdd\u6301\u53ef\u7528\u6027\uff1b\u5bf9\u4f4e\u7aef MCU \u4ec5\u589e\u52a0\u7ea6 2.3% \u7684\u5185\u5b58\u4e0e\u786c\u4ef6\u5f00\u9500\u3002", "motivation": "\u5b9e\u65f6\u7cfb\u7edf\u7684\u8fd0\u884c\u65f6\u5b8c\u6574\u6027\u76d1\u63a7\u901a\u5e38\u589e\u52a0\u6267\u884c\u5f00\u9500\uff1b\u9762\u4e34\u5728\u4fdd\u8bc1\u7cfb\u7edf\u5b89\u5168\u548c\u6ee1\u8db3 deadlines \u4e4b\u95f4\u7684\u4e24\u96be\u9009\u62e9\u3002\u9700\u8981\u4e00\u4e2a\u4ecb\u4e8e\u4e24\u7aef\u7684\u65b9\u6848\uff0c\u5b9e\u73b0\u9009\u62e9\u6027\u4e2d\u6b62\u8fdd\u89c4\u4efb\u52a1\u4ee5\u7ef4\u6301\u53ef\u7528\u6027\u3002", "method": "\u63d0\u51fa PAIR\uff0c\u57fa\u4e8e\u786c\u4ef6\u5b9e\u73b0\u7684\u8fd0\u884c\u65f6\u5b8c\u6574\u6027\u76d1\u63a7\uff0c\u7ef4\u62a4\u4e00\u4e2a AR\uff0c\u82e5\u4efb\u52a1\u8fdd\u53cd\u5219\u89e6\u53d1\u975e\u5c4f\u853d\u4e2d\u65ad\u7ec8\u6b62\u8be5\u4efb\u52a1\uff0c\u5141\u8bb8 AR \u4e2d\u7684\u5176\u4ed6\u4efb\u52a1\u7ee7\u7eed\u6267\u884c\uff1b\u5bf9\u6b63\u5728\u6267\u884c\u7684\u4efb\u52a1\u65e0\u989d\u5916\u8fd0\u884c\u65f6\u5f00\u9500\uff0c\u4e14\u5bf9\u4f4e\u7aef MCU \u53cb\u597d\uff0c\u5185\u5b58\u548c\u786c\u4ef6\u5f00\u9500\u7ea6 +2.3%\u3002", "result": "\u5b9e\u73b0\u673a\u5236\u80fd\u591f\u4fdd\u8bc1\u53ea\u6709\u8fdd\u89c4\u4efb\u52a1\u88ab\u963b\u6b62\u6267\u884c\uff0c\u540c\u65f6\u7ef4\u6301\u7cfb\u7edf\u7684\u53ef\u7528\u6027\uff0c\u4e14\u5f15\u5165\u7684\u786c\u4ef6/\u5185\u5b58\u5f00\u9500\u8f83\u4f4e\u3002", "conclusion": "\u4e3a\u5b9e\u65f6\u7cfb\u7edf\u63d0\u4f9b\u4e00\u4e2a\u5728\u5b89\u5168\u6027\u4e0e\u53ef\u7528\u6027\u4e4b\u95f4\u7684\u6298\u4e2d\u65b9\u6848\uff0c\u6613\u4e8e\u4e0e RTOS \u96c6\u6210\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684 MCU\u3002"}}
{"id": "2511.13965", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.13965", "abs": "https://arxiv.org/abs/2511.13965", "authors": ["Yating Zou", "Batuhan Keskin", "Gregor G. Taylor", "Zenghui Li", "Jie Wang", "Eduard Alarcon", "Fabio Sebastiano", "Masoud Babaie", "Edoardo Charbon"], "title": "Power Delivery for Cryogenic Scalable Quantum Applications: Challenges and Opportunities", "comment": "5 pages, 4 figures", "summary": "Quantum technologies offer unprecedented capabilities in computation and secure information transfer. Their implementation requires qubits to operate at cryogenic temperatures (CT) while control and readout electronics typically still remains at room temperature (RT). As systems scale to millions of qubits, the electronics should also operate at CT to avoid a wiring bottleneck. However, wired power transfer from RT for such electronics introduces severe challenges, including thermal load between cooling stages, Joule heating, noise coupling, and wiring scalability. This paper addresses those challenges by evaluating several candidate architectures for scalable power transfer in the dilution frige: high-voltage (HV) wired power transfer, radiative wireless transfer, non-radiative wireless transfer, and a hybrid HV and non-radiative transfer. These architectures are analyzed in terms of thermal load, power loss, heating, coupling noise, power density, scalability, reliability, and complexity. Comparative analysis demonstrates the trade-offs among these architectures, while highlighting HV non-radiative transfer as a promising candidate for scalable quantum systems.", "AI": {"tldr": "HV\u975e\u8f90\u5c04\u6709\u7ebf\u4f9b\u7535\u5728\u53ef\u6269\u5c55\u91cf\u5b50\u7cfb\u7edf\u4e2d\u6700\u5177\u6f5c\u529b\uff0c\u6743\u8861\u70ed\u8d1f\u8377\u3001\u566a\u58f0\u8026\u5408\u4e0e\u6269\u5c55\u6027\u7b49\u56e0\u7d20\u3002", "motivation": "\u4e3a\u767e\u4e07\u91cf\u7ea7\u91cf\u5b50\u6bd4\u7279\u7684\u51b7\u5374\u9700\u6c42\u8bbe\u8ba1\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u4f4e\u6e29\u4f9b\u7535\u65b9\u6848\uff0c\u89e3\u51b3\u6e29\u5dee\u5f15\u53d1\u7684\u70ed\u8d1f\u8377\u3001\u7ebf\u7f06\u6570\u91cf\u4e0e\u566a\u58f0\u95ee\u9898\u3002", "method": "\u5bf9HV\u6709\u7ebf\u4f9b\u7535\u3001\u8f90\u5c04\u5f0f\u65e0\u7ebf\u4f9b\u7535\u3001\u975e\u8f90\u5c04\u5f0f\u65e0\u7ebf\u4f9b\u7535\u4ee5\u53ca\u6df7\u5408HV\u4e0e\u975e\u8f90\u5c04\u65b9\u6848\u5728\u7a00\u91ca\u5236\u51b7\u673a\u73af\u5883\u4e2d\u7684\u53ef\u884c\u6027\u8fdb\u884c\u5b9a\u6027/\u5b9a\u91cf\u6bd4\u8f83\uff0c\u8bc4\u4f30\u70ed\u8d1f\u8377\u3001\u529f\u7387\u635f\u5931\u3001\u52a0\u70ed\u3001\u8026\u5408\u566a\u58f0\u3001\u529f\u7387\u5bc6\u5ea6\u3001\u53ef\u6269\u5c55\u6027\u3001\u53ef\u9760\u6027\u548c\u590d\u6742\u6027\u3002", "result": "\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\u63ed\u793a\u5404\u67b6\u6784\u7684\u6743\u8861\u4e0e\u9002\u7528\u573a\u666f\uff0c\u6307\u51faHV\u975e\u8f90\u5c04\u4f9b\u7535\u5728\u603b\u4f53\u6307\u6807\u4e0a\u5177\u5907\u8f83\u4f18\u5e73\u8861\uff0c\u6210\u4e3a\u53ef\u6269\u5c55\u91cf\u5b50\u7cfb\u7edf\u7684\u6709\u529b\u5019\u9009\u3002", "conclusion": "\u5728\u9762\u5411\u5927\u89c4\u6a21\u91cf\u5b50\u7cfb\u7edf\u7684\u4f9b\u7535\u9700\u6c42\u4e2d\uff0c\u4f18\u5148\u53d1\u5c55HV\u975e\u8f90\u5c04\u4f9b\u7535\u8def\u7ebf\uff0c\u4ee5\u5b9e\u73b0\u4f4e\u70ed\u8d1f\u8377\u3001\u4f4e\u566a\u58f0\u8026\u5408\u548c\u826f\u597d\u6269\u5c55\u6027\uff1b\u4f46\u9700\u8fdb\u4e00\u6b65\u5de5\u7a0b\u5316\u4f18\u5316\u4e0e\u5b9e\u9a8c\u9a8c\u8bc1\u3002"}}
{"id": "2511.13762", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2511.13762", "abs": "https://arxiv.org/abs/2511.13762", "authors": ["Jiaxin Qi", "Yan Cui", "Jianqiang Huang", "Gaogang Xie"], "title": "Gene Incremental Learning for Single-Cell Transcriptomics", "comment": "Accepted by AAAI 2026", "summary": "Classes, as fundamental elements of Computer Vision, have been extensively studied within incremental learning frameworks. In contrast, tokens, which play essential roles in many research fields, exhibit similar characteristics of growth, yet investigations into their incremental learning remain significantly scarce. This research gap primarily stems from the holistic nature of tokens in language, which imposes significant challenges on the design of incremental learning frameworks for them. To overcome this obstacle, in this work, we turn to a type of token, gene, for a large-scale biological dataset--single-cell transcriptomics--to formulate a pipeline for gene incremental learning and establish corresponding evaluations. We found that the forgetting problem also exists in gene incremental learning, thus we adapted existing class incremental learning methods to mitigate the forgetting of genes. Through extensive experiments, we demonstrated the soundness of our framework design and evaluations, as well as the effectiveness of our method adaptations. Finally, we provide a complete benchmark for gene incremental learning in single-cell transcriptomics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u56e0\u589e\u91cf\u5b66\u4e60\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u6570\u636e\uff0c\u6539\u7f16\u81ea\u7c7b\u589e\u91cf\u5b66\u4e60\u4ee5\u7f13\u89e3\u9057\u5fd8\uff0c\u7ed9\u51fa\u5b8c\u6574\u7684\u57fa\u56e0\u589e\u91cf\u5b66\u4e60\u57fa\u51c6\u3002", "motivation": "\u672c\u7814\u7a76\u4ee5\u5f80\u589e\u91cf\u5b66\u4e60\u591a\u5173\u6ce8\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u7c7b\u522b\u4e0e\u4ee4\u724c\uff0c\u7f3a\u4e4f\u5bf9\u4ee4\u724c\u7ea7\u522b\u589e\u91cf\u5b66\u4e60\u7684\u7cfb\u7edf\u7814\u7a76\u3002\u7531\u4e8e\u8bed\u8a00\u4e2d\u7684\u5168\u5c40\u6027\u4f7f\u589e\u91cf\u5b66\u4e60\u8bbe\u8ba1\u56f0\u96be\uff0c\u4f5c\u8005\u5c06\u7814\u7a76\u7126\u70b9\u8f6c\u5411\u4e00\u7c7b\u7279\u6b8a\u7684\u4ee4\u724c\u2014\u2014\u57fa\u56e0\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u751f\u7269\u6570\u636e\u96c6\u4e0a\u63d0\u51fa\u589e\u91cf\u5b66\u4e60\u7ba1\u7ebf\u4e0e\u8bc4\u4f30\uff0c\u4ee5\u586b\u8865\u65b9\u6cd5\u5b66\u7a7a\u767d\u3002", "method": "\u5c06\u73b0\u6709\u7684\u7c7b\u589e\u91cf\u5b66\u4e60\u65b9\u6cd5\u6539\u7f16\u7528\u4e8e\u57fa\u56e0\u589e\u91cf\u5b66\u4e60\uff0c\u7814\u7a76\u5e76\u7f13\u89e3\u9057\u5fd8\u73b0\u8c61\uff0c\u6784\u5efa\u589e\u91cf\u5b66\u4e60\u7ba1\u7ebf\u5e76\u5728\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u6570\u636e\u4e0a\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\u4ee5\u9a8c\u8bc1\u6846\u67b6\u4e0e\u9002\u914d\u7b56\u7565\u3002", "result": "\u53d1\u73b0\u57fa\u56e0\u589e\u91cf\u5b66\u4e60\u4e2d\u4e5f\u5b58\u5728\u9057\u5fd8\u95ee\u9898\uff0c\u9a8c\u8bc1\u4e86\u6539\u7f16\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u6846\u67b6\u8bbe\u8ba1\u4e0e\u8bc4\u4f30\u5177\u6709\u5408\u7406\u6027\uff0c\u6700\u7ec8\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u57fa\u56e0\u589e\u91cf\u5b66\u4e60\u57fa\u51c6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u57fa\u56e0\u589e\u91cf\u5b66\u4e60\u5728\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u7528\u7684\u6846\u67b6\u3001\u8bc4\u4f30\u548c\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u6807\u51c6\u5316\u4e0e\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2511.13764", "categories": ["cs.LG", "cs.PF", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.13764", "abs": "https://arxiv.org/abs/2511.13764", "authors": ["Arun Thangamani", "Md Asghar Ahmad Shahid", "Adam Siemieniuk", "Rolf Morel", "Renato Golin", "Alexander Heinecke"], "title": "Library Liberation: Competitive Performance Matmul Through Compiler-composed Nanokernels", "comment": null, "summary": "The rapidly evolving landscape of AI and machine learning workloads has widened the gap between high-level domain operations and efficient hardware utilization. Achieving near-peak performance still demands deep hardware expertise-experts either handcraft target-specific kernels (e.g., DeepSeek) or rely on specialized libraries (e.g., CUTLASS)-both of which add complexity and limit scalability for most ML practitioners.\n  This paper introduces a compilation scheme that automatically generates scalable, high-performance microkernels by leveraging the MLIR dialects to bridge domain-level operations and processor capabilities. Our approach removes dependence on low-level libraries by enabling the compiler to auto-generate near-optimal code directly. At its core is a mechanism for composing nanokernels from low-level IR constructs with near-optimal register utilization, forming efficient microkernels tailored to each target. We implement this technique in an MLIR-based compiler supporting both vector and tile based CPU instructions. Experiments show that the generated nanokernels are of production-quality, and competitive with state-of-the-art microkernel libraries.", "AI": {"tldr": "\u57fa\u4e8e MLIR \u7684\u7f16\u8bd1\u6846\u67b6\uff0c\u81ea\u52a8\u751f\u6210\u53ef\u6269\u5c55\u4e14\u9ad8\u6027\u80fd\u7684\u5fae\u5185\u6838\uff0c\u964d\u4f4e\u5bf9\u4f4e\u7ea7\u5e93\u7684\u4f9d\u8d56\uff0c\u5e76\u5728\u76ee\u6807 CPU \u7684\u5411\u91cf\u4e0e\u5206\u5757\u6307\u4ee4\u4e0a\u5b9e\u73b0\u8fd1\u4f3c\u6700\u4f18\u5bc4\u5b58\u5668\u5229\u7528\u3002", "motivation": "AI/ML \u5de5\u4f5c\u8d1f\u8f7d\u65e5\u76ca\u590d\u6742\uff0c\u4f46\u9ad8\u6548\u786c\u4ef6\u5229\u7528\u4ecd\u9700\u6df1\u539a\u786c\u4ef6\u77e5\u8bc6\uff1b\u624b\u5de5\u5185\u6838\u6216\u4f9d\u8d56\u4e13\u7528\u5e93\u96be\u4ee5\u6269\u5c55\u5230\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u901a\u8fc7 MLIR dialect\uff0c\u8bbe\u8ba1\u4e00\u79cd\u5c06\u9886\u57df\u64cd\u4f5c\u6620\u5c04\u5230\u5904\u7406\u5668\u80fd\u529b\u7684\u7f16\u8bd1\u65b9\u6848\uff0c\u5e76\u4ece\u4f4e\u7ea7 IR \u6784\u9020\u7eb3\u7c73\u5185\u6838\uff0c\u5b9e\u73b0\u9ad8\u6548\u5bc4\u5b58\u5668\u4f7f\u7528\uff1b\u652f\u6301\u5411\u91cf\u4e0e\u5206\u5757 CPU \u6307\u4ee4\u3002", "result": "\u751f\u6210\u7684 nanokernel \u8fbe\u5230\u751f\u4ea7\u7ea7\u8d28\u91cf\uff0c\u5e76\u4e0e\u73b0\u6709\u5fae\u5185\u6838\u5e93\u76f8\u7ade\u4e89\u3002", "conclusion": "\u8bc1\u660e\u4e86\u57fa\u4e8e MLIR \u7684\u81ea\u52a8\u5fae\u5185\u6838\u751f\u6210\u53ef\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\uff0c\u964d\u4f4e\u5bf9\u4e13\u7528\u5e93\u7684\u4f9d\u8d56\uff0c\u9002\u5408\u5e7f\u6cdb\u7684 ML \u5b9e\u8df5\u8005\u3002"}}
{"id": "2511.14132", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14132", "abs": "https://arxiv.org/abs/2511.14132", "authors": ["Kavya Bhand", "Payal Khubchandani", "Jyoti Khubchandani"], "title": "A Fuzzy Logic-Based Cryptographic Framework For Real-Time Dynamic Key Generation For Enhanced Data Encryption", "comment": null, "summary": "With the ever-growing demand for cybersecurity, static key encryption mechanisms are increasingly vulnerable to adversarial attacks due to their deterministic and non-adaptive nature. Brute-force attacks, key compromise, and unauthorized access have become highly common cyber threats. This research presents a novel fuzzy logic-based cryptographic framework that dynamically generates encryption keys in real-time by accessing system-level entropy and hardware-bound trust. The proposed system leverages a Fuzzy Inference System (FIS) to evaluate system parameters that include CPU utilization, process count, and timestamp variation. It assigns entropy level based on linguistically defined fuzzy rules which are fused with hardware-generated randomness and then securely sealed using a Trusted Platform Module (TPM). The sealed key is incorporated in an AES-GCM encryption scheme to ensure both confidentiality and integrity of the data. This system introduces a scalable solution for adaptive encryption in high-assurance computing, zero-trust environments, and cloud-based infrastructure.", "AI": {"tldr": "\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684\u52a8\u6001\u5bc6\u94a5\u751f\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u7cfb\u7edf\u71b5\u4e0e\u786c\u4ef6\u4fe1\u4efb\uff0c\u901a\u8fc7 TPM \u5c01\u88c5\u540e\u7528\u4e8e AES-GCM \u5b9e\u73b0\u81ea\u9002\u5e94\u52a0\u5bc6\u3002", "motivation": "\u89e3\u51b3\u9759\u6001\u5bc6\u94a5\u5728\u66b4\u529b\u653b\u51fb\u3001\u5bc6\u94a5\u6cc4\u9732\u548c\u672a\u6388\u6743\u8bbf\u95ee\u4e2d\u7684\u8106\u5f31\u6027\uff0c\u63d0\u4f9b\u5728\u9ad8\u5b89\u5168\u3001\u96f6\u4fe1\u4efb\u548c\u4e91\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u3001\u53ef\u6269\u5c55\u7684\u5bc6\u94a5\u751f\u6210\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u8bc4\u4f30\u7cfb\u7edf\u53c2\u6570\uff08CPU\u5229\u7528\u7387\u3001\u8fdb\u7a0b\u6570\u91cf\u3001\u65f6\u95f4\u6233\u53d8\u5316\u7b49\uff09\uff0c\u57fa\u4e8e\u6a21\u7cca\u89c4\u5219\u5206\u914d\u71b5\u7b49\u7ea7\uff1b\u5c06\u6b64\u71b5\u4e0e\u786c\u4ef6\u968f\u673a\u6027\u878d\u5408\uff0c\u5e76\u901a\u8fc7 TPM \u5c01\u88c5\uff0c\u5f62\u6210\u5bc6\u94a5\u5e76\u5d4c\u5165 AES-GCM \u4ee5\u4fdd\u8bc1\u6570\u636e\u7684\u673a\u5bc6\u6027\u548c\u5b8c\u6574\u6027\u3002", "result": "\u63d0\u51fa\u8bbe\u8ba1\u4e0e\u5b9e\u73b0\u601d\u8def\uff0c\u5f3a\u8c03\u53ef\u6269\u5c55\u6027\u548c\u5bf9\u9ad8\u5b89\u5168\u73af\u5883\u7684\u9002\u7528\u6027\uff0c\u4f46\u672a\u5728\u6458\u8981\u4e2d\u7ed9\u51fa\u5b9e\u9a8c\u7ed3\u679c\uff0c\u9700\u540e\u7eed\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u81ea\u9002\u5e94\u52a0\u5bc6\u63d0\u4f9b\u53ef\u6269\u5c55\u65b9\u6848\uff0c\u7ed3\u5408\u786c\u4ef6\u4fe1\u4efb\u4e0e\u7cfb\u7edf\u71b5\u63d0\u5347\u5bc6\u94a5\u5b89\u5168\u6027\uff0c\u672a\u6765\u5de5\u4f5c\u5305\u62ec\u6027\u80fd\u8bc4\u4f30\u3001\u5bc6\u94a5\u7ba1\u7406\u7b56\u7565\u4ee5\u53ca\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u517c\u5bb9\u6027\u7814\u7a76\u3002"}}
{"id": "2511.14141", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.14141", "abs": "https://arxiv.org/abs/2511.14141", "authors": ["Grant Ruan", "Marija D. Ilic", "Le Xie"], "title": "Data Center Control Against Sub-Synchronous Resonance: A Data-Driven Approach", "comment": "12 pages, CIGRE Grid of the Future Symposium", "summary": "Data centers host a variety of essential services such as cloud computing and artificial intelligence. Electric grid operators, however, have limited knowledge of the reliability risks of data center interconnection due to their unique operational characteristics. An emerging concern is the sub-synchronous resonance (SSR) which refer to unexpected voltage/current oscillations at typical frequencies below 60/50 Hz. It remains unknown whether and how the interactions between data centers and the grid may trigger resonances, equipment damages, and even cascading failures. In this paper, we focus on grid-connected data centers that draw electricity from the grid through power factor correction (PFC) converters. We conduct two-tone frequency sweep to investigate the data centers' impedance characteristics, i.e. magnitude and phase angle variations over frequencies, and showcase their deep dependence on compute workloads. The impedance modeling provides a direct approach to evaluating SSR risks and enable a cooperative mechanism to alarm and avoid resonance-prone situations. Building upon the impedance, a data-driven preventive controller is then established to raise early warnings of risky operation and suggest flexible workload management according to the given grid conditions. Through case study, we demonstrate how to use impedance to understand the unexpected interactions. Data-driven impedance is validated to show decent performance in capturing the unique impedance dips and tracking the impedance variations across a range of workload scenarios. The early warning and preventive control approaches are further effective to improve the safety margins with minimal workload rescheduling. The key findings of this work will provide valuable insights for grid operators and data center managers, and support preparation for future scenarios involving large-scale data center integration.", "AI": {"tldr": "\u901a\u8fc7\u5bf9\u6570\u636e\u4e2d\u5fc3\u4e0e\u7535\u7f51\u8026\u5408\u7684\u963b\u6297\u7279\u6027\u53ca\u5176\u968f\u8ba1\u7b97\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\u7684\u4e24\u97f3\u626b\u9891\u5206\u6790\uff0c\u63d0\u51fa\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u963b\u6297\u7684\u65e9\u671f\u9884\u8b66\u4e0e\u81ea\u9002\u5e94\u5de5\u4f5c\u8d1f\u8f7d\u7ba1\u7406\u7b56\u7565\uff0c\u4ee5\u964d\u4f4e\u4e9a\u540c\u6b65\u8c10\u632fSSR\u7684\u98ce\u9669\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u901a\u8fc7PFC\u8f6c\u6362\u5668\u4ece\u7535\u7f51\u53d6\u7535\uff0c\u4e14\u5176\u4e0e\u7535\u7f51\u7684\u76f8\u4e92\u4f5c\u7528\u5bf9SSR\u53ca\u6f5c\u5728\u7ea7\u8054\u6545\u969c\u7684\u98ce\u9669\u8ba4\u8bc6\u4e0d\u8db3\uff1b\u9700\u8981\u5b9a\u91cf\u5316\u963b\u6297\u7279\u5f81\u5e76\u636e\u6b64\u5f00\u5c55\u9884\u8b66\u4e0e\u63a7\u5236\u3002", "method": "\u8fdb\u884c\u4e24\u97f3\u626b\u9891\u4ee5\u83b7\u53d6\u6570\u636e\u4e2d\u5fc3\u963b\u6297\uff08\u5e45\u503c\u3001\u76f8\u4f4d\uff09\u968f\u9891\u7387\u7684\u53d8\u5316\uff0c\u7814\u7a76\u5de5\u4f5c\u8d1f\u8f7d\u5bf9\u963b\u6297\u7684\u6df1\u523b\u5f71\u54cd\uff1b\u57fa\u4e8e\u963b\u6297\u5efa\u7acb\u6570\u636e\u9a71\u52a8\u7684\u53ef\u7528\u6027\u8bc4\u4f30\u4e0e\u65e9\u671f\u8b66\u62a5\u673a\u5236\uff0c\u5e76\u7ed9\u51fa\u5728\u7ed9\u5b9a\u7535\u7f51\u6761\u4ef6\u4e0b\u7684\u7075\u6d3b\u5de5\u4f5c\u8d1f\u8f7d\u8c03\u5ea6\u7b56\u7565\uff1b\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u963b\u6297\u5efa\u6a21\u3001\u9884\u8b66\u4e0e\u63a7\u5236\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u963b\u6297\u968f\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\u5b58\u5728\u660e\u663e\u7684\u963b\u6297\u8c37\uff0c\u80fd\u6355\u6349\u5230\u5de5\u4f5c\u8d1f\u8f7d\u5bfc\u81f4\u7684\u9891\u7387-\u963b\u6297\u7279\u5f81\uff1b\u6570\u636e\u9a71\u52a8\u963b\u6297\u80fd\u6709\u6548\u523b\u753b\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u963b\u6297\u53d8\u5316\u5e76\u7528\u4e8eSSR\u98ce\u9669\u8bc4\u4f30\uff1b\u65e9\u671f\u8b66\u62a5\u548c\u9884\u9632\u6027\u63a7\u5236\u53ef\u63d0\u9ad8\u5b89\u5168\u88d5\u5ea6\u4e14\u5bf9\u5de5\u4f5c\u8d1f\u8f7d\u91cd\u65b0\u5206\u914d\u7684\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "\u4e3a\u7535\u7f51\u8fd0\u7ef4\u4e0e\u6570\u636e\u4e2d\u5fc3\u7ba1\u7406\u8005\u63d0\u4f9b\u4e86\u5229\u7528\u963b\u6297\u89c6\u89d2\u7406\u89e3\u4e24\u8005\u8026\u5408\u3001\u5e76\u5728\u672a\u6765\u5927\u89c4\u6a21\u6570\u636e\u4e2d\u5fc3\u63a5\u5165\u60c5\u666f\u4e2d\u63d0\u5347\u5b89\u5168\u6027\u4e0e\u9c81\u68d2\u6027\u7684\u5de5\u5177\u4e0e\u65b9\u6cd5\u3002"}}
{"id": "2511.13765", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13765", "abs": "https://arxiv.org/abs/2511.13765", "authors": ["Shengjie Sun", "Jiafei Lyu", "Runze Liu", "Mengbei Yan", "Bo Liu", "Deheng Ye", "Xiu Li"], "title": "PROF: An LLM-based Reward Code Preference Optimization Framework for Offline Imitation Learning", "comment": null, "summary": "Offline imitation learning (offline IL) enables training effective policies without requiring explicit reward annotations. Recent approaches attempt to estimate rewards for unlabeled datasets using a small set of expert demonstrations. However, these methods often assume that the similarity between a trajectory and an expert demonstration is positively correlated with the reward, which oversimplifies the underlying reward structure. We propose PROF, a novel framework that leverages large language models (LLMs) to generate and improve executable reward function codes from natural language descriptions and a single expert trajectory. We propose Reward Preference Ranking (RPR), a novel reward function quality assessment and ranking strategy without requiring environment interactions or RL training. RPR calculates the dominance scores of the reward functions, where higher scores indicate better alignment with expert preferences. By alternating between RPR and text-based gradient optimization, PROF fully automates the selection and refinement of optimal reward functions for downstream policy learning. Empirical results on D4RL demonstrate that PROF surpasses or matches recent strong baselines across numerous datasets and domains, highlighting the effectiveness of our approach.", "AI": {"tldr": "PROF\u901a\u8fc7LLMs\u751f\u6210\u5e76\u6539\u8fdb\u79bb\u7ebfIL\u7684\u53ef\u6267\u884c\u5956\u52b1\u51fd\u6570\uff0c\u5e76\u7528RPR\u5728\u4e0d\u4f9d\u8d56\u73af\u5883\u4ea4\u4e92\u7684\u60c5\u51b5\u4e0b\u5bf9\u5956\u52b1\u51fd\u6570\u8fdb\u884c\u6392\u5e8f\uff0c\u4ece\u800c\u5728D4RL\u4e0a\u5b9e\u73b0\u5f3a\u7ade\u4e89\u529b\u3002", "motivation": "\u79bb\u7ebf\u6a21\u4eff\u5b66\u4e60\u9700\u8981\u5728\u7f3a\u4e4f\u5956\u52b1\u4fe1\u53f7\u7684\u6761\u4ef6\u4e0b\u5b66\u4e60\u7b56\u7565\uff1b\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u5047\u8bbe\u8f68\u8ff9\u4e0e\u4e13\u5bb6\u6f14\u793a\u7684\u76f8\u4f3c\u5ea6\u4e0e\u5956\u52b1\u6b63\u76f8\u5173\uff0c\u96be\u4ee5\u6b63\u786e\u5efa\u6a21\u590d\u6742\u7684\u5956\u52b1\u7ed3\u6784\u3002\u672c\u6587\u63d0\u51faPROF\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u548c\u5355\u4e2a\u4e13\u5bb6\u8f68\u8ff9\u751f\u6210\u5e76\u6539\u8fdb\u53ef\u6267\u884c\u7684\u5956\u52b1\u51fd\u6570\u4ee3\u7801\u3002\u4e3a\u907f\u514d\u9700\u8981\u73af\u5883\u4ea4\u4e92\u6216RL\u8bad\u7ec3\uff0c\u63d0\u51faReward Preference Ranking (RPR)\u4ee5\u5bf9\u5956\u52b1\u51fd\u6570\u8fdb\u884c\u8d28\u91cf\u8bc4\u4f30\u4e0e\u6392\u5e8f\u3002", "method": "PROF\u5148\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u548c\u5355\u4e2a\u4e13\u5bb6\u8f68\u8ff9\u751f\u6210\u5e76\u6539\u8fdb\u53ef\u6267\u884c\u7684\u5956\u52b1\u51fd\u6570\u4ee3\u7801\uff1b\u518d\u901a\u8fc7RPR\u5bf9\u5019\u9009\u5956\u52b1\u51fd\u6570\u8fdb\u884c\u6392\u5e8f\uff0c\u8bc4\u4f30\u6807\u51c6\u4e3a\u4e0e\u4e13\u5bb6\u504f\u597d\u7684\u652f\u914d\u5173\u7cfb\u3002\u968f\u540e\u4ea4\u66ff\u8fdb\u884c\u57fa\u4e8e\u6587\u672c\u7684\u68af\u5ea6\u4f18\u5316\u4e0eRPR\u6392\u540d\uff0c\u81ea\u52a8\u9009\u53d6\u5e76\u7ec6\u5316\u6700\u4f73\u5956\u52b1\u51fd\u6570\u7528\u4e8e\u4e0b\u6e38\u7b56\u7565\u5b66\u4e60\u3002", "result": "\u5728D4RL\u6570\u636e\u96c6\u4e0a\uff0cPROF\u80fd\u591f\u8d85\u8d8a\u6216\u5339\u914d\u6700\u8fd1\u7684\u5f3a\u57fa\u7ebf\uff0c\u5c55\u793a\u5176\u5728\u591a\u6570\u636e\u96c6\u4e0e\u9886\u57df\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "PROF\u5b9e\u73b0\u4e86\u79bb\u7ebfIL\u4e2d\u5956\u52b1\u51fd\u6570\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u751f\u6210\u3001\u7b5b\u9009\u4e0e\u6539\u8fdb\uff0c\u914d\u5408RPR\u4e3a\u5956\u52b1\u51fd\u6570\u8d28\u91cf\u63d0\u4f9b\u65e0\u73af\u5883\u4ea4\u4e92\u7684\u8bc4\u4f30\u4e0e\u6392\u5e8f\uff0c\u63d0\u5347\u4e0b\u6e38\u7b56\u7565\u5b66\u4e60\u7684\u6548\u679c\u3002"}}
{"id": "2511.14140", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14140", "abs": "https://arxiv.org/abs/2511.14140", "authors": ["Hajun Kim", "Hyunsik Na", "Daeseon Choi"], "title": "Beyond Fixed and Dynamic Prompts: Embedded Jailbreak Templates for Advancing LLM Security", "comment": null, "summary": "As the use of large language models (LLMs) continues to expand, ensuring their safety and robustness has become a critical challenge. In particular, jailbreak attacks that bypass built-in safety mechanisms are increasingly recognized as a tangible threat across industries, driving the need for diverse templates to support red-teaming efforts and strengthen defensive techniques. However, current approaches predominantly rely on two limited strategies: (i) substituting harmful queries into fixed templates, and (ii) having the LLM generate entire templates, which often compromises intent clarity and reproductibility. To address this gap, this paper introduces the Embedded Jailbreak Template, which preserves the structure of existing templates while naturally embedding harmful queries within their context. We further propose a progressive prompt-engineering methodology to ensure template quality and consistency, alongside standardized protocols for generation and evaluation. Together, these contributions provide a benchmark that more accurately reflects real-world usage scenarios and harmful intent, facilitating its application in red-teaming and policy regression testing.", "AI": {"tldr": "\u63d0\u51fa\u5d4c\u5165\u5f0f\u8d8a\u72f1\u6a21\u677f\u548c\u6e10\u8fdb\u5f0f\u63d0\u793a\u5de5\u7a0b\uff0c\u63d0\u5347\u5bf9LLMs\u7684\u7ea2\u961f\u6f14\u7ec3\u4e0e\u653f\u7b56\u56de\u5f52\u6d4b\u8bd5\u7684\u771f\u5b9e\u6027\u4e0e\u53ef\u590d\u73b0\u6027\u3002", "motivation": "\u5f53\u524d\u8d8a\u72f1\u7814\u7a76\u53d7\u9650\u4e8e\u56fa\u5b9a\u6a21\u677f\u6216\u7531LLM\u751f\u6210\u6574\u5957\u6a21\u677f\uff0c\u5bfc\u81f4\u610f\u56fe\u4e0d\u6e05\u6670\u4e14\u53ef\u590d\u73b0\u5b9e\u8df5\u6027\u4e0d\u8db3\u3002\u9700\u8981\u5728\u4fdd\u6301\u6a21\u677f\u7ed3\u6784\u7684\u540c\u65f6\uff0c\u5c06\u6709\u5bb3\u67e5\u8be2\u81ea\u7136\u5d4c\u5165\u4e0a\u4e0b\u6587\uff0c\u4ee5\u66f4\u8d34\u8fd1\u771f\u5b9e\u4f7f\u7528\u60c5\u666f\u4e0e\u653b\u51fb\u610f\u56fe\u3002", "method": "\u63d0\u51fa Embedded Jailbreak Template\uff0c\u4fdd\u6301\u6a21\u677f\u7ed3\u6784\u5e76\u5728\u5176\u4e2d\u5d4c\u5165\u6709\u5bb3\u67e5\u8be2\uff1b\u91c7\u7528\u6e10\u8fdb\u5f0f\u63d0\u793a\u5de5\u7a0b\u786e\u4fdd\u6a21\u677f\u8d28\u91cf\u4e0e\u4e00\u81f4\u6027\uff1b\u5236\u5b9a\u6807\u51c6\u5316\u7684\u751f\u6210\u4e0e\u8bc4\u4f30 protocol\u3002", "result": "\u63d0\u4f9b\u4e00\u4e2a\u66f4\u8d34\u8fd1\u73b0\u5b9e\u4f7f\u7528\u60c5\u5883\u7684\u57fa\u51c6\uff0c\u80fd\u591f\u771f\u5b9e\u4f53\u73b0\u6709\u5bb3\u610f\u56fe\uff0c\u6709\u52a9\u4e8e\u7ea2\u961f\u6f14\u7ec3\u4e0e\u7b56\u7565\u56de\u5f52\u6d4b\u8bd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e30\u5bcc\u4e86\u5bf9LLMs\u5b89\u5168\u7814\u7a76\u7684\u57fa\u51c6\u4e0e\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4fc3\u8fdb\u66f4\u7a33\u5065\u7684\u6a21\u578b\u90e8\u7f72\u548c\u9632\u5fa1\u7b56\u7565\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.14390", "categories": ["eess.SY", "eess.AS", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.14390", "abs": "https://arxiv.org/abs/2511.14390", "authors": ["Chin-Yun Yu", "Gy\u00f6rgy Fazekas"], "title": "Accelerating Automatic Differentiation of Direct Form Digital Filters", "comment": "Accepted at the 1st Workshop on Differentiable Systems and Scientific Machine Learning @ EurIPS 2025", "summary": "We introduce a general formulation for automatic differentiation through direct form filters, yielding a closed-form backpropagation that includes initial condition gradients. The result is a single expression that can represent both the filter and its gradients computation while supporting parallelism. C++/CUDA implementations in PyTorch achieve at least 1000x speedup over naive Python implementations and consistently run fastest on the GPU. For the low-order filters commonly used in practice, exact time-domain filtering with analytical gradients outperforms the frequency-domain method in terms of speed. The source code is available at https://github.com/yoyolicoris/philtorch.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u76f4\u63a5\u5f62\u6210\u6ee4\u6ce2\u5668\u5b9e\u73b0\u81ea\u52a8\u5fae\u5206\u7684\u901a\u7528\u8868\u8ff0\uff0c\u7ed9\u51fa\u5305\u542b\u521d\u59cb\u6761\u4ef6\u68af\u5ea6\u7684\u5c01\u95ed\u5f62\u5f0f\u53cd\u5411\u4f20\u64ad\u3002\u8fd9\u4e00\u5355\u4e00\u8868\u8fbe\u5f0f\u540c\u65f6\u63cf\u8ff0\u6ee4\u6ce2\u5668\u53ca\u5176\u68af\u5ea6\u8ba1\u7b97\uff0c\u4e14\u652f\u6301\u5e76\u884c\u3002", "motivation": "\u89e3\u51b3\u5728\u4fe1\u53f7\u6ee4\u6ce2\u4e2d\u8fdb\u884c\u9ad8\u6548\u68af\u5ea6\u8ba1\u7b97\u7684\u9700\u6c42\uff0c\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u524d\u5411\u4e0e\u68af\u5ea6\u8ba1\u7b97\u8868\u8fbe\u5f0f\uff0c\u907f\u514d\u5bf9\u4e0d\u540c\u6ee4\u6ce2\u5668\u9010\u4e2a\u5b9e\u73b0\u5bfc\u6570\uff0c\u4ee5\u53ca\u63d0\u5347\u5e76\u884c\u6027\u3002", "method": "\u63a8\u5bfc\u4e00\u4e2a\u76f4\u63a5\u5f62\u5f0f\u6ee4\u6ce2\u5668\u7684\u5c01\u95ed\u5f62\u5f0f\u53cd\u5411\u4f20\u64ad\u8868\u8fbe\u5f0f\uff0c\u5305\u542b\u521d\u59cb\u6761\u4ef6\u7684\u68af\u5ea6\uff1b\u5b9e\u73b0\u4e3aC++/CUDA\u7684PyTorch\u5b9e\u73b0\uff0c\u80fd\u5728GPU\u4e0a\u8fbe\u5230\u660e\u663e\u7684\u52a0\u901f\uff1b\u5c06\u65f6\u95f4\u57df\u7684\u89e3\u6790\u68af\u5ea6\u4e0e\u9891\u57df\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u5728\u57fa\u4e8ePython\u7684\u6734\u7d20\u5b9e\u73b0\u4e0b\u5b9e\u73b0\u4e0d\u4f4e\u4e8e1000x\u7684\u52a0\u901f\uff0c\u5e76\u5728GPU\u4e0a\u59cb\u7ec8\u662f\u6700\u5feb\u5b9e\u73b0\uff1b\u5bf9\u4e8e\u5b9e\u6218\u4e2d\u5e38\u7528\u7684\u4f4e\u9636\u6ee4\u6ce2\u5668\uff0c\u65f6\u95f4\u57df\u7684\u89e3\u6790\u68af\u5ea6\u4f18\u52bf\u4e8e\u9891\u57df\u65b9\u6cd5\u5728\u901f\u5ea6\u4e0a\uff1b\u6e90\u4ee3\u7801\u6258\u7ba1\u5728GitHub\u3002", "conclusion": "\u63d0\u51fa\u7684\u901a\u7528\u8868\u8ff0\u4f7f\u6ee4\u6ce2\u5668\u7684\u6b63\u5411\u8ba1\u7b97\u548c\u68af\u5ea6\u8ba1\u7b97\u53ef\u4ee5\u5e76\u884c\u5316\u3001\u7edf\u4e00\u5316\uff0c\u663e\u8457\u63d0\u5347\u5fae\u5206\u80fd\u529b\u7684\u5b9e\u73b0\u6548\u7387\uff0c\u9002\u5408\u9ad8\u6027\u80fd\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2511.14158", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.14158", "abs": "https://arxiv.org/abs/2511.14158", "authors": ["Arnab Bhattacharjee"], "title": "Uncertainty Discounting in Deterministic Black Box Price Predictions for Energy Arbitrage", "comment": "5 pages, 3 figures, 1 table", "summary": "This study examines the economic impact of post-hoc uncertainty discounting in predictive energy management, specifically in battery energy arbitrage. A 2.2 MWh, 1.1 MW Tesla battery, emulating operations at the University of Queensland's St. Lucia campus, is used as a test system. Traditionally, Model Predictive Control (MPC) frameworks rely on deterministic spot price forecasts from the Australian Energy Market Operator (AEMO) to optimize battery scheduling. However, these forecasts lack uncertainty awareness, making arbitrage strategies vulnerable to extreme price volatility. To address this, we propose simple heuristic uncertainty discounting methods, which require no access to the predictive model's architecture or inputs. By integrating these strategies into existing MPC frameworks, we demonstrate a more than 20% improvement in economic returns under identical operational constraints. This approach enhances decision-making in energy arbitrage while remaining practical, scalable, and independent of specific forecasting models", "AI": {"tldr": "\u5f15\u5165\u57fa\u4e8e\u540e\u9a8c\u4e0d\u786e\u5b9a\u6027\u6298\u6263\u7684\u7b80\u5355\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5c06\u5176\u6574\u5408\u5230\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\u4e2d\uff0c\u7528\u4e8e\u7535\u6c60\u80fd\u6e90\u5957\u5229\uff0c\u4e14\u4e0d\u4f9d\u8d56\u5177\u4f53\u9884\u6d4b\u6a21\u578b\uff0c\u5373\u53ef\u5728\u76f8\u540c\u7ea6\u675f\u4e0b\u63d0\u5347\u7ecf\u6d4e\u56de\u62a5\u8d85\u8fc720%\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u7684\u7535\u529b\u5e02\u573a\u4ef7\u683c\u5b58\u5728\u663e\u8457\u4e0d\u786e\u5b9a\u6027\uff0c\u4f20\u7edf\u7684\u786e\u5b9a\u6027\u9884\u6d4b\uff08\u5982AEMO\u7684\u73b0\u8d27\u4ef7\u683c\u9884\u6d4b\uff09\u5728\u6781\u7aef\u4ef7\u683c\u6ce2\u52a8\u4e0b\u6613\u5bfc\u81f4\u5957\u5229\u7b56\u7565\u8868\u73b0\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u4e0d\u4f9d\u8d56\u9884\u6d4b\u6a21\u578b\u5185\u90e8\u7ed3\u6784\u7684\u9c81\u68d2\u6298\u6263\u7b56\u7565\u6765\u63d0\u5347\u6536\u76ca\u3002", "method": "\u63d0\u51fa\u65e0\u9700\u8bbf\u95ee\u9884\u6d4b\u6a21\u578b\u7ed3\u6784\u6216\u8f93\u5165\u7684\u7b80\u5355\u542f\u53d1\u5f0f\u4e0d\u786e\u5b9a\u6027\u6298\u6263\u7b56\u7565\uff0c\u5e76\u5c06\u5176\u5d4c\u5165\u73b0\u6709\u7684MPC\u6846\u67b6\u6765\u4f18\u5316\u7535\u6c60\u8c03\u5ea6\uff0c\u4ee5\u5b9e\u73b0\u5bf9\u4ef7\u683c\u4e0d\u786e\u5b9a\u6027\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728\u76f8\u540c\u8fd0\u8425\u7ea6\u675f\u4e0b\uff0c\u7ecf\u6d4e\u56de\u62a5\u63d0\u5347\u8d85\u8fc720%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u7528\u3001\u53ef\u6269\u5c55\uff0c\u72ec\u7acb\u4e8e\u5177\u4f53\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u80fd\u5728\u80fd\u6e90\u5957\u5229\u51b3\u7b56\u4e2d\u663e\u8457\u63d0\u5347\u6536\u76ca\u3002"}}
{"id": "2511.13766", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13766", "abs": "https://arxiv.org/abs/2511.13766", "authors": ["Kaizheng Wang", "Fabio Cuzzolin", "David Moens", "Hans Hallez"], "title": "Credal Ensemble Distillation for Uncertainty Quantification", "comment": "An extended version for Credal Ensemble Distillation for Uncertainty Quantification, which has been accepted for publication at AAAI 2026", "summary": "Deep ensembles (DE) have emerged as a powerful approach for quantifying predictive uncertainty and distinguishing its aleatoric and epistemic components, thereby enhancing model robustness and reliability. However, their high computational and memory costs during inference pose significant challenges for wide practical deployment. To overcome this issue, we propose credal ensemble distillation (CED), a novel framework that compresses a DE into a single model, CREDIT, for classification tasks. Instead of a single softmax probability distribution, CREDIT predicts class-wise probability intervals that define a credal set, a convex set of probability distributions, for uncertainty quantification. Empirical results on out-of-distribution detection benchmarks demonstrate that CED achieves superior or comparable uncertainty estimation compared to several existing baselines, while substantially reducing inference overhead compared to DE.", "AI": {"tldr": "\u63d0\u51fa\u4e86 credal ensemble distillation (CED)\uff0c\u5c06\u6df1\u5ea6\u96c6\u6210\u538b\u7f29\u4e3a\u5355\u6a21\u578b CREDIT\uff0c\u901a\u8fc7\u8f93\u51fa\u7c7b\u522b\u6982\u7387\u533a\u95f4\u5f62\u6210\u53ef\u4fe1\u96c6\u5408\u4ee5\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u5728 OOD \u68c0\u6d4b\u4e0a\u4e0e\u57fa\u7ebf\u76f8\u5f53\u6216\u66f4\u4f18\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u63a8\u7406\u5f00\u9500\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u96c6\u5408\u5728\u63a8\u7406\u9636\u6bb5\u7684\u9ad8\u8ba1\u7b97\u4e0e\u5185\u5b58\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u7559\u5bf9\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u91cf\u5316\u80fd\u529b\uff0c\u5c24\u5176\u533a\u5206\u5e76\u8861\u91cf aleatoric \u4e0e epistemic \u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u901a\u8fc7\u5c06\u6df1\u5ea6\u96c6\u5408\u7684\u77e5\u8bc6\u538b\u7f29\u4e3a\u5355\u4e00\u6a21\u578b CREDIT\uff0c\u4f7f\u5176\u8f93\u51fa\u6bcf\u4e2a\u7c7b\u522b\u7684\u6982\u7387\u533a\u95f4\uff0c\u5b9a\u4e49\u4e00\u4e2a\u6982\u7387\u5206\u5e03\u7684\u7b49\u4ef7\u96c6\u5408\uff08credal set\uff09\uff0c\u4ee5\u83b7\u5f97\u66f4\u4e30\u5bcc\u7684\u4e0d\u786e\u5b9a\u6027\u4fe1\u606f\u5e76\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u3002", "result": "\u5728\u5916\u90e8\u5206\u5e03\u68c0\u6d4b\uff08OOD\uff09\u57fa\u51c6\u4e0a\uff0cCED \u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4f18\u4e8e\u6216\u7b49\u540c\u4e8e\u82e5\u5e72\u57fa\u7ebf\uff0c\u5e76\u5728\u63a8\u7406\u6210\u672c\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u539f\u59cb\u7684\u6df1\u5ea6\u96c6\u5408\u3002", "conclusion": "CED \u4e3a\u5728\u4fdd\u6301\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u538b\u7f29\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u53ef\u4fe1\u6027\u8bc4\u4f30\u3002"}}
{"id": "2511.14301", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14301", "abs": "https://arxiv.org/abs/2511.14301", "authors": ["Eric Xue", "Ruiyi Zhang", "Zijun Zhang", "Pengtao Xie"], "title": "Steganographic Backdoor Attacks in NLP: Ultra-Low Poisoning and Defense Evasion", "comment": null, "summary": "Transformer models are foundational to natural language processing (NLP) applications, yet remain vulnerable to backdoor attacks introduced through poisoned data, which implant hidden behaviors during training. To strengthen the ability to prevent such compromises, recent research has focused on designing increasingly stealthy attacks to stress-test existing defenses, pairing backdoor behaviors with stylized artifact or token-level perturbation triggers. However, this trend diverts attention from the harder and more realistic case: making the model respond to semantic triggers such as specific names or entities, where a successful backdoor could manipulate outputs tied to real people or events in deployed systems. Motivated by this growing disconnect, we introduce SteganoBackdoor, bringing stealth techniques back into line with practical threat models. Leveraging innocuous properties from natural-language steganography, SteganoBackdoor applies a gradient-guided data optimization process to transform semantic trigger seeds into steganographic carriers that embed a high backdoor payload, remain fluent, and exhibit no representational resemblance to the trigger. Across diverse experimental settings, SteganoBackdoor achieves over 99% attack success at an order-of-magnitude lower data-poisoning rate than prior approaches while maintaining unparalleled evasion against a comprehensive suite of data-level defenses. By revealing this practical and covert attack, SteganoBackdoor highlights an urgent blind spot in current defenses and demands immediate attention to adversarial data defenses and real-world threat modeling.", "AI": {"tldr": "SteganoBackdoor is a sequence-level, semantic-backdoor attack that uses natural-language steganography and gradient-guided data optimization to convert semantic triggers (names/entities) into steganographic carriers embedding a backdoor payload, achieving >99% success with much less poisoning and strong defense evasion.", "motivation": "Existing backdoor research focuses on stylized artifacts or token-level triggers, leaving a realistic threat model where semantic triggers (names/entities) can influence outputs. There is a gap between practical defenses and semantic backdoors that this work aims to address by exposing and mitigating a blind spot in current defenses.", "method": "Apply gradient-guided data optimization to transform semantic trigger seeds into steganographic carriers. The carriers embed a high backdoor payload while remaining fluent and lacking representational resemblance to the trigger, enabling covert activation. Evaluate across diverse NLP tasks and defenses to demonstrate stealth and efficacy.", "result": "Achieves over 99% attack success with an order-of-magnitude lower data-poisoning rate than prior approaches and shows strong evasion against a comprehensive suite of data-level defenses.", "conclusion": "Reveals a practical and covert backdoor threat aligned with real-world semantic triggers, underscoring the need for adversarial data defenses and threat modeling that account for semantic backdoors in deployed NLP systems."}}
{"id": "2511.13767", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13767", "abs": "https://arxiv.org/abs/2511.13767", "authors": ["Sibgat Ul Islam", "Jawad Ibn Ahad", "Fuad Rahman", "Mohammad Ruhul Amin", "Nabeel Mohammed", "Shafin Rahman"], "title": "Dynamic Temperature Scheduler for Knowledge Distillation", "comment": null, "summary": "Knowledge Distillation (KD) trains a smaller student model using a large, pre-trained teacher model, with temperature as a key hyperparameter controlling the softness of output probabilities. Traditional methods use a fixed temperature throughout training, which is suboptimal. Moreover, architectural differences between teacher and student often result in mismatched logit magnitudes. We demonstrate that students benefit from softer probabilities early in training but require sharper probabilities in later stages. We introduce Dynamic Temperature Scheduler (DTS), which adjusts temperature dynamically based on the cross-entropy loss gap between teacher and student. To our knowledge, this is the first temperature scheduling method that adapts based on the divergence between teacher and student distributions. Our method integrates seamlessly with existing KD frameworks. We validate DTS across multiple KD strategies on vision (CIFAR-100, Tiny-ImageNet) and NLP tasks (GLUE, Dolly, SelfIns, UnNI, S-NI), consistently outperforming static-temperature baselines. Code is available at https://github.com/Sibgat-Ul/DTS.", "AI": {"tldr": "Proposes Dynamic Temperature Scheduler (DTS) for knowledge distillation (KD) that adapts the softmax temperature based on the divergence between teacher and student (via cross-entropy loss gap). Demonstrates consistent gains over fixed-temperature baselines across vision and NLP tasks; code released.", "motivation": "Fixed, static temperature in KD is suboptimal due to early benefits of softer distributions and later need for sharper distributions; architectural mismatches cause logit magnitude differences; a temperature that adapts to teacher-student divergence can improve KD performance.", "method": "Introduce Dynamic Temperature Scheduler (DTS) that adjusts the KD temperature dynamically according to the cross-entropy loss gap between teacher and student. DTS integrates with existing KD frameworks and can be applied across different KD strategies. Evaluation on vision tasks (CIFAR-100, Tiny-ImageNet) and NLP tasks (GLUE, Dolly, SelfIns, UnNI, S-NI) showing improvements; code available at provided repository.", "result": "DTS consistently outperforms static-temperature baselines across multiple KD strategies and datasets in both vision and NLP domains.", "conclusion": "DTS provides a practical, model-agnostic temperature scheduling mechanism for KD that adapts to teacher-student divergence, improving performance and integration with existing KD frameworks; encourages broader adoption and further exploration of dynamic hyperparameters in KD."}}
{"id": "2511.14422", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14422", "abs": "https://arxiv.org/abs/2511.14422", "authors": ["Zhengchunmin Dai", "Jiaxiong Tang", "Peng Sun", "Honglong Chen", "Liantao Wu"], "title": "Sigil: Server-Enforced Watermarking in U-Shaped Split Federated Learning via Gradient Injection", "comment": "18 pages,8 figures", "summary": "In decentralized machine learning paradigms such as Split Federated Learning (SFL) and its variant U-shaped SFL, the server's capabilities are severely restricted. Although this enhances client-side privacy, it also leaves the server highly vulnerable to model theft by malicious clients. Ensuring intellectual property protection for such capability-limited servers presents a dual challenge: watermarking schemes that depend on client cooperation are unreliable in adversarial settings, whereas traditional server-side watermarking schemes are technically infeasible because the server lacks access to critical elements such as model parameters or labels.\n  To address this challenge, this paper proposes Sigil, a mandatory watermarking framework designed specifically for capability-limited servers. Sigil defines the watermark as a statistical constraint on the server-visible activation space and embeds the watermark into the client model via gradient injection, without requiring any knowledge of the data. Besides, we design an adaptive gradient clipping mechanism to ensure that our watermarking process remains both mandatory and stealthy, effectively countering existing gradient anomaly detection methods and a specifically designed adaptive subspace removal attack. Extensive experiments on multiple datasets and models demonstrate Sigil's fidelity, robustness, and stealthiness.", "AI": {"tldr": "Proposes Sigil, a mandatory watermarking framework for capability-limited servers in Split Federated Learning; embeds a statistical activation-space constraint via gradient injection and uses adaptive gradient clipping to ensure stealthy, mandatory watermarking without data access; demonstrates fidelity, robustness, and stealthiness across datasets and models.", "motivation": "In Split Federated Learning and its variants, servers have limited access to model parameters and data, increasing risk of model theft by malicious clients. Existing client-cooperation-dependent watermarking or server-side approaches that require data access are infeasible in this setting.", "method": "Define the watermark as a statistical constraint on the server-visible activation space. Embed the watermark into client models through gradient injection without requiring knowledge of the training data. Introduce adaptive gradient clipping to keep the watermark mandatory and stealthy, resisting gradient anomaly detection and adaptive subspace removal attacks.", "result": "Extensive experiments across multiple datasets and models show Sigil achieves high fidelity of watermark, robustness against attacks, and stealthiness.", "conclusion": "Sigil offers a practical, data-free, mandatory watermarking framework for protecting intellectual property of capability-limited servers in Split Federated Learning, addressing both reliability and stealthiness in adversarial settings."}}
{"id": "2511.14209", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.14209", "abs": "https://arxiv.org/abs/2511.14209", "authors": ["Davood Keshavarzi", "Alexander Koehler", "Wolfram H. Wellssow", "Stefan M. Goetz"], "title": "Entirely Transformerless Universal Direct-Injection Power-Flow Controller", "comment": "8 pages, 12 figures", "summary": "An increasing penetration of renewable energy resources, electric vehicle chargers, and energy storage systems into low-voltage power grids causes several power management and stability problems, such as reverse power flow, (local) overload lines, and over- / under-voltage. Previous power-flow and soft-open-point solutions are bulky and expensive. They need transformers and large magnetics, some on grid frequency, others more compact at high frequency. Even suggested circuits with high-frequency transformers still struggle with cost and size. We present a compact partial power-conversion high-current full-power-flow control circuit without a single transformer. We combine silicon and silicon-carbide, each with their specific advantages for current-dense direct injection. The circuit further needs fewer semiconductors than previous concepts. The circuit links a shunt converter through a non-isolated inverter bidirectionally with low-voltage series modules that practically float with their respective phases can serve between different feeders in low-voltage power grids. We analyze the circuit mathematically and evaluate the operation in simulation and experimental results.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u53d8\u538b\u5668\u7684\u7d27\u51d1\u9ad8\u7535\u6d41\u5168\u529f\u7387\u6d41\u63a7\u5236\u7535\u8def\uff0c\u7528\u7845/\u78b3\u5316\u7845\u6df7\u5408\u5668\u4ef6\u5b9e\u73b0\u76f4\u6d41\u6ce8\u5165\uff0c\u80fd\u5728\u4f4e\u538b\u7535\u7f51\u4e2d\u5b9e\u73b0\u53cc\u5411\u9988\u7ebf\u4e4b\u95f4\u7684\u65e0\u9694\u79bb inverter \u8fde\u63a5\u7684\u529f\u7387\u6d41\u63a7\u5236\uff0c\u4e14\u4eff\u771f\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\u3002", "motivation": "\u9ad8\u6bd4\u4f8b\u53ef\u518d\u751f\u80fd\u6e90\u3001\u96fb\u52d5\u8eca\u5145\u96fb\u548c\u50a8\u80fd\u5bf9\u4f4e\u538b\u7535\u7f51\u9020\u6210\u529f\u7387\u7ba1\u7406\u548c\u7a33\u5b9a\u6027\u6311\u6218\uff08\u53cd\u5411\u6f6e\u6d41\u3001\u5c40\u90e8\u8fc7\u8f7d\u3001\u5bf9/\u6b20\u7535\u538b\u7b49\uff09\u3002\u73b0\u6709\u6f6e\u6d41\u548c\u8f6f\u5f00\u70b9\u65b9\u6848\u7b28\u91cd\u3001\u6210\u672c\u9ad8\uff0c\u9700\u8981\u53d8\u538b\u5668\u548c\u5927\u78c1\u6027\u5143\u4ef6\uff0c\u5c3d\u7ba1\u6709\u9ad8\u9891\u53d8\u538b\u5668\u65b9\u6848\u4e5f\u96be\u4ee5\u964d\u4f4e\u6210\u672c\u4e0e\u4f53\u79ef\u3002\u56e0\u6b64\u9700\u8981\u66f4\u7d27\u51d1\u3001\u4f4e\u6210\u672c\u3001\u65e0\u53d8\u538b\u5668\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7535\u8def\u62d3\u6251\uff0c\u5c06\u5e76\u8054\u7684\u5e76\u7f51\u5206\u6d41\u53d8\u6362\u5668\u901a\u8fc7\u975e\u9694\u79bb\u9006\u53d8\u5668\u53cc\u5411\u8026\u5408\u5230\u4f4e\u538b\u4e32\u8054\u6a21\u7ec4\uff0c\u6a21\u7ec4\u80fd\u4e0e\u5404\u81ea\u76f8\u4f4d\u6d6e\u52a8\u5730\u8fde\u63a5\uff0c\u5728\u4e0d\u540c\u9988\u7ebf\u4e4b\u95f4\u5b9e\u73b0\u76f4\u63a5\u6ce8\u5165\u4e0e\u5168\u529f\u7387\u6d41\u63a7\u5236\u3002\u8be5\u65b9\u6848\u7ed3\u5408\u7845\u548c\u78b3\u5316\u7845\u5668\u4ef6\u7684\u4f18\u52bf\u4ee5\u5b9e\u73b0\u9ad8\u7535\u6d41\u5bc6\u5ea6\u7684\u76f4\u63a5\u6ce8\u5165\uff0c\u5e76\u8bbe\u8ba1\u6bd4\u4ee5\u5f80\u65b9\u6848\u66f4\u5c11\u7684\u534a\u5bfc\u4f53\u5668\u4ef6\u3002\u5bf9\u7535\u8def\u8fdb\u884c\u4e86\u6570\u5b66\u5206\u6790\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u4e0e\u5b9e\u9a8c\u7ed3\u679c\u5bf9\u5176\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7535\u8def\u5177\u5907\u7d27\u51d1\u7ed3\u6784\u4e0e\u9ad8\u7535\u6d41\u5168\u529f\u7387\u6d41\u63a7\u5236\u80fd\u529b\uff0c\u4e14\u65e0\u9700\u53d8\u538b\u5668\uff0c\u6240\u7528\u534a\u5bfc\u4f53\u6570\u91cf\u5c11\u4e8e\u524d\u671f\u6982\u5ff5\u8bbe\u8ba1\uff1b\u5728\u4eff\u771f\u548c\u5b9e\u9a8c\u5c42\u9762\u5747\u8bc1\u660e\u4e86\u53ef\u884c\u6027\uff0c\u663e\u793a\u51fa\u5728\u4f4e\u538b\u7535\u7f51\u4e2d\u5b9e\u73b0\u53cc\u5411\u3001\u8de8\u9988\u7ebf\u7684\u529f\u7387\u6ce8\u5165\u4e0e\u7535\u538b/\u6f6e\u6d41\u7ba1\u7406\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8bc1\u660e\u4e86\u65e0\u53d8\u538b\u5668\u3001\u7d27\u51d1\u578b\u9ad8\u7535\u6d41\u5168\u529f\u7387\u6d41\u63a7\u5236\u5728\u4f4e\u538b\u7535\u7f51\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u80fd\u6709\u6548\u7f13\u89e3\u53ef\u518d\u751f\u80fd\u6e90\u6e17\u900f\u5e26\u6765\u7684\u9006\u6f6e\u6d41\u4e0e\u7535\u538b\u6ce2\u52a8\u7b49\u95ee\u9898\uff0c\u5e76\u5177\u6709\u6f5c\u5728\u7684\u6210\u672c\u4e0e\u4f53\u79ef\u4f18\u52bf\uff0c\u9002\u5408\u5e94\u7528\u4e8e\u591a\u9988\u7ebf\u4f4e\u538b\u914d\u7535\u573a\u666f\u3002"}}
{"id": "2511.14611", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.14611", "abs": "https://arxiv.org/abs/2511.14611", "authors": ["Charles Cheng Ji", "Brandon Kong"], "title": "SecureSign: Bridging Security and UX in Mobile Web3 through Emulated EIP-6963 Sandboxing", "comment": "19 pages, 11 figures", "summary": "Mobile Web3 faces catastrophic retention (< 5%) yielding effective acquisition costs of \\$500 - \\$1,000 per retained user. Existing solutions force an impossible tradeoff: embedded wallets achieve moderate usability but suffer inherent click-jacking vulnerabilities; app wallets maintain security at the cost of 2 - 3% retention due to download friction and context-switching penalties. We present SecureSign, a PWA-based architecture that adapts desktop browser extension security to mobile via EIP-6963 provider sandboxing. SecureSign isolates dApp execution in iframes within a trusted parent application, achieving click-jacking immunity and transaction integrity while enabling native mobile capabilities (push notifications, home screen installation, zero context-switching). Our drop-in SDK requires no codebase changes for existing Web3 applications. Threat model analysis demonstrates immunity to click-jacking, overlay, and skimming attacks while maintaining wallet interoperability across dApps.", "AI": {"tldr": "\u63d0\u51fa SecureSign\uff0c\u4e00\u79cd\u57fa\u4e8ePWA\u7684\u79fb\u52a8\u7aefWeb3\u94b1\u5305\u67b6\u6784\uff0c\u901a\u8fc7EIP-6963 provider\u6c99\u7bb1\u5316\uff0c\u5c06dApp\u5728\u53ef\u4fe1\u7236\u5e94\u7528\u7684iframe\u4e2d\u6267\u884c\uff0c\u517c\u987e\u9ad8\u5b89\u5168\u6027\u4e0e\u539f\u751f\u79fb\u52a8\u80fd\u529b\uff0c\u4e14\u65e0\u9700\u6539\u52a8\u73b0\u6709\u5e94\u7528\u4ee3\u7801\u3002", "motivation": "\u89e3\u51b3\u79fb\u52a8\u7aefWeb3\u7684\u6781\u4f4e\u7559\u5b58\u7387\uff08<5%\uff09\u548c\u9ad8\u83b7\u53d6\u6210\u672c\uff08$500-$1,000/\u7559\u5b58\u7528\u6237\uff09\u7684\u77db\u76fe\u3002\u73b0\u6709\u5d4c\u5165\u5f0f\u94b1\u5305\u6613\u53d7\u70b9\u51fb\u52ab\u6301\uff0c\u5e94\u7528\u94b1\u5305\u5c3d\u7ba1\u5b89\u5168\u5374\u56e0\u4e0b\u8f7d\u548c\u4e0a\u4e0b\u6587\u5207\u6362\u6210\u672c\u5bfc\u81f4\u4f4e\u7559\u5b58\u3002", "method": "\u5c06\u684c\u9762\u6d4f\u89c8\u5668\u6269\u5c55\u7684\u5b89\u5168\u6a21\u578b\u79fb\u690d\u5230\u79fb\u52a8\u7aef\uff0c\u91c7\u7528EIP-6963\u63d0\u4f9b\u7a0b\u5e8f\u6c99\u7bb1\u5316\uff0c\u5c06dApp\u653e\u5165\u53d7\u4fe1\u4efb\u7236\u5e94\u7528\u4e2d\u7684iframe\u5185\u6267\u884c\uff0c\u4ee5\u5b9e\u73b0\u70b9\u51fb\u52ab\u6301\u514d\u75ab\u3001\u4ea4\u6613\u5b8c\u6574\u6027\uff0c\u540c\u65f6\u652f\u6301\u539f\u751f\u79fb\u52a8\u80fd\u529b\uff08\u63a8\u9001\u901a\u77e5\u3001\u4e3b\u5c4f\u5b89\u88c5\u3001\u96f6\u4e0a\u4e0b\u6587\u5207\u6362\uff09\u3002\u63d0\u4f9b\u5373\u63d2\u5373\u7528\u7684SDK\uff0c\u65e0\u9700\u6539\u52a8\u73b0\u6709\u4ee3\u7801\u5e93\u3002", "result": "\u5728\u653b\u51fb\u8868\u9762\u4e0a\u58f0\u79f0\u5bf9\u70b9\u51fb\u52ab\u6301\u3001\u8986\u76d6\u548c skim \u7b49\u653b\u51fb\u5177\u6709\u514d\u75ab\u529b\uff0c\u4fdd\u6301\u8de8dApp\u7684\u94b1\u5305\u4e92\u64cd\u4f5c\u6027\uff1b\u6458\u8981\u4e2d\u672a\u7ed9\u51fa\u5b9e\u8bc1\u6570\u636e\uff0c\u4f46\u63d0\u51fa\u663e\u8457\u63d0\u5347\u7559\u5b58\u4e0e\u83b7\u53d6\u6210\u672c\u7684\u6f5c\u529b\u3002", "conclusion": "SecureSign\u901a\u8fc7\u5728\u79fb\u52a8\u7aef\u590d\u5236\u684c\u9762\u6269\u5c55\u7684\u5b89\u5168\u6027\u5e76\u7ed3\u5408\u539f\u751f\u79fb\u52a8\u80fd\u529b\uff0c\u89e3\u51b3\u79fb\u52a8\u7aefWeb3\u7684\u5b89\u5168\u4e0e\u6613\u7528\u6027\u77db\u76fe\uff0c\u5177\u5907\u63d0\u5347\u7559\u5b58\u4e0e\u964d\u4f4e\u83b7\u53d6\u6210\u672c\u7684\u6f5c\u529b\uff1b\u672a\u6765\u5de5\u4f5c\u5305\u62ec\u66f4\u5168\u9762\u7684\u5b9e\u8bc1\u8bc4\u4f30\u4e0e\u5927\u89c4\u6a21\u90e8\u7f72\u7684\u53ef\u884c\u6027\u7814\u7a76\u3002"}}
{"id": "2511.13780", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13780", "abs": "https://arxiv.org/abs/2511.13780", "authors": ["Nihal Mehta"], "title": "Self-Attention as Distributional Projection: A Unified Interpretation of Transformer Architecture", "comment": "17 pages, 0 figures. This work provides a mathematical interpretation of self-attention mechanisms in Transformers through distributional semantics principles", "summary": "This paper presents a mathematical interpretation of self-attention by connecting it to distributional semantics principles. We show that self-attention emerges from projecting corpus-level co-occurrence statistics into sequence context. Starting from the co-occurrence matrix underlying GloVe embeddings, we demonstrate how the projection naturally captures contextual influence, with the query-key-value mechanism arising as the natural asymmetric extension for modeling directional relationships. Positional encodings and multi-head attention then follow as structured refinements of this same projection principle. Our analysis demonstrates that the Transformer architecture's particular algebraic form follows from these projection principles rather than being an arbitrary design choice.", "AI": {"tldr": "\u81ea\u6ce8\u610f\u529b\u53ef\u4ece\u5206\u5e03\u5f0f\u8bed\u4e49\u5b66\u7684\u6295\u5f71\u4e2d\u63a8\u5bfc\u800c\u6765\uff0cTransformer \u7684\u7ed3\u6784\u662f\u57fa\u4e8e\u5171\u73b0\u7edf\u8ba1\u6295\u5f71\u7684\u81ea\u7136\u7ed3\u679c\uff0c\u800c\u975e\u4efb\u610f\u8bbe\u8ba1\u3002", "motivation": "\u63ed\u793a\u81ea\u6ce8\u610f\u529b\u4e0e\u5206\u5e03\u5f0f\u8bed\u4e49\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u63d0\u4f9b\u5bf9 Transformer \u53ca\u5176\u6210\u5206\uff08Q/K/V\u3001\u4f4d\u7f6e\u7f16\u7801\u3001\u591a\u5934\u6ce8\u610f\u529b\uff09\u7684\u4e00\u79cd principled \u7406\u89e3\u3002", "method": "\u4ee5 GloVe \u7684\u5171\u73b0\u77e9\u9635\u4e3a\u51fa\u53d1\u70b9\uff0c\u5c55\u793a\u5982\u4f55\u5c06\u5176\u6295\u5f71\u5230\u5e8f\u5217\u4e0a\u4e0b\u6587\u4e2d\uff0c\u63a8\u5bfc\u51fa\u67e5\u8be2-\u952e-\u503c\u7684\u975e\u5bf9\u79f0\u6269\u5c55\u4ee5\u5efa\u6a21\u65b9\u5411\u6027\u5173\u7cfb\uff0c\u5e76\u5c06\u4f4d\u7f6e\u7f16\u7801\u4e0e\u591a\u5934\u6ce8\u610f\u529b\u89c6\u4e3a\u5bf9\u8fd9\u79cd\u6295\u5f71\u539f\u7406\u7684\u7ed3\u6784\u5316 refinements\u3002", "result": "\u8bc1\u660e Transformer \u7684\u4ee3\u6570\u5f62\u5f0f\u6765\u81ea\u8fd9\u4e9b\u6295\u5f71\u539f\u5219\u800c\u975e\u4efb\u610f\u9009\u62e9\uff1b\u5efa\u7acb\u4ece\u5171\u73b0\u7edf\u8ba1\u5230\u6ce8\u610f\u529b\u673a\u5236\u7684\u6e05\u6670\u8def\u5f84\uff0c\u89e3\u91ca\u4e86\u5206\u5e03\u5f0f\u8bed\u4e49\u4e0e\u5e8f\u5217\u5efa\u6a21\u7684\u7edf\u4e00\u3002", "conclusion": "Transformer \u67b6\u6784\u7684\u6838\u5fc3\u7b97\u5b50\u548c\u7ec4\u4ef6\u53ef\u4ee5\u4ece\u6295\u5f71\u5206\u89e3\u7684\u539f\u5219\u63a8\u5bfc\u51fa\uff0c\u5f3a\u8c03\u7edf\u8ba1\u5171\u73b0\u5230\u6ce8\u610f\u529b\u7684\u81ea\u7136\u8fc7\u6e21\uff0c\u589e\u5f3a\u5bf9\u6a21\u578b\u8bbe\u8ba1\u7684\u7406\u8bba\u57fa\u7840\u7406\u89e3\u3002"}}
{"id": "2511.14267", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.14267", "abs": "https://arxiv.org/abs/2511.14267", "authors": ["Jialong Chen", "Jimin Wang", "Ji-Feng Zhang"], "title": "Secure parameter identification of ARX systems with CKKS cryptosystem", "comment": "12 pages, 2 figures, submitted to IFAC World Congress 2026", "summary": "This paper focuses on the cloud-based parameter identification problem of ARX systems while protecting the system input and output. To do so, a CKKS-cryptosystem-based parameter identification algorithm is proposed. By rigorously proving that the statistical distance between the Gaussian distribution and the truncated discrete one is negligible, the algorithm has the same security level as the standard CKKS cryptosystem. By utilizing the projection mapping on the estimates, the conditions for correct encryption and decryption are given. Based on these conditions, the stochastic approximation method is further employed to achieve the almost sure and mean square convergence of the algorithm. The effectiveness is demonstrated through a numerical example.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e CKKS \u7684\u4e91\u7aef\u9690\u79c1\u4fdd\u62a4\u7684 ARX \u53c2\u6570\u8fa8\u8bc6\u7b97\u6cd5\uff0c\u5e76\u7ed9\u51fa\u5728\u4f30\u8ba1\u91cf\u4e0a\u7684\u6295\u5f71\u6620\u5c04\u6761\u4ef6\uff0c\u8bc1\u660e\u7edf\u8ba1\u8ddd\u79bb\u8fd1\u4f3c\u4e3a\u96f6\u4ece\u800c\u83b7\u5f97\u4e0e\u6807\u51c6 CKKS \u76f8\u540c\u7684\u5b89\u5168\u6027\uff1b\u5e76\u5229\u7528\u968f\u673a\u903c\u8fd1\u65b9\u6cd5\u8bc1\u660e\u7b97\u6cd5\u5728\u51e0\u4e4e\u5904\u5904\u6536\u655b\u548c\u5e73\u65b9\u5747\u65b9\u6536\u655b\uff0c\u901a\u8fc7\u6570\u503c\u793a\u4f8b\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u5728\u4e91\u7aef\u8fdb\u884c ARX \u7cfb\u7edf\u7684\u53c2\u6570\u8fa8\u8bc6\u65f6\uff0c\u9700\u8981\u4fdd\u62a4\u7cfb\u7edf\u8f93\u5165\u8f93\u51fa\u7684\u9690\u79c1\uff0c\u4f20\u7edf\u4e91\u7aef\u8fa8\u8bc6\u9762\u4e34\u6570\u636e\u66b4\u9732\u98ce\u9669\u3002\u901a\u8fc7\u540c\u6001\u52a0\u5bc6\uff08CKKS\uff09\u5b9e\u73b0\u6570\u636e\u52a0\u5bc6\u540e\u7aef\u8ba1\u7b97\uff0c\u4ece\u800c\u5728\u4e0d\u66b4\u9732\u539f\u59cb\u6570\u636e\u7684\u524d\u63d0\u4e0b\u5b8c\u6210\u8fa8\u8bc6\uff0c\u540c\u65f6\u4fdd\u6301\u4e00\u5b9a\u7684\u5b89\u5168\u5f3a\u5ea6\u3002", "method": "\u91c7\u7528 CKKS \u516c\u94a5\u5bc6\u7801\u4f53\u7cfb\u8fdb\u884c\u53c2\u6570\u8fa8\u8bc6\uff0c\u8bc1\u660e\u9ad8\u65af\u5206\u5e03\u4e0e\u622a\u65ad\u79bb\u6563\u5206\u5e03\u4e4b\u95f4\u7684\u7edf\u8ba1\u8ddd\u79bb\u53ef\u5ffd\u7565\uff0c\u4ece\u800c\u5f97\u5230\u4e0e\u6807\u51c6 CKKS \u76f8\u540c\u7684\u5b89\u5168\u7b49\u7ea7\uff1b\u5bf9\u4f30\u8ba1\u91cf\u65bd\u4ee5\u6295\u5f71\u6620\u5c04\uff0c\u7ed9\u51fa\u6b63\u786e\u52a0\u89e3\u5bc6\u7684\u6761\u4ef6\uff1b\u5728\u6b64\u6761\u4ef6\u4e0b\uff0c\u5229\u7528\u968f\u673a\u903c\u8fd1\uff08 stochastic approximation\uff09\u65b9\u6cd5\u6765\u8bc1\u660e\u7b97\u6cd5\u7684\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u548c\u5747\u65b9\u6536\u655b\u6027\u3002", "result": "\u8be5\u7b97\u6cd5\u5728\u5b89\u5168\u6027\u65b9\u9762\u8fbe\u5230\u4e0e\u6807\u51c6 CKKS \u76f8\u540c\u7684\u6c34\u5e73\uff0c\u5e76\u4e14\u5728\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5728\u7ed9\u5b9a\u6761\u4ef6\u4e0b\u7684\u6536\u655b\u6027\uff08\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u4e0e\u5e73\u65b9\u5747\u65b9\u6536\u655b\uff09\uff0c\u6570\u503c\u793a\u4f8b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u5728\u7b26\u5408\u6761\u4ef6\u7684\u524d\u63d0\u4e0b\uff0c\u53ef\u4ee5\u5b9e\u73b0\u57fa\u4e8e CKKS \u7684\u4e91\u7aef\u9690\u79c1\u4fdd\u62a4\u7684 ARX \u53c2\u6570\u8fa8\u8bc6\uff0c\u65e2\u4fdd\u969c\u6570\u636e\u9690\u79c1\u53c8\u4fdd\u8bc1\u6536\u655b\u6027\u4e0e\u5b9e\u7528\u6027\uff0c\u7814\u7a76\u4e3a\u5c06\u8fa8\u8bc6\u4efb\u52a1\u5916\u5305\u5230\u4e91\u7aef\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u5b89\u5168\u65b9\u6848\u3002"}}
{"id": "2511.14288", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.14288", "abs": "https://arxiv.org/abs/2511.14288", "authors": ["Huanzhu Lyu", "Xiao Yang", "Xintong Ji"], "title": "Overtourism to Equilibrium: A System Dynamics & Multi-Objective Model for Sustainable Destinations", "comment": "16 pages, 16 figures, 2 tables. This work was originally prepared for the 2025 MCM/ICM competition (Problem B), where it received the Meritorious Winner award", "summary": "Overtourism poses severe challenges to popular destinations worldwide, threatening natural environments and local communities. This paper develops a decision-making model integrating system dynamics with multi-objective evolutionary algorithms (NSGA-II) to balance economic returns, environmental protection, and social satisfaction. We collect multi-source data from 2008-2024 including visitor arrivals (up to 3.1M), government revenue/expenditure (up to $10.3M), glacier retreat (220-350 ft), CO2 emissions (77K-105K tons), and social satisfaction (0.29-0.48), and establish a dynamic system with four modules: tourist behavior, government finance, environmental evolution, and social well-being.\n  We optimize three objectives via NSGA-II: cumulative net revenue, final environmental index, and final social satisfaction. Experiments on Juneau show optimal solutions yield net revenue up to $1.64B with environmental index 0.93 and social satisfaction 0.86. Extending to Iceland reveals Pareto fronts spanning revenues $150M-$200M, environment indices up to 0.92, and social satisfaction above 0.80.\n  Sobol and Morris sensitivity analyses indicate carbon fees and price elasticity account for over 60% of environmental outcome variance, while capacity limits explain around 90% of net revenue variability. Scenario simulations demonstrate how capacity limits and dynamic pricing on crowded attractions, combined with marketing and infrastructure investment in lesser-known sites, mitigate congestion and enhance sustainability.\n  This work contributes: (i) an integrated system-dynamics and NSGA-II framework for sustainable tourism management; (ii) demonstrated portability via case studies on Juneau and Iceland; and (iii) global sensitivity analysis highlighting influential policy levers for decision makers.", "AI": {"tldr": "Integrated system-dynamics and NSGA-II framework for sustainable tourism; multi-objective optimization across revenue, environment, and social well-being; tested on Juneau and Iceland with sensitivity analyses guiding policy levers.", "motivation": "Overtourism threatens natural environments and communities; need decision-support that balances economic, environmental, and social goals under dynamic, data-rich contexts.", "method": "Develop a dynamic system with four modules (tourist behavior, government finance, environmental evolution, social well-being) and collect data from 2008-2024. Use NSGA-II to optimize three objectives: cumulative net revenue, final environmental index, final social satisfaction. Perform Sobol and Morris sensitivity analyses. Conduct scenario simulations on capacity limits, dynamic pricing at crowded attractions, and investment strategies in lesser-known sites.", "result": "Juneau: Pareto-optimal solutions yield net revenue up to 1.64B with environmental index 0.93 and social satisfaction 0.86. Iceland extension: revenues 150M-200M, environmental index up to 0.92, social >0.80. Sensitivity: carbon fees and price elasticity explain >60% of environmental outcome variance; capacity limits explain ~90% of net revenue variability. Scenarios show capacity, pricing, marketing/infrastructure strategies can mitigate congestion and enhance sustainability.", "conclusion": "An integrated SD-NSGA-II framework is effective for sustainable tourism management and demonstrates portability across diverse destinations; global sensitivity analysis helps identify policy levers for decision-makers."}}
{"id": "2511.13809", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13809", "abs": "https://arxiv.org/abs/2511.13809", "authors": ["Emanuel Covaci", "Fabian Galis", "Radu Balan", "Daniela Zaharie", "Darian Onchis"], "title": "ScoresActivation: A New Activation Function for Model Agnostic Global Explainability by Design", "comment": "Paper submitted to ECAI 2025 Conference", "summary": "Understanding the decision of large deep learning models is a critical challenge for building transparent and trustworthy systems. Although the current post hoc explanation methods offer valuable insights into feature importance, they are inherently disconnected from the model training process, limiting their faithfulness and utility. In this work, we introduce a novel differentiable approach to global explainability by design, integrating feature importance estimation directly into model training. Central to our method is the ScoresActivation function, a feature-ranking mechanism embedded within the learning pipeline. This integration enables models to prioritize features according to their contribution to predictive performance in a differentiable and end-to-end trainable manner. Evaluations across benchmark datasets show that our approach yields globally faithful, stable feature rankings aligned with SHAP values and ground-truth feature importance, while maintaining high predictive performance. Moreover, feature scoring is 150 times faster than the classical SHAP method, requiring only 2 seconds during training compared to SHAP's 300 seconds for feature ranking in the same configuration. Our method also improves classification accuracy by 11.24% with 10 features (5 relevant) and 29.33% with 16 features (5 relevant, 11 irrelevant), demonstrating robustness to irrelevant inputs. This work bridges the gap between model accuracy and interpretability, offering a scalable framework for inherently explainable machine learning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53ef\u5fae\u5206\u7684\u5168\u5c40\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u5c06\u7279\u5f81\u91cd\u8981\u6027\u878d\u5165\u6a21\u578b\u8bad\u7ec3\uff0c\u901a\u8fc7 ScoresActivation \u5b9e\u73b0\u5d4c\u5165\u5f0f\u3001\u7aef\u5230\u7aef\u7684\u7279\u5f81\u6392\u5e8f\uff0c\u5e76\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u5206\u7c7b\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u4f9b\u4e0e SHAP \u503c\u4e00\u81f4\u7684\u5168\u5c40\u7279\u5f81\u6392\u540d\u3002", "motivation": "\u5f53\u524d\u7684\u4e8b\u540e\u89e3\u91ca\u65b9\u6cd5\u4e0e\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u5206\u79bb\uff0c\u5bfc\u81f4\u89e3\u91ca\u7684\u53ef\u4fe1\u5ea6\u548c\u5b9e\u7528\u6027\u53d7\u9650\uff1b\u9700\u8981\u4e00\u79cd\u5728\u8bad\u7ec3\u9636\u6bb5\u5c31\u80fd\u63d0\u4f9b\u9ad8\u4fdd\u771f\u3001\u53ef\u6269\u5c55\u7684\u5168\u5c40\u89e3\u91ca\u673a\u5236\u3002", "method": "\u5f15\u5165 ScoresActivation \u51fd\u6570\uff0c\u4f5c\u4e3a\u7279\u5f81\u6392\u5e8f\u673a\u5236\u5d4c\u5165\u5b66\u4e60\u7ba1\u9053\uff0c\u5b9e\u73b0\u5728\u68af\u5ea6\u53ef\u4f20\u9012\u7684\u65b9\u5f0f\u4e0b\u6309\u8d21\u732e\u5ea6\u6392\u5e8f\u7279\u5f81\uff0c\u5e76\u5728\u7aef\u5230\u7aef\u8bad\u7ec3\u4e2d\u4f18\u5316\uff0c\u517c\u987e\u9884\u6d4b\u6027\u80fd\u548c\u89e3\u91ca\u4e00\u81f4\u6027\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u5f97\u5230\u5168\u5c40\u53ef\u4fe1\u3001\u7a33\u5b9a\u7684\u7279\u5f81\u6392\u5e8f\uff0c\u4e0e SHAP \u503c\u548c\u771f\u5b9e\u91cd\u8981\u6027\u4e00\u81f4\uff1b\u4fdd\u6301\u8f83\u9ad8\u9884\u6d4b\u6027\u80fd\uff1b\u7279\u5f81\u6392\u5e8f\u6bd4\u4f20\u7edf SHAP \u5feb 150 \u500d\uff1a\u8bad\u7ec3\u4e2d\u4ec5\u9700 2 \u79d2\u5b8c\u6210\u6392\u5e8f\uff0c\u76f8\u8f83 SHAP \u7684 300 \u79d2\u3002\u5e76\u4e14\u5728 10 \u4e2a\u7279\u5f81\uff08\u5176\u4e2d 5 \u4e2a\u76f8\u5173\uff09\u65f6\u51c6\u786e\u7387\u63d0\u5347 11.24%\uff0c\u5728 16 \u4e2a\u7279\u5f81\uff085 \u76f8\u5173\u300111 \u4e0d\u76f8\u5173\uff09\u65f6\u63d0\u5347 29.33%\uff1b\u5bf9\u65e0\u5173\u8f93\u5165\u9c81\u68d2\u3002", "conclusion": "\u672c\u65b9\u6cd5\u5f25\u5408\u6a21\u578b\u51c6\u786e\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u56fa\u6709\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\u3002"}}
{"id": "2511.13893", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.13893", "abs": "https://arxiv.org/abs/2511.13893", "authors": ["Kai Chen", "Chen Gong", "Tianhao Wang"], "title": "Beyond One-Size-Fits-All: Neural Networks for Differentially Private Tabular Data Synthesis", "comment": "18 pages. Github Link provided: https://github.com/KaiChen9909/margnet", "summary": "In differentially private (DP) tabular data synthesis, the consensus is that statistical models are better than neural network (NN)-based methods. However, we argue that this conclusion is incomplete and overlooks the challenge of densely correlated datasets, where intricate dependencies can overwhelm statistical models. In such complex scenarios, neural networks are more suitable due to their capacity to fit complex distributions by learning directly from samples. Despite this potential, existing NN-based algorithms still suffer from significant limitations. We therefore propose MargNet, incorporating successful algorithmic designs of statistical models into neural networks. MargNet applies an adaptive marginal selection strategy and trains the neural networks to generate data that conforms to the selected marginals. On sparsely correlated datasets, our approach achieves utility close to the best statistical method while offering an average 7$\\times$ speedup over it. More importantly, on densely correlated datasets, MargNet establishes a new state-of-the-art, reducing fidelity error by up to 26\\% compared to the previous best. We release our code on GitHub.\\footnote{https://github.com/KaiChen9909/margnet}", "AI": {"tldr": "MargNet combines adaptive marginal selection with neural-network-based generation to improve DP tabular data synthesis, achieving near-best performance of statistical methods with 7x faster speed on sparsely correlated data, and state-of-the-art fidelity on densely correlated data (up to 26% improvement). Code released on GitHub.", "motivation": "The prevailing view in DP tabular data synthesis is that statistical models outperform neural-network (NN) approaches. However, densely correlated datasets present complex dependencies that can overwhelm statistical methods. NNs have potential to model such distributions directly from samples but currently suffer limitations. This work argues for a hybrid approach that leverages the strengths of both families to address data with varying correlation structure.", "method": "Introduce MargNet, which integrates successful algorithmic designs of statistical models into neural networks. It uses an adaptive marginal selection strategy and trains the NN to generate data that conforms to the selected marginals, effectively combining marginal-based constraints with neural generation.", "result": "On sparsely correlated datasets, MargNet achieves utility close to the best statistical method while providing an average 7\u00d7 speedup. On densely correlated datasets, it establishes new state-of-the-art, reducing fidelity error by up to 26% compared to the previous best.", "conclusion": "MargNet bridges the gap between statistical models and neural networks for DP tabular data synthesis, offering high utility across correlation regimes and practical benefits in speed. The authors release code on GitHub."}}
{"id": "2511.14311", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.14311", "abs": "https://arxiv.org/abs/2511.14311", "authors": ["Lukas Schroth", "Daniel Morton", "Amon Lahr", "Daniele Gammelli", "Andrea Carron", "Marco Pavone"], "title": "Multi-Timescale Model Predictive Control for Slow-Fast Systems", "comment": null, "summary": "Model Predictive Control (MPC) has established itself as the primary methodology for constrained control, enabling autonomy across diverse applications. While model fidelity is crucial in MPC, solving the corresponding optimization problem in real time remains challenging when combining long horizons with high-fidelity models that capture both short-term dynamics and long-term behavior. Motivated by results on the Exponential Decay of Sensitivities (EDS), which imply that, under certain conditions, the influence of modeling inaccuracies decreases exponentially along the prediction horizon, this paper proposes a multi-timescale MPC scheme for fast-sampled control. Tailored to systems with both fast and slow dynamics, the proposed approach improves computational efficiency by i) switching to a reduced model that captures only the slow, dominant dynamics and ii) exponentially increasing integration step sizes to progressively reduce model detail along the horizon. We evaluate the method on three practically motivated robotic control problems in simulation and observe speed-ups of up to an order of magnitude.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eEDS\u7684\u591a\u65f6\u95f4\u5c3a\u5ea6MPC\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u9884\u6d4b horizon \u4e0a\u9010\u6b65\u5207\u6362\u5230\u7b80\u5316\u7684\u6162\u52a8\u6001\u6a21\u578b\u5e76\u6307\u6570\u6027\u589e\u52a0\u6b65\u957f\uff0c\u4ee5\u5b9e\u73b0\u5bf9\u5feb/\u6162\u52a8\u6001\u7cfb\u7edf\u7684\u9ad8\u6548\u5b9e\u65f6\u63a7\u5236\u3002\u5b9e\u9a8c\u5728\u4eff\u771f\u4e2d\u7684\u4e09\u4e2a\u673a\u5668\u4eba\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad8\u7ea610\u00d7\u7684\u52a0\u901f\u3002", "motivation": "MPC\u5728\u7ea6\u675f\u63a7\u5236\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u4f9d\u8d56\u4e8e\u9ad8\u4fdd\u771f\u6a21\u578b\u548c\u957f\u9884\u6d4b horizon\uff0c\u4f46\u5b9e\u65f6\u89e3\u7b97\u6210\u672c\u9ad8\uff0c\u9650\u5236\u5e94\u7528\u3002EDS\u8868\u660e\u8bef\u5dee\u5bf9\u9884\u6d4b horizon \u7684\u5f71\u54cd\u968f\u8ddd\u79bb\u589e\u5927\u800c\u6307\u6570\u8870\u51cf\uff0c\u63d0\u4f9b\u4e86\u5728 horizon \u672b\u7aef\u964d\u4f4e\u6a21\u578b\u7ec6\u8282\u7684\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u591a\u65f6\u95f4\u5c3a\u5ea6\u7684MPC\uff1a\u5728\u9884\u6d4b\u8fc7\u7a0b\u4e2d\u6309\u8ddd\u79bb\u65f6\u95f4\u6b65\u957f\u628a\u6a21\u578b\u5206\u4e3a\u5feb/\u6162\u4e24\u7ec4\uff0c\u5e76\u5728 horizon \u5185\u9010\u6b65\u5207\u6362\u5230\u4ec5\u5305\u542b\u6162\u52a8\u6001\u7684\u7b80\u5316\u6a21\u578b\uff0c\u540c\u65f6\u5c06\u79ef\u5206\u6b65\u957f\u6309 horizon \u6307\u6570\u589e\u957f\uff0c\u4f7f\u540e\u6bb5\u7684\u6c42\u89e3\u4f7f\u7528\u66f4\u5927\u6b65\u957f\u548c\u66f4\u7c97\u7684\u6a21\u578b\u3002", "result": "\u5728\u4e09\u79cd\u673a\u5668\u4eba\u63a7\u5236\u4efb\u52a1\u7684\u4eff\u771f\u5b9e\u9a8c\u4e2d\uff0c\u83b7\u5f97\u9ad8\u8fbe\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u52a0\u901f\uff08\u63a5\u8fd110\u00d7\uff09\u7684\u8ba1\u7b97\u6548\u7387\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u63a5\u53d7\u7684\u63a7\u5236\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u7406\u8bba\u5c42\u9762\u5229\u7528EDS\u7279\u6027\u6765\u964d\u4f4e\u8ba1\u7b97\u9700\u6c42\uff0c\u9002\u5408\u5b58\u5728\u660e\u663e\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\u7684\u7cfb\u7edf\uff0c\u9700\u5728\u672a\u6765\u5de5\u4f5c\u4e2d\u9a8c\u8bc1\u9c81\u68d2\u6027\u3001\u7a33\u5b9a\u6027\u53ca\u5728\u4e0d\u540c\u786c\u4ef6\u4e0a\u7684\u63a8\u5e7f\u6027\u3002"}}
{"id": "2511.13841", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13841", "abs": "https://arxiv.org/abs/2511.13841", "authors": ["Zelei Shao", "Vikranth Srivatsa", "Sanjana Srivastava", "Qingyang Wu", "Alpay Ariyak", "Xiaoxia Wu", "Ameen Patel", "Jue Wang", "Percy Liang", "Tri Dao", "Ce Zhang", "Yiying Zhang", "Ben Athiwaratkun", "Chenfeng Xu", "Junxiong Wang"], "title": "Beat the long tail: Distribution-Aware Speculative Decoding for RL Training", "comment": null, "summary": "Reinforcement learning(RL) post-training has become essential for aligning large language models (LLMs), yet its efficiency is increasingly constrained by the rollout phase, where long trajectories are generated token by token. We identify a major bottleneck:the long-tail distribution of rollout lengths, where a small fraction of long generations dominates wall clock time and a complementary opportunity; the availability of historical rollouts that reveal stable prompt level patterns across training epochs. Motivated by these observations, we propose DAS, a Distribution Aware Speculative decoding framework that accelerates RL rollouts without altering model outputs. DAS integrates two key ideas: an adaptive, nonparametric drafter built from recent rollouts using an incrementally maintained suffix tree, and a length aware speculation policy that allocates more aggressive draft budgets to long trajectories that dominate makespan. This design exploits rollout history to sustain acceptance while balancing base and token level costs during decoding. Experiments on math and code reasoning tasks show that DAS reduces rollout time up to 50% while preserving identical training curves, demonstrating that distribution-aware speculative decoding can significantly accelerate RL post training without compromising learning quality.", "AI": {"tldr": "DAS: \u4f7f\u7528\u5206\u5e03\u611f\u77e5\u7684\u63a8\u6d4b\u89e3\u7801\u6765\u52a0\u901fRL\u5bf9\u9f50\u4e2dLLMs\u7684 rollout\uff0c\u5229\u7528\u57fa\u4e8e\u5386\u53f2rollouts\u7684suffix\u6811\u6784\u5efa\u7684\u81ea\u9002\u5e94\u65e0\u53c2\u6570\u8349\u62df\u5668\u548c\u957f\u5ea6\u611f\u77e5\u7684\u63a8\u6d4b\u7b56\u7565\uff0c\u5728\u4e0d\u6539\u53d8\u6a21\u578b\u8f93\u51fa\u7684\u524d\u63d0\u4e0b\uff0c\u6700\u9ad8\u53ef\u63d0\u9ad850%\u7684 rollout\u901f\u5ea6\u3002", "motivation": "RL\u540e\u8bad\u7ec3\u5728\u5bf9\u9f50LLMs\u65f6\u9700\u8981\u5de8\u91cfrollout\uff0c\u4e14\u6eda\u52a8\u957f\u5ea6\u5448\u957f\u5c3e\u5206\u5e03\uff0c\u6781\u5c11\u6570\u957f\u751f\u6210\u5360\u7528\u5927\u90e8\u5206\u771f\u5b9e\u65f6\u95f4\uff1b\u540c\u65f6\u5386\u53f2rollouts\u63ed\u793a\u4e86\u8de8\u8bad\u7ec3\u5468\u671f\u7684\u7a33\u5b9a\u63d0\u793a\u5c42\u6a21\u5f0f\uff0c\u5982\u4f55\u5728\u4e0d\u635f\u5931\u5b66\u4e60\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u6548\u7387\u6210\u4e3a\u5173\u952e\u3002", "method": "\u63d0\u51faDAS\uff1a1) \u57fa\u4e8e\u6700\u8fd1rollouts\u7684\u81ea\u9002\u5e94\u975e\u53c2\u6570\u8349\u62df\u5668\uff0c\u5229\u7528\u589e\u91cf\u7ef4\u62a4\u7684\u540e\u7f00\u6811\u8fdb\u884c\u8349\u62df\uff1b2) \u7ed3\u5408\u957f\u5ea6\u611f\u77e5\u7684\u63a8\u6d4b\u7b56\u7565\uff0c\u7ed9\u8f83\u957f\u8f68\u8ff9\u5206\u914d\u66f4\u79ef\u6781\u7684\u8349\u62df\u9884\u7b97\uff0c\u4ece\u800c\u964d\u4f4e\u4e3b\u65f6\u5ef6\u5e76\u5e73\u8861\u57fa\u7840\u548c\u9010\u5b57\u89e3\u7801\u6210\u672c\u3002\u8be5\u8bbe\u8ba1\u5229\u7528\u5386\u53f2rollout\u6765\u7ef4\u6301\u63a5\u53d7\u5ea6\uff0c\u5e76\u5728\u89e3\u7801\u9636\u6bb5\u5b9e\u73b0\u6210\u672c\u7684\u6743\u8861\u3002", "result": "\u5728\u6570\u5b66\u4e0e\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\u4e0a\uff0cDAS\u5b9e\u73b0\u4e86 rollout \u65f6\u95f4\u6700\u9ad8\u53ef\u51cf\u5c11\u7ea650%\u7684\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u7b49\u6548\u7684\u8bad\u7ec3\u66f2\u7ebf\u548c\u5b66\u4e60\u8d28\u91cf\u3002", "conclusion": "\u5206\u5e03\u611f\u77e5\u7684\u63a8\u6d4b\u89e3\u7801\u80fd\u591f\u663e\u8457\u52a0\u901fRL\u540e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684rollout\u800c\u4e0d\u635f\u5bb3\u5b66\u4e60\u6548\u679c\uff0c\u5177\u6709\u5bf9LLM\u5bf9\u9f50\u4efb\u52a1\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.14319", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.14319", "abs": "https://arxiv.org/abs/2511.14319", "authors": ["Ignacio Sanchez", "Filiberto Fele", "Daniel Limon"], "title": "An adaptive extension to robust data-driven predictive control under parametric uncertainty", "comment": "6 pages, 2 figures. Comments are welcome!", "summary": "Robust data-driven controllers typically rely on datasets from previous experiments, which embed information on the variability of the system parameters across past operational conditions. Complementarily, data collected online can contribute to improving the feedback performance relative to the current system's conditions, but are unable to account for the overall -- possibly time-varying -- system operation.\n  With this in mind, we consider the problem of stabilizing a time-varying linear system, whose parameters are only known to lie within a bounded polytopic set. Taking a robust data-driven approach, we synthesize the control law by simultaneously leveraging two sets of historical state and input measures: an offline dataset -- which covers the extreme variations of the system parameters -- and an online dataset consisting of a rolling window of the latest state and input samples.\n  Our approach relies on the data informativity framework: we thus relax persistent excitation requirements (i.e., the collected samples need not be sufficient for system identification), while still allowing for the design of a stabilizing controller. The state feedback law is obtained from standard Lyapunov arguments, implemented via semi-definite optimization: this also yields an upper bound on the cost-to-go for the class of systems that are consistent with the online data, while guaranteeing a decreasing cost for all systems compatible with the offline data. Numerical experiments are presented to illustrate the effectiveness of the proposed controller.", "AI": {"tldr": "A robust data-driven control scheme for time-varying linear systems with polytopic uncertainty that fuses offline extreme-variation data and online rolling-window data via data informativity and SDP to achieve stabilization and a bound on the cost-to-go, without requiring full system identification.", "motivation": "Stabilize time-varying linear systems with uncertain parameters using data-driven methods that exploit both historical extremes and current online measurements, reducing reliance on system identification while maintaining guarantees.", "method": "Employ the data informativity framework to combine an offline dataset capturing extreme parameter variations with an online rolling window of recent state-input data. Use Lyapunov-based arguments implemented via semidefinite programming to synthesize a state-feedback controller. The approach yields an upper bound on the cost-to-go for systems consistent with the online data and ensures a decreasing cost for systems compatible with the offline data.", "result": "A stabilizing data-driven state-feedback controller is obtained via SDP, with an explicit bound on the cost-to-go for online-consistent systems and a guaranteed decrease of cost for offline-consistent systems; numerical experiments illustrate effectiveness.", "conclusion": "The proposed robust data-driven framework successfully stabilizes time-varying linear systems under bounded polytopic uncertainty by fusing offline extremes and online data, relaxing excitation requirements while providing performance guarantees and demonstrating practical efficacy."}}
{"id": "2511.13880", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.13880", "abs": "https://arxiv.org/abs/2511.13880", "authors": ["Saleh Momeni", "Changnan Xiao", "Bing Liu"], "title": "AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection", "comment": null, "summary": "This paper studies the problem of class-incremental learning (CIL), a core setting within continual learning where a model learns a sequence of tasks, each containing a distinct set of classes. Traditional CIL methods, which do not leverage pre-trained models (PTMs), suffer from catastrophic forgetting (CF) due to the need to incrementally learn both feature representations and the classifier. The integration of PTMs into CIL has recently led to efficient approaches that treat the PTM as a fixed feature extractor combined with analytic classifiers, achieving state-of-the-art performance. However, they still face a major limitation: the inability to continually adapt feature representations to best suit the CIL tasks, leading to suboptimal performance. To address this, we propose AnaCP (Analytic Contrastive Projection), a novel method that preserves the efficiency of analytic classifiers while enabling incremental feature adaptation without gradient-based training, thereby eliminating the CF caused by gradient updates. Our experiments show that AnaCP not only outperforms existing baselines but also achieves the accuracy level of joint training, which is regarded as the upper bound of CIL.", "AI": {"tldr": "\u63d0\u51fa AnaCP \u7684\u7c7b\u589e\u91cf\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u6027\u6295\u5f71\u5b9e\u73b0\u589e\u91cf\u7279\u5f81\u81ea\u9002\u5e94\uff0c\u540c\u65f6\u4fdd\u6301\u5206\u6790\u6027\u5206\u7c7b\u5668\u7684\u9ad8\u6548\u6027\uff0c\u5728\u4e0d\u8fdb\u884c\u68af\u5ea6\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u6d88\u9664\u8bb0\u5fc6\u707e\u96be\uff0c\u5e76\u8fbe\u5230\u8054\u5408\u8bad\u7ec3\u7684\u6c34\u5e73\u3002", "motivation": "\u5728\u6301\u7eed\u5b66\u4e60\u7684\u7c7b\u589e\u91cf\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0cCF \u4ecd\u7136\u662f\u6838\u5fc3\u96be\u9898\u3002\u5c3d\u7ba1\u628a\u9884\u8bad\u7ec3\u6a21\u578b\uff08PTM\uff09\u4f5c\u4e3a\u56fa\u5b9a\u7279\u5f81\u63d0\u53d6\u5668\u5e76\u7ed3\u5408\u89e3\u6790\u5206\u7c7b\u5668\u7684\u505a\u6cd5\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u4ecd\u65e0\u6cd5\u5bf9\u7279\u5f81\u8868\u793a\u8fdb\u884c\u589e\u91cf\u81ea\u9002\u5e94\uff0c\u5bfc\u81f4\u6027\u80fd\u53d7\u9650\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5728\u4e0d\u8fdb\u884c\u68af\u5ea6\u8bad\u7ec3\u7684\u524d\u63d0\u4e0b\u6301\u7eed\u8c03\u6574\u7279\u5f81\u8868\u793a\u7684\u65b9\u6848\u3002", "method": "\u63d0\u51fa AnaCP\uff08Analytic Contrastive Projection\uff09\uff0c\u5728\u4fdd\u6301\u89e3\u6790\u5206\u7c7b\u5668\u9ad8\u6548\u6027\u7684\u540c\u65f6\uff0c\u5229\u7528\u5206\u6790\u6027\u6295\u5f71\u5b9e\u73b0\u589e\u91cf\u7279\u5f81\u81ea\u9002\u5e94\uff0c\u907f\u514d\u68af\u5ea6\u66f4\u65b0\u5e26\u6765\u7684CF\u3002\u901a\u8fc7\u5bf9\u65b0\u4efb\u52a1\u7684\u7279\u5f81\u8fdb\u884c\u5bf9\u6bd4\u5b66\u4e60\u5f0f\u7684\u5206\u6790\u6027\u6295\u5f71\uff0c\u4f7f\u5f97\u7279\u5f81\u4e0e\u56fa\u5b9a\u5206\u7c7b\u5668\u4e4b\u95f4\u7684\u517c\u5bb9\u6027\u63d0\u5347\uff0c\u8fbe\u5230\u53ef\u589e\u91cf\u6269\u5c55\u800c\u4e0d\u4f9d\u8d56\u68af\u5ea6\u4f18\u5316\u7684\u7279\u5f81\u66f4\u65b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1aAnaCP\u5728\u591a\u9879\u57fa\u7ebf\u65b9\u6cd5\u4e0a\u5b9e\u73b0\u663e\u8457\u63d0\u5347\uff0c\u5e76\u8fbe\u5230\u4e0e\u8054\u5408\u8bad\u7ec3\u76f8\u8fd1\u751a\u81f3\u76f8\u540c\u7684\u51c6\u786e\u5ea6\uff0c\u63a5\u8fd1CIL\u7684\u4e0a\u754c\u3002", "conclusion": "AnaCP \u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u7c7b\u589e\u91cf\u5b66\u4e60\u65b0\u8303\u5f0f\uff1a\u5728\u4fdd\u6301\u5206\u6790\u6027\u5206\u7c7b\u5668\u4f18\u70b9\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u5206\u6790\u6027\u6295\u5f71\u5b9e\u73b0\u589e\u91cf\u7279\u5f81\u81ea\u9002\u5e94\uff0c\u6d88\u9664\u4e86\u56e0\u68af\u5ea6\u8bad\u7ec3\u5f15\u53d1\u7684\u9057\u5fd8\u95ee\u9898\uff0c\u63a5\u8fd1\u8054\u5408\u8bad\u7ec3\u7684\u6027\u80fd\u4e0a\u9650\u3002"}}
{"id": "2511.14003", "categories": ["cs.LG", "cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.14003", "abs": "https://arxiv.org/abs/2511.14003", "authors": ["Quoc Viet Vo", "Tashreque M. Haq", "Paul Montague", "Tamas Abraham", "Ehsan Abbasnejad", "Damith C. Ranasinghe"], "title": "Certified but Fooled! Breaking Certified Defences with Ghost Certificates", "comment": "Published as a conference paper at the Fortieth AAAI Conference on Artificial Intelligence (AAAI-26). Code available at: https://github.com/ghostcert/ghostcert", "summary": "Certified defenses promise provable robustness guarantees. We study the malicious exploitation of probabilistic certification frameworks to better understand the limits of guarantee provisions. Now, the objective is to not only mislead a classifier, but also manipulate the certification process to generate a robustness guarantee for an adversarial input certificate spoofing. A recent study in ICLR demonstrated that crafting large perturbations can shift inputs far into regions capable of generating a certificate for an incorrect class. Our study investigates if perturbations needed to cause a misclassification and yet coax a certified model into issuing a deceptive, large robustness radius for a target class can still be made small and imperceptible. We explore the idea of region-focused adversarial examples to craft imperceptible perturbations, spoof certificates and achieve certification radii larger than the source class ghost certificates. Extensive evaluations with the ImageNet demonstrate the ability to effectively bypass state-of-the-art certified defenses such as Densepure. Our work underscores the need to better understand the limits of robustness certification methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u901a\u8fc7\u6982\u7387\u8ba4\u8bc1\u6846\u67b6\u7684\u6076\u610f\u5229\u7528\u6765\u7406\u89e3\u9c81\u68d2\u6027\u8bc1\u660e\u7684\u5c40\u9650\uff0c\u63d0\u51fa\u533a\u57df\u805a\u7126\u7684\u5bf9\u6297\u6270\u52a8\u4ee5\u4f2a\u9020\u8bc1\u4e66\u5e76\u83b7\u5f97\u5bf9\u76ee\u6807\u7c7b\u522b\u7684\u8d85\u5927\u8ba4\u8bc1\u534a\u5f84\uff0c\u540c\u65f6\u5bf9 ImageNet \u4e0a\u7684 DensePure \u7b49\u65b9\u6cd5\u8fdb\u884c\u7ed5\u8fc7\u5b9e\u9a8c\u3002", "motivation": "\u9c81\u68d2\u6027\u8ba4\u8bc1\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u5176\u5b89\u5168\u6027\u4e0e\u53ef\u4fe1\u5ea6\u9762\u4e34\u6311\u6218\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u901a\u8fc7\u4f2a\u9020\u8bc1\u4e66\u6765\u8bef\u5bfc\u6a21\u578b\uff0c\u6216\u63d0\u5347\u9519\u8bef\u7c7b\u522b\u7684\u8ba4\u8bc1\u534a\u5f84\u3002", "method": "\u5206\u6790\u5e76\u8bbe\u8ba1\u5728\u6270\u52a8\u5c0f\u4e14\u4e0d\u53ef\u611f\u77e5\u7684\u524d\u63d0\u4e0b\uff0c\u4f7f\u8f93\u5165\u4ea7\u751f\u9519\u8bef\u5206\u7c7b\u5e76\u8bf1\u5bfc\u8ba4\u8bc1\u7cfb\u7edf\u53d1\u51fa\u5bf9\u76ee\u6807\u7c7b\u7684\u4f2a\u8bc1\u4e66\uff1b\u63d0\u51fa\u533a\u57df\u805a\u7126\u7684\u5bf9\u6297\u6837\u672c\u4ee5\u5b9e\u73b0\u8bc1\u4e66\u4f2a\u88c5\uff1b\u5728 ImageNet \u4e0a\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u5bf9 DensePure \u7b49\u6700\u65b0\u8ba4\u8bc1\u9632\u5fa1\u7684\u7ed5\u8fc7\u80fd\u529b\u3002", "result": "\u8bc1\u660e\u5b58\u5728\u80fd\u591f\u7ed5\u8fc7\u6700\u5148\u8fdb\u7684\u8ba4\u8bc1\u9632\u5fa1\u5e76\u4ea7\u751f\u6bd4\u6e90\u7c7b\u522b\u8bc1\u4e66\u66f4\u5927\u534a\u5f84\u7684\u5bf9\u6297\u6837\u672c\uff1bRegion-focused\u5bf9\u6297\u6837\u672c\u80fd\u5b9e\u73b0\u4e0d\u53ef\u611f\u77e5\u7684\u6270\u52a8\u5e76 spoof \u8bc1\u4e66\u3002", "conclusion": "\u8ba4\u8bc1\u9c81\u68d2\u6027\u5b58\u5728\u660e\u663e\u5c40\u9650\u6027\uff0c\u9700\u8981\u5bf9\u6982\u7387\u8bc1\u4e66\u6846\u67b6\u7684\u9c81\u68d2\u6027\u8fdb\u884c\u66f4\u6df1\u5165\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u7814\u7a76\uff0c\u63d0\u5347\u5bf9\u8bc1\u4e66\u6b3a\u9a97\u7684\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2511.14337", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.14337", "abs": "https://arxiv.org/abs/2511.14337", "authors": ["Ivo Kraayeveld", "Thomas de Jong", "Mircea Lazar"], "title": "Offset-free Data-Driven Predictive Control for Grid-Connected Power Converters in Weak Grid Faults", "comment": null, "summary": "Grid-connected power converters encounter significant stability challenges during weak grid faults, when conventional PI-based controllers exhibit an oscillatory response and poor fault-ride-through performance. This paper addresses this problem by replacing the conventional outer PI controllers that regulate DC-link and PCC voltages with an offset-free data-driven predictive controller. The developed algorithm leverages either pre-fault or fault-time data to construct input-output predictors, yielding offset-free control without the need for physics-based modelling. Simulation results show that pre-fault offset-free DPC doubles the critical equivalent grid impedance that can be handled and reduces the root mean squared error during faults by a factor of 40, while maintaining computation times comparable to conventional PI control. These findings demonstrate that the developed offset-free data predictive controller offers a simple, robust, and computationally efficient alternative to conventional control, significantly enhancing fault-ride-through capabilities of converters in weak grids.", "AI": {"tldr": "\u5728\u5f31\u7f51\u6545\u969c\u4e0b\uff0c\u4f7f\u7528\u504f\u79fb\u81ea\u7531\u6570\u636e\u9a71\u52a8\u9884\u6d4b\u63a7\u5236\u66ff\u4ee3 PI \u63a7\u5236\uff0c\u63d0\u5347\u5bb9\u9519\u4e0e\u9c81\u68d2\u6027\uff1b\u4eff\u771f\u663e\u793a\u663e\u8457\u63d0\u5347\u963b\u6297\u5bb9\u9650\u548c\u51cf\u5c0f\u8bef\u5dee\uff0c\u8ba1\u7b97\u6210\u672c\u63a5\u8fd1 PI\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf PI \u63a7\u5236\u5728\u5f31\u7f51\u6545\u969c\u4e2d\u7684\u632f\u8361\u4e0e\u6545\u969c\u7a7f\u8d8a\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u65e8\u5728\u63d0\u4f9b\u65e0\u9700\u7269\u7406\u5efa\u6a21\u4e14\u5bf9\u504f\u79fb\u5177\u9c81\u68d2\u6027\u7684\u63a7\u5236\u65b9\u6848\u3002", "method": "\u63d0\u51fa offset-free \u6570\u636e\u9a71\u52a8\u9884\u6d4b\u63a7\u5236\uff08DPC\uff09\uff0c\u5229\u7528\u6545\u969c\u524d\u6216\u6545\u969c\u65f6\u6570\u636e\u6784\u5efa\u8f93\u5165\u8f93\u51fa\u9884\u6d4b\u5668\uff0c\u66ff\u4ee3\u5916\u73af PI \u8c03\u8282\u76f4\u6d41\u73af\u8def\u4e0e PCC \u7535\u538b\uff0c\u8fbe\u5230\u504f\u79fb\u81ea\u7531\u63a7\u5236\u3002", "result": "\u4eff\u771f\u8868\u660e\uff1a\u524d\u6545\u969c\u504f\u79fb\u81ea\u7531 DPC \u53ef\u5c06\u53ef\u5904\u7406\u7684\u4e34\u754c\u7b49\u6548\u7f51\u963b\u6297\u7ffb\u500d\uff1b\u6545\u969c\u671f\u95f4 RMSE \u964d\u4f4e\u7ea6 40 \u500d\uff1b\u8ba1\u7b97\u65f6\u95f4\u4e0e\u4f20\u7edf PI \u76f8\u5f53\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5f31\u7f51\u4e0b\u53d8\u6d41\u5668\u63d0\u4f9b\u7b80\u5355\u3001\u9c81\u68d2\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u66ff\u4ee3\u63a7\u5236\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u6545\u969c\u7a7f\u8d8a\u80fd\u529b\u3002"}}
{"id": "2511.13888", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13888", "abs": "https://arxiv.org/abs/2511.13888", "authors": ["Nicolas M. Cuadrado A.", "Mohannad Takrouri", "Ji\u0159\u00ed N\u011bme\u010dek", "Martin Tak\u00e1\u010d", "Jakub Mare\u010dek"], "title": "Tractable Probabilistic Models for Investment Planning", "comment": null, "summary": "Investment planning in power utilities, such as generation and transmission expansion, requires decade-long forecasts under profound uncertainty. Forecasting of energy mix and energy use decades ahead is nontrivial. Classical approaches focus on generating a finite number of scenarios (modeled as a mixture of Diracs in statistical theory terms), which limits insight into scenario-specific volatility and hinders robust decision-making. We propose an alternative using tractable probabilistic models (TPMs), particularly sum-product networks (SPNs). These models enable exact, scalable inference of key quantities such as scenario likelihoods, marginals, and conditional probabilities, supporting robust scenario expansion and risk assessment.\n  This framework enables direct embedding of chance-constrained optimization into investment planning, enforcing safety or reliability with prescribed confidence levels. TPMs allow both scenario analysis and volatility quantification by compactly representing high-dimensional uncertainties. We demonstrate the approach's effectiveness through a representative power system planning case study, illustrating computational and reliability advantages over traditional scenario-based models.", "AI": {"tldr": "\u4f7f\u7528\u53ef\u5207\u5b9e\u53ef\u63a8\u65ad\u7684\u6982\u7387\u6a21\u578b\uff08Sum-Product Networks\uff0cSPN\uff09\u6765\u5bf9\u7535\u529b\u7cfb\u7edf\u6295\u8d44\u89c4\u5212\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u7cbe\u786e\u63a8\u65ad\uff0c\u4ece\u800c\u5b9e\u73b0\u7a33\u5065\u7684\u60c5\u666f\u5206\u6790\u548c\u76f4\u63a5\u5d4c\u5165\u673a\u4f1a\u7ea6\u675f\u7684\u4f18\u5316\uff0c\u7ed3\u679c\u5728\u4e00\u4e2a\u4ee3\u8868\u6027\u6848\u4f8b\u4e2d\u663e\u793a\u51fa\u76f8\u8f83\u4f20\u7edf\u60c5\u666f\u6a21\u578b\u7684\u8ba1\u7b97\u4e0e\u53ef\u9760\u6027\u4f18\u52bf\u3002", "motivation": "\u5728\u51e0\u5341\u5e74\u5c3a\u5ea6\u4e0a\u7684\u80fd\u6e90\u7ed3\u6784\u4e0e\u9700\u6c42\u9884\u6d4b\u5b58\u5728\u6df1\u523b\u4e0d\u786e\u5b9a\u6027\uff0c\u4f20\u7edf\u7684\u6709\u9650\u60c5\u666f\u65b9\u6cd5\u96be\u4ee5\u63ed\u793a\u60c5\u666f\u7279\u5b9a\u7684\u6ce2\u52a8\u6027\uff0c\u5f71\u54cd\u7a33\u5065\u51b3\u7b56\u3002", "method": "\u91c7\u7528\u53ef\u63a8\u65ad\u7684\u6982\u7387\u6a21\u578b\uff08TPM\uff09\uff0c\u7279\u522b\u662f Sum-Product Networks\uff08SPN\uff09\uff0c\u5bf9\u9ad8\u7ef4\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u9ad8\u6548\u3001\u53ef\u7cbe\u786e\u63a8\u65ad\uff0c\u6c42\u53d6\u60c5\u666f\u4f3c\u7136\u3001\u8fb9\u7f18\u3001\u6761\u4ef6\u6982\u7387\u7b49\u5e76\u5d4c\u5165\u5230\u673a\u4f1a\u7ea6\u675f\u4f18\u5316\u4e2d\uff1b\u4e0e\u4f20\u7edf\u60c5\u666f\u6a21\u578b\u5bf9\u6bd4\u5c55\u793a\u4f18\u52bf\u3002", "result": "\u901a\u8fc7\u4e00\u4e2a\u4ee3\u8868\u6027\u7684\u7535\u529b\u7cfb\u7edf\u89c4\u5212\u6848\u4f8b\uff0c\u8bc1\u660e TPM\uff08SPN\uff09\u5728\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u9760\u6027\u8bc4\u4f30\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u57fa\u4e8e\u60c5\u666f\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u76f4\u63a5\u8fdb\u884c\u60c5\u666f\u5206\u6790\u4e0e\u6ce2\u52a8\u6027\u91cf\u5316\u3002", "conclusion": "TPMs\uff08\u5c24\u5176\u662f SPN\uff09\u4e3a\u5728\u6df1\u5ea6\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u7535\u529b\u7cfb\u7edf\u6295\u8d44\u89c4\u5212\u63d0\u4f9b\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u5b9e\u73b0\u7684\u7a33\u5065\u6846\u67b6\uff0c\u4fbf\u4e8e\u5b9e\u73b0\u673a\u4f1a\u7ea6\u675f\u4e0e\u98ce\u9669\u8bc4\u4f30\u3002"}}
{"id": "2511.14084", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14084", "abs": "https://arxiv.org/abs/2511.14084", "authors": ["Iden Kalemaj", "Luca Melis", "Maxime Boucher", "Ilya Mironov", "Saeed Mahloujifar"], "title": "Observational Auditing of Label Privacy", "comment": null, "summary": "Differential privacy (DP) auditing is essential for evaluating privacy guarantees in machine learning systems. Existing auditing methods, however, pose a significant challenge for large-scale systems since they require modifying the training dataset -- for instance, by injecting out-of-distribution canaries or removing samples from training. Such interventions on the training data pipeline are resource-intensive and involve considerable engineering overhead. We introduce a novel observational auditing framework that leverages the inherent randomness of data distributions, enabling privacy evaluation without altering the original dataset. Our approach extends privacy auditing beyond traditional membership inference to protected attributes, with labels as a special case, addressing a key gap in existing techniques. We provide theoretical foundations for our method and perform experiments on Criteo and CIFAR-10 datasets that demonstrate its effectiveness in auditing label privacy guarantees. This work opens new avenues for practical privacy auditing in large-scale production environments.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.14358", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.14358", "abs": "https://arxiv.org/abs/2511.14358", "authors": ["Kai Ren", "Maryam Kamgarpour"], "title": "Identifying Time-varying Costs in Finite-horizon Linear Quadratic Gaussian Games", "comment": null, "summary": "We address cost identification in a finite-horizon linear quadratic Gaussian game. We characterize the set of cost parameters that generate a given Nash equilibrium policy. We propose a backpropagation algorithm to identify the time-varying cost parameters. We derive a probabilistic error bound when the cost parameters are identified from finite trajectories. We test our method in numerical and driving simulations. Our algorithm identifies the cost parameters that can reproduce the Nash equilibrium policy and trajectory observations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.14406", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14406", "abs": "https://arxiv.org/abs/2511.14406", "authors": ["Bastien Vuillod", "Pierre-Alain Moellic", "Jean-Max Dutertre"], "title": "Watch Out for the Lifespan: Evaluating Backdoor Attacks Against Federated Model Adaptation", "comment": "Accepted at FPS 2025", "summary": "Large models adaptation through Federated Learning (FL) addresses a wide range of use cases and is enabled by Parameter-Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA). However, this distributed learning paradigm faces several security threats, particularly to its integrity, such as backdoor attacks that aim to inject malicious behavior during the local training steps of certain clients. We present the first analysis of the influence of LoRA on state-of-the-art backdoor attacks targeting model adaptation in FL. Specifically, we focus on backdoor lifespan, a critical characteristic in FL, that can vary depending on the attack scenario and the attacker's ability to effectively inject the backdoor. A key finding in our experiments is that for an optimally injected backdoor, the backdoor persistence after the attack is longer when the LoRA's rank is lower. Importantly, our work highlights evaluation issues of backdoor attacks against FL and contributes to the development of more robust and fair evaluations of backdoor attacks, enhancing the reliability of risk assessments for critical FL systems. Our code is publicly available.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u5206\u6790\u4e86\u5728\u8054\u90a6\u5b66\u4e60\u4e2dLoRA\u5bf9\u540e\u95e8\u653b\u51fb\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5bf9\u6700\u4f73\u6ce8\u5165\u60c5\u5f62\uff0cLoRA\u79e9\u8f83\u4f4e\u65f6\u540e\u95e8\u6301\u4e45\u6027\u66f4\u9ad8\uff0c\u5e76\u63ed\u793a\u8bc4\u4f30\u540e\u95e8\u653b\u51fb\u5728FL\u4e2d\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5927\u6a21\u578b\u5728\u5206\u5e03\u5f0f\u3001\u9690\u79c1\u4fdd\u62a4\u573a\u666f\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u7406\u89e3\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08\u5982LoRA\uff09\u5bf9\u5b89\u5168\u6027\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u540e\u95e8\u653b\u51fb\u7684\u6301\u7eed\u6027\u4e0e\u8bc4\u4f30\u516c\u6b63\u6027\uff0c\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u5728\u4e0d\u540cLoRA\u79e9\u8bbe\u7f6e\u4e0b\uff0c\u7cfb\u7edf\u8bc4\u4f30\u540e\u95e8\u5728FL\u4e2d\u7684\u5bff\u547d\uff08backdoor lifespan\uff09\uff0c\u5206\u6790\u653b\u51fb\u573a\u666f\u4e0e\u653b\u51fb\u8005\u6ce8\u5165\u80fd\u529b\u5bf9\u6301\u4e45\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u4f9b\u516c\u5f00\u53ef\u7528\u7684\u5b9e\u73b0\u4ee3\u7801\u3002", "result": "\u5173\u952e\u53d1\u73b0\uff1a\u5bf9\u4e8e\u6700\u4f18\u6ce8\u5165\u7684\u540e\u95e8\uff0cLoRA\u79e9\u8f83\u4f4e\u65f6\u540e\u95e8\u7684\u6301\u4e45\u6027\u66f4\u957f\uff1bLoRA\u5bf9\u540e\u95e8\u653b\u51fb\u7684\u5f71\u54cd\u53d6\u51b3\u4e8e\u5177\u4f53\u6ce8\u5165\u6761\u4ef6\uff0c\u4e14\u63ed\u793a\u4e86\u8bc4\u4f30FL\u4e2d\u540e\u95e8\u653b\u51fb\u7684\u6f5c\u5728\u504f\u5dee\u548c\u95ee\u9898\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63a8\u52a8\u5bf9FL\u73af\u5883\u4e0b\u540e\u95e8\u653b\u51fb\u8bc4\u4f30\u65b9\u6cd5\u7684\u6539\u8fdb\uff0c\u4fc3\u8fdb\u66f4\u5065\u58ee\u3001\u516c\u5e73\u7684\u5b89\u5168\u98ce\u9669\u8bc4\u4f30\uff0c\u5e76\u63d0\u5347\u5bf9\u5173\u952eFL\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u8ba4\u77e5\u3002"}}
{"id": "2511.14447", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.14447", "abs": "https://arxiv.org/abs/2511.14447", "authors": ["Ilan Kurtser", "Yoav Koral", "Eldad Holdengreber", "Shmuel E. Schacham", "Eliyahu Farber"], "title": "Ultra-Low Insertion Loss Stepped Impedance Resonator Topology for HTSC RF Front-End", "comment": null, "summary": "We present the design, fabrication, and measurement of a high-temperature superconductor (HTSC) Stepped Impedance Resonator (SIR) band-pass filter for S-band applications, and its incorporation into a cryogenic receiver cascade. The 11-pole filter, implemented in YBa2Cu3O(7-x) (YBCO) thin films on sapphire, exhibits an ultra-low insertion loss (IL) of -0.1~dB, a sharp roll-off of 100~MHz, and a rejection level exceeding --80~dB. These measured results represent, to the best of our knowledge, the lowest reported IL for an S-band filter with this number of poles. When integrated with a cryogenic low-noise amplifier (LNA), system-level simulations and measurements predict a receiver noise figure (NF) of 0.34~dB at 3.39~GHz, enabling a 20% increase in radar detection range compared with conventional copper-based front ends. This work demonstrates the feasibility of practical HTSC-based RF front-ends for next-generation communication and radar systems.", "AI": {"tldr": "11-pole HTSC SIR S-band filter using YBCO on sapphire achieves ultra-low insertion loss (-0.1 dB), sharp roll-off (~100 MHz), and high rejection (>80 dB); when integrated with a cryogenic LNA, system-level analysis predicts a noise figure of ~0.34 dB at 3.39 GHz, enabling ~20% radar range improvement over copper front ends. Demonstrates feasibility of practical HTSC RF front-ends for future communication and radar systems.", "motivation": "\u5728\u4f4e\u6e29\u6761\u4ef6\u4e0b\u63d0\u9ad8\u5c04\u9891\u524d\u7aef\u7684\u7075\u654f\u5ea6\u548c\u5e26\u901a\u9009\u62e9\u6027\uff0c\u4ee5\u5b9e\u73b0\u66f4\u957f\u63a2\u6d4b\u8ddd\u79bb\u548c\u66f4\u4f4e\u566a\u58f0\uff1bHTSC\u6750\u6599\u7684\u6781\u4f4e\u635f\u8017\u7ed3\u5408SIR\u62d3\u6251\u6709\u6f5c\u529b\u663e\u8457\u63d0\u5347S-band\u524d\u7aef\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u3001\u5236\u5907\u5e76\u6d4b\u8bd511\u9636\uff0811-pole\uff09YBCO\u8584\u819cSIR\u6ee4\u6ce2\u5668\uff0c\u57fa\u4e8e\u84dd\u5b9d\u77f3\u886c\u5e95\uff0c\u5b9e\u73b0S\u6ce2\u6bb5\u5e94\u7528\uff1b\u6d4b\u91cf\u63d2\u5165\u635f\u8017\u3001\u6eda\u964d\u548c\u6291\u5236\uff1b\u4e0e\u4f4e\u6e29LNA\u8026\u5408\uff0c\u8fdb\u884c\u7cfb\u7edf\u7ea7\u4eff\u771f\u4e0e\u6d4b\u91cf\u4ee5\u4f30\u7b97NF\u53ca\u63a2\u6d4b\u8ddd\u79bb\u6539\u8fdb\uff1b", "result": "\u63d2\u5165\u635f\u8017\u7ea6-0.1 dB\uff0c\u6eda\u964d\u7ea6100 MHz\uff0c\u6291\u5236>80 dB\uff1b\u4e0eLNA\u8026\u5408\u65f6\u9884\u6d4b\u57283.39 GHz\u5904NF\u7ea60.34 dB\uff0cRadar\u63a2\u6d4b\u8ddd\u79bb\u53ef\u6bd4\u94dc\u57fa\u524d\u7aef\u63d0\u5347\u7ea620%\u3002", "conclusion": "\u663e\u793a\u57fa\u4e8eHTSC\u7684RF\u524d\u7aef\u5728\u4e0b\u4e00\u4ee3\u901a\u4fe1\u548c\u96f7\u8fbe\u7cfb\u7edf\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5c24\u5176\u5728\u4f4e\u6e29\u6761\u4ef6\u4e0b\u53ef\u663e\u8457\u964d\u4f4e\u566a\u58f0\u548c\u63d0\u5347\u63a2\u6d4b\u8ddd\u79bb\u3002"}}
{"id": "2511.14478", "categories": ["eess.SY", "cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2511.14478", "abs": "https://arxiv.org/abs/2511.14478", "authors": ["Soham Ghosh", "Gaurav Mittal"], "title": "Agentic AI Systems in Electrical Power Systems Engineering: Current State-of-the-Art and Challenges", "comment": null, "summary": "Agentic AI systems have recently emerged as a critical and transformative approach in artificial intelligence, offering capabilities that extend far beyond traditional AI agents and contemporary generative AI models. This rapid evolution necessitates a clear conceptual and taxonomical understanding to differentiate this new paradigm. Our paper addresses this gap by providing a comprehensive review that establishes a precise definition and taxonomy for \"agentic AI,\" with the aim of distinguishing it from previous AI paradigms. The concepts are gradually introduced, starting with a highlight of its diverse applications across the broader field of engineering. The paper then presents four detailed, state-of-the-art use case applications specifically within electrical engineering. These case studies demonstrate practical impact, ranging from an advanced agentic framework for streamlining complex power system studies and benchmarking to a novel system developed for survival analysis of dynamic pricing strategies in battery swapping stations. Finally, to ensure robust deployment, the paper provides detailed failure mode investigations. From these findings, we derive actionable recommendations for the design and implementation of safe, reliable, and accountable agentic AI systems, offering a critical resource for researchers and practitioners.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5bf9\u201cagentic AI\u201d\u7684\u5b9a\u4e49\u4e0e\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u4ee5\u7535\u6c14\u5de5\u7a0b\u4e2d\u7684\u56db\u4e2a\u524d\u6cbf\u7528\u4f8b\u4e3a\u652f\u6491\uff0c\u5c55\u793a\u5176\u5728\u5de5\u7a0b\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u8f85\u4ee5\u6545\u969c\u6a21\u5f0f\u5206\u6790\u4e0e\u8bbe\u8ba1\u5efa\u8bae\uff0c\u65e8\u5728\u7ed9\u51fa\u5b89\u5168\u3001\u53ef\u9760\u3001\u53ef\u95ee\u8d23\u7684\u5b9e\u73b0\u8def\u7ebf\u3002", "motivation": "\u968f\u7740 agentic AI \u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u5176\u80fd\u529b\u4e0e\u98ce\u9669\u5e76\u5b58\uff0c\u4e9f\u9700\u6e05\u6670\u7684\u6982\u5ff5\u6846\u67b6\u548c\u5206\u7c7b\u4ee5\u5f15\u5bfc\u7814\u7a76\u4e0e\u4ea7\u4e1a\u5e94\u7528\uff0c\u907f\u514d\u6df7\u6dc6\u4e0e\u6ee5\u7528\u3002", "method": "\u8fdb\u884c\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u63d0\u51fa\u5b9a\u4e49\u4e0e\u5206\u7c7b\uff08taxonomy\uff09\uff0c\u5e76\u7ed3\u5408\u7535\u6c14\u5de5\u7a0b\u4e2d\u7684\u56db\u4e2a\u5177\u4f53\u7528\u4f8b\u8fdb\u884c\u6848\u4f8b\u5206\u6790\uff0c\u540c\u65f6\u7ed9\u51fa\u6545\u969c\u6a21\u5f0f\u5206\u6790\u4e0e\u8bbe\u8ba1\u8981\u70b9\u3002", "result": "\u5efa\u7acb\u4e86\u5173\u4e8e agentic AI \u7684\u660e\u786e\u5b9a\u4e49\u4e0e\u5206\u5c42/\u5206\u7c7b\u6846\u67b6\uff0c\u5c55\u793a\u5176\u5728\u7535\u529b\u7cfb\u7edf\u7814\u7a76\u3001\u52a8\u6001\u5b9a\u4ef7\u4e0e\u7535\u6c60\u5171\u4eab\u7b49\u573a\u666f\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u4ee5\u53ca\u76f8\u5e94\u7684\u5b89\u5168\u4e0e\u53ef\u95ee\u8d23\u8981\u70b9\u3002", "conclusion": "\u4e3a\u7814\u7a76\u8005\u4e0e\u4ece\u4e1a\u8005\u63d0\u4f9b\u8bbe\u8ba1\u4e0e\u5b9e\u73b0 agentic AI \u7684\u5b89\u5168\u3001\u53ef\u9760\u3001\u53ef\u95ee\u8d23\u7684\u8def\u7ebf\u56fe\u4e0e\u53c2\u8003\u6846\u67b6\u3002"}}
{"id": "2511.13952", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13952", "abs": "https://arxiv.org/abs/2511.13952", "authors": ["Micha\u0142 Iwaniuk", "Mateusz Jarosz", "Bart\u0142omiej Borycki", "Bartosz Jezierski", "Jan Cwalina", "Stanis\u0142aw Ka\u017amierczak", "Jacek Ma\u0144dziuk"], "title": "The Impact of Bootstrap Sampling Rate on Random Forest Performance in Regression Tasks", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Random Forests (RFs) typically train each tree on a bootstrap sample of the same size as the training set, i.e., bootstrap rate (BR) equals 1.0. We systematically examine how varying BR from 0.2 to 5.0 affects RF performance across 39 heterogeneous regression datasets and 16 RF configurations, evaluating with repeated two-fold cross-validation and mean squared error. Our results demonstrate that tuning the BR can yield significant improvements over the default: the best setup relied on BR \\leq 1.0 for 24 datasets, BR > 1.0 for 15, and BR = 1.0 was optimal in 4 cases only. We establish a link between dataset characteristics and the preferred BR: datasets with strong global feature-target relationships favor higher BRs, while those with higher local target variance benefit from lower BRs. To further investigate this relationship, we conducted experiments on synthetic datasets with controlled noise levels. These experiments reproduce the observed bias-variance trade-off: in low-noise scenarios, higher BRs effectively reduce model bias, whereas in high-noise settings, lower BRs help reduce model variance. Overall, BR is an influential hyperparameter that should be tuned to optimize RF regression models.", "AI": {"tldr": "\u8c03\u53c2\u5173\u952e\u4fe1\u606f\uff1a\u968f\u673a\u68ee\u6797\u56de\u5f52\u4e2d\u81ea\u4e3e\u6837\u672c\u6bd4\u4f8b\uff08BR\uff09\u5bf9\u6027\u80fd\u5f71\u54cd\u663e\u8457\uff0c\u975e\u9ed8\u8ba4 BR \u5e38\u5e38\u4f18\u4e8e BR=1.0\uff0c\u4e14\u6700\u4f18 BR \u53d6\u51b3\u4e8e\u6570\u636e\u7279\u5f81\u4e0e\u566a\u58f0\u6c34\u5e73\u3002", "motivation": "BR \u662f\u4e00\u4e2a\u5e38\u8bbe\u9ed8\u8ba4\u503c\uff08BR=1.0\uff09\uff0c\u4f46\u5176\u5bf9\u56de\u5f52\u6027\u80fd\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7cfb\u7edf\u7814\u7a76\uff1b\u63ed\u793a BR \u4e0e\u6570\u636e\u7279\u5f81\u4e4b\u95f4\u7684\u5173\u7cfb\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u5b9a\u5236 RF \u56de\u5f52\u6a21\u578b\u3002", "method": "\u572839\u4e2a\u5f02\u8d28\u56de\u5f52\u6570\u636e\u96c6\u548c16\u79cd RF \u914d\u7f6e\u4e0b\uff0c\u7cfb\u7edf\u6027\u5730\u5c06 BR \u4ece0.2\u52305.0\u8fdb\u884c\u53d8\u5316\uff0c\u901a\u8fc7\u91cd\u590d\u4e24\u6298\u4ea4\u53c9\u9a8c\u8bc1\u548c\u5747\u65b9\u8bef\u5dee\u8bc4\u4f30\u6027\u80fd\uff1b\u6b64\u5916\u5728\u53d7\u63a7\u566a\u58f0\u7684\u5408\u6210\u6570\u636e\u4e0a\u7814\u7a76\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u3002", "result": "\u6700\u4f73 BR \u572824\u4e2a\u6570\u636e\u96c6\u4e3a BR \u2264 1.0\uff0c15\u4e2a\u6570\u636e\u96c6 BR > 1.0\uff0c\u53ea\u67094\u4e2a\u6570\u636e\u96c6 BR=1.0 \u6700\u4f18\uff1b\u6570\u636e\u96c6\u7279\u5f81\u4e0eBR\u504f\u597d\u5b58\u5728\u5173\u8054\uff1a\u5f53\u5168\u5c40\u7279\u5f81-\u76ee\u6807\u5173\u7cfb\u5f3a\u65f6\u504f\u597d\u66f4\u9ad8 BR\uff1b\u5f53\u5c40\u90e8\u76ee\u6807\u65b9\u5dee\u8f83\u9ad8\u65f6\u504f\u597d\u66f4\u4f4e BR\u3002\u5408\u6210\u6570\u636e\u8868\u660e\u4f4e\u566a\u58f0\u4e0b\u9ad8 BR \u80fd\u964d\u4f4e\u504f\u5dee\uff0c\u9ad8\u566a\u58f0\u4e0b\u4f4e BR \u80fd\u964d\u4f4e\u65b9\u5dee\uff0c\u9a8c\u8bc1\u4e86\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u3002", "conclusion": "BR \u662f\u4e00\u4e2a\u5177\u6709\u663e\u8457\u5f71\u54cd\u7684\u8d85\u53c2\u6570\uff0c\u5e94\u5bf9\u56de\u5f52\u968f\u673a\u68ee\u6797\u8fdb\u884c\u8c03\u4f18\uff1b\u57fa\u4e8e\u6570\u636e\u96c6\u7684\u5168\u5c40\u5173\u7cfb\u4e0e\u566a\u58f0\u6c34\u5e73\u7ed9\u51fa BR \u7684\u9009\u53d6\u65b9\u5411\uff0c\u63d0\u5347 RF \u56de\u5f52\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2511.14652", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.14652", "abs": "https://arxiv.org/abs/2511.14652", "authors": ["Mahmood Mazare", "Hossein Ramezani"], "title": "Robust Offset-free Kernelized Data-Driven Predictive Control for Nonlinear Systems", "comment": null, "summary": "This paper proposes a novel Kernelized Data-Driven Predictive Control (KDPC) scheme for robust, offset-free tracking of nonlinear systems. Our computationally efficient hybrid approach separates the prediction: (1) kernel ridge regression learns the nonlinear map from past trajectories, and (2) analytical linearization of the kernel map approximates the effect of future inputs. This linearization is key, allowing the controller to be formulated as a standard Quadratic Program (QP) for efficient real-time implementation. Offset-free tracking is inherently achieved by using input increments. We provide theoretical guarantees for recursive feasibility and asymptotic stability. The algorithm is validated on a nonlinear Van der Pol oscillator, where it successfully rejects unmeasured disturbances and eliminates steady-state errors, outperforming a standard model-based controller.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd Kernelized Data-Driven Predictive Control (KDPC)\uff0c\u901a\u8fc7\u6838\u5cad\u56de\u5f52\u5b66\u4e60\u975e\u7ebf\u6027\u6620\u5c04\u5e76\u5bf9\u6838\u6620\u5c04\u8fdb\u884c\u89e3\u6790\u7ebf\u6027\u5316\uff0c\u4f7f\u9884\u6d4b\u53ef\u8f6c\u5316\u4e3a\u6807\u51c6\u4e8c\u6b21\u89c4\u5212\uff08QP\uff09\uff0c\u5b9e\u73b0\u9c81\u68d2\u7684\u3001\u65e0\u504f\u5dee\u7684\u8ddf\u8e2a\u5e76\u5177\u5907\u6536\u655b\u6027\u4e0e\u53ef\u884c\u6027\u4fdd\u8bc1\uff1b\u5728 Van der Pol \u632f\u8361\u5668\u4e0a\u9a8c\u8bc1\uff0c\u6297\u6270\u4e14\u6d88\u9664\u7a33\u6001\u8bef\u5dee\uff0c\u6027\u80fd\u4f18\u4e8e\u6807\u51c6\u6a21\u578b\u4e3a\u57fa\u7840\u7684\u63a7\u5236\u5668\u3002", "motivation": "\u89e3\u51b3\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u9c81\u68d2\u8ddf\u8e2a\u4e0e\u5b9e\u65f6\u5b9e\u73b0\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u672a\u77e5\u6270\u52a8\u548c\u504f\u7f6e\u65f6\u53ef\u80fd\u4e0d\u5177\u5907\u65e0\u504f\u8ddf\u8e2a\u80fd\u529b\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u901a\u8fc7\u5c06\u6570\u636e\u9a71\u52a8\u7684\u6838\u65b9\u6cd5\u4e0e\u7ebf\u6027\u5316\u7b56\u7565\u7ed3\u5408\uff0c\u63d0\u4f9b\u4e00\u4e2a\u5728\u7406\u8bba\u4e0a\u5177\u5907\u53ef\u884c\u6027\u4e0e\u6e10\u8fd1\u7a33\u5b9a\u6027\u7684\u9ad8\u6548\u63a7\u5236\u6846\u67b6\u3002", "method": "\u628a\u9884\u6d4b\u8fc7\u7a0b\u5206\u6210\u4e24\u6b65\uff1a1) \u4f7f\u7528\u6838\u5cad\u56de\u5f52\u4ece\u5386\u53f2\u8f68\u8ff9\u5b66\u4e60\u975e\u7ebf\u6027\u6620\u5c04\uff1b2) \u5bf9\u6838\u6620\u5c04\u8fdb\u884c\u89e3\u6790\u7ebf\u6027\u5316\uff0c\u4ee5\u8fd1\u4f3c\u672a\u6765\u8f93\u5165\u7684\u5f71\u54cd\uff0c\u4f7f\u63a7\u5236\u5668\u53ef\u5199\u6210\u4e00\u4e2a\u6807\u51c6\u7684\u4e8c\u6b21\u89c4\u5212\uff08QP\uff09\u5f62\u5f0f\u5b9e\u73b0\u5b9e\u65f6\u8ba1\u7b97\u3002\u504f\u7f6e\u8ddf\u8e2a\u901a\u8fc7\u8f93\u5165\u589e\u91cf\u5b9e\u73b0\u65e0\u504f\u5dee\u4fe1\u53f7\u3002\u7406\u8bba\u4e0a\u7ed9\u51fa\u9012\u5f52\u53ef\u884c\u6027\u548c\u6e10\u8fd1\u7a33\u5b9a\u6027\u4fdd\u8bc1\u3002", "result": "\u7ed9\u51fa\u9012\u5f52\u53ef\u884c\u6027\u4e0e\u6e10\u8fd1\u7a33\u5b9a\u6027\u7684\u7406\u8bba\u4fdd\u969c\u3002\u4eff\u771f/\u9a8c\u8bc1\u5728\u975e\u7ebf\u6027 Van der Pol \u632f\u8361\u5668\u4e0a\u8fdb\u884c\uff0c\u80fd\u591f\u6709\u6548\u6291\u5236\u672a\u6d4b\u6270\u52a8\u3001\u6d88\u9664\u7a33\u6001\u8bef\u5dee\uff0c\u6027\u80fd\u4f18\u4e8e\u6807\u51c6\u6a21\u578b\u4e3a\u57fa\u7840\u7684\u63a7\u5236\u5668\u3002", "conclusion": "KDPC \u63d0\u4f9b\u4e00\u4e2a\u8ba1\u7b97\u9ad8\u6548\u4e14\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u975e\u7ebf\u6027\u7cfb\u7edf\u9c81\u68d2\u3001\u65e0\u504f\u8ddf\u8e2a\u7684\u63a7\u5236\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u63a7\u5236\u4efb\u52a1\u3002\u901a\u8fc7\u6838\u5b66\u4e60\u4e0e\u7ebf\u6027\u5316\u76f8\u7ed3\u5408\u5b9e\u73b0\u7684 QP \u6c42\u89e3\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u6f5c\u5728\u7684\u666e\u9002\u6027\u548c\u6269\u5c55\u6027\u3002"}}
{"id": "2511.13981", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13981", "abs": "https://arxiv.org/abs/2511.13981", "authors": ["Ashwin Saraswatula", "David Klindt"], "title": "Data Whitening Improves Sparse Autoencoder Learning", "comment": "Accepted to the AAAI 2026 XAI4Science Workshop", "summary": "Sparse autoencoders (SAEs) have emerged as a promising approach for learning interpretable features from neural network activations. However, the optimization landscape for SAE training can be challenging due to correlations in the input data. We demonstrate that applying PCA Whitening to input activations -- a standard preprocessing technique in classical sparse coding -- improves SAE performance across multiple metrics. Through theoretical analysis and simulation, we show that whitening transforms the optimization landscape, making it more convex and easier to navigate. We evaluate both ReLU and Top-K SAEs across diverse model architectures, widths, and sparsity regimes. Empirical evaluation on SAEBench, a comprehensive benchmark for sparse autoencoders, reveals that whitening consistently improves interpretability metrics, including sparse probing accuracy and feature disentanglement, despite minor drops in reconstruction quality. Our results challenge the assumption that interpretability aligns with an optimal sparsity--fidelity trade-off and suggest that whitening should be considered as a default preprocessing step for SAE training, particularly when interpretability is prioritized over perfect reconstruction.", "AI": {"tldr": "PCA whitening of input activations improves interpretability and optimization ease for sparse autoencoders, with a slight drop in reconstruction; suggests whitening as default preprocessing when interpretability is priority.", "motivation": "Interpretability of features learned by SAEs is hindered by correlated inputs; improved optimization landscape could enhance interpretability metrics.", "method": "Apply PCA whitening to SAE inputs; theoretical analysis showing convexification; empirical evaluation of ReLU and Top-K SAEs across architectures, widths, and sparsity using SAEBench; measure interpretability metrics (sparse probing accuracy, feature disentanglement) and reconstruction quality.", "result": "Whitening consistently improves interpretability metrics and makes optimization landscape more convex; minor decrease in reconstruction quality.", "conclusion": "PCA whitening should be considered a default preprocessing step for SAE training when interpretability is prioritized over reconstruction fidelity; the link between sparsity-fidelity and interpretability may be non-optimal under standard training assumptions."}}
{"id": "2511.14725", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.14725", "abs": "https://arxiv.org/abs/2511.14725", "authors": ["Michael A. Boateng", "Russell Bent", "Sidhant Misra", "Parikshit Pareek", "Pascal Van Hentenryck", "Daniel Molzahn"], "title": "Towards AC Feasibility of DCOPF Dispatch", "comment": null, "summary": "DC Optimal Power Flow (DCOPF) is widely utilized in power system operations due to its simplicity and computational efficiency. However, its lossless, reactive power-agnostic model often yields dispatches that are infeasible under practical operating scenarios such as the nonlinear AC power flow (ACPF) equations. While theoretical analysis demonstrates that DCOPF solutions are inherently AC-infeasible, their widespread industry adoption suggests substantial practical utility. This paper develops a unified DCOPF-ACPF pipeline to recover AC feasible solutions from DCOPF-based dispatches. The pipeline uses four DCOPF variants and applies AC feasibility recovery using both distributed slack allocation and PV/PQ switching. The main objective is to identify the most effective pipeline for restoring AC feasibility. Evaluation across over 10,000 dispatch scenarios on various test cases demonstrates that the structured ACPF model yields solutions that satisfy both the ACPF equations, and all engineering inequality constraints. In a 13,659 bus case, the mean absolute error and cost differences between DCOPF and ACOPF are reduced by 75% and 93%, respectively, compared to conventional single slack bus methods. Under extreme loading conditions, the pipeline reduces inequality constraint violations by a factor of 3 to 5.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684 DCOPF-ACPF \u7ba1\u7ebf\uff0c\u5728\u56db\u79cd DCOPF \u53d8\u4f53\u548c\u5206\u5e03\u5f0f slack \u5206\u914d/ PV/PQ \u5207\u6362\u7684\u7ec4\u5408\u4e0b\uff0c\u4ece DCOPF \u51fa\u53d1\u6062\u590d AC \u53ef\u884c\u89e3\uff0c\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\u548c\u5408\u89c4\u6027\u3002", "motivation": "DCOPF \u867d\u7136\u7b80\u5355\u9ad8\u6548\uff0c\u4f46\u5176\u65e0\u635f\u3001\u5bf9\u65e0\u529f\u4e0d\u8003\u8651\u7684\u6a21\u578b\u5728\u5b9e\u9645 AC \u65b9\u7a0b\u4e0b\u5f80\u5f80\u4e0d\u53ef\u884c\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u884c\u4e1a\u4ecd\u5e7f\u6cdb\u91c7\u7528\uff0c\u9700\u8981\u4e00\u4e2a\u4ece DCOPF \u5230 AC \u53ef\u884c\u89e3\u7684\u5b9e\u7528\u8f6c\u6362\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u56db\u79cd DCOPF \u53d8\u4f53\uff0c\u7ed3\u5408\u57fa\u4e8e\u5206\u5e03\u5f0f slack \u5206\u914d\u548c PV/PQ \u5207\u6362\u7684 AC \u53ef\u884c\u6027\u6062\u590d\uff0c\u6784\u5efa\u4e00\u4e2a\u7edf\u4e00\u7684\u7ba1\u7ebf\uff0c\u7528\u4ee5\u4ece DCOPF \u4ea7\u51fa\u6062\u590d AC \u53ef\u884c\u89e3\uff0c\u5e76\u5728\u591a\u79cd\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u4ee5\u9009\u51fa\u6700\u6709\u6548\u7ec4\u5408\u3002", "result": "\u5728\u8d85\u8fc7 10,000 \u4e2a\u8c03\u5ea6\u573a\u666f\u548c\u591a\u79cd\u6d4b\u8bd5\u60c5\u5f62\u4e0b\uff0c\u7ed3\u6784\u5316\u7684 ACPF \u6a21\u578b\u5b9e\u73b0\u4e86\u540c\u65f6\u6ee1\u8db3 ACPF \u65b9\u7a0b\u4e0e\u5de5\u7a0b\u4e0d\u7b49\u5f0f\u7ea6\u675f\u7684\u89e3\uff1b\u5728 13,659 \u8282\u70b9\u5927\u89c4\u6a21\u6848\u4f8b\u4e2d\uff0c\u4e0e\u4f20\u7edf\u5355 slack \u603b\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cDCOPF-ACPF \u7684\u5747\u503c\u7edd\u5bf9\u8bef\u5dee(\u6216 MAE)\u4e0e\u6210\u672c\u5dee\u5f02\u5206\u522b\u51cf\u5c11\u7ea6 75% \u4e0e 93%\uff1b\u5728\u6781\u7aef\u8d1f\u8f7d\u6761\u4ef6\u4e0b\uff0c\u7ba1\u7ebf\u5bf9\u4e0d\u7b49\u5f0f\u8fdd\u53cd\u7684\u6291\u5236\u6548\u679c\u63d0\u5347 3\u20135 \u500d\u3002", "conclusion": "\u4ee5\u7ed3\u6784\u5316 ACPF \u4e3a\u6838\u5fc3\u7684\u7ba1\u7ebf\u5728\u6062\u590d AC \u53ef\u884c\u6027\u65b9\u9762\u6700\u6709\u6548\uff0c\u4e14\u80fd\u5728\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u7a33\u5b9a\u8fd0\u884c\uff0c\u5177\u6709\u660e\u663e\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u5efa\u8bae\u4f18\u5148\u91c7\u7528\u8be5\u7ba1\u7ebf\u7684\u7ec4\u5408\u3002"}}
{"id": "2511.13984", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13984", "abs": "https://arxiv.org/abs/2511.13984", "authors": ["Hilaf Hasson", "Ruocheng Guo"], "title": "Node-Level Uncertainty Estimation in LLM-Generated SQL", "comment": null, "summary": "We present a practical framework for detecting errors in LLM-generated SQL by estimating uncertainty at the level of individual nodes in the query's abstract syntax tree (AST). Our approach proceeds in two stages. First, we introduce a semantically aware labeling algorithm that, given a generated SQL and a gold reference, assigns node-level correctness without over-penalizing structural containers or alias variation. Second, we represent each node with a rich set of schema-aware and lexical features - capturing identifier validity, alias resolution, type compatibility, ambiguity in scope, and typo signals - and train a supervised classifier to predict per-node error probabilities. We interpret these probabilities as calibrated uncertainty, enabling fine-grained diagnostics that pinpoint exactly where a query is likely to be wrong. Across multiple databases and datasets, our method substantially outperforms token log-probabilities: average AUC improves by +27.44% while maintaining robustness under cross-database evaluation. Beyond serving as an accuracy signal, node-level uncertainty supports targeted repair, human-in-the-loop review, and downstream selective execution. Together, these results establish node-centric, semantically grounded uncertainty estimation as a strong and interpretable alternative to aggregate sequence level confidence measures.", "AI": {"tldr": "\u901a\u8fc7\u5bf9\u751f\u6210\u7684 SQL \u7684 AST \u8282\u70b9\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\uff0c\u63d0\u51fa\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\u4ee5\u68c0\u6d4b LLM \u751f\u6210\u7684 SQL \u9519\u8bef\uff1a\u9636\u6bb5\u4e00\u5bf9\u8282\u70b9\u8fdb\u884c\u8bed\u4e49\u5316\u6807\u6ce8\uff0c\u9636\u6bb5\u4e8c\u7528\u4e30\u5bcc\u7684\u7279\u5f81\u8bad\u7ec3\u5206\u7c7b\u5668\u9884\u6d4b\u9010\u8282\u70b9\u9519\u8bef\u6982\u7387\uff0c\u5e76\u5c06\u6982\u7387\u89c6\u4e3a\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u5b9e\u73b0\u7cbe\u7ec6\u8bca\u65ad\u3001\u5b9a\u4f4d\u4e0e\u4fee\u590d\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u4ee4\u724c\u7684\u7f6e\u4fe1\u5ea6\u901a\u5e38\u5bf9\u7ed3\u6784\u5bb9\u5668\u3001\u522b\u540d\u7b49\u4e0d\u654f\u611f\uff0c\u96be\u4ee5\u5bf9\u751f\u6210\u7684 SQL \u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bca\u65ad\u3002\u9700\u8981\u4e00\u79cd\u53ef\u89e3\u91ca\u3001\u5bf9\u8de8\u6570\u636e\u5e93\u9c81\u68d2\u7684\u8282\u70b9\u7ea7\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\uff0c\u4ee5\u652f\u6301\u5b9a\u4f4d\u3001\u4fee\u590d\u548c\u4eba\u673a\u534f\u540c\u3002", "method": "\u9636\u6bb51\uff1a\u63d0\u51fa\u8bed\u4e49\u611f\u77e5\u7684\u6807\u6ce8\u7b97\u6cd5\uff0c\u5728\u751f\u6210 SQL \u4e0e\u91d1\u6807\u51c6\u4e4b\u95f4\u4e3a\u6bcf\u4e2a AST \u8282\u70b9\u5206\u914d\u6b63\u786e\u6027\u6807\u7b7e\uff0c\u907f\u514d\u8fc7\u5ea6\u60e9\u7f5a\u7ed3\u6784\u6027\u5bb9\u5668\u6216\u522b\u540d\u53d8\u5316\u3002\u9636\u6bb52\uff1a\u5bf9\u6bcf\u4e2a\u8282\u70b9\u6784\u5efa\u4e30\u5bcc\u7684\u7279\u5f81\uff08\u6a21\u5f0f\u611f\u77e5\u7684\u3001\u8bcd\u6c47/\u6807\u8bc6\u7b26\u76f8\u5173\u3001\u522b\u540d\u89e3\u6790\u3001\u7c7b\u578b\u517c\u5bb9\u3001\u4f5c\u7528\u57df\u6b67\u4e49\u3001\u62fc\u5199\u4fe1\u53f7\u7b49\uff09\uff0c\u5e76\u8bad\u7ec3\u4e00\u4e2a\u76d1\u7763\u5206\u7c7b\u5668\u6765\u9884\u6d4b\u9010\u8282\u70b9\u7684\u9519\u8bef\u6982\u7387\u3002\u5c06\u8fd9\u4e9b\u6982\u7387\u89e3\u91ca\u4e3a\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u7528\u4e8e\u7cbe\u7ec6\u8bca\u65ad\u3001\u5b9a\u4f4d\u9519\u8bef\u4f4d\u7f6e\u3002", "result": "\u5728\u591a\u6570\u636e\u5e93\u4e0e\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u7684\u5e73\u5747 AUC \u6bd4\u57fa\u4e8e token \u7684\u5bf9\u6570\u6982\u7387\u63d0\u5347\u7ea6 27.44%\uff0c\u5e76\u5728\u8de8\u6570\u636e\u5e93\u8bc4\u4f30\u4e2d\u4fdd\u6301\u9c81\u68d2\u6027\u3002\u9664\u4e86\u4f5c\u4e3a\u51c6\u786e\u6027\u4fe1\u53f7\uff0c\u8282\u70b9\u7ea7\u4e0d\u786e\u5b9a\u6027\u8fd8\u80fd\u652f\u6301\u5b9a\u5411\u4fee\u590d\u3001\u4eba\u673a\u53c2\u4e0e\u5ba1\u6838\u548c\u540e\u7eed\u7684\u9009\u62e9\u6027\u6267\u884c\u3002", "conclusion": "\u8282\u70b9\u4e2d\u5fc3\u3001\u8bed\u4e49\u5316\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u4e14\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f18\u4e8e\u805a\u5408\u5e8f\u5217\u7ea7\u7f6e\u4fe1\u5ea6\uff0c\u5e76\u4e3a\u7cbe\u7ec6\u8bca\u65ad\u3001\u5b9a\u4f4d\u548c\u540e\u7eed\u4fee\u590d\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u4fe1\u53f7\u3002"}}
{"id": "2511.14057", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14057", "abs": "https://arxiv.org/abs/2511.14057", "authors": ["Xianghe Liu", "Jiajia Liu", "Chuxian Xu", "Minghan Wang", "Hongbo Peng", "Tao Sun", "Jiaqi Xu"], "title": "A Machine Learning-Based Multimodal Framework for Wearable Sensor-Based Archery Action Recognition and Stress Estimation", "comment": null, "summary": "In precision sports such as archery, athletes' performance depends on both biomechanical stability and psychological resilience. Traditional motion analysis systems are often expensive and intrusive, limiting their use in natural training environments. To address this limitation, we propose a machine learning-based multimodal framework that integrates wearable sensor data for simultaneous action recognition and stress estimation. Using a self-developed wrist-worn device equipped with an accelerometer and photoplethysmography (PPG) sensor, we collected synchronized motion and physiological data during real archery sessions. For motion recognition, we introduce a novel feature--Smoothed Differential Acceleration (SmoothDiff)--and employ a Long Short-Term Memory (LSTM) model to identify motion phases, achieving 96.8% accuracy and 95.9% F1-score. For stress estimation, we extract heart rate variability (HRV) features from PPG signals and apply a Multi-Layer Perceptron (MLP) classifier, achieving 80% accuracy in distinguishing high- and low-stress levels. The proposed framework demonstrates that integrating motion and physiological sensing can provide meaningful insights into athletes' technical and mental states. This approach offers a foundation for developing intelligent, real-time feedback systems for training optimization in archery and other precision sports.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7528\u4e8e\u540c\u65f6\u8fdb\u884c\u52a8\u4f5c\u8bc6\u522b\u548c\u538b\u529b\u4f30\u8ba1\uff0c\u9002\u7528\u4e8e\u5c04\u7bad\u7b49\u7cbe\u51c6\u8fd0\u52a8\uff0c\u53ef\u5b9e\u73b0\u5b9e\u65f6\u53cd\u9988\u3002\"", "motivation": "\u7cbe\u51c6\u8fd0\u52a8\u9700\u8981\u751f\u7269\u529b\u5b66\u7a33\u5b9a\u6027\u4e0e\u5fc3\u7406\u97e7\u6027\uff0c\u4f20\u7edf\u8fd0\u52a8\u5206\u6790\u7cfb\u7edf\u6602\u8d35\u4e14\u5177\u6709\u4fb5\u5165\u6027\uff0c\u9650\u5236\u5b9e\u9645\u8bad\u7ec3\u3002\u7814\u7a76\u901a\u8fc7\u4fbf\u643a\u5f0f\u4f20\u611f\u8bbe\u5907\u4e0e\u673a\u5668\u5b66\u4e60\u5b9e\u73b0\u975e\u4fb5\u5165\u3001\u81ea\u7136\u573a\u666f\u4e0b\u7684\u52a8\u4f5c\u5206\u8bc6\u4e0e\u538b\u529b\u8bc4\u4f30\uff0c\u63d0\u5347\u8bad\u7ec3\u6548\u679c\u3002", "method": "\u4f7f\u7528\u81ea\u7814\u624b\u8155\u88c5\u7f6e\uff0c\u88c5\u8f7d\u52a0\u901f\u5ea6\u8ba1\u4e0ePPG\u4f20\u611f\u5668\uff0c\u91c7\u96c6\u540c\u6b65\u7684\u8fd0\u52a8\u4e0e\u751f\u7406\u6570\u636e\u3002\u63d0\u51fa\u5e73\u6ed1\u5dee\u5206\u52a0\u901f\u5ea6\uff08SmoothDiff\uff09\u7279\u5f81\u7528\u4e8e\u52a8\u4f5c\u8bc6\u522b\uff0c\u91c7\u7528LSTM\u6a21\u578b\u8fdb\u884c\u52a8\u4f5c\u9636\u6bb5\u8bc6\u522b\u3002\u5bf9PPG\u4fe1\u53f7\u63d0\u53d6\u5fc3\u7387\u53d8\u5f02\u6027(HRV)\u7279\u5f81\uff0c\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u673a(MLP)\u8fdb\u884c\u538b\u529b\u7b49\u7ea7\u5206\u7c7b\u3002", "result": "\u52a8\u4f5c\u8bc6\u522b\u51c6\u786e\u5ea6\u4e3a96.8%\uff0cF1-score\u4e3a95.9%\uff1b\u538b\u529b\u4e8c\u5206\u7c7b\u51c6\u786e\u7387\u4e3a80%\u3002", "conclusion": "\u5c06\u8fd0\u52a8\u4fe1\u53f7\u4e0e\u751f\u7406\u4fe1\u53f7\u6709\u6548\u878d\u5408\uff0c\u80fd\u4e3a\u5c04\u7bad\u53ca\u5176\u4ed6\u7cbe\u51c6\u8fd0\u52a8\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u6280\u672f\u4e0e\u5fc3\u7406\u72b6\u6001\u6d1e\u5bdf\uff0c\u5177\u5907\u5b9e\u73b0\u5b9e\u65f6\u667a\u80fd\u53cd\u9988\u7cfb\u7edf\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.14064", "categories": ["cs.LG", "cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.14064", "abs": "https://arxiv.org/abs/2511.14064", "authors": ["Kelin Ren", "Chan-Yang Ju", "Dong-Ho Lee"], "title": "CafeMed: Causal Attention Fusion Enhanced Medication Recommendation", "comment": "Accepted by BIBM 2025", "summary": "Medication recommendation systems play a crucial role in assisting clinicians with personalized treatment decisions. While existing approaches have made significant progress in learning medication representations, they suffer from two fundamental limitations: (i) treating medical entities as independent features without modeling their synergistic effects on medication selection; (ii) employing static causal relationships that fail to adapt to patient-specific contexts and health states. To address these challenges, we propose CafeMed, a framework that integrates dynamic causal reasoning with cross-modal attention for safe and accurate medication recommendation. CafeMed introduces two key components: the Causal Weight Generator (CWG) that transforms static causal effects into dynamic modulation weights based on individual patient states, and the Channel Harmonized Attention Refinement Module (CHARM) that captures complex interdependencies between diagnoses and procedures. This design enables CafeMed to model how different medical conditions jointly influence treatment decisions while maintaining medication safety constraints. Extensive experiments on MIMIC-III and MIMIC-IV datasets demonstrate that CafeMed significantly outperforms state-of-the-art baselines, achieving superior accuracy in medication prediction while maintaining the lower drug--drug interaction rates. Our results indicate that incorporating dynamic causal relationships and cross-modal synergies leads to more clinically-aligned and personalized medication recommendations. Our code is released publicly at https://github.com/rkl71/CafeMed.", "AI": {"tldr": "CafeMed \u5c06\u52a8\u6001\u56e0\u679c\u63a8\u7406\u4e0e\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u7ed3\u5408\uff0c\u7528\u4e8e\u4e2a\u6027\u5316\u4e14\u5b89\u5168\u7684\u836f\u7269\u63a8\u8350\uff0c\u901a\u8fc7\u5c06\u9759\u6001\u56e0\u679c\u6548\u5e94\u8f6c\u5316\u4e3a\u4ee5\u60a3\u8005\u72b6\u6001\u4e3a\u6761\u4ef6\u7684\u52a8\u6001\u6743\u91cd\uff0c\u5e76\u901a\u8fc7 CHARM \u5efa\u6a21\u8bca\u65ad\u4e0e\u5904\u7f6e\u4e4b\u95f4\u7684\u590d\u6742\u4f9d\u5b58\u5173\u7cfb\uff0c\u5728 MIMIC-III/IV \u4e0a\u663e\u8457\u4f18\u4e8e\u6700\u65b0\u57fa\u7ebf\uff0c\u8fbe\u5230\u66f4\u9ad8\u7684\u836f\u7269\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u533b\u5b66\u5b9e\u4f53\u770b\u4f5c\u72ec\u7acb\u7279\u5f81\uff0c\u5ffd\u7565\u5b83\u4eec\u5728\u836f\u7269\u9009\u62e9\u4e2d\u7684\u534f\u540c\u6548\u5e94\uff1b\u6b64\u5916\uff0c\u4f7f\u7528\u9759\u6001\u56e0\u679c\u5173\u7cfb\uff0c\u65e0\u6cd5\u9002\u5e94\u60a3\u8005\u7279\u5b9a\u60c5\u5883\u548c\u5065\u5eb7\u72b6\u6001\uff0c\u9650\u5236\u4e2a\u6027\u5316\u548c\u5b89\u5168\u6027\u3002\u9700\u8981\u540c\u65f6\u5efa\u6a21\u5b9e\u4f53\u95f4\u7684\u534f\u540c\u4f5c\u7528\u548c\u968f\u60a3\u8005\u72b6\u6001\u52a8\u6001\u53d8\u5316\u7684\u56e0\u679c\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u4e24\u5927\u6a21\u5757\uff1aCWG\uff08Causal Weight Generator\uff09\u5c06\u9759\u6001\u56e0\u679c\u6548\u5e94\u8f6c\u5316\u4e3a\u57fa\u4e8e\u60a3\u8005\u72b6\u6001\u7684\u52a8\u6001\u8c03\u5236\u6743\u91cd\uff1bCHARM\uff08Channel Harmonized Attention Refinement Module\uff09\u901a\u8fc7\u8de8\u6a21\u6001\u6ce8\u610f\u529b\uff0c\u6355\u6349\u8bca\u65ad\u4e0e\u5904\u7f6e\u4e4b\u95f4\u7684\u590d\u6742\u4e92\u4f9d\u5173\u7cfb\uff0c\u5f3a\u5316\u8de8\u6a21\u6001\u7279\u5f81\u7684\u534f\u540c\u8868\u8fbe\u3002", "result": "\u5728 MIMIC-III/MIMIC-IV \u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cCafeMed \u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u5728\u836f\u7269\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u63d0\u5347\uff0c\u540c\u65f6\u964d\u4f4e\u836f\u7269\u95f4\u76f8\u4e92\u4f5c\u7528\u7684\u53d1\u751f\u7387\u3002", "conclusion": "\u5c06\u52a8\u6001\u56e0\u679c\u5173\u7cfb\u548c\u8de8\u6a21\u6001\u534f\u540c\u4f5c\u7528\u878d\u5165\u836f\u7269\u63a8\u8350\uff0c\u53ef\u5b9e\u73b0\u66f4\u8d34\u8fd1\u4e34\u5e8a\u7684\u4e2a\u6027\u5316\u5b89\u5168\u836f\u7269\u51b3\u7b56\uff1b\u7814\u7a76\u7ed3\u679c\u652f\u6301\u8be5\u65b9\u6cd5\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u4ee3\u7801\u516c\u5f00\u3002"}}
{"id": "2511.14075", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14075", "abs": "https://arxiv.org/abs/2511.14075", "authors": ["Nakkyu Yang", "Yechan Lee", "SooJean Han"], "title": "CFG-EC: Error Correction Classifier-Free Guidance", "comment": null, "summary": "Classifier-Free Guidance (CFG) has become a mainstream approach for simultaneously improving prompt fidelity and generation quality in conditional generative models. During training, CFG stochastically alternates between conditional and null prompts to enable both conditional and unconditional generation. However, during sampling, CFG outputs both null and conditional prompts simultaneously, leading to inconsistent noise estimates between the training and sampling processes. To reduce this error, we propose CFG-EC, a versatile correction scheme augmentable to any CFG-based method by refining the unconditional noise predictions. CFG-EC actively realigns the unconditional noise error component to be orthogonal to the conditional error component. This corrective maneuver prevents interference between the two guidance components, thereby constraining the sampling error's upper bound and establishing more reliable guidance trajectories for high-fidelity image generation. Our numerical experiments show that CFG-EC handles the unconditional component more effectively than CFG and CFG++, delivering a marked performance increase in the low guidance sampling regime and consistently higher prompt alignment across the board.", "AI": {"tldr": "CFG-EC \u901a\u8fc7\u5c06\u672a\u6761\u4ef6\u566a\u58f0\u9884\u6d4b\u7684\u8bef\u5dee\u4e0e\u6761\u4ef6\u8bef\u5dee\u6b63\u4ea4\u5316\u6765\u51cf\u5c11\u91c7\u6837\u8bef\u5dee\uff0c\u4ece\u800c\u63d0\u5347\u57fa\u4e8e CFG \u7684\u65b9\u6cd5\u5728\u4f4e\u5f15\u5bfc\u4e0b\u7684\u91c7\u6837\u8d28\u91cf\u548c\u63d0\u793a\u5bf9\u9f50\u3002", "motivation": "\u5728\u5206\u7c7b\u65e0\u5f15\u5bfc\uff08CFG\uff09\u8bad\u7ec3\u9636\u6bb5\uff0c\u6a21\u578b\u5728\u6761\u4ef6\u63d0\u793a\u4e0e\u7a7a\u63d0\u793a\u4e4b\u95f4\u968f\u673a\u5207\u6362\uff1b\u800c\u5728\u91c7\u6837\u9636\u6bb5\uff0cCFG \u8f93\u51fa\u540c\u65f6\u5305\u542b\u7a7a\u4e0e\u6761\u4ef6\u63d0\u793a\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0e\u91c7\u6837\u8fc7\u7a0b\u4e2d\u566a\u58f0\u4f30\u8ba1\u4e0d\u4e00\u81f4\uff0c\u8fdb\u800c\u5f71\u54cd\u751f\u6210\u8d28\u91cf\u3002", "method": "\u63d0\u51fa CFG-EC\uff0c\u4e00\u79cd\u53ef\u6269\u5c55\u5230\u4efb\u610f CFG \u57fa\u65b9\u6cd5\u7684\u7ea0\u6b63\u65b9\u6848\uff0c\u901a\u8fc7 refining \u672a\u6761\u4ef6\u7684\u566a\u58f0\u9884\u6d4b\u6765\u4f7f\u672a\u6761\u4ef6\u8bef\u5dee\u6b63\u4ea4\u4e8e\u6761\u4ef6\u8bef\u5dee\uff0c\u4ece\u800c\u907f\u514d\u4e24\u8005\u4e4b\u95f4\u7684\u5e72\u6270\uff0c\u6536\u655b\u91c7\u6837\u8bef\u5dee\u4e0a\u754c\uff0c\u63d0\u5347\u6307\u5bfc\u8f68\u8ff9\u7684\u7a33\u5b9a\u6027\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0cCFG-EC \u76f8\u8f83 CFG \u4e0e CFG++ \u66f4\u6709\u6548\u5730\u5904\u7406\u672a\u6761\u4ef6\u5206\u91cf\uff0c\u5728\u4f4e\u5f15\u5bfc\u91c7\u6837\u6a21\u5f0f\u4e0b\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5728\u6574\u4f53\u4e0a\u8fbe\u5230\u66f4\u9ad8\u7684\u63d0\u793a\u5bf9\u9f50\u3002", "conclusion": "CFG-EC \u4e3a CFG \u57fa\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u4e14\u6709\u6548\u7684\u7ea0\u6b63\u673a\u5236\uff0c\u80fd\u66f4\u53ef\u9760\u5730\u5f15\u5bfc\u751f\u6210\u8fc7\u7a0b\uff0c\u964d\u4f4e\u91c7\u6837\u8bef\u5dee\u4e0a\u9650\u3002"}}
{"id": "2511.14102", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.14102", "abs": "https://arxiv.org/abs/2511.14102", "authors": ["Wenfeng Wang", "Jiacheng Liu", "Xiaofeng Hou", "Xinfeng Xia", "Peng Tang", "Mingxuan Zhang", "Chao Li", "Minyi Guo"], "title": "MoE-SpeQ: Speculative Quantized Decoding with Proactive Expert Prefetching and Offloading for Mixture-of-Experts", "comment": null, "summary": "The immense memory requirements of state-of-the-art Mixture-of-Experts (MoE) models present a significant challenge for inference, often exceeding the capacity of a single accelerator. While offloading experts to host memory is a common solution, it introduces a severe I/O bottleneck over the PCIe bus, as the data-dependent nature of expert selection places these synchronous transfers directly on the critical path of execution, crippling performance.\n  This paper argues that the I/O bottleneck can be overcome by trading a small amount of cheap, on-device computation to hide the immense cost of data movement. We present MoE-SpeQ, a new inference system built on a novel co-design of speculative execution and expert offloading. MoE-SpeQ employs a small, on-device draft model to predict the sequence of required experts for future tokens. This foresight enables a runtime orchestrator to prefetch these experts from host memory, effectively overlapping the expensive I/O with useful computation and hiding the latency from the critical path. To maximize performance, an adaptive governor, guided by an Amortization Roofline Model, dynamically tunes the speculation strategy to the underlying hardware. Our evaluation on memory-constrained devices shows that for the Phi-MoE model, MoE-SpeQ achieves at most 2.34x speedup over the state-of-the-art offloading framework. Our work establishes a new, principled approach for managing data-dependent memory access in resource-limited environments, making MoE inference more accessible on commodity hardware.", "AI": {"tldr": "MoE-SpeQ introduces an on-device draft model to predict future expert usage and prefetch their weights from host memory, overlapping data transfer with computation to hide I/O latency and surpass traditional offloading. It uses an adaptive governor guided by an Amortization Roofline Model to tune speculation for hardware, achieving up to 2.34x speedup on Phi-MoE compared to state-of-the-art offloading.", "motivation": "State-of-the-art Mixture-of-Experts (MoE) models demand memory beyond a single accelerator. Offloading experts to host memory incurs a severe I/O bottleneck on PCIe due to data-dependent expert selection, which lies on the critical path of inference.", "method": "Co-design of speculative execution and expert offloading named MoE-SpeQ. It uses a small on-device draft model to forecast the sequence of required experts for upcoming tokens, enabling a runtime orchestrator to prefetch these experts from host memory. This prefetching overlaps I/O with computation. An adaptive governor, guided by an Amortization Roofline Model, dynamically tunes the speculation strategy to the hardware.", "result": "On memory-constrained devices, MoE-SpeQ achieves up to 2.34\u00d7 speedup over a state-of-the-art offloading framework for the Phi-MoE model.", "conclusion": "This work provides a principled approach to managing data-dependent memory access in resource-limited environments, enabling more accessible MoE inference on commodity hardware."}}
{"id": "2511.14117", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14117", "abs": "https://arxiv.org/abs/2511.14117", "authors": ["Agamdeep Singh", "Ashish Tiwari", "Hosein Hasanbeig", "Priyanshu Gupta"], "title": "Soft-Label Training Preserves Epistemic Uncertainty", "comment": null, "summary": "Many machine learning tasks involve inherent subjectivity, where annotators naturally provide varied labels. Standard practice collapses these label distributions into single labels, aggregating diverse human judgments into point estimates. We argue that this approach is epistemically misaligned for ambiguous data--the annotation distribution itself should be regarded as the ground truth. Training on collapsed single labels forces models to express false confidence on fundamentally ambiguous cases, creating a misalignment between model certainty and the diversity of human perception. We demonstrate empirically that soft-label training, which treats annotation distributions as ground truth, preserves epistemic uncertainty. Across both vision and NLP tasks, soft-label training achieves 32% lower KL divergence from human annotations and 61% stronger correlation between model and annotation entropy, while matching the accuracy of hard-label training. Our work repositions annotation distributions from noisy signals to be aggregated away, to faithful representations of epistemic uncertainty that models should learn to reproduce.", "AI": {"tldr": "\u628a\u6ce8\u91ca\u5206\u5e03\u4f5c\u4e3a\u5730\u9762\u771f\u76f8\u6765\u8bad\u7ec3\u6a21\u578b\uff0c\u800c\u4e0d\u662f\u5c06\u5b83\u4eec\u6298\u53e0\u4e3a\u5355\u4e00\u6807\u7b7e\uff0c\u8fd9\u80fd\u66f4\u597d\u5730\u6355\u6349 epistemic uncertainty\uff0c\u5e76\u5728\u89c6\u89c9\u4e0eNLP\u4efb\u52a1\u4e0a\u6bd4\u786c\u6807\u7b7e\u8bad\u7ec3\u5728\u4e0e\u4eba\u7c7b\u6ce8\u91ca\u7684\u4e00\u81f4\u6027\u65b9\u9762\u66f4\u597d\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u5ea6\u3002", "motivation": "\u6ce8\u91ca\u7684\u4e3b\u89c2\u6027\u5bfc\u81f4\u6807\u7b7e\u5206\u5e03\u591a\u6837\uff0c\u4f20\u7edf\u7684\u53ea\u4fdd\u7559\u4e00\u4e2a\u6807\u7b7e\u5ffd\u7565\u4e86\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd9\u6837\u7684\u8bad\u7ec3\u9519\u914d\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u4e0e\u4eba\u7c7b\u611f\u77e5\u7684\u591a\u6837\u6027\u3002", "method": "\u5c06\u6ce8\u91ca\u5206\u5e03\u4f5c\u4e3a\u8bad\u7ec3\u76ee\u6807\uff08\u8f6f\u6807\u7b7e\uff09\uff0c\u5728\u89c6\u89c9\u548cNLP\u4efb\u52a1\u4e0a\u6bd4\u8f83\u8f6f\u6807\u7b7e\u4e0e\u786c\u6807\u7b7e\u8bad\u7ec3\uff0c\u8bc4\u4f30KL\u53d1\u6563\u548c\u6ce8\u91ca\u71b5\u7684\u4e00\u81f4\u6027\u4e0e\u76f8\u5173\u6027\uff1b\u5e76\u6bd4\u8f83\u51c6\u786e\u5ea6\u3002", "result": "\u8f6f\u6807\u7b7e\u8bad\u7ec3\u5728KL\u6563\u5ea6\u76f8\u8f83\u4eba\u7c7b\u6ce8\u91ca\u4e0b\u964d\u7ea632%\uff0c\u6a21\u578b\u5bf9\u6ce8\u91ca\u71b5\u7684\u76f8\u5173\u6027\u63d0\u5347\u7ea661%\uff0c\u5728\u51c6\u786e\u5ea6\u4e0a\u7b49\u540c\u4e8e\u786c\u6807\u7b7e\u8bad\u7ec3\u3002", "conclusion": "\u5c06\u6ce8\u91ca\u5206\u5e03\u4ece\u566a\u58f0\u4fe1\u53f7\u8f6c\u4e3a\u5bf9 epistemic uncertainty \u7684 faithful \u8868\u5f81\uff0c\u6a21\u578b\u5e94\u5b66\u4e60\u91cd\u73b0\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\uff1b\u8fd9\u6539\u53d8\u4e86\u5bf9\u6ce8\u91ca\u5206\u5e03\u7684\u7406\u89e3\uff0c\u4ece\u53ef\u5ffd\u7565\u7684\u566a\u58f0\u5230\u5173\u952e\u7684\u77e5\u8bc6\u6765\u6e90\u3002"}}
{"id": "2511.14133", "categories": ["cs.LG", "econ.EM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.14133", "abs": "https://arxiv.org/abs/2511.14133", "authors": ["Jessy Xinyi Han", "Devavrat Shah"], "title": "Synthetic Survival Control: Extending Synthetic Controls for \"When-If\" Decision", "comment": null, "summary": "Estimating causal effects on time-to-event outcomes from observational data is particularly challenging due to censoring, limited sample sizes, and non-random treatment assignment. The need for answering such \"when-if\" questions--how the timing of an event would change under a specified intervention--commonly arises in real-world settings with heterogeneous treatment adoption and confounding. To address these challenges, we propose Synthetic Survival Control (SSC) to estimate counterfactual hazard trajectories in a panel data setting where multiple units experience potentially different treatments over multiple periods. In such a setting, SSC estimates the counterfactual hazard trajectory for a unit of interest as a weighted combination of the observed trajectories from other units. To provide formal justification, we introduce a panel framework with a low-rank structure for causal survival analysis. Indeed, such a structure naturally arises under classical parametric survival models. Within this framework, for the causal estimand of interest, we establish identification and finite sample guarantees for SSC. We validate our approach using a multi-country clinical dataset of cancer treatment outcomes, where the staggered introduction of new therapies creates a quasi-experimental setting. Empirically, we find that access to novel treatments is associated with improved survival, as reflected by lower post-intervention hazard trajectories relative to their synthetic counterparts. Given the broad relevance of survival analysis across medicine, economics, and public policy, our framework offers a general and interpretable tool for counterfactual survival inference using observational data.", "AI": {"tldr": "\u63d0\u51fa\u4e86 Synthetic Survival Control (SSC) \u7684\u65b9\u6cd5\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u9762\u677f\u6570\u636e\u4e2d\u4f30\u8ba1\u65f6\u95f4\u4e8b\u4ef6\u7684\u53cd\u4e8b\u5b9e\u98ce\u9669\u8f68\u8ff9\uff0c\u89e3\u51b3\u89c2\u6d4b\u6570\u636e\u4e2d\u7684\u6df7\u6742\u3001\u5220\u5931\u4e0e\u6cbb\u7597\u5f02\u8d28\u6027\u95ee\u9898\uff1b\u5728\u4f4e\u79e9\u7ed3\u6784\u4e0b\u5bf9\u56e0\u679c\u6027\u8fdb\u884c\u8bc6\u522b\u4e0e\u6709\u9650\u6837\u672c\u4fdd\u8bc1\uff0c\u5e76\u5728\u591a\u56fd\u764c\u75c7\u6cbb\u7597\u6570\u636e\u4e0a\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793a\u83b7\u5f97\u65b0\u6cbb\u7597\u6709\u52a9\u4e8e\u964d\u4f4e\u4e8b\u4ef6\u540e\u98ce\u9669\uff0c\u63d0\u5347\u751f\u5b58\u7ed3\u5c40\u3002", "motivation": "\u5728\u89c2\u6d4b\u6570\u636e\u4e2d\u4f30\u8ba1\u65f6\u95f4-\u4e8b\u4ef6\u7ed3\u5c40\u7684\u56e0\u679c\u6548\u5e94\u9762\u4e34\u5220\u5931\u3001\u6837\u672c\u6709\u9650\u4e0e\u6cbb\u7597\u6307\u6d3e\u975e\u968f\u673a\u7b49\u6311\u6218\uff0c\u4e14\u9700\u8981\u56de\u7b54\u201c\u5982\u679c\u5728\u7279\u5b9a\u5e72\u9884\u4e0b\u4e8b\u4ef6\u53d1\u751f\u7684\u65f6\u673a\u4f1a\u5982\u4f55\u53d8\u5316\u201d\u7684\u201cwhen-if\u201d\u95ee\u9898\uff0c\u5c24\u5176\u5728\u6cbb\u7597\u91c7\u7528\u5b58\u5728\u5f02\u8d28\u6027\u4e0e\u6df7\u6742\u65f6\u3002", "method": "\u5728\u9762\u677f\u6570\u636e\u548c\u591a\u671f\u6cbb\u7597\u573a\u666f\u4e2d\uff0c\u63d0\u51fa SSC\uff0c\u901a\u8fc7\u5c06\u76ee\u6807\u5355\u4f4d\u7684\u53cd\u4e8b\u5b9e\u5371\u9669\u8f68\u8ff9\u8868\u793a\u4e3a\u6765\u81ea\u5176\u4ed6\u5355\u4f4d\u89c2\u5bdf\u8f68\u8ff9\u7684\u52a0\u6743\u7ec4\u5408\uff1b\u5728\u4e00\u4e2a\u4f4e\u79e9\u7ed3\u6784\u7684\u56e0\u679c\u751f\u5b58\u5206\u6790\u6846\u67b6\u4e0b\u7ed9\u51fa formal \u7684\u8bc6\u522b\u6027\u7ed3\u679c\u4e0e\u6709\u9650\u6837\u672c\u4fdd\u969c\uff1b\u5e76\u7406\u8bba\u4e0a\u8bf4\u660e\u8be5\u4f4e\u79e9\u7ed3\u6784\u5728\u7ecf\u5178\u751f\u5b58\u6a21\u578b\u4e0b\u81ea\u7136\u51fa\u73b0\u3002", "result": "\u5728\u4e00\u4e2a\u591a\u56fd\u764c\u75c7\u6cbb\u7597\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u6cbb\u7597\u5b58\u5728\u9636\u6bb5\u6027\u5f15\u5165\u5bfc\u81f4\u51c6\u5b9e\u9a8c\u73af\u5883\uff1b\u7ed3\u679c\u663e\u793a\u83b7\u5f97\u65b0\u6cbb\u7597\u4e0e\u8f83\u4f4e\u7684\u540e\u671f\u5371\u9669\u8f68\u8ff9\u76f8\u5173\uff0c\u76f8\u5bf9\u4e8e\u5408\u6210\u5bf9\u7167\u5177\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "SSC \u4e3a\u89c2\u6d4b\u6570\u636e\u4e2d\u7684\u53cd\u4e8b\u5b9e\u751f\u5b58\u63a8\u65ad\u63d0\u4f9b\u4e86\u4e00\u822c\u4e14\u53ef\u89e3\u91ca\u7684\u5de5\u5177\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u9002\u7528\u4e8e\u533b\u5b66\u3001\u7ecf\u6d4e\u5b66\u4e0e\u516c\u5171\u653f\u7b56\u4e2d\u7684\u751f\u5b58\u5206\u6790\u573a\u666f\u3002"}}
{"id": "2511.14135", "categories": ["cs.LG", "cs.AI", "cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.14135", "abs": "https://arxiv.org/abs/2511.14135", "authors": ["Promise Ekpo", "Saesha Agarwal", "Felix Grimm", "Lekan Molu", "Angelique Taylor"], "title": "Fair-GNE : Generalized Nash Equilibrium-Seeking Fairness in Multiagent Healthcare Automation", "comment": null, "summary": "Enforcing a fair workload allocation among multiple agents tasked to achieve an objective in learning enabled demand side healthcare worker settings is crucial for consistent and reliable performance at runtime. Existing multi-agent reinforcement learning (MARL) approaches steer fairness by shaping reward through post hoc orchestrations, leaving no certifiable self-enforceable fairness that is immutable by individual agents at runtime. Contextualized within a setting where each agent shares resources with others, we address this shortcoming with a learning enabled optimization scheme among self-interested decision makers whose individual actions affect those of other agents. This extends the problem to a generalized Nash equilibrium (GNE) game-theoretic framework where we steer group policy to a safe and locally efficient equilibrium, so that no agent can improve its utility function by unilaterally changing its decisions. Fair-GNE models MARL as a constrained generalized Nash equilibrium-seeking (GNE) game, prescribing an ideal equitable collective equilibrium within the problem's natural fabric. Our hypothesis is rigorously evaluated in our custom-designed high-fidelity resuscitation simulator. Across all our numerical experiments, Fair-GNE achieves significant improvement in workload balance over fixed-penalty baselines (0.89 vs.\\ 0.33 JFI, $p < 0.01$) while maintaining 86\\% task success, demonstrating statistically significant fairness gains through adaptive constraint enforcement. Our results communicate our formulations, evaluation metrics, and equilibrium-seeking innovations in large multi-agent learning-based healthcare systems with clarity and principled fairness enforcement.", "AI": {"tldr": "\u63d0\u51faFair-GNE\uff1a\u4e00\u4e2a\u57fa\u4e8e\u7ea6\u675f\u5e7f\u4e49\u7eb3\u4ec0\u5747\u8861\u7684\u81ea\u6211\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u9a71\u52a8\u7684\u9700\u6c42\u4fa7\u533b\u7597\u5de5\u4f5c\u8d1f\u8f7d\u5206\u914d\u4e2d\u5b9e\u73b0\u53ef\u8bc1\u5b9e\u7684\u516c\u5e73\u6027\uff0c\u4e14\u5728\u4eff\u771f\u4e2d\u83b7\u5f97\u663e\u8457\u6539\u5584\u548c\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u534f\u4f5c/\u7ade\u4e89\u60c5\u666f\u4e2d\uff0c\u4f20\u7edfMARL\u901a\u8fc7\u540e\u7f6e\u5956\u52b1\u5851\u5f62\u5b9e\u73b0\u516c\u5e73\uff0c\u4f46\u7f3a\u4e4f\u53ef\u81ea\u6211\u6267\u884c\u3001\u4e0d\u53ef\u7be1\u6539\u7684\u516c\u5e73\u6027\u7ea6\u675f\u3002\u9700\u8981\u4e00\u4e2a\u81ea\u5305\u542b\u4e14\u5bf9\u5404agent\u4e0d\u53ef\u88ab\u5355\u65b9\u9762\u6539\u52a8\u7684\u516c\u5e73\u673a\u5236\u3002", "method": "\u5c06MARL\u5efa\u6a21\u4e3a\u53d7\u7ea6\u675f\u7684\u5e7f\u4e49\u7eb3\u4ec0\u5747\u8861\u535a\u5f08\uff0c\u4f7f\u7528GNE\u5bfb\u6c42\u7b97\u6cd5\u5b9e\u73b0\u7fa4\u4f53\u7b56\u7565\u6536\u655b\u5230\u4e00\u4e2a\u5c40\u90e8\u6709\u6548\u4e14\u5b89\u5168\u7684\u5747\u8861\uff1b\u8bbe\u8ba1\u4e00\u4e2a\u81ea\u9002\u5e94\u7ea6\u675f\u4ee5\u4fc3\u6210\u516c\u5e73\u7684\u5de5\u4f5c\u91cf\u5206\u914d\uff1b\u5728\u9ad8\u4fdd\u771f\u590d\u82cf\u6a21\u62df\u5668\u4e2d\u9a8c\u8bc1\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u56fa\u5b9a\u60e9\u7f5a\u57fa\u7ebf\uff0cFair-GNE\u5728\u5de5\u4f5c\u8d1f\u8f7d\u5747\u8861\u65b9\u9762\u663e\u8457\u63d0\u5347\uff080.89 vs 0.33 JFI\uff0cp<0.01\uff09\uff0c\u540c\u65f6\u4efb\u52a1\u6210\u529f\u7387\u8fbe\u523086%\u3002", "conclusion": "\u63d0\u51fa\u7684Fair-GNE\u53ca\u5176\u81ea\u9002\u5e94\u7ea6\u675f\u6267\u884c\u63d0\u4f9b\u4e86\u5728\u5927\u89c4\u6a21\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u533b\u7597\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u516c\u5e73\u7684\u539f\u7406\u3001\u8bc4\u4f30\u6307\u6807\u548c\u5747\u8861\u5bfb\u6c42\u521b\u65b0\u3002"}}
{"id": "2511.14153", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.14153", "abs": "https://arxiv.org/abs/2511.14153", "authors": ["Fatima Kazi", "Alex Young", "Yash Inani", "Setareh Rafatirad"], "title": "A Comprehensive Study of Implicit and Explicit Biases in Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) inherit explicit and implicit biases from their training datasets. Identifying and mitigating biases in LLMs is crucial to ensure fair outputs, as they can perpetuate harmful stereotypes and misinformation. This study highlights the need to address biases in LLMs amid growing generative AI. We studied bias-specific benchmarks such as StereoSet and CrowSPairs to evaluate the existence of various biases in multiple generative models such as BERT and GPT 3.5. We proposed an automated Bias-Identification Framework to recognize various social biases in LLMs such as gender, race, profession, and religion. We adopted a two-pronged approach to detect explicit and implicit biases in text data. Results indicated fine-tuned models struggle with gender biases but excelled at identifying and avoiding racial biases. Our findings illustrated that despite having some success, LLMs often over-relied on keywords. To illuminate the capability of the analyzed LLMs in detecting implicit biases, we employed Bag-of-Words analysis and unveiled indications of implicit stereotyping within the vocabulary. To bolster the model performance, we applied an enhancement strategy involving fine-tuning models using prompting techniques and data augmentation of the bias benchmarks. The fine-tuned models exhibited promising adaptability during cross-dataset testing and significantly enhanced performance on implicit bias benchmarks, with performance gains of up to 20%.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u81ea\u52a8\u5316\u7684\u504f\u89c1\u8bc6\u522b\u6846\u67b6\u4ee5\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u663e\u6027\u548c\u9690\u6027\u793e\u4f1a\u504f\u89c1\uff0c\u5e76\u5728\u504f\u89c1\u57fa\u51c6\u4e0a\u8bc4\u4f30\u591a\u6a21\u578b\uff0c\u7ed3\u5408\u63d0\u793a\u6280\u672f\u548c\u6570\u636e\u589e\u5f3a\u5b9e\u73b0\u7ea620%\u7684\u9690\u6027\u504f\u89c1\u63d0\u5347\u3002", "motivation": "LLMs\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u7ee7\u627f\u504f\u89c1\uff0c\u5f71\u54cd\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\uff1b\u9700\u8981\u7cfb\u7edf\u5316\u7684\u8bc6\u522b\u548c\u7f13\u89e3\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7StereoSet\u3001CrowSPairs\u7b49\u57fa\u51c6\u8bc4\u4f30\u3002", "method": "\u5efa\u7acb\u4e24\u6b65\u6cd5\u6765\u68c0\u6d4b\u663e\u6027\u4e0e\u9690\u6027\u504f\u89c1\uff1b\u5f00\u53d1\u81ea\u52a8\u5316Bias-Identification Framework\uff1b\u5728\u6587\u672c\u6570\u636e\u4e2d\u4f7f\u7528Bag-of-Words\u5206\u6790\uff1b\u5bf9BERT\u3001GPT-3.5\u7b49\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3001\u63d0\u793a\u6280\u5de7\u4e0e\u6570\u636e\u589e\u5f3a\uff1b\u8fdb\u884c\u8de8\u6570\u636e\u96c6\u6d4b\u8bd5\u3002", "result": "\u5fae\u8c03\u6a21\u578b\u5bf9\u6027\u522b\u504f\u89c1\u8868\u73b0\u4e0d\u4f73\u5374\u5728\u79cd\u65cf\u504f\u89c1\u68c0\u6d4b\u4e0a\u8868\u73b0\u826f\u597d\uff1b\u6a21\u578b\u8fc7\u5ea6\u4f9d\u8d56\u5173\u952e\u8bcd\uff1bBag-of-Words\u8868\u660e\u5b58\u5728\u9690\u6027\u5b9a\u578b\uff1b\u901a\u8fc7\u63d0\u793a\u548c\u6570\u636e\u589e\u5f3a\u7684\u5fae\u8c03\u63d0\u5347\u5728\u9690\u6027\u504f\u89c1\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\uff0c\u63d0\u5347\u5e45\u5ea6\u53ef\u8fbe\u7ea620%\u3002", "conclusion": "\u81ea\u52a8\u5316\u504f\u89c1\u8bc6\u522b\u4e0e\u9488\u5bf9\u6027\u5fae\u8c03\u5bf9\u6539\u8fdbLLM\u504f\u89c1\u7f13\u89e3\u6709\u5e2e\u52a9\uff0c\u4f46\u5728\u6027\u522b\u7b49\u9886\u57df\u4ecd\u5b58\u5728\u6311\u6218\uff1b\u9700\u8981\u6301\u7eed\u5f00\u53d1\u4ee5\u5b9e\u73b0\u66f4\u5168\u9762\u4e14\u7a33\u5065\u7684\u516c\u5e73\u6027\u4e0e\u5b89\u5168\u6027\u3002"}}
{"id": "2511.14218", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14218", "abs": "https://arxiv.org/abs/2511.14218", "authors": ["Xinlei Xiong", "Wenbo Hu", "Shuxun Zhou", "Kaifeng Bi", "Lingxi Xie", "Ying Liu", "Richang Hong", "Qi Tian"], "title": "Bridging the Gap Between Bayesian Deep Learning and Ensemble Weather Forecasts", "comment": null, "summary": "Weather forecasting is fundamentally challenged by the chaotic nature of the atmosphere, necessitating probabilistic approaches to quantify uncertainty. While traditional ensemble prediction (EPS) addresses this through computationally intensive simulations, recent advances in Bayesian Deep Learning (BDL) offer a promising but often disconnected alternative. We bridge these paradigms through a unified hybrid Bayesian Deep Learning framework for ensemble weather forecasting that explicitly decomposes predictive uncertainty into epistemic and aleatoric components, learned via variational inference and a physics-informed stochastic perturbation scheme modeling flow-dependent atmospheric dynamics, respectively. We further establish a unified theoretical framework that rigorously connects BDL and EPS, providing formal theorems that decompose total predictive uncertainty into epistemic and aleatoric components under the hybrid BDL framework. We validate our framework on the large-scale 40-year ERA5 reanalysis dataset (1979-2019) with 0.25\u00b0 spatial resolution. Experimental results show that our method not only improves forecast accuracy and yields better-calibrated uncertainty quantification but also achieves superior computational efficiency compared to state-of-the-art probabilistic diffusion models. We commit to making our code open-source upon acceptance of this paper.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6df7\u5408\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u96c6\u5408\u5929\u6c14\u9884\u62a5\uff0c\u5c06\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u4e3a\u77e5\u8bc6\u4e0d\u786e\u5b9a\u6027\uff08epistemic\uff09\u548c\u672c\u5f81\u4e0d\u786e\u5b9a\u6027\uff08aleatoric\uff09\uff0c\u901a\u8fc7\u53d8\u5206\u63a8\u65ad\u548c\u7269\u7406\u4fe1\u606f\u9a71\u52a8\u7684\u968f\u673a\u6270\u52a8\u6765\u5efa\u6a21\uff0c\u7406\u8bba\u4e0a\u5c06BDL\u4e0eEPS\u8054\u7cfb\u8d77\u6765\u3002\u57fa\u4e8eERA5\u6570\u636e\u96c6\u8fdb\u884c\u5927\u5c3a\u5ea6\u9a8c\u8bc1\uff0c\u7ed3\u679c\u5728\u51c6\u786e\u6027\u3001\u6821\u51c6\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u6982\u7387\u6269\u6563\u6a21\u578b\uff0c\u5e76\u8ba1\u5212\u5f00\u6e90\u4ee3\u7801\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u96c6\u5408\u9884\u62a5\uff08EPS\uff09\u4e0e\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\uff08BDL\uff09\u4e4b\u95f4\u7684\u5272\u88c2\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u5bf9\u6d41\u573a\u4f9d\u8d56\u578b\u4e0d\u786e\u5b9a\u6027\u53cb\u597d\u7684\u6982\u7387\u5929\u6c14\u9884\u62a5\u65b9\u6cd5\uff0c\u7ed3\u5408\u7269\u7406\u7ea6\u675f\u4e0e\u6570\u636e\u9a71\u52a8\u6765\u63d0\u5347\u9884\u6d4b\u4e0e\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6df7\u5408BDL\u6846\u67b6\uff1a\u4f7f\u7528\u53d8\u5206\u63a8\u65ad\u6765\u5efa\u6a21 epistemic \u4e0d\u786e\u5b9a\u6027\uff1b\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u9a71\u52a8\u7684\u968f\u673a\u6270\u52a8\u6765\u5efa\u6a21 aleatoric\uff08\u4e0e\u5927\u6c14\u52a8\u529b\u5b66\u76f8\u5173\u7684\uff09\u4e0d\u786e\u5b9a\u6027\uff1b\u5c06\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u4e3a\u4e24\u90e8\u5206\uff0c\u5e76\u5efa\u7acb\u4e0eEPS\u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u548c\u5b9a\u7406\u3002\u5bf9 large-scale ERA5\uff081979-2019\uff0c0.25\u00b0\uff09\u8fdb\u884c\u8bc4\u4f30\uff0c\u6d4b\u8bd5\u5305\u62ec\u9884\u6d4b\u51c6\u786e\u6027\u3001\u6821\u51c6\u6027\u53ca\u8ba1\u7b97\u6548\u7387\uff0c\u4e14\u4e0e\u6982\u7387\u6269\u6563\u6a21\u578b\u76f8\u6bd4\u5177\u5907\u66f4\u9ad8\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u65b9\u9762\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\uff0c\u5e76\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6982\u7387\u6269\u6563\u6a21\u578b\u3002\u7814\u7a76\u8fd8\u627f\u8bfa\u5728\u8bba\u6587\u63a5\u53d7\u540e\u5f00\u6e90\u4ee3\u7801\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408BDL\u6846\u67b6\u6210\u529f\u5c06BDL\u4e0eEPS\u7edf\u4e00\u5728\u4e00\u4e2a\u7406\u8bba\u4e0e\u5b9e\u8df5\u4f53\u7cfb\u4e2d\uff0c\u63d0\u4f9b\u5bf9\u6d41\u573a\u9a71\u52a8\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u4ee5\u53ca\u66f4\u9ad8\u6548\u7684\u6982\u7387\u5929\u6c14\u9884\u62a5\u9014\u5f84\uff0c\u5177\u5907\u826f\u597d\u63a8\u5e7f\u6f5c\u529b\u3002"}}
{"id": "2511.14229", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14229", "abs": "https://arxiv.org/abs/2511.14229", "authors": ["Jim Broadbent", "Felix Cohen", "Frederik Hvilsh\u00f8j", "Eric Landau", "Eren Sasoglu"], "title": "EBind: a practical approach to space binding", "comment": null, "summary": "We simplify space binding by focusing on two core components, a single encoder per modality and high-quality data; enabling training state-of-the-art models on a single GPU in a few hours as opposed to multiple days. We present EBind, an Easy, data-centric, and parameter-efficient method to Bind the embedding spaces of multiple contrastive models. We demonstrate that a simple 1.8B-parameter image-text-video-audio-3D model can outperform models 4 to 17x the size. The key to achieving this is a carefully curated dataset of three complementary data sources: i) 6.7M fully-automated multimodal quintuples sourced via SOTA retrieval models, ii) 1M diverse, semi-automated triples annotated by humans as negative, partial, or positive matches, and iii) 3.4M pre-existing captioned data items. We use 13 different evaluations to demonstrate the value of each data source. Due to limitations with existing benchmarks, we further introduce the first high-quality, consensus-annotated zero-shot classification benchmark between audio and PCs. In contrast to related work, we will open-source our code, model weights, and datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u4e2d\u5fc3\u5316\u3001\u53c2\u6570\u9ad8\u6548\u7684\u8de8\u6a21\u6001\u5bf9\u9f50\u65b9\u6cd5 EBind\uff0c\u901a\u8fc7\u5355\u6a21\u6001\u7f16\u7801\u5668\u548c\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u5c061.8B\u53c2\u6570\u7684\u591a\u6a21\u6001\u6a21\u578b\u63a8\u5411SOTA\uff0c\u8bad\u7ec3\u6210\u672c\u663e\u8457\u964d\u4f4e\u3002", "motivation": "\u964d\u4f4e\u8de8\u6a21\u6001\u5bf9\u9f50\u6a21\u578b\u7684\u8bad\u7ec3\u6210\u672c\u4e0e\u8d44\u6e90\u9700\u6c42\uff0c\u5b9e\u73b0\u5728\u5355GPU\u4e0a\u6570\u5c0f\u65f6\u5b8c\u6210\u8bad\u7ec3\uff0c\u63d0\u5347\u6570\u636e\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u540c\u65f6\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u65b9\u5f0f\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51fa EBind\uff08Easy, data-centric, parameter-efficient Bind\uff09\u65b9\u6cd5\uff0c\u7ed1\u5b9a\u591a\u4f4d\u5bf9\u6bd4\u6a21\u578b\u7684\u5d4c\u5165\u7a7a\u95f4\uff0c\u91c7\u7528\u5355\u4e00\u7f16\u7801\u5668\u8986\u76d6\u56fe\u50cf/\u6587\u672c/\u89c6\u9891/\u97f3\u9891/3D \u591a\u6a21\u6001\uff0c\u5e76\u4ee5\u4e09\u7c7b\u6570\u636e\u6e90\uff08\u5927\u89c4\u6a21\u81ea\u52a8\u5316\u7684\u4e94\u6a21\u6001\u6570\u636e\u3001\u7ecf\u8fc7\u4eba\u7c7b\u6807\u6ce8\u76841M \u4e09\u5143\u7ec4\u53ca\u591a\u6807\u7b7e\u3001\u4ee5\u53ca3.4M \u73b0\u6709\u7684\u6807\u9898\u6570\u636e\uff09\u8fdb\u884c\u6570\u636e\u9a71\u52a8\u8bad\u7ec3\u4e0e\u5bf9\u6bd4\u5b66\u4e60\uff1b\u63d0\u4f9b13\u79cd\u8bc4\u4f30\u6765\u8861\u91cf\u5404\u6570\u636e\u6e90\u7684\u4ef7\u503c\uff0c\u5e76\u9996\u6b21\u5f15\u5165\u9ad8\u8d28\u91cf\u5171\u8bc6\u6ce8\u91ca\u7684\u97f3\u9891\u4e0e\u8ba1\u7b97\u673a\u89c6\u89c9\u4e4b\u95f4\u7684\u96f6\u6837\u672c\u5206\u7c7b\u57fa\u51c6\uff0c\u6700\u540e\u5bf9\u5916\u5f00\u6e90\u4ee3\u7801\u3001\u6a21\u578b\u6743\u91cd\u4e0e\u6570\u636e\u96c6\u3002", "result": "1.8B \u53c2\u6570\u7684\u56fe\u50cf-\u6587\u672c-\u89c6\u9891-\u97f3\u9891-3D\u6a21\u578b\u5728\u591a\u6a21\u6001\u5bf9\u9f50\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u4f18\u4e8e\u6bd4\u5b83\u59274\u523017\u500d\u89c4\u6a21\u6a21\u578b\u7684\u6027\u80fd\u3002\u901a\u8fc713\u9879\u8bc4\u4f30\u9a8c\u8bc1\u5404\u6570\u636e\u6e90\u7684\u8d21\u732e\uff0c\u4e14\u5728\u5bf9\u6bd4\u5b9e\u9a8c\u4e2d\u4f53\u73b0\u51fa\u6570\u636e\u9a71\u52a8\u7684\u4f18\u52bf\u3002\u9996\u6b21\u5efa\u7acb\u9ad8\u8d28\u91cf\u5171\u8bc6\u6807\u6ce8\u7684\u96f6-shot \u97f3\u9891-PCs\u5206\u7c7b\u57fa\u51c6\u3002", "conclusion": "\u6570\u636e\u7684\u9ad8\u8d28\u91cf\u4e0e\u9009\u62e9\u6027\u4f7f\u7528\uff0c\u4ee5\u53ca\u7b80\u5316\u7684\u6a21\u578b\u7ed3\u6784\uff0c\u5171\u540c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u5f3a\u7684\u8de8\u6a21\u6001\u5bf9\u9f50\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728\u8de8\u6a21\u6001\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u627f\u8bfa\u5f00\u6e90\u3002"}}
{"id": "2511.14262", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14262", "abs": "https://arxiv.org/abs/2511.14262", "authors": ["Yosuke Nishimoto", "Takashi Matsubara"], "title": "Object-Centric World Models for Causality-Aware Reinforcement Learning", "comment": "Accepted by AAAI-26", "summary": "World models have been developed to support sample-efficient deep reinforcement learning agents. However, it remains challenging for world models to accurately replicate environments that are high-dimensional, non-stationary, and composed of multiple objects with rich interactions since most world models learn holistic representations of all environmental components. By contrast, humans perceive the environment by decomposing it into discrete objects, facilitating efficient decision-making. Motivated by this insight, we propose \\emph{Slot Transformer Imagination with CAusality-aware reinforcement learning} (STICA), a unified framework in which object-centric Transformers serve as the world model and causality-aware policy and value networks. STICA represents each observation as a set of object-centric tokens, together with tokens for the agent action and the resulting reward, enabling the world model to predict token-level dynamics and interactions. The policy and value networks then estimate token-level cause--effect relations and use them in the attention layers, yielding causality-guided decision-making. Experiments on object-rich benchmarks demonstrate that STICA consistently outperforms state-of-the-art agents in both sample efficiency and final performance.", "AI": {"tldr": "STICA introduces an object-centric world model using a Slot Transformer, paired with causality-aware policy and value networks, to handle high-dimensional, non-stationary, object-rich environments with improved sample efficiency and final performance.", "motivation": "The challenge of learning accurate world models for environments that are high-dimensional, non-stationary, and composed of multiple interacting objects is difficult with holistic representations. Emulating human object-centric perception can improve decision-making efficiency.", "method": "Represent observations as a set of object-centric tokens plus action and reward tokens. Use a Slot Transformer as the world model to predict token-level dynamics and interactions. Train policy and value networks to infer token-level causal relations and incorporate them into attention mechanisms, guiding decision-making causally.", "result": "Experiments on object-rich benchmarks show STICA achieves superior sample efficiency and final performance compared to state-of-the-art agents.", "conclusion": "Object-centric world models with causality-aware decision-making enable more sample-efficient and high-performing reinforcement learning in environments with many interacting objects."}}
{"id": "2511.14265", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14265", "abs": "https://arxiv.org/abs/2511.14265", "authors": ["Rui Zhang", "Chao Li", "Kezhong Liu", "Chen Wang", "Bolong Zheng", "Hongbo Jiang"], "title": "Unified Multimodal Vessel Trajectory Prediction with Explainable Navigation Intention", "comment": null, "summary": "Vessel trajectory prediction is fundamental to intelligent maritime systems. Within this domain, short-term prediction of rapid behavioral changes in complex maritime environments has established multimodal trajectory prediction (MTP) as a promising research area. However, existing vessel MTP methods suffer from limited scenario applicability and insufficient explainability. To address these challenges, we propose a unified MTP framework incorporating explainable navigation intentions, which we classify into sustained and transient categories. Our method constructs sustained intention trees from historical trajectories and models dynamic transient intentions using a Conditional Variational Autoencoder (CVAE), while using a non-local attention mechanism to maintain global scenario consistency. Experiments on real Automatic Identification System (AIS) datasets demonstrates our method's broad applicability across diverse scenarios, achieving significant improvements in both ADE and FDE. Furthermore, our method improves explainability by explicitly revealing the navigational intentions underlying each predicted trajectory.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u53ef\u89e3\u91ca\u591a\u6a21\u6001\u8239\u8236\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u6301\u7eed\u4e0e\u77ac\u6001\u5bfc\u822a\u610f\u5411\uff1a\u4f7f\u7528\u5386\u53f2\u8f68\u8ff9\u6784\u5efa\u6301\u7eed\u610f\u5411\u6811\u3001\u7528CVAE\u5efa\u6a21\u77ac\u6001\u610f\u5411\u3001\u5e76\u901a\u8fc7\u975e\u5c40\u90e8\u6ce8\u610f\u529b\u4fdd\u6301\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u5728AIS\u6570\u636e\u4e0a\u5b9e\u73b0ADE/FDE\u63d0\u5347\u4e0e\u53ef\u89e3\u91ca\u6027\u589e\u5f3a\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u8239\u8236\u591a\u6a21\u6001\u8f68\u8ff9\u9884\u6d4b\u5728\u573a\u666f\u9002\u7528\u6027\u4e0d\u8db3\u4e0e\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u7edf\u4e00\u6846\u67b6\u6765\u8986\u76d6\u66f4\u591a\u573a\u666f\u5e76\u63ed\u793a\u9884\u6d4b\u80cc\u540e\u7684\u5bfc\u822a\u610f\u5411\u3002", "method": "\u63d0\u51fa\u6301\u7eed\u610f\u5411\u6811\u6765\u4ece\u5386\u53f2\u8f68\u8ff9\u4e2d\u63d0\u53d6\u7a33\u5b9a\u7684\u610f\u5411\uff1b\u4f7f\u7528\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668(CVAE)\u5efa\u6a21\u52a8\u6001\u77ac\u6001\u610f\u5411\uff1b\u5f15\u5165\u975e\u5c40\u90e8\u6ce8\u610f\u529b\u4ee5\u4fdd\u6301\u5168\u5c40\u573a\u666f\u4e00\u81f4\u6027\uff1b\u5e76\u5728\u8f93\u51fa\u4e2d\u663e\u5f0f\u63ed\u793a\u6bcf\u6761\u9884\u6d4b\u8f68\u8ff9\u7684\u5bfc\u822a\u610f\u5411\u3002", "result": "\u5728\u771f\u5b9eAIS\u6570\u636e\u96c6\u4e0a\uff0c\u65b9\u6cd5\u5bf9\u591a\u6837\u573a\u666f\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u5e76\u5728ADE\u548cFDE\u6307\u6807\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb\uff1b\u540c\u65f6\u63d0\u5347\u53ef\u89e3\u91ca\u6027\uff0c\u660e\u786e\u63ed\u793a\u6bcf\u6761\u9884\u6d4b\u8f68\u8ff9\u6240\u5bf9\u5e94\u7684\u5bfc\u822a\u610f\u5411\u3002", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u5e7f\u6cdb\u9002\u7528\u6027\u7684\u5e73\u8861\uff0c\u5c55\u793a\u4e86\u5c06\u6301\u7eed\u4e0e\u77ac\u6001\u610f\u5411\u7ed3\u5408\u7684\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u5168\u5c40\u6ce8\u610f\u529b\u673a\u5236\u548cCVAE\u5b9e\u73b0\u5bf9\u590d\u6742\u6d77\u51b5\u7684\u9c81\u68d2\u591a\u6a21\u6001\u9884\u6d4b\u3002"}}
{"id": "2511.14276", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14276", "abs": "https://arxiv.org/abs/2511.14276", "authors": ["Frederik Hoppe", "Lars Kleinemeier", "Astrid Franz", "Udo G\u00f6bel"], "title": "Comparing Task-Agnostic Embedding Models for Tabular Data", "comment": "Accepted at AI for Tabular Data (EurIPS 2025 Workshop)", "summary": "Recent foundation models for tabular data achieve strong task-specific performance via in-context learning. Nevertheless, they focus on direct prediction by encapsulating both representation learning and task-specific inference inside a single, resource-intensive network. This work specifically focuses on representation learning, i.e., on transferable, task-agnostic embeddings. We systematically evaluate task-agnostic representations from tabular foundation models (TabPFN and TabICL) alongside with classical feature engineering (TableVectorizer) across a variety of application tasks as outlier detection (ADBench) and supervised learning (TabArena Lite). We find that simple TableVectorizer features achieve comparable or superior performance while being up to three orders of magnitude faster than tabular foundation models. The code is available at https://github.com/ContactSoftwareAI/TabEmbedBench.", "AI": {"tldr": "\u7b80\u6d01\u7684\u53d1\u73b0\u662f\uff1a\u5728\u8868\u683c\u6570\u636e\u4efb\u52a1\u4e2d\uff0c\u7528\u7b80\u5355\u7684 TableVectorizer \u7279\u5f81\u5c31\u80fd\u8fbe\u5230\u4e0e\u6216\u8d85\u8d8a\u57fa\u4e8e\u5927\u89c4\u6a21 TabPFN/TabICL \u7684\u8868\u793a\u5b66\u4e60\u6027\u80fd\uff0c\u5e76\u4e14\u901f\u5ea6\u5feb\u5f97\u591a\uff08\u53ef\u8fbe\u4e0a\u5343\u500d\u52a0\u901f\uff09\uff0c\u8868\u660e\u5bf9\u8868\u793a\u5b66\u4e60\u7684\u8fc7\u5ea6\u4f9d\u8d56\u5e76\u975e\u5fc5\u8981\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u8bc4\u4f30\u57fa\u4e8e\u8868\u683c\u6570\u636e\u7684\u57fa\u7840\u6a21\u578b\u5728\u4efb\u52a1\u65e0\u5173\u7684\u8868\u793a\u5b66\u4e60\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5373\u83b7\u5f97\u53ef\u8fc1\u79fb\u7684\u3001\u4efb\u52a1\u65e0\u5173\u7684\u5d4c\u5165\u3002\u4f5c\u8005\u5c06 TabPFN\u3001TabICL \u7b49\u8868\u683c\u57fa\u7840\u6a21\u578b\u7684\u4efb\u52a1\u65e0\u5173\u8868\u793a\u4e0e\u7ecf\u5178\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5 TableVectorizer \u8fdb\u884c\u5bf9\u6bd4\uff0c\u5e76\u5728\u4e0d\u540c\u5e94\u7528\u4efb\u52a1\u4e0a\u8bc4\u4f30\u5176\u6548\u679c\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u5728\u591a\u4efb\u52a1\u8bbe\u5b9a\u4e0b\u8bc4\u4f30\u4efb\u52a1\u65e0\u5173\u7684\u8868\u793a\uff1a\u5bf9\u6bd4 TabPFN\u3001TabICL \u4e0e TableVectorizer \u5728\u5f02\u5e38\u68c0\u6d4b ADBench \u548c\u76d1\u7763\u5b66\u4e60 TabArena Lite \u7b49\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u8003\u5bdf\u901f\u5ea6\u4e0e\u6548\u7387\uff0c\u4ee5\u4ee3\u7801\u5b9e\u73b0 TabEmbedBench \u7684\u57fa\u7ebf\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0cTableVectorizer \u7684\u7279\u5f81\u5728\u5927\u591a\u6570\u4efb\u52a1\u4e2d\u8fbe\u5230\u53ef\u6bd4\u751a\u81f3\u4f18\u4e8e\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u8868\u793a\u5b66\u4e60\uff0c\u4e14\u901f\u5ea6\u6bd4 TabPFN/TabICL \u5feb\u8bb8\u591a\uff0c\u8fbe\u5230\u4e86\u6700\u591a\u4e09\u4e2a\u6570\u91cf\u7ea7\u7684\u63d0\u5347\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\uff0c\u5728\u8868\u683c\u6570\u636e\u9886\u57df\uff0c\u4efb\u52a1\u65e0\u5173\u7684\u9ad8\u5bb9\u91cf\u5d4c\u5165\u5e76\u975e\u5fc5\u8981\uff1b\u7ecf\u8fc7\u7b80\u5355\u7684\u7279\u5f81\u5de5\u7a0b\uff08TableVectorizer\uff09\u4fbf\u53ef\u83b7\u5f97\u7ade\u4e89\u6027\u8868\u73b0\u4e14\u663e\u8457\u63d0\u9ad8\u6548\u7387\u3002\u5e76\u7ed9\u51fa\u5f00\u6e90\u4ee3\u7801 TabEmbedBench\u3002"}}
{"id": "2511.14312", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14312", "abs": "https://arxiv.org/abs/2511.14312", "authors": ["Chenyang Xu", "Siming Li", "Hao Wang"], "title": "H-LDM: Hierarchical Latent Diffusion Models for Controllable and Interpretable PCG Synthesis from Clinical Metadata", "comment": "This paper was accepted by IEEE BIBM 2025 conference", "summary": "Phonocardiogram (PCG) analysis is vital for cardiovascular disease diagnosis, yet the scarcity of labeled pathological data hinders the capability of AI systems. To bridge this, we introduce H-LDM, a Hierarchical Latent Diffusion Model for generating clinically accurate and controllable PCG signals from structured metadata. Our approach features: (1) a multi-scale VAE that learns a physiologically-disentangled latent space, separating rhythm, heart sounds, and murmurs; (2) a hierarchical text-to-biosignal pipeline that leverages rich clinical metadata for fine-grained control over 17 distinct conditions; and (3) an interpretable diffusion process guided by a novel Medical Attention module. Experiments on the PhysioNet CirCor dataset demonstrate state-of-the-art performance, achieving a Fr\u00e9chet Audio Distance of 9.7, a 92% attribute disentanglement score, and 87.1% clinical validity confirmed by cardiologists. Augmenting diagnostic models with our synthetic data improves the accuracy of rare disease classification by 11.3\\%. H-LDM establishes a new direction for data augmentation in cardiac diagnostics, bridging data scarcity with interpretable clinical insights.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u6f5c\u5728\u6269\u6563\u6a21\u578bH-LDM\uff0c\u7528\u7ed3\u6784\u5316\u5143\u6570\u636e\u5b9e\u73b0\u5bf9\u5fc3\u97f3\u4fe1\u53f7\u7684\u53ef\u63a7\u751f\u6210\uff0c\u89e3\u51b3PCG\u6570\u636e\u6807\u6ce8\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u901a\u8fc7\u591a\u5c3a\u5ea6VAE\u5b9e\u73b0\u751f\u7406\u89e3\u8026\u7684\u6f5c\u5728\u7a7a\u95f4\u3001\u5206\u5c42\u6587\u672c\u5230\u751f\u7269\u4fe1\u53f7\u7684\u7ba1\u7ebf\u5bf917\u79cd\u6761\u4ef6\u8fdb\u884c\u63a7\u5236\u3001\u4ee5\u53caMedical Attention\u6a21\u5757\u5f15\u5bfc\u7684\u53ef\u89e3\u91ca\u6269\u6563\u8fc7\u7a0b\uff0c\u5728PhysioNet CirCor\u6570\u636e\u96c6\u4e0a\u8fbe\u5230FAD 9.7\u300192%\u5c5e\u6027\u89e3\u8026\u300187.1%\u4e34\u5e8a\u6709\u6548\u6027\uff0c\u5e76\u80fd\u63d0\u5347\u7f55\u89c1\u75be\u75c5\u8bca\u65ad\u51c6\u786e\u738711.3%\u3002", "motivation": "\u89e3\u51b3\u5fc3\u8840\u7ba1\u75be\u75c5\u8bca\u65ad\u4e2d\u6807\u6ce8\u7a00\u7f3a\u7684\u75c5\u7406PCG\u6570\u636e\uff0c\u63d0\u51fa\u53ef\u63a7\u4e14\u5177\u6709\u4e34\u5e8a\u89e3\u91ca\u6027\u7684\u5408\u6210\u6570\u636e\u4ee5\u589e\u5f3aAI\u7cfb\u7edf\u6027\u80fd\u3002", "method": "1) \u591a\u5c3a\u5ea6VAE\u5b66\u4e60\u751f\u7406\u4e0a\u89e3\u8026\u7684\u6f5c\u5728\u7a7a\u95f4\uff08\u8282\u5f8b\u3001\u5fc3\u97f3\u3001\u6742\u97f3\uff09\uff1b2) \u5229\u7528\u4e30\u5bcc\u4e34\u5e8a\u5143\u6570\u636e\u7684\u5206\u5c42\u6587\u672c\u5230\u751f\u7269\u4fe1\u53f7\u7ba1\u7ebf\uff0c\u5b9e\u73b0\u5bf917\u79cd\u6761\u4ef6\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\uff1b3) \u901a\u8fc7\u65b0\u9896\u7684Medical Attention\u6a21\u5757\u5f15\u5bfc\u7684\u53ef\u89e3\u91ca\u6269\u6563\u8fc7\u7a0b\uff1b\u6574\u4f53\u7ec4\u6210H-LDM\u3002", "result": "\u5728PhysioNet CirCor\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0FAD = 9.7\u3001\u5c5e\u6027\u89e3\u8026\u738792%\u3001\u4e34\u5e8a\u6709\u6548\u602787.1%\uff0c\u4f7f\u7528\u5408\u6210\u6570\u636e\u63d0\u5347\u7f55\u89c1\u75be\u75c5\u5206\u7c7b\u51c6\u786e\u738711.3%\u3002", "conclusion": "\u4e3a\u5fc3\u810f\u8bca\u65ad\u4e2d\u7684\u6570\u636e\u589e\u5f3a\u5f00\u8f9f\u65b0\u65b9\u5411\uff0c\u7ed3\u5408\u53ef\u89e3\u91ca\u6027\u4e34\u5e8a\u6d1e\u5bdf\u4e0e\u6570\u636e\u7a00\u7f3a\u4e4b\u95f4\u7684\u6865\u6881\u3002"}}
{"id": "2511.14317", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14317", "abs": "https://arxiv.org/abs/2511.14317", "authors": ["Yuwen Zhang", "Viet Tran", "Paul Weng"], "title": "Intervention Efficiency and Perturbation Validation Framework: Capacity-Aware and Robust Clinical Model Selection under the Rashomon Effect", "comment": null, "summary": "In clinical machine learning, the coexistence of multiple models with comparable performance -- a manifestation of the Rashomon Effect -- poses fundamental challenges for trustworthy deployment and evaluation. Small, imbalanced, and noisy datasets, coupled with high-dimensional and weakly identified clinical features, amplify this multiplicity and make conventional validation schemes unreliable. As a result, selecting among equally performing models becomes uncertain, particularly when resource constraints and operational priorities are not considered by conventional metrics like F1 score. To address these issues, we propose two complementary tools for robust model assessment and selection: Intervention Efficiency (IE) and the Perturbation Validation Framework (PVF). IE is a capacity-aware metric that quantifies how efficiently a model identifies actionable true positives when only limited interventions are feasible, thereby linking predictive performance with clinical utility. PVF introduces a structured approach to assess the stability of models under data perturbations, identifying models whose performance remains most invariant across noisy or shifted validation sets. Empirical results on synthetic and real-world healthcare datasets show that using these tools facilitates the selection of models that generalize more robustly and align with capacity constraints, offering a new direction for tackling the Rashomon Effect in clinical settings.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u7528\u4e8e\u9c81\u68d2\u6a21\u578b\u8bc4\u4f30\u4e0e\u9009\u62e9\u7684\u5de5\u5177\uff1a\u5e72\u9884\u6548\u7387\uff08IE\uff09\u548c\u6270\u52a8\u9a8c\u8bc1\u6846\u67b6\uff08PVF\uff09\u3002IE\u5728\u6709\u9650\u5e72\u9884\u6761\u4ef6\u4e0b\u8861\u91cf\u6a21\u578b\u8bc6\u522b\u53ef\u884c\u52a8\u771f\u9633\u6027\uff08actionable TP\uff09\u7684\u80fd\u529b\uff0c\u5f3a\u8c03\u4e0e\u4e34\u5e8a\u5b9e\u7528\u6027\u7684\u5173\u7cfb\uff1bPVF\u5728\u6570\u636e\u6270\u52a8\u4e0b\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u7684\u7a33\u5b9a\u6027\uff0c\u5e2e\u52a9\u8bc6\u522b\u5728\u9a8c\u8bc1\u96c6\u566a\u58f0\u6216\u5206\u5e03\u504f\u79fb\u4e2d\u4fdd\u6301\u6700\u7a33\u5b9a\u7684\u6a21\u578b\u3002\u901a\u8fc7\u5bf9\u5408\u6210\u548c\u771f\u5b9e\u533b\u7597\u6570\u636e\u7684\u5b9e\u8bc1\uff0c\u8868\u660e\u8fd9\u4e24\u5de5\u5177\u6709\u52a9\u4e8e\u9009\u51fa\u6cdb\u5316\u66f4\u7a33\u5065\u4e14\u7b26\u5408\u5bb9\u91cf\u7ea6\u675f\u7684\u6a21\u578b\uff0c\u4ece\u800c\u7f13\u89e3\u4e34\u5e8a\u573a\u666f\u4e2d\u7684Rashomon\u6548\u5e94\u3002", "motivation": "\u5728\u4e34\u5e8a\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u5b58\u5728\u591a\u79cd\u6027\u80fd\u76f8\u5f53\u7684\u6a21\u578b\uff08Rashomon\u6548\u5e94\uff09\uff0c\u8fd9\u7ed9\u53ef\u4fe1\u90e8\u7f72\u548c\u8bc4\u4f30\u5e26\u6765\u6311\u6218\u3002\u5c0f\u6837\u672c\u3001\u4e0d\u5747\u8861\u3001\u566a\u58f0\u6570\u636e\uff0c\u4ee5\u53ca\u9ad8\u7ef4\u3001\u5f31\u8bc6\u522b\u7279\u5f81\uff0c\u653e\u5927\u4e86\u6a21\u578b\u591a\u6837\u6027\uff0c\u4f7f\u4f20\u7edf\u9a8c\u8bc1\u65b9\u6848\u4e0d\u53ef\u9760\uff0c\u5355\u7eaf\u7528F1\u7b49\u6307\u6807\u96be\u4ee5\u5728\u8d44\u6e90\u548c\u64cd\u4f5c\u4f18\u5148\u7ea7\u7ea6\u675f\u4e0b\u505a\u51fa\u9009\u62e9\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u4e92\u8865\u5de5\u5177\uff1a\u5e72\u9884\u6548\u7387\uff08IE\uff09\u548c\u6270\u52a8\u9a8c\u8bc1\u6846\u67b6\uff08PVF\uff09\u3002IE\u662f\u4e00\u4e2a\u5bb9\u91cf\u611f\u77e5\u7684\u5ea6\u91cf\uff0c\u91cf\u5316\u5728\u6709\u9650\u5e72\u9884\u6761\u4ef6\u4e0b\u6a21\u578b\u8bc6\u522b\u201c\u53ef\u884c\u52a8\u201d\u7684\u771f\u9633\u6027\uff08true positives\uff09\u6548\u7387\uff0c\u5f3a\u8c03\u9884\u6d4b\u6027\u80fd\u4e0e\u4e34\u5e8a\u5b9e\u7528\u6027\u4e4b\u95f4\u7684\u8054\u7cfb\uff1bPVF\u63d0\u4f9b\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u65b9\u6cd5\uff0c\u5728\u5e26\u6709\u6570\u636e\u6270\u52a8\u7684\u60c5\u5f62\u4e0b\u8bc4\u4f30\u6a21\u578b\u7684\u7a33\u5b9a\u6027\uff0c\u8bc6\u522b\u5728\u566a\u58f0\u6216\u5206\u5e03\u504f\u79fb\u7684\u9a8c\u8bc1\u96c6\u4e0a\u8868\u73b0\u6700\u4e0d\u6613\u53d7\u5f71\u54cd\u7684\u6a21\u578b\u3002\u5bf9\u5408\u6210\u548c\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u5de5\u5177\u7ec4\u5408\u6709\u52a9\u4e8e\u9009\u62e9\u5177\u6709\u66f4\u5f3a\u6cdb\u5316\u6027\u4e14\u7b26\u5408\u5bb9\u91cf\u7ea6\u675f\u7684\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528IE\u548cPVF\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u5206\u8fa8\u51fa\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u66f4\u5177\u9c81\u68d2\u6027\u548c\u53ef\u7528\u6027\u7684\u6a21\u578b\uff0c\u76f8\u8f83\u4ec5\u51ed\u4f20\u7edf\u6307\u6807\u66f4\u80fd\u5bf9Rashomon\u6548\u5e94\u8fdb\u884c\u7f13\u89e3\u3002", "conclusion": "\u4e24\u79cd\u5de5\u5177\u4e3a\u4e34\u5e8a\u8bbe\u7f6e\u4e2d\u7684\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff1a\u5728\u5173\u6ce8\u5bb9\u91cf\u7ea6\u675f\u7684\u524d\u63d0\u4e0b\uff0c\u7ed3\u5408\u6027\u80fd\u4e0e\u81e8\u5e8a\u5b9e\u7528\u6027\u8fdb\u884c\u8bc4\u4f30\uff0c\u4ece\u800c\u63d0\u5347\u9c81\u68d2\u6027\u548c\u53ef\u90e8\u7f72\u6027\u3002"}}
{"id": "2511.14320", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14320", "abs": "https://arxiv.org/abs/2511.14320", "authors": ["Aneesh Barthakur", "Luiz F. O. Chamon"], "title": "Learning with Statistical Equality Constraints", "comment": "to be published in the 39th Annual Conference on Neural Information Processing Systems", "summary": "As machine learning applications grow increasingly ubiquitous and complex, they face an increasing set of requirements beyond accuracy. The prevalent approach to handle this challenge is to aggregate a weighted combination of requirement violation penalties into the training objective. To be effective, this approach requires careful tuning of these hyperparameters (weights), involving trial-and-error and cross-validation, which becomes ineffective even for a moderate number of requirements. These issues are exacerbated when the requirements involve parities or equalities, as is the case in fairness and boundary value problems. An alternative technique uses constrained optimization to formulate these learning problems. Yet, existing approximation and generalization guarantees do not apply to problems involving equality constraints. In this work, we derive a generalization theory for equality-constrained statistical learning problems, showing that their solutions can be approximated using samples and rich parametrizations. Using these results, we propose a practical algorithm based on solving a sequence of unconstrained, empirical learning problems. We showcase its effectiveness and the new formulations enabled by equality constraints in fair learning, interpolating classifiers, and boundary value problems.", "AI": {"tldr": "Generalization theory for equality-constrained learning; a practical algorithm converting equality-constrained problems into a sequence of unconstrained empirical problems; demonstrated in fair learning, interpolating classifiers, and boundary value problems.", "motivation": "As ML systems become more complex, fixing accuracy is insufficient. Tuning penalties for multiple requirements is hard, particularly when constraints involve equalities (e.g., fairness, boundary values). Existing constrained approaches lack generalization guarantees for equality constraints, creating a gap between theory and practice.", "method": "Develop a generalization theory for equality-constrained statistical learning and show that solutions can be approximated from finite samples with rich parameterizations. Propose a practical algorithm that solves a sequence of unconstrained, empirical learning problems to enforce equality constraints.", "result": "The theory establishes that equality-constrained solutions can be approximated using finite samples. The proposed algorithm is effective in practice and enables new formulations driven by equality constraints in areas such as fair learning, interpolating classifiers, and boundary value problems.", "conclusion": "Equality constraints extend the scope of learnable problems and provide a path to principled generalization guarantees. The proposed approach offers a practical, scalable way to incorporate equality constraints into ML training for broader applications."}}
{"id": "2511.14348", "categories": ["cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.14348", "abs": "https://arxiv.org/abs/2511.14348", "authors": ["Nanxi Chen", "Sifan Wang", "Rujin Ma", "Airong Chen", "Chuanjie Cui"], "title": "Enforcing hidden physics in physics-informed neural networks", "comment": null, "summary": "Physics-informed neural networks (PINNs) represent a new paradigm for solving partial differential equations (PDEs) by integrating physical laws into the learning process of neural networks. However, despite their foundational role, the hidden irreversibility implied by the Second Law of Thermodynamics is often neglected during training, leading to unphysical solutions or even training failures in conventional PINNs. In this paper, we identify this critical gap and introduce a simple, generalized, yet robust irreversibility-regularized strategy that enforces hidden physical laws as soft constraints during training. This approach ensures that the learned solutions consistently respect the intrinsic one-way nature of irreversible physical processes. Across a wide range of benchmarks spanning traveling wave propagation, steady combustion, ice melting, corrosion evolution, and crack propagation, we demonstrate that our regularization scheme reduces predictive errors by more than an order of magnitude, while requiring only minimal modification to existing PINN frameworks. We believe that the proposed framework is broadly applicable to a wide class of PDE-governed physical systems and will have significant impact within the scientific machine learning community.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9PINN\u8fdb\u884c\u4e0d\u53ef\u9006\u6027\u6b63\u5219\u5316\u7684\u65b9\u6cd5\uff0c\u5c06\u9690\u85cf\u7684\u70ed\u529b\u5b66\u7b2c\u4e8c\u5b9a\u5f8b\u4e0d\u53ef\u9006\u6027\u4f5c\u4e3a\u8f6f\u7ea6\u675f\u52a0\u5165\u8bad\u7ec3\uff0c\u4ee5\u786e\u4fdd\u5b66\u4e60\u5f97\u5230\u7684\u89e3\u7b26\u5408\u5355\u5411\u7684\u4e0d\u53ef\u9006\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709PINN\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f80\u5f80\u5ffd\u7565\u9690\u85cf\u7684\u4e0d\u53ef\u9006\u6027\uff08\u5982\u70ed\u529b\u5b66\u7b2c\u4e8c\u5b9a\u5f8b\uff09\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e0d\u7269\u7406\u7684\u89e3\u6216\u8bad\u7ec3\u5931\u8d25\u3002\u9700\u8981\u5728\u7269\u7406\u5148\u9a8c\u57fa\u7840\u4e0a\u52a0\u5165\u4e0d\u53ef\u9006\u6027\u7ea6\u675f\u4ee5\u63d0\u9ad8\u89e3\u7684\u7269\u7406\u4e00\u81f4\u6027\u548c\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7b80\u5355\u3001\u5e7f\u4e49\u4e14\u9c81\u68d2\u7684\u4e0d\u53ef\u9006\u6027\u6b63\u5219\u5316\u7b56\u7565\uff0c\u5c06\u5176\u4f5c\u4e3a\u8f6f\u7ea6\u675f\u878d\u5165PINN\u8bad\u7ec3\u4e2d\uff0c\u5f3a\u5236\u5b66\u4e60\u7684\u89e3\u9075\u5faa\u4e0d\u53ef\u9006\u8fc7\u7a0b\u7684\u5355\u5411\u6027\uff0c\u4e14\u5bf9\u73b0\u6709PINN\u6846\u67b6\u6539\u52a8\u6781\u5c11\u3002", "result": "\u5728\u65c5\u884c\u6ce2\u4f20\u64ad\u3001\u5b9a\u5e38\u71c3\u70e7\u3001\u51b0\u878d\u89e3\u3001\u8150\u8680\u6f14\u5316\u548c\u88c2\u7eb9\u6269\u5c55\u7b49\u591a\u79cd\u57fa\u51c6\u4e0a\uff0c\u6b63\u5219\u5316\u663e\u8457\u964d\u4f4e\u9884\u6d4b\u8bef\u5dee\uff08\u8d85\u8fc7\u4e00\u4e2a\u6570\u91cf\u7ea7\uff09\uff0c\u540c\u65f6\u51e0\u4e4e\u4e0d\u9700\u8981\u5bf9\u73b0\u6709PINN\u6846\u67b6\u505a\u5927\u89c4\u6a21\u4fee\u6539\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e0d\u53ef\u9006\u6027\u6b63\u5219\u5316\u6846\u67b6\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u53ef\u5e94\u7528\u4e8e\u5e7f\u4e49\u7684PDE\u9a71\u52a8\u7269\u7406\u7cfb\u7edf\uff0c\u9884\u8ba1\u5bf9\u79d1\u7814\u673a\u5668\u5b66\u4e60\u9886\u57df\u4ea7\u751f\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2511.14416", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14416", "abs": "https://arxiv.org/abs/2511.14416", "authors": ["Haobin Li", "Mouxing Yang", "Xi Peng"], "title": "Toward Robust and Harmonious Adaptation for Cross-modal Retrieval", "comment": "19 pages, 6 figures", "summary": "Recently, the general-to-customized paradigm has emerged as the dominant approach for Cross-Modal Retrieval (CMR), which reconciles the distribution shift problem between the source domain and the target domain. However, existing general-to-customized CMR methods typically assume that the entire target-domain data is available, which is easily violated in real-world scenarios and thus inevitably suffer from the query shift (QS) problem. Specifically, query shift embraces the following two characteristics and thus poses new challenges to CMR. i) Online Shift: real-world queries always arrive in an online manner, rendering it impractical to access the entire query set beforehand for customization approaches; ii) Diverse Shift: even with domain customization, the CMR models struggle to satisfy queries from diverse users or scenarios, leaving an urgent need to accommodate diverse queries. In this paper, we observe that QS would not only undermine the well-structured common space inherited from the source model, but also steer the model toward forgetting the indispensable general knowledge for CMR. Inspired by the observations, we propose a novel method for achieving online and harmonious adaptation against QS, dubbed Robust adaptation with quEry ShifT (REST). To deal with online shift, REST first refines the retrieval results to formulate the query predictions and accordingly designs a QS-robust objective function on these predictions to preserve the well-established common space in an online manner. As for tackling the more challenging diverse shift, REST employs a gradient decoupling module to dexterously manipulate the gradients during the adaptation process, thus preventing the CMR model from forgetting the general knowledge. Extensive experiments on 20 benchmarks across three CMR tasks verify the effectiveness of our method against QS.", "AI": {"tldr": "\u63d0\u51faREST\uff0c\u5728\u8de8\u6a21\u6001\u68c0\u7d22\u4e2d\u5e94\u5bf9\u5728\u7ebf\u4e14\u591a\u6837\u5316\u7684\u67e5\u8be2\u6f02\u79fb\u95ee\u9898\u3002\u901a\u8fc7\u5bf9\u67e5\u8be2\u9884\u6d4b\u8fdb\u884c\u5728\u7ebf refined\u3001\u8bbe\u8ba1\u67e5\u8be2\u6f02\u79fb\u9c81\u68d2\u7684\u76ee\u6807\u51fd\u6570\uff0c\u4ee5\u53ca\u4f7f\u7528\u68af\u5ea6\u89e3\u8026\u6a21\u5757\u9632\u6b62\u5bf9\u901a\u7528\u77e5\u8bc6\u7684\u9057\u5fd8\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9QS\u7684\u9c81\u68d2\u81ea\u9002\u5e94\uff0c\u4e14\u572820\u4e2a\u57fa\u51c6\u30013\u4e2a\u8de8\u6a21\u6001\u68c0\u7d22\u4efb\u52a1\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u6e90\u6a21\u578b\u5728\u76ee\u6807\u57df\u6570\u636e\u5206\u5e03\u9519\u4f4d\u3001\u4ee5\u53ca\u5728\u7ebf\u3001 Diverse \u67e5\u8be2\u5e26\u6765\u7684\u67e5\u8be2\u6f02\u79fb\uff08QS\uff09\uff0c\u907f\u514d\u5728\u81ea\u9002\u5e94\u8fc7\u7a0b\u4e2d\u9057\u5fd8\u901a\u7528\u8de8\u6a21\u6001\u68c0\u7d22\u77e5\u8bc6\u3002", "method": "\u63d0\u51faREST\uff1a1) \u5728\u7ebf\u79fb\u5ba2\u5e26\u6765\u7684\u67e5\u8be2\u9884\u6d4b\u7684\u518d\u6784\u9020\u4e0e\u5bf9\u9f50\uff0c\u5f62\u6210QS\u9c81\u68d2\u7684\u76ee\u6807\u51fd\u6570\uff1b2) \u4f7f\u7528\u68af\u5ea6\u89e3\u8026\u6a21\u5757\u5728\u9002\u5e94\u9636\u6bb5\u64cd\u63a7\u68af\u5ea6\uff0c\u9632\u6b62\u9057\u5fd8\u4e00\u822c\u77e5\u8bc6\uff0c\u4fdd\u6301\u8de8\u6a21\u6001\u901a\u7528\u7a7a\u95f4\u3002", "result": "\u572820\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u30013\u4e2aCMR\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u5c55\u73b0\u5bf9\u67e5\u8be2\u6f02\u79fb\u7684\u9c81\u68d2\u6027\u4e0e\u5bf9\u901a\u7528\u77e5\u8bc6\u7684\u4fdd\u7559\uff0c\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\u3002", "conclusion": "REST\u5b9e\u73b0\u4e86\u5728\u7ebf\u4e14\u548c\u8c10\u7684\u81ea\u9002\u5e94\uff0c\u7f13\u89e3\u67e5\u8be2\u6f02\u79fb\u5bf9\u8de8\u6a21\u6001\u68c0\u7d22\u7684\u6311\u6218\uff0c\u4f7f\u6a21\u578b\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2511.14419", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14419", "abs": "https://arxiv.org/abs/2511.14419", "authors": ["Xiaowei Xu", "Justin Sonneck", "Hongxiao Wang", "Roman Burkard", "Hendrik Wohrle", "Anton Grabmasier", "Matthias Gunzer", "Jianxu Chen"], "title": "FlowRoI A Fast Optical Flow Driven Region of Interest Extraction Framework for High-Throughput Image Compression in Immune Cell Migration Analysis", "comment": "12 pages, 9 figures, 2 tables", "summary": "Autonomous migration is essential for the function of immune cells such as neutrophils and plays a pivotal role in diverse diseases. Recently, we introduced ComplexEye, a multi-lens array microscope comprising 16 independent aberration-corrected glass lenses arranged at the pitch of a 96-well plate, capable of capturing high-resolution movies of migrating cells. This architecture enables high-throughput live-cell video microscopy for migration analysis, supporting routine quantification of autonomous motility with strong potential for clinical translation. However, ComplexEye and similar high-throughput imaging platforms generate data at an exponential rate, imposing substantial burdens on storage and transmission. To address this challenge, we present FlowRoI, a fast optical-flow-based region of interest (RoI) extraction framework designed for high-throughput image compression in immune cell migration studies. FlowRoI estimates optical flow between consecutive frames and derives RoI masks that reliably cover nearly all migrating cells. The raw image and its corresponding RoI mask are then jointly encoded using JPEG2000 to enable RoI-aware compression. FlowRoI operates with high computational efficiency, achieving runtimes comparable to standard JPEG2000 and reaching an average throughput of about 30 frames per second on a modern laptop equipped with an Intel i7-1255U CPU. In terms of image quality, FlowRoI yields higher peak signal-to-noise ratio (PSNR) in cellular regions and achieves 2.0-2.2x higher compression rates at matched PSNR compared to standard JPEG2000.", "AI": {"tldr": "FlowRoI \u901a\u8fc7\u57fa\u4e8e\u5149\u6d41\u7684 ROI \u63d0\u53d6\u5b9e\u73b0\u9ad8\u541e\u5410\u91cf\u514d\u75ab\u7ec6\u80de\u8fc1\u79fb\u89c6\u9891\u7684 ROI \u611f\u77e5\u538b\u7f29\uff0c\u63d0\u4f9b\u4e0e JPEG2000 \u76f8\u8fd1\u7684\u901f\u5ea6\u5e76\u5728\u76f8\u540c PSNR \u6761\u4ef6\u4e0b\u5b9e\u73b0\u66f4\u9ad8\u7684\u6570\u636e\u538b\u7f29\u6bd4\u3002", "motivation": "\u5e94\u5bf9\u9ad8\u541e\u5410\u6210\u50cf\u5e73\u53f0\uff08\u5982 ComplexEye\uff09\u5e26\u6765\u7684\u6570\u636e\u7206\u70b8\u5f0f\u589e\u957f\uff0c\u9700\u9ad8\u6548\u7684\u5b58\u50a8\u4e0e\u4f20\u8f93\u65b9\u6848\uff0c\u540c\u65f6\u4fdd\u6301\u8fc1\u79fb\u7ec6\u80de\u7684\u5b9a\u91cf\u5206\u6790\u80fd\u529b\u3002", "method": "\u5229\u7528\u76f8\u90bb\u5e27\u4e4b\u95f4\u7684\u5149\u6d41\u4f30\u8ba1\uff0c\u63a8\u5bfc\u8986\u76d6\u51e0\u4e4e\u6240\u6709\u8fc1\u79fb\u7ec6\u80de\u7684 RoI \u63a9\u6a21\uff1b\u5c06\u539f\u59cb\u56fe\u50cf\u4e0e RoI \u63a9\u6a21\u8054\u5408\u7f16\u7801\u4e3a JPEG2000\uff0c\u4ece\u800c\u5b9e\u73b0 RoI \u611f\u77e5\u538b\u7f29\uff1b\u5728 i7-1255U CPU \u7684\u73b0\u4ee3\u7b14\u8bb0\u672c\u4e0a\u5b9e\u73b0\u7ea6 30 \u5e27/\u79d2\u7684\u8fd0\u884c\u65f6\uff0c\u4e14\u5728\u7ec6\u80de\u533a\u57df\u83b7\u5f97\u66f4\u9ad8\u7684 PSNR\uff0c\u5e76\u5728\u5339\u914d PSNR \u65f6\u5b9e\u73b0 2.0\u20132.2 \u500d\u7684\u538b\u7f29\u7387\u3002", "result": "FlowRoI \u7684\u541e\u5410\u91cf\u63a5\u8fd1\u6807\u51c6 JPEG2000 \u7684\u6c34\u5e73\uff0c\u7ec6\u80de\u533a\u57df\u7684 PSNR \u66f4\u9ad8\uff1b\u5728\u76f8\u540c PSNR \u6761\u4ef6\u4e0b\uff0c\u538b\u7f29\u7387\u63d0\u5347\u7ea6 2.0\u20132.2 \u500d\u3002", "conclusion": "\u57fa\u4e8e\u5149\u6d41\u7684 RoI \u63d0\u53d6\u4e0e\u8054\u5408\u7f16\u7801\u7684 FlowRoI \u4e3a\u9ad8\u541e\u5410\u514d\u75ab\u7ec6\u80de\u8fc1\u79fb\u7814\u7a76\u63d0\u4f9b\u4e00\u79cd\u9ad8\u6548\u7684 ROI \u611f\u77e5\u538b\u7f29\u89e3\u51b3\u65b9\u6848\uff0c\u4fbf\u4e8e\u6570\u636e\u7ba1\u7406\u5e76\u5177\u5907\u5411\u4e34\u5e8a\u8f6c\u5316\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.14426", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.14426", "abs": "https://arxiv.org/abs/2511.14426", "authors": ["Andrey Okhotin", "Maksim Nakhodnov", "Nikita Kazeev", "Andrey E Ustyuzhanin", "Dmitry Vetrov"], "title": "MiAD: Mirage Atom Diffusion for De Novo Crystal Generation", "comment": null, "summary": "In recent years, diffusion-based models have demonstrated exceptional performance in searching for simultaneously stable, unique, and novel (S.U.N.) crystalline materials. However, most of these models don't have the ability to change the number of atoms in the crystal during the generation process, which limits the variability of model sampling trajectories. In this paper, we demonstrate the severity of this restriction and introduce a simple yet powerful technique, mirage infusion, which enables diffusion models to change the state of the atoms that make up the crystal from existent to non-existent (mirage) and vice versa. We show that this technique improves model quality by up to $\\times2.5$ compared to the same model without this modification. The resulting model, Mirage Atom Diffusion (MiAD), is an equivariant joint diffusion model for de novo crystal generation that is capable of altering the number of atoms during the generation process. MiAD achieves an $8.2\\%$ S.U.N. rate on the MP-20 dataset, which substantially exceeds existing state-of-the-art approaches. The source code can be found at \\href{https://github.com/andrey-okhotin/miad.git}{\\texttt{github.com/andrey-okhotin/miad}}.", "AI": {"tldr": " Mirage infusion \u8ba9\u6269\u6563\u6a21\u578b\u5728\u6676\u4f53\u751f\u6210\u4e2d\u4e5f\u80fd\u6539\u53d8\u539f\u5b50\u6570\u91cf\uff0c\u663e\u8457\u63d0\u5347\u8d28\u91cf\u4e0e S.U.N. \u6bd4\u4f8b\uff1bMiAD \u5728 MP-20 \u6570\u636e\u96c6\u8fbe\u5230 8.2% \u7684 S.U.N. \u7387\uff0c\u4e14\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee3\u7801\u516c\u5f00\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u7684\u6676\u4f53\u751f\u6210\u5f80\u5f80\u56fa\u5b9a\u539f\u5b50\u6570\uff0c\u9650\u5236\u4e86\u91c7\u6837\u8f68\u8ff9\u548c\u591a\u6837\u6027\uff1b\u9700\u8981\u8ba9\u6a21\u578b\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u52a8\u6001\u6539\u53d8\u539f\u5b50\u6570\u91cf\u4ee5\u63a2\u7d22\u66f4\u5927\u8bbe\u8ba1\u7a7a\u95f4\u3002", "method": "\u63d0\u51fa mirage infusion \u6280\u672f\uff0c\u4f7f\u6676\u4f53\u4e2d\u7684\u539f\u5b50\u72b6\u6001\u53ef\u5728\u5b58\u5728/\u975e\u5b58\u5728\u4e4b\u95f4\u5207\u6362\uff1b\u63d0\u51fa\u4e00\u4e2a\u7b49\u53d8\u8054\u5408\u6269\u6563\u6a21\u578b MiAD\uff0c\u80fd\u591f\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u6539\u53d8\u539f\u5b50\u6570\uff0c\u8fdb\u884c\u53bb novo \u6676\u4f53\u751f\u6210\u3002", "result": "\u76f8\u8f83\u540c\u6a21\u578b\u672a\u4fee\u6539\u7684\u60c5\u51b5\u4e0b\uff0c\u8d28\u91cf\u63d0\u5347\u6700\u591a\u7ea6 2.5 \u500d\uff1b\u5728 MP-20 \u6570\u636e\u96c6\u5b9e\u73b0 8.2% \u7684 S.U.N. \u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": " Mirage Atom Diffusion\uff08MiAD\uff09\u4e3a\u53bb novo \u6676\u4f53\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u539f\u5b50\u6570\u52a8\u6001\u8c03\u6574\u80fd\u529b\uff0cmirage infusion \u4f5c\u4e3a\u7b80\u5355\u800c\u5f3a\u5927\u7684\u6280\u672f\u624b\u6bb5\uff0c\u63d0\u5347\u4e86\u751f\u6210\u8d28\u91cf\u4e0e\u591a\u6837\u6027\uff1b\u4ee3\u7801\u516c\u5f00\u4e8e GitHub\u3002"}}
{"id": "2511.14452", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14452", "abs": "https://arxiv.org/abs/2511.14452", "authors": ["Emanuele Palumbo", "Sorawit Saengkyongam", "Maria R. Cervera", "Jens Behrmann", "Andrew C. Miller", "Guillermo Sapiro", "Christina Heinze-Deml", "Antoine Wehenkel"], "title": "Hybrid Modeling of Photoplethysmography for Non-invasive Monitoring of Cardiovascular Parameters", "comment": null, "summary": "Continuous cardiovascular monitoring can play a key role in precision health. However, some fundamental cardiac biomarkers of interest, including stroke volume and cardiac output, require invasive measurements, e.g., arterial pressure waveforms (APW). As a non-invasive alternative, photoplethysmography (PPG) measurements are routinely collected in hospital settings. Unfortunately, the prediction of key cardiac biomarkers from PPG instead of APW remains an open challenge, further complicated by the scarcity of annotated PPG measurements. As a solution, we propose a hybrid approach that uses hemodynamic simulations and unlabeled clinical data to estimate cardiovascular biomarkers directly from PPG signals. Our hybrid model combines a conditional variational autoencoder trained on paired PPG-APW data with a conditional density estimator of cardiac biomarkers trained on labeled simulated APW segments. As a key result, our experiments demonstrate that the proposed approach can detect fluctuations of cardiac output and stroke volume and outperform a supervised baseline in monitoring temporal changes in these biomarkers.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff1a\u901a\u8fc7\u5bf9PPG-APW\u914d\u5bf9\u6570\u636e\u8bad\u7ec3\u7684\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08cVAE\uff09\u548c\u5728\u5e26\u6807\u7b7e\u7684\u6a21\u62dfAPW\u7247\u6bb5\u4e0a\u8bad\u7ec3\u7684\u6761\u4ef6\u5bc6\u5ea6\u4f30\u8ba1\u5668\uff0c\u7ed3\u5408\u4eff\u771f\u4e0e\u672a\u6807\u6ce8\u4e34\u5e8a\u6570\u636e\u6765\u4ecePPG\u63a8\u65ad\u5fc3\u8840\u7ba1\u5173\u952e biomarkers\uff08SV\u548cCO\uff09\uff0c\u5e76\u5728\u76d1\u6d4b\u65f6\u95f4\u53d8\u5316\u4e0a\u4f18\u4e8e\u6709\u76d1\u7763\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3\u4ece\u65e0\u521bPPG\u9884\u6d4b\u5173\u952e\u5fc3\u810f\u751f\u7269\u6807\u5fd7\u7269\uff08\u5982 SV\u3001CO\uff09\u6240\u9762\u4e34\u7684\u6570\u636e\u7a00\u7f3a\u4e0e\u4fe1\u53f7\u4e0d\u5145\u5206\u95ee\u9898\uff0c\u5229\u7528\u7269\u7406\u4eff\u771f\u4e0e\u672a\u6807\u6ce8\u6570\u636e\u5b9e\u73b0\u4ecePPG\u5230\u8840\u6d41\u529b\u5b66\u6307\u6807\u7684\u51c6\u786e\u4f30\u8ba1\u3002", "method": "1) \u4f7f\u7528\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08cVAE\uff09\uff0c\u5728\u6210\u5bf9\u7684PPG-APW\u6570\u636e\u4e0a\u5b66\u4e60PPG\u5230\u6f5c\u5728\u8868\u5f81\u7684\u6620\u5c04\uff1b2) \u5728\u5e26\u6807\u7b7e\u7684\u6a21\u62dfAPW\u7247\u6bb5\u4e0a\u8bad\u7ec3\u6761\u4ef6\u5bc6\u5ea6\u4f30\u8ba1\u5668\uff0c\u4ee5\u4f30\u8ba1\u5fc3\u810f\u751f\u7269\u6807\u5fd7\u7269\u7684\u6761\u4ef6\u5206\u5e03\uff1b3) \u5c06\u4e24\u8005\u7ed3\u5408\uff0c\u76f4\u63a5\u4ecePPG\u4f30\u8ba1SV\u548cCO\u7684\u5206\u5e03\u5e76\u76d1\u6d4b\u5176\u65f6\u95f4\u53d8\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6df7\u5408\u6a21\u578b\u80fd\u591f\u68c0\u6d4bCO\u548cSV\u7684\u6ce2\u52a8\uff0c\u5e76\u5728\u76d1\u6d4b\u8fd9\u4e9b\u751f\u7269\u6807\u5fd7\u7269\u7684\u65f6\u95f4\u53d8\u5316\u65b9\u9762\u4f18\u4e8e\u6709\u76d1\u7763\u57fa\u7ebf\u3002", "conclusion": "\u5c06\u7269\u7406\u4eff\u771f\u4e0e\u65e0\u6807\u6ce8\u6570\u636e\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u53ef\u5b9e\u73b0\u975e\u4fb5\u5165\u6027\u5fc3\u8840\u7ba1\u751f\u7269\u6807\u5fd7\u7269\u7684\u66f4\u4f18\u8ddf\u8e2a\uff0c\u4e0e\u7eaf\u76d1\u7763\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u66f4\u5f3a\u7684\u65f6\u95f4\u53d8\u5316\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2511.14465", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14465", "abs": "https://arxiv.org/abs/2511.14465", "authors": ["Cl\u00e9ment Dumas"], "title": "nnterp: A Standardized Interface for Mechanistic Interpretability of Transformers", "comment": "7 pages, 1 figure, accepted at the mechanistic interpretability workshop of NeurIPS 2025", "summary": "Mechanistic interpretability research requires reliable tools for analyzing transformer internals across diverse architectures. Current approaches face a fundamental tradeoff: custom implementations like TransformerLens ensure consistent interfaces but require coding a manual adaptation for each architecture, introducing numerical mismatch with the original models, while direct HuggingFace access through NNsight preserves exact behavior but lacks standardization across models. To bridge this gap, we develop nnterp, a lightweight wrapper around NNsight that provides a unified interface for transformer analysis while preserving original HuggingFace implementations. Through automatic module renaming and comprehensive validation testing, nnterp enables researchers to write intervention code once and deploy it across 50+ model variants spanning 16 architecture families. The library includes built-in implementations of common interpretability methods (logit lens, patchscope, activation steering) and provides direct access to attention probabilities for models that support it. By packaging validation tests with the library, researchers can verify compatibility with custom models locally. nnterp bridges the gap between correctness and usability in mechanistic interpretability tooling.", "AI": {"tldr": "nnterp is a lightweight wrapper around NNsight that unifies transformer analysis across 50+ models and 16 architecture families, preserving HuggingFace behavior while standardizing interfaces and adding validation tests.", "motivation": "There is a fundamental tradeoff in mechanistic interpretability tooling: custom pipelines offer consistency but require architecture-specific adaptations with potential numerical drift, while direct HuggingFace access preserves behavior but lacks cross-model standardization. A unified, validated tool is needed to enable reliable cross-architecture analysis.", "method": "nnterp wraps NNsight with automatic module renaming to produce a consistent interface across architectures, includes built-in interpretability methods (logit lens, patchscope, activation steering), exposes attention probabilities where supported, and packages comprehensive validation tests so researchers can verify compatibility with custom models locally across 50+ variants and 16 architecture families.", "result": "A unified, compatible interface is produced that preserves original HuggingFace implementations while enabling cross-model analysis, reduces numerical mismatch risk, and provides validation coverage to ensure compatibility with bespoke models.", "conclusion": "nnterp bridges correctness and usability in mechanistic interpretability tooling by enabling one-time intervention code to run across a broad spectrum of transformer architectures with validated reliability."}}
{"id": "2511.14485", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14485", "abs": "https://arxiv.org/abs/2511.14485", "authors": ["Diego Armando P\u00e9rez-Rosero", "Danna Valentina Salazar-Dubois", "Juan Camilo Lugo-Rojas", "Andr\u00e9s Marino \u00c1lvarez-Meza", "Germ\u00e1n Castellanos-Dominguez"], "title": "Notes on Kernel Methods in Machine Learning", "comment": null, "summary": "These notes provide a self-contained introduction to kernel methods and their geometric foundations in machine learning. Starting from the construction of Hilbert spaces, we develop the theory of positive definite kernels, reproducing kernel Hilbert spaces (RKHS), and Hilbert-Schmidt operators, emphasizing their role in statistical estimation and representation of probability measures. Classical concepts such as covariance, regression, and information measures are revisited through the lens of Hilbert space geometry. We also introduce kernel density estimation, kernel embeddings of distributions, and the Maximum Mean Discrepancy (MMD). The exposition is designed to serve as a foundation for more advanced topics, including Gaussian processes, kernel Bayesian inference, and functional analytic approaches to modern machine learning.", "AI": {"tldr": "\u4ee5Hilbert\u7a7a\u95f4\u4e3a\u57fa\u7840\u7684\u6838\u65b9\u6cd5\u81ea\u6d3d\u5165\u95e8\uff0c\u7cfb\u7edf\u6784\u5efa\u6b63\u5b9a\u6838\u3001RKHS\u3001Hilbert\u2013Schmidt\u7b97\u5b50\u7b49\u5de5\u5177\uff0c\u5e76\u5c06\u534f\u65b9\u5dee\u3001\u56de\u5f52\u3001\u4fe1\u606f\u91cf\u7b49\u7ecf\u5178\u6982\u5ff5\u6620\u5c04\u5230\u51e0\u4f55\u6846\u67b6\uff0c\u6db5\u76d6\u6838\u5bc6\u5ea6\u4f30\u8ba1\u3001\u5206\u5e03\u5d4c\u5165\u4e0eMMD\uff0c\u4e3a\u9ad8\u65af\u8fc7\u7a0b\u3001\u6838\u8d1d\u53f6\u65af\u63a8\u65ad\u7b49\u540e\u7eed\u4e3b\u9898\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u671f\u671b\u628a\u6838\u65b9\u6cd5\u4e0e\u51e0\u4f55/\u51fd\u6570\u5206\u6790\u89c6\u89d2\u7edf\u4e00\u8d77\u6765\uff0c\u63d0\u4f9b\u4e00\u4e2a\u81ea\u6d3d\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4fbf\u4e8e\u7edf\u8ba1\u4f30\u8ba1\u548c\u5206\u5e03\u8868\u793a\u7684\u5206\u6790\u4e0e\u5b9e\u73b0\u3002", "method": "\u4ece\u6784\u9020\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u51fa\u53d1\uff0c\u7cfb\u7edf\u53d1\u5c55\u6b63\u5b9a\u6838\u4e0eRKHS\u7684\u6027\u8d28\u3001Hilbert\u2013Schmidt\u7b97\u5b50\u53ca\u5176\u5728\u4f30\u8ba1\u4e0e\u5206\u5e03\u8868\u793a\u4e2d\u7684\u4f5c\u7528\uff1b\u901a\u8fc7\u8be5\u51e0\u4f55\u89c6\u89d2\u91cd\u65b0\u5ba1\u89c6\u534f\u65b9\u5dee\u3001\u56de\u5f52\u548c\u4fe1\u606f\u5ea6\u91cf\uff1b\u4ecb\u7ecd\u6838\u5bc6\u5ea6\u4f30\u8ba1\u3001\u5206\u5e03\u7684\u6838\u5d4c\u5165\u4ee5\u53ca\u6700\u5927\u5747\u503c\u5dee(MMD)\u7b49\u5de5\u5177\uff1b\u4e3a\u540e\u7eed\u4e3b\u9898\uff08\u9ad8\u65af\u8fc7\u7a0b\u3001\u6838\u8d1d\u53f6\u65af\u63a8\u65ad\u3001\u51fd\u6570\u5206\u6790\u65b9\u6cd5\u5728ML\u4e2d\u7684\u5e94\u7528\uff09\u6253\u57fa\u7840\u3002", "result": "\u63d0\u4f9b\u4e00\u4e2a\u81ea\u6d3d\u7684\u7406\u8bba\u4e0e\u65b9\u6cd5\u8bba\u6846\u67b6\uff0c\u4f7f\u5f97\u6838\u65b9\u6cd5\u7684\u7edf\u8ba1\u63a8\u65ad\u3001\u5206\u5e03\u6bd4\u8f83\u548c\u77e5\u8bc6\u8868\u793a\u80fd\u591f\u5728RKHS\u4e0eHilbert\u2013Schmidt\u7684\u6846\u67b6\u5185\u7edf\u4e00\u5904\u7406\u3002", "conclusion": "\u8be5\u7b14\u8bb0\u5c06\u4f5c\u4e3a\u66f4\u9ad8\u7ea7\u4e3b\u9898\u7684\u57fa\u7840\u6027\u6559\u6750\uff0c\u9f13\u52b1\u4ee5\u51e0\u4f55-\u5206\u6790\u89c6\u89d2\u63a8\u8fdb\u6838\u65b9\u6cd5\u5728\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u4e0e\u7406\u8bba\u53d1\u5c55\u3002"}}
{"id": "2511.14488", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14488", "abs": "https://arxiv.org/abs/2511.14488", "authors": ["Jintao Zhang", "Mingyue Cheng", "Zirui Liu", "Xianquan Wang", "Yitong Zhou", "Qi Liu"], "title": "Towards Stable and Structured Time Series Generation with Perturbation-Aware Flow Matching", "comment": null, "summary": "Time series generation is critical for a wide range of applications, which greatly supports downstream analytical and decision-making tasks. However, the inherent temporal heterogeneous induced by localized perturbations present significant challenges for generating structurally consistent time series. While flow matching provides a promising paradigm by modeling temporal dynamics through trajectory-level supervision, it fails to adequately capture abrupt transitions in perturbed time series, as the use of globally shared parameters constrains the velocity field to a unified representation. To address these limitations, we introduce \\textbf{PAFM}, a \\textbf{P}erturbation-\\textbf{A}ware \\textbf{F}low \\textbf{M}atching framework that models perturbed trajectories to ensure stable and structurally consistent time series generation. The framework incorporates perturbation-guided training to simulate localized disturbances and leverages a dual-path velocity field to capture trajectory deviations under perturbation, enabling refined modeling of perturbed behavior to enhance the structural coherence. In order to further improve sensitivity to trajectory perturbations while enhancing expressiveness, a mixture-of-experts decoder with flow routing dynamically allocates modeling capacity in response to different trajectory dynamics. Extensive experiments on both unconditional and conditional generation tasks demonstrate that PAFM consistently outperforms strong baselines. Code is available at https://anonymous.4open.science/r/PAFM-03B2.", "AI": {"tldr": "PAFM \u63d0\u51fa Perturbation-Aware Flow Matching \u6846\u67b6\uff0c\u901a\u8fc7\u6270\u52a8\u5f15\u5bfc\u8bad\u7ec3\u3001\u53cc\u8def\u5f84\u901f\u5ea6\u573a\u4e0e\u6df7\u5408\u4e13\u5bb6\u89e3\u7801\u5b9e\u73b0\u5bf9\u6270\u52a8\u8f68\u8ff9\u7684\u5efa\u6a21\uff0c\u4ece\u800c\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u7684\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u4e14\u5728\u65e0\u6761\u4ef6\u4e0e\u6709\u6761\u4ef6\u751f\u6210\u4efb\u52a1\u4e2d\u8d85\u8d8a\u57fa\u7ebf\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u9700\u8981\u4fdd\u6301\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u4f46\u5c40\u90e8\u6270\u52a8\u5bfc\u81f4\u7684\u65f6\u95f4\u5f02\u8d28\u6027\u4f7f\u73b0\u6709\u7684\u6d41\u5339\u914d\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u77ac\u53d8\u4e0e\u975e\u5e73\u7a33\u6027\u3002", "method": "\u5f15\u5165\u6270\u52a8\u611f\u77e5\u7684\u6d41\u5339\u914d\u6846\u67b6\uff0c\u4f7f\u7528\u53cc\u8def\u5f84\u901f\u5ea6\u573a\u6355\u6349\u6270\u52a8\u4e0b\u7684\u8f68\u8ff9\u504f\u79bb\uff0c\u91c7\u7528\u6270\u52a8\u5f15\u5bfc\u8bad\u7ec3\u6765\u6a21\u62df\u5c40\u90e8\u6270\u52a8\uff0c\u5e76\u4f7f\u7528 mixture-of-experts \u89e3\u7801\u5668\u901a\u8fc7\u6d41\u8def\u7531\u52a8\u6001\u5206\u914d\u5efa\u6a21\u5bb9\u91cf\u4ee5\u9002\u5e94\u4e0d\u540c\u8f68\u8ff9\u52a8\u529b\u5b66\u3002", "result": "\u5728\u65e0\u6761\u4ef6\u548c\u6761\u4ef6\u751f\u6210\u4efb\u52a1\u4e0a\uff0cPAFM \u76f8\u5bf9\u4e8e\u5f3a\u57fa\u7ebf\u5177\u6709\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5b9e\u9a8c\u8868\u660e\u5bf9\u6270\u52a8\u7684\u654f\u611f\u6027\u4e0e\u8868\u8fbe\u80fd\u529b\u663e\u8457\u589e\u5f3a\u3002", "conclusion": "PAFM \u80fd\u6709\u6548\u5efa\u6a21\u6270\u52a8\u8f68\u8ff9\u3001\u63d0\u5347\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u5e76\u901a\u8fc7\u66f4\u5177\u8868\u8fbe\u529b\u7684\u89e3\u7801\u5668\u5b9e\u73b0\u5bf9\u6270\u52a8\u7684\u81ea\u9002\u5e94\u5efa\u6a21\uff1b\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2511.14510", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14510", "abs": "https://arxiv.org/abs/2511.14510", "authors": ["Jiawei Yi", "Ping Gong", "Youhui Bai", "Jiaqi Ruan", "Shengnan Wang", "Pengcheng Wang", "Haibo Wang", "Weiguang Wang", "Xia Zhu", "Feng Wu", "Cheng Li"], "title": "CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design", "comment": null, "summary": "The growth of million-token LLMs exposes the scalability limits of inference systems, where the KVCache dominates memory usage and data transfer overhead. Recent offloading systems migrate the KVCache to CPU memory and incorporate top-k attention to reduce the volume of data transferred from the CPU, while further applying system-level optimizations such as on-GPU caching and prefetching to lower transfer overhead. However, they overlook the CPU bottleneck in three aspects: (1) substantial overhead of fine-grained dynamic cache management performed on the CPU side, (2) significant transfer overhead from poor PCIe bandwidth utilization caused by heavy gathering operations at the CPU side, and (3) GPU runtime bubbles introduced by coarse-grained CPU-centric synchronization. To address these challenges, we propose CLO, a CPU-light KVCache offloading system via algorithm-system co-design. CLO features: (1) a coarse-grained head-wise approximate on-GPU caching strategy with negligible cache management cost, (2) seamless combination of data prefetching and on-GPU persistent caching for lower transfer overhead, (3) a zero-copy transfer engine to fully exploit PCIe bandwidth, and a GPU-centric synchronization method to eliminate GPU stalls. Evaluation on two widely-used LLMs demonstrates that CLO achieves comparable accuracy to state-of-the-art systems, while substantially minimizing CPU overhead, fully utilizing PCIe bandwidth, thus improving decoding throughput by 9.3%-66.6%. Our results highlight that algorithm-system co-design is essential for memory-constrained LLM inference on modern GPU platforms. We open source CLO at https://github.com/CommediaJW/CLO.", "AI": {"tldr": "CLO\u662f\u4e00\u79cdCPU\u8f7b\u91cf\u7ea7KVCache\u4e0b\u6c89\u6846\u67b6\uff0c\u901a\u8fc7\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u5b9e\u73b0\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u9ad8\u6548\u5185\u5b58\u4e0e\u4f20\u8f93\u7ba1\u7406\u3002\u4e0e\u73b0\u6709\u7cfb\u7edf\u76f8\u6bd4\uff0c\u5728\u4fdd\u6301\u76f8\u8fd1\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4eCPU\u5f00\u9500\uff0c\u5145\u5206\u5229\u7528PCIe\u5e26\u5bbd\uff0c\u89e3\u7801\u541e\u5410\u91cf\u63d0\u5347\u7ea69.3%~66.6%\u3002", "motivation": "\u968f\u7740\u767e\u4e07\u7ea7\u522btoken\u7684LLM\u589e\u957f\uff0cKVCache\u6210\u4e3a\u63a8\u7406\u4e2d\u7684\u5185\u5b58\u4e0e\u6570\u636e\u4f20\u8f93\u74f6\u9888\u3002\u73b0\u6709\u4e0b\u6c89\u7cfb\u7edf\u591a\u5173\u6ce8CPU\u7aef\u7f13\u5b58\u7ba1\u7406\u5f00\u9500\u3001CPU\u7aef\u805a\u96c6\u64cd\u4f5c\u5bfc\u81f4\u7684PCIe\u5e26\u5bbd\u4f4e\u6548\uff0c\u4ee5\u53caCPU\u4e3b\u5bfc\u7684\u540c\u6b65\u9020\u6210\u7684GPU\u7aef\u7a7a\u95f2\uff0c\u56e0\u6b64\u4ecd\u672a\u89e3\u51b3CPU\u74f6\u9888\u4e0e\u4f20\u8f93\u74f6\u9888\u7684\u7efc\u5408\u95ee\u9898\u3002", "method": "\u63d0\u51faCLO\uff1a1) \u7c97\u7c92\u5ea6\u7684\u9010\u5934(head-wise)\u8fd1\u4f3c\u7684GPU\u7aef\u7f13\u5b58\u7b56\u7565\uff0c\u7f13\u5b58\u7ba1\u7406\u5f00\u9500\u6781\u4f4e\uff1b2) \u6570\u636e\u9884\u53d6\u4e0eGPU\u7aef\u6301\u4e45\u7f13\u5b58\u7684\u65e0\u7f1d\u7ed3\u5408\uff0c\u964d\u4f4e\u4f20\u8f93\u5f00\u9500\uff1b3) \u96f6\u62f7\u8d1d\u4f20\u8f93\u5f15\u64ce\uff0c\u5145\u5206\u6316\u6398PCIe\u5e26\u5bbd\uff1b4) \u4ee5GPU\u4e3a\u4e2d\u5fc3\u7684\u540c\u6b65\u673a\u5236\uff0c\u6d88\u9664GPU\u7b49\u5f85\u3002", "result": "\u5728\u4e24\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684LLM\u4e0a\u8bc4\u4f30\uff0cCLO\u5728\u4fdd\u6301\u4e0e\u6700\u5148\u8fdb\u7cfb\u7edf\u76f8\u5f53\u7684\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4eCPU\u5f00\u9500\uff0c\u5145\u5206\u5229\u7528PCIe\u5e26\u5bbd\uff0c\u4f7f\u89e3\u7801\u541e\u5410\u91cf\u63d0\u5347\u57289.3%\u523066.6%\u4e4b\u95f4\u3002", "conclusion": "\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u5bf9\u4e8e\u73b0\u4ee3GPU\u5e73\u53f0\u4e0a\u5185\u5b58\u53d7\u9650\u7684LLM\u63a8\u7406\u81f3\u5173\u91cd\u8981\uff0cCLO\u5df2\u5f00\u6e90\u5b9e\u73b0\uff0c\u5c55\u793a\u4e86\u9762\u5411\u5927\u89c4\u6a21KVCache\u7684\u6709\u6548\u52a0\u901f\u601d\u8def\u3002"}}
{"id": "2511.14543", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14543", "abs": "https://arxiv.org/abs/2511.14543", "authors": ["Youran Zhou", "Mohamed Reda Bouadjenek", "Sunil Aryal"], "title": "MissHDD: Hybrid Deterministic Diffusion for Hetrogeneous Incomplete Data Imputation", "comment": null, "summary": "Incomplete data are common in real-world tabular applications, where numerical, categorical, and discrete attributes coexist within a single dataset. This heterogeneous structure presents significant challenges for existing diffusion-based imputation models, which typically assume a homogeneous feature space and rely on stochastic denoising trajectories. Such assumptions make it difficult to maintain conditional consistency, and they often lead to information collapse for categorical variables or instability when numerical variables require deterministic updates. These limitations indicate that a single diffusion process is insufficient for mixed-type tabular imputation.\n  We propose a hybrid deterministic diffusion framework that separates heterogeneous features into two complementary generative channels. A continuous DDIM-based channel provides efficient and stable deterministic denoising for numerical variables, while a discrete latent-path diffusion channel, inspired by loopholing-based discrete diffusion, models categorical and discrete features without leaving their valid sample manifolds. The two channels are trained under a unified conditional imputation objective, enabling coherent reconstruction of mixed-type incomplete data.\n  Extensive experiments on multiple real-world datasets show that the proposed framework achieves higher imputation accuracy, more stable sampling trajectories, and improved robustness across MCAR, MAR, and MNAR settings compared with existing diffusion-based and classical methods. These results demonstrate the importance of structure-aware diffusion processes for advancing deep learning approaches to incomplete tabular data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u786e\u5b9a\u6027\u6269\u6563\u6846\u67b6\u7528\u4e8e\u6df7\u5408\u7c7b\u578b\u8868\u683c\u7f3a\u5931\u503c\u586b\u5145\uff0c\u901a\u8fc7\u5c06\u8fde\u7eed\u6570\u503c\u7279\u5f81\u7528 DDIM \u4f5c\u4e3a\u786e\u5b9a\u6027\u53bb\u566a\u901a\u9053\u3001\u5c06\u79bb\u6563/\u7c7b\u522b\u7279\u5f81\u7528\u79bb\u6563\u6f5c\u5728\u8def\u5f84\u6269\u6563\u901a\u9053\u5206\u79bb\u5efa\u6a21\uff0c\u5e76\u5728\u7edf\u4e00\u6761\u4ef6\u586b\u5145\u76ee\u6807\u4e0b\u5171\u540c\u8bad\u7ec3\uff0c\u4ee5\u63d0\u5347\u7cbe\u5ea6\u3001\u7a33\u5b9a\u6027\u548c\u5bf9 MCAR/MAR/MNAR \u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u8868\u683c\u6570\u636e\u5e38\u540c\u65f6\u5305\u542b\u6570\u503c\u3001\u5206\u7c7b\u548c\u79bb\u6563\u5c5e\u6027\uff0c\u73b0\u6709\u6269\u6563\u6a21\u578b\u901a\u5e38\u5047\u8bbe\u540c\u8d28\u7279\u5f81\u7a7a\u95f4\u4e14\u4f9d\u8d56\u968f\u673a\u53bb\u566a\uff0c\u5bfc\u81f4\u6761\u4ef6\u4e00\u81f4\u6027\u5dee\u3001\u7c7b\u522b\u53d8\u91cf\u4fe1\u606f\u584c\u9677\u6216\u6570\u503c\u53d8\u91cf\u66f4\u65b0\u4e0d\u7a33\u5b9a\u3002\u5355\u4e00\u6269\u6563\u8fc7\u7a0b\u96be\u4ee5\u6709\u6548\u5904\u7406\u6df7\u5408\u7c7b\u578b\u7f3a\u5931\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u7ed3\u6784\u5316\u7684\u6269\u6563\u6846\u67b6\u6765\u63d0\u5347\u586b\u5145\u8d28\u91cf\u4e0e\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6df7\u5408\u786e\u5b9a\u6027\u6269 diffusion \u6846\u67b6\uff0c\u5c06\u5f02\u8d28\u7279\u5f81\u5206\u79bb\u4e3a\u4e24\u6761\u4e92\u8865\u7684\u751f\u6210\u901a\u9053\uff1a\u4e00\u6761\u57fa\u4e8e DDIM \u7684\u8fde\u7eed\u901a\u9053\u7528\u4e8e\u6570\u503c\u53d8\u91cf\u7684\u9ad8\u6548\u786e\u5b9a\u6027\u53bb\u566a\uff1b\u53e6\u4e00\u6761\u53d7 loopholing-based \u79bb\u6563\u6269\u6563\u542f\u53d1\u7684\u79bb\u6563\u6f5c\u5728\u8def\u5f84\u6269\u6563\u901a\u9053\u7528\u4e8e\u7c7b\u522b/\u79bb\u6563\u7279\u5f81\uff0c\u786e\u4fdd\u7559\u5728\u6709\u6548\u6837\u672c\u6d41\u5f62\u3002\u4e24\u6761\u901a\u9053\u5728\u7edf\u4e00\u7684\u6761\u4ef6\u586b\u5145\u76ee\u6807\u4e0b\u5171\u540c\u8bad\u7ec3\u3002", "result": "\u5728\u591a\u7ec4\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u6240\u63d0\u6846\u67b6\u5728\u586b\u5145\u7cbe\u5ea6\u3001\u91c7\u6837\u8f68\u8ff9\u7a33\u5b9a\u6027\u4ee5\u53ca\u5bf9 MCAR\u3001MAR\u3001MNAR \u7684\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6269\u6563\u53ca\u7ecf\u5178\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u6784\u611f\u77e5\u7684\u6269\u6563\u8fc7\u7a0b\u5bf9\u6df7\u5408\u7c7b\u578b\u7f3a\u5931\u8868\u683c\u6570\u636e\u7684\u6df1\u5ea6\u5b66\u4e60\u586b\u5145\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u6df7\u5408\u901a\u9053\u8bbe\u8ba1\u80fd\u63d0\u5347\u586b\u5145\u8d28\u91cf\u4e0e\u7a33\u5b9a\u6027\u3002"}}
{"id": "2511.14544", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14544", "abs": "https://arxiv.org/abs/2511.14544", "authors": ["Jaume Ros", "Alessio Arleo", "Fernando Paulovich"], "title": "Mind the Gaps: Measuring Visual Artifacts in Dimensionality Reduction", "comment": null, "summary": "Dimensionality Reduction (DR) techniques are commonly used for the visual exploration and analysis of high-dimensional data due to their ability to project datasets of high-dimensional points onto the 2D plane. However, projecting datasets in lower dimensions often entails some distortion, which is not necessarily easy to recognize but can lead users to misleading conclusions. Several Projection Quality Metrics (PQMs) have been developed as tools to quantify the goodness-of-fit of a DR projection; however, they mostly focus on measuring how well the projection captures the global or local structure of the data, without taking into account the visual distortion of the resulting plots, thus often ignoring the presence of outliers or artifacts that can mislead a visual analysis of the projection. In this work, we introduce the Warping Index (WI), a new metric for measuring the quality of DR projections onto the 2D plane, based on the assumption that the correct preservation of empty regions between points is of crucial importance towards a faithful visual representation of the data.", "AI": {"tldr": "\u63d0\u51fa Warping Index\uff08WI\uff09\u4f5c\u4e3a\u65b0\u7684\u4e8c\u7ef4\u964d\u7ef4\u6295\u5f71\u8d28\u91cf\u5ea6\u91cf\uff0c\u805a\u7126\u4e8e\u4fdd\u6301\u70b9\u4e4b\u95f4\u7684\u7a7a\u767d\u533a\u57df\u4ee5\u63d0\u5347\u6295\u5f71\u7684\u89c6\u89c9\u4fdd\u771f\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u6295\u5f71\u8d28\u91cf\u5ea6\u91cf\uff08PQMs\uff09\u591a\u5173\u6ce8\u5168\u5c40\u6216\u5c40\u90e8\u7ed3\u6784\u7684\u4fdd\u7559\uff0c\u800c\u5ffd\u7565\u6295\u5f71\u56fe\u4e2d\u7684\u89c6\u89c9\u5931\u771f\u3001\u5f02\u5e38\u70b9\u6216\u4f2a\u5f71\uff0c\u53ef\u80fd\u5bfc\u81f4\u8bef\u5bfc\u6027\u7684\u5206\u6790\u7ed3\u8bba\u3002\u9700\u8981\u4e00\u4e2a\u4e0e\u4eba\u7c7b\u89c6\u89c9\u611f\u77e5\u66f4\u4e00\u81f4\u7684\u5ea6\u91cf\uff0c\u5c24\u5176\u5173\u6ce8\u70b9\u4e4b\u95f4\u7684\u7a7a\u767d\u533a\u57df\u5728\u6295\u5f71\u4e2d\u7684\u4fdd\u6301\u3002", "method": "\u5728\u4e8c\u7ef4\u6295\u5f71\u4e2d\u57fa\u4e8e\u201c\u6b63\u786e\u4fdd\u7559\u7a7a\u767d\u533a\u57df\u201d\u7684\u5047\u8bbe\u6784\u5efa\u5ea6\u91cf\u6846\u67b6 WI\uff0c\u7528\u4ee5\u91cf\u5316\u6295\u5f71\u5bf9\u7a7a\u767d\u533a\u57df\u7684\u4fdd\u7559\u7a0b\u5ea6\uff0c\u4ece\u800c\u8bc4\u4f30\u6295\u5f71\u7684\u626d\u66f2\u3002\u6458\u8981\u672a\u7ed9\u51fa\u5177\u4f53\u7684\u8ba1\u7b97\u7ec6\u8282\u6216\u7b97\u6cd5\u5b9e\u73b0\uff0c\u56e0\u6b64\u8fd9\u91cc\u4ee5\u6982\u5ff5\u5c42\u9762\u7684\u63cf\u8ff0\u5448\u73b0\u3002", "result": "\u6458\u8981\u672a\u7ed9\u51fa\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\u3001\u5bf9\u6bd4\u6216\u5b9a\u91cf\u8bc4\u4f30\uff0c\u660e\u786e\u63d0\u51fa\u4e86 WI \u7684\u6982\u5ff5\u4e0e\u76ee\u6807\u3002", "conclusion": "WI \u4f5c\u4e3a\u5bf9\u4e8c\u7ef4\u964d\u7ef4\u6295\u5f71\u53ef\u89c6\u5316\u8d28\u91cf\u7684\u8865\u5145\u6027\u5ea6\u91cf\uff0c\u65e8\u5728\u901a\u8fc7\u5173\u6ce8\u7a7a\u767d\u533a\u57df\u7684\u4fdd\u7559\u6765\u6539\u5584\u5bf9\u6295\u5f71\u5931\u771f\u7684\u68c0\u6d4b\uff0c\u5e2e\u52a9\u907f\u514d\u56e0\u89c6\u89c9\u4f2a\u5f71\u800c\u5bfc\u81f4\u7684\u8bef\u5bfc\u6027\u5206\u6790\u3002"}}
{"id": "2511.14569", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14569", "abs": "https://arxiv.org/abs/2511.14569", "authors": ["Adam Hazimeh", "Alessandro Favero", "Pascal Frossard"], "title": "Task Addition and Weight Disentanglement in Closed-Vocabulary Models", "comment": null, "summary": "Task arithmetic has recently emerged as a promising method for editing pre-trained \\textit{open-vocabulary} models, offering a cost-effective alternative to standard multi-task fine-tuning. However, despite the abundance of \\textit{closed-vocabulary} models that are not pre-trained with language supervision, applying task arithmetic to these models remains unexplored. In this paper, we deploy and study task addition in closed-vocabulary image classification models. We consider different pre-training schemes and find that \\textit{weight disentanglement} -- the property enabling task arithmetic -- is a general consequence of pre-training, as it appears in different pre-trained closed-vocabulary models. In fact, we find that pre-trained closed-vocabulary vision transformers can also be edited with task arithmetic, achieving high task addition performance and enabling the efficient deployment of multi-task models. Finally, we demonstrate that simple linear probing is a competitive baseline to task addition. Overall, our findings expand the applicability of task arithmetic to a broader class of pre-trained models and open the way for more efficient use of pre-trained models in diverse settings.", "AI": {"tldr": "\u5728\u95ed\u8bcd\u6c47\u89c6\u89c9\u6a21\u578b\u4e2d\u5e94\u7528\u4efb\u52a1\u76f8\u52a0\uff0c\u63ed\u793a\u6743\u91cd\u89e3\u8026\u4e3a\u666e\u904d\u73b0\u8c61\uff0c\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u7684\u591a\u4efb\u52a1\u7f16\u8f91\u4e0e\u90e8\u7f72\uff1b\u7ebf\u6027\u63a2\u6d4b\u540c\u6837\u5177\u7ade\u4e89\u529b\u3002", "motivation": "\u5728\u5f00\u653e\u8bcd\u6c47\u6a21\u578b\u4e2d\uff0c\u4efb\u52a1\u7b97\u672f\u88ab\u7528\u6765\u9ad8\u6548\u5730\u7f16\u8f91\u6a21\u578b\uff1b\u4f46\u5bf9\u672a\u4f7f\u7528\u8bed\u8a00\u76d1\u7763\u3001\u95ed\u8bcd\u6c47\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u9002\u7528\u6027\u5c1a\u672a\u7814\u7a76\u3002", "method": "\u7cfb\u7edf\u5730\u5728\u95ed\u8bcd\u6c47\u89c6\u89c9\u53d8\u6362\u5668\u4e0a\u6d4b\u8bd5\u4efb\u52a1\u76f8\u52a0\uff0c\u6bd4\u8f83\u4e0d\u540c\u9884\u8bad\u7ec3\u65b9\u6848\uff0c\u5206\u6790\u6743\u91cd\u89e3\u8026\u7684\u51fa\u73b0\uff0c\u5e76\u4e0e\u7ebf\u6027\u63a2\u6d4b\u57fa\u7ebf\u6bd4\u8f83\u3002", "result": "\u9884\u8bad\u7ec3\u5bfc\u81f4\u7684\u6743\u91cd\u89e3\u8026\u662f\u4e00\u79cd\u901a\u7528\u73b0\u8c61\uff1b\u95ed\u8bcd\u6c47\u89c6\u89c9\u53d8\u6362\u5668\u4e5f\u53ef\u4ee5\u901a\u8fc7\u4efb\u52a1\u76f8\u52a0\u8fdb\u884c\u6709\u6548\u7f16\u8f91\uff0c\u83b7\u5f97\u8f83\u9ad8\u7684\u4efb\u52a1\u6dfb\u52a0\u6027\u80fd\uff1b\u7ebf\u6027\u63a2\u6d4b\u5728\u6b64\u4efb\u52a1\u4e2d\u4e5f\u5177\u7ade\u4e89\u529b\u3002", "conclusion": "\u6269\u5927\u4efb\u52a1\u7b97\u672f\u7684\u9002\u7528\u8303\u56f4\uff0c\u4fc3\u8fdb\u591a\u4efb\u52a1\u9ad8\u6548\u90e8\u7f72\uff0c\u5e76\u5f3a\u8c03\u7ebf\u6027\u63a2\u6d4b\u662f\u4e00\u4e2a\u5f3a\u6709\u529b\u7684\u57fa\u7ebf\u3002"}}
{"id": "2511.14584", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14584", "abs": "https://arxiv.org/abs/2511.14584", "authors": ["Ankush Kadu", "Ashwanth Krishnan"], "title": "ReflexGrad: Three-Way Synergistic Architecture for Zero-Shot Generalization in LLM Agents", "comment": null, "summary": "Enabling agents to learn from experience and generalize across diverse tasks without task-specific training remains a fundamental challenge in reinforcement learning and decision-making. While recent approaches have explored episodic memory (Reflexion), gradient-based prompt optimization (TextGrad),and hierarchical task decomposition independently, their potential for synergistic integration remains unexplored. We introduce ReflexGrad, a novel architecture that tightly couples three complementary mechanisms: (1) LLM-based hierarchical TODO decomposition for strategic planning, (2) history-aware causal reflection that analyzes recent action patterns to identify failure root causes and enable within-trial learning, and (3) gradient-based optimization for systematic improvement. Unlike prior work relying on few-shot demonstrations, our system achieves true zero-shot generalization through pure LLM semantic reasoning,requiring no task-specific examples, fine-tuning, or hardcoded similarity metrics. Evaluated on ALFWorld benchmark tasks, ReflexGrad demonstrates 67% zero-shot success rate on Trial 0 without any prior task experience or demonstrations, establishing effective performance on first exposure. Through empirical analysis, we identify the architectural mechanisms underlying stable convergence (zero action loops) and effective cross-task transfer (67% to 78% improvement).Our work demonstrates that synergistic integration of complementary learning mechanisms enables robust zero-shot generalization that approaches few-shot baselines from prior work.", "AI": {"tldr": "\u63d0\u51fa ReflexGrad\uff0c\u5c06LLM\u7684\u5206\u5c42\u4efb\u52a1\u5206\u89e3\u3001\u5386\u53f2\u53cd\u601d\u7684\u56e0\u679c\u5206\u6790\u4e0e\u68af\u5ea6\u4f18\u5316\u4e09\u79cd\u673a\u5236\u8026\u5408\uff0c\u5b9e\u73b0\u96f6\u6837\u672c\u6cdb\u5316\u5e76\u5728 ALFWorld \u4e0a\u5c55\u73b0\u5f3a\u521d\u6b21\u66b4\u9732\u8868\u73b0\u548c\u8de8\u4efb\u52a1\u8f6c\u79fb\u3002", "motivation": "\u5728\u5f3a\u5316\u5b66\u4e60\u4e0e\u51b3\u7b56\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4ece\u7ecf\u9a8c\u5b66\u4e60\u5e76\u8de8\u4efb\u52a1\u6cdb\u5316\u4ecd\u662f\u6838\u5fc3\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u72ec\u7acb\u4f7f\u7528\u8bb0\u5fc6\u3001\u63d0\u793a\u4f18\u5316\u6216\u5c42\u6b21\u5316\u4efb\u52a1\u5206\u89e3\uff0c\u7f3a\u4e4f\u7efc\u5408\u534f\u540c\u6548\u5e94\u4e0e\u96f6\u6837\u672c\u901a\u7528\u6027\u3002", "method": "\u4e09\u5927\u673a\u5236\u8026\u5408\uff1a1) \u57fa\u4e8eLLM\u7684\u5206\u5c42TODO\u5206\u89e3\u7528\u4e8e\u7b56\u7565\u6027\u89c4\u5212\uff1b2) \u9762\u5411\u5386\u53f2\u7684\u56e0\u679c\u53cd\u601d\uff0c\u5206\u6790\u8fd1\u671f\u884c\u52a8\u6a21\u5f0f\u4ee5\u53d1\u73b0\u5931\u8d25\u6839\u56e0\u5e76\u5b9e\u73b0\u540c\u573a\u5b66\u4e60\uff1b3) \u68af\u5ea6\u4f18\u5316\u4ee5\u7cfb\u7edf\u6027\u6539\u8fdb\u3002\u4e0e\u4ee5\u5f80\u4ec5\u4f9d\u8d56\u5c11\u91cf\u793a\u4f8b\u4e0d\u540c\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u7eafLLM\u8bed\u4e49\u63a8\u7406\u5b9e\u73b0\u771f\u6b63\u96f6\u6837\u672c\u6cdb\u5316\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u793a\u4f8b\u3001\u5fae\u8c03\u6216\u786c\u7f16\u7801\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u3002", "result": "\u5728 ALFWorld \u57fa\u51c6\u4efb\u52a1\u4e0a\uff0cReflexGrad \u5728 Trial 0 \u7684\u96f6\u6837\u672c\u6210\u529f\u7387\u8fbe\u5230 67%\uff0c\u9996\u6b21\u66b4\u9732\u5c31\u8868\u73b0\u51fa\u6709\u6548\u80fd\u529b\u3002\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5bfc\u81f4\u7a33\u5b9a\u6536\u655b\uff08\u96f6\u52a8\u4f5c\u5faa\u73af\uff09\u548c\u6709\u6548\u8de8\u4efb\u52a1\u8f6c\u79fb\uff08\u63d0\u5347 67% \u5230 78%\uff09\u7684\u67b6\u6784\u673a\u5236\u3002", "conclusion": "\u8bc1\u660e\u4e09\u79cd\u4e92\u8865\u5b66\u4e60\u673a\u5236\u7684\u534f\u540c\u96c6\u6210\u53ef\u5b9e\u73b0\u9c81\u68d2\u7684\u96f6\u6837\u672c\u6cdb\u5316\uff0c\u5176\u6027\u80fd\u63a5\u8fd1\u5148\u524d\u5de5\u4f5c\u4e2d\u7684\u5c11\u6837\u672c\u57fa\u7ebf\u3002"}}
{"id": "2511.14619", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14619", "abs": "https://arxiv.org/abs/2511.14619", "authors": ["Marco Locatelli", "Arjen Hommersom", "Roberto Clemens Cerioli", "Daniela Besozzi", "Fabio Stella"], "title": "Expert-Guided POMDP Learning for Data-Efficient Modeling in Healthcare", "comment": null, "summary": "Learning the parameters of Partially Observable Markov Decision Processes (POMDPs) from limited data is a significant challenge. We introduce the Fuzzy MAP EM algorithm, a novel approach that incorporates expert knowledge into the parameter estimation process by enriching the Expectation Maximization (EM) framework with fuzzy pseudo-counts derived from an expert-defined fuzzy model. This integration naturally reformulates the problem as a Maximum A Posteriori (MAP) estimation, effectively guiding learning in environments with limited data. In synthetic medical simulations, our method consistently outperforms the standard EM algorithm under both low-data and high-noise conditions. Furthermore, a case study on Myasthenia Gravis illustrates the ability of the Fuzzy MAP EM algorithm to recover a clinically coherent POMDP, demonstrating its potential as a practical tool for data-efficient modeling in healthcare.", "AI": {"tldr": "\u4f7f\u7528\u4e13\u5bb6\u77e5\u8bc6\u7684\u6a21\u7cca\u4f2a\u8ba1\u6570\u6765\u5f15\u5bfcPOMDP\u53c2\u6570\u4f30\u8ba1\uff0c\u63d0\u51faFuzzy MAP EM\uff0c\u5728\u6570\u636e\u4e0d\u8db3\u65f6\u5bf9\u53c2\u6570\u5b66\u4e60\u66f4\u7a33\u5065\uff0c\u4e14\u5728\u533b\u7597\u573a\u666f\u4e2d\u5b9e\u73b0\u6570\u636e\u9ad8\u6548\u5efa\u6a21\u5e76\u4ea7\u751f\u4e34\u5e8a\u4e00\u81f4\u7684POMDP\u3002", "motivation": "\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u4ecePOMDP\u53c2\u6570\u4e2d\u5b66\u4e60\u662f\u4e00\u9879\u6311\u6218\uff1b\u901a\u8fc7\u5c06\u5148\u9a8c\u77e5\u8bc6\u4ee5\u6a21\u7cca\u4fe1\u606f\u878d\u5165EM\u6846\u67b6\uff0c\u8f6c\u5316\u4e3aMAP\u4f30\u8ba1\uff0c\u4ee5\u5728\u6570\u636e\u7a00\u7f3a\u548c\u566a\u58f0\u8f83\u5927\u65f6\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u53c2\u6570\u4f30\u8ba1\u3002", "method": "\u5c06\u57fa\u4e8e\u4e13\u5bb6\u5b9a\u4e49\u7684\u6a21\u7cca\u6a21\u578b\u4ea7\u751f\u7684\u6a21\u7cca\u4f2a\u8ba1\u6570\u5f15\u5165\u5230EM\u6846\u67b6\uff0c\u5f62\u6210Fuzzy MAP EM\u7b97\u6cd5\uff0c\u4f7f\u5b66\u4e60\u8fc7\u7a0b\u81ea\u7136\u5730\u6210\u4e3aMAP\u4f18\u5316\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u6b63\u5219\u5316\uff0c\u5f15\u5bfc\u5728\u6709\u9650\u6570\u636e\u4e0b\u7684\u5b66\u4e60\u3002", "result": "\u5728\u5408\u6210\u533b\u5b66\u4eff\u771f\u4e2d\uff0cFuzzy MAP EM\u5728\u6570\u636e\u91cf\u8f83\u5c11\u548c\u566a\u58f0\u8f83\u9ad8\u7684\u6761\u4ef6\u4e0b\uff0c\u7a33\u5b9a\u5730\u4f18\u4e8e\u6807\u51c6EM\u7b97\u6cd5\uff1b\u5728Myasthenia Gravis\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u80fd\u591f\u6062\u590d\u51fa\u4e00\u4e2a\u4e34\u5e8a\u4e00\u81f4\u7684POMDP\uff0c\u663e\u793a\u5176\u4f5c\u4e3a\u533b\u7597\u9886\u57df\u6570\u636e\u9ad8\u6548\u5efa\u6a21\u7684\u6f5c\u5728\u5b9e\u7528\u6027\u3002", "conclusion": "Fuzzy MAP EM\u4e3a\u6570\u636e\u7a00\u7f3a\u73af\u5883\u4e0b\u7684POMDP\u53c2\u6570\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u878d\u5165\u4e13\u5bb6\u77e5\u8bc6\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u5177\u6709\u5728\u533b\u7597\u7b49\u9886\u57df\u5b9e\u73b0\u6570\u636e\u9ad8\u6548\u5efa\u6a21\u7684\u6f5c\u5728\u5e94\u7528\u4e0e\u4ef7\u503c\u3002"}}
{"id": "2511.14630", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14630", "abs": "https://arxiv.org/abs/2511.14630", "authors": ["Ivy Yuqian Yang", "David Yu Zhang"], "title": "Failure to Mix: Large language models struggle to answer according to desired probability distributions", "comment": "13 pages, 6 figures. Code and reproducibility package: https://github.com/BiostateAIresearch/failure-to-mix", "summary": "Scientific idea generation and selection requires exploration following a target probability distribution. In contrast, current AI benchmarks have objectively correct answers, and training large language models (LLMs) via reinforcement learning against these benchmarks discourages probabilistic exploration. Here, we conducted systematic experiments requesting LLMs to produce outputs following simple probabilistic distributions, and found that all modern LLMs tested grossly fail to follow the distributions. For example, requesting a binary output of \"1\" 49% of the time produces an answer of \"0\" nearly 100% of the time. This step function-like behavior of near-exclusively generating the output with marginally highest probability even overrules even strong in-built LLM biases.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.14632", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14632", "abs": "https://arxiv.org/abs/2511.14632", "authors": ["Yuchen Luo", "Xinyu Li", "Liuhua Peng", "Mingming Gong"], "title": "Adapformer: Adaptive Channel Management for Multivariate Time Series Forecasting", "comment": null, "summary": "In multivariate time series forecasting (MTSF), accurately modeling the intricate dependencies among multiple variables remains a significant challenge due to the inherent limitations of traditional approaches. Most existing models adopt either \\textbf{channel-independent} (CI) or \\textbf{channel-dependent} (CD) strategies, each presenting distinct drawbacks. CI methods fail to leverage the potential insights from inter-channel interactions, resulting in models that may not fully exploit the underlying statistical dependencies present in the data. Conversely, CD approaches often incorporate too much extraneous information, risking model overfitting and predictive inefficiency. To address these issues, we introduce the Adaptive Forecasting Transformer (\\textbf{Adapformer}), an advanced Transformer-based framework that merges the benefits of CI and CD methodologies through effective channel management. The core of Adapformer lies in its dual-stage encoder-decoder architecture, which includes the \\textbf{A}daptive \\textbf{C}hannel \\textbf{E}nhancer (\\textbf{ACE}) for enriching embedding processes and the \\textbf{A}daptive \\textbf{C}hannel \\textbf{F}orecaster (\\textbf{ACF}) for refining the predictions. ACE enhances token representations by selectively incorporating essential dependencies, while ACF streamlines the decoding process by focusing on the most relevant covariates, substantially reducing noise and redundancy. Our rigorous testing on diverse datasets shows that Adapformer achieves superior performance over existing models, enhancing both predictive accuracy and computational efficiency, thus making it state-of-the-art in MTSF.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
