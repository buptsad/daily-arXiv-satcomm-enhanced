{"id": "2511.20671", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.20671", "abs": "https://arxiv.org/abs/2511.20671", "authors": ["Zhaoxin Chang", "Shuguang Xiao", "Fusang Zhang", "Xujun Ma", "Badii Jouaber", "Qingfeng Zhang", "Daqing Zhang"], "title": "WiRainbow: Single-Antenna Direction-Aware Wi-Fi Sensing via Dispersion Effect", "comment": null, "summary": "Recently, Wi-Fi signals have emerged as a powerful tool for contactless sensing. During the sensing process, obtaining target direction information can provide valuable contextual insights for various applications. Existing direction estimation methods typically rely on antenna arrays, which are costly and complex to deploy in real-world scenarios. In this paper, we present WiRainbow, a novel approach that enables single-antenna-based direction awareness for Wi-Fi sensing by leveraging the dispersion effect of frequency-scanning antennas (FSAs), which can naturally steer Wi-Fi subcarriers toward distinct angles during signal transmission. To address key challenges in antenna design and signal processing, we propose a coupled-resonator-based antenna architecture that significantly expands the narrow Field-of-View inherent in conventional FSAs, improving sensing coverage. Additionally, we develop a sensing signal-to-noise-ratio-based signal processing framework that reliably estimates target direction in multipath-rich environments. We prototype WiRainbow and evaluate its performance through benchmark experiments and real-world case studies, demonstrating its ability to achieve accurate, robust, and cost-effective direction awareness for diverse Wi-Fi sensing applications.", "AI": {"tldr": "WiRainbow\u901a\u8fc7\u5355\u5929\u7ebfWi-Fi\u611f\u77e5\u5b9e\u73b0\u65b9\u5411\u611f\u77e5\uff0c\u5229\u7528\u9891\u7387\u626b\u63cf\u5929\u7ebf\u7684\u8272\u6563\u6548\u5e94\u53ca\u8026\u5408\u8c10\u632f\u7ed3\u6784\u6269\u5c55\u89c6\u573a\uff0c\u5e76\u8f85\u4ee5\u57fa\u4e8e\u4fe1\u566a\u6bd4\u7684\u4fe1\u53f7\u5904\u7406\uff0c\u5728\u591a\u5f84\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u3001\u9c81\u68d2\u4e14\u6210\u672c\u4f4e\u7684\u5b9a\u5411\u4f30\u8ba1\u3002", "motivation": "\u73b0\u6709\u5b9a\u5411\u611f\u77e5\u591a\u4f9d\u8d56\u5929\u7ebf\u9635\u5217\uff0c\u6210\u672c\u9ad8\u3001\u90e8\u7f72\u590d\u6742\u3002\u9700\u8981\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u6613\u90e8\u7f72\u7684\u5355\u5929\u7ebf\u65b9\u6848\u6765\u5b9e\u73b0Wi-Fi sensing\u4e2d\u7684\u76ee\u6807\u65b9\u5411\u4fe1\u606f\u3002", "method": "\u5229\u7528\u9891\u7387\u626b\u63cf\u5929\u7ebf\u7684\u8272\u6563\u6548\u5e94\u5c06Wi-Fi\u5b50\u8f7d\u6ce2\u5b9a\u5411\u5230\u4e0d\u540c\u89d2\u5ea6\uff1b\u63d0\u51fa\u8026\u5408\u8c10\u632f\u5668\u5929\u7ebf\u7ed3\u6784\u4ee5\u6269\u5c55FSAs\u7684\u7a84\u89c6\u573a\uff1b\u5f00\u53d1\u57fa\u4e8e sensing SNR \u7684\u4fe1\u53f7\u5904\u7406\u6846\u67b6\uff0c\u5728\u591a\u5f84\u73af\u5883\u4e2d\u53ef\u9760\u4f30\u8ba1\u76ee\u6807\u65b9\u5411\u3002", "result": "\u539f\u578b\u7cfb\u7edfWiRainbow\u5df2\u5b9e\u73b0\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u5b9e\u9a8c\u4e0e\u771f\u5b9e\u573a\u666f\u6848\u4f8b\u9a8c\u8bc1\uff0c\u663e\u793a\u5728\u6210\u672c\u6548\u76ca\u4e0e\u9c81\u68d2\u6027\u65b9\u9762\u5177\u6709\u826f\u597d\u8868\u73b0\uff0c\u80fd\u591f\u5b9e\u73b0\u51c6\u786e\u7684\u65b9\u5411\u611f\u77e5\u3002", "conclusion": "\u63d0\u4f9b\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u5355\u5929\u7ebf\u5b9a\u5411\u611f\u77e5\u65b9\u6848\uff0c\u964d\u4f4e\u90e8\u7f72\u6210\u672c\u3001\u7b80\u5316\u7cfb\u7edf\u590d\u6742\u5ea6\uff0c\u5e76\u6269\u5927Wi-Fi\u611f\u77e5\u7684\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2511.20696", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20696", "abs": "https://arxiv.org/abs/2511.20696", "authors": ["Dan Li", "Hye-Bin Shin", "Yeon-Woo Choi"], "title": "Prototype-Guided Non-Exemplar Continual Learning for Cross-subject EEG Decoding", "comment": "4 pages, 2 figures, 14th IEEE International Winter Conference on Brain-Computer Interface Conference 2026", "summary": "Due to the significant variability in electroencephalogram (EEG) signals across individuals, knowledge acquired from previous subjects is often overwritten as new subjects are introduced in continual EEG decoding task. Current works mainly rely on storing the historical data of seen subjects as a replay buffer to prevent forgetting. However, privacy concerns or memory constraints make keeping such data impractical. Instead, we propose a Prototype-guided Non-Exemplar Continual Learning (ProNECL)framework that preserves prior knowledge without accessing any historical EEG samples. ProNECL constructs class-level prototypes to summarize discriminative representations from each subject and incrementally aligns new feature spaces with the global prototype memory through cross-subject feature alignment and knowledge distillation. Validated on the BCI Competition IV 2a and 2b datasets, our framework effectively balances knowledge retention and adaptability, achieving superior performance in cross-subject continual EEG decoding tasks.", "AI": {"tldr": "ProNECL\u63d0\u51fa\u4e00\u79cd\u539f\u578b\u5f15\u5bfc\u7684\u975e\u6837\u672c\u578b\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u8de8\u53d7\u8bd5\u8005\u7684\u6301\u7eed\u8111\u7535\u89e3\u7801\uff0c\u907f\u514d\u56de\u653e\u5386\u53f2\u6570\u636e\uff0c\u901a\u8fc7\u6784\u5efa\u7c7b\u522b\u539f\u578b\u5e76\u4e0e\u5168\u5c40\u539f\u578b\u8bb0\u5fc6\u5bf9\u9f50\u5b9e\u73b0\u77e5\u8bc6\u8fc1\u79fb\uff0c\u5b9e\u73b0\u5728BCI 2a/2b\u6570\u636e\u96c6\u4e0a\u7684\u4f18\u8d8a\u7ee9\u6548\u3002", "motivation": "EEG\u4fe1\u53f7\u5728\u4e2a\u4f53\u95f4\u5b58\u5728\u663e\u8457\u53d8\u5f02\uff0c\u968f\u7740\u65b0\u53d7\u8bd5\u8005\u52a0\u5165\uff0c\u5148\u524d\u77e5\u8bc6\u6613\u88ab\u8986\u76d6\uff1b\u4f20\u7edf\u56de\u653e\u7f13\u51b2\u533a\u5728\u9690\u79c1\u4e0e\u5185\u5b58\u65b9\u9762\u5b58\u5728\u9650\u5236\uff0c\u9700\u5f00\u53d1\u4e0d\u8bbf\u95ee\u5386\u53f2\u6837\u672c\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u7c7b\u522b\u7ea7\u539f\u578b\u4ee5\u6982\u62ec\u5404\u53d7\u8bd5\u8005\u7684\u5224\u522b\u8868\u793a\uff1b\u901a\u8fc7\u8de8\u53d7\u8bd5\u8005\u7279\u5f81\u5bf9\u9f50\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u5c06\u65b0\u7279\u5f81\u7a7a\u95f4\u6e10\u8fdb\u5730\u4e0e\u5168\u5c40\u539f\u578b\u8bb0\u5fc6\u5bf9\u9f50\uff1b\u4e0d\u8bbf\u95ee\u5386\u53f2EEG\u6837\u672c\uff0c\u539f\u578b\u8bb0\u5fc6\u7528\u4e8e\u7ef4\u6301\u5148\u9a8c\u77e5\u8bc6\uff1b\u5728\u6bcf\u4e2a\u65b0\u53d7\u8bd5\u8005\u52a0\u5165\u65f6\u589e\u91cf\u66f4\u65b0\u539f\u578b\u4e0e\u5bf9\u9f50\u7b56\u7565\u3002", "result": "\u5728BCI Competition IV 2a/2b\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u5728\u77e5\u8bc6\u4fdd\u7559\u4e0e\u9002\u5e94\u6027\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u5e76\u5728\u8de8\u53d7\u8bd5\u8005\u6301\u7eedEEG\u89e3\u7801\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5bf9\u6bd4\u57fa\u7ebf\u3002", "conclusion": "ProNECL\u65e0\u9700\u5386\u53f2\u6837\u672c\u5373\u53ef\u6709\u6548\u4fdd\u7559\u5148\u524d\u77e5\u8bc6\uff0c\u4e14\u901a\u8fc7\u539f\u578b\u5f15\u5bfc\u7684\u975e\u6837\u672c\u6301\u7eed\u5b66\u4e60\u63d0\u5347\u4e86\u8de8\u53d7\u8bd5\u8005\u7684EEG\u89e3\u7801\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u539f\u578b\u8bb0\u5fc6 + \u8de8\u53d7\u8bd5\u8005\u5bf9\u9f50\u5728\u9690\u79c1\u53cb\u597d\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.21277", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.21277", "abs": "https://arxiv.org/abs/2511.21277", "authors": ["Arman Maghsoudnia", "Aoyu Gong", "Raphael Cannat\u00e0", "Dan Mihai Dumitriu", "Haitham Hassanieh"], "title": "LatencyScope: A System-Level Mathematical Framework for 5G RAN Latency", "comment": "23 pages, 18 figures", "summary": "This paper presents LatencyScope, a mathematical framework for accurately computing one-way latency (for uplink and downlink) in the 5G RAN across diverse system configurations. LatencyScope models latency sources at every layer of the Radio Access Network (RAN), pinpointing system-level bottlenecks--such as radio interfaces, scheduling policies, and hardware/software constraints--while capturing their intricate dependencies and their stochastic nature. LatencyScope also includes a configuration optimizer that uses its mathematical models to search through hundreds of billions of configurations and find settings that meet latency-reliability targets under user constraints. We validate LatencyScope on two open-sourced 5G RAN testbeds (srsRAN and OAI), demonstrating that it can closely match empirical latency distributions and significantly outperform prior analytical models and widely used simulators (MATLAB 5G Toolbox, 5G-LENA). It can also find system configurations that meet Ultra-Reliable Low-Latency Communications (URLLC) targets and enable network operators to efficiently identify the best setup for their systems.", "AI": {"tldr": "LatencyScope\u63d0\u51fa\u4e00\u4e2a\u5bf95G RAN\u5355\u5411\u65f6\u5ef6\u7684\u5b8c\u6574\u6570\u5b66\u6846\u67b6\uff0c\u7ed3\u5408\u5c42\u7ea7\u5efa\u6a21\u548c\u5168\u5c40\u914d\u7f6e\u4f18\u5316\uff0c\u5728\u591a\u4e2a\u5f00\u6e90RAN\u6d4b\u8bd5\u5e8a\u4e0a\u9a8c\u8bc1\uff0c\u80fd\u8d34\u8fd1\u5b9e\u6d4b\u5206\u5e03\u5e76\u8d85\u8d8a\u73b0\u6709\u5206\u6790\u6a21\u578b\u4e0e\u4eff\u771f\u5de5\u5177\uff0c\u4e14\u53ef\u7528\u4e8eURRLC\u76ee\u6807\u7684\u914d\u7f6e\u641c\u7d22\u3002", "motivation": "\u5728\u590d\u6742\u591a\u53d8\u76845G RAN\u914d\u7f6e\u4e2d\uff0c\u5355\u5411\u65f6\u5ef6\u7684\u6765\u6e90\u8de8\u8d8a\u591a\u4e2a\u5c42\u6b21\u4e14\u5177\u6709\u968f\u673a\u6027\uff0c\u73b0\u6709\u5206\u6790\u548c\u4eff\u771f\u5de5\u5177\u5f80\u5f80\u96be\u4ee5\u540c\u65f6\u51c6\u786e\u5efa\u6a21\u5404\u5c42\u8026\u5408\u5173\u7cfb\u4e0e\u5de8\u5927\u53c2\u6570\u7a7a\u95f4\uff0c\u4e9f\u9700\u4e00\u4e2a\u80fd\u591f\uff08i\uff09\u4ece\u5168\u6808\u89d2\u5ea6\u91cf\u5316\u65f6\u5ef6\u6765\u6e90\u548c\u74f6\u9888\uff0c\uff08ii\uff09\u5728\u6570\u5341\u4ebf\u7ea7\u914d\u7f6e\u7a7a\u95f4\u4e2d\u9ad8\u6548\u5bfb\u4f18\u4ee5\u6ee1\u8db3URLCC\u76ee\u6807\u7684\u6846\u67b6\u3002", "method": "\u5efa\u7acb\u8986\u76d6RAN\u5404\u5c42\u7684\u65f6\u5ef6\u6e90\u6a21\u578b\uff0c\u6db5\u76d6\u5c04\u9891\u63a5\u53e3\u3001\u8c03\u5ea6\u7b56\u7565\u3001\u786c\u4ef6/\u8f6f\u4ef6\u7ea6\u675f\u53ca\u5176\u4f9d\u8d56\u4e0e\u968f\u673a\u6027\uff1b\u5e76\u8bbe\u8ba1\u4e00\u4e2a\u914d\u7f6e\u4f18\u5316\u5668\uff0c\u80fd\u5728\u6781\u5927\u914d\u7f6e\u7a7a\u95f4\u4e2d\u9ad8\u6548\u641c\u7d22\uff0c\u627e\u51fa\u6ee1\u8db3\u65f6\u5ef6-\u53ef\u9760\u6027\u76ee\u6807\u7684\u8bbe\u7f6e\u3002", "result": "\u5728\u4e24\u4e2a\u5f00\u6e905G RAN\u6d4b\u8bd5\u5e8asrsRAN\u4e0eOAI\u4e0a\u8fdb\u884c\u9a8c\u8bc1\uff0cLatencScope\u7684\u9884\u6d4b\u5206\u5e03\u4e0e\u5b9e\u6d4b\u5206\u5e03\u9ad8\u5ea6\u543b\u5408\uff1b\u76f8\u8f83\u4e8e\u5148\u524d\u7684\u5206\u6790\u6a21\u578b\u4e0e\u4e3b\u6d41\u4eff\u771f\u5de5\u5177\uff08\u5982MATLAB 5G Toolbox\u30015G-LENA\uff09\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\uff1b\u5e76\u4e14\u80fd\u591f\u53d1\u73b0\u6ee1\u8db3URLLC\u76ee\u6807\u7684\u7cfb\u7edf\u914d\u7f6e\uff0c\u5e2e\u52a9\u8fd0\u8425\u5546\u5728\u7cfb\u7edf\u5c42\u9762\u505a\u51fa\u66f4\u4f18\u914d\u7f6e\u51b3\u7b56\u3002", "conclusion": "LatencScope\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u5728\u591a\u79cd\u7cfb\u7edf\u914d\u7f6e\u4e0b\u51c6\u786e\u8ba1\u7b97\u548c\u4f18\u53165G RAN\u5355\u5411\u65f6\u5ef6\u7684\u5de5\u5177\u5316\u6846\u67b6\uff0c\u63d0\u5347\u5bf9\u65f6\u5ef6\u74f6\u9888\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u53ef\u64cd\u4f5c\u6027\uff0c\u5e76\u80fd\u9ad8\u6548\u5730\u4e3aURLLC\u573a\u666f\u6311\u9009\u5408\u9002\u7684\u7cfb\u7edf\u8bbe\u7f6e\u3002"}}
{"id": "2511.20874", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20874", "abs": "https://arxiv.org/abs/2511.20874", "authors": ["Ashutossh Gupta", "Vassilis Kekatos", "Dionysios Aliprantis", "Steve Pekarek"], "title": "Dynamic Modeling of Load Demand in Electrified Highways Based on the EV Composition", "comment": "5 pages, 3 figures, 1 table", "summary": "Electrified roadways (ERs) equipped with the dynamic wireless power transfer (DWPT) technology can achieve longer driving range and reduce on-board battery requirements for electric vehicles (EVs). Due to the spatial arrangement of transmitter (Tx) coils embedded into the ER pavement, the power drawn by the EV's receiver (Rx) coil is oscillatory in nature. Therefore, understanding the dynamic behavior of the total DWPT load is important for power system dynamic studies. To this end, we model the load of individual EVs in the time and frequency domains for constant EV speed. We establish that a nonlinear control scheme implemented in existing DWPT-enabled EVs exhibits milder frequency harmonics compared to its linear alternative. According to this model, the harmonics of an EV load decrease in amplitude with the Rx coil length. We further propose and analyze stochastic models for the total DWPT load served by an ER segment. Our models explain how the EV composition on the ER affects its frequency spectrum. Interestingly, we show that serving more EVs with longer Rx coils (trucks) does not necessarily entail milder harmonics. Our analytical findings are corroborated using realistic flows from a traffic simulator and offer valuable insights to grid operators and ER designers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5728\u56fa\u5b9a\u901f\u5ea6\u4e0b\uff0c\u5c06\u7535\u52a8\u6c7d\u8f66(EV)\u5728\u5145\u7535\u9053\u8def(ER)\u4e0a\u7684\u52a8\u6001\u65e0\u7ebf\u7535\u529b\u4f20\u8f93(DWPT)\u8d1f\u8f7d\u8fdb\u884c\u65f6\u57df\u4e0e\u9891\u57df\u5efa\u6a21\uff0c\u6bd4\u8f83\u975e\u7ebf\u6027\u4e0e\u7ebf\u6027\u63a7\u5236\u5bf9\u8c10\u6ce2\u7684\u5f71\u54cd\uff0c\u7814\u7a76\u4e0d\u540cRx\u7ebf\u5708\u957f\u5ea6\u4e0eEV\u7ec4\u6210\u5bf9\u603b\u8d1f\u8f7d\u9891\u8c31\u7684\u5f71\u54cd\uff0c\u5e76\u4ee5\u4ea4\u901a\u4eff\u771f\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\uff0c\u4e3a\u7535\u7f51\u8fd0\u8425\u548cER\u8bbe\u8ba1\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u968f\u7740ER\u914d\u5907DWPT\uff0cEV\u5bf9\u8def\u9762\u8026\u5408\u7684\u53ef\u53d8\u8d1f\u8f7d\u6210\u4e3a\u7535\u529b\u7cfb\u7edf\u52a8\u6001\u7814\u7a76\u7684\u5173\u952e\u56e0\u7d20\u3002\u9700\u8981\u5bf9\u5355\u4e2aEV\u548c\u6c47\u603b\u5c42\u9762\u7684DWPT\u8d1f\u8f7d\u5728\u65f6\u57df\u548c\u9891\u57df\u7684\u7279\u6027\u8fdb\u884c\u5efa\u6a21\uff0c\u4ee5\u8bc4\u4f30\u5bf9\u7535\u7f51\u7a33\u5b9a\u6027\u548c\u8c10\u6ce2\u5f71\u54cd\u3002", "method": "\u5728\u6052\u901f\u6761\u4ef6\u4e0b\uff0c\u5bf9\u5355\u4e2aEV\u5728ER\u4e0a\u7684DWPT\u8d1f\u8f7d\u8fdb\u884c\u65f6\u57df\u4e0e\u9891\u57df\u5efa\u6a21\uff1b\u6bd4\u8f83\u5728DWPT-enabled EV\u4e2d\uff0c\u975e\u7ebf\u6027\u63a7\u5236\u4e0e\u7ebf\u6027\u63a7\u5236\u5bf9\u8d1f\u8f7d\u8c10\u6ce2\u7684\u5f71\u54cd\uff0c\u63a8\u5bfcRx\u7ebf\u5708\u957f\u5ea6\u5bf9\u8c10\u6ce2\u5e45\u503c\u7684\u5f71\u54cd\u89c4\u5f8b\uff1b\u63d0\u51fa\u5e76\u5206\u6790ER\u6bb5\u603bDWPT\u8d1f\u8f7d\u7684\u968f\u673a\u6a21\u578b\uff0c\u7814\u7a76EV\u7ec4\u6210\u5bf9\u603b\u8d1f\u8f7d\u9891\u8c31\u7684\u5f71\u54cd\uff1b\u5229\u7528\u4ea4\u901a\u4eff\u771f\u5668\u7684\u771f\u5b9e\u6d41\u91cf\u6570\u636e\u5bf9\u7406\u8bba\u7ed3\u679c\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5173\u952e\u53d1\u73b0\u5305\u62ec\uff1a1) \u975e\u7ebf\u6027\u63a7\u5236\u80fd\u4f7f\u8d1f\u8f7d\u8c10\u6ce2\u5e45\u503c\u8f83\u7ebf\u6027\u63a7\u5236\u66f4\u4f4e\uff0c\u8c10\u6ce2\u5bf9\u7a33\u5b9a\u6027\u6709\u79ef\u6781\u610f\u4e49\uff1b2) \u6839\u636e\u6a21\u578b\uff0cEV\u7684Rx\u7ebf\u5708\u957f\u5ea6\u8d8a\u957f\uff0c\u8c10\u6ce2\u5e45\u503c\u5448\u4e0b\u964d\u8d8b\u52bf\uff1b3) ER\u6bb5\u7684\u603b\u8d1f\u8f7d\u9891\u8c31\u53d7\u5230EV\u7ec4\u6210\u7684\u5f71\u54cd\uff0c\u66f4\u591a\u5e26\u6709\u8f83\u957fRx\u7ebf\u5708\u7684\u8f66\u8f86\uff08\u5982\u8d27\u8f66\uff09\u5e76\u4e0d\u4e00\u5b9a\u964d\u4f4e\u8c10\u6ce2\u3002\u7814\u7a76\u7ed3\u679c\u5728\u57fa\u4e8e\u73b0\u5b9e\u4ea4\u901a\u6d41\u7684\u4eff\u771f\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86DWPT\u8d1f\u8f7d\u7684\u65f6\u9891\u884c\u4e3a\u53ca\u5176\u5bf9ER\u8bbe\u8ba1\u548c\u7535\u7f51\u8fd0\u8425\u7684\u5f71\u54cd\uff0c\u4e3aER\u8bbe\u8ba1\u8005\u548c\u7535\u7f51\u8fd0\u8425\u8005\u63d0\u4f9b\u4e86\u8bc4\u4f30\u8d1f\u8f7d\u8c10\u6ce2\u7684\u91cd\u8981\u5de5\u5177\uff0c\u5e76\u6307\u51fa\u4e86\u4e0d\u540cEV\u7ec4\u6210\u5728\u51cf\u5c0f/\u63a7\u5236\u8c10\u6ce2\u65b9\u9762\u5e76\u975e\u7b80\u5355\u7ebf\u6027\u5173\u7cfb\uff0c\u4fbf\u4e8e\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u8fdb\u884c\u8d1f\u8f7d\u8c31\u4f18\u5316\u3002"}}
{"id": "2511.20831", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.20831", "abs": "https://arxiv.org/abs/2511.20831", "authors": ["Khuram Naveed", "Naveed ur Rehman"], "title": "A Fully Multivariate Multifractal Detrended Fluctuation Analysis Method for Fault Diagnosis", "comment": null, "summary": "We propose a fully multivariate generalization of multifractal detrended fluctuation analysis (MFDFA) and leverage it to develop a fault diagnosis framework for multichannel machine vibration data. We introduce a novel covariance-weighted $L_{pq}$ matrix norm based on Mahalanobis distance to define a fully multivariate fluctuation function that uniquely captures cross-channel dependencies and variance biases in multichannel vibration data. This formulation, termed FM-MFDFA, allows for a more accurate characterization of the multiscale structure of multivariate signals. To enhance feature relevance, the proposed framework integrates multivariate variational mode decomposition (MVMD) to isolate fault-relevant components before applying FM-MFDFA. Results on wind turbine gearbox data demonstrate that the proposed method outperforms conventional MFDFA approaches by effectively distinguishing between healthy and faulty machine states, even under noisy conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u53d8\u91cf\u7684\u591a\u5143MFDFA\u6269\u5c55 FM-MFDFA\uff0c\u5e76\u7ed3\u5408MVMD\u5b9e\u73b0\u6545\u969c\u8bca\u65ad\uff0c\u9002\u7528\u4e8e\u591a\u901a\u9053\u632f\u52a8\u6570\u636e\u7684\u8de8\u901a\u9053\u76f8\u5173\u6027\u5efa\u6a21\uff0c\u6548\u679c\u4f18\u4e8e\u4f20\u7edfMFDFA\u3002", "motivation": "\u5728\u591a\u901a\u9053\u632f\u52a8\u4fe1\u53f7\u4e2d\uff0c\u8de8\u901a\u9053\u76f8\u5173\u6027\u548c\u65b9\u5dee\u504f\u7f6e\u5bf9\u6545\u969c\u8bca\u65ad\u7684\u5f71\u54cd\u672a\u88ab\u5145\u5206\u6355\u83b7\uff1b\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u5904\u7406\u591a\u5c3a\u5ea6\u7ed3\u6784\u4e0e\u901a\u9053\u76f8\u5173\u6027\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u9a6c\u6c0f\u8ddd\u79bb\u7684\u534f\u65b9\u5dee\u52a0\u6743 L_pq \u77e9\u9635\u8303\u6570\u6765\u5b9a\u4e49\u5168\u53d8\u91cf\u7684\u6ce2\u52a8\u51fd\u6570\uff0c\u5f62\u6210 FM-MFDFA\uff1b\u7ed3\u5408 MVMD \u5206\u89e3\u4ee5\u63d0\u53d6\u4e0e\u6545\u969c\u76f8\u5173\u5206\u91cf\uff0c\u518d\u5e94\u7528 FM-MFDFA\uff1b\u5728\u98ce\u7535\u9f7f\u8f6e\u7bb1\u6570\u636e\u4e0a\u9a8c\u8bc1\u3002", "result": "\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\uff0cFM-MFDFA \u80fd\u66f4\u6709\u6548\u533a\u5206\u5065\u5eb7\u4e0e\u6545\u969c\u72b6\u6001\uff0c\u4f18\u4e8e\u4f20\u7edfMFDFA\u3002", "conclusion": "\u901a\u8fc7\u628a\u591a\u53d8\u91cf\u7b26\u53f7\u7684\u8de8\u901a\u9053\u76f8\u5173\u6027\u548c\u65b9\u5dee\u504f\u7f6e\u7eb3\u5165\u6ce2\u52a8\u5206\u6790\uff0c\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u591a\u5c3a\u5ea6\u8868\u5f81\u4e0e\u6545\u969c\u8bca\u65ad\u80fd\u529b\uff1bMVMD \u7684\u4e8b\u524d\u5206\u79bb\u589e\u5f3a\u4e86\u7279\u5f81\u76f8\u5173\u6027\u63d0\u53d6\u3002"}}
{"id": "2511.21271", "categories": ["eess.SY", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.21271", "abs": "https://arxiv.org/abs/2511.21271", "authors": ["Xinyan Xie", "Xuesong Wang", "Xin Lai", "Yongheng Wen", "Fengrui Yang", "Haoyang He", "Lai Zhang", "Dong Zhao"], "title": "Adaptive Lighting Control in Visible Light Systems: An Integrated Sensing, Communication, and Illumination Framework", "comment": null, "summary": "Indoor visible light communication (VLC) is a promising sixth-generation (6G) technology, as its directional and sensitive optical signals are naturally suited for integrated sensing and communication (ISAC). However, current research mainly focuses on maximizing data rates and sensing accuracy, creating a conflict between high performance, high energy consumption, and user visual comfort. This paper proposes an adaptive integrated sensing, communication, and illumination (ISCI) framework that resolves this conflict by treating energy savings as a primary objective. The framework's mechanism first partitions the receiving plane using a geometric methodology, defining an activity area and a surrounding non-activity area to match distinct user requirements. User location, determined using non-line-of-sight (NLOS) sensing, then acts as a dynamic switch for the system's optimization objective. The system adaptively shifts between minimizing total transmit power while guaranteeing communication and illumination performance in the activity area and maximizing signal-to-noise ratio (SNR) uniformity in the non-activity area. Numerical results confirm that this adaptive ISCI approach achieves 53.59% energy savings over a non-adaptive system and improves SNR uniformity by 57.79%, while satisfying all illumination constraints and maintaining a mean localization error of 0.071 m.", "AI": {"tldr": "Adaptive ISCI framework for indoor VLC that uses a geometric partition of the receiving plane and NLOS-based localization to switch optimization objectives, achieving energy savings and improved SNR uniformity while meeting illumination constraints and maintaining high localization accuracy.", "motivation": "To resolve the conflict among high data-rate/sensing performance, energy consumption, and user visual comfort in indoor VLCISAC systems by prioritizing energy efficiency and making objective functions adaptive to user position.", "method": "Partition the receiving plane into an activity area and a surrounding non-activity area using a geometric approach. Use NLOS sensing to determine user location, which acts as a dynamic switch for the optimization objective. When the user is in the activity area, the system minimizes total transmit power while ensuring communications and illumination; when in the non-activity area, it maximizes SNR uniformity. The framework adapts in real time to user position.", "result": "The adaptive ISCI approach achieves 53.59% energy savings compared with a non-adaptive system, and improves SNR uniformity by 57.79%. It also satisfies all illumination constraints and achieves a mean localization error of 0.071 m.", "conclusion": "An adaptive, location-aware ISCI framework can efficiently balance energy efficiency, communication/illumination performance, and visual comfort in indoor VLC, providing significant energy savings and uniform sensing performance with precise localization."}}
{"id": "2511.20895", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20895", "abs": "https://arxiv.org/abs/2511.20895", "authors": ["Kimia Ahmadi", "Wouter A. Serdijn"], "title": "Adaptive Gradient Descent MPPT Algorithm With Complexity-Aware Benchmarking for Low-Power PV Systems", "comment": "12 pages, 13 figures", "summary": "This paper proposes a computationally efficient, real-time maximum power point tracking (MPPT) algorithm tailored for low-power photovoltaic (PV) systems operating under fast-changing irradiance and partial shading conditions (PSC). The proposed method augments the classical perturb and observe (P&O) algorithm with an adaptive gradient descent mechanism that dynamically scales the perturbation step size based on the instantaneous power-voltage slope, thereby minimizing tracking time and steady-state oscillations. An optional initialization routine enhances global MPP (GMPP) tracking under PSC. Extensive simulations, including irradiance recordings from freely moving rodent subjects relevant to the targeted application, and tests across varying converter topologies and temperatures, demonstrate its robust, topology-independent performance. The proposed algorithm achieves 99.94 percent MPPT efficiency under standard test conditions (STC), 99.21 percent when applied to experimental data, and more than 99.6 percent for the tested temperature profiles. Under PSC, the initialization routine improves tracking efficiency by up to 7.8 percent. A normalized gate-level complexity analysis and a unified figure-of-merit (FoM) incorporating efficiency, tracking time, and computational cost demonstrate that the proposed algorithm outperforms 35 state-of-the-art P&O-based MPPT algorithms. These results underscore its suitability for integration in low-power power management integrated circuits (PMICs) operating under dynamic and resource-constrained conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u4f4e\u529f\u8017\u5149\u4f0f\u7cfb\u7edf\u7684\u5b9e\u65f6MPPT\u7b97\u6cd5\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u68af\u5ea6\u4e0b\u964d\u7684\u6b65\u8fdb\u8c03\u8282\u6765\u6539\u8fdb\u7ecf\u5178\u6270\u52a8\u89c2\u5bdf\u6cd5\uff08P&O\uff09\uff0c\u5e76\u53ef\u9009\u5730\u5728\u504f\u5149\u548c\u5feb\u901f\u5149\u7167\u53d8\u5316\u6761\u4ef6\u4e0b\u8fdb\u884c\u5168\u5c40\u6700\u5927\u529f\u7387\u70b9\u8ffd\u8e2a\uff08GMPP\uff09\u521d\u59cb\u5316\u3002\u4e0e\u591a\u79cd\u62d3\u6251\u3001\u6e29\u5ea6\u6761\u4ef6\u53ca\u5b9e\u9645\u6570\u636e\u96c6\u5bf9\u6bd4\uff0c\u7b97\u6cd5\u5728STC\u548cPSC\u4e0b\u5747\u663e\u793a\u9ad8\u6548\u80fd\u4e0e\u4f4e\u590d\u6742\u5ea6\uff0c\u4e14\u4f18\u4e8e35\u4e2a\u540c\u7c7bP&O MPPT\u7b97\u6cd5\uff0c\u9002\u5408\u96c6\u6210\u5230\u4f4e\u529f\u8017PMIC\u4e2d\u3002", "motivation": "\u5728\u5feb\u901f\u53d8\u5316\u7684\u5149\u7167\u548c\u90e8\u5206\u906e\u6321\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4f4e\u529f\u8017\u3001\u5b9e\u65f6\u4e14\u9c81\u68d2\u7684MPPT\uff0c\u4ee5\u51cf\u5c11\u8ffd\u8e2a\u65f6\u95f4\u548c\u7a33\u6001\u632f\u8361\uff0c\u540c\u65f6\u964d\u4f4e\u5b9e\u73b0\u590d\u6742\u5ea6\u4ee5\u4fbf\u96c6\u6210\u5230PMIC\u4e2d\u3002", "method": "\u5728\u7ecf\u5178P&O\u7684\u57fa\u7840\u4e0a\u5f15\u5165\u81ea\u9002\u5e94\u68af\u5ea6\u4e0b\u964d\u673a\u5236\uff0c\u6839\u636e\u77ac\u65f6\u529f\u7387-\u7535\u538b\u659c\u7387\u52a8\u6001\u7f29\u653e\u6270\u52a8\u6b65\u957f\uff1b\u63d0\u4f9b\u53ef\u9009\u7684GMPP\u521d\u59cb\u5316\u4ee5\u63d0\u5347PSC\u4e0b\u7684\u5168\u5c40\u641c\u7d22\u80fd\u529b\uff1b\u901a\u8fc7\u5bf9\u4e0d\u540c\u53d8\u6362\u5668\u62d3\u6251\u3001\u6e29\u5ea6\u548c\u57fa\u4e8e\u5b9e\u9645 irradiance \u8bb0\u5f55\u7684\u4eff\u771f/\u6d4b\u8bd5\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u8fdb\u884c\u95e8\u7ea7\u590d\u6742\u5ea6\u5f52\u4e00\u5316\u5206\u6790\u4e0e\u7edf\u4e00FoM\u8bc4\u4f30\u3002", "result": "MPPT\u6548\u7387\u5728STC\u8fbe\u523099.94%\uff0c\u5bf9\u5b9e\u9a8c\u6570\u636e\u4e3a99.21%\uff0c\u5404\u6e29\u5ea6\u60c5\u5f62>99.6%\uff1b\u5728PSC\u6761\u4ef6\u4e0b\uff0cGMPP\u521d\u59cb\u5316\u53ef\u63d0\u5347\u8ffd\u8e2a\u6548\u7387\u6700\u9ad87.8%\uff1bFoM\u5206\u6790\u663e\u793a\u572835\u4e2aP&O-based\u7b97\u6cd5\u4e2d\u5177\u6709\u9886\u5148\u5730\u4f4d\uff0c\u95e8\u7ea7\u590d\u6742\u5ea6\u4f4e\uff0c\u62d3\u6251\u65e0\u5173\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u9002\u5e94P&O-\u68af\u5ea6\u4e0b\u964dMPPT\u5728\u52a8\u6001\u3001\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u8868\u73b0\u9c81\u68d2\u4e14\u9ad8\u6548\uff0c\u9002\u5408\u5728\u4f4e\u529f\u8017PMIC\u4e2d\u5b9e\u73b0\uff0c\u4e0e\u591a\u79cd\u62d3\u6251\u548c\u6e29\u5ea6\u6761\u4ef6\u76f8\u5bb9\u3002"}}
{"id": "2511.21345", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.21345", "abs": "https://arxiv.org/abs/2511.21345", "authors": ["Chin-Hung Chen", "Yan Wu", "Wim van Houtum", "Alex Alvarado"], "title": "Blind Turbo Demodulation for Differentially Encoded OFDM with 2D Trellis Decomposition", "comment": "preprint", "summary": "Digital Audio Broadcasting (DAB)-like systems employ differentially encoded (DE) phase-shift keying (PSK) for transmission. While turbo-DE-PSK receivers offer substantial performance gains through iterative decoding by making the DE-PSK an inner code, they rely on accurate channel estimation without pilots, which is a key challenge in DAB-like scenarios. This paper develops a fully blind turbo-DE-PSK scheme that jointly estimates channel phase, channel gain, and noise variance directly from the received signal. The design leverages a two-dimensional (2D) trellis decomposition for blind phase estimation, complemented by power-based estimators for channel gain and noise variance. We provide a comprehensive system assessment across practical system parameters, including inner code length, phase quantization, and 2D block size. Simulation results show that the blind 2D turbo demodulator approaches the performance of receivers with perfect channel knowledge and remains robust under realistic transmission conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u76f2\u76842D turbo-DE-PSK\u89e3\u8c03\u65b9\u6848\uff0c\u901a\u8fc72D\u6811\u7b49\u7ea7\u7ed3\u6784\u8fdb\u884c\u76f2\u76f8\u4f4d\u4f30\u8ba1\uff0c\u5e76\u7528\u57fa\u4e8e\u529f\u7387\u7684\u4f30\u8ba1\u91cf\u4f30\u8ba1\u4fe1\u9053\u589e\u76ca\u548c\u566a\u58f0\u65b9\u5dee\uff0c\u80fd\u5728\u65e0\u5bfc\u9891\u6761\u4ef6\u4e0b\u63a5\u8fd1\u6709\u5b8c\u7f8e\u4fe1\u9053\u77e5\u8bc6\u65f6\u7684\u6027\u80fd\u3002", "motivation": "\u5728DAB\u7c7b\u7cfb\u7edf\u4e2d\uff0cDE-PSK\u7684\u8fed\u4ee3\u89e3\u8c03\u5728\u4e0d\u4f7f\u7528\u5bfc\u9891\u7684\u60c5\u51b5\u4e0b\u5bf9\u4fe1\u9053\u4f30\u8ba1\u654f\u611f\uff0c\u4e9f\u9700\u4e00\u79cd\u5b8c\u5168\u76f2\u7684\u89e3\u8c03\u65b9\u6848\u4ee5\u964d\u4f4e\u5bf9\u5bfc\u9891\u7684\u4f9d\u8d56\u5e76\u63d0\u9ad8\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5b8c\u5168\u76f2\u7684turbo-DE-PSK\u7ed3\u6784\uff0c\u5229\u7528\u4e8c\u7ef4\uff082D\uff09trellis\u5206\u89e3\u8fdb\u884c\u76f2\u76f8\u4f4d\u4f30\u8ba1\uff0c\u5e76\u8f85\u4ee5\u57fa\u4e8e\u529f\u7387\u7684\u4f30\u8ba1\u91cf\u6765\u4f30\u8ba1\u4fe1\u9053\u589e\u76ca\u548c\u566a\u58f0\u65b9\u5dee\u3002\u7cfb\u7edf\u5728\u591a\u79cd\u5b9e\u9645\u53c2\u6570\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u8bc4\u4f30\uff08\u5185\u7801\u957f\u5ea6\u3001\u76f8\u4f4d\u91cf\u5316\u30012D\u5757\u5927\u5c0f\u7b49\uff09\uff0c\u5e76\u5c06\u5176\u5d4c\u5165\u5230turbo\u89e3\u8c03\u6846\u67b6\u4e2d\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u76f22D turbo\u89e3\u8c03\u5668\u7684\u6027\u80fd\u63a5\u8fd1\u5177\u6709\u5b8c\u7f8e\u4fe1\u9053\u77e5\u8bc6\u7684\u63a5\u6536\u673a\uff0c\u4e14\u5728\u73b0\u5b9e\u4f20\u8f93\u6761\u4ef6\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u76f22D turbo-DE-PSK\u65b9\u6848\u5728\u65e0\u9700\u5bfc\u9891\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u4fe1\u9053\u77e5\u8bc6\u7684\u6027\u80fd\uff0c\u662fDAB\u7c7b\u7cfb\u7edf\u4e2d\u5bf9\u5bfc\u9891\u4f9d\u8d56\u8f83\u5927\u573a\u666f\u7684\u4e00\u79cd\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20878", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.20878", "abs": "https://arxiv.org/abs/2511.20878", "authors": ["Jaehwan Park", "Kyungchan Lim", "Seonhye Park", "Doowon Kim"], "title": "Supporting Students in Navigating LLM-Generated Insecure Code", "comment": "7 pages", "summary": "The advent of Artificial Intelligence (AI), particularly large language models (LLMs), has revolutionized software development by enabling developers to specify tasks in natural language and receive corresponding code, boosting productivity. However, this shift also introduces security risks, as LLMs may generate insecure code that can be exploited by adversaries. Current educational approaches emphasize efficiency while overlooking these risks, leaving students underprepared to identify and mitigate security issues in AI-assisted workflows.\n  To address this gap, we present Bifr\u00f6st, an educational framework that cultivates security awareness in AI-augmented development. Bifr\u00f6st integrates (1) a Visual Studio Code extension simulating realistic environments, (2) adversarially configured LLMs that generate insecure code, and (3) a feedback system highlighting vulnerabilities. By immersing students in tasks with compromised LLMs and providing targeted security analysis, Bifr\u00f6st cultivates critical evaluation skills; classroom deployments (n=61) show vulnerability to insecure code, while a post-intervention survey (n=21) indicates increased skepticism toward LLM outputs.", "AI": {"tldr": "\u63d0\u51fa Bifr\u00f6st \u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u6027 LLM\u3001VS Code \u6269\u5c55\u4e0e\u6f0f\u6d1e\u53cd\u9988\u57f9\u517b AI \u8f85\u52a9\u5f00\u53d1\u4e2d\u7684\u5b89\u5168\u610f\u8bc6\uff0c\u521d\u6b65\u8bc1\u636e\u663e\u793a\u63d0\u5347\u5bf9 LLM \u8f93\u51fa\u7684\u6000\u7591\u6027\u5e76\u66b4\u9732\u5b66\u751f\u5bf9\u4e0d\u5b89\u5168\u4ee3\u7801\u7684\u6613\u611f\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5f00\u53d1\u8005\u53ef\u4ee5\u7528\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u4efb\u52a1\u5e76\u83b7\u5f97\u4ee3\u7801\uff0c\u4f46\u8fd9\u4e5f\u5e26\u6765\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff1b\u73b0\u6709\u6559\u80b2\u5f80\u5f80\u5f3a\u8c03\u6548\u7387\u800c\u5ffd\u89c6\u5b89\u5168\u57f9\u8bad\uff0c\u5bfc\u81f4\u5b66\u751f\u7f3a\u4e4f\u8bc6\u522b\u4e0e\u7f13\u89e3 AI \u53c2\u4e0e\u5de5\u4f5c\u6d41\u4e2d\u5b89\u5168\u95ee\u9898\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa Bifr\u00f6st \u6559\u80b2\u6846\u67b6\uff0c\u5305\u4e09\u90e8\u5206\uff1a1) Visual Studio Code \u6269\u5c55\uff0c\u7528\u4ee5\u6a21\u62df\u73b0\u5b9e\u5f00\u53d1\u73af\u5883\uff1b2) \u5bf9\u6297\u6027\u914d\u7f6e\u7684 LLMs\uff0c\u751f\u6210\u4e0d\u5b89\u5168\u4ee3\u7801\u4ee5\u66b4\u9732\u5b89\u5168\u7f3a\u9677\uff1b3) \u4e00\u4e2a\u6f0f\u6d1e\u53cd\u9988\u7cfb\u7edf\uff0c\u7a81\u51fa\u5e76\u5f15\u5bfc\u5206\u6790\u8fd9\u4e9b\u5b89\u5168\u95ee\u9898\u3002\u901a\u8fc7\u8ba9\u5b66\u751f\u5728\u53d7\u63a7\u60c5\u5883\u4e2d\u5904\u7406\u53d7\u4e0d\u5b89\u5168 LLM \u5f71\u54cd\u7684\u4ee3\u7801\u5e76\u8fdb\u884c\u5b89\u5168\u5206\u6790\u6765\u57f9\u517b\u6279\u5224\u6027\u8bc4\u4f30\u80fd\u529b\u3002", "result": "\u8bfe\u5802\u90e8\u7f72\u6837\u672c\u91cf\u4e3a 61\uff0c\u63ed\u793a\u5b66\u751f\u5bf9\u4e0d\u5b89\u5168\u4ee3\u7801\u7684\u6613\u611f\u6027\uff1b\u5e72\u9884\u540e\u7684\u8c03\u67e5\u6837\u672c\u91cf\u4e3a 21\uff0c\u663e\u793a\u5b66\u751f\u5bf9 LLM \u8f93\u51fa\u7684\u6000\u7591\u6027\u589e\u5f3a\uff0c\u8868\u660e\u5b89\u5168\u5206\u6790\u80fd\u529b\u6709\u521d\u6b65\u63d0\u5347\u7684\u8ff9\u8c61\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a AI \u8f85\u52a9\u5f00\u53d1\u7684\u5b89\u5168\u6559\u80b2\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u8def\u5f84\uff0c\u901a\u8fc7\u6c89\u6d78\u5f0f\u4efb\u52a1\u4e0e\u9488\u5bf9\u6027\u53cd\u9988\u63d0\u5347\u5b66\u751f\u7684\u5b89\u5168\u5ba1\u67e5\u80fd\u529b\uff1b\u4f46\u9700\u8981\u5728\u66f4\u5927\u6837\u672c\u3001\u4e0d\u540c\u573a\u666f\u4e2d\u8fdb\u884c\u957f\u671f\u6548\u679c\u9a8c\u8bc1\u4e0e\u6269\u5c55\u3002"}}
{"id": "2511.20702", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20702", "abs": "https://arxiv.org/abs/2511.20702", "authors": ["Chinmay Tripurwar", "Utkarsh Maurya", "Dishant"], "title": "Post-Pruning Accuracy Recovery via Data-Free Knowledge Distillation", "comment": null, "summary": "Model pruning is a widely adopted technique to reduce the computational complexity and memory footprint of Deep Neural Networks (DNNs). However, global unstructured pruning often leads to significant degradation in accuracy, typically necessitating fine-tuning on the original training dataset to recover performance. In privacy-sensitive domains such as healthcare or finance, access to the original training data is often restricted post-deployment due to regulations (e.g., GDPR, HIPAA). This paper proposes a Data-Free Knowledge Distillation framework to bridge the gap between model compression and data privacy. We utilize DeepInversion to synthesize privacy-preserving ``dream'' images from the pre-trained teacher model by inverting Batch Normalization (BN) statistics. These synthetic images serve as a transfer set to distill knowledge from the original teacher to the pruned student network. Experimental results on CIFAR-10 across various architectures (ResNet, MobileNet, VGG) demonstrate that our method significantly recovers accuracy lost during pruning without accessing a single real data point.", "AI": {"tldr": "Data-free knowledge distillation for model pruning: synthesize privacy-preserving data from a pre-trained teacher using DeepInversion (BN stats) as a transfer set to recover pruning accuracy without real data.", "motivation": "In privacy-sensitive domains, access to original training data is restricted (GDPR/HIPAA). Global unstructured pruning often hurts accuracy; need a data-free approach to recover performance after compression.", "method": "Inverting BN statistics via DeepInversion to generate synthetic images (dream images) from the teacher model, using these images as a transfer set to distill knowledge from the teacher to a pruned student network.", "result": "Experiments on CIFAR-10 across architectures (ResNet, MobileNet, VGG) show substantial recovery of pruning-induced accuracy loss without using any real data.", "conclusion": "A data-free KD framework can effectively combine model compression and data privacy; synthetic data from BN inversion enables effective distillation to recover performance after pruning."}}
{"id": "2511.20902", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.20902", "abs": "https://arxiv.org/abs/2511.20902", "authors": ["Glener Lanes Pizzolato", "Brenda Medeiros Lopes", "Claudio Schepke", "Diego Kreutz"], "title": "A Taxonomy of Pix Fraud in Brazil: Attack Methodologies, AI-Driven Amplification, and Defensive Strategies", "comment": "5 pages, 1 figure, 2 tables, submitted to ERRC/WRSeg 2025", "summary": "This work presents a review of attack methodologies targeting Pix, the instant payment system launched by the Central Bank of Brazil in 2020. The study aims to identify and classify the main types of fraud affecting users and financial institutions, highlighting the evolution and increasing sophistication of these techniques. The methodology combines a structured literature review with exploratory interviews conducted with professionals from the banking sector. The results show that fraud schemes have evolved from purely social engineering approaches to hybrid strategies that integrate human manipulation with technical exploitation. The study concludes that security measures must advance at the same pace as the growing complexity of attack methodologies, with particular emphasis on adaptive defenses and continuous user awareness.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.20704", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20704", "abs": "https://arxiv.org/abs/2511.20704", "authors": ["Abolfazl Moslemi", "Hossein Peyvandi"], "title": "Pretraining Transformer-Based Models on Diffusion-Generated Synthetic Graphs for Alzheimer's Disease Prediction", "comment": "14 pages. Preprint", "summary": "Early and accurate detection of Alzheimer's disease (AD) is crucial for enabling timely intervention and improving outcomes. However, developing reliable machine learning (ML) models for AD diagnosis is challenging due to limited labeled data, multi-site heterogeneity, and class imbalance. We propose a Transformer-based diagnostic framework that combines diffusion-based synthetic data generation with graph representation learning and transfer learning. A class-conditional denoising diffusion probabilistic model (DDPM) is trained on the real-world NACC dataset to generate a large synthetic cohort that mirrors multimodal clinical and neuroimaging feature distributions while balancing diagnostic classes. Modality-specific Graph Transformer encoders are first pretrained on this synthetic data to learn robust, class-discriminative representations and are then frozen while a neural classifier is trained on embeddings from the original NACC data. We quantify distributional alignment between real and synthetic cohorts using metrics such as Maximum Mean Discrepancy (MMD), Frechet distance, and energy distance, and complement discrimination metrics with calibration and fixed-specificity sensitivity analyses. Empirically, our framework outperforms standard baselines, including early and late fusion deep neural networks and the multimodal graph-based model MaGNet, yielding higher AUC, accuracy, sensitivity, and specificity under subject-wise cross-validation on NACC. These results show that diffusion-based synthetic pretraining with Graph Transformers can improve generalization in low-sample, imbalanced clinical prediction settings.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.20939", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20939", "abs": "https://arxiv.org/abs/2511.20939", "authors": ["Youhong Chen", "Debraj Bhattacharjee", "Balarko Chaudhuri", "Mark O Malley", "Nan Qin", "Adrian Pilkaer Expethit"], "title": "Data-Driven Post-Event Analysis with Real-World Oscillation Data from Denmark", "comment": "5 pages, 6 figures, real power network event data, submitted to IEEE General Meeting 2026", "summary": "This paper demonstrates how Extended Dynamic Mode Decomposition (EDMD), grounded in Koopman operator theory, can effectively identify the main contributor(s) to oscillations in power grids. We use PMU data recorded from a real 0.15 Hz oscillation event in Denmark for post-event analysis. To this end, the EDMD algorithm processed only voltage and current phasors from nineteen PMUs at different voltage levels across the Danish grid. In such a blind-test setting with no supplementary system information, EDMD accurately pinpointed the location of the main contributor to the 0.2 Hz oscillation, consistent with the location of the problematic IBR plant later confirmed by Energinet, where the underlying cause was a control system issue. Conventional approaches, such as the dissipating energy flow (DEF) method used in the ISO-NE OSL tool did not clearly identify this plant. This joint validation with Energinet, reinforcing earlier studies using simulated IBR-dominated systems and real PMU data from ISO-NE, highlights the potential of EDMD-based post-event analysis for identifying major oscillation contributors and enabling targeted SSO mitigation.", "AI": {"tldr": "\u4f7f\u7528\u6269\u5c55\u52a8\u6001\u6a21\u6001\u5206\u89e3\uff08EDMD\uff09\u57fa\u4e8eKoopman\u7406\u8bba\uff0c\u4ece19\u4e2aPMU\u6570\u636e\u4e2d\u8bc6\u522b\u5bfc\u81f40.2 Hz\u632f\u8361\u7684\u4e3b\u8981\u6e90\u5934\uff0c\u5728\u4e39\u9ea6\u771f\u5b9e\u4e8b\u4ef6\u4e2d\u4e0e Energinet \u7684\u786e\u8ba4\u4e00\u81f4\uff0c\u4f18\u4e8e\u5e38\u89c4\u7684\u80fd\u91cf\u6d41\u8017\u6563\u6cd5\uff08DEF\uff09\u3002", "motivation": "\u89e3\u51b3\u5728\u7f3a\u4e4f\u8be6\u5c3d\u7cfb\u7edf\u6a21\u578b\u4fe1\u606f\u65f6\uff0c\u5feb\u901f\u3001\u65e0\u6a21\u578b\u4f9d\u8d56\u5730\u5b9a\u4f4d\u7535\u7f51\u632f\u8361\u6e90\uff0c\u4ee5\u4fbf\u8fdb\u884c\u9488\u5bf9\u6027\u7a33\u5b9a\u6027\u6539\u8fdb\u548c\u51cf\u9707\u63aa\u65bd\u3002", "method": "\u5bf9\u4e39\u9ea60.15 Hz \u5b9e\u9645\u4e8b\u4ef6\u7684PMU\u6570\u636e\uff08\u4e0d\u540c\u7535\u538b\u7b49\u7ea7\u300119\u4e2aPMU\uff0c\u7535\u538b\u4e0e\u7535\u6d41\u76f8\u91cf\uff09\u5e94\u7528EDMD\uff1b\u5728\u76f2\u6d4b\u8bd5\u8bbe\u7f6e\u4e0b\u4e0d\u4f7f\u7528\u989d\u5916\u7cfb\u7edf\u4fe1\u606f\uff0c\u5b9a\u4f4d\u4e3b\u8981\u6e90\u5934\u5e76\u4e0e Energinet \u7684\u4e8b\u540e\u786e\u8ba4\u8fdb\u884c\u6bd4\u5bf9\uff0c\u540c\u65f6\u4e0e DEF \u6cd5\u7b49\u4f20\u7edf\u65b9\u6cd5\u8fdb\u884c\u5bf9\u7167\u3002", "result": "EDMD \u80fd\u51c6\u786e\u5b9a\u4f4d\u5f15\u53d10.2 Hz\u632f\u8361\u7684\u4e3b\u6e90\uff0c\u6b64\u6e90\u70b9\u4e0e Energinet \u540e\u7eed\u786e\u8ba4\u7684\u95ee\u9898 IBR \u7535\u5382\u4e00\u81f4\uff1bDEF \u65b9\u6cd5\u672a\u80fd\u6e05\u6670\u8bc6\u522b\u8be5\u5382\uff1b\u7814\u7a76\u4e0e Energinet \u7684\u9a8c\u8bc1\u4ee5\u53ca\u5148\u524d\u7684\u6a21\u62dfISO-NE\u7814\u7a76\u7ed3\u679c\u4e00\u81f4\uff0c\u663e\u793a EDMD \u5728\u4e8b\u540e\u5206\u6790\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8eEDMD\u7684\u4e8b\u540e\u5206\u6790\u5728\u8bc6\u522b\u7535\u7f51\u4e3b\u8981\u632f\u8361\u6e90\u5e76\u5b9e\u73b0\u5b9a\u5411\u51cf\u632f\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u6709\u671b\u4f5c\u4e3a\u65e0\u6a21\u578b\u6570\u636e\u9a71\u52a8\u7684\u6709\u529b\u5de5\u5177\u7528\u4e8eSSO\uff08\u7a33\u6001\u5b89\u5168\u6027\u4f18\u5316\uff09\u4e2d\u7684\u76ee\u6807\u5b9a\u4f4d\u3002"}}
{"id": "2511.21080", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21080", "abs": "https://arxiv.org/abs/2511.21080", "authors": ["Yeswanth Ravichandran", "Duoduo Liao", "Charan Teja Kurakula"], "title": "Data-Driven Assessment of Concrete Slab Integrity via Impact-Echo Signals and Neural Networks", "comment": "Accepted by IEEE Big Data 2025", "summary": "Subsurface defects such as delamination, voids, and honeycombing critically affect the durability of concrete bridge decks but are difficult to detect reliably using visual inspection or manual sounding. This paper presents a machine learning based Impact Echo (IE) framework that automates both defect localization and multi-class classification of common concrete defects. Raw IE signals from Federal Highway Administration (FHWA) laboratory slabs and in-service bridge decks are transformed via Fast Fourier Transform (FFT) into dominant peak-frequency features and interpolated into spatial maps for defect zone visualization. Unsupervised k-means clustering highlights low-frequency, defect-prone regions, while Ground Truth Masks (GTMs) derived from seeded lab defects are used to validate spatial accuracy and generate high-confidence training labels. From these validated regions, spatially ordered peak-frequency sequences are constructed and fed into a stacked Long Short-Term Memory (LSTM) network that classifies four defect types shallow delamination, deep delamination, voids, and honeycombing with 73% overall accuracy. Field validation on the bridge deck demonstrates that models trained on laboratory data generalize under realistic coupling, noise, and environmental variability. The proposed framework enhances the objectivity, scalability, and repeatability of Non-Destructive Evaluation (NDE), supporting intelligent, data-driven bridge health monitoring at a network scale.", "AI": {"tldr": "ML-based Impact Echo framework for automated defect localization and multi-class classification of concrete defects using FFT-derived peak-frequency features, k-means clustering, GTMs for labels, and a stacked LSTM, achieving 73% accuracy; validated on lab and field data for scalable NDE of bridge decks.", "motivation": "Subsurface defects (delamination, voids, honeycombing) critically affect concrete bridge deck durability and are hard to detect reliably by visual methods. A data-driven, scalable, and objective NDE approach is needed for bridge health monitoring.", "method": "Transform IE signals via FFT to dominant peak-frequency features; interpolate into spatial maps for defect visualization. Use unsupervised k-means to identify defect-prone regions. Generate training labels with Ground Truth Masks (GTMs) derived from seeded lab defects. Construct spatially ordered peak-frequency sequences and feed into a stacked LSTM to classify four defect types: shallow delamination, deep delamination, voids, honeycombing.", "result": "Achieves 73% overall accuracy in defect classification. Field validation shows models trained on laboratory data generalize under realistic coupling, noise, and environmental variability.", "conclusion": "The framework improves objectivity, scalability, and repeatability of NDE and supports data-driven bridge health monitoring at a network scale."}}
{"id": "2511.20977", "categories": ["eess.SY", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.20977", "abs": "https://arxiv.org/abs/2511.20977", "authors": ["Junkai Hu", "Li Xia"], "title": "Independent policy gradient-based reinforcement learning for economic and reliable energy management of multi-microgrid systems", "comment": null, "summary": "Efficiency and reliability are both crucial for energy management, especially in multi-microgrid systems (MMSs) integrating intermittent and distributed renewable energy sources. This study investigates an economic and reliable energy management problem in MMSs under a distributed scheme, where each microgrid independently updates its energy management policy in a decentralized manner to optimize the long-term system performance collaboratively. We introduce the mean and variance of the exchange power between the MMS and the main grid as indicators for the economic performance and reliability of the system. Accordingly, we formulate the energy management problem as a mean-variance team stochastic game (MV-TSG), where conventional methods based on the maximization of expected cumulative rewards are unsuitable for variance metrics. To solve MV-TSGs, we propose a fully distributed independent policy gradient algorithm, with rigorous convergence analysis, for scenarios with known model parameters. For large-scale scenarios with unknown model parameters, we further develop a deep reinforcement learning algorithm based on independent policy gradients, enabling data-driven policy optimization. Numerical experiments in two scenarios validate the effectiveness of the proposed methods. Our approaches fully leverage the distributed computational capabilities of MMSs and achieve a well-balanced trade-off between economic performance and operational reliability.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5747\u503c-\u65b9\u5dee\u7684\u591a\u5fae\u7f51\u80fd\u91cf\u7ba1\u7406\u535a\u5f08\uff0c\u5e76\u7ed9\u51fa\u5206\u5e03\u5f0f\u72ec\u7acb\u7b56\u7565\u68af\u5ea6\u65b9\u6848\u53ca\u5176\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6269\u5c55\uff0c\u517c\u987e\u7ecf\u6d4e\u6027\u4e0e\u53ef\u9760\u6027\u3002", "motivation": "\u5728\u542b\u5206\u5e03\u5f0f\u53ef\u518d\u751f\u80fd\u6e90\u7684\u591a\u5fae\u7f51\u7cfb\u7edf\u4e2d\uff0c\u9700\u540c\u65f6\u63d0\u5347\u7ecf\u6d4e\u6027\u4e0e\u7cfb\u7edf\u53ef\u9760\u6027\uff1b\u4ec5\u4f18\u5316\u671f\u671b\u5956\u52b1\u5f80\u5f80\u5ffd\u7565\u98ce\u9669/\u65b9\u5dee\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u5747\u503c-\u65b9\u5dee\u56e2\u961f\u968f\u673a\u535a\u5f08(MV-TSG)\uff0c\u63d0\u51fa\u5728\u5df2\u77e5\u6a21\u578b\u53c2\u6570\u4e0b\u7684\u5206\u5e03\u5f0f\u72ec\u7acb\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\uff1b\u5728\u672a\u77e5\u53c2\u6570\u65f6\uff0c\u63d0\u51fa\u57fa\u4e8e\u72ec\u7acb\u7b56\u7565\u68af\u5ea6\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4ee5\u5b9e\u73b0\u6570\u636e\u9a71\u52a8\u7684\u7b56\u7565\u4f18\u5316\u3002", "result": "\u7ed9\u51fa\u6536\u655b\u6027\u5206\u6790\uff1b\u901a\u8fc7\u4e24\u79cd\u573a\u666f\u7684\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u6240\u63d0\u51fa\u65b9\u6cd5\u5728\u5206\u5e03\u5f0f\u8ba1\u7b97\u73af\u5883\u4e0b\u6709\u6548\uff0c\u8fbe\u6210\u7ecf\u6d4e\u6027\u4e0e\u53ef\u9760\u6027\u4e4b\u95f4\u7684\u6298\u4e2d\u3002", "conclusion": "\u65b9\u6cd5\u5145\u5206\u5229\u7528MMS\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u80fd\u529b\uff0c\u63d0\u4f9b\u7ecf\u6d4e\u6027\u4e0e\u8fd0\u884c\u53ef\u9760\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u89e3\uff0c\u5177\u5907\u5728\u5927\u89c4\u6a21\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2511.21133", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.21133", "abs": "https://arxiv.org/abs/2511.21133", "authors": ["Xi Zhang", "Miguel Bernal", "Wei-Ning Lee"], "title": "2D Sparse Array Design via Reweighted L1 Second Order Cone Programming for 3D Ultrasound Imaging", "comment": null, "summary": "Two-dimensional (2D) fully-addressed arrays can conveniently realize three-dimensional (3D) ultrasound imaging while fully controlled such arrays usually demands thousands of independent channels, which is costly. Sparse array technique using stochastic optimization methods is one of promising techniques to reduce channel counts while due to the stochastic nature of these methods, the optimized results are usually unstable. In this work, we introduce a sparse array design approach that formulates the synthesis problem of sparse arrays as second-order cone programming (SOCP) and a re-weighted L1 technique is implemented to sequentially optimize the SOCP. Based on this method, an on-grid quasi-flatten side-lobe (Q-Flats) 2D sparse array with side-lobe level (SLL) no more than -21.26 dB and 252 activated elements is designed, which aims to achieve as high contrast performance as possible under the limits of resolution and maximum number of independent channels (i.e., 256). The imaging performance of the Q-Flats array was compared with those of a corresponding dense array (Dense), a Fermat spiral array (Spiral) and a spatially 50%-Tukey tapered spiral array (Spiral-Taper) using Field II simulations in a multi-angle steered diverging wave transmission scheme. It was demonstrated that the Dense achieved the best resolution and contrast and the Spiral-Taper the worst. The Q-Flats showed better resolution (about 3%) but slightly worse contrast than the Spiral. All the results indicate the re-weighted L1 SOCP method is a promising and flexible method for seeking trade-offs among resolution, contrast, and number of activated elements.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSOCP\u7684\u91cd\u52a0\u6743L1\u7a00\u758f\u9635\u5217\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e8c\u7ef4\u5168\u5b9a\u5411\u8d85\u58f0\u9635\u5217\u76843D\u6210\u50cf\uff0c\u5728256\u901a\u9053\u7ea6\u675f\u4e0b\u8bbe\u8ba1\u51fa252\u4e2a\u6fc0\u6d3b\u5143\u4ef6\u7684Q-Flats\u7a00\u758f\u9635\u5217\uff0c\u5b9e\u73b0\u5206\u8fa8\u7387\u4e0e\u5bf9\u6bd4\u5ea6\u7684\u6709\u6548\u6298\u8877\u3002", "motivation": "\u89e3\u51b3\u4e8c\u7ef4\u5168\u5b9a\u5411\u9635\u5217\u5728\u5b9e\u73b03D\u6210\u50cf\u65f6\u5bf9\u901a\u9053\u6570\u9700\u6c42\u8fc7\u9ad8\u7684\u95ee\u9898\uff0c\u540c\u65f6\u7f13\u89e3\u57fa\u4e8e\u968f\u673a\u5316\u7a00\u758f\u5316\u65b9\u6cd5\u9020\u6210\u7684\u7ed3\u679c\u4e0d\u7a33\u5b9a\u6027\uff1b\u9700\u8981\u9c81\u68d2\u4e14\u53ef\u63a7\u7684\u8bbe\u8ba1\u6846\u67b6\u3002", "method": "\u5c06\u7a00\u758f\u9635\u5217\u7efc\u5408\u95ee\u9898\u5efa\u6a21\u4e3a\u4e8c\u9636\u9525\u89c4\u5212\uff08SOCP\uff09\uff0c\u5e76\u7ed3\u5408\u91cd\u52a0\u6743L1\u7b56\u7565\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002\u8bbe\u8ba1\u51fa_on-grid_\u7684Q-Flats\u7a00\u758f\u9635\u5217\uff0cSLL\u2264-21.26 dB\uff0c252\u4e2a\u6d3b\u8dc3\u5143\u7d20\uff0c\u4e14\u53d7256\u901a\u9053\u4e0a\u9650\u7ea6\u675f\uff1b\u901a\u8fc7Field II\u5728\u591a\u89d2\u5ea6\u6247\u5f62\u53d1\u5c04\u573a\u666f\u4e2d\uff0c\u4e0eDense\u3001Spiral\u3001Spiral-Taper\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "Dense\u5728\u5206\u8fa8\u7387\u548c\u5bf9\u6bd4\u5ea6\u65b9\u9762\u6700\u4f73\uff1bSpiral-Taper\u6700\u5dee\u3002Q-Flats\u5728\u5206\u8fa8\u7387\u4e0a\u4f18\u4e8eSpiral\u7ea63%\uff0c\u5bf9\u6bd4\u5ea6\u7565\u5dee\u4e8eSpiral\uff0c\u4f46\u5728256\u901a\u9053\u7ea6\u675f\u5185\u5b9e\u73b0\u4e86\u8f83\u597d\u7684\u6298\u8877\u3002\u91cd\u52a0\u6743L1 SOCP\u65b9\u6cd5\u5bf9\u5206\u8fa8\u7387\u3001\u5bf9\u6bd4\u5ea6\u4e0e\u6d3b\u8dc3\u5143\u7d20\u6570\u4e4b\u95f4\u7684\u6743\u8861\u5177\u6709\u826f\u597d\u7075\u6d3b\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u91cd\u52a0\u6743L1 SOCP\u7a00\u758f\u8bbe\u8ba1\u65b9\u6cd5\u662f\u5b9e\u73b0\u7a00\u758f\u9635\u5217MIMO\u6210\u50cf\u7684\u6709\u524d\u666f\u7684\u3001\u7075\u6d3b\u7684\u5de5\u5177\uff0c\u53ef\u5728\u5206\u8fa8\u7387\u3001\u5bf9\u6bd4\u5ea6\u4e0e\u901a\u9053\u6570\u4e4b\u95f4\u53d6\u5f97\u6709\u6548\u6298\u8877\u3002"}}
{"id": "2511.20922", "categories": ["cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20922", "abs": "https://arxiv.org/abs/2511.20922", "authors": ["Guilin Zhang", "Wulan Guo", "Ziqi Tan", "Hongyang He", "Hailong Jiang"], "title": "Readout-Side Bypass for Residual Hybrid Quantum-Classical Models", "comment": "5 pages, 1 figure, 6 tables", "summary": "Quantum machine learning (QML) promises compact and expressive representations, but suffers from the measurement bottleneck - a narrow quantum-to-classical readout that limits performance and amplifies privacy risk. We propose a lightweight residual hybrid architecture that concatenates quantum features with raw inputs before classification, bypassing the bottleneck without increasing quantum complexity. Experiments show our model outperforms pure quantum and prior hybrid models in both centralized and federated settings. It achieves up to +55% accuracy improvement over quantum baselines, while retaining low communication cost and enhanced privacy robustness. Ablation studies confirm the effectiveness of the residual connection at the quantum-classical interface. Our method offers a practical, near-term pathway for integrating quantum models into privacy-sensitive, resource-constrained settings like federated edge learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u6b8b\u5dee\u6df7\u5408\u67b6\u6784\uff0c\u5c06\u91cf\u5b50\u7279\u5f81\u4e0e\u539f\u59cb\u8f93\u5165\u62fc\u63a5\u540e\u7528\u4e8e\u5206\u7c7b\uff0c\u4ee5\u7ed5\u8fc7\u91cf\u5b50\u6d4b\u91cf\u74f6\u9888\uff0c\u540c\u65f6\u4e0d\u589e\u52a0\u91cf\u5b50\u590d\u6742\u5ea6\u3002\u5b9e\u9a8c\u663e\u793a\u8be5\u6a21\u578b\u5728\u96c6\u4e2d\u5f0f\u548c\u8054\u90a6\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u5747\u4f18\u4e8e\u7eaf\u91cf\u5b50\u4e0e\u5148\u524d\u6df7\u5408\u6a21\u578b\uff0c\u63d0\u5347\u53ef\u8fbe\u7ea655%\u7684\u51c6\u786e\u7387\uff0c\u4e14\u901a\u4fe1\u6210\u672c\u8f83\u4f4e\u4e14\u9690\u79c1\u9c81\u68d2\u6027\u589e\u5f3a\u3002\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u91cf\u5b50-\u7ecf\u5178\u63a5\u53e3\u5904\u6b8b\u5dee\u8fde\u63a5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6d4b\u91cf\u74f6\u9888\u53ca\u7531\u6b64\u5e26\u6765\u7684\u9690\u79c1\u98ce\u9669\uff1b\u5728\u9690\u79c1\u654f\u611f\u3001\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\uff08\u5982\u8054\u90a6\u8fb9\u7f18\u5b66\u4e60\uff09\u5b9e\u73b0\u8fd1\u7aef\u53ef\u884c\u7684\u91cf\u5b50\u6a21\u578b\u96c6\u6210\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6b8b\u5dee\u6df7\u5408\u67b6\u6784\uff0c\u5728\u91cf\u5b50\u7279\u5f81\u4e0e\u539f\u59cb\u8f93\u5165\u4e4b\u95f4\u8fdb\u884c\u62fc\u63a5\u540e\u8fdb\u884c\u5206\u7c7b\uff0c\u4ece\u800c\u7ed5\u8fc7\u6d4b\u91cf\u74f6\u9888\u4e14\u4e0d\u589e\u52a0\u91cf\u5b50\u6bd4\u7279\u7684\u590d\u6742\u5ea6\u3002\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u6b8b\u5dee\u8fde\u63a5\u5728\u91cf\u5b50-\u7ecf\u5178\u754c\u9762\u7684\u4f5c\u7528\uff0c\u5e76\u5728\u96c6\u4e2d\u548c\u8054\u90a6\u5b66\u4e60\u573a\u666f\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u76f8\u8f83\u4e8e\u91cf\u5b50\u57fa\u7ebf\uff0c\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe\u7ea655%\uff1b\u4f18\u4e8e\u7eaf\u91cf\u5b50\u6a21\u578b\u548c\u65e9\u671f\u6df7\u5408\u6a21\u578b\uff1b\u5177\u6709\u4f4e\u901a\u4fe1\u6210\u672c\u4e0e\u589e\u5f3a\u7684\u9690\u79c1\u9c81\u68d2\u6027\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u91cf\u5b50-\u7ecf\u5178\u63a5\u53e3\u5904\u7684\u6b8b\u5dee\u8fde\u63a5\u6709\u6548\u3002", "conclusion": "\u4e3a\u5728\u9690\u79c1\u654f\u611f\u3001\u8d44\u6e90\u53d7\u9650\u7684\u573a\u666f\uff08\u5982\u8054\u90a6\u8fb9\u7f18\u5b66\u4e60\uff09\u4e2d\u5c06\u91cf\u5b50\u6a21\u578b\u843d\u5730\u63d0\u4f9b\u4e86\u73b0\u5b9e\u53ef\u884c\u8def\u5f84\uff0c\u5177\u6709\u4e2d\u671f\u53ef\u884c\u6027\u3002"}}
{"id": "2511.20713", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20713", "abs": "https://arxiv.org/abs/2511.20713", "authors": ["Minhui Zhang", "Prahar Ijner", "Yoav Wald", "Elliot Creager"], "title": "Active Slice Discovery in Large Language Models", "comment": "Accepted for presentation at NeurIPS 2025 - Reliable ML Workshop", "summary": "Large Language Models (LLMs) often exhibit systematic errors on specific subsets of data, known as error slices. For instance, a slice can correspond to a certain demographic, where a model does poorly in identifying toxic comments regarding that demographic. Identifying error slices is crucial to understanding and improving models, but it is also challenging. An appealing approach to reduce the amount of manual annotation required is to actively group errors that are likely to belong to the same slice, while using limited access to an annotator to verify whether the chosen samples share the same pattern of model mistake. In this paper, we formalize this approach as Active Slice Discovery and explore it empirically on a problem of discovering human-defined slices in toxicity classification. We examine the efficacy of active slice discovery under different choices of feature representations and active learning algorithms. On several slices, we find that uncertainty-based active learning algorithms are most effective, achieving competitive accuracy using 2-10% of the available slice membership information, while significantly outperforming baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e3b\u52a8\u5207\u7247\u53d1\u73b0\uff08Active Slice Discovery\uff09\u6765\u9ad8\u6548\u5730\u53d1\u73b0\u5e76\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u9519\u8bef\u5207\u7247\u4e0a\u7684\u6a21\u5f0f\uff0c\u964d\u4f4e\u624b\u52a8\u6807\u6ce8\u6210\u672c\u3002", "motivation": "LLMs\u5728\u67d0\u4e9b\u5b50\u96c6\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u9519\u8bef\uff08\u5982\u5bf9\u7279\u5b9a\u4eba\u7fa4\u7684\u6bd2\u6027\u8bc4\u8bba\u8bc6\u522b\u5dee\uff09\uff0c\u8bc6\u522b\u8fd9\u4e9b\u9519\u8bef\u5207\u7247\u5bf9\u7406\u89e3\u4e0e\u6539\u8fdb\u6a21\u578b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9010\u6761\u6807\u6ce8\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u6b64\u9700\u8981\u9ad8\u6548\u7684\u5206\u7ec4\u4e0e\u6709\u9650\u6807\u6ce8\u9a8c\u8bc1\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u9519\u8bef\u6837\u672c\u57fa\u4e8e\u7279\u5f81\u8868\u793a\u8fdb\u884c\u5206\u7ec4/\u805a\u7c7b\uff0c\u5e76\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u4e3a\u4e3b\u7684\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\u6311\u9009\u6837\u672c\uff0c\u7531\u6807\u6ce8\u8005\u9a8c\u8bc1\u6240\u9009\u6837\u672c\u662f\u5426\u5171\u4eab\u76f8\u540c\u7684\u9519\u8bef\u6a21\u5f0f\uff0c\u4ece\u800c\u5728\u6709\u9650\u7684\u4fe1\u606f\u4e0b\u53d1\u73b0\u540c\u4e00\u5207\u7247\u3002\u5bf9\u6bd2\u6027\u5206\u7c7b\u4e2d\u7684\u4eba\u5b9a\u4e49\u5207\u7247\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e0d\u540c\u8868\u793a\u4e0e\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5\u7684\u6548\u679c\u3002", "result": "\u5728\u82e5\u5e72\u5207\u7247\u4e0a\uff0c\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5\u6700\u6709\u6548\uff0c\u4f7f\u7528\u4ec52-10%\u7684\u5207\u7247\u6210\u5458\u4fe1\u606f\u5373\u53ef\u83b7\u5f97\u5177\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u4e3b\u52a8\u5207\u7247\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u4f4e\u6807\u6ce8\u6210\u672c\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u80fd\u5728\u8f83\u5c11\u6807\u7b7e\u4fe1\u606f\u4e0b\u8bc6\u522b\u5e76\u63cf\u8ff0\u6a21\u578b\u7684\u9519\u8bef\u5207\u7247\uff0c\u4fbf\u4e8e\u9488\u5bf9\u6027\u6539\u8fdb\u6a21\u578b\u3002"}}
{"id": "2511.20995", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20995", "abs": "https://arxiv.org/abs/2511.20995", "authors": ["Felix Biert\u00fcmpfel", "Bin Hu", "Geir Dullerud", "Peter Seiler"], "title": "An Exact, Finite Dimensional Representation for Full-Block, Circle Criterion Multipliers", "comment": null, "summary": "This paper provides the first finite-dimensional characterization for the complete set of full-block, circle criterion multipliers. We consider the interconnection of a discrete-time, linear time-invariant system in feedback with a non-repeated, sector-bounded nonlinearity. Sufficient conditions for stability and performance can be derived using: (i) dissipation inequalities, and (ii) Quadratic Constraints (QCs) that bound the input/output pairs of the nonlinearity. Larger classes of QCs (or multipliers) reduce the conservatism of the conditions. Full-block, circle criterion multipliers define the complete set of all possible QCs for non-repeated, sector-bounded nonlinearities. These provide the least conservative conditions. However, full-block multipliers are defined by an uncountably infinite number of constraints and hence do not lead to computationally tractable solutions if left in this raw form. This paper provides a new finite-dimensional characterization for the set of full-block, circle criterion multipliers. The key theoretical insight is: the set of all input/output pairs of non-repeated sector-bounded nonlinearities is equal to the set of all incremental pairs for an appropriately constructed piecewise linear function. Our new description for the complete set of multipliers only requires a finite number of matrix copositivity constraints. These conditions have an exact, computationally tractable implementation for problems where the nonlinearity has small input/output dimensions $(\\le 4)$. We illustrate the use of our new characterization via a simple example.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6709\u9650\u7ef4\u63cf\u8ff0\u96c6\u5408\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b8c\u6574\u7684\u5168\u5757\u5706\u5224\u522b\u4e58\u5b50\uff0c\u89e3\u51b3\u5168\u96c6\u5408\u9700\u65e0\u7a77\u591a\u7ea6\u675f\u7684\u95ee\u9898\u3002", "motivation": "\u5728\u79bb\u6563\u65f6\u95f4\u7ebf\u6027\u7cfb\u7edf\u4e0e\u76f8\u5206\u6bb5\u975e\u7ebf\u6027\u53cd\u9988\u4e2d\uff0c\u5706\u5224\u522b\u4e58\u5b50\u63d0\u4f9b\u7684\u7a33\u5b9a\u6027/\u6027\u80fd\u6761\u4ef6\u901a\u5e38\u53d7\u9650\u4e8e\u5168\u96c6\u5408\u7684\u4e0d\u53ef\u8ba1\u7b97\u6027\uff1b\u5b8c\u6574\u96c6\u5408\u7406\u8bba\u4e0a\u6700\u5c11\u4fdd\u5b88\uff0c\u4f46\u5b9e\u73b0\u56f0\u96be\u3002", "method": "\u5c06\u5168\u5757\u5706\u5224\u522b\u4e58\u5b50\u4e0e\u975e\u91cd\u590d\u7684 sector-bounded \u975e\u7ebf\u6027\u8f93\u5165\u8f93\u51fa\u5bf9\u7684\u96c6\u5408\u7b49\u4ef7\u4e3a\u4e00\u4e2a\u589e\u91cf\u5bf9\u96c6\u5408\uff0c\u5e76\u5f15\u5165\u4e00\u4e2a\u9488\u5bf9\u5206\u6bb5\u7ebf\u6027\u51fd\u6570\u7684\u6784\u9020\u4ee5\u5b9e\u73b0\u6709\u9650\u7ef4\u63cf\u8ff0\uff1b\u901a\u8fc7\u6709\u9650\u4e2a\u77e9\u9635\u5171\u6b63\u6027\u7ea6\u675f\u6765\u523b\u753b\u8be5\u96c6\u5408\u3002", "result": "\u7ed9\u51fa\u53ef\u8ba1\u7b97\u7684\u5224\u636e\uff0c\u5f53\u975e\u7ebf\u6027\u8f93\u5165\u8f93\u51fa\u7ef4\u5ea6\u8f83\u5c0f\u65f6\uff08\u22644\uff09\u53ef\u5b9e\u73b0\u7cbe\u786e\u63cf\u8ff0\uff1b\u63d0\u4f9b\u4e00\u4e2a\u7b80\u5355\u793a\u4f8b\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u65e0\u635f\u4e14\u53ef\u5b9e\u73b0\u7684\u6709\u9650\u7ef4\u63cf\u8ff0\uff0c\u964d\u4f4e\u5168\u5757\u5706\u5224\u522b\u4e58\u5b50\u5728\u5b9e\u9645\u95ee\u9898\u4e2d\u7684\u4fdd\u5b88\u6027\u4e0e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u9002\u7528\u4e8e\u5c0f\u7ef4\u975e\u7ebf\u6027\u8f93\u5165\u8f93\u51fa\u573a\u666f\u3002"}}
{"id": "2511.21274", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21274", "abs": "https://arxiv.org/abs/2511.21274", "authors": ["Junhui Rao", "Yi Liu", "Jichen Zhang", "Zhaoyang Ming", "Tianrui Qiao", "Yujie Zhang", "Chi Yuk Chiu", "Hua Wang", "Ross Murch"], "title": "Multiport Analytical Pixel Electromagnetic Simulator (MAPES) for AI-assisted RFIC and Microwave Circuit Design", "comment": null, "summary": "This paper proposes a novel analytical framework, termed the Multiport Analytical Pixel Electromagnetic Simulator (MAPES). MAPES enables efficient and accurate prediction of the electromagnetic (EM) performance of arbitrary pixel-based microwave (MW) and RFIC structures. Inspired by the Integrated Internal Multiport Method (IMPM), MAPES extends the concept to the pixel presence/absence domain used in AI-assisted EM design. By introducing virtual pixels and diagonal virtual pixels and inserting virtual ports at critical positions, MAPES captures all horizontal, vertical, and diagonal electromagnetic couplings within a single multiport impedance matrix. Only a small set of full-wave simulations (typically about 1% of the datasets required by AI-assisted EM simulators) is needed to construct this matrix. Subsequently, any arbitrary pixel configuration can be evaluated analytically using a closed-form multiport relation without additional full-wave calculations. The proposed approach eliminates data-driven overfitting and ensures accurate results across all design variations. Comprehensive examples for single- and double-layer CMOS processes (180 nm and 65 nm) and PCBs confirm that MAPES achieves high prediction accuracy with 600- 2000x speed improvement compared to CST simulations. Owing to its efficiency, scalability and reliability, MAPES provides a practical and versatile tool for AI-assisted MW circuit and RFIC design across diverse fabrication technologies.", "AI": {"tldr": "MAPES is a physics-based analytical framework that predicts EM performance of pixel-based MW/RFIC structures with high accuracy and huge speed gains by constructing a single multiport impedance matrix from a small set of full-wave simulations and then evaluating any pixel configuration analytically.", "motivation": "There is a need for fast, accurate, and generalizable EM prediction for pixel-based designs in AI-assisted EM design, where data-driven methods suffer from overfitting and computational cost is high.", "method": "MAPES extends the Integrated Internal Multiport Method (IMPM) to the pixel presence/absence domain by introducing virtual pixels and diagonal virtual pixels and inserting virtual ports at critical locations. This creates a single multiport impedance matrix that captures horizontal, vertical, and diagonal couplings. Only a small set of full-wave simulations (about 1% of what typical AI-assisted EM simulators require) are required to populate the matrix. Any arbitrary pixel configuration can then be evaluated analytically via a closed-form multiport relation without further full-wave computations.", "result": "MAPES delivers high prediction accuracy with 600\u20132000\u00d7 speed-up compared to CST simulations, validated on single- and double-layer CMOS processes (180 nm and 65 nm) and PCBs, demonstrating efficiency, scalability, and reliability for AI-assisted MW circuit and RFIC design across technologies.", "conclusion": "MAPES provides a practical and versatile tool for AI-assisted microwave and RFIC design, offering fast, accurate EM predictions across diverse fabrication technologies while avoiding data-driven overfitting."}}
{"id": "2511.21340", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21340", "abs": "https://arxiv.org/abs/2511.21340", "authors": ["Chin-Hung Chen", "Ivana Nikoloska", "Wim van Houtum", "Yan Wu", "Alex Alvarado"], "title": "Phase-Aware Code-Aided EM Algorithm for Blind Channel Estimation in PSK-Modulated OFDM", "comment": "preprint", "summary": "This paper presents a fully blind phase-aware expectation-maximization (EM) algorithm for OFDM systems with the phase-shift keying (PSK) modulation. We address the well-known local maximum problem of the EM algorithm for blind channel estimation. This is primarily caused by the unknown phase ambiguity in the channel estimates, which conventional blind EM estimators cannot resolve. To overcome this limitation, we propose to exploit the extrinsic information from the decoder as model evidence metrics. A finite set of candidate models is generated based on the inherent symmetries of PSK modulation, and the decoder selects the most likely candidate model. Simulation results demonstrate that, when combined with a simple convolutional code, the phase-aware EM algorithm reliably resolves phase ambiguity during the initialization stage and reduces the local convergence rate from 80% to nearly 0% in frequency-selective channels with a constant phase ambiguity. The algorithm is invoked only once after the EM initialization stage, resulting in negligible additional complexity during subsequent turbo iterations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u76f2\u7684\u76f8\u4f4d\u611f\u77e5EM\u7b97\u6cd5\u7528\u4e8ePSK\u8c03\u5236\u7684OFDM\u7cfb\u7edf\uff0c\u901a\u8fc7\u5229\u7528\u89e3\u7801\u5668\u7684\u5916\u90e8\u4fe1\u606f\u4f5c\u4e3a\u6a21\u578b\u8bc1\u636e\uff0c\u5e76\u57fa\u4e8ePSK\u5bf9\u79f0\u6027\u6784\u5efa\u6709\u9650\u5019\u9009\u6a21\u578b\u96c6\u5408\uff0c\u9009\u62e9\u6700\u53ef\u80fd\u7684\u6a21\u578b\u6765\u89e3\u51b3\u76f8\u4f4d\u6a21\u7cca\u95ee\u9898\uff0c\u4e14\u521d\u59cb\u5316\u9636\u6bb5\u4ec5\u8c03\u7528\u4e00\u6b21\uff0c\u540e\u7eed turbo \u8fed\u4ee3\u7684\u989d\u5916\u590d\u6742\u5ea6\u5f88\u5c0f\u3002", "motivation": "\u76f2\u4fe1\u9053\u4f30\u8ba1\u4e2d\u7684\u76f8\u4f4d\u6a21\u7cca\u5bfc\u81f4\u5c40\u90e8\u6781\u5927\u503c\u95ee\u9898\uff0c\u4f20\u7edf\u76f2EM\u96be\u4ee5\u6d88\u9664\u76f8\u4f4d\u6b67\u4e49\uff0c\u4ece\u800c\u5f71\u54cd\u6536\u655b\u6027\u548c\u4f30\u8ba1\u8d28\u91cf\u3002\u9700\u8981\u4e00\u79cd\u673a\u5236\u5728\u521d\u59cb\u5316\u9636\u6bb5\u4ee5\u53ca\u540e\u7eed\u8fed\u4ee3\u4e2d\u6709\u6548\u89e3\u9664\u76f8\u4f4d\u6b67\u4e49\u5e76\u4fdd\u6301\u8f83\u4f4e\u590d\u6742\u5ea6\u3002", "method": "\u5728EM\u6846\u67b6\u4e2d\u5f15\u5165\u6765\u81ea\u89e3\u7801\u5668\u7684\u5916\u90e8\u4fe1\u606f\uff0c\u5c06PSK\u8c03\u5236\u7684\u5bf9\u79f0\u6027\u8f6c\u5316\u4e3a\u6709\u9650\u7684\u5019\u9009\u6a21\u578b\u96c6\u5408\uff1b\u901a\u8fc7\u89e3\u7801\u5668\u5bf9\u8fd9\u4e9b\u5019\u9009\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\uff0c\u9009\u53d6\u6700\u53ef\u80fd\u7684\u6a21\u578b\u4ee5\u6d88\u9664\u76f8\u4f4d\u6b67\u4e49\uff0c\u5e76\u5728EM\u521d\u59cb\u5316\u540e\u8fdb\u884c\u4e00\u6b21\u6027\u8c03\u7528\uff0c\u540e\u7eed turbo \u8fed\u4ee3\u7684\u989d\u5916\u590d\u6742\u5ea6\u57fa\u672c\u53ef\u5ffd\u7565\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff1a\u7ed3\u5408\u7b80\u5355\u5377\u79ef\u7801\u65f6\uff0c\u8be5\u76f8\u4f4d\u611f\u77e5EM\u7b97\u6cd5\u5728\u521d\u59cb\u5316\u9636\u6bb5\u5c31\u80fd\u7a33\u5b9a\u89e3\u51b3\u76f8\u4f4d\u6b67\u4e49\uff0c\u5c40\u90e8\u6536\u655b\u5931\u8d25\u7387\u753180%\u964d\u81f3\u63a5\u8fd10%\uff1b\u5728\u5177\u6709\u9891\u7387\u9009\u62e9\u6027\u7684\u4fe1\u9053\u4e14\u76f8\u4f4d\u6052\u5b9a\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u540e\u7eed turbo \u8fed\u4ee3\u4e2d\u7684\u989d\u5916\u590d\u6742\u5ea6\u51e0\u4e4e\u53ef\u4ee5\u5ffd\u7565\u3002", "conclusion": "\u901a\u8fc7\u57fa\u4e8ePSK\u5bf9\u79f0\u6027\u7684\u5019\u9009\u6a21\u578b\u4ee5\u53ca\u89e3\u7801\u5668\u8bc1\u636e\u7684\u7ed3\u5408\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u6d88\u9664\u4e86\u76f2\u4fe1\u9053\u4f30\u8ba1\u4e2d\u7684\u76f8\u4f4d\u6a21\u7cca\u95ee\u9898\uff0c\u63d0\u5347\u4e86OFDM\u7684\u76f2\u4fe1\u9053\u4f30\u8ba1\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2511.21180", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21180", "abs": "https://arxiv.org/abs/2511.21180", "authors": ["Shuhan Xia", "Jing Dai", "Hui Ouyang", "Yadong Shang", "Dongxiao Zhao", "Peipei Li"], "title": "CAHS-Attack: CLIP-Aware Heuristic Search Attack Method for Stable Diffusion", "comment": null, "summary": "Diffusion models exhibit notable fragility when faced with adversarial prompts, and strengthening attack capabilities is crucial for uncovering such vulnerabilities and building more robust generative systems. Existing works often rely on white-box access to model gradients or hand-crafted prompt engineering, which is infeasible in real-world deployments due to restricted access or poor attack effect. In this paper, we propose CAHS-Attack , a CLIP-Aware Heuristic Search attack method. CAHS-Attack integrates Monte Carlo Tree Search (MCTS) to perform fine-grained suffix optimization, leveraging a constrained genetic algorithm to preselect high-potential adversarial prompts as root nodes, and retaining the most semantically disruptive outcome at each simulation rollout for efficient local search. Extensive experiments demonstrate that our method achieves state-of-the-art attack performance across both short and long prompts of varying semantics. Furthermore, we find that the fragility of SD models can be attributed to the inherent vulnerability of their CLIP-based text encoders, suggesting a fundamental security risk in current text-to-image pipelines.", "AI": {"tldr": "\u63d0\u51fa CAHS-Attack\uff0c\u4e00\u79cd\u7ed3\u5408 MCTS \u7684 CLIP \u9a71\u52a8\u542f\u53d1\u5f0f\u641c\u7d22\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u57fa\u56e0\u7b97\u6cd5\u9884\u9009\u6839\u8282\u70b9\u5e76\u5728 rollout \u8fc7\u7a0b\u4fdd\u7559\u8bed\u4e49\u7834\u574f\u6027\u6700\u5f3a\u7684\u7ed3\u679c\uff0c\u4ee5\u5b9e\u73b0\u5bf9\u6269\u6563\u6a21\u578b\u7684\u9ad8\u6548\u653b\u51fb\uff0c\u8fbe\u5230\u65b0\u9ad8\u7684\u653b\u51fb\u6548\u679c\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5bf9\u5bf9\u6297\u63d0\u793a\u7684\u6613\u8106\u5f31\u6027\uff0c\u73b0\u6709\u9ed1\u767d\u76d2\u653b\u51fb\u5728\u73b0\u5b9e\u573a\u666f\u53d7\u9650\uff0c\u8feb\u5207\u9700\u8981\u66f4\u5f3a\u7684\u3001\u53ef\u6269\u5c55\u7684\u65e0\u906e\u6321\u653b\u51fb\u65b9\u6cd5\uff1b\u540c\u65f6\u63ed\u793a CLIP \u6587\u672c\u7f16\u7801\u5668\u5728\u6587\u672c-\u56fe\u50cf\u5bf9\u9f50\u4e2d\u7684\u5b89\u5168\u9690\u60a3\u3002", "method": "\u5c06\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7528\u4e8e\u5bf9\u6297\u63d0\u793a\u7684\u7ec6\u7c92\u5ea6\u540e\u7f00\u4f18\u5316\uff0c\u5229\u7528\u53d7\u9650\u7684\u9057\u4f20\u7b97\u6cd5\u5728\u6839\u8282\u70b9\u4e0a\u8fdb\u884c\u521d\u9009\uff0c\u4e14\u5728\u6bcf\u6b21\u4eff\u771f rollout \u4e2d\u9009\u53d6\u8bed\u4e49\u7834\u574f\u6027\u6700\u5f3a\u7684\u7ed3\u679c\u7528\u4e8e\u5c40\u90e8\u641c\u7d22\u3002", "result": "\u5728\u77ed\u957f\u63d0\u793a\u3001\u4e0d\u540c\u8bed\u4e49\u5c42\u7ea7\u7684\u8bbe\u5b9a\u4e0b\uff0c\u8fbe\u5230\u6216\u8d85\u8fc7\u73b0\u6709\u65b9\u6cd5\u7684\u653b\u51fb\u6027\u80fd\uff0c\u663e\u793a\u51fa state-of-the-art \u7684\u653b\u51fb\u6548\u679c\u3002", "conclusion": "SD \u6a21\u578b\u7684\u8106\u5f31\u6027\u53ef\u5f52\u56e0\u4e8e\u5176 CLIP \u57fa\u6587\u672c\u7f16\u7801\u7684\u56fa\u6709\u8106\u5f31\u6027\uff0c\u63ed\u793a\u5f53\u524d text-to-image \u6d41\u7a0b\u4e2d\u7684\u6839\u672c\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2511.20725", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20725", "abs": "https://arxiv.org/abs/2511.20725", "authors": ["Deng Fucheng", "Wang Wanjie", "Gong Ao", "Wang Xiaoqi", "Wang Fan"], "title": "Gradient Descent Algorithm Survey", "comment": null, "summary": "Focusing on the practical configuration needs of optimization algorithms in deep learning, this article concentrates on five major algorithms: SGD, Mini-batch SGD, Momentum, Adam, and Lion. It systematically analyzes the core advantages, limitations, and key practical recommendations of each algorithm. The research aims to gain an in-depth understanding of these algorithms and provide a standardized reference for the reasonable selection, parameter tuning, and performance improvement of optimization algorithms in both academic research and engineering practice, helping to solve optimization challenges in different scales of models and various training scenarios.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4e94\u79cd\u4e3b\u6d41\u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\uff08SGD\u3001Mini-batch SGD\u3001Momentum\u3001Adam\u3001Lion\uff09\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u63ed\u793a\u5176\u6838\u5fc3\u4f18\u70b9\u3001\u5c40\u9650\u4e0e\u53ef\u64cd\u4f5c\u7684\u5b9e\u7528\u5efa\u8bae\uff0c\u65e8\u5728\u4e3a\u5b66\u672f\u7814\u7a76\u4e0e\u5de5\u7a0b\u5b9e\u8df5\u63d0\u4f9b\u7edf\u4e00\u7684\u53c2\u6570\u8c03\u4f18\u4e0e\u7b97\u6cd5\u9009\u62e9\u53c2\u8003\u3002", "motivation": "\u5728\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u4e2d\uff0c\u5982\u4f55\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u548c\u591a\u6837\u5316\u8bad\u7ec3\u573a\u666f\u4e2d\u9009\u62e9\u5408\u9002\u7684\u4f18\u5316\u7b97\u6cd5\u5e76\u8fdb\u884c\u6709\u6548\u8c03\u53c2\uff0c\u662f\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u5173\u952e\u96be\u9898\u3002\u672c\u6587\u901a\u8fc7\u5bf9\u5e38\u7528\u4f18\u5316\u7b97\u6cd5\u7684\u7cfb\u7edf\u68b3\u7406\uff0c\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6307\u5357\u4e0e\u5bf9\u6bd4\u5206\u6790\u3002", "method": "\u901a\u8fc7\u5bf9\u4e94\u79cd\u4f18\u5316\u7b97\u6cd5\u7684\u6838\u5fc3\u7279\u6027\u3001\u4f18\u7f3a\u70b9\u548c\u5b9e\u9645\u5e94\u7528\u8981\u70b9\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u7ed3\u5408\u7406\u8bba\u56de\u987e\u4e0e\u5b9e\u8bc1\u89c2\u5bdf\uff0c\u63d0\u51fa\u9488\u5bf9\u4e0d\u540c\u573a\u666f\u7684\u53c2\u6570\u8c03\u4f18\u7b56\u7565\u4e0e\u4f7f\u7528\u5efa\u8bae\u3002", "result": "\u7ed9\u51fa\u4e94\u79cd\u7b97\u6cd5\u7684\u4f18\u7f3a\u70b9\u6e05\u5355\u3001\u91cd\u8981\u8d85\u53c2\u6570\u7684\u8c03\u4f18\u8981\u70b9\u3001\u5e38\u89c1\u9677\u9631\u53ca\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0e\u8bad\u7ec3\u573a\u666f\u4e2d\u7684\u63a8\u8350\u4f7f\u7528\u7b56\u7565\uff0c\u5f62\u6210\u53ef\u4f9b\u53c2\u8003\u7684\u6807\u51c6\u5316\u6846\u67b6\u3002", "conclusion": "\u5e0c\u671b\u4e3a\u7814\u7a76\u8005\u548c\u5de5\u7a0b\u5e08\u5728\u6a21\u578b\u89c4\u6a21\u4e0e\u8bad\u7ec3\u573a\u666f\u591a\u6837\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u505a\u51fa\u66f4\u5408\u7406\u7684\u7b97\u6cd5\u9009\u62e9\u4e0e\u53c2\u6570\u8bbe\u7f6e\uff0c\u4ece\u800c\u63d0\u5347\u4f18\u5316\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2511.21216", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.21216", "abs": "https://arxiv.org/abs/2511.21216", "authors": ["Fangming Shi", "Li Li", "Kejiang Chen", "Guorui Feng", "Xinpeng Zhang"], "title": "AuthenLoRA: Entangling Stylization with Imperceptible Watermarks for Copyright-Secure LoRA Adapters", "comment": "16 pages, 7 figures, 12 tables", "summary": "Low-Rank Adaptation (LoRA) offers an efficient paradigm for customizing diffusion models, but its ease of redistribution raises concerns over unauthorized use and the generation of untraceable content. Existing watermarking techniques either target base models or verify LoRA modules themselves, yet they fail to propagate watermarks to generated images, leaving a critical gap in traceability. Moreover, traceability watermarking designed for base models is not tightly coupled with stylization and often introduces visual degradation or high false-positive detection rates. To address these limitations, we propose AuthenLoRA, a unified watermarking framework that embeds imperceptible, traceable watermarks directly into the LoRA training process while preserving stylization quality. AuthenLoRA employs a dual-objective optimization strategy that jointly learns the target style distribution and the watermark-induced distribution shift, ensuring that any image generated with the watermarked LoRA reliably carries the watermark. We further design an expanded LoRA architecture for enhanced multi-scale adaptation and introduce a zero-message regularization mechanism that substantially reduces false positives during watermark verification. Extensive experiments demonstrate that AuthenLoRA achieves high-fidelity stylization, robust watermark propagation, and significantly lower false-positive rates compared with existing approaches. Open-source implementation is available at: https://github.com/ShiFangming0823/AuthenLoRA", "AI": {"tldr": "\u5728 LoRA \u5fae\u8c03\u7684\u6269\u6563\u6a21\u578b\u4e2d\uff0c\u63d0\u51fa AuthenLoRA\uff0c\u5c06\u6c34\u5370\u5d4c\u5165\u8bad\u7ec3\u9636\u6bb5\uff0c\u786e\u4fdd\u751f\u6210\u56fe\u50cf\u643a\u5e26\u53ef\u8ffd\u6eaf\u6c34\u5370\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u4fdd\u771f\u98ce\u683c\u5316\u548c\u4f4e\u8bef\u68c0\u7387\u3002", "motivation": "\u89e3\u51b3 LoRA \u6c34\u5370\u7684\u4f20\u64ad\u4e0e\u8ffd\u6eaf\u7f3a\u9677\uff1a\u73b0\u6709\u6c34\u5370\u8981\u4e48\u5d4c\u5165\u57fa\u6a21\u578b\u3001\u8981\u4e48\u4ec5\u9a8c\u8bc1 LoRA \u6a21\u5757\uff0c\u672a\u80fd\u4e0e\u751f\u6210\u56fe\u50cf\u6301\u7eed\u8026\u5408\uff0c\u4e14\u57fa\u4e8e\u98ce\u683c\u5316\u7684\u6c34\u5370\u6613\u5f15\u5165\u89c6\u89c9\u635f\u4f24\u6216\u9ad8\u5047\u9633\u6027\uff0c\u9700\u8981\u5728\u4fdd\u6301 stylization \u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u53ef\u9760\u6eaf\u6e90\u3002", "method": "\u63d0\u51fa\u53cc\u76ee\u6807\u4f18\u5316\uff0c\u8054\u5408\u5b66\u4e60\u76ee\u6807\u98ce\u683c\u5206\u5e03\u4e0e\u6c34\u5370\u8bf1\u5bfc\u7684\u5206\u5e03\u6f02\u79fb\uff1b\u6269\u5c55 LoRA \u67b6\u6784\u4ee5\u5b9e\u73b0\u591a\u5c3a\u5ea6\u81ea\u9002\u5e94\uff1b\u5f15\u5165\u96f6\u4fe1\u606f\u6b63\u5219\u5316\u4ee5\u663e\u8457\u964d\u4f4e\u6c34\u5370\u9a8c\u8bc1\u7684\u8bef\u62a5\uff1b\u5728 LoRA \u7684\u8bad\u7ec3\u6d41\u7a0b\u4e2d\u5d4c\u5165\u6c34\u5370\u673a\u5236\u5e76\u5b9e\u73b0\u5bf9\u751f\u6210\u56fe\u50cf\u7684\u6c34\u5370\u4f20\u64ad\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5728\u4fdd\u6301\u9ad8\u4fdd\u771f\u98ce\u683c\u5316\u7684\u540c\u65f6\uff0c\u6c34\u5370\u4f20\u64ad\u9c81\u68d2\u3001\u9a8c\u8bc1\u8bef\u62a5\u7387\u663e\u8457\u4f4e\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5177\u5907\u826f\u597d\u7684\u53ef\u6eaf\u6027\u3002", "conclusion": "AuthenLoRA \u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u4e14\u53ef\u5f00\u6e90\u7684\u6c34\u5370\u6846\u67b6\uff0c\u80fd\u5728 LoRA \u5fae\u8c03\u7684\u6269\u6563\u6a21\u578b\u4e2d\u5b9e\u73b0\u53ef\u8ffd\u6eaf\u7684\u6c34\u5370\u4f20\u64ad\uff0c\u5e76\u517c\u987e\u98ce\u683c\u5316\u8d28\u91cf\u4e0e\u8bef\u68c0\u63a7\u5236\u3002"}}
{"id": "2511.21255", "categories": ["eess.SY", "cs.RO", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.21255", "abs": "https://arxiv.org/abs/2511.21255", "authors": ["Jewel Benny", "Pranjal Mahajan", "Srayan Sankar Chatterjee", "Mohd Wajid", "Abhishek Srivastava"], "title": "Design and Measurements of mmWave FMCW Radar Based Non-Contact Multi-Patient Heart Rate and Breath Rate Monitoring System", "comment": "Presented at BioCAS 2023", "summary": "Recent developments in mmWave radar technologies have enabled the truly non-contact heart-rate (HR) and breath-rate (BR) measurement approaches, which provides a great ease in patient monitoring. Additionally, these technologies also provide opportunities to simultaneously detect HR and BR of multiple patients, which has become increasingly important for efficient mass monitoring scenarios. In this work, a frequency modulated continuous wave (FMCW) mmWave radar based truly non-contact multiple patient HR and BR monitoring system has been presented. Furthermore, a novel approach is also proposed, which combines multiple processing methods using a least squares solution to improve measurement accuracy, generalization, and handle measurement error. The proposed system has been developed using Texas Instruments' FMCW radar and experimental results with multiple subjects are also presented, which show >97% and >93% accuracy in the measured BR and HR values, respectively.", "AI": {"tldr": "\u57fa\u4e8eFMCW\u6beb\u7c73\u6ce2\u96f7\u8fbe\u7684\u591a\u4eba\u5458\u975e\u63a5\u89e6\u5fc3\u7387/\u547c\u5438\u7387\u76d1\u6d4b\uff0c\u7ed3\u5408\u6700\u5c0f\u4e8c\u4e58\u878d\u5408\u4ee5\u63d0\u5347\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027", "motivation": "\u5728\u65e0\u63a5\u89e6\u3001\u53ef\u7528\u4e8e\u5927\u89c4\u6a21\u76d1\u6d4b\u573a\u666f\u7684\u9700\u6c42\u80cc\u666f\u4e0b\uff0c\u53d1\u5c55\u80fd\u591f\u540c\u65f6\u5bf9\u591a\u540d\u60a3\u8005\u6d4b\u91cfHR\u548cBR\u7684\u5feb\u901f\u3001\u9c81\u68d2\u7cfb\u7edf", "method": "\u91c7\u7528Texas Instruments\u7684FMCW\u6beb\u7c73\u6ce2\u96f7\u8fbe\uff0c\u63d0\u51fa\u5c06\u591a\u79cd\u5904\u7406\u65b9\u6cd5\u901a\u8fc7\u6700\u5c0f\u4e8c\u4e58\u89e3\u7ec4\u5408\u4ee5\u63d0\u9ad8\u6d4b\u91cf\u51c6\u786e\u6027\u4e0e\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5b9e\u73b0\u591a\u60a3\u8005\u5e76\u884c\u76d1\u6d4b", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0cBR\u6d4b\u91cf\u51c6\u786e\u5ea6>97%\uff0cHR\u6d4b\u91cf\u51c6\u786e\u5ea6>93%\uff0c\u5e76\u7ed9\u51fa\u5bf9\u7cbe\u5ea6\u3001\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u7684\u63d0\u5347\u63cf\u8ff0", "conclusion": "\u6240\u63d0\u51fa\u7684\u7cfb\u7edf\u5728\u591a\u60a3\u8005\u975e\u63a5\u89e6\u76d1\u6d4b\u65b9\u9762\u5177\u6709\u53ef\u884c\u6027\u548c\u9ad8\u51c6\u786e\u6027\uff0c\u4e14\u6700\u5c0f\u4e8c\u4e58\u878d\u5408\u63d0\u5347\u4e86\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u76d1\u6d4b\u573a\u666f"}}
{"id": "2511.20729", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20729", "abs": "https://arxiv.org/abs/2511.20729", "authors": ["Sean Bin Yang", "Ying Sun", "Yunyao Cheng", "Yan Lin", "Kristian Torp", "Jilin Hu"], "title": "Spatio-Temporal Trajectory Foundation Model - Recent Advances and Future Directions", "comment": "This paper has been accepted by CIKM 2025 STIntelligence Workshop", "summary": "Foundation models (FMs) have emerged as a powerful paradigm, enabling a diverse range of data analytics and knowledge discovery tasks across scientific fields. Inspired by the success of FMs, particularly large language models, researchers have recently begun to explore spatio-temporal foundation models (STFMs) to improve adaptability and generalization across a wide spectrum of spatio-temporal (ST) tasks. Despite rapid progress, a systematic investigation of trajectory foundation models (TFMs), a crucial subclass of STFMs, is largely lacking. This tutorial addresses this gap by offering a comprehensive overview of recent advances in TFMs, including a taxonomy of existing methodologies and a critical analysis of their strengths and limitations. In addition, the tutorial highlights open challenges and outlines promising research directions to advance spatio-temporal general intelligence through the development of robust, responsible, and transferable TFMs.", "AI": {"tldr": "\u672c\u7814\u7a76/\u6559\u7a0b\u5bf9\u8f68\u8ff9\u57fa\u7840\u6a21\u578b\uff08TFMs\uff09\u5728\u65f6\u7a7a\u57fa\u7840\u6a21\u578b\uff08STFMs\uff09\u6846\u67b6\u5185\u8fdb\u884c\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u7ed9\u51fa\u65b9\u6cd5\u5b66\u7684\u5206\u7c7b\u3001\u4f18\u7f3a\u70b9\u7684\u6279\u5224\u6027\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u9762\u5411\u9c81\u68d2\u3001\u53ef\u8fc1\u79fb\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u63a8\u52a8\u65f6\u7a7a\u901a\u7528\u667a\u80fd\u7684\u53d1\u5c55\u3002", "motivation": "\u5c3d\u7ba1STFMs\u7814\u7a76\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u9488\u5bf9TFMs\u8fd9\u4e00\u91cd\u8981\u5b50\u7c7b\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u4ecd\u7136\u7f3a\u4e4f\u3002\u9700\u8981\u5bf9\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u5206\u7c7b\u68b3\u7406\u3001\u4f18\u7f3a\u70b9\u8bc4\u4f30\uff0c\u5e76\u63ed\u793a\u5173\u952e\u6311\u6218\u4e0e\u7814\u7a76\u673a\u4f1a\uff0c\u4ee5\u63d0\u9ad8TFMs\u5728\u5e7f\u57df\u65f6\u7a7a\u4efb\u52a1\u4e2d\u7684\u9002\u5e94\u6027\u548c\u8fc1\u79fb\u6027\u3002", "method": "\u63d0\u4f9b\u5bf9\u73b0\u6709TFMs\u7684\u5206\ub958\uff08taxonomy\uff09\uff0c\u5bf9\u5176\u4f18\u7f3a\u70b9\u8fdb\u884c\u6279\u5224\u6027\u5206\u6790\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u603b\u7ed3\u5f00\u653e\u6027\u6311\u6218\uff0c\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u7684\u8def\u7ebf\u56fe\u4e0e\u7814\u7a76\u8bae\u9898\u3002", "result": "\u7ed9\u51fa\u5bf9TFMs\u9886\u57df\u7684\u5168\u9762\u7efc\u8ff0\u4e0e\u5206\u7c7b\u6846\u67b6\uff0c\u660e\u786e\u5404\u65b9\u6cd5\u7684\u4f18\u70b9\u4e0e\u5c40\u9650\u6027\uff0c\u8bc6\u522b\u5c1a\u5f85\u89e3\u51b3\u7684\u6311\u6218\uff0c\u52fe\u52d2\u63a8\u52a8\u9c81\u68d2\u3001\u53ef\u8f6c\u79fb\u7684\u65f6\u7a7a\u901a\u7528\u667a\u80fd\u7684\u53d1\u5c55\u8def\u5f84\u3002", "conclusion": "TFMs\u662f\u63a8\u52a8\u65f6\u7a7a\u901a\u7528\u667a\u80fd\u7684\u91cd\u8981\u5de5\u5177\uff0c\u9700\u8fdb\u4e00\u6b65\u5b8c\u5584\u9c81\u68d2\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u8d23\u4efb\u6027\u4e0e\u53ef\u8fc1\u79fb\u6027\uff0c\u540c\u65f6\u52a0\u5f3a\u5bf9\u6570\u636e\u4f26\u7406\u4e0e\u98ce\u9669\u7684\u8003\u91cf\uff0c\u624d\u80fd\u5728\u5e7f\u6cdb\u7684\u65f6\u7a7a\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6709\u6548\u5e94\u7528\u3002"}}
{"id": "2511.21269", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21269", "abs": "https://arxiv.org/abs/2511.21269", "authors": ["Jinhui Chen", "Huadong Sun", "Ping Wu", "Baocai Wang", "Bing Zhao"], "title": "Response-Based Frequency Stability Assessment under Multi-Scale Disturbances in High-Renewable Power Systems", "comment": "10 pages, 13 figures", "summary": "In high-renewable power systems, active-power disturbances are becoming larger and exhibit increasingly diverse time scales, which complicates frequency stability assessment under unanticipated events. This paper presents a response-based frequency stability assessment method that uses disturbance power, inferred from generator electrical responses, to provide a unified treatment of multi-scale disturbances. Unanticipated disturbances are first classified into short-term and permanent events; permanent disturbances are further divided into step, second-level slope and minute-level slope disturbances. Based on the measured power responses of generator groups, a unified disturbance-power model is constructed to identify the disturbance type online and to quantify disturbance intensity through the disturbance power and its rate of change. Analytical frequency-response models are then derived for each disturbance class. For step disturbances, the maximum tolerable disturbance power is obtained under steady-state and transient frequency deviation constraints, and a safety-margin index is defined. For slope-type disturbances, an improved system frequency response (SFR) model and the rotor motion equation after exhaustion of primary frequency regulation are used to compute the over-limit time of frequency deviation. The proposed response-based assessment method is validated on the CSEE-FS frequency-stability benchmark system, demonstrating its effectiveness and accuracy for quantitative frequency stability assessment in high-renewable power systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6270\u52a8\u529f\u7387\u7684\u54cd\u5e94\u578b\u9891\u7387\u7a33\u5b9a\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u80fd\u5c06\u591a\u5c3a\u5ea6\u6270\u52a8\u7edf\u4e00\u5904\u7406\uff0c\u901a\u8fc7\u57fa\u4e8e\u53d1\u7535\u673a\u7ec4\u54cd\u5e94\u63a8\u65ad\u7684\u6270\u52a8\u529f\u7387\u5728\u7ebf\u8bc6\u522b\u6270\u52a8\u7c7b\u578b\u5e76\u91cf\u5316\u5f3a\u5ea6\uff0c\u9488\u5bf9\u4e0d\u540c\u6270\u52a8\u7c7b\u522b\u7ed9\u51fa\u89e3\u6790\u9891\u7387\u54cd\u5e94\u6a21\u578b\uff0c\u63d0\u4f9b\u7a33\u6001/\u77ac\u6001\u7ea6\u675f\u4e0b\u7684\u5bb9\u5fcd\u754c\u9650\u4e0e\u5b89\u5168\u88d5\u5ea6\uff0c\u5e76\u5728\u9ad8\u6bd4\u4f8b\u53ef\u518d\u751f\u80fd\u6e90\u7cfb\u7edf\u7684\u57fa\u51c6\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u4e0e\u51c6\u786e\u6027\u3002", "motivation": "\u9ad8\u6bd4\u4f8b\u53ef\u518d\u751f\u80fd\u6e90\u7684\u53d1\u7535\u7cfb\u7edf\u4e2d\uff0c\u6d3b\u8dc3\u529f\u7387\u6270\u52a8\u89c4\u6a21\u589e\u5927\u4e14\u5177\u6709\u591a\u5c3a\u5ea6\u7279\u6027\uff0c\u5e38\u89c4\u7684\u9891\u7387\u7a33\u5b9a\u6027\u8bc4\u4f30\u96be\u4ee5\u5e94\u5bf9\u672a\u9884\u671f\u4e8b\u4ef6\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u7ebf\u8bc6\u522b\u6270\u52a8\u7c7b\u578b\u3001\u7edf\u4e00\u5904\u7406\u591a\u5c3a\u5ea6\u6270\u52a8\u5e76\u7ed9\u51fa\u53ef\u91cf\u5316\u7684\u7a33\u5b9a\u6027\u6307\u6807\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u53d1\u7535\u673a\u7ec4\u7684\u54cd\u5e94\u529f\u7387\u6784\u5efa\u7edf\u4e00\u6270\u52a8\u529f\u7387\u6a21\u578b\uff0c\u901a\u8fc7\u89c2\u6d4b\u529f\u7387\u54cd\u5e94\u5b9e\u73b0\u6270\u52a8\u7c7b\u578b\u5728\u7ebf\u8bc6\u522b\u4e0e\u6270\u52a8\u5f3a\u5ea6\u53ca\u5176\u53d8\u5316\u7387\u7684\u91cf\u5316\u3002\u5c06\u6270\u52a8\u5206\u4e3a\u77ed\u65f6\u548c\u6c38\u4e45\u6270\u52a8\uff0c\u6c38\u4e45\u6270\u52a8\u518d\u5206\u4e3a\u9636\u8dc3\u3001\u4e8c\u7ea7\u659c\u7387\u548c\u5206\u7ea7\u659c\u7387\u6270\u52a8\u3002\u9488\u5bf9\u5404\u6270\u52a8\u7c7b\u522b\u63a8\u5bfc\u89e3\u6790\u7684\u9891\u7387\u54cd\u5e94\u6a21\u578b\uff1a\u5bf9\u9636\u8dc3\u6270\u52a8\u7ed9\u51fa\u5728\u7a33\u6001\u4e0e\u77ac\u6001\u7ea6\u675f\u4e0b\u7684\u6700\u5927\u53ef\u627f\u53d7\u6270\u52a8\u529f\u7387\u53ca\u5b89\u5168\u88d5\u5ea6\uff1b\u5bf9\u659c\u7387\u6270\u52a8\u4f7f\u7528\u6539\u8fdb\u7684\u7cfb\u7edf\u9891\u7387\u54cd\u5e94\u6a21\u578b\u53ca\u4e3b\u8981\u9891\u7387\u5236\u52a8\u8017\u5c3d\u540e\u7684\u8f6c\u5b50\u8fd0\u52a8\u65b9\u7a0b\uff0c\u8ba1\u7b97\u9891\u7387\u8d85\u9650\u7684\u6301\u7eed\u65f6\u95f4\u3002", "result": "\u5728CSEE-FS\u57fa\u51c6\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\uff0c\u7ed3\u679c\u663e\u793a\u5176\u5728\u9ad8\u53ef\u518d\u751f\u80fd\u6e90\u7cfb\u7edf\u4e2d\u7684\u9891\u7387\u7a33\u5b9a\u6027\u5b9a\u91cf\u8bc4\u4f30\u65b9\u9762\u5177\u6709\u8f83\u9ad8\u7684\u6709\u6548\u6027\u548c\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u54cd\u5e94\u578b\u8bc4\u4f30\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5bf9\u591a\u5c3a\u5ea6\u6270\u52a8\u7684\u5728\u7ebf\u8bc6\u522b\u4e0e\u7edf\u4e00\u5904\u7406\uff0c\u63d0\u4f9b\u53ef\u91cf\u5316\u7684\u5b89\u5168\u88d5\u5ea6\u548c\u8d85\u9650\u65f6\u95f4\u7b49\u6307\u6807\uff0c\u4fbf\u4e8e\u5728\u9ad8\u6bd4\u4f8b\u53ef\u518d\u751f\u7cfb\u7edf\u4e2d\u8fdb\u884c\u9891\u7387\u7a33\u5b9a\u6027\u8bc4\u4f30\u4e0e\u51b3\u7b56\u3002"}}
{"id": "2511.21434", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.21434", "abs": "https://arxiv.org/abs/2511.21434", "authors": ["Fabrizio Andr\u00e9 Farf\u00e1n Prado", "William C\u00e9sar P\u00e9rez Campos", "Steisy Anahi Carre\u00f1o Tacuri", "Favio David Cabrera Alva", "Harold Jacobed Carhuas Lizarbe"], "title": "Design Of A Communication System To Send Text Using Lora At 400 MHz", "comment": null, "summary": "This work describes the design and implementation of a low-power wireless communication system for transmitting text using ESP32 modules and the LoRa DXLR01. The proposal arises as a solution to connectivity and energy-efficiency problems commonly found in rural areas and certain urban environments where Wi-Fi or mobile networks are unavailable or operate with limitations. To address this, LoRa technology known for its long-range capability and low power consumption is integrated with an ESP32 responsible for capturing, processing, and sending messages.\n  The LoRa DXLR01 module, which operates in the 433 MHz band, is configured with parameters aimed at maximising both transmission range and efficient energy usage. Messages are sent using Chirp Spread Spectrum (CSS) modulation, improving signal penetration in obstructed areas and reducing the likelihood of errors. On the receiving end, the ESP32 interprets the data and displays it on an LCD screen. Additionally, the received information is sent to the ThingSpeak platform, allowing remote storage and visualisation without relying on conventional network infrastructure.\n  Tests conducted in a controlled environment show an average latency of 3.2 seconds for text transmission. It was also verified that the system can be used in applications such as remote monitoring, infrastructure management, and access control.", "AI": {"tldr": "Design and implementation of a low-power text transmission system using ESP32 + LoRa (DXLR01) at 433 MHz, leveraging CSS modulation; data displayed on LCD and uploaded to ThingSpeak; demonstrates feasibility in rural/limited networks with latency ~3.2 s.", "motivation": "Address connectivity and energy-efficiency gaps in areas with no reliable Wi\u2011Fi/mobile coverage; long-range, low-power wireless communication is needed.", "method": "Hardware: ESP32 with LoRa DXLR01 (433 MHz); configure parameters to maximize range and energy efficiency; use Chirp Spread Spectrum modulation; capture, process, and transmit messages; LCD display; forward received data to ThingSpeak for remote storage/visualization.", "result": "Controlled-environment tests show average transmission latency of 3.2 seconds; successful reception and display; data also pushed to ThingSpeak enabling remote monitoring.", "conclusion": "Demonstrates feasibility of low-power, long-range text transmission for remote monitoring and control; CSS-based LoRa with ESP32 can operate in infrastructure-limited environments; potential for further optimization and real-world deployment."}}
{"id": "2511.21291", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.21291", "abs": "https://arxiv.org/abs/2511.21291", "authors": ["Tien Dat Hoang"], "title": "Illuminating the Black Box: Real-Time Monitoring of Backdoor Unlearning in CNNs via Explainable AI", "comment": "5 pages, 4 figures, IEEE conference format", "summary": "Backdoor attacks pose severe security threats to deep neural networks by embedding malicious triggers that force misclassification. While machine unlearning techniques can remove backdoor behaviors, current methods lack transparency and real-time interpretability. This paper introduces a novel framework that integrates Gradient-weighted Class Activation Mapping (Grad-CAM) into the unlearning process to provide real-time monitoring and explainability. We propose the Trigger Attention Ratio (TAR) metric to quantitatively measure the model's attention shift from trigger patterns to legitimate object features. Our balanced unlearning strategy combines gradient ascent on backdoor samples, Elastic Weight Consolidation (EWC) for catastrophic forgetting prevention, and a recovery phase for clean accuracy restoration. Experiments on CIFAR-10 with BadNets attacks demonstrate that our approach reduces Attack Success Rate (ASR) from 96.51% to 5.52% while retaining 99.48% of clean accuracy (82.06%), achieving a 94.28% ASR reduction. The integration of explainable AI enables transparent, observable, and verifiable backdoor removal.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5c06 Grad-CAM \u878d\u5165\u540e\u95e8\u53bb\u9664\uff08unlearning\uff09\u7684\u6846\u67b6\uff0c\u5e76\u5f15\u5165 Trigger Attention Ratio (TAR) \u4ee5\u5b9e\u73b0\u53ef\u89e3\u91ca\u3001\u5b9e\u65f6\u76d1\u63a7\u7684\u540e\u95e8\u79fb\u9664\u3002", "motivation": "\u73b0\u6709\u7684\u540e\u95e8\u53bb\u9664\u65b9\u6cd5\u7f3a\u4e4f\u900f\u660e\u6027\u4e0e\u5b9e\u65f6\u89e3\u91ca\u80fd\u529b\uff0c\u96be\u4ee5\u63d0\u4f9b\u53ef\u89c2\u6d4b\u3001\u53ef\u9a8c\u8bc1\u7684\u79fb\u9664\u8fc7\u7a0b\uff0c\u56e0\u6b64\u9700\u8981\u517c\u5177\u89e3\u91ca\u6027\u4e0e\u9ad8\u6548\u6027\u7684\u65b0\u6846\u67b6\u3002", "method": "\u5c06 Grad-CAM \u7eb3\u5165 unlearning \u8fc7\u7a0b\uff0c\u63d0\u51fa Trigger Attention Ratio (TAR) \u4ee5\u91cf\u5316\u6a21\u578b\u5bf9\u89e6\u53d1\u6a21\u5f0f\u4e0e\u5408\u6cd5\u5bf9\u8c61\u7279\u5f81\u7684\u6ce8\u610f\u529b\u8fc1\u79fb\u3002\u63d0\u51fa\u4e00\u4e2a\u5e73\u8861\u7684\u53bb\u5b66\u4e60\u7b56\u7565\uff1a\u5bf9\u540e\u95e8\u6837\u672c\u8fdb\u884c\u68af\u5ea6\u4e0a\u5347\u4ee5\u5f3a\u5316\u5bf9\u540e\u95e8\u7684\u5e72\u6270\uff0c\u7ed3\u5408 Elastic Weight Consolidation (EWC) \u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5e76\u8bbe\u7f6e\u4e00\u4e2a\u6062\u590d\u9636\u6bb5\u4ee5\u63d0\u5347\u6e05\u6d01\u51c6\u786e\u7387\u3002", "result": "\u5728 CIFAR-10/BadNets \u5b9e\u9a8c\u4e2d\uff0c\u540e\u95e8\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\u4ece 96.51% \u964d\u81f3 5.52%\uff0c\u6e05\u6d01\u51c6\u786e\u7387\u63d0\u5347\u6216\u4fdd\u6301\u5728 82.06%\uff08\u5360\u539f\u59cb\u6c34\u5e73\u7684 99.48%\uff09\uff0c\u5b9e\u73b0\u4e86\u7ea6 94.28% \u7684 ASR \u964d\u4f4e\u3002", "conclusion": "\u5c06\u53ef\u89e3\u91ca\u6027 AI \u878d\u5165\u540e\u95e8\u79fb\u9664\u6d41\u7a0b\uff0c\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u89c2\u5bdf\u3001\u53ef\u9a8c\u8bc1\u7684\u540e\u95e8\u53bb\u9664\u673a\u5236\u3002"}}
{"id": "2511.20779", "categories": ["cs.LG", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.20779", "abs": "https://arxiv.org/abs/2511.20779", "authors": ["Thomas Norrenbrock", "Timo Kaiser", "Sovan Biswas", "Neslihan Kose", "Ramesh Manuvinakurike", "Bodo Rosenhahn"], "title": "CHiQPM: Calibrated Hierarchical Interpretable Image Classification", "comment": "Accepted to NeurIPS 2025", "summary": "Globally interpretable models are a promising approach for trustworthy AI in safety-critical domains. Alongside global explanations, detailed local explanations are a crucial complement to effectively support human experts during inference. This work proposes the Calibrated Hierarchical QPM (CHiQPM) which offers uniquely comprehensive global and local interpretability, paving the way for human-AI complementarity. CHiQPM achieves superior global interpretability by contrastively explaining the majority of classes and offers novel hierarchical explanations that are more similar to how humans reason and can be traversed to offer a built-in interpretable Conformal prediction (CP) method. Our comprehensive evaluation shows that CHiQPM achieves state-of-the-art accuracy as a point predictor, maintaining 99% accuracy of non-interpretable models. This demonstrates a substantial improvement, where interpretability is incorporated without sacrificing overall accuracy. Furthermore, its calibrated set prediction is competitively efficient to other CP methods, while providing interpretable predictions of coherent sets along its hierarchical explanation.", "AI": {"tldr": "\u63d0\u51fa Calibrated Hierarchical QPM (CHiQPM)\uff0c\u5728\u5168\u7403\u4e0e\u5c40\u90e8\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u5e76\u901a\u8fc7\u5c42\u7ea7\u89e3\u91ca\u4e0e\u53ef\u6821\u51c6\u7684\u9884\u6d4b\u96c6\u5408\u5b9e\u73b0\u4eba\u673a\u4e92\u8865\u3002", "motivation": "\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\uff0c\u4fe1\u4efb\u7684\u524d\u63d0\u662f\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002\u672c\u6587\u63d0\u51fa\u7684 CHiQPM \u540c\u65f6\u63d0\u4f9b\u5168\u9762\u7684\u5168\u5c40\u89e3\u91ca\u4e0e\u7ec6\u7c92\u5ea6\u7684\u5c40\u90e8\u89e3\u91ca\uff0c\u5e76\u901a\u8fc7\u5206\u5c42\u7ed3\u6784\u4f7f\u89e3\u91ca\u66f4\u8d34\u8fd1\u4eba\u7c7b\u63a8\u7406\uff0c\u540c\u65f6\u4e0e\u53ef\u6821\u51c6\u9884\u6d4b\uff08Conformal Prediction\uff09\u7ed3\u5408\uff0c\u63d0\u9ad8\u9884\u6d4b\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u63d0\u51fa CHiQPM \u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u591a\u6570\u7c7b\u522b\u8fdb\u884c\u5bf9\u6bd4\u6027\u5168\u5c40\u89e3\u91ca\u3001\u6784\u5efa\u5c42\u7ea7\u5316\u7684\u89e3\u91ca\u8def\u5f84\uff0c\u5e76\u7ed3\u5408\u53ef\u6821\u51c6\u7684 Conformal Prediction \u4ee5\u5b9e\u73b0\u70b9\u9884\u6d4b\u4e0e\u96c6\u5408\u9884\u6d4b\u7684\u4e92\u8865\uff0c\u4e14\u5176\u5c42\u7ea7\u89e3\u91ca\u80fd\u6cbf\u8def\u5f84\u904d\u5386\uff0c\u4fbf\u4e8e\u4eba-\u673a\u534f\u4f5c\u3002", "result": "\u5728\u70b9\u9884\u6d4b\u65b9\u9762\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u4e14\u4fdd\u6301\u5bf9\u975e\u89e3\u91ca\u6a21\u578b\u7684 99% \u7cbe\u5ea6\uff0c\u8868\u660e\u5728\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u672a\u663e\u8457\u727a\u7272\u51c6\u786e\u6027\u3002\u5176\u6821\u51c6\u96c6\u5408\u9884\u6d4b\u4e0e\u5176\u4ed6 CP \u65b9\u6cd5\u76f8\u5f53\u6216\u5177\u7ade\u4e89\u529b\uff0c\u5e76\u63d0\u4f9b\u4e0e\u5206\u5c42\u89e3\u91ca\u76f8\u4e00\u81f4\u7684\u53ef\u89e3\u91ca\u96c6\u5408\u9884\u6d4b\u3002", "conclusion": "CHiQPM \u663e\u793a\u51fa\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u5168\u7403\u4e0e\u5c40\u90e8\u53ef\u89e3\u91ca\u6027\u7684\u6f5c\u529b\uff0c\u63a8\u52a8\u5728\u4eba\u673a\u4e92\u8865\u7684\u5b89\u5168\u5173\u952e\u9886\u57df\u5e94\u7528\u3002"}}
{"id": "2511.21301", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.21301", "abs": "https://arxiv.org/abs/2511.21301", "authors": ["Leonardo Regano", "Daniele Canavese", "Cataldo Basile", "Marco Torchiano"], "title": "Empirical Assessment of the Code Comprehension Effort Needed to Attack Programs Protected with Obfuscation", "comment": null, "summary": "Evaluating the effectiveness of software protection is crucial for selecting the most effective methods to safeguard assets within software applications. Obfuscation involves techniques that deliberately modify software to make it more challenging to understand and reverse-engineer, while maintaining its original functionality. Although obfuscation is widely adopted, its effectiveness remains largely unexplored and unthoroughly evaluated. This paper presents a controlled experiment involving Master's students performing code comprehension tasks on applications hardened with obfuscation. The experiment's goals are to assess the effectiveness of obfuscation in delaying code comprehension by attackers and to determine whether complexity metrics can accurately predict the impact of these protections on success rates and durations of code comprehension tasks. The study is the first to evaluate the effect of layering multiple obfuscation techniques on a single piece of protected code. It also provides experimental evidence of the correlation between objective metrics of the attacked code and the likelihood of a successful attack, bridging the gap between objective and subjective approaches to estimating potency. Finally, the paper highlights significant aspects that warrant additional analysis and opens new avenues for further experiments.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4e00\u4e2a\u53d7\u63a7\u5b9e\u9a8c\u8bc4\u4f30\u5bf9\u4ee3\u7801\u6df7\u6dc6\u7684\u6709\u6548\u6027\uff0c\u91cd\u70b9\u5728\u4e8e\u8861\u91cf\u5bf9\u653b\u51fb\u8005\u7406\u89e3\u4ee3\u7801\u7684\u5ef6\u8fdf\u6548\u679c\uff0c\u5e76\u8003\u5bdf\u590d\u6742\u6027\u5ea6\u91cf\u662f\u5426\u80fd\u9884\u6d4b\u6210\u529f\u7387\u548c\u4efb\u52a1\u65f6\u957f\uff1b\u9996\u6b21\u8bc4\u4f30\u5bf9\u540c\u4e00\u4ee3\u7801\u5206\u5c42\u591a\u91cd\u6df7\u6dc6\u7684\u6548\u679c\uff0c\u63d0\u4f9b\u5ba2\u89c2\u6307\u6807\u4e0e\u653b\u51fb\u6210\u529f\u6982\u7387\u4e4b\u95f4\u7684\u76f8\u5173\u8bc1\u636e\uff0c\u5e76\u6307\u660e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4fdd\u62a4\u8f6f\u4ef6\u8d44\u4ea7\u7684\u6709\u6548\u6027\u9700\u8981\u5b9e\u8bc1\u6570\u636e\uff1b\u5c3d\u7ba1\u6df7\u6dc6\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u6548\u679c\u5c1a\u672a\u88ab\u5145\u5206\u8bc4\u4f30\uff1b\u901a\u8fc7\u5c06\u591a\u5c42\u6df7\u6dc6\u548c\u5ba2\u89c2\u6307\u6807\u7ed3\u5408\uff0c\u586b\u8865\u7406\u8bba\u4e0e\u7ecf\u9a8c\u4e4b\u95f4\u7684\u7a7a\u767d\u3002", "method": "\u5728\u53d7\u8bd5\u8005\u4e3a\u7855\u58eb\u751f\u7684\u63a7\u5236\u5b9e\u9a8c\u4e2d\uff0c\u6bd4\u8f83\u88ab\u6df7\u6dc6\u548c\u672a\u6df7\u6dc6\u4ee3\u7801\u7684\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\uff1b\u5f15\u5165\u591a\u5c42\u6df7\u6dc6\u7684\u7ec4\u5408\uff1b\u6d4b\u91cf\u4efb\u52a1\u6210\u529f\u7387\u4e0e\u5b8c\u6210\u65f6\u957f\uff0c\u5e76\u6536\u96c6\u4ee3\u7801\u590d\u6742\u6027\u7b49\u5ba2\u89c2\u6307\u6807\uff0c\u5206\u6790\u5176\u4e0e\u653b\u51fb\u6210\u529f\u7684\u76f8\u5173\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6df7\u6dc6\u80fd\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u5ef6\u7f13\u4ee3\u7801\u7406\u89e3\uff1b\u4ee3\u7801\u590d\u6742\u6027\u6307\u6807\u4e0e\u653b\u51fb\u6210\u529f\u7387\u548c\u8017\u65f6\u5b58\u5728\u76f8\u5173\u6027\uff1b\u9996\u6b21\u63d0\u4f9b\u5bf9\u5206\u5c42\u6df7\u6dc6\u7684\u5b9e\u9a8c\u8bc1\u636e\uff1b\u5f25\u5408\u5ba2\u89c2\u6307\u6807\u4e0e\u4e3b\u89c2\u8bc4\u4f30\u4e4b\u95f4\u7684\u8054\u7cfb\uff1b\u6307\u51fa\u9700\u8981\u8fdb\u4e00\u6b65\u5206\u6790\u7684\u65b9\u9762\u3002", "conclusion": "\u6df7\u6dc6\u5728\u5ef6\u7f13\u653b\u51fb\u8005\u7406\u89e3\u65b9\u9762\u5177\u6709\u53ef\u89c2\u7684\u6548\u679c\uff1b\u5ba2\u89c2\u590d\u6742\u6027\u6307\u6807\u53ef\u9884\u6d4b\u653b\u51fb\u6210\u529f\u6982\u7387\u4e0e\u8017\u65f6\uff0c\u4f46\u9700\u8981\u5728\u66f4\u5e7f\u6cdb\u573a\u666f\u548c\u53c2\u4e0e\u8005\u7fa4\u4f53\u4e2d\u9a8c\u8bc1\uff1b\u672a\u6765\u5de5\u4f5c\u5e94\u6df1\u5165\u7814\u7a76\u5206\u5c42\u6df7\u6dc6\u7684\u5f71\u54cd\u3001\u6307\u6807\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u53ca\u6269\u5c55\u5230\u5b9e\u9645\u5e94\u7528\u60c5\u5883\u3002"}}
{"id": "2511.20798", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.20798", "abs": "https://arxiv.org/abs/2511.20798", "authors": ["Rio Alexa Fear", "Payel Mukhopadhyay", "Michael McCabe", "Alberto Bietti", "Miles Cranmer"], "title": "Physics Steering: Causal Control of Cross-Domain Concepts in a Physics Foundation Model", "comment": "16 Pages, 9 Figures. Code available at https://github.com/DJ-Fear/walrus_steering", "summary": "Recent advances in mechanistic interpretability have revealed that large language models (LLMs) develop internal representations corresponding not only to concrete entities but also distinct, human-understandable abstract concepts and behaviour. Moreover, these hidden features can be directly manipulated to steer model behaviour. However, it remains an open question whether this phenomenon is unique to models trained on inherently structured data (ie. language, images) or if it is a general property of foundation models. In this work, we investigate the internal representations of a large physics-focused foundation model. Inspired by recent work identifying single directions in activation space for complex behaviours in LLMs, we extract activation vectors from the model during forward passes over simulation datasets for different physical regimes. We then compute \"delta\" representations between the two regimes. These delta tensors act as concept directions in activation space, encoding specific physical features. By injecting these concept directions back into the model during inference, we can steer its predictions, demonstrating causal control over physical behaviours, such as inducing or removing some particular physical feature from a simulation. These results suggest that scientific foundation models learn generalised representations of physical principles. They do not merely rely on superficial correlations and patterns in the simulations. Our findings open new avenues for understanding and controlling scientific foundation models and has implications for AI-enabled scientific discovery.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u7269\u7406\u4e13\u6ce8\u578b\u57fa\u7840\u6a21\u578b\u662f\u5426\u5177\u5907\u53ef\u63d0\u53d6\u4e0e\u64cd\u63a7\u7684\u201c\u9690\u6027\u6982\u5ff5\u201d\u65b9\u5411\uff0c\u5e76\u5c1d\u8bd5\u901a\u8fc7\u5728\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u8ba1\u7b97\u4e24\u4e2a\u7269\u7406 regime \u7684 delta \u8868\u8fbe\u5f0f\u6765\u5b9e\u73b0\u5bf9\u6a21\u578b\u8f93\u51fa\u7684\u56e0\u679c\u63a7\u5236\uff0c\u4ece\u800c\u63a8\u52a8\u5bf9\u79d1\u5b66\u57fa\u7840\u6a21\u578b\u7684\u7406\u89e3\u4e0e\u5e94\u7528\u3002", "motivation": "\u9a8c\u8bc1\u79d1\u5b66\u57fa\u7840\u6a21\u578b\u662f\u5426\u80fd\u50cf\u5728\u8bed\u8a00\u4e0e\u89c6\u89c9\u6a21\u578b\u4e2d\u89c2\u5bdf\u5230\u7684\u90a3\u6837\u5b66\u4e60\u901a\u7528\u3001\u53ef\u89e3\u8bfb\u7684\u62bd\u8c61\u6982\u5ff5\u53ca\u5176\u64cd\u63a7\u6027\uff0c\u8fdb\u800c\u6269\u5c55\u5230\u53d7\u7269\u7406\u89c4\u5f8b\u9a71\u52a8\u7684\u63a8\u7406\u4e0e\u53d1\u73b0\u9886\u57df\u3002", "method": "\u4ece\u7269\u7406\u4eff\u771f\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u6a21\u578b\u524d\u5411\u4f20\u64ad\u65f6\u7684\u6fc0\u6d3b\u5411\u91cf\uff0c\u6bd4\u8f83\u4e0d\u540c\u7269\u7406 regime \u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u5f97\u5230 delta \u5f20\u91cf\u4f5c\u4e3a\u6982\u5ff5\u65b9\u5411\uff1b\u5c06\u8fd9\u4e9b\u6982\u5ff5\u65b9\u5411\u6ce8\u5165\u6a21\u578b\u4ee5\u5f71\u54cd\u63a8\u7406\u8fc7\u7a0b\uff0c\u68c0\u9a8c\u80fd\u5426\u56e0\u679c\u5730\u63a7\u5236\u4eff\u771f\u4e2d\u7684\u7269\u7406\u7279\u5f81\u3002", "result": "\u63ed\u793a\u4e86\u7269\u7406\u4e13\u6ce8\u578b\u57fa\u7840\u6a21\u578b\u5728\u5185\u90e8\u8868\u793a\u4e2d\u5305\u542b\u53ef\u89e3\u91ca\u7684\u7269\u7406\u539f\u7406\u65b9\u5411\uff0c\u4e14\u901a\u8fc7\u6ce8\u5165\u6982\u5ff5\u65b9\u5411\u53ef\u4ee5\u6539\u53d8\u6a21\u578b\u7684\u9884\u6d4b\u884c\u4e3a\uff0c\u4f53\u73b0\u4e86\u5bf9\u7269\u7406\u7279\u5f81\u7684\u56e0\u679c\u63a7\u5236\u3002", "conclusion": "\u79d1\u5b66\u57fa\u7840\u6a21\u578b\u5177\u5907\u5bf9\u7269\u7406\u89c4\u5f8b\u7684\u6cdb\u5316\u8868\u793a\u80fd\u529b\uff0c\u4e0d\u4ec5\u4ec5\u4f9d\u8d56\u8868\u9762\u76f8\u5173\u6027\uff1b\u8be5\u53d1\u73b0\u4e3aAI \u652f\u6301\u7684\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u65b0\u8def\u5f84\uff0c\u4fc3\u4f7f\u5bf9\u590d\u6742\u79d1\u5b66\u7cfb\u7edf\u7684\u7406\u89e3\u4e0e\u64cd\u63a7\u80fd\u529b\u63d0\u5347\u3002"}}
{"id": "2511.21273", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21273", "abs": "https://arxiv.org/abs/2511.21273", "authors": ["Ana Cordon-Avila", "Mostafa Selim", "Momen Abayazid"], "title": "Respiratory Motion Compensation and Haptic Feedback for X-ray-Guided Teleoperated Robotic Needle Insertion", "comment": null, "summary": "Respiratory motion limits the accuracy and precision of abdominal percutaneous procedures. In this paper, respiratory motion is compensated robotically using motion estimation models. Additionally, a teleoperated insertion is performed using proximity-based haptic feedback to guide physicians during insertion, enabling a radiation-free remote insertion for the end-user. The study has been validated using a robotic liver phantom, and five insertions were performed. The resulting motion estimation errors were below 3 mm for all directions of motion, and the overall resulting 3D insertion errors were 2.60, 7.75, and 2.86 mm for the superior-inferior, lateral, and anterior-posterior directions of motion, respectively. The proposed approach is expected to minimize the chances of inaccurate treatment or diagnosis due to respiratory-induced motion and reduce radiation exposure.", "AI": {"tldr": "\u901a\u8fc7\u547c\u5438\u8fd0\u52a8\u4f30\u7b97\u4e0e\u8fdc\u7a0b\u89e6\u89c9\u5f15\u5bfc\u5b9e\u73b0\u65e0\u653e\u5c04\u9065\u63a7\u809d\u810f\u63d2\u5165\uff0c\u673a\u5668\u4eba\u6a21\u578b\u9a8c\u8bc1\u4e0b\u6beb\u7c73\u7ea7\u8fd0\u52a8\u8865\u507f\u548c3D\u63d2\u5165\u8bef\u5dee\uff0c\u63d0\u5347\u6cbb\u7597/\u8bca\u65ad\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u8f90\u5c04\u66b4\u9732\u3002", "motivation": "\u547c\u5438\u5f15\u8d77\u7684\u8179\u90e8\u5668\u5b98\u8fd0\u52a8\u663e\u8457\u964d\u4f4e\u8179\u90e8\u7ecf\u76ae\u6cbb\u7597\u7684\u5b9a\u4f4d\u51c6\u786e\u6027\uff0c\u9700\u5728\u975e\u653e\u5c04\u6027\u73af\u5883\u4e0b\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u4e0e\u5b89\u5168\u7684\u8fdc\u7a0b\u64cd\u4f5c\u3002", "method": "\u5229\u7528\u547c\u5438\u8fd0\u52a8\u4f30\u7b97\u6a21\u578b\u8fdb\u884c\u8fd0\u52a8\u8865\u507f\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u8ddd\u79bb\u7684\u89e6\u89c9\u53cd\u9988\u5b9e\u73b0\u8fdc\u7a0b\u63d2\u5165\u7684\u5f15\u5bfc\u4e0e\u63a7\u5236\uff1b\u5728\u673a\u5668\u4eba\u809d\u810f\u4eff\u771f\u6a21\u578b\u4e0a\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5b8c\u62105\u6b21\u63d2\u5165\u4ee5\u8bc4\u4f30\u5b9a\u4f4d\u4e0e\u63d2\u5165\u8bef\u5dee\u3002", "result": "\u8fd0\u52a8\u4f30\u8ba1\u8bef\u5dee\u5728\u6240\u6709\u8fd0\u52a8\u65b9\u5411\u5747\u5c0f\u4e8e3 mm\uff1b3D\u63d2\u5165\u8bef\u5dee\u5728S-I\u65b9\u5411\u4e3a2.60 mm\uff0cLateral\u65b9\u5411\u4e3a7.75 mm\uff0cA-P\u65b9\u5411\u4e3a2.86 mm\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u671b\u51cf\u5c11\u56e0\u547c\u5438\u5f15\u8d77\u7684\u5b9a\u4f4d\u4e0d\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u653e\u5c04\u66b4\u9732\uff0c\u4ece\u800c\u63d0\u5347\u8179\u90e8\u7ecf\u76ae\u6cbb\u7597\u7684\u5b89\u5168\u6027\u548c\u53ef\u53ca\u6027\u3002"}}
{"id": "2511.21448", "categories": ["cs.CR", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.21448", "abs": "https://arxiv.org/abs/2511.21448", "authors": ["Rebeka Toth", "Tamas Bisztray", "Richard Dubniczky"], "title": "Constructing and Benchmarking: a Labeled Email Dataset for Text-Based Phishing and Spam Detection Framework", "comment": null, "summary": "Phishing and spam emails remain a major cybersecurity threat, with attackers increasingly leveraging Large Language Models (LLMs) to craft highly deceptive content. This study presents a comprehensive email dataset containing phishing, spam, and legitimate messages, explicitly distinguishing between human- and LLM-generated content. Each email is annotated with its category, emotional appeal (e.g., urgency, fear, authority), and underlying motivation (e.g., link-following, credential theft, financial fraud). We benchmark multiple LLMs on their ability to identify these emotional and motivational cues and select the most reliable model to annotate the full dataset. To evaluate classification robustness, emails were also rephrased using several LLMs while preserving meaning and intent. A state-of-the-art LLM was then assessed on its performance across both original and rephrased emails using expert-labeled ground truth. The results highlight strong phishing detection capabilities but reveal persistent challenges in distinguishing spam from legitimate emails. Our dataset and evaluation framework contribute to improving AI-assisted email security systems. To support open science, all code, templates, and resources are available on our project site.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5305\u542b\u9493\u9c7c\u3001\u5783\u573e\u90ae\u4ef6\u53ca\u5408\u6cd5\u90ae\u4ef6\u7684\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u533a\u5206\u4eba\u5de5\u4e0eLLM\u751f\u6210\u5185\u5bb9\uff0c\u5e76\u6807\u6ce8\u60c5\u611f\u8bc9\u6c42\u4e0e\u52a8\u673a\uff1b\u901a\u8fc7\u591a\u6a21\u578b\u8bc4\u4f30\u8bc6\u522b\u60c5\u611f/\u52a8\u673a\u7ebf\u7d22\u7684\u80fd\u529b\uff0c\u5e76\u8bc4\u4f30\u5bf9\u539f\u59cb\u4e0e\u6539\u5199\u90ae\u4ef6\u7684\u4e00\u81f4\u6027\u4e0e\u9c81\u68d2\u6027\uff1b\u5728\u5f3a\u529b\u7684\u9493\u9c7c\u68c0\u6d4b\u540c\u65f6\uff0c\u5783\u573e\u90ae\u4ef6\u4e0e\u5408\u6cd5\u90ae\u4ef6\u533a\u5206\u4ecd\u5177\u6311\u6218\u6027\uff1b\u5e76\u63d0\u4f9b\u5f00\u6e90\u8d44\u6e90\u4e0e\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u5e94\u5bf9LLM\u5728\u90ae\u4ef6\u6b3a\u8bc8\u751f\u6210\u4e2d\u7684\u65e5\u76ca\u666e\u53ca\uff0c\u4e9f\u9700\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u96c6\u4e0e\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u63d0\u5347AI\u8f85\u52a9\u90ae\u4ef6\u5b89\u5168\u7cfb\u7edf\u7684\u68c0\u6d4b\u80fd\u529b\u4e0e\u9c81\u68d2\u6027\uff0c\u5e76\u4fc3\u8fdb\u5f00\u6e90\u7814\u7a76\u3002", "method": "\u6784\u5efa\u5305\u542b\u7c7b\u522b\u3001\u60c5\u611f\u8bc9\u6c42\uff08\u5982\u7d27\u8feb\u611f\u3001\u6050\u60e7\u3001\u6743\u5a01\uff09\u4e0e\u52a8\u673a\uff08\u94fe\u63a5\u8ddf\u968f\u3001\u51ed\u636e\u76d7\u53d6\u3001\u91d1\u878d\u6b3a\u8bc8\uff09\u7684\u90ae\u4ef6\u6570\u636e\u96c6\uff0c\u5e76\u5bf9\u591a\u79cdLLM\u5728\u8bc6\u522b\u60c5\u611f/\u52a8\u673a\u7ebf\u7d22\u4e0a\u7684\u80fd\u529b\u8fdb\u884c\u57fa\u7ebf\u8bc4\u4f30\uff1b\u9009\u53d6\u6700\u53ef\u9760\u7684\u6a21\u578b\u5bf9\u6574\u7ec4\u6570\u636e\u8fdb\u884c\u6ce8\u91ca\uff1b\u901a\u8fc7\u5bf9\u90ae\u4ef6\u8fdb\u884c\u591a\u8f6eLLM\u6539\u5199\u4ee5\u4fdd\u6301\u8bed\u4e49\u4e0e\u610f\u56fe\uff0c\u8bc4\u4f30\u5206\u7c7b\u9c81\u68d2\u6027\uff1b\u4ee5\u4e13\u5bb6\u6807\u6ce8\u7684\u771f\u503c\u5bf9\u4e00\u6d41LLM\u5728\u539f\u59cb\u4e0e\u6539\u5199\u90ae\u4ef6\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u8bc4\u4f30\uff1b", "result": "\u7ed3\u679c\u663e\u793a\u5728\u9493\u9c7c\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u5728\u5c06\u5783\u573e\u90ae\u4ef6\u4e0e\u5408\u6cd5\u90ae\u4ef6\u533a\u5206\u5f00\u65b9\u9762\u4ecd\u5b58\u5728\u660e\u663e\u6311\u6218\uff1b\u6570\u636e\u96c6\u4e0e\u8bc4\u4f30\u6846\u67b6\u6709\u52a9\u4e8e\u6539\u8fdbAI\u8f85\u52a9\u7684\u90ae\u4ef6\u5b89\u5168\u7cfb\u7edf\uff1b\u5f00\u6e90\u8d44\u6e90\u3001\u4ee3\u7801\u4e0e\u6a21\u677f\u5bf9\u7814\u7a76\u793e\u533a\u5f00\u653e\uff0c\u4fc3\u8fdb\u518d\u73b0\u6027\u548c\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u4e14\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u5e73\u53f0\uff0c\u5f3a\u8c03\u901a\u8fc7\u60c5\u611f\u4e0e\u52a8\u673a\u7ebf\u7d22\u6765\u63d0\u5347\u90ae\u4ef6\u5b89\u5168\u68c0\u6d4b\u7684\u80fd\u529b\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5783\u573e\u90ae\u4ef6\u4e0e\u5408\u6cd5\u90ae\u4ef6\u533a\u5206\u7684\u96be\u70b9\uff0c\u652f\u6301\u5f00\u6e90\u79d1\u5b66\u751f\u6001\u3002"}}
{"id": "2511.20811", "categories": ["cs.LG", "cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.20811", "abs": "https://arxiv.org/abs/2511.20811", "authors": ["Aaron O. Feldman", "D. Isaiah Harp", "Joseph Duncan", "Mac Schwager"], "title": "Conformal Safety Monitoring for Flight Testing: A Case Study in Data-Driven Safety Learning", "comment": "ICRA 2025 Workshop on Robot safety under uncertainty from intangible specifications", "summary": "We develop a data-driven approach for runtime safety monitoring in flight testing, where pilots perform maneuvers on aircraft with uncertain parameters. Because safety violations can arise unexpectedly as a result of these uncertainties, pilots need clear, preemptive criteria to abort the maneuver in advance of safety violation. To solve this problem, we use offline stochastic trajectory simulation to learn a calibrated statistical model of the short-term safety risk facing pilots. We use flight testing as a motivating example for data-driven learning/monitoring of safety due to its inherent safety risk, uncertainty, and human-interaction. However, our approach consists of three broadly-applicable components: a model to predict future state from recent observations, a nearest neighbor model to classify the safety of the predicted state, and classifier calibration via conformal prediction. We evaluate our method on a flight dynamics model with uncertain parameters, demonstrating its ability to reliably identify unsafe scenarios, match theoretical guarantees, and outperform baseline approaches in preemptive classification of risk.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u98de\u884c\u6d4b\u8bd5\u8fd0\u884c\u65f6\u5b89\u5168\u76d1\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u7ebf\u968f\u673a\u8f68\u8ff9\u4eff\u771f\u5b66\u4e60\u5df2\u6821\u51c6\u7684\u77ed\u671f\u5b89\u5168\u98ce\u9669\u6a21\u578b\uff1b\u5305\u542b\u672a\u6765\u72b6\u6001\u9884\u6d4b\u3001\u6700\u8fd1\u90bb\u5b89\u5168\u5206\u7c7b\u4e0e\u57fa\u4e8e\u4fdd\u5f62\u9884\u6d4b\u7684\u5206\u7c7b\u5668\u6821\u51c6\uff1b\u5728\u542b\u4e0d\u786e\u5b9a\u53c2\u6570\u7684\u98de\u884c\u52a8\u529b\u5b66\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u80fd\u53ef\u9760\u8bc6\u522b\u4e0d\u5b89\u5168\u60c5\u5f62\u3001\u5177\u5907\u7406\u8bba\u4fdd\u8bc1\u5e76\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u7684\u9884\u9632\u6027\u98ce\u9669\u5206\u7c7b\u3002", "motivation": "\u5728\u98de\u884c\u6d4b\u8bd5\u4e2d\uff0c\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u4e0e\u4eba\u673a\u4ea4\u4e92\u5bfc\u81f4\u5b89\u5168\u8fdd\u89c4\u53ef\u80fd\u5728\u672a\u9884\u671f\u65f6\u53d1\u751f\uff0c\u9700\u8981\u5728\u8fdd\u89c4\u524d\u5c31\u7ed9\u51fa\u6e05\u6670\u3001\u53ef\u64cd\u4f5c\u7684\u4e2d\u6b62\u6807\u51c6\u3002\u8be5\u7814\u7a76\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u548c\u76d1\u6d4b\uff0c\u5c06\u5b89\u5168\u76d1\u6d4b\u4ece\u4e8b\u540e\u5206\u6790\u8f6c\u5411\u53ef\u9884\u9632\u6027\u51b3\u7b56\uff0c\u5e76\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002", "method": "\u79bb\u7ebf\u7684\u968f\u673a\u8f68\u8ff9\u4eff\u771f\u7528\u4e8e\u5b66\u4e60\u4e00\u4e2a\u5bf9\u77ed\u671f\u5b89\u5168\u98ce\u9669\u8fdb\u884c\u6821\u51c6\u7684\u7edf\u8ba1\u6a21\u578b\uff1b\u6846\u67b6\u5305\u542b\u4e09\u5927\u7ec4\u4ef6\uff1a1) \u57fa\u4e8e\u6700\u8fd1\u89c2\u6d4b\u9884\u6d4b\u672a\u6765\u72b6\u6001\u7684\u6a21\u578b\uff1b2) \u6700\u8fd1\u90bb\u6a21\u578b\u5bf9\u9884\u6d4b\u72b6\u6001\u7684\u5b89\u5168\u6027\u8fdb\u884c\u5206\u7c7b\uff1b3) \u901a\u8fc7\u4fdd\u5f62\u9884\u6d4b\u5bf9\u5206\u7c7b\u5668\u8fdb\u884c\u6821\u51c6\u4ee5\u63d0\u4f9b\u53ef\u9760\u7684\u7f6e\u4fe1\u5ea6\u3002\u7814\u7a76\u5728\u542b\u53c2\u6570\u4e0d\u786e\u5b9a\u7684\u98de\u884c\u52a8\u529b\u5b66\u6a21\u578b\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u80fd\u53ef\u9760\u8bc6\u522b\u4e0d\u5b89\u5168\u60c5\u666f\u3001\u8fbe\u5230\u7406\u8bba\u4fdd\u8bc1\u5e76\u5728\u9884\u9632\u6027\u98ce\u9669\u5206\u7c7b\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "result": "\u65b9\u6cd5\u80fd\u591f\u5728\u5b89\u5168\u8fb9\u754c\u9644\u8fd1\u7684\u77ed\u671f\u65f6\u95f4\u7a97\u5185\u8bc6\u522b\u6f5c\u5728\u4e0d\u5b89\u5168\u60c5\u666f\uff0c\u63d0\u4f9b\u4e0e\u7406\u8bba\u4fdd\u8bc1\u4e00\u81f4\u7684\u7f6e\u4fe1\u6821\u51c6\uff0c\u5e76\u5728\u4e0e\u57fa\u7ebf\u76f8\u6bd4\u7684\u5c1d\u8bd5\u4e2d\u5b9e\u73b0\u66f4\u65e9\u7684\u9884\u9632\u6027\u98ce\u9669\u5206\u7c7b\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5c06\u6570\u636e\u9a71\u52a8\u7684\u5b89\u5168\u76d1\u6d4b\u4e0e\u4fdd\u5f62\u9884\u6d4b\u6821\u51c6\u7ed3\u5408\uff0c\u9002\u7528\u4e8e\u98de\u884c\u6d4b\u8bd5\u53ca\u5176\u4ed6\u9ad8\u98ce\u9669\u3001\u4eba\u673a\u534f\u4f5c\u573a\u666f\uff0c\u5177\u5907\u826f\u597d\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u53ef\u6269\u5c55\u6027\uff0c\u80fd\u591f\u5728\u672a\u53d1\u751f\u5b89\u5168\u8fdd\u89c4\u524d\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u51b3\u7b56\u4f9d\u636e\u3002"}}
{"id": "2511.21314", "categories": ["eess.SY", "cs.RO", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.21314", "abs": "https://arxiv.org/abs/2511.21314", "authors": ["Jewel Benny", "Narahari N. Moudhgalya", "Mujeev Khan", "Hemant Kumar Meena", "Mohd Wajid", "Abhishek Srivastava"], "title": "Scalable Multisubject Vital Sign Monitoring With mmWave FMCW Radar and FPGA Prototyping", "comment": "Published in IEEE Sensors Journal", "summary": "In this work, we introduce an innovative approach to estimate the vital signs of multiple human subjects simultaneously in a non-contact way using a Frequency Modulated Continuous Wave (FMCW) radar-based system. Traditional vital sign monitoring methods often face significant limitations, including subject discomfort with wearable devices, challenges in calibration, and the risk of infection transmission through contact measurement devices. To address these issues, this research is motivated by the need for versatile, non-contact vital monitoring solutions applicable in various critical scenarios. This work also explores the challenges of extending this capability to an arbitrary number of subjects, including hardware and theoretical limitations. Supported by rigorous experimental results and discussions, the paper illustrates the system's potential to redefine vital sign monitoring. An FPGA-based implementation is also presented as proof of concept for a hardware-based and portable solution, improving upon previous works by offering 2.7x faster execution and 18.4% less Look-Up Table (LUT) utilization, as well as providing over 7400x acceleration compared to its software counterpart.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e FMCW \u96f7\u8fbe\u7684\u975e\u63a5\u89e6\u591a\u4eba\u4f53\u751f\u547d\u4f53\u5f81\u4f30\u8ba1\u7cfb\u7edf\uff0c\u5e76\u7ed9\u51fa\u7528\u4e8e\u73b0\u573a\u90e8\u7f72\u7684 FPGA \u5b9e\u73b0\uff0c\u663e\u8457\u63d0\u5347\u901f\u5ea6\u4e0e\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u53ef\u7a7f\u6234\u8bbe\u5907\u5e26\u6765\u7684\u4e0d\u9002\u3001\u6821\u51c6\u56f0\u96be\u4ee5\u53ca\u611f\u67d3\u4f20\u64ad\u98ce\u9669\u7b49\u95ee\u9898\uff0c\u63d0\u51fa\u53ef\u6269\u5c55\u7684\u975e\u63a5\u89e6\u5f0f\u751f\u547d\u4f53\u5f81\u76d1\u6d4b\u65b9\u6848\uff0c\u5e76\u63a2\u8ba8\u6269\u5c55\u5230\u4efb\u610f\u6570\u91cf\u53d7\u8bd5\u8005\u7684\u786c\u4ef6\u4e0e\u7406\u8bba\u9650\u5236\u3002", "method": "\u91c7\u7528 FMCW \u96f7\u8fbe\u8fdb\u884c\u591a\u76ee\u6807\u751f\u547d\u4f53\u5f81\u4f30\u8ba1\uff0c\u5206\u6790\u5728\u53ef\u6269\u5c55\u6027\u65b9\u9762\u7684\u6311\u6218\uff0c\u5e76\u7ed9\u51fa\u4e00\u4e2a FPGA \u57fa\u7840\u7684\u5b9e\u73b0\u4f5c\u4e3a\u786c\u4ef6\u539f\u578b\u4ee5\u5b9e\u73b0\u4fbf\u643a\u6027\u4e0e\u9ad8\u6548\u6027\u3002", "result": "\u4e0e\u8f6f\u4ef6\u5b9e\u73b0\u76f8\u6bd4\uff0cFPGA \u65b9\u6848\u5b9e\u73b0\u7ea6 2.7 \u500d\u6267\u884c\u52a0\u901f\uff0cLUT \u4f7f\u7528\u7387\u4e0b\u964d\u7ea6 18.4%\uff0c\u5e76\u76f8\u5bf9\u4e8e\u8f6f\u4ef6\u8fbe\u5230\u8d85\u8fc7 7400 \u500d\u7684\u52a0\u901f\uff0c\u540c\u65f6\u8ba8\u8bba\u4e86\u6269\u5c55\u5230\u66f4\u591a\u53d7\u8bd5\u8005\u7684\u53ef\u884c\u6027\u4e0e\u9650\u5236\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c55\u793a\u4e86\u975e\u63a5\u89e6\u5f0f\u751f\u547d\u4f53\u5f81\u76d1\u6d4b\u7684\u53ef\u884c\u6027\u4e0e\u6f5c\u529b\uff0c\u5c24\u5176\u5728\u9ad8\u6548\u3001\u4fbf\u643a\u7684\u786c\u4ef6\u5b9e\u73b0\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5e76\u4e3a\u672a\u6765\u591a\u4eba\u4f53\u76d1\u6d4b\u7684\u53d1\u5c55\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2511.20944", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.20944", "abs": "https://arxiv.org/abs/2511.20944", "authors": ["Yaw Osei Adjei"], "title": "Semantic Superiority vs. Forensic Efficiency: A Comparative Analysis of Deep Learning and Psycholinguistics for Business Email Compromise Detection", "comment": "8 pages, 12 figures, 7 tables", "summary": "Business Email Compromise (BEC) is a sophisticated social engineering threat that manipulates organizational hierarchies and exploits psychological vulnerabilities, leading to significant financial damage. According to the 2024 FBI Internet Crime Report, BEC accounts for over $2.9 billion in annual adjusted losses, presenting significant economic asymmetry: the cost of a False Negative (fraud loss) exceeds the cost of a False Positive (manual review) by orders of magnitude (approximately 1 to 5,480).\n  This paper examines two detection paradigms for BEC: the Forensic Psycholinguistic Stream, which utilizes CatBoost to analyze psycholinguistic cues with high interpretability and low latency, and the Semantic Stream, which employs DistilBERT for deep learning-based contextual language understanding, offering superior accuracy at higher computational cost. We evaluated DistilBERT on an adversarially poisoned dataset (N = 7,990) generated via our Black Hole protocol, benchmarked on Tesla T4 GPU infrastructure, achieving superior detection (AUC = 1.0000, F1 = 0.9981) with acceptable real-time latency (7.403 milliseconds). CatBoost achieves competitive detection (AUC = 0.9905, F1 = 0.9486) at 8.4x lower latency (0.885 milliseconds), consuming negligible computational resources. For organizations with GPU infrastructure, DistilBERT offers superior accuracy. CatBoost is preferable for edge deployments or cost-sensitive environments due to comparable security and lower operational costs. Both approaches demonstrate return on investment exceeding 99.96% when optimized through cost-sensitive learning, by significantly reducing false negatives and associated financial losses.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cdBEC\u68c0\u6d4b\u8303\u5f0f\uff1aForensic Psycholinguistic Stream\uff08CatBoost\uff0c\u89e3\u91ca\u6027\u5f3a\u3001\u4f4e\u65f6\u5ef6\uff09\u4e0eSemantic Stream\uff08DistilBERT\uff0c\u6df1\u5ea6\u5b66\u4e60\u3001\u4e0a\u4e0b\u6587\u7406\u89e3\uff0c\u7cbe\u5ea6\u9ad8\u4f46\u6210\u672c\u4e5f\u9ad8\uff09\u5728\u5bf9\u6297\u6027\u6c61\u67d3\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u3002DistilBERT\u5728GPU\u4e0a\u8868\u73b0\u6700\u597d\uff0c\u4f46CatBoost\u5728\u8fb9\u7f18\u8bbe\u5907\u548c\u6210\u672c\u654f\u611f\u573a\u666f\u66f4\u5177\u4f18\u52bf\uff1b\u4e24\u8005\u5728\u6210\u672c\u654f\u611f\u5b66\u4e60\u4e0b\u7684\u6295\u8d44\u56de\u62a5\u7387\u9ad8\u4e8e99.96%\u3002", "motivation": "BEC\u5e26\u6765\u5de8\u5927\u7ecf\u6d4e\u635f\u5931\uff0c\u73b0\u6709\u68c0\u6d4b\u9700\u517c\u987e\u51c6\u786e\u6027\u3001\u5ef6\u8fdf\u548c\u6210\u672c\uff0c\u9700\u6bd4\u8f83\u53ef\u89e3\u91ca\u6027\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e2e\u52a9\u7ec4\u7ec7\u5728\u4e0d\u540c\u786c\u4ef6\u6761\u4ef6\u4e0b\u9009\u62e9\u5408\u9002\u7684\u68c0\u6d4b\u8303\u5f0f\u3002", "method": "\u6bd4\u8f83\u4e24\u79cd\u68c0\u6d4b\u6d41\uff1aForensic Psycholinguistic Stream\u4f7f\u7528CatBoost\u63d0\u53d6\u5fc3\u7406\u8bed\u8a00\u7ebf\u7d22\uff0c\u5177\u89e3\u91ca\u6027\u4e0e\u4f4e\u5ef6\u8fdf\uff1bSemantic Stream\u4f7f\u7528DistilBERT\u8fdb\u884c\u4e0a\u4e0b\u6587\u8bed\u8a00\u7406\u89e3\uff0c\u5e0c\u671b\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u6027\u3002\u5bf9\u542b\u6709\u5bf9\u6297\u6c61\u67d3\u7684\u6570\u636e\u96c6N=7,990\u8fdb\u884c\u8bc4\u4f30\uff0c\u5728Tesla T4 GPU\u4e0a\u8fd0\u884c\uff0c\u6d4b\u91cfAUC\u4e0eF1\uff0c\u8bc4\u4f30\u5ef6\u8fdf\u3002", "result": "DistilBERT\u5728\u5bf9\u6297\u6027\u6c61\u67d3\u6570\u636e\u96c6\u4e0a\u7684AUC\u8fbe\u52301.0000\u3001F1\u4e3a0.9981\uff0c\u5ef6\u8fdf\u7ea67.403\u6beb\u79d2\uff1bCatBoost\u7684AUC\u4e3a0.9905\u3001F1\u4e3a0.9486\uff0c\u5ef6\u8fdf\u7ea60.885\u6beb\u79d2\uff0c\u8d44\u6e90\u5360\u7528\u6781\u4f4e\uff1bGPU\u73af\u5883\u4e0bDistilBERT\u5728\u51c6\u786e\u6027\u65b9\u9762\u5360\u4f18\uff1bCatBoost\u5728\u8fb9\u7f18\u90e8\u7f72\u6216\u6210\u672c\u654f\u611f\u573a\u666f\u5177\u6709\u4f18\u52bf\uff1b\u4e24\u8005\u6210\u672c\u654f\u611f\u5b66\u4e60\u4e0b\u7684ROI\u5747\u8d85\u8fc799.96%\u3002", "conclusion": "\u5bf9\u4e8e\u5177\u5907GPU\u57fa\u7840\u8bbe\u65bd\u7684\u7ec4\u7ec7\uff0cDistilBERT\u63d0\u4f9b\u66f4\u9ad8\u7684\u68c0\u6d4b\u51c6\u786e\u6027\uff1b\u5bf9\u4e8e\u8fb9\u7f18\u90e8\u7f72\u6216\u4f4e\u6210\u672c\u573a\u666f\uff0cCatBoost\u4ecd\u7136\u662f\u4e00\u79cd\u53ef\u884c\u4e14\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.20839", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20839", "abs": "https://arxiv.org/abs/2511.20839", "authors": ["Vladimer Khasia"], "title": "Primal: A Unified Deterministic Framework for Quasi-Orthogonal Hashing and Manifold Learning", "comment": null, "summary": "We present Primal, a deterministic feature mapping framework that harnesses the number-theoretic independence of prime square roots to construct robust, tunable vector representations. Diverging from standard stochastic projections (e.g., Random Fourier Features), our method exploits the Besicovitch property to create irrational frequency modulations that guarantee infinite non-repeating phase trajectories. We formalize two distinct algorithmic variants: (1) StaticPrime, a sequence generation method that produces temporal position encodings empirically approaching the theoretical Welch bound for quasi-orthogonality; and (2) DynamicPrime, a tunable projection layer for input-dependent feature mapping. A central novelty of the dynamic framework is its ability to unify two disparate mathematical utility classes through a single scaling parameter \u03c3. In the low-frequency regime, the method acts as an isometric kernel map, effectively linearizing non-convex geometries (e.g., spirals) to enable high-fidelity signal reconstruction and compressive sensing. Conversely, the high-frequency regime induces chaotic phase wrapping, transforming the projection into a maximum-entropy one-way hash suitable for Hyperdimensional Computing and privacy-preserving Split Learning. Empirical evaluations demonstrate that our framework yields superior orthogonality retention and distribution tightness compared to normalized Gaussian baselines, establishing it as a computationally efficient, mathematically rigorous alternative to random matrix projections. The code is available at https://github.com/VladimerKhasia/primal", "AI": {"tldr": "Primal\u63d0\u51fa\u4e00\u79cd\u786e\u5b9a\u6027\u7279\u5f81\u6620\u5c04\u6846\u67b6\uff0c\u5229\u7528\u8d28\u6570\u5e73\u65b9\u6839\u7684\u6570\u8bba\u72ec\u7acb\u6027\u6784\u5efa\u53ef\u63a7\u7279\u5f81\u5411\u91cf\uff0c\u4e0e\u968f\u673a\u7279\u5f81\u6295\u5f71\u5f62\u6210\u5bf9\u6bd4\u3002\u5305\u542bStaticPrime\u4e0eDynamicPrime\u4e24\u79cd\u53d8\u4f53\uff0c\u5728\u4f4e\u9891\u5b9e\u73b0\u7b49\u8ddd\u6838\u6620\u5c04\u5e76\u7ebf\u6027\u5316\u975e\u51f8\u51e0\u4f55\uff0c\u5728\u9ad8\u9891\u5b9e\u73b0\u76f8\u4f4d\u6df7\u6c8c\u5305\u88c5\u4ee5\u5b9e\u73b0\u6700\u5927\u71b5\u54c8\u5e0c\uff0c\u6027\u80fd\u4e0a\u4f18\u4e8e\u5f52\u4e00\u5316\u9ad8\u65af\u57fa\u7ebf\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u514b\u670d\u968f\u673a\u7279\u5f81\u6295\u5f71\u7684\u968f\u673a\u6027\u4e0e\u4e0d\u53ef\u63a7\u6027\uff0c\u8ffd\u6c42\u786e\u5b9a\u6027\u3001\u53ef\u63a7\u7684\u9ad8\u7ef4\u7279\u5f81\u6620\u5c04\u3002\u5229\u7528Besicovitch\u6027\u8d28\u5f15\u5165\u4e0d\u53ef\u91cd\u590d\u7684\u76f8\u4f4d\u8f68\u8ff9\uff0c\u5e76\u901a\u8fc7\u8d28\u6570\u5e73\u65b9\u6839\u7684\u72ec\u7acb\u6027\u589e\u5f3a\u6b63\u4ea4\u6027\u4e0e\u5206\u5e03\u7a33\u5b9a\u6027\uff1b\u76ee\u6807\u662f\u5728\u4e0d\u540c\u9891\u6bb5\u5b9e\u73b0\u4e0d\u540c\u7684\u51e0\u4f55\u4e0e\u9690\u79c1\u5c5e\u6027\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u53d8\u4f53\uff1aStaticPrime\u548cDynamicPrime\u3002StaticPrime\u901a\u8fc7\u786e\u5b9a\u6027\u5e8f\u5217\u751f\u6210\u5b9e\u73b0\u63a5\u8fd1Welch\u754c\u7684\u51c6\u6b63\u4ea4\u6027\u7684\u5e8f\u5217\u5316\u4f4d\u7f6e\u4fe1\u7f16\u7801\uff1bDynamicPrime\u63d0\u4f9b\u4e00\u4e2a\u8f93\u5165\u76f8\u5173\u7684\u53ef\u4f38\u7f29\u6295\u5f71\u5c42\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u5355\u53c2\u6570\u03c3\u5c06\u4e24\u5927\u6570\u5b66\u6548\u7528\u7c7b\u5408\u4e00\u3002\u5728\u4f4e\u9891\u6bb5\uff0c\u6620\u5c04\u6210\u4e3a\u7b49\u8ddd\u6838\u6620\u5c04\uff0c\u7ebf\u6027\u5316\u975e\u51f8\u51e0\u4f55\u5e76\u652f\u6301\u9ad8\u4fdd\u771f\u91cd\u5efa\u4e0e\u538b\u7f29\u611f\u77e5\uff1b\u5728\u9ad8\u9891\u6bb5\uff0c\u4ea7\u751f\u76f8\u4f4d\u5305\u88c5\u7684\u6df7\u6c8c\u884c\u4e3a\uff0c\u8f6c\u5316\u4e3a\u6700\u5927\u71b5\u7684\u5355\u5411\u54c8\u5e0c\uff0c\u4e14\u9002\u7528\u4e8e\u8d85\u7ef4\u8ba1\u7b97\u4e0e\u9690\u79c1\u4fdd\u62a4\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u3002", "result": "\u4e0e\u5f52\u4e00\u5316\u9ad8\u65af\u57fa\u7ebf\u76f8\u6bd4\uff0c Primal\u5728\u6b63\u4ea4\u6027\u4fdd\u6301\u4e0e\u5206\u5e03\u7d27\u51d1\u5ea6\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u63d0\u4f9b\u4e00\u79cd\u8ba1\u7b97\u6548\u7387\u9ad8\u3001\u6570\u5b66\u57fa\u7840\u624e\u5b9e\u7684\u66ff\u4ee3\u968f\u673a\u77e9\u9635\u6295\u5f71\u7684\u65b9\u6cd5\u3002\u516c\u5f00\u5b9e\u73b0\u4ee3\u7801\uff1aGitHub\u3002", "conclusion": "Primal\u63d0\u4f9b\u4e00\u79cd\u786e\u5b9a\u6027\u3001\u53ef\u63a7\u7684\u7279\u5f81\u6620\u5c04\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u8bba\u4e0e\u76f8\u4f4d\u52a8\u6001\u7279\u6027\u5728\u4f4e\u9891\u548c\u9ad8\u9891\u4e0b\u5b9e\u73b0\u4e0d\u540c\u7684\u51e0\u4f55\u4e0e\u9690\u79c1\u5c5e\u6027\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u4f18\u4e8e\u968f\u673a\u6295\u5f71\u7684\u5206\u5e03\u7279\u6027\u548c\u6b63\u4ea4\u6027\uff0c\u5e76\u5177\u5907\u5f00\u6e90\u5b9e\u73b0\uff0c\u9002\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u4e0e\u9690\u79c1\u4fdd\u62a4\u573a\u666f\u3002"}}
{"id": "2511.21319", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21319", "abs": "https://arxiv.org/abs/2511.21319", "authors": ["Alailton J. Alves Junior", "Daniel Barbosa", "Ricardo A. S. Fernandes", "Denis V. Coury"], "title": "Analytical Phasor-Based Fault Location Enhancement for Wind Farm Collector Networks", "comment": null, "summary": "The increasing integration of Inverter-Based Resources (IBRs) is reshaping fault current characteristics, presenting significant challenges to traditional protection and fault location methods. This paper addresses a key limitation in fault location within wind farm collector networks, i.e., one-terminal phasor-based methods become inaccurate when IBRs are electrically located downstream from the fault. In such cases, the voltage drop caused by IBR fault current injections is not captured by the Intelligent Electronic Device, resulting in a systematic overestimation of fault distance. To mitigate this issue, a general compensation framework was proposed by augmenting classical loop formulations with a distance-dependent voltage correction term. The methodology was derived analytically using a sequence-domain representation and generalized to multiple fault types through a unified notation. It maintains the simplicity and interpretability of conventional approaches and can be implemented using only local measurements. The method was evaluated through EMT simulations in PSCAD using a realistic wind farm model. Results show significant improvements in location accuracy, with average and maximum errors notably reduced, especially for ground-involved faults where reductions exceed 90\\%. Furthermore, the compensation eliminates sensitivity to wind penetration levels and ensures uniform performance across feeders, positioning the method as a practical solution for modern renewable-dominated grids.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u7528\u7684\u8865\u507f\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u7ecf\u5178\u73af\u8def\u516c\u5f0f\u4e2d\u52a0\u5165\u4e0e\u8ddd\u79bb\u76f8\u5173\u7684\u7535\u538b\u4fee\u6b63\u9879\u6765\u6539\u8fdb\u98ce\u7535\u573a\u96c6\u6d41\u6bcd\u7ebf\u5728\u542bIBR\u7684\u60c5\u666f\u4e0b\u7684\u6545\u969c\u5b9a\u4f4d\u51c6\u786e\u6027\uff1b\u8be5\u65b9\u6cd5\u4ee5\u5e8f\u57df\u5206\u6790\u63a8\u5bfc\uff0c\u53ef\u7528\u4e8e\u591a\u79cd\u6545\u969c\uff0c\u5e76\u4ec5\u9700\u5c40\u90e8\u91cf\u6d4b\u3002", "motivation": "\u968f\u7740\u5e76\u7f51\u7684\u9006\u53d8\u578b\u8d44\u6e90(IBRs)\u6bd4\u4f8b\u6301\u7eed\u4e0a\u5347\uff0c\u6545\u969c\u7535\u6d41\u53ca\u7535\u538b\u5206\u5e03\u53d1\u751f\u663e\u8457\u53d8\u5316\uff0c\u4f20\u7edf\u7684\u4e00\u7aef\u7aef\u5b50\u76f8\u91cf\u6cd5\u5728IBR\u4f4d\u4e8e\u6545\u969c\u4e0b\u6e38\u65f6\u4ea7\u751f\u7cfb\u7edf\u6027\u8ddd\u79bb\u8fc7\u4f30\uff0c\u5bfc\u81f4\u6545\u969c\u5b9a\u4f4d\u4e0d\u51c6\u786e\uff1b\u9700\u8981\u4e00\u4e2a\u7b80\u5355\u3001\u57fa\u4e8e\u5c40\u90e8\u91cf\u6d4b\u3001\u5e76\u5bf9\u591a\u79cd\u6545\u969c\u7c7b\u578b\u7edf\u4e00\u5904\u7406\u7684\u4fee\u6b63\u673a\u5236\u3002", "method": "\u5728\u7ecf\u5178\u73af\u8def\u65b9\u7a0b\u4e2d\u5f15\u5165\u8ddd\u79bb\u76f8\u5173\u7684\u7535\u538b\u4fee\u6b63\u9879\uff0c\u5e76\u4ee5\u5e8f\u57df\u8868\u793a\u8fdb\u884c\u5206\u6790\u63a8\u5bfc\uff1b\u5c06\u5176\u63a8\u5e7f\u5230\u591a\u79cd\u6545\u969c\u60c5\u5f62\uff0c\u4fdd\u6301\u65b9\u6cd5\u7684\u76f4\u89c2\u6027\u548c\u6613\u5b9e\u73b0\u6027\uff1b\u4ec5\u4f9d\u8d56\u5c40\u90e8\u6d4b\u91cf\u5b9e\u73b0\u3002", "result": "\u5728PSCAD\u7684EMT\u4eff\u771f\u4e2d\uff0c\u57fa\u4e8e\u771f\u5b9e\u98ce\u7535\u573a\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5b9a\u4f4d\u8bef\u5dee\u663e\u8457\u964d\u4f4e\uff0c\u5e73\u5747\u548c\u6700\u5927\u8bef\u5dee\u5747\u6709\u660e\u663e\u6539\u5584\uff0c\u5c24\u5176\u662f\u5bf9\u63a5\u5730\u6545\u969c\u8bef\u5dee\u4e0b\u964d\u8d85\u8fc790%\uff1b\u4fee\u6b63\u9879\u5bf9\u98ce\u901f/\u6e17\u900f\u6c34\u5e73\u4e0d\u654f\u611f\uff0c\u4e14\u5728\u5404\u9988\u7ebf\u4e0a\u7684\u6027\u80fd\u8d8b\u4e8e\u4e00\u81f4\u3002", "conclusion": "\u8be5\u8865\u507f\u6846\u67b6\u4e3a\u73b0\u4ee3\u4ee5\u53ef\u518d\u751f\u80fd\u6e90\u4e3a\u4e3b\u7684\u7535\u7f51\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u6d01\u3001\u53ef\u5b9e\u73b0\u7684\u5c40\u90e8\u91cf\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u7f13\u89e3IBR\u5f15\u5165\u7684\u6545\u969c\u5b9a\u4f4d\u504f\u5dee\uff0c\u63d0\u5347\u6545\u969c\u5b9a\u4f4d\u7684\u9c81\u68d2\u6027\u548c\u9002\u7528\u6027\u3002"}}
{"id": "2511.20870", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20870", "abs": "https://arxiv.org/abs/2511.20870", "authors": ["Nan Jiang"], "title": "Selecting Belief-State Approximations in Simulators with Latent States", "comment": null, "summary": "State resetting is a fundamental but often overlooked capability of simulators. It supports sample-based planning by allowing resets to previously encountered simulation states, and enables calibration of simulators using real data by resetting to states observed in real-system traces. While often taken for granted, state resetting in complex simulators can be nontrivial: when the simulator comes with latent variables (states), state resetting requires sampling from the posterior over the latent state given the observable history, a.k.a. the belief state (Silver and Veness, 2010). While exact sampling is often infeasible, many approximate belief-state samplers can be constructed, raising the question of how to select among them using only sampling access to the simulator.\n  In this paper, we show that this problem reduces to a general conditional distribution-selection task and develop a new algorithm and analysis under sampling-only access. Building on this reduction, the belief-state selection problem admits two different formulations: latent state-based selection, which directly targets the conditional distribution of the latent state, and observation-based selection, which targets the induced distribution over the observation. Interestingly, these formulations differ in how their guarantees interact with the downstream roll-out methods: perhaps surprisingly, observation-based selection may fail under the most natural roll-out method (which we call Single-Reset) but enjoys guarantees under the less conventional alternative (which we call Repeated-Reset). Together with discussion on issues such as distribution shift and the choice of sampling policies, our paper reveals a rich landscape of algorithmic choices, theoretical nuances, and open questions, in this seemingly simple problem.", "AI": {"tldr": "\u5c06\u72b6\u6001\u91cd\u7f6e\u4e0e\u4fe1\u5ff5\u72b6\u6001\u91c7\u6837\u95ee\u9898\u7edf\u4e00\u4e3a\u6761\u4ef6\u5206\u5e03\u9009\u62e9\u95ee\u9898\uff0c\u63d0\u51fa\u5728\u4ec5\u80fd\u91c7\u6837\u7684\u8bbe\u5b9a\u4e0b\u7684\u7b97\u6cd5\u4e0e\u7406\u8bba\u5206\u6790\uff0c\u533a\u5206\u6f5c\u5728\u72b6\u6001\u57fa\u62e3\u9009\u4e0e\u89c2\u6d4b\u57fa\u62e3\u9009\uff0c\u4ee5\u53ca\u4e24\u79cd\u56de\u6eda/\u5c55\u5f00\u7b56\u7565\u5bf9\u4fdd\u8bc1\u7684\u5f71\u54cd\u3002", "motivation": "\u5728\u590d\u6742\u4eff\u771f\u5668\u4e2d\uff0c\u91cd\u7f6e\u5230\u5386\u53f2\u72b6\u6001\u5bf9\u6837\u672c\u89c4\u5212\u548c\u4e0e\u771f\u5b9e\u6570\u636e\u7684\u6821\u51c6\u81f3\u5173\u91cd\u8981\uff1b\u82e5\u5b58\u5728\u6f5c\u5728\u53d8\u91cf\uff0c\u9700\u4ece\u89c2\u6d4b\u5386\u53f2\u7684\u540e\u9a8c\u4e2d\u62bd\u6837\u4fe1\u5ff5\u72b6\u6001\uff0c\u76f4\u63a5\u91c7\u6837\u5f80\u5f80\u4e0d\u53ef\u884c\uff0c\u56e0\u6b64\u9700\u8981\u5728\u4ec5\u6709\u91c7\u6837\u80fd\u529b\u7684\u6761\u4ef6\u4e0b\u9009\u62e9\u5408\u9002\u7684\u4fe1\u5ff5\u72b6\u6001\u91c7\u6837\u5668\u3002", "method": "\u5c06\u4fe1\u5ff5\u72b6\u6001\u9009\u62e9\u95ee\u9898\u5f52\u7ed3\u4e3a\u6761\u4ef6\u5206\u5e03\u9009\u62e9\u4efb\u52a1\uff0c\u63d0\u51fa\u65b0\u7b97\u6cd5\u5e76\u7ed9\u51fa\u5728\u4ec5\u80fd\u91c7\u6837\u7684\u8bbf\u95ee\u6761\u4ef6\u4e0b\u7684\u5206\u6790\u3002\u63d0\u51fa\u4e24\u79cd\u5f62\u5f0f\uff1a\u6f5c\u5728\u72b6\u6001\u57fa\u62e3\u9009\uff08\u76f4\u63a5\u9488\u5bf9\u6f5c\u5728\u72b6\u6001\u7684\u6761\u4ef6\u5206\u5e03\uff09\u4e0e\u89c2\u6d4b\u57fa\u62e3\u9009\uff08\u9488\u5bf9\u89c2\u6d4b\u5206\u5e03\uff09\u3002\u5206\u6790\u5b83\u4eec\u4e0e\u4e0b\u6e38\u56de\u6eda\u5c55\u5f00\u65b9\u6cd5\u7684\u5173\u7cfb\uff0c\u7279\u522b\u5bf9\u5355\u6b21\u91cd\u7f6e\uff08Single-Reset\uff09\u4e0e\u91cd\u590d\u91cd\u7f6e\uff08Repeated-Reset\uff09\u7684\u5f71\u54cd\u3002", "result": "\u7406\u8bba\u4e0a\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u7b97\u6cd5\u53ca\u5176\u5728\u4e24\u79cd\u9009\u62e9\u8303\u5f0f\u4e0b\u7684 guarantees\uff1b\u53d1\u73b0\u89c2\u6d4b\u57fa\u62e3\u9009\u5728\u6700\u81ea\u7136\u7684\u56de\u6eda\u7b56\u7565\u4e0b\u53ef\u80fd\u5931\u6548\uff0c\u4f46\u5728\u53e6\u4e00\u79cd\u56de\u6eda\u7b56\u7565\u4e0b\u5177\u5907\u4fdd\u8bc1\u3002", "conclusion": "\u5bf9\u4fe1\u5ff5\u72b6\u6001\u9009\u62e9\u95ee\u9898\u7684\u7b97\u6cd5\u9009\u9879\u3001\u7406\u8bba\u7ec6\u8282\u4e0e\u5f00\u653e\u95ee\u9898\u7ed9\u51fa\u6e05\u6670\u7684\u5168\u666f\uff0c\u5f3a\u8c03\u5206\u5e03\u53d8\u6362\u4e0e\u91c7\u6837\u7b56\u7565\u7684\u5173\u952e\u5f71\u54cd\uff0c\u63ed\u793a\u8be5\u770b\u4f3c\u7b80\u5355\u95ee\u9898\u4e2d\u7684\u4e30\u5bcc\u666f\u89c2\u3002"}}
{"id": "2511.21343", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21343", "abs": "https://arxiv.org/abs/2511.21343", "authors": ["Laura Boca de Giuli", "Samuel Mallick", "Alessio La Bella", "Azita Dabiri", "Bart De Schutter", "Riccardo Scattolini"], "title": "Model Predictive Control and Moving Horizon Estimation using Statistically Weighted Data-Based Ensemble Models", "comment": "7 pages, 4 figures, submitted to ECC 2026", "summary": "This paper presents a model predictive control (MPC) framework leveraging an ensemble of data-based models to optimally control complex systems under multiple operating conditions. A novel combination rule for ensemble models is proposed, based on the statistical Mahalanobis distance, enabling the ensemble weights to suitably vary across the prediction window based on the system input. In addition, a novel state observer for ensemble models is developed using moving horizon estimation (MHE). The effectiveness of the proposed methodology is demonstrated on a benchmark energy system operating under multiple conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8eMPC\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8e\u6570\u636e\u7684\u6a21\u578b\u96c6\u5408\uff0c\u901a\u8fc7\u57fa\u4e8e\u9a6c\u6c0f\u8ddd\u79bb\u7684\u7ec4\u5408\u89c4\u5219\u5b9e\u73b0\u8de8\u9884\u6d4b\u7a97\u7684\u52a0\u6743\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u79fb\u52a8\u89c6\u7a97\u4f30\u8ba1\u7684\u96c6\u5408\u6a21\u578b\u72b6\u6001\u89c2\u6d4b\u5668\uff0c\u5728\u591a\u5de5\u51b5\u80fd\u91cf\u7cfb\u7edf\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u5728\u590d\u6742\u7cfb\u7edf\u7684\u591a\u5de5\u51b5\u4e0b\uff0c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u548c\u5de5\u51b5\u5207\u6362\u4f1a\u524a\u5f31MPC\u8868\u73b0\u3002\u91c7\u7528\u6a21\u578b\u96c6\u5408\u53ef\u8986\u76d6\u591a\u79cd\u884c\u4e3a\u6a21\u5f0f\uff1b\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u6a21\u578b\u4e0e\u81ea\u9002\u5e94\u6743\u91cd\u4ee5\u63d0\u9ad8\u9c81\u68d2\u6027\u4e0e\u6cdb\u5316\u80fd\u529b\uff1b\u540c\u65f6\u9700\u53ef\u9760\u7684\u72b6\u6001\u4f30\u8ba1\u4ee5\u652f\u6491\u89c2\u6d4b\u4e0e\u63a7\u5236\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u6570\u636e\u9a71\u52a8\u6a21\u578b\u96c6\u5408\u7528\u4e8eMPC\uff1b\u63d0\u51fa\u4ee5\u7edf\u8ba1\u9a6c\u6c0f\u8ddd\u79bb\u4e3a\u57fa\u7840\u7684\u7ec4\u5408\u89c4\u5219\uff0c\u4f7f\u96c6\u5408\u6743\u91cd\u5728\u9884\u6d4b\u7a97\u5185\u968f\u7cfb\u7edf\u8f93\u5165\u800c\u52a8\u6001\u53d8\u5316\uff1b\u5f00\u53d1\u7528\u4e8e\u96c6\u5408\u6a21\u578b\u7684\u57fa\u4e8e\u79fb\u52a8\u89c6\u7a97\u4f30\u8ba1\u7684\u72b6\u6001\u89c2\u6d4b\u5668\uff1b\u5728\u4e00\u4e2a\u591a\u5de5\u51b5\u7684\u57fa\u51c6\u80fd\u91cf\u7cfb\u7edf\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5728\u57fa\u51c6\u80fd\u91cf\u7cfb\u7edf\u53ca\u591a\u5de5\u51b5\u60c5\u5f62\u4e0b\u8bc1\u660e\u4e86\u6240\u63d0\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u8868\u73b0\u51fa\u5bf9\u5de5\u51b5\u53d8\u5316\u7684\u9c81\u68d2\u6027\u548c\u63a7\u5236\u6027\u80fd\u7684\u6539\u5584\uff08abstract\u672a\u7ed9\u51fa\u5177\u4f53\u6570\u503c\uff09\u3002", "conclusion": "\u7ed9\u51fa\u4e86\u4e00\u79cd\u5c06\u6570\u636e\u9a71\u52a8\u6a21\u578b\u96c6\u5408\u4e0eMPC\u7ed3\u5408\u7684\u65b0\u9014\u5f84\uff0c\u5e76\u901a\u8fc7MHE\u63d0\u5347\u96c6\u5408\u6a21\u578b\u7684\u72b6\u6001\u4f30\u8ba1\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u7684\u9c81\u68d2\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u610f\u4e49\u7684\u7814\u7a76\u65b9\u5411\uff0c\u672a\u6765\u53ef\u5728\u66f4\u591a\u7cfb\u7edf\u548c\u5b9e\u65f6\u5b9e\u73b0\u65b9\u9762\u8fdb\u884c\u6269\u5c55\u4e0e\u8bc4\u4f30\u3002"}}
{"id": "2511.21371", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21371", "abs": "https://arxiv.org/abs/2511.21371", "authors": ["Yichen Liu", "Hongyu Wu", "Bo Liu"], "title": "Evaluation of Large Language Models for Numeric Anomaly Detection in Power Systems", "comment": null, "summary": "Large language models (LLMs) have gained increasing attention in power grids for their general-purpose capabilities. Meanwhile, anomaly detection (AD) remains critical for grid resilience, requiring accurate and interpretable decisions based on multivariate telemetry. Yet the performance of LLMs on large-scale numeric data for AD remains largely unexplored. This paper presents a comprehensive evaluation of LLMs for numeric AD in power systems. We use GPT-OSS-20B as a representative model and evaluate it on the IEEE 14-bus system. A standardized prompt framework is applied across zero-shot, few-shot, in-context learning, low rank adaptation (LoRA), fine-tuning, and a hybrid LLM-traditional approach. We adopt a rule-aware design based on the three-sigma criterion, and report detection performance and rationale quality. This study lays the groundwork for further investigation into the limitations and capabilities of LLM-based AD and its integration with classical detectors in cyber-physical power grid applications.", "AI": {"tldr": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u7535\u7f51\u6570\u503c\u5f02\u5e38\u68c0\u6d4b\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u57fa\u4e8eGPT-OSS-20B\uff0c\u5728IEEE 14-bus\u4e0a\u6bd4\u8f83\u591a\u79cd\u5b66\u4e60/\u5fae\u8c03\u7b56\u7565\u5e76\u5f15\u5165\u4e09\u897f\u683c\u739b\u89c4\u5219\uff0c\u63ed\u793a\u6f5c\u529b\u4e0e\u5c40\u9650\uff0c\u4e3a\u4e0e\u7ecf\u5178\u63a2\u6d4b\u5668\u7684\u96c6\u6210\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u9ad8\u538b\u7535\u7f51\u7684\u591a\u53d8\u91cf\u9065\u6d4b\u6570\u636e\u9700\u8981\u9ad8\u51c6\u786e\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u73b0\u6709\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5f80\u5f80\u96be\u4ee5\u517c\u987e\u5927\u89c4\u6a21\u6570\u503c\u6570\u636e\u7684\u9c81\u68d2\u6027\u4e0e\u63a8\u7406\u900f\u660e\u6027\uff1b\u5c3d\u7ba1LLMs\u5728\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u5176\u5728\u5927\u89c4\u6a21\u6570\u503c\u5f02\u5e38\u68c0\u6d4b\u4e0a\u7684\u5e94\u7528\u7814\u7a76\u5c1a\u4e0d\u5145\u5206\u3002", "method": "\u91c7\u7528\u6807\u51c6\u5316\u63d0\u793a\u6846\u67b6\uff0c\u5728\u96f6-shot\u3001\u5c11-shot\u3001\u5c31\u5730\u5b66\u4e60\u3001\u4f4e\u79e9\u9002\u914d\uff08LoRA\uff09\u3001\u5fae\u8c03\u3001\u4ee5\u53ca\u6df7\u5408LLM\u4e0e\u4f20\u7edf\u68c0\u6d4b\u7684\u60c5\u5883\u4e0b\u8fdb\u884c\u8bc4\u4f30\uff1b\u8bbe\u8ba1\u57fa\u4e8e\u4e09\u897f\u683c\u739b\u7684\u89c4\u5219\u611f\u77e5\u68c0\u6d4b\u7b56\u7565\uff1b\u4ee5IEEE 14-bus\u7cfb\u7edf\u4e3a\u8bc4\u4f30\u5bf9\u8c61\uff0c\u6bd4\u8f83\u4e0d\u540c\u8bad\u7ec3/\u63a8\u7406\u7b56\u7565\u4e0b\u7684\u68c0\u6d4b\u6027\u80fd\u4e0e\u63a8\u7406\u8d28\u91cf\uff08 rationale quality \uff09\u3002", "result": "\u62a5\u544a\u68c0\u6d4b\u6027\u80fd\u4e0e\u63a8\u7406\u8d28\u91cf\uff0c\u672a\u7ed9\u51fa\u5177\u4f53\u6570\u503c\uff0c\u4f46\u9a8c\u8bc1\u4e86LLMs\u5728\u6570\u503c\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u5b66\u4e60\u8303\u5f0f\u4e0b\u7684\u8868\u73b0\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u540e\u7eed\u4e0e\u7ecf\u5178\u63a2\u6d4b\u5668\u878d\u5408\u7684\u7814\u7a76\u63d0\u4f9b\u57fa\u7ebf\u4e0e\u65b9\u5411\u3002", "conclusion": "LLM\u4e3a\u6570\u503c\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u8def\u5f84\uff0c\u5177\u6709\u6f5c\u529b\u4e0e\u5c40\u9650\u5e76\u5b58\uff1b\u672c\u6587 establisher \u57fa\u7ebf\uff0c\u6307\u660e\u672a\u6765\u5728\u4e0e\u4f20\u7edf\u63a2\u6d4b\u5668\u7ed3\u5408\u3001\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u4e0e\u9c81\u68d2\u6027\u65b9\u9762\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.20893", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20893", "abs": "https://arxiv.org/abs/2511.20893", "authors": ["Aodong Li", "Abishek Sankararaman", "Balakrishnan Narayanaswamy"], "title": "Probabilistic Hash Embeddings for Online Learning of Categorical Features", "comment": "AAAI 2026 Oral", "summary": "We study streaming data with categorical features where the vocabulary of categorical feature values is changing and can even grow unboundedly over time. Feature hashing is commonly used as a pre-processing step to map these categorical values into a feature space of fixed size before learning their embeddings. While these methods have been developed and evaluated for offline or batch settings, in this paper we consider online settings. We show that deterministic embeddings are sensitive to the arrival order of categories and suffer from forgetting in online learning, leading to performance deterioration. To mitigate this issue, we propose a probabilistic hash embedding (PHE) model that treats hash embeddings as stochastic and applies Bayesian online learning to learn incrementally from data. Based on the structure of PHE, we derive a scalable inference algorithm to learn model parameters and infer/update the posteriors of hash embeddings and other latent variables. Our algorithm (i) can handle an evolving vocabulary of categorical items, (ii) is adaptive to new items without forgetting old items, (iii) is implementable with a bounded set of parameters that does not grow with the number of distinct observed values on the stream, and (iv) is invariant to the item arrival order. Experiments in classification, sequence modeling, and recommendation systems in online learning setups demonstrate the superior performance of PHE while maintaining high memory efficiency (consumes as low as 2~4 memory of a one-hot embedding table). Supplementary materials are at https://github.com/aodongli/probabilistic-hash-embeddings", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6982\u7387\u54c8\u5e0c\u5d4c\u5165\uff08PHE\uff09\u7528\u4e8e\u5728\u7ebf\u5b66\u4e60\u7684\u5206\u7c7b\u7279\u5f81\uff0c\u89e3\u51b3\u5728\u6d41\u6570\u636e\u4e2d\u7c7b\u522b\u8bcd\u6c47\u4e0d\u65ad\u6269\u589e\u65f6\u7684\u786e\u5b9a\u6027\u54c8\u5e0c\u5d4c\u5165\u6613\u53d7\u5230\u5230\u8fbe\u987a\u5e8f\u5f71\u54cd\u548c\u9057\u5fd8\u7684\u95ee\u9898\u3002\u901a\u8fc7\u8d1d\u53f6\u65af\u5728\u7ebf\u5b66\u4e60\u5bf9\u54c8\u5e0c\u5d4c\u5165\u53ca\u76f8\u5173\u6f5c\u53d8\u91cf\u8fdb\u884c\u589e\u91cf\u63a8\u65ad\uff0c\u6784\u5efa\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u5bf9\u65b0\u9879\u81ea\u9002\u5e94\u4e14\u53c2\u6570\u91cf\u754c\u9650\u56fa\u5b9a\u3001\u5bf9\u9879\u5230\u8fbe\u987a\u5e8f\u4e0d\u654f\u611f\u7684\u5d4c\u5165\u6a21\u578b\uff0c\u5728\u5206\u7c7b\u3001\u5e8f\u5217\u5efa\u6a21\u548c\u63a8\u8350\u7b49\u5728\u7ebf\u4efb\u52a1\u4e0a\u663e\u793a\u51fa\u66f4\u4f18\u7684\u6027\u80fd\u548c\u66f4\u9ad8\u7684\u5185\u5b58\u6548\u7387\u3002", "motivation": "\u5728\u7ebf\u8bbe\u7f6e\u4e0b\uff0c\u7c7b\u522b\u7279\u5f81\u7684\u8bcd\u6c47\u8868\u4f1a\u4e0d\u65ad\u6f14\u5316\uff0c\u4f20\u7edf\u7684\u786e\u5b9a\u6027\u54c8\u5e0c\u5d4c\u5165\u6613\u53d7\u5230\u8fbe\u987a\u5e8f\u5f71\u54cd\u5e76\u4ea7\u751f\u9057\u5fd8\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u589e\u91cf\u3001\u5bf9\u65b0\u9879\u53cb\u597d\u4e14\u8bb0\u5fc6\u5f00\u9500\u53d7\u63a7\u7684\u5d4c\u5165\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6982\u7387\u54c8\u5e0c\u5d4c\u5165\uff08PHE\uff09\uff0c\u5c06\u54c8\u5e0c\u5d4c\u5165\u89c6\u4e3a\u968f\u673a\u53d8\u91cf\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u5728\u7ebf\u5b66\u4e60\u8fdb\u884c\u589e\u91cf\u63a8\u65ad\u3002\u57fa\u4e8ePHE\u6784\u5efa\u53ef\u6269\u5c55\u7684\u63a8\u65ad\u7b97\u6cd5\uff0c\u5b66\u4e60\u6a21\u578b\u53c2\u6570\u5e76\u63a8\u65ad/\u66f4\u65b0\u54c8\u5e0c\u5d4c\u5165\u53ca\u5176\u4ed6\u6f5c\u5728\u53d8\u91cf\u7684\u540e\u9a8c\u3002\u7b97\u6cd5\u5177\u5907\uff1a\u5904\u7406\u6f14\u5316\u8bcd\u6c47\u8868\u3001\u5bf9\u65b0\u9879\u81ea\u9002\u5e94\u4e14\u4e0d\u5fd8\u8bb0\u65e7\u9879\u3001\u53c2\u6570\u91cf\u754c\u9650\u4e14\u4e0d\u968f\u89c2\u6d4b\u503c\u6570\u76ee\u589e\u957f\u3001\u5bf9\u9879\u5230\u8fbe\u987a\u5e8f\u4e0d\u654f\u611f\u3002", "result": "\u5728\u5728\u7ebf\u5b66\u4e60\u8bbe\u5b9a\u4e0b\u8fdb\u884c\u5206\u7c7b\u3001\u5e8f\u5217\u5efa\u6a21\u548c\u63a8\u8350\u4efb\u52a1\u7684\u5b9e\u9a8c\uff0c\u663e\u793aPHE\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u54c8\u5e0c\u5d4c\u5165\uff0c\u4e14\u5185\u5b58\u5f00\u9500\u6781\u4f4e\uff08\u4ec5\u4e3a\u5355\u70ed\u5d4c\u5165\u8868\u7684\u7ea62\u20134%\uff09\u3002 supplementary materials\u5728GitHub\u63d0\u4f9b\u3002", "conclusion": "PHE\u63d0\u4f9b\u4e86\u4e00\u79cd\u9c81\u68d2\u3001\u53ef\u6269\u5c55\u4e14\u5bf9\u8bcd\u6c47\u52a8\u6001\u6f14\u5316\u5177\u6709\u5bb9\u9519\u6027\u7684\u5728\u7ebf\u5d4c\u5165\u89e3\u51b3\u65b9\u6848\uff0c\u786e\u4fdd\u4e0d\u968f\u9879\u5230\u8fbe\u987a\u5e8f\u800c\u9057\u5fd8\uff0c\u9002\u7528\u4e8e\u6d41\u6570\u636e\u573a\u666f\u7684\u5206\u7c7b\u3001\u5e8f\u5217\u5efa\u6a21\u4e0e\u63a8\u8350\u7b49\u4efb\u52a1\u3002"}}
{"id": "2511.21385", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21385", "abs": "https://arxiv.org/abs/2511.21385", "authors": ["Andr\u00e9s E. Quintero", "Vin\u00edcius A. Lacerda", "Oriol Gomis-Bellmunt", "Mois\u00e9s J. B. B. Davi", "Mario Oleskovicz"], "title": "Influence of converter current limiting and prioritization on protection of highly IBR-penetrated networks", "comment": "Submitted to DPSP Global 2026", "summary": "This paper investigates how grid-forming (GFM) and grid-following (GFL) control strategies in inverter-based resources (IBRs) influence line distance and differential protection in converter-dominated transmission systems. A modified IEEE 39-bus system is evaluated with GFM and GFL units equipped with low-voltage ride-through logic, current limiting, and positive- or negative-sequence prioritization. Distance protection is implemented with a mho characteristic, while line differential protection uses an alpha-plane approach. Results show that phase-to-ground loops in distance protection can substantially overestimate the fault location near the Zone-1 reach. For line differential protection, external faults may cause the operating point to briefly enter the trip region of the alpha-plane, even for the healthy-phase in ABG faults under GFL control and during the initial moments of the fault, demanding strong external security measures. These findings highlight that modern converter controls, together with current limitation and sequence-current prioritization, can compromise the reliability and security of traditional protection schemes.", "AI": {"tldr": "\u73b0\u4ee3\u53d8\u6d41\u5668\u63a7\u5236\uff08GFM/GFL\uff09\u5bf9\u8ddd\u79bb\u4fdd\u62a4\u548c\u5206\u5e03\u4fdd\u62a4\u7684\u53ef\u9760\u6027\u4e0e\u5b89\u5168\u6027\u6709\u663e\u8457\u5f71\u54cd\uff0c\u53ef\u80fd\u5bfc\u81f4\u6545\u969c\u5b9a\u4f4d\u8bef\u5dee\u4e0e\u8bef\u52a8\u4f5c\u98ce\u9669\uff0c\u9700\u6539\u8fdb\u4fdd\u62a4\u7b56\u7565\u3002", "motivation": "\u5728 converter-dominated \u4f20\u8f93\u7cfb\u7edf\u4e2d\uff0c\u4e86\u89e3\u7f51\u683c-forming \u4e0e\u7f51\u683c-following \u63a7\u5236\u5bf9\u4f20\u7edf\u4fdd\u62a4\uff08\u8ddd\u79bb\u4fdd\u62a4\u3001\u7ebf\u5dee\u4fdd\u62a4\uff09\u7684\u5f71\u54cd\uff0c\u4ee5\u63d0\u5347\u4fdd\u62a4\u7684\u53ef\u9760\u6027\u4e0e\u5b89\u5168\u6027\uff1b\u5e76\u8bc4\u4f30\u4f4e\u538b\u7a7f\u8d8a\u3001\u9650\u6d41\u4ee5\u53ca\u5e8f\u5206\u4f18\u5148\u7ea7\u7684\u5f71\u54cd\u3002", "method": "\u5728\u6539\u8fdb\u7684IEEE 39-bus \u7cfb\u7edf\u4e2d\uff0c\u90e8\u7f72\u5e26 LVRT\u3001\u9650\u6d41\u4e0e\u6b63/\u8d1f\u5e8f\u4f18\u5148\u7ea7\u7684 GFM \u4e0e GFL \u5355\u5143\uff1b\u8ddd\u79bb\u4fdd\u62a4\u91c7\u7528 mho \u7279\u6027\uff0c\u7ebf\u5dee\u4fdd\u62a4\u91c7\u7528 alpha-plane \u65b9\u6cd5\uff0c\u8bc4\u4f30\u5728\u4e0d\u540c\u5de5\u51b5\u4e0b\u7684\u4fdd\u62a4\u884c\u4e3a\u3002", "result": "\u8ddd\u79bb\u4fdd\u62a4\u4e2d\u76f8\u5bf9\u5730\u73af\u8def\u4f1a\u663e\u8457\u9ad8\u4f30 Zone-1 \u8986\u76d6\u533a\u5185\u8fd1\u7aef\u6545\u969c\u4f4d\u7f6e\uff1b\u7ebf\u5dee\u4fdd\u62a4\u65b9\u9762\uff0c\u5916\u90e8\u6545\u969c\u53ef\u80fd\u4f7f\u5de5\u4f5c\u70b9\u77ed\u65f6\u8fdb\u5165 alpha-plane \u7684\u8df3\u95f8\u533a\uff0c\u751a\u81f3\u5728 ABG \u6545\u969c\u7684\u5065\u5eb7\u76f8\u4e0a\u4e5f\u5982\u6b64\uff0c\u4e14\u53d1\u751f\u5728\u6545\u969c\u521d\u671f\uff0c\u9700\u5f3a\u5916\u90e8\u5b89\u5168\u63aa\u65bd\u3002\u603b\u4f53\u800c\u8a00\uff0c\u73b0\u4ee3\u53d8\u6d41\u5668\u63a7\u5236\u7ed3\u5408\u9650\u6d41\u4e0e\u5e8f\u5206\u4f18\u5148\u7ea7\u4f1a\u524a\u5f31\u4f20\u7edf\u4fdd\u62a4\u7684\u53ef\u9760\u6027\u4e0e\u5b89\u5168\u6027\u3002", "conclusion": "\u73b0\u4ee3\u53d8\u6d41\u5668\u63a7\u5236\u7b56\u7565\u82e5\u4e0e\u9650\u6d41\u3001\u5e8f\u5206\u4f18\u5148\u534f\u540c\u4f5c\u7528\uff0c\u4f1a\u5bf9\u8ddd\u79bb\u4fdd\u62a4\u4e0e\u7ebf\u5dee\u4fdd\u62a4\u5f62\u6210\u6311\u6218\uff0c\u9700\u8981\u5bf9\u4fdd\u62a4\u7b97\u6cd5\u548c\u4fdd\u62a4\u533a\u8bbe\u7f6e\u8fdb\u884c\u518d\u8bbe\u8ba1\u4e0e\u589e\u5f3a\u3002"}}
{"id": "2511.20909", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.20909", "abs": "https://arxiv.org/abs/2511.20909", "authors": ["Anil K. Saini", "Jose Guadalupe Hernandez", "Emily F. Wong", "Debanshi Misra", "Jason H. Moore"], "title": "Evolved SampleWeights for Bias Mitigation: Effectiveness Depends on Optimization Objectives", "comment": null, "summary": "Machine learning models trained on real-world data may inadvertently make biased predictions that negatively impact marginalized communities. Reweighting is a method that can mitigate such bias in model predictions by assigning a weight to each data point used during model training. In this paper, we compare three methods for generating these weights: (1) evolving them using a Genetic Algorithm (GA), (2) computing them using only dataset characteristics, and (3) assigning equal weights to all data points. Model performance under each strategy was evaluated using paired predictive and fairness metrics, which also served as optimization objectives for the GA during evolution. Specifically, we used two predictive metrics (accuracy and area under the Receiver Operating Characteristic curve) and two fairness metrics (demographic parity difference and subgroup false negative fairness). Using experiments on eleven publicly available datasets (including two medical datasets), we show that evolved sample weights can produce models that achieve better trade-offs between fairness and predictive performance than alternative weighting methods. However, the magnitude of these benefits depends strongly on the choice of optimization objectives. Our experiments reveal that optimizing with accuracy and demographic parity difference metrics yields the largest number of datasets for which evolved weights are significantly better than other weighting strategies in optimizing both objectives.", "AI": {"tldr": "\u901a\u8fc7\u6bd4\u8f83\u4e09\u79cd\u6570\u636e\u70b9\u52a0\u6743\u751f\u6210\u65b9\u6cd5\uff0c\u7814\u7a76\u9057\u4f20\u7b97\u6cd5\u6f14\u5316\u6743\u91cd\u5728\u516c\u5e73\u6027\u4e0e\u9884\u6d4b\u6027\u80fd\u6743\u8861\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u76ee\u6807\u51fd\u6570\u7684\u9009\u62e9\u5bf9\u6536\u76ca\u5f71\u54cd\u663e\u8457\uff0c\u4e14\u4ee5\u51c6\u786e\u6027+\u4eba\u53e3\u7edf\u8ba1\u5e73\u7b49\u5dee\u5f02\u4e3a\u76ee\u6807\u65f6\u6536\u76ca\u6700\u663e\u8457\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53ef\u80fd\u5bf9\u8fb9\u7f18\u7fa4\u4f53\u4ea7\u751f\u504f\u89c1\u3002\u901a\u8fc7\u5bf9\u8bad\u7ec3\u6570\u636e\u70b9\u8d4b\u4e88\u6743\u91cd\u6765\u7f13\u89e3\u504f\u89c1\u662f\u4e00\u4e2a\u5e38\u7528\u7b56\u7565\u3002\u672c\u6587\u6bd4\u8f83\u4e09\u79cd\u6743\u91cd\u751f\u6210\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\u4e0b\u8bc4\u4f30\u5b83\u4eec\u5728\u9884\u6d4b\u6027\u80fd\u4e0e\u516c\u5e73\u6027\u4e4b\u95f4\u7684\u6298\u8877\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u6743\u91cd\u751f\u6210\u7b56\u7565\uff1a\u2460\u7528\u9057\u4f20\u7b97\u6cd5(EA)\u6f14\u5316\u6837\u672c\u6743\u91cd\uff1b\u2461\u4ec5\u57fa\u4e8e\u6570\u636e\u96c6\u7279\u5f81\u8ba1\u7b97\u6743\u91cd\uff1b\u2462\u5c06\u6240\u6709\u6837\u672c\u8bbe\u4e3a\u7b49\u6743\u91cd\u3002GA\u5728\u8fdb\u5316\u8fc7\u7a0b\u4e2d\u4ee5\u6210\u5bf9\u7684\u9884\u6d4b\u6027\u6307\u6807\u548c\u516c\u5e73\u6027\u6307\u6807\u4f5c\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u76ee\u6807\uff0c\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u4e24\u5927\u9884\u6d4b\u6307\u6807(\u51c6\u786e\u7387\u3001AUC)\u53ca\u4e24\u5927\u516c\u5e73\u6027\u6307\u6807(\u4eba\u53e3\u7edf\u8ba1\u5b66\u5e73\u7b49\u5dee\u5f02\u3001\u5b50\u7fa4\u5047\u9634\u6027\u516c\u5e73\u6027)\u3002\u572811\u4e2a\u516c\u5f00\u6570\u636e\u96c6(\u542b2\u4e2a\u533b\u5b66\u6570\u636e\u96c6)\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u4ee5\u8fd9\u4e9b\u6307\u6807\u8861\u91cf\u6a21\u578b\u6027\u80fd\u4e0e\u516c\u5e73\u6027\u7684\u6743\u8861\u3002", "result": "\u6f14\u5316\u5f97\u5230\u7684\u6837\u672c\u6743\u91cd\u5728\u591a\u6570\u6570\u636e\u96c6\u4e0a\u80fd\u5b9e\u73b0\u6bd4\u5176\u4ed6\u52a0\u6743\u65b9\u6cd5\u66f4\u4f18\u7684\u516c\u5e73\u6027\u4e0e\u9884\u6d4b\u6027\u80fd\u4e4b\u95f4\u7684\u6298\u8877\uff0c\u4f46\u8fd9\u79cd\u4f18\u52bf\u5f3a\u70c8\u4f9d\u8d56\u4e8e\u6240\u9009\u7684\u4f18\u5316\u76ee\u6807\u3002\u5b9e\u9a8c\u6307\u51fa\uff0c\u4ee5\u51c6\u786e\u7387\u548c\u4eba\u53e3\u7edf\u8ba1\u5e73\u7b49\u5dee\u5f02\u4f5c\u4e3a\u4f18\u5316\u76ee\u6807\u65f6\uff0c\u80fd\u4f7f\u663e\u8457\u591a\u7684\u6570\u636e\u96c6\u5728\u4e24\u8005\u4e4b\u95f4\u53d6\u5f97\u66f4\u4f18\u7684\u6298\u8877\uff0c\u4e14\u83b7\u5f97\u7684\u6570\u636e\u96c6\u6570\u91cf\u4e3a\u6700\u9ad8\u3002", "conclusion": "\u4f18\u5316\u76ee\u6807\u7684\u9009\u62e9\u5bf9\u7ed3\u679c\u5f71\u54cd\u663e\u8457\u3002\u7528\u9057\u4f20\u7b97\u6cd5\u751f\u6210\u7684\u6743\u91cd\u786e\u5b9e\u80fd\u63d0\u5347\u516c\u5e73\u6027\u4e0e\u9884\u6d4b\u6027\u80fd\u7684\u6743\u8861\uff0c\u5c24\u5176\u5728\u5c06\u51c6\u786e\u7387\u4e0e\u4eba\u53e3\u7edf\u8ba1\u5e73\u7b49\u5dee\u5f02\u4f5c\u4e3a\u4f18\u5316\u76ee\u6807\u65f6\uff0c\u6536\u76ca\u6700\u4e3a\u660e\u663e\u3002"}}
{"id": "2511.21387", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21387", "abs": "https://arxiv.org/abs/2511.21387", "authors": ["Saurav Dulal", "Mohammed M. Olama", "Ali R. Ekti", "Nils M. Stenvig", "Yilu Liu"], "title": "Understanding Regional Inertia Dynamics in CAISO from Real Grid Disturbances", "comment": "This work has been accepted for publication in IEEE PES T&D 2026. The final published version will be available via IEEE Xplore", "summary": "The shift from synchronous generators to inverter-based resources has caused power system inertia to be unevenly distributed across power grids. As a result, certain grid regions are more vulnerable to high rate-of-change of frequency (RoCoF) during disturbances. This paper presents a measurement-based framework for estimating grid inertia in CAISO (California Independent System Operator) region using real disturbance-driven frequency data from the Frequency Monitoring Network (FNET/GridEye). By analyzing confirmed disturbances from 2013 to 2024, we identify trends in regional inertia and frequency dynamics, highlighting their relationship with renewable generation and the evolving duck curve. Regional RoCoF values were up to six times higher than interconnection-wide values, coinciding with declining inertia. Recent recovery in inertia is attributed to the increased deployment of battery energy storage systems with synthetic inertia capabilities. These findings underscore the importance of regional inertia monitoring, strategic resource planning, and adaptive operational practices to ensure grid reliability amid growing renewable integration.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.20913", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20913", "abs": "https://arxiv.org/abs/2511.20913", "authors": ["Yingchuan Sun", "Shengpu Tang"], "title": "Exploring Time-Step Size in Reinforcement Learning for Sepsis Treatment", "comment": null, "summary": "Existing studies on reinforcement learning (RL) for sepsis management have mostly followed an established problem setup, in which patient data are aggregated into 4-hour time steps. Although concerns have been raised regarding the coarseness of this time-step size, which might distort patient dynamics and lead to suboptimal treatment policies, the extent to which this is a problem in practice remains unexplored. In this work, we conducted empirical experiments for a controlled comparison of four time-step sizes ($\u0394t\\!=\\!1,2,4,8$ h) on this domain, following an identical offline RL pipeline. To enable a fair comparison across time-step sizes, we designed action re-mapping methods that allow for evaluation of policies on datasets with different time-step sizes, and conducted cross-$\u0394t$ model selections under two policy learning setups. Our goal was to quantify how time-step size influences state representation learning, behavior cloning, policy training, and off-policy evaluation. Our results show that performance trends across $\u0394t$ vary as learning setups change, while policies learned at finer time-step sizes ($\u0394t = 1$ h and $2$ h) using a static behavior policy achieve the overall best performance and stability. Our work highlights time-step size as a core design choice in offline RL for healthcare and provides evidence supporting alternatives beyond the conventional 4-hour setup.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.20927", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20927", "abs": "https://arxiv.org/abs/2511.20927", "authors": ["Vitoria Barin-Pacela", "Kartik Ahuja", "Simon Lacoste-Julien", "Pascal Vincent"], "title": "Operationalizing Quantized Disentanglement", "comment": null, "summary": "Recent theoretical work established the unsupervised identifiability of quantized factors under any diffeomorphism. The theory assumes that quantization thresholds correspond to axis-aligned discontinuities in the probability density of the latent factors. By constraining a learned map to have a density with axis-aligned discontinuities, we can recover the quantization of the factors. However, translating this high-level principle into an effective practical criterion remains challenging, especially under nonlinear maps. Here, we develop a criterion for unsupervised disentanglement by encouraging axis-aligned discontinuities. Discontinuities manifest as sharp changes in the estimated density of factors and form what we call cliffs. Following the definition of independent discontinuities from the theory, we encourage the location of the cliffs along a factor to be independent of the values of the other factors. We show that our method, Cliff, outperforms the baselines on all disentanglement benchmarks, demonstrating its effectiveness in unsupervised disentanglement.", "AI": {"tldr": "\u63d0\u51fa Cliff \u51c6\u5219\uff0c\u901a\u8fc7\u9f13\u52b1\u56e0\u5b50\u5206\u5e03\u5728\u8f74\u5bf9\u9f50\u7684\u65ad\u70b9\u5904\u51fa\u73b0\u5c16\u9510\u8df3\u53d8\u6765\u5b9e\u73b0\u65e0\u76d1\u7763\u89e3\u8026\u7684\u8bc6\u522b\u4e0e\u5b66\u4e60\uff0c\u5728\u975e\u7ebf\u6027\u6620\u5c04\u4e0b\u4e5f\u6709\u6548\uff0c\u4e14\u5728\u89e3\u8026\u57fa\u51c6\u4e0a\u8d85\u8d8a\u57fa\u7ebf\u3002", "motivation": "\u5728\u65e0\u76d1\u7763\u60c5\u5f62\u4e0b\u5b9e\u73b0\u56e0\u5b50\u89e3\u8026\u4e00\u76f4\u662f\u6311\u6218\uff0c\u7406\u8bba\u8868\u660e quantized factors \u7684\u9608\u503c\u5e94\u5bfc\u81f4\u6982\u7387\u5bc6\u5ea6\u7684\u8f74\u5bf9\u9f50\u4e0d\u8fde\u7eed\u3002\u672c\u6587\u5c06\u8fd9\u4e00\u9ad8\u5c42\u539f\u7406\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u6b63\u5219\u5316\u76ee\u6807\u3002", "method": "\u5728\u5b66\u4e60\u6620\u5c04\u7684\u6761\u4ef6\u5bc6\u5ea6\u4f30\u8ba1\u4e2d\uff0c\u9f13\u52b1\u8f74\u5bf9\u9f50\u7684\u4e0d\u8fde\u7eed\u6027\uff08\u79f0\u4e3a cliffs\uff09\uff0c\u5e76\u4f7f\u8fd9\u4e9b\u4e0d\u8fde\u7eed\u70b9\u5728\u67d0\u4e2a\u56e0\u5b50\u4e0a\u7684\u4f4d\u7f6e\u72ec\u7acb\u4e8e\u5176\u4ed6\u56e0\u5b50\u53d6\u503c\uff0c\u4ece\u800c\u5b9e\u73b0\u65e0\u76d1\u7763\u7684\u56e0\u5b50\u89e3\u8026\uff0c\u65b9\u6cd5\u547d\u540d\u4e3a Cliff\u3002", "result": "\u5728\u89e3\u8026\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cCliff \u76f8\u8f83\u591a\u57fa\u7ebf\u8868\u73b0\u66f4\u597d\uff0c\u663e\u793a\u4e86\u5728\u65e0\u76d1\u7763\u89e3\u8026\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u5bc6\u5ea6\u7684\u8f74\u5bf9\u9f50\u4e0d\u8fde\u7eed\u6027\u8fdb\u884c\u6b63\u5219\u5316\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u975e\u7ebf\u6027\u6620\u5c04\u7684\u65e0\u76d1\u7763\u89e3\u8026\u65b0\u7b56\u7565\u3002"}}
{"id": "2511.21619", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21619", "abs": "https://arxiv.org/abs/2511.21619", "authors": ["Lorenzo Nespoli", "Vasco Medici"], "title": "Robust Rule-Based Sizing and Control of Batteries for Peak Shaving Applications", "comment": null, "summary": "As the cost of batteries lowers, sizing and control methods that are both fast and can achieve their promised performances when deployed are becoming more important. In this paper, we show how stochastically tuned rule based controllers (RBCs) can be effectively used to achieve both these goals, providing more realistic estimates in terms of achievable levelised cost of energy (LCOE), and better performances while in operation when compared to deterministic model predictive control (MPC). We test the proposed methodology on yearly profiles from real meters for peak shaving applications and provide strong evidence about these claims.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5728\u7535\u6c60\u7cfb\u7edf\u4e2d\u4f7f\u7528\u968f\u673a\u8c03\u8c10\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u63a7\u5236\u5668\uff08RBC\uff09\uff0c\u76f8\u8f83\u4e8e\u786e\u5b9a\u6027MPC\uff0c\u80fd\u591f\u66f4\u5feb\u5730\u5b9e\u73b0\u5bb9\u91cf\u4e0e\u63a7\u5236\u76ee\u6807\u3001\u63d0\u4f9b\u66f4\u73b0\u5b9e\u7684LCOE\u4f30\u7b97\u5e76\u63d0\u5347\u8fd0\u884c\u6027\u80fd\uff1b\u5728\u771f\u5b9e\u5e74\u5ea6\u7528\u7535\u66f2\u7ebf\u7684\u5cf0\u503c\u524a\u51cf\u4efb\u52a1\u4e2d\u5f97\u5230\u6709\u529b\u8bc1\u636e\u3002", "motivation": "\u968f\u7740\u7535\u6c60\u6210\u672c\u4e0b\u964d\uff0c\u5bf9\u65e2\u5feb\u53c8\u80fd\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u5b9e\u73b0\u627f\u8bfa\u6027\u80fd\u7684\u5bb9\u91cf\u5206\u914d\u548c\u63a7\u5236\u65b9\u6cd5\u7684\u9700\u6c42\u65e5\u76ca\u589e\u5f3a\u3002\u76f8\u8f83\u4e8e\u786e\u5b9a\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\uff0c\u73b0\u6709\u65b9\u6cd5\u53ef\u80fd\u5728\u73b0\u5b9e\u573a\u666f\u4e0b\u672a\u80fd\u7ed9\u51fa\u771f\u5b9e\u7684LCOE\u6216\u6027\u80fd\u8bc4\u4f30\u3002\u672c\u6587\u65e8\u5728\u5c55\u793a\u968f\u673a\u8c03\u8c10\u7684RBC\u5728\u8fd9\u4e24\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u5e76\u6d4b\u8bd5\u968f\u673a\u8c03\u8c10\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u63a7\u5236\u5668\uff08RBCs\uff09\uff0c\u5e76\u4e0e\u786e\u5b9a\u6027MPC\u8fdb\u884c\u5bf9\u6bd4\uff1b\u57fa\u4e8e\u771f\u5b9e\u8868\u8ba1\u7684\u5e74\u5ea6\u6570\u636e\u7528\u4e8e\u5cf0\u503c\u524a\u51cf\u573a\u666f\u8fdb\u884c\u8bc4\u4f30\uff1b\u91cd\u70b9\u6bd4\u8f83LCOE\u7684\u73b0\u5b9e\u6027\u548c\u8fd0\u884c\u9636\u6bb5\u7684\u6027\u80fd\u8868\u73b0\u3002", "result": "\u4e0eMPC\u76f8\u6bd4\uff0cRBC\u5728\u63d0\u4f9b\u66f4\u73b0\u5b9e\u7684LCOE\u4f30\u7b97\u548c\u66f4\u4f18\u7684\u8fd0\u884c\u6027\u80fd\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff1b\u57fa\u4e8e\u771f\u5b9e\u7528\u7535\u6570\u636e\u7684\u5b9e\u9a8c\u7ed9\u51fa\u6709\u529b\u8bc1\u636e\u652f\u6301\u3002", "conclusion": "\u968f\u673a\u8c03\u8c10\u7684RBCs\u662f\u5b9e\u73b0\u5feb\u901f\u6c42\u89e3\u4e0e\u53ef\u9760\u90e8\u7f72\u6027\u80fd\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\uff0c\u5c24\u5176\u5728\u5cf0\u503c\u524a\u51cf\u7b49\u5e94\u7528\u4e2d\uff0c\u80fd\u63d0\u4f9b\u6bd4\u786e\u5b9a\u6027MPC\u66f4\u73b0\u5b9e\u7684\u6210\u672c\u4f30\u7b97\u4e0e\u66f4\u4f18\u7684\u8fd0\u8425\u8868\u73b0\u3002"}}
{"id": "2511.20993", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20993", "abs": "https://arxiv.org/abs/2511.20993", "authors": ["Shanwei Fan"], "title": "Subgoal Graph-Augmented Planning for LLM-Guided Open-World Reinforcement Learning", "comment": null, "summary": "Large language models (LLMs) offer strong high-level planning capabilities for reinforcement learning (RL) by decomposing tasks into subgoals. However, their practical utility is limited by poor planning-execution alignment, which reflects a critical gap between abstract plans and actionable, environment-compatible behaviors. This misalignment arises from two interrelated limitations: (1) LLMs often produce subgoals that are semantically plausible but infeasible or irrelevant in the target environment due to insufficient grounding in environment-specific knowledge, and (2) single-LLM planning conflates generation with self-verification, resulting in overconfident yet unreliable subgoals that frequently fail during execution. To address these challenges, we propose Subgoal Graph-Augmented Actor-Critic-Refiner (SGA-ACR), a framework that integrates an environment-specific subgoal graph and structured entity knowledge with a multi-LLM planning pipeline that explicitly separates generation, critique, and refinement to produce executable and verifiable subgoals. A subgoal tracker further monitors execution progress, provides auxiliary rewards, and adaptively updates the subgoal graph to maintain alignment between plans and actions. Experimental results on 22 diverse tasks in the open-world game \"Crafter\" demonstrate the effectiveness of our proposed method.", "AI": {"tldr": "\u63d0\u51fa Subgoal Graph-Augmented Actor-Critic-Refiner (SGA-ACR) \u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u73af\u5883\u7279\u5b9a\u7684\u5b50\u76ee\u6807\u56fe\u548c\u7ed3\u6784\u5316\u5b9e\u4f53\u77e5\u8bc6\uff0c\u4ee5\u53ca\u4e00\u4e2a\u5206\u79bb\u7684\u591a-LLM \u89c4\u5212\u6d41\u7a0b\uff08\u751f\u6210/\u6279\u8bc4/ refined\uff09\uff0c\u5b9e\u73b0\u53ef\u6267\u884c\u4e14\u53ef\u9a8c\u8bc1\u7684\u5b50\u76ee\u6807\u751f\u6210\uff0c\u63d0\u5347\u8ba1\u5212\u4e0e\u6267\u884c\u7684\u5bf9\u9f50\u3002\u901a\u8fc7\u5b50\u76ee\u6807\u8ffd\u8e2a\u5668\u5728 Crafter \u7684 22 \u4e2a\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "LLMs \u5728\u9ad8\u5c42\u6b21\u89c4\u5212\u4e2d\u80fd\u5206\u89e3\u4efb\u52a1\u4e3a\u5b50\u76ee\u6807\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u5177\u4f53\u73af\u5883\u7684 grounding\uff0c\u5bfc\u81f4\u5b50\u76ee\u6807\u5728\u76ee\u6807\u73af\u5883\u4e2d\u4e0d\u53ef\u884c\u6216\u65e0\u5173\u7d27\u8981\u3002\u6b64\u5916\uff0c\u5355\u4e00\u6a21\u578b\u7684\u89c4\u5212\u5e38\u5c06\u751f\u6210\u4e0e\u81ea\u6211\u9a8c\u8bc1\u6df7\u4e3a\u4e00\u4f53\uff0c\u4ea7\u751f\u81ea\u4fe1\u4f46\u4e0d\u53ef\u9760\u7684\u5b50\u76ee\u6807\u3002\u9700\u8981\u4e00\u4e2a\u53ef\u5c06\u751f\u6210\u3001\u8bc4\u4f30\u3001 refinement \u89e3\u8026\u5e76\u7ed3\u5408\u73af\u5883\u77e5\u8bc6\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa SGA-ACR\uff1a1) \u5f15\u5165\u73af\u5883\u7279\u5b9a\u7684\u5b50\u76ee\u6807\u56fe\u4e0e\u7ed3\u6784\u5316\u5b9e\u4f53\u77e5\u8bc6\u4f5c\u4e3a\u73af\u5883\u7ea6\u675f\uff1b2) \u4f7f\u7528\u591a-LLM \u89c4\u5212\u6d41\u6c34\u7ebf\uff0c\u5c06\u751f\u6210\u3001\u6279\u8bc4\u4e0e refinement \u5206\u79bb\uff0c\u786e\u4fdd\u5b50\u76ee\u6807\u7684\u53ef\u6267\u884c\u6027\u4e0e\u53ef\u9a8c\u8bc1\u6027\uff1b3) \u5f15\u5165\u5b50\u76ee\u6807\u8ffd\u8e2a\u5668\uff0c\u76d1\u63a7\u6267\u884c\u8fdb\u5ea6\u3001\u63d0\u4f9b\u8f85\u52a9\u5956\u52b1\uff0c\u5e76\u52a8\u6001\u66f4\u65b0\u5b50\u76ee\u6807\u56fe\u4ee5\u7ef4\u6301\u8ba1\u5212\u4e0e\u884c\u52a8\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u5f00\u653e\u4e16\u754c\u6e38\u620f Crafter \u7684 22 \u4e2a\u591a\u6837\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u6539\u5584\u89c4\u5212\u4e0e\u6267\u884c\u4e4b\u95f4\u7684\u5bf9\u9f50\uff0c\u63d0\u5347\u4efb\u52a1\u5b8c\u6210\u7684\u53ef\u9760\u6027\u4e0e\u6548\u7387\uff08\u4e0e\u57fa\u7ebf\u76f8\u6bd4\u5177\u6709\u7edf\u8ba1\u663e\u8457\u7684\u6539\u5584\uff09\u3002", "conclusion": "\u901a\u8fc7\u5c06\u73af\u5883\u7279\u5b9a\u7684\u5b50\u76ee\u6807\u56fe\u3001\u7ed3\u6784\u5316\u77e5\u8bc6\u4e0e\u5206\u79bb\u5f0f\u7684\u591a-LLM \u89c4\u5212\u6d41\u7a0b\u7ed3\u5408\uff0cSGA-ACR \u80fd\u5b9e\u73b0\u53ef\u6267\u884c\u4e14\u53ef\u9a8c\u8bc1\u7684\u5b50\u76ee\u6807\u751f\u6210\uff0c\u5e76\u901a\u8fc7\u5b50\u76ee\u6807\u8ffd\u8e2a\u5668\u5b9e\u73b0\u6301\u7eed\u5bf9\u9f50\u4e0e\u81ea\u9002\u5e94\u66f4\u65b0\uff0c\u4e3a\u5f00\u653e\u4e16\u754c\u548c\u590d\u6742\u73af\u5883\u4e2d\u7684\u89c4\u5212-\u6267\u884c\u8026\u5408\u63d0\u4f9b\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.21633", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.21633", "abs": "https://arxiv.org/abs/2511.21633", "authors": ["Liraz Mudrik", "Yaakov Oshman"], "title": "Bang-Bang Evasion: Its Stochastic Optimality and a Terminal-Set-Based Implementation", "comment": "29 pages, 4 figures", "summary": "We address the problem of optimal evasion in a planar endgame engagement, where a target with bounded lateral acceleration seeks to avoid interception by a missile guided by a linear feedback law. Contrary to existing approaches, that assume perfect information or use heuristic maneuver models in stochastic settings, we formulate the problem in an inherently stochastic framework involving imperfect information and bounded controls. Complying with the generalized separation theorem, the control law factors in the posterior distribution of the state. Extending the well-known optimality of bang-bang evasion maneuvers in deterministic settings to the realm of realistic, stochastic evasion scenarios, we firstly prove that an optimal evasion strategy always exists, and that the set of optimal solutions includes at least one bang-bang policy, rendering the resulting optimal control problem finite-dimensional. Leveraging this structure, we secondly propose the closed-loop terminal-set-based evasion (TSE) strategy, and demonstrate its effectiveness in simulation against a proportional navigation pursuer. Monte Carlo simulations show that the TSE strategy outperforms traditional stochastic evasion strategies based on random telegraph, Singer, and weaving models.", "AI": {"tldr": "\u5728\u5e26\u540e\u9a8c\u4fe1\u606f\u7684\u968f\u673a\u73af\u5883\u4e0b\uff0c\u63d0\u51fa\u4e00\u7c7b\u6700\u4f18\u89c4\u907f\u7b56\u7565\u5e76\u7ed9\u51fa\u4e00\u4e2a\u57fa\u4e8e\u95ed\u73af\u7ec8\u7aef\u96c6\u5408\u7684 TSE \u7b56\u7565\uff0c\u5176\u5b58\u5728\u6027\u4e0e bang-bang \u6700\u4f18\u6027\u5f97\u5230\u8bc1\u660e\u4e14\u5728\u4eff\u771f\u4e2d\u4f18\u4e8e\u4f20\u7edf\u968f\u673a\u6a21\u578b\u3002", "motivation": "\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\uff0c\u62e6\u622a\u7cfb\u7edf\u901a\u5e38\u57fa\u4e8e\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u548c\u6709\u754c\u63a7\u5236\u7684\u6761\u4ef6\uff0c\u4f20\u7edf\u65b9\u6cd5\u591a\u4f9d\u8d56\u5b8c\u7f8e\u4fe1\u606f\u6216\u542f\u53d1\u5f0f\u968f\u673a\u6a21\u578b\u3002\u9700\u8981\u4e00\u4e2a\u7406\u8bba\u4e0a\u5b58\u5728\u4e14\u53ef\u5b9e\u73b0\u7684\u6700\u4f18\u89c4\u907f\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u5728\u968f\u673a\u73af\u5883\u4e0b\u7684\u751f\u5b58\u6982\u7387\u548c\u9c81\u68d2\u6027\u3002", "method": "\u628a\u95ee\u9898\u5efa\u6a21\u4e3a\u5e26\u540e\u9a8c\u72b6\u6001\u5206\u5e03\u7684\u968f\u673a\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u7b26\u5408\u5e7f\u4e49\u5206\u79bb\u5b9a\u7406\uff0c\u63a7\u5236\u5f8b\u4f9d\u8d56\u72b6\u6001\u7684\u540e\u9a8c\u5206\u5e03\u3002\u8bc1\u660e\u5728\u786e\u5b9a\u6027\u60c5\u5f62\u4e0b\u7684 bang-bang \u6700\u4f18\u6027\u5ef6\u62d3\u81f3\u968f\u673a\u60c5\u5f62\uff0c\u5b58\u5728\u4e00\u4e2a\u6700\u4f18\u89e3\u65cf\u4e14\u81f3\u5c11\u5305\u542b bang-bang \u7b56\u7565\uff1b\u636e\u6b64\u63d0\u51fa\u95ed\u73af\u7ec8\u7aef\u96c6\u5408\u57fa\u7684\u89c4\u907f(TSE)\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4\u6bd4\u4f8b\u5bfc\u822a\u8ffd\u51fb\u6a21\u578b\u8fdb\u884c\u8499\u7279\u5361\u6d1b\u4eff\u771f\u3002", "result": "\u6570\u5b66\u4e0a\u8bc1\u660e\u4e86\u5b58\u5728\u6700\u4f18\u89e3\u4e14\u5305\u542b\u81f3\u5c11\u4e00\u4e2a bang-bang \u7b56\u7565\uff0c\u4f7f\u5f97\u95ee\u9898\u6210\u4e3a\u4e00\u4e2a\u6709\u9650\u7ef4\u7684\u95ee\u9898\u3002\u4eff\u771f\u8868\u660e TSE \u5728\u5bf9\u6297\u6bd4\u4f8b\u5bfc\u822a\u7684\u8ffd\u51fb\u4e2d\u4f18\u4e8e\u57fa\u4e8e\u968f\u673a telegraph\u3001Singer \u4e0e weaving \u7b49\u968f\u673a\u5316\u7b56\u7565\u3002", "conclusion": "\u5728\u5e26\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u548c\u6709\u754c\u63a7\u5236\u7684\u73b0\u5b9e\u6027\u968f\u673a\u5bf9\u6297\u4e2d\uff0cbang-bang \u6700\u4f18\u6027\u4f9d\u7136\u6210\u7acb\u4e14\u53ef\u5b9e\u73b0\uff1bTSE \u7b56\u7565\u63d0\u4f9b\u4e86\u7a33\u5b9a\u800c\u4f18\u8d8a\u7684\u95ed\u73af\u89c4\u907f\u89e3\uff0c\u5bf9\u73b0\u5b9e\u4e2d\u7684\u7aef\u76ee\u96c6\u5408\u63a7\u5236\u5177\u6709\u6f5c\u5728\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.20997", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20997", "abs": "https://arxiv.org/abs/2511.20997", "authors": ["Jiaoyang Li", "Jun Fang", "Tianhao Gao", "Xiaohui Zhang", "Zhiyuan Liu", "Chao Liu", "Pengzhang Liu", "Qixia Jiang"], "title": "FANoise: Singular Value-Adaptive Noise Modulation for Robust Multimodal Representation Learning", "comment": "13 pages, 5 figures, accept to AAAI2026", "summary": "Representation learning is fundamental to modern machine learning, powering applications such as text retrieval and multimodal understanding. However, learning robust and generalizable representations remains challenging. While prior work has demonstrated that active noise injection, a form of data augmentation, can enhance encoding performance, most existing methods rely on heuristic or static noise, overlooking the dynamic nature of feature distributions during training. In this work, we systematically study the role of noise in representation learning from both gradient-based and feature distribution perspectives, using InfoNCE loss as a representative example. Focusing on multimodal representation learning, we propose FANoise, a novel feature-adaptive noise injection strategy. By leveraging the dynamics of contrastive learning, FANoise effectively mitigates the negative impacts of noise while preserving its benefits. Under this theoretically grounded framework, comprehensive experiments demonstrate that FANoise consistently improves overall performance on multimodal tasks across various base VLM models.", "AI": {"tldr": "\u63d0\u51fa FANoise\uff1a\u4e00\u79cd\u57fa\u4e8e\u7279\u5f81\u7684\u81ea\u9002\u5e94\u566a\u58f0\u6ce8\u5165\u7b56\u7565\uff0c\u7528\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u7684\u8de8\u6a21\u6001\u8868\u5f81\u5b66\u4e60\uff0c\u7ed3\u5408 InfoNCE \u76ee\u6807\uff0c\u5728\u8bad\u7ec3\u52a8\u6001\u4e0b\u6291\u5236\u566a\u58f0\u8d1f\u6548\u5e94\u3001\u4fdd\u7559\u5176\u6b63\u6548\u5e94\uff0c\u63d0\u5347\u591a\u6a21\u6001\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u589e\u5f3a\u4e2d\u7684\u566a\u58f0\u6ce8\u5165\u591a\u6570\u4e3a\u9759\u6001\u6216\u542f\u53d1\u5f0f\uff0c\u672a\u5145\u5206\u8003\u8651\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7279\u5f81\u5206\u5e03\u548c\u68af\u5ea6\u4fe1\u53f7\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5bfc\u81f4\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u53d7\u9650\u3002\u9700\u8981\u4e00\u4e2a\u80fd\u52a8\u6001\u9002\u5e94\u8bad\u7ec3\u72b6\u6001\u7684\u566a\u58f0\u6ce8\u5165\u673a\u5236\uff0c\u4ee5\u63d0\u5347\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u7684\u8868\u5f81\u8d28\u91cf\u3002", "method": "\u63d0\u51fa FANoise\uff0c\u4e00\u79cd\u9762\u5411\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u7684\u7279\u5f81\u81ea\u9002\u5e94\u566a\u58f0\u6ce8\u5165\u7b56\u7565\u3002\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u52a8\u6001\u7279\u6027\uff0c\u7ed3\u5408 InfoNCE \u635f\u5931\u7684\u7406\u8bba\u6846\u67b6\uff0c\u8bbe\u8ba1\u80fd\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u81ea\u9002\u5e94\u8c03\u6574\u6ce8\u5165\u566a\u58f0\u7684\u5f3a\u5ea6\u548c\u5f62\u5f0f\u7684\u673a\u5236\uff0c\u4ee5\u51cf\u8f7b\u566a\u58f0\u7684\u8d1f\u9762\u5f71\u54cd\u5e76\u4fdd\u7559\u5176\u6f5c\u5728\u6b63\u5411\u4f5c\u7528\uff0c\u5e76\u5728\u591a\u6a21\u6001\u57fa\u7ebf\u6a21\u578b\u4e0a\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFANoise \u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u5bf9\u591a\u79cd\u57fa\u7840\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5747\u6709\u6301\u7eed\u4e14\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u80fd\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6a21\u578b\u8bbe\u5b9a\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002\u7406\u8bba\u5206\u6790\u4e0e\u5b9e\u9a8c\u76f8\u7ed3\u5408\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u566a\u58f0\u52a8\u6001\u5e73\u8861\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "\u52a8\u6001\u3001\u7279\u5f81\u81ea\u9002\u5e94\u7684\u566a\u58f0\u6ce8\u5165\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u8de8\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u7684\u8868\u5f81\u8d28\u91cf\uff0cFANoise \u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8bad\u7ec3\u52a8\u6001\u7684\u7406\u8bba-\u5b9e\u9a8c\u6846\u67b6\uff0c\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.21641", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21641", "abs": "https://arxiv.org/abs/2511.21641", "authors": ["Michael Ruderman"], "title": "Model-free practical PI-Lead control design by ultimate sensitivity principle", "comment": "6 pages, 10 figures", "summary": "Practical design and tuning of feedback controllers has to do often without any model of the given dynamic process. Only some general assumptions about the process, in this work type-one stable behavior, can be available for engineers, in particular in motion control systems. This paper proposes a practical and simple in realization procedure for designing a robust PI-Lead control without modeling. The developed method derives from the ultimate sensitivity principles, known in the empirical Ziegler-Nichols tuning of PID control, and makes use of some general characteristics of loop shaping. A three-steps procedure is proposed to determine the integration time constant, control gain, and Lead-element in a way to guarantee a sufficient phase margin, while all steps are served by only experimental observations of the output value. The proposed method is also evaluated with experiments on a noise-perturbed electro-mechanical actuator system with translational motion.", "AI": {"tldr": "\u5728\u65e0\u7cbe\u786e\u6a21\u578b\u7684\u524d\u63d0\u4e0b\u63d0\u51fa\u4e00\u4e2a\u9c81\u68d2\u7684PI-Lead\u63a7\u5236\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u57fa\u4e8e\u6781\u9650\u7075\u654f\u5ea6\u7684\u7406\u8bba\u548c\u73af\u8def\u6574\u5f62\u7684\u901a\u7528\u7279\u5f81\uff0c\u7ed9\u51fa\u4e00\u4e2a\u4e09\u6b65\u5f0f\u7684\u5b9e\u9a8c\u89c2\u6d4b\u9a71\u52a8\u5b9a\u6807\u6d41\u7a0b\uff0c\u7528\u4ee5\u786e\u5b9a\u79ef\u5206\u65f6\u95f4\u5e38\u6570\u3001\u63a7\u5236\u589e\u76ca\u548cLead\u5143\u4ef6\uff0c\u786e\u4fdd\u8db3\u591f\u7684\u76f8\u4f4d\u88d5\u91cf\uff0c\u5e76\u5728\u5e26\u566a\u58f0\u7684\u6267\u884c\u5668\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u5de5\u7a0b\u9886\u57df\u5e38\u9047\u5230\u65e0\u6cd5\u83b7\u5f97\u51c6\u786e\u7cfb\u7edf\u6a21\u578b\u7684\u60c5\u51b5\uff0c\u9700\u63d0\u4f9b\u7b80\u5355\u3001\u9c81\u68d2\u4e14\u6613\u5b9e\u73b0\u7684\u63a7\u5236\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u8fd0\u52a8\u63a7\u5236\u573a\u666f\u4e2d\u3002\u7814\u7a76\u65e8\u5728\u5728\u65e0\u6a21\u578b\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9c81\u68d2\u7684PI-Lead\u63a7\u5236\u5e76\u4fdd\u8bc1\u76f8\u4f4d\u88d5\u91cf\u3002", "method": "\u57fa\u4e8e\u6781\u9650\u7075\u654f\u5ea6\u539f\u5219\uff0c\u7ed3\u5408\u7ecf\u9a8cZiegler\u2013Nichols\u5bf9PID\u6574\u5b9a\u7684\u601d\u8def\u53ca\u73af\u8def\u6574\u5f62\u7684\u4e00\u822c\u7279\u5f81\uff0c\u63d0\u51fa\u4e00\u4e2a\u4e09\u6b65\u6cd5\u6765\u786e\u5b9a\u79ef\u5206\u65f6\u95f4\u5e38\u6570\u3001\u63a7\u5236\u589e\u76ca\u4e0eLead\u5143\u4ef6\u3002\u6bcf\u4e00\u6b65\u4ec5\u4f9d\u8d56\u901a\u8fc7\u8f93\u51fa\u89c2\u6d4b\u83b7\u5f97\u7684\u5b9e\u9a8c\u6570\u636e\uff0c\u4ee5\u786e\u4fdd\u8fbe\u5230\u6240\u9700\u7684\u76f8\u4f4d\u88d5\u91cf\u3002", "result": "\u5c06\u6240\u63d0\u65b9\u6cd5\u5728\u4e00\u4e2a\u566a\u58f0\u5e72\u6270\u7684\u7535\u673a\u68b0\u6267\u884c\u5668\u7cfb\u7edf\uff08\u5e73\u79fb\u8fd0\u52a8\uff09\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\u4e0e\u9c81\u68d2\u6027\u3002", "conclusion": "\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u6d01\u4e14\u53ef\u843d\u5730\u7684\u65e0\u6a21\u578bPI-Lead\u8bbe\u8ba1\u6d41\u7a0b\uff0c\u5728\u7f3a\u4e4f\u7cbe\u786e\u7cfb\u7edf\u5efa\u6a21\u7684\u60c5\u5f62\u4e0b\u4ecd\u80fd\u83b7\u5f97\u7a33\u5b9a\u6027\u88d5\u91cf\u4e0e\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.21008", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.21008", "abs": "https://arxiv.org/abs/2511.21008", "authors": ["Constantinos Daskalakis", "Vardis Kandiros", "Rui Yao"], "title": "Estimating Ising Models in Total Variation Distance", "comment": null, "summary": "We consider the problem of estimating Ising models over $n$ variables in Total Variation (TV) distance, given $l$ independent samples from the model. While the statistical complexity of the problem is well-understood [DMR20], identifying computationally and statistically efficient algorithms has been challenging. In particular, remarkable progress has occurred in several settings, such as when the underlying graph is a tree [DP21, BGPV21], when the entries of the interaction matrix follow a Gaussian distribution [GM24, CK24], or when the bulk of its eigenvalues lie in a small interval [AJK+24, KLV24], but no unified framework for polynomial-time estimation in TV exists so far. Our main contribution is a unified analysis of the Maximum Pseudo-Likelihood Estimator (MPLE) for two general classes of Ising models. The first class includes models that have bounded operator norm and satisfy the Modified Log-Sobolev Inequality (MLSI), a functional inequality that was introduced to study the convergence of the associated Glauber dynamics to stationarity. In the second class of models, the interaction matrix has bounded infinity norm (or bounded width), which is the most common assumption in the literature for structure learning of Ising models. We show how our general results for these classes yield polynomial-time algorithms and optimal or near-optimal sample complexity guarantees in a variety of settings. Our proofs employ a variety of tools from tensorization inequalities to measure decompositions and concentration bounds.", "AI": {"tldr": "\u63d0\u51fa\u5bf9\u4e24\u5927\u7c7bIsing\u6a21\u578b\u7684MPLE\u5206\u6790\uff0c\u7ed9\u51fa\u5728\u603b\u53d8\u5dee\u8ddd\u79bb\u4e0b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7ed3\u5408\u4e24\u7c7b\u6a21\u578b\u6761\u4ef6\uff08\u6709\u754c\u7b97\u5b50\u8303\u6570\u5e76\u6ee1\u8db3MLSI\uff1b\u4ee5\u53ca\u6709\u754c\u65e0\u7a77\u8303\u6570/\u5bbd\u5ea6\uff09\uff0c\u5b9e\u73b0\u591a\u9879\u5f0f\u65f6\u95f4\u4f30\u8ba1\u4ee5\u53ca\u6700\u4f18\u6216\u8fd1\u4f3c\u6700\u4f18\u7684\u6837\u672c\u590d\u6742\u6027\u3002\u9002\u7528\u4e8e\u5e7f\u6cdb\u8bbe\u7f6e\uff0c\u8f85\u4ee5\u5f20\u91cf\u5316\u4e0d\u7b49\u5f0f\u3001\u5ea6\u91cf\u5206\u89e3\u4e0e\u5206\u5e03\u5f0f\u4e00\u81f4\u6027\u5de5\u5177\u3002", "motivation": "\u5728TV\u8ddd\u79bb\u4e0b\u4f30\u8ba1Ising\u6a21\u578b\u7684\u7edf\u8ba1\u590d\u6742\u5ea6\u6e05\u695a\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u3001\u5728\u591a\u79cd\u6a21\u578b\u5047\u8bbe\u4e0b\u7684\u9ad8\u6548\u7b97\u6cd5\u6846\u67b6\u3002\u672c\u6587\u529b\u6c42\u901a\u8fc7\u5bf9MPLE\u7684\u7edf\u4e00\u5206\u6790\uff0c\u6784\u5efa\u4e24\u7c7b\u901a\u7528\u6761\u4ef6\u4e0b\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u4f30\u8ba1\u5668\uff0c\u8fbe\u5230\u63a5\u8fd1\u6700\u4f18\u7684\u6837\u672c\u6548\u7387\u3002", "method": "\u5bf9\u6700\u5927\u4f2a\u4f3c\u7136\u4f30\u8ba1\uff08MPLE\uff09\u8fdb\u884c\u7edf\u4e00\u5206\u6790\uff0c\u8986\u76d6\u4e24\u5927\u7c7b\u6a21\u578b\uff1a1) \u6ee1\u8db3MLSI\u4e14\u5177\u6709\u6709\u754c\u7b97\u5b50\u8303\u6570\u7684Ising\u6a21\u578b\uff1b2) \u4e92\u4f5c\u7528\u77e9\u9635\u5177\u6709\u6709\u754c\u65e0\u7a77\u8303\u6570\uff08\u5bbd\u5ea6\u6709\u754c\uff09\u7684\u6a21\u578b\u3002\u901a\u8fc7\u5f20\u91cf\u5316\u3001\u4e0d\u7b49\u5f0f\u5206\u89e3\u3001\u4ee5\u53ca\u5206\u5e03\u96c6\u4e2d\u6027\u7b49\u5de5\u5177\uff0c\u63a8\u5bfc\u51fa\u5728TV\u8ddd\u79bb\u4e0b\u7684\u8bef\u5dee\u754c\u4e0e\u6837\u672c\u590d\u6742\u6027\uff0c\u5e76\u7ed9\u51fa\u591a\u9879\u5f0f\u65f6\u95f4\u5b9e\u73b0\u7684\u4f30\u8ba1\u7b97\u6cd5\u3002", "result": "\u5728\u4e24\u7c7b\u6a21\u578b\u4e0b\u5747\u7ed9\u51fa\u591a\u9879\u5f0f\u65f6\u95f4\u7684\u4f30\u8ba1\u7b97\u6cd5\uff0c\u5e76\u7ed9\u51fa\u6700\u4f18\u6216\u63a5\u8fd1\u6700\u4f18\u7684\u6837\u672c\u590d\u6742\u6027\u754c\uff1b\u7ed3\u8bba\u6db5\u76d6\u5bf9\u5e7f\u4e49Ising\u6a21\u578b\u4f30\u8ba1\u7684\u7edf\u4e00\u6846\u67b6\u53ca\u5176\u5728\u4e0d\u540c\u7ed3\u6784\u5047\u8bbe\u4e0b\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684MPLE\u5206\u6790\u6846\u67b6\uff0c\u8fde\u63a5\u7edf\u8ba1\u590d\u6742\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u5728\u4e24\u7c7b\u5e38\u89c1\u7ed3\u6784\u5047\u8bbe\u4e0b\u5b9e\u73b0\u9ad8\u6548\u4f30\u8ba1\uff0c\u4e3aIsing\u6a21\u578b\u5728TV\u8ddd\u79bb\u7684\u4f30\u8ba1\u63d0\u4f9b\u4e86\u5e7f\u6cdb\u7684\u7406\u8bba\u652f\u6491\u4e0e\u65b9\u6cd5\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.21009", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21009", "abs": "https://arxiv.org/abs/2511.21009", "authors": ["Md Tasnin Tanvir", "Dr Santanu Kumar Dash", "Ishan Shahnan", "Nafis Fuad", "Tanvir Rahman", "Abdullah Al Faisal", "Asadullah Al Mamun"], "title": "ChatGpt Content detection: A new approach using xlm-roberta alignment", "comment": null, "summary": "The challenge of separating AI-generated text from human-authored content is becoming more urgent as generative AI technologies like ChatGPT become more widely available. In this work, we address this issue by looking at both the detection of content that has been entirely generated by AI and the identification of human text that has been reworded by AI. In our work, a comprehensive methodology to detect AI- generated text using XLM-RoBERTa, a state-of-the-art multilingual transformer model. Our approach includes rigorous preprocessing, and feature extraction involving perplexity, semantic, and readability features. We fine-tuned the XLM-RoBERTa model on a balanced dataset of human and AI-generated texts and evaluated its performance. The model demonstrated high accuracy and robust performance across various text genres. Additionally, we conducted feature analysis to understand the model's decision-making process, revealing that perplexity and attention-based features are critical in differentiating between human and AI-generated texts. Our findings offer a valuable tool for maintaining academic integrity and contribute to the broader field of AI ethics by promoting transparency and accountability in AI systems. Future research directions include exploring other advanced models and expanding the dataset to enhance the model's generalizability.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u591a\u8bed\u8a00Transformer\uff08XLM-RoBERTa\uff09\u7684AI\u6587\u672c\u68c0\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u541e\u5410\u524d\u5904\u7406\u3001\u56f0\u60d1\u5ea6\u3001\u8bed\u4e49\u548c\u53ef\u8bfb\u6027\u7279\u5f81\uff0c\u901a\u8fc7\u5e73\u8861\u6570\u636e\u96c6\u5fae\u8c03\u6a21\u578b\uff0c\u5728\u591a\u79cd\u6587\u672c\u9886\u57df\u5b9e\u73b0\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u5206\u6790\u7279\u5f81\u5bf9\u51b3\u7b56\u7684\u8d21\u732e\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\uff08\u5982ChatGPT\uff09\u65e5\u76ca\u666e\u53ca\uff0c\u533a\u5206AI\u751f\u6210\u6587\u672c\u4e0e\u4eba\u7c7b\u6587\u672c\u7684\u9700\u6c42\u65e5\u76ca\u7d27\u8feb\uff0c\u6d89\u53ca\u5b66\u672f\u8bda\u4fe1\u3001\u900f\u660e\u5ea6\u4e0eAI\u4f26\u7406\u3002", "method": "1) \u91c7\u7528\u4e25\u683c\u7684\u9884\u5904\u7406\u548c\u591a\u7279\u5f81\u63d0\u53d6\uff08\u56f0\u60d1\u5ea6\u3001\u8bed\u4e49\u3001\u53ef\u8bfb\u6027\u7b49\uff09 2) \u5728\u4eba\u5de5\u4e0eAI\u6587\u672c\u5e73\u8861\u7684\u6570\u636e\u96c6\u4e0a\u5bf9XLM-RoBERTa\u8fdb\u884c\u5fae\u8c03 3) \u8bc4\u4f30\u6a21\u578b\u5728\u4e0d\u540c\u6587\u672c\u4f53\u88c1\u4e0a\u7684\u9c81\u68d2\u6027 4) \u8fdb\u884c\u7279\u5f81\u5206\u6790\uff0c\u63ed\u793a\u56f0\u60d1\u5ea6\u4e0e\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u7279\u5f81\u5728\u533a\u5206\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "result": "\u6a21\u578b\u663e\u793a\u9ad8\u51c6\u786e\u6027\u548c\u5bf9\u591a\u9886\u57df\u6587\u672c\u7684\u9c81\u68d2\u6027\uff1b\u56f0\u60d1\u5ea6\u4e0e\u6ce8\u610f\u529b\u7b49\u7279\u5f81\u88ab\u786e\u8ba4\u4e3a\u533a\u5206AI\u6587\u672c\u4e0e\u4eba\u7c7b\u6587\u672c\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u4e3a\u7ef4\u62a4\u5b66\u672f\u8bda\u4fe1\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u68c0\u6d4b\u5de5\u5177\uff0c\u5e76\u4e3aAI\u4f26\u7406\u9886\u57df\u7684\u900f\u660e\u5ea6\u4e0e\u95ee\u8d23\u5236\u8d21\u732e\u529b\u91cf\u3002\u672a\u6765\u5de5\u4f5c\u5305\u62ec\u63a2\u7d22\u5176\u4ed6\u5148\u8fdb\u6a21\u578b\u53ca\u6269\u5927\u6570\u636e\u96c6\u4ee5\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.21531", "categories": ["cs.LG", "cs.AI", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21531", "abs": "https://arxiv.org/abs/2511.21531", "authors": ["Jin Pin", "Krasowski Hanna", "Vanneaux Elena"], "title": "Predictive Safety Shield for Dyna-Q Reinforcement Learning", "comment": null, "summary": "Obtaining safety guarantees for reinforcement learning is a major challenge to achieve applicability for real-world tasks. Safety shields extend standard reinforcement learning and achieve hard safety guarantees. However, existing safety shields commonly use random sampling of safe actions or a fixed fallback controller, therefore disregarding future performance implications of different safe actions. In this work, we propose a predictive safety shield for model-based reinforcement learning agents in discrete space. Our safety shield updates the Q-function locally based on safe predictions, which originate from a safe simulation of the environment model. This shielding approach improves performance while maintaining hard safety guarantees. Our experiments on gridworld environments demonstrate that even short prediction horizons can be sufficient to identify the optimal path. We observe that our approach is robust to distribution shifts, e.g., between simulation and reality, without requiring additional training.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u79bb\u6563\u7a7a\u95f4\u7684\u6a21\u578b\u57fa\u9884\u6d4b\u5b89\u5168\u76fe\u724c\uff0c\u57fa\u4e8e\u5b89\u5168\u9884\u6d4b\u5728\u5c40\u90e8\u66f4\u65b0Q\u51fd\u6570\uff0c\u517c\u987e\u786c\u6027\u5b89\u5168\u4e0e\u6027\u80fd\uff1b\u7f51\u683c\u4e16\u754c\u5b9e\u9a8c\u663e\u793a\u77ed\u65f6\u9884\u6d4b\u5373\u53ef\u8bc6\u522b\u6700\u4f18\u8def\u5f84\uff0c\u5bf9\u4eff\u771f-\u73b0\u5b9e\u5206\u5e03\u6f02\u79fb\u9c81\u68d2\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u7684\u5b89\u5168\u6027\u96be\u4ee5\u4fdd\u969c\uff0c\u73b0\u6709\u5b89\u5168\u76fe\u724c\u591a\u4f7f\u7528\u968f\u673a\u62bd\u6837\u6216\u56fa\u5b9a\u540e\u5907\u63a7\u5236\uff0c\u5ffd\u7565\u4e0d\u540c\u5b89\u5168\u884c\u52a8\u7684\u672a\u6765\u6027\u80fd\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u5728\u4fdd\u8bc1\u5b89\u5168\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u957f\u671f\u56de\u62a5\u3002", "method": "\u63d0\u51fa\u9884\u6d4b\u5b89\u5168\u76fe\u724c\uff0c\u901a\u8fc7\u5bf9\u73af\u5883\u6a21\u578b\u8fdb\u884c\u5b89\u5168\u4eff\u771f\uff0c\u5f97\u5230\u5b89\u5168\u9884\u6d4b\uff1b\u5728\u8be5\u9884\u6d4b\u57fa\u7840\u4e0a\u5bf9Q\u51fd\u6570\u8fdb\u884c\u5c40\u90e8\u66f4\u65b0\uff0c\u4ee5\u7ea6\u675f\u7b56\u7565\u9009\u62e9\uff0c\u4ee5\u5b9e\u73b0\u786c\u5b89\u5168\u4e0e\u6539\u8fdb\u7684\u6027\u80fd\u3002", "result": "\u5728\u7f51\u683c\u4e16\u754c\u7684\u5b9e\u9a8c\u4e2d\uff0c\u77ed\u9884\u6d4b horizon \u5373\u80fd\u8bc6\u522b\u6700\u4f18\u8def\u5f84\uff1b\u65b9\u6cd5\u5bf9\u5206\u5e03\u6f02\u79fb\u9c81\u68d2\uff08\u5982\u4eff\u771f\u5230\u73b0\u5b9e\uff09\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "conclusion": "\u8be5\u76fe\u724c\u5728\u4fdd\u7559\u786c\u5b89\u5168\u4fdd\u8bc1\u7684\u540c\u65f6\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4e14\u5bf9\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u548c\u57df\u504f\u79fb\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5177\u5907\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.21011", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21011", "abs": "https://arxiv.org/abs/2511.21011", "authors": ["Sid Bharthulwar", "Stone Tao", "Hao Su"], "title": "Staggered Environment Resets Improve Massively Parallel On-Policy Reinforcement Learning", "comment": null, "summary": "Massively parallel GPU simulation environments have accelerated reinforcement learning (RL) research by enabling fast data collection for on-policy RL algorithms like Proximal Policy Optimization (PPO). To maximize throughput, it is common to use short rollouts per policy update, increasing the update-to-data (UTD) ra- tio. However, we find that, in this setting, standard synchronous resets introduce harmful nonstationarity, skewing the learning signal and destabilizing training. We introduce staggered resets, a simple yet effective technique where environments are initialized and reset at varied points within the task horizon. This yields training batches with greater temporal diversity, reducing the nonstationarity induced by synchronized rollouts. We characterize dimensions along which RL environments can benefit significantly from staggered resets through illustrative toy environ- ments. We then apply this technique to challenging high-dimensional robotics environments, achieving significantly higher sample efficiency, faster wall-clock convergence, and stronger final performance. Finally, this technique scales better with more parallel environments compared to naive synchronized rollouts.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165 staggered resets \u6765\u964d\u4f4e\u5927\u89c4\u6a21\u5e76\u884c\u73af\u5883\u4e2d\u7684\u975e\u5e73\u7a33\u6027\uff0c\u63d0\u9ad8 PPO \u7b49 on-policy RL \u5728\u77ed rollout \u8bbe\u7f6e\u4e0b\u7684\u6837\u672c\u6548\u7387\u548c\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u5728 GPU \u52a0\u901f\u7684\u5e76\u884c\u73af\u5883\u4e2d\uff0c\u4e3a\u63d0\u9ad8\u541e\u5410\u91cf\uff0c\u901a\u5e38\u91c7\u7528\u77ed rollout \u548c\u9ad8\u66f4\u65b0/\u6570\u636e\u6bd4\u7387\uff0c\u4f46\u540c\u6b65\u91cd\u7f6e\u9020\u6210\u975e\u5e73\u7a33\u6027\uff0c\u5f71\u54cd\u5b66\u4e60\u4fe1\u53f7\uff0c\u964d\u4f4e\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa staggered resets\uff1a\u5728\u4efb\u52a1 horizon \u5185\u7684\u4e0d\u540c\u70b9\u521d\u59cb\u5316\u548c\u91cd\u7f6e\u73af\u5883\uff0c\u4ee5\u589e\u52a0\u8bad\u7ec3\u6279\u6b21\u7684\u65f6\u95f4\u591a\u6837\u6027\uff0c\u964d\u4f4e\u540c\u6b65 rollout \u5e26\u6765\u7684\u975e\u5e73\u7a33\u6027\u3002\u7528 toy \u73af\u5883\u523b\u753b\u5728\u5404\u79cd\u7ef4\u5ea6\u7684\u6536\u76ca\uff0c\u5e76\u5728\u9ad8\u7ef4\u673a\u5668\u4eba\u73af\u5883\u4e2d\u9a8c\u8bc1\uff0c\u6bd4\u8f83\u540c\u6b65\u91cd\u7f6e\u3002", "result": "\u5728 toy \u73af\u5883\u4e2d\u5c55\u793a\u4e86\u7ef4\u5ea6\u4e0a\u7684\u6536\u76ca\uff0c\u5728\u9ad8\u7ef4\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u5b9e\u73b0\u663e\u8457\u7684\u6837\u672c\u6548\u7387\u63d0\u5347\u3001\u5899\u949f\u65f6\u95f4\u6536\u655b\u66f4\u5feb\u3001\u6700\u7ec8\u6027\u80fd\u66f4\u5f3a\uff0c\u5e76\u4e14\u968f\u7740\u5e76\u884c\u73af\u5883\u589e\u591a\uff0cstaggered resets \u7684\u6548\u679c\u4f18\u4e8e\u7b80\u5355\u540c\u6b65 rollout\u3002", "conclusion": "staggered resets \u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u5e76\u884c RL \u7684\u975e\u5e73\u7a33\u6027\uff0c\u63d0\u5347\u541e\u5410\u4e0e\u5b66\u4e60\u7a33\u5b9a\u6027\uff0c\u4e14\u968f\u7740\u5e76\u884c\u89c4\u6a21\u589e\u5927\uff0c\u5176\u4f18\u52bf\u66f4\u660e\u663e\uff0c\u9002\u5408\u63d0\u5347 on-policy RL \u7684\u6570\u636e\u6548\u7387\u4e0e\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002"}}
{"id": "2511.21032", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21032", "abs": "https://arxiv.org/abs/2511.21032", "authors": ["Yuxuan Zhu", "Cong Fu", "Yabo Ni", "Anxiang Zeng", "Yuan Fang"], "title": "A Probabilistic Framework for Temporal Distribution Generalization in Industry-Scale Recommender Systems", "comment": null, "summary": "Temporal distribution shift (TDS) erodes the long-term accuracy of recommender systems, yet industrial practice still relies on periodic incremental training, which struggles to capture both stable and transient patterns. Existing approaches such as invariant learning and self-supervised learning offer partial solutions but often suffer from unstable temporal generalization, representation collapse, or inefficient data utilization. To address these limitations, we propose ELBO$_\\text{TDS}$, a probabilistic framework that integrates seamlessly into industry-scale incremental learning pipelines. First, we identify key shifting factors through statistical analysis of real-world production data and design a simple yet effective data augmentation strategy that resamples these time-varying factors to extend the training support. Second, to harness the benefits of this extended distribution while preventing representation collapse, we model the temporal recommendation scenario using a causal graph and derive a self-supervised variational objective, ELBO$_\\text{TDS}$, grounded in the causal structure. Extensive experiments supported by both theoretical and empirical analysis demonstrate that our method achieves superior temporal generalization, yielding a 2.33\\% uplift in GMV per user and has been successfully deployed in Shopee Product Search. Code is available at https://github.com/FuCongResearchSquad/ELBO4TDS.", "AI": {"tldr": "\u63d0\u51fa ELBO_TDS\uff0c\u4e00\u4e2a\u7ed3\u5408\u56e0\u679c\u56fe\u548c\u81ea\u76d1\u7763\u53d8\u5206\u63a8\u65ad\u7684\u65f6\u5e8f\u5206\u5e03\u504f\u79fb\u9c81\u68d2\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u6269\u5c55\u8bad\u7ec3\u5206\u5e03\uff0c\u63d0\u5347\u957f\u671f\u6cdb\u5316\uff0c\u5df2\u5728 Shopee \u90e8\u7f72\uff0cGMV \u63d0\u5347\u7ea62.33%\u3002", "motivation": "Temporal distribution shift\uff08TDS\uff09\u4f1a\u4fb5\u8680\u63a8\u8350\u7cfb\u7edf\u7684\u957f\u671f\u51c6\u786e\u6027\uff0c\u73b0\u6709\u7684\u5468\u671f\u6027\u589e\u91cf\u8bad\u7ec3\u96be\u4ee5\u540c\u65f6\u6355\u6349\u7a33\u5b9a\u6a21\u5f0f\u548c\u77ac\u65f6\u6a21\u5f0f\uff1b\u73b0\u6709\u7684\u5bf9\u6bd4\u65b9\u6cd5\u5982\u4e0d\u53d8\u91cf\u5b66\u4e60\u548c\u81ea\u76d1\u7763\u5b66\u4e60\u5728\u6cdb\u5316\u3001\u8868\u793a\u584c\u7f29\u6216\u6570\u636e\u5229\u7528\u6548\u7387\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u5728\u5de5\u4e1a\u573a\u666f\u53ef\u843d\u5730\u4e14\u80fd\u5145\u5206\u5229\u7528\u6269\u5c55\u5206\u5e03\u7684\u65b9\u6848\u3002", "method": "\u8bc6\u522b\u73b0\u5b9e\u751f\u4ea7\u6570\u636e\u4e2d\u7684\u5173\u952e\u65f6\u79fb\u56e0\u7d20\u5e76\u8bbe\u8ba1\u7b80\u6d01\u6709\u6548\u7684\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u5bf9\u8fd9\u4e9b\u65f6\u53d8\u56e0\u7d20\u8fdb\u884c\u91cd\u91c7\u6837\u4ee5\u6269\u5c55\u8bad\u7ec3\u6837\u672c\u5206\u5e03\uff1b\u5728\u56e0\u679c\u56fe\u6846\u67b6\u4e0b\u5efa\u6a21\u65f6\u5e8f\u63a8\u8350\u573a\u666f\uff0c\u63a8\u5bfc\u81ea\u76d1\u7763\u7684\u53d8\u5206\u76ee\u6807 ELBO_TDS\uff0c\u4f7f\u5bf9\u6269\u5c55\u5206\u5e03\u7684\u5229\u7528\u4e0e\u56e0\u679c\u7ed3\u6784\u4fdd\u6301\u4e00\u81f4\uff0c\u4ee5\u907f\u514d\u8868\u793a\u584c\u7f29\u3002", "result": "\u7406\u8bba\u548c\u7ecf\u9a8c\u5206\u6790\u5747\u8868\u660e\u65b9\u6cd5\u5177\u5907\u66f4\u5f3a\u7684\u65f6\u5e8f\u6cdb\u5316\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u5bf9\u7528\u6237GMV\u7684\u63d0\u5347\u4e3a2.33%\uff0c\u5e76\u5df2\u5728 Shopee Product Search \u4e2d\u6210\u529f\u90e8\u7f72\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u5f00\u6e90\u4ee3\u7801\u3002", "conclusion": "ELBO_TDS \u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u5de5\u4e1a\u89c4\u6a21\u7684\u589e\u91cf\u5b66\u4e60\u6d41\u6c34\u7ebf\u4e2d\uff0c\u63d0\u5347\u5bf9\u65f6\u5e8f\u53d8\u5316\u7684\u9c81\u68d2\u6027\u548c\u957f\u671f\u6027\u80fd\uff0c\u5177\u6709\u8f83\u597d\u7684\u5b9e\u9645\u843d\u5730\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2511.21034", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21034", "abs": "https://arxiv.org/abs/2511.21034", "authors": ["Mahdi Saki", "Justin Lipman"], "title": "Prediction of Herd Life in Dairy Cows Using Multi-Head Attention Transformers", "comment": null, "summary": "Dairy farmers should decide to keep or cull a cow based on an objective assessment of her likely performance in the herd. For this purpose, farmers need to identify more resilient cows, which can cope better with farm conditions and complete more lactations. This decision-making process is inherently complex, with significant environmental and economic implications. In this study, we develop an AI-driven model to predict cow longevity using historical multivariate time-series data recorded from birth. Leveraging advanced AI techniques, specifically Multi-Head Attention Transformers, we analysed approximately 780,000 records from 19,000 unique cows across 7 farms in Australia. The results demonstrate that our model achieves an overall determination coefficient of 83% in predicting herd life across the studied farms, highlighting its potential for practical application in dairy herd management.", "AI": {"tldr": "\u5229\u7528\u591a\u5934\u6ce8\u610f\u529b\u53d8\u6362\u5668\u7684AI\u6a21\u578b\uff0c\u5728\u51fa\u751f\u65f6\u7684\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0a\u9884\u6d4b\u5976\u725b\u7684\u957f\u671f\u5b58\u6d3b\uff0c\u8de87\u4e2a\u519c\u573a\u300119,000\u5934\u725b\u4e0e\u7ea6780,000\u6761\u8bb0\u5f55\uff0cR^2\u7ea683%\uff0c\u5177\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5976\u519c\u9700\u8981\u5bf9\u5976\u725b\u7684\u957f\u671f\u6027\u80fd\u8fdb\u884c\u5ba2\u89c2\u8bc4\u4f30\uff0c\u4ee5\u8bc6\u522b\u66f4\u5177\u97e7\u6027\u7684\u5976\u725b\uff0c\u4ece\u800c\u63d0\u5347\u4ea7\u5976\u671f\u548c\u7ecf\u6d4e\u6548\u76ca\uff1b\u51b3\u7b56\u6d89\u53ca\u73af\u5883\u548c\u7ecf\u6d4e\u5f71\u54cd\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u5728\u5b9e\u9645\u517b\u6b96\u573a\u4e2d\u843d\u5730\u7684\u9884\u6d4b\u5de5\u5177\u3002", "method": "\u91c7\u7528\u591a\u5934\u6ce8\u610f\u529bTransformer\u5bf9\u51fa\u751f\u5f00\u59cb\u5c31\u7684\u5386\u53f2\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u8fdb\u884c\u5efa\u6a21\uff0c\u5206\u6790\u7ea6780,000\u6761\u8bb0\u5f55\uff0c\u8986\u76d619,000\u5934\u725b\u57287\u4e2a\u6fb3\u5927\u5229\u4e9a\u519c\u573a\u7684\u6570\u636e\uff0c\u5e76\u8bc4\u4f30\u8de8\u519c\u573a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u6a21\u578b\u5728\u9884\u6d4b\u7fa4\u4f53\u5bff\u547d\uff08herd life\uff09\u65b9\u9762\u7684\u51b3\u5b9a\u7cfb\u6570\u8fbe\u523083%\uff0c\u5728\u6240\u7814\u7a76\u7684\u519c\u573a\u4e2d\u8868\u73b0\u51fa\u8f83\u5f3a\u7684\u9884\u6d4b\u80fd\u529b\u3002", "conclusion": "\u663e\u793a\u8be5AI\u9a71\u52a8\u65b9\u6cd5\u5728\u5976\u725b\u7fa4\u7ba1\u7406\u4e2d\u7684\u6f5c\u5728\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u6709\u52a9\u4e8e\u8bc6\u522b\u5177\u5907\u66f4\u9ad8\u957f\u671f\u4ea7\u5976\u6f5c\u529b\u7684\u4e2a\u4f53\uff0c\u5e76\u4e3a\u6dd8\u6c70\u51b3\u7b56\u63d0\u4f9b\u66f4\u79d1\u5b66\u7684\u4f9d\u636e\uff1b\u8de8\u591a\u519c\u573a\u7684\u826f\u597d\u8868\u73b0\u652f\u6301\u5176\u5728\u771f\u5b9e\u517b\u6b96\u73af\u5883\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2511.21048", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21048", "abs": "https://arxiv.org/abs/2511.21048", "authors": ["Jingtao Guo", "Yuyi Mao", "Ivan Wang-Hei Ho"], "title": "FedAPA: Federated Learning with Adaptive Prototype Aggregation Toward Heterogeneous Wi-Fi CSI-based Crowd Counting", "comment": "17 pages, 11 figures, this article was submitted to IEEE for possible publication", "summary": "Wi-Fi channel state information (CSI)-based sensing provides a non-invasive, device-free approach for tasks such as human activity recognition and crowd counting, but large-scale deployment is hindered by the need for extensive site-specific training data. Federated learning (FL) offers a way to avoid raw data sharing but is challenged by heterogeneous sensing data and device resources. This paper proposes FedAPA, a collaborative Wi-Fi CSI-based sensing algorithm that uses adaptive prototype aggregation (APA) strategy to assign similarity-based weights to peer prototypes, enabling adaptive client contributions and yielding a personalized global prototype for each client instead of a fixed-weight aggregation. During local training, we adopt a hybrid objective that combines classification learning with representation contrastive learning to align local and global knowledge. We provide a convergence analysis of FedAPA and evaluate it in a real-world distributed Wi-Fi crowd counting scenario with six environments and up to 20 people. The results show that our method outperform multiple baselines in terms of accuracy, F1 score, mean absolute error (MAE), and communication overhead, with FedAPA achieving at least a 9.65% increase in accuracy, a 9% gain in F1 score, a 0.29 reduction in MAE, and a 95.94% reduction in communication overhead.", "AI": {"tldr": "FedAPA \u63d0\u51fa\u4e00\u79cd\u81ea\u9002\u5e94\u539f\u578b\u805a\u5408\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8eWi-Fi CSI \u57fa\u4e8e sensing\u3002\u901a\u8fc7\u5bf9\u540c\u4f34\u539f\u578b\u7684\u76f8\u4f3c\u6027\u8fdb\u884c\u52a0\u6743\uff0c\u5b9e\u73b0\u5728\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684\u4e2a\u6027\u5316\u5168\u5c40\u539f\u578b\uff0c\u5e76\u5728\u672c\u5730\u8bad\u7ec3\u9636\u6bb5\u5f15\u5165\u5206\u7c7b\u4e0e\u8868\u793a\u5bf9\u6bd4\u5b66\u4e60\u7684\u6df7\u5408\u76ee\u6807\uff0c\u7406\u8bba\u4e0a\u7ed9\u51fa\u6536\u655b\u6027\u5206\u6790\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u5927\u89c4\u6a21\u90e8\u7f72\u4e2d\u9700\u8981\u5927\u91cf\u7ad9\u70b9\u7279\u5b9a\u7684\u8bad\u7ec3\u6570\u636e\uff1b\u8054\u90a6\u5b66\u4e60\u80fd\u907f\u514d raw data \u5171\u4eab\uff0c\u4f46\u5f02\u8d28\u6027\u6570\u636e\u548c\u8bbe\u5907\u8d44\u6e90\u53d7\u9650\u4f7f\u5f97 global \u6a21\u578b\u96be\u4ee5\u6cdb\u5316\u3002\u9700\u5bf9\u5ba2\u6237\u7aef\u8d21\u732e\u8fdb\u884c\u81ea\u9002\u5e94\u52a0\u6743\u4ee5\u5b9e\u73b0\u4e2a\u6027\u5316\u4e14\u9ad8\u6548\u7684\u5168\u5c40\u8868\u793a\u3002", "method": "\u63d0\u51fa FedAPA\uff1a\u4f7f\u7528\u81ea\u9002\u5e94\u539f\u578b\u805a\u5408\uff08APA\uff09\u7b56\u7565\uff0c\u4e3a\u540c\u4f34\u539f\u578b\u5206\u914d\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u6743\u91cd\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684\u4e2a\u6027\u5316\u5168\u5c40\u539f\u578b\uff1b\u5728\u672c\u5730\u8bad\u7ec3\u4e2d\u91c7\u7528\u6df7\u5408\u76ee\u6807\uff0c\u7ed3\u5408\u5206\u7c7b\u5b66\u4e60\u548c\u8868\u793a\u5bf9\u6bd4\u5b66\u4e60\u4ee5\u5bf9\u9f50\u5c40\u90e8\u4e0e\u5168\u5c40\u77e5\u8bc6\uff1b\u7ed9\u51fa\u6536\u655b\u6027\u5206\u6790\uff0c\u5e76\u5728\u5305\u542b\u516d\u4e2a\u73af\u5883\u3001\u6700\u591a20\u4eba\u5206\u5e03\u5f0f Wi-Fi \u573a\u666f\u4e2d\u8fdb\u884c\u5b9e\u9645\u8bc4\u4f30\u3002", "result": "\u76f8\u5bf9\u4e8e\u591a\u9879\u57fa\u7ebf\uff0cFedAPA \u5728\u51c6\u786e\u7387\u3001F1\u3001MAE \u4ee5\u53ca\u901a\u4fe1\u5f00\u9500\u65b9\u9762\u5747\u6709\u63d0\u5347\uff1a\u51c6\u786e\u7387\u81f3\u5c11\u63d0\u5347 9.65%\uff0cF1 \u63d0\u5347\u7ea6 9%\uff0cMAE \u964d\u4f4e\u7ea6 0.29\uff0c\u901a\u4fe1\u5f00\u9500\u964d\u4f4e\u7ea6 95.94%\u3002", "conclusion": "FedAPA \u6709\u6548\u7f13\u89e3\u4e86\u5f02\u8d28\u6027\u6570\u636e\u548c\u8d44\u6e90\u7ea6\u675f\u5e26\u6765\u7684\u6311\u6218\uff0c\u901a\u8fc7\u5bf9\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684\u4e2a\u6027\u5316\u5168\u5c40\u539f\u578b\u5b9e\u73b0\u66f4\u7cbe\u51c6\u7684 CSI \u57fa\u4e8e\u611f\u77e5\uff0c\u4e14\u5728\u7406\u8bba\u6536\u655b\u6027\u4e0e\u5b9e\u8bc1\u8bc4\u4f30\u4e0a\u5747\u8868\u73b0\u826f\u597d\uff0c\u663e\u793a\u5728\u73b0\u5b9e\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.21050", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.21050", "abs": "https://arxiv.org/abs/2511.21050", "authors": ["Dongkyu Derek Cho", "Huan Song", "Arijit Ghosh Chowdhury", "Haotian An", "Yawei Wang", "Rohit Thekkanal", "Negin Sokhandan", "Sharlina Keshava", "Hannah Marlowe"], "title": "Breaking the Safety-Capability Tradeoff: Reinforcement Learning with Verifiable Rewards Maintains Safety Guardrails in LLMs", "comment": "AAAI-26 Workshop on Post-AI Formal Methods", "summary": "Fine-tuning large language models (LLMs) for downstream tasks typically exhibit a fundamental safety-capability tradeoff, where improving task performance degrades safety alignment even on benign datasets. This degradation persists across standard approaches including supervised finetuning (SFT) and reinforcement learning from human feedback (RLHF). While reinforcement learning with verifiable rewards (RLVR) has emerged as a promising alternative that optimizes models on objectively measurable tasks, its safety implications remain unexplored. We present the first comprehensive theoretical and empirical analysis of safety properties in RLVR. Theoretically, we derive upper bounds on safety drift under KL-constrained optimization and prove conditions under which safety degradation is eliminated. Empirically, we conduct extensive experiments across five adversarial safety benchmarks, demonstrating that RLVR can simultaneously enhance reasoning capabilities while maintaining or improving safety guardrails. Our comprehensive ablation studies examine the effects of optimization algorithms, model scale, and task domains. Our findings challenge the prevailing assumption of an inevitable safety capability trade-off, and establish that a specific training methodology can achieve both objectives simultaneously, providing insights for the safe deployment of reasoning-capable LLMs.", "AI": {"tldr": "RLVR\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\u4e2d\u663e\u793a\uff0c\u5728KL\u7ea6\u675f\u4e0b\u53ef\u4ee5\u540c\u65f6\u63d0\u9ad8\u63a8\u7406\u80fd\u529b\u4e0e\u5b89\u5168\u6027\uff0c\u6311\u6218\u4e86\u666e\u904d\u7684\u5b89\u5168-\u80fd\u529b\u6743\u8861\u5047\u8bbe\u3002", "motivation": "\u73b0\u6709\u5fae\u8c03\u7b56\u7565\uff08SFT\u3001RLHF\uff09\u5728\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u65f6\u5e38\u4f34\u968f\u5b89\u5168\u6027\u4e0b\u964d\uff0c\u5b58\u5728\u5b89\u5168\u4e0e\u80fd\u529b\u7684\u56fa\u6709\u6743\u8861\u3002\u5c3d\u7ba1RLVR\u5f15\u5165\u53ef\u9a8c\u8bc1\u7684\u5956\u52b1\u4ee5\u89e3\u51b3\u53ef\u6d4b\u4efb\u52a1\uff0c\u4f46\u5176\u5b89\u5168\u6027\u5f71\u54cd\u5c1a\u672a\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u7406\u8bba\u5206\u6790\uff1a\u5728KL\u7ea6\u675f\u4f18\u5316\u4e0b\u63a8\u5bfc\u5b89\u5168\u6f02\u79fb\u7684\u4e0a\u754c\uff0c\u5e76\u7ed9\u51fa\u5728\u4f55\u79cd\u6761\u4ef6\u4e0b\u53ef\u6d88\u9664\u5b89\u5168\u9000\u5316\u7684\u5145\u8981\u6761\u4ef6\uff1b\u5b9e\u8bc1\u5206\u6790\uff1a\u5728\u4e94\u4e2a\u5bf9\u6297\u6027\u5b89\u5168\u57fa\u51c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4f18\u5316\u7b97\u6cd5\u3001\u6a21\u578b\u89c4\u6a21\u4e0e\u4efb\u52a1\u9886\u57df\u7684\u5f71\u54cd\uff0c\u8f85\u4ee5\u6d88\u878d\u7814\u7a76\u3002", "result": "\u7406\u8bba\u4e0a\u7ed9\u51fa\u5b89\u5168\u6f02\u79fb\u4e0a\u754c\uff0c\u5e76\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u6d88\u9664\u5b89\u5168\u9000\u5316\uff1b\u5b9e\u8bc1\u4e0a\uff0cRLVR\u5728\u591a\u9879\u57fa\u51c6\u4e0a\u540c\u65f6\u63d0\u5347\u63a8\u7406\u80fd\u529b\u4e0e\u4fdd\u6301\u6216\u6539\u5584\u5b89\u5168\u62a4\u680f\uff0c\u4e14\u5bf9\u4f18\u5316\u7b97\u6cd5\u3001\u6a21\u578b\u89c4\u6a21\u548c\u4efb\u52a1\u57df\u7684\u654f\u611f\u6027\u5f97\u5230\u7cfb\u7edf\u5206\u6790\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u5b89\u5168-\u80fd\u529b\u5fc5\u7136\u6743\u8861\u7684\u666e\u904d\u8ba4\u77e5\uff0c\u8868\u660e\u901a\u8fc7\u5408\u9002\u7684\u8bad\u7ec3\u8303\u5f0f\uff08\u5982\u5e26KL\u7ea6\u675f\u7684RLVR\uff09\u53ef\u5b9e\u73b0\u4e24\u8005\u5171\u8d62\uff0c\u4e3a\u5b89\u5168\u53ef\u63a7\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u63d0\u4f9b\u65b0\u8def\u5f84\u3002"}}
{"id": "2511.21054", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21054", "abs": "https://arxiv.org/abs/2511.21054", "authors": ["Jiaming Guo", "Rui Zhang", "Zerun Li", "Yunkai Gao", "Shaohui Peng", "Siming Lan", "Xing Hu", "Zidong Du", "Xishan Zhang", "Ling Li"], "title": "Efficient Diffusion Planning with Temporal Diffusion", "comment": "Accepted by the AAAI26 Conference Main Track", "summary": "Diffusion planning is a promising method for learning high-performance policies from offline data. To avoid the impact of discrepancies between planning and reality on performance, previous works generate new plans at each time step. However, this incurs significant computational overhead and leads to lower decision frequencies, and frequent plan switching may also affect performance. In contrast, humans might create detailed short-term plans and more general, sometimes vague, long-term plans, and adjust them over time. Inspired by this, we propose the Temporal Diffusion Planner (TDP) which improves decision efficiency by distributing the denoising steps across the time dimension. TDP begins by generating an initial plan that becomes progressively more vague over time. At each subsequent time step, rather than generating an entirely new plan, TDP updates the previous one with a small number of denoising steps. This reduces the average number of denoising steps, improving decision efficiency. Additionally, we introduce an automated replanning mechanism to prevent significant deviations between the plan and reality. Experiments on D4RL show that, compared to previous works that generate new plans every time step, TDP improves the decision-making frequency by 11-24.8 times while achieving higher or comparable performance.", "AI": {"tldr": "Temporal Diffusion Planner (TDP) \u5c06\u6269\u6563\u8ba1\u5212\u4e2d\u7684\u53bb\u566a\u6b65\u9aa4\u5206\u6563\u5230\u65f6\u95f4\u7ef4\u5ea6\uff0c\u901a\u8fc7\u751f\u6210\u521d\u59cb\u8ba1\u5212\u5e76\u4f7f\u5176\u968f\u65f6\u95f4\u9010\u6e10\u53d8\u5f97\u6a21\u7cca\uff0c\u5728\u540e\u7eed\u65f6\u95f4\u6b65\u4ec5\u5bf9\u524d\u4e00\u8ba1\u5212\u8fdb\u884c\u5c11\u91cf\u53bb\u566a\u66f4\u65b0\uff0c\u4ece\u800c\u964d\u4f4e\u8ba1\u7b97\u91cf\u5e76\u63d0\u9ad8\u51b3\u7b56\u9891\u7387\uff0c\u540c\u65f6\u5f15\u5165\u81ea\u52a8\u518d\u89c4\u5212\u4ee5\u907f\u514d\u4e0e\u73b0\u5b9e\u504f\u5dee\u8fc7\u5927\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728 D4RL \u4e0a\u76f8\u6bd4\u9010\u6b65\u91cd\u65b0\u751f\u6210\u8ba1\u5212\u7684\u65b9\u6cd5\uff0c\u51b3\u7b56\u9891\u7387\u63d0\u5347\u7ea6 11-24.8 \u500d\uff0c\u4e14\u6027\u80fd\u76f8\u540c\u6216\u66f4\u597d\u3002", "motivation": "\u79bb\u7ebf\u6570\u636e\u4e0a\u5b66\u4e60\u9ad8\u6027\u80fd\u7b56\u7565\u7684\u6269\u6563\u89c4\u5212\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u751f\u6210\u65b0\u8ba1\u5212\u4f1a\u5e26\u6765\u663e\u8457\u7684\u8ba1\u7b97\u5f00\u9500\u5e76\u964d\u4f4e\u51b3\u7b56\u9891\u7387\uff0c\u4e14\u9891\u7e41\u5207\u6362\u8ba1\u5212\u53ef\u80fd\u5f71\u54cd\u6027\u80fd\u3002\u53d7\u4eba\u7c7b\u201c\u77ed\u671f\u5177\u4f53\u3001\u957f\u671f\u6982\u62ec\u201d\u7684\u89c4\u5212\u65b9\u5f0f\u542f\u53d1\uff0c\u63d0\u51fa\u4e00\u79cd\u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u5206\u914d\u53bb\u566a\u6b65\u9aa4\u7684\u7b56\u7565\u4ee5\u63d0\u9ad8\u51b3\u7b56\u6548\u7387\u5e76\u4fdd\u6301\u5bf9\u73b0\u5b9e\u73af\u5883\u7684\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51fa Temporal Diffusion Planner (TDP)\uff1a\u5148\u751f\u6210\u521d\u59cb\u8ba1\u5212\uff0c\u8ba9\u5176\u968f\u65f6\u95f4\u9010\u6b65\u53d8\u5f97\u6a21\u7cca\uff1b\u5728\u6bcf\u4e2a\u540e\u7eed\u65f6\u95f4\u6b65\u5bf9\u524d\u4e00\u8ba1\u5212\u505a\u5c11\u91cf\u7684\u53bb\u566a\u66f4\u65b0\uff0c\u800c\u975e\u91cd\u65b0\u751f\u6210\u4e00\u4e2a\u65b0\u8ba1\u5212\uff1b\u901a\u8fc7\u8fd9\u79cd\u8de8\u65f6\u95f4\u7684\u53bb\u566a\u5206\u5e03\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u51b3\u7b56\uff0c\u5e76\u5f15\u5165\u81ea\u52a8\u518d\u89c4\u5212\u673a\u5236\u4ee5\u9632\u6b62\u8ba1\u5212\u4e0e\u73b0\u5b9e\u4e4b\u95f4\u51fa\u73b0\u8fc7\u5927\u504f\u5dee\u3002\u5b9e\u9a8c\u5728 D4RL \u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4e0e\u9010\u6b65\u751f\u6210\u65b0\u8ba1\u5212\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u51b3\u7b56\u9891\u7387\u663e\u8457\u63d0\u9ad8\u4e14\u6027\u80fd\u7b49\u4ef7\u6216\u63d0\u5347\u3002", "result": "\u4e0e\u9010\u6b65\u751f\u6210\u65b0\u8ba1\u5212\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0cTDP \u5c06\u51b3\u7b56\u9891\u7387\u63d0\u9ad8\u4e86\u7ea6 11-24.8 \u500d\uff0c\u540c\u65f6\u5728\u591a\u6570\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u76f8\u540c\u6216\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5c06\u53bb\u566a\u6b65\u9aa4\u5206\u6563\u5230\u65f6\u95f4\u7ef4\u5ea6\uff0cTDP \u663e\u8457\u63d0\u5347\u51b3\u7b56\u6548\u7387\u5e76\u7ef4\u6301\u6216\u63d0\u5347\u6027\u80fd\uff1b\u81ea\u52a8\u518d\u89c4\u5212\u673a\u5236\u6709\u6548\u51cf\u5c11\u8ba1\u5212\u4e0e\u73b0\u5b9e\u4e4b\u95f4\u7684\u504f\u5dee\uff0c\u8bc1\u660e\u4e86\u5728\u79bb\u7ebf\u5b66\u4e60\u573a\u666f\u4e2d\uff0c\u5206\u65f6\u7684\u6269\u6563\u89c4\u5212\u662f\u53ef\u884c\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.21056", "categories": ["cs.LG", "cs.CL", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.21056", "abs": "https://arxiv.org/abs/2511.21056", "authors": ["Quan Xiao", "Tianyi Chen"], "title": "A Unified Understanding of Offline Data Selection and Online Self-refining Generation for Post-training LLMs", "comment": null, "summary": "Offline data selection and online self-refining generation, which enhance the data quality, are crucial steps in adapting large language models (LLMs) to specific downstream tasks. We tackle offline data selection and online self-refining generations through an optimization perspective. Specifically, bilevel data selection is used for offline data selection with respect to the validation dataset, and we treat online self-refining generation as a model adaptation step of selecting the model trained on current responses that best fits the validation data. Our framework offers a unified understanding of offline data selection and self-refining generation by assigning a learned data weight to each question and response, either explicitly or implicitly. For the first time, we theoretically demonstrate the effectiveness of the bilevel data selection framework and demonstrate its performance gains over unfiltered direct mixing baselines. By combining offline data with validation-weighted online generations, our method enhances fine-tuning performance. Experiments on quality enhancement and safety-aware LLM fine-tuning validate its effectiveness.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5c06\u79bb\u7ebf\u6570\u636e\u9009\u62e9\u548c\u5728\u7ebf\u81ea\u6211\u7cbe\u70bc\u751f\u6210\u7edf\u4e00\u89c6\u89d2\u7684\u6846\u67b6\uff0c\u7528\u4ee5\u9002\u914d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\uff0c\u91c7\u7528\u53cc\u5c42\u6570\u636e\u9009\u62e9\u5e76\u5bf9\u6bcf\u4e2a\u95ee\u9898/\u54cd\u5e94\u5206\u914d\u53ef\u5b66\u4e60\u7684\u6743\u91cd\uff0c\u7406\u8bba\u4e0a\u8bc1\u660e\u5176\u6709\u6548\u6027\u5e76\u5728\u8d28\u91cf\u63d0\u5347\u4e0e\u5b89\u5168\u5bf9\u9f50\u4efb\u52a1\u4e0a\u4f18\u4e8e\u672a\u7b5b\u9009\u57fa\u7ebf\u3002", "motivation": "LLM\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u6570\u636e\u8d28\u91cf\u76f4\u63a5\u51b3\u5b9a\u6027\u80fd\uff1b\u79bb\u7ebf\u6570\u636e\u9009\u62e9\u548c\u5728\u7ebf\u81ea\u6211\u7cbe\u70bc\u751f\u6210\u662f\u63d0\u5347\u6570\u636e\u8d28\u91cf\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u4f18\u5316\u6846\u67b6\u3002\u6587\u4e2d\u901a\u8fc7\u4f18\u5316\u89c6\u89d2\uff0c\u5c06\u79bb\u7ebf\u9009\u62e9\u4e0e\u5728\u7ebf\u81ea\u6211\u6539\u8fdb\u7ed3\u5408\uff0c\u5229\u7528\u9a8c\u8bc1\u96c6\u6743\u91cd\u6765\u6307\u5bfc\u6570\u636e\u4e0e\u6a21\u578b\u7684\u9002\u914d\u3002", "method": "\u63d0\u51fa\u53cc\u5c42(bilevel)\u6570\u636e\u9009\u62e9\u7528\u4e8e\u79bb\u7ebf\u6570\u636e\u5bf9\u9a8c\u8bc1\u96c6\u7684\u9009\u62e9\uff0c\u5e76\u5c06\u5728\u7ebf\u81ea\u6211\u7cbe\u70bc\u751f\u6210\u89c6\u4e3a\u5bf9\u5f53\u524d\u56de\u7b54\u5e8f\u5217\u7684\u6a21\u578b\u9002\u914d\uff08\u9009\u62e9\u5728\u5f53\u524d\u54cd\u5e94\u4e0a\u8bad\u7ec3\u5f97\u5230\u7684\u6a21\u578b\u4ee5\u66f4\u597d\u62df\u5408\u9a8c\u8bc1\u6570\u636e\uff09\uff0c\u5bf9\u6bcf\u4e2a\u95ee\u9898\u4e0e\u56de\u7b54\u5206\u914d\u5b66\u4e60\u5f97\u5230\u7684\u6570\u636e\u6743\u91cd\uff0c\u8fd9\u4e9b\u6743\u91cd\u53ef\u663e\u5f0f\u6216\u9690\u5f0f\u5730\u4f53\u73b0\u3002\u9996\u6b21\u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u53cc\u5c42\u6570\u636e\u9009\u62e9\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u79bb\u7ebf\u6570\u636e\u4e0e\u57fa\u4e8e\u9a8c\u8bc1\u6570\u636e\u6743\u91cd\u7684\u5728\u7ebf\u751f\u6210\u76f8\u7ed3\u5408\u65f6\u63d0\u5347\u6027\u80fd\u3002", "result": "\u7406\u8bba\u5c42\u9762\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u76f8\u5bf9\u4e8e\u672a\u7b5b\u9009\u76f4\u63a5\u6df7\u5408\u57fa\u7ebf\u7684\u6027\u80fd\u63d0\u5347\uff1b\u5728\u8d28\u91cf\u63d0\u5347\u548c\u5b89\u5168\u53cb\u597d/\u5b89\u5168\u610f\u8bc6\u7684LLM\u5fae\u8c03\u4efb\u52a1\u4e0a\u5b9e\u9a8c\u7ed3\u679c\u652f\u6301\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u79bb\u7ebf\u6570\u636e\u9009\u62e9\u4e0e\u81ea\u6211\u7cbe\u70bc\u751f\u6210\u7684\u7edf\u4e00\u7406\u89e3\uff0c\u7ed3\u5408\u79bb\u7ebf\u6570\u636e\u4e0e\u4ee5\u9a8c\u8bc1\u6570\u636e\u4e3a\u6743\u91cd\u7684\u5728\u7ebf\u751f\u6210\u53ef\u63d0\u5347\u5fae\u8c03\u6027\u80fd\u3002"}}
{"id": "2511.21075", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21075", "abs": "https://arxiv.org/abs/2511.21075", "authors": ["Zhenchao Tang", "Fang Wang", "Haohuai He", "Jiale Zhou", "Tianxu Lv", "Jun Zhu", "Shouzhi Chen", "Minghao Yang", "Yu Wang", "Jiayang Wu", "Yidong Song", "Jianhua Yao"], "title": "Aligning LLMs with Biomedical Knowledge using Balanced Fine-Tuning", "comment": null, "summary": "Effective post-training is essential to align Large Language Models (LLMs) with specialized biomedical knowledge to accelerate life science research. However, current approaches face significant limitations. First, biomedical reasoning involves intricate mechanisms often represented by sparse textual data. Standard Supervised Fine-Tuning (SFT) tends to overfit to surface-level instruction patterns without effectively internalizing this fragmented scientific knowledge. Second, Reinforcement Learning (RL) is impractical for this domain, as defining meaningful rewards often necessitates prohibitive experimental validation (e.g., wet-lab verification of drug responses), rendering real-time feedback unfeasible. We propose Balanced Fine-Tuning (BFT), an efficient post-training method designed to learn complex reasoning from sparse data without external reward signals. BFT operates through a two-layer weighting mechanism: 1. At the token level, it scales loss via prediction probabilities to stabilize gradients and prevent overfitting; 2. At the sample level, it uses \"minimum group confidence\" to adaptively enhance the learning of hard samples. Experiments demonstrate that BFT significantly outperforms SFT. In medical tasks, it enables LLMs to acquire knowledge that SFT misses. In biological tasks, BFT-based LLMs surpass GeneAgent (an accurate agent for biology analysis) in biological process reasoning. Moreover, the text embeddings generated by BFT can be directly applied to downstream tasks, such as gene interaction and single-cell perturbation response prediction. These results indicate that BFT facilitates broad applications of LLMs in biomedical research.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3a Balanced Fine-Tuning (BFT) \u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u5c42\u6743\u91cd\u673a\u5236\u5728\u7f3a\u4e4f\u5916\u90e8\u5956\u52b1\u7684\u60c5\u51b5\u4e0b\u4ece\u7a00\u758f\u751f\u7269\u533b\u5b66\u6570\u636e\u4e2d\u5b66\u4e60\u590d\u6742\u63a8\u7406\uff0c\u663e\u8457\u4f18\u4e8e SFT\uff0c\u5e76\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684 SFT \u5bb9\u6613\u5bf9\u8868\u5c42\u6307\u4ee4\u6a21\u5f0f\u8fc7\u62df\u5408\uff0c\u4e14\u751f\u7269\u533b\u5b66\u63a8\u7406\u4f9d\u8d56\u7a00\u758f\u6587\u672c\u6570\u636e\uff1bRL \u9700\u8981\u65e0\u6cd5\u5b9e\u73b0\u7684\u5916\u90e8\u5956\u52b1\u548c\u9a8c\u8bc1\uff0c\u96be\u4ee5\u5728\u8be5\u9886\u57df\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\u6765\u589e\u5f3a\u5bf9\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u7684\u5185\u5728\u5316\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4e24\u5c42\u6743\u91cd\uff1a1) \u4ee4\u724c\u7ea7\u635f\u5931\u901a\u8fc7\u9884\u6d4b\u6982\u7387\u653e\u7f29\u4ee5\u7a33\u5b9a\u68af\u5ea6\u3001\u9632\u6b62\u8fc7\u62df\u5408\uff1b2) \u6837\u672c\u7ea7\u901a\u8fc7\u201c\u6700\u5c0f\u7ec4\u7f6e\u4fe1\u5ea6\u201d\uff08minimum group confidence\uff09\u81ea\u9002\u5e94\u63d0\u5347\u5bf9\u96be\u6837\u672c\u7684\u5b66\u4e60\uff1b\u65e0\u9700\u5916\u90e8\u5956\u52b1\u4fe1\u53f7\uff1b\u5bf9\u6bd4\u5b9e\u9a8c\u663e\u793a\u5bf9 SFT \u66f4\u4f18\u3002", "result": "BFT \u5728\u533b\u7597\u4efb\u52a1\u4e2d\u4f7f\u6a21\u578b\u83b7\u5f97 SFT \u672a\u80fd\u83b7\u5f97\u7684\u77e5\u8bc6\uff1b\u5728\u751f\u7269\u4efb\u52a1\u4e2d\uff0cBFT \u7684\u6a21\u578b\u5728\u751f\u7269\u8fc7\u7a0b\u63a8\u7406\u65b9\u9762\u4f18\u4e8e GeneAgent\uff1b\u6587\u672c\u5d4c\u5165\u53ef\u76f4\u63a5\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\uff0c\u5982\u57fa\u56e0\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u548c\u5355\u7ec6\u80de\u6270\u52a8\u53cd\u5e94\u9884\u6d4b\uff1b\u603b\u4f53\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u751f\u7269\u533b\u5b66\u9886\u57df\u7684 LLMS \u80fd\u529b\u3002", "conclusion": "BFT \u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u65e0\u5956\u52b1\u4fe1\u53f7\u7684\u540e\u8bad\u7ec3\u7b56\u7565\uff0c\u80fd\u4ece\u7a00\u758f\u6570\u636e\u4e2d\u5b66\u4e60\u590d\u6742\u63a8\u7406\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u751f\u7269\u533b\u836f\u7814\u7a76\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.21089", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21089", "abs": "https://arxiv.org/abs/2511.21089", "authors": ["Ivan Novikov"], "title": "MLPMoE: Zero-Shot Architectural Metamorphosis of Dense LLM MLPs into Static Mixture-of-Experts", "comment": null, "summary": "Large Language Models (LLMs) are predominantly deployed as dense transformers, where every parameter in every feed-forward block is activated for every token. While architecturally simple, this is computationally inefficient, since inference costs scale linearly with parameter count. Recent upcycling methods such as MoEfication, CMoE, ToMoE, and MoORE reveal that much of the useful computation lives in sparse, semi-modular substructures inside dense feed-forward networks, but these approaches typically rely on clustering, activation profiling, singular value decomposition, or custom routing that requires calibration data. This paper introduces MLPMoE (MLP Mixture-of-Experts), a training-free, deterministic transformation that restructures the dense MLP in transformer blocks into a static, high-cardinality mixture of experts. The transformation uses simple tensor slicing and summation, reinterpreting the algebra of tensor parallelism as a topological conversion rather than a distributed training pattern. We further introduce Fractal Fade (differential branch sparsity) and Compensated Pruning (variance-preserving branch reduction) as lightweight mechanisms for structured sparsity. On Qwen2.5-0.5B-Instruct and DeepSeek-R1-Distill-Llama-8B, the zero-shot MLPMoE transform changes a proxy perplexity metric by less than 0.05 percent while keeping the parameter count effectively constant. On the 8B model, differential sparsity removes about 20 percent of MLP parameters while keeping perplexity within about 2 percent of the dense baseline. The method operates entirely post hoc on existing checkpoints and does not require gradients, calibration sets, or router training. Code is available at https://gist.github.com/iwallarm/fc2ef1eddf226ca7814f9e5e2ae9bad1", "AI": {"tldr": "A training-free, deterministic method (MLPMoE) converts dense MLPs in transformers into a static, high-cardinality mixture of experts via tensor slicing, enabling structured sparsity with minimal accuracy loss; augmented by Fractal Fade and Compensated Pruning, it works post hoc on checkpoints without training data or routers, and achieves substantial parameter reduction (\u224820%) with small perplexity changes on large models.", "motivation": "Inference cost in dense LLMs scales linearly with parameter count; prior sparse MoE methods require calibration data, clustering, or training. A training-free, deterministic transformation to a fixed mixture of experts promises efficiency without additional data or gradient steps.", "method": "Apply MLPMoE: reinterpret tensor parallelism as a topological conversion and restructure dense MLPs into a static, high-cardinality mixture of experts using simple tensor slicing and summation. Introduce Fractal Fade (differential branch sparsity) and Compensated Pruning (variance-preserving branch reduction) to induce structured sparsity. The process is post hoc, code-based, and does not require gradients or router training.", "result": "Zero-shot MLPMoE on Qwen2.5-0.5B-Instruct and DeepSeek-R1-Distill-Llama-8B changes proxy perplexity by <0.05% with essentially unchanged parameter count. On an 8B model, differential sparsity removes ~20% of MLP parameters while keeping perplexity within ~2% of the dense baseline.", "conclusion": "A training-free, gradient-free post hoc transformation can induce structured sparsity in dense transformers with minimal impact on perplexity, enabling more efficient inference without extra calibration data or training; accompanying code is available."}}
{"id": "2511.21092", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21092", "abs": "https://arxiv.org/abs/2511.21092", "authors": ["Seunghun Baek", "Jaejin Lee", "Jaeyoon Sim", "Minjae Jeong", "Won Hwa Kim"], "title": "MNM : Multi-level Neuroimaging Meta-analysis with Hyperbolic Brain-Text Representations", "comment": "MICCAI 2025 (Provisional Accept; top ~9%)", "summary": "Various neuroimaging studies suffer from small sample size problem which often limit their reliability. Meta-analysis addresses this challenge by aggregating findings from different studies to identify consistent patterns of brain activity. However, traditional approaches based on keyword retrieval or linear mappings often overlook the rich hierarchical structure in the brain. In this work, we propose a novel framework that leverages hyperbolic geometry to bridge the gap between neuroscience literature and brain activation maps. By embedding text from research articles and corresponding brain images into a shared hyperbolic space via the Lorentz model, our method captures both semantic similarity and hierarchical organization inherent in neuroimaging data. In the hyperbolic space, our method performs multi-level neuroimaging meta-analysis (MNM) by 1) aligning brain and text embeddings for semantic correspondence, 2) guiding hierarchy between text and brain activations, and 3) preserving the hierarchical relationships within brain activation patterns. Experimental results demonstrate that our model outperforms baselines, offering a robust and interpretable paradigm of multi-level neuroimaging meta-analysis via hyperbolic brain-text representation.", "AI": {"tldr": "\u5c06\u6587\u672c\u4e0e\u8111\u6fc0\u6d3b\u56fe\u5728\u6d1b\u4f26\u5179\u8d85\u66f2\u7387\u7a7a\u95f4\u4e2d\u5d4c\u5165\uff0c\u5b9e\u73b0\u8de8\u5c42\u7ea7\u7684\u795e\u7ecf\u5f71\u50cf\u5143\u5206\u6790\uff1b\u901a\u8fc7\u8d85\u66f2\u7387\u51e0\u4f55\u540c\u65f6\u6355\u83b7\u8bed\u4e49\u76f8\u4f3c\u6027\u4e0e\u5c42\u7ea7\u7ed3\u6784\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u795e\u7ecf\u5f71\u50cf\u7814\u7a76\u5e38\u56e0\u6837\u672c\u91cf\u5c0f\u800c\u53ef\u91cd\u590d\u6027\u5dee\uff1b\u4f20\u7edf\u65b9\u6cd5\u5ffd\u7565\u8111\u7684\u5c42\u7ea7\u7ec4\u7ec7\u7ed3\u6784\uff0c\u96be\u4ee5\u7edf\u4e00\u5904\u7406\u6587\u672c\u4e0e\u8111\u6fc0\u6d3b\u6570\u636e\u3002\u8d85\u66f2\u7387\u51e0\u4f55\u80fd\u5929\u7136\u5efa\u6a21\u5206\u5c42\u5173\u7cfb\uff0c\u4fbf\u4e8e\u8de8\u6a21\u6001\u7684\u8bed\u4e49\u4e0e\u8111\u6fc0\u6d3b\u5bf9\u9f50\u3002", "method": "\u5728\u540c\u4e00\u8d85\u66f2\u7ebf\u7a7a\u95f4\uff08\u6d1b\u4f26\u5179\u6a21\u578b\uff09\u4e2d\uff0c\u5c06\u7814\u7a76\u6587\u7ae0\u7684\u6587\u672c\u4e0e\u76f8\u5e94\u7684\u8111\u56fe\u50cf\u8fdb\u884c\u5d4c\u5165\u4e0e\u5bf9\u9f50\uff1b\u901a\u8fc7\u8be5\u5d4c\u5165\u5b9e\u73b0\u6587\u672c-\u8111\u6fc0\u6d3b\u7684\u8bed\u4e49\u5bf9\u5e94\u3001\u6587\u672c\u4e0e\u8111\u6fc0\u6d3b\u4e4b\u95f4\u7684\u5c42\u7ea7\u5f15\u5bfc\uff0c\u4ee5\u53ca\u5bf9\u8111\u6fc0\u6d3b\u6a21\u5f0f\u5185\u90e8\u5c42\u7ea7\u5173\u7cfb\u7684\u4fdd\u6301\uff0c\u5b8c\u6210\u591a\u5c42\u6b21\u795e\u7ecf\u5f71\u50cf\u5143\u5206\u6790\uff08MNM\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4e0e\u591a\u9879\u57fa\u7ebf\u7684\u5bf9\u6bd4\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u5177\u5907\u66f4\u597d\u7684\u9c81\u68d2\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u8d85\u66f2\u7ebf\u8111-\u6587\u672c\u8868\u793a\u6846\u67b6\u4e3a\u591a\u5c42\u6b21\u795e\u7ecf\u5f71\u50cf\u5143\u5206\u6790\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u80fd\u591f\u540c\u65f6\u6355\u83b7\u8bed\u4e49\u548c\u5c42\u7ea7\u4fe1\u606f\uff0c\u63d0\u5347\u5206\u6790\u7684\u89e3\u91ca\u6027\u4e0e\u53ef\u9760\u6027\u3002"}}
{"id": "2511.21095", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21095", "abs": "https://arxiv.org/abs/2511.21095", "authors": ["Juhee Hong", "Meng Liu", "Shengzhi Wang", "Xiaoheng Mao", "Huihui Cheng", "Leon Gao", "Christopher Leung", "Jin Zhou", "Chandra Mouli Sekar", "Zhao Zhu", "Ruochen Liu", "Tuan Trieu", "Dawei Sun", "Jeet Kanjani", "Rui Li", "Jing Qian", "Xuan Cao", "Minjie Fan", "Mingze Gao"], "title": "Generative Early Stage Ranking", "comment": null, "summary": "Large-scale recommendations commonly adopt a multi-stage cascading ranking system paradigm to balance effectiveness and efficiency. Early Stage Ranking (ESR) systems utilize the \"user-item decoupling\" approach, where independently learned user and item representations are only combined at the final layer. While efficient, this design is limited in effectiveness, as it struggles to capture fine-grained user-item affinities and cross-signals. To address these, we propose the Generative Early Stage Ranking (GESR) paradigm, introducing the Mixture of Attention (MoA) module which leverages diverse attention mechanisms to bridge the effectiveness gap: the Hard Matching Attention (HMA) module encodes explicit cross-signals by computing raw match counts between user and item features; the Target-Aware Self Attention module generates target-aware user representations conditioned on the item, enabling more personalized learning; and the Cross Attention modules facilitate early and more enriched interactions between user-item features. MoA's specialized attention encodings are further refined in the final layer through a Multi-Logit Parameterized Gating (MLPG) module, which integrates the newly learned embeddings via gating and produces secondary logits that are fused with the primary logit. To address the efficiency and latency challenges, we have introduced a comprehensive suite of optimization techniques. These span from custom kernels that maximize the capabilities of the latest hardware to efficient serving solutions powered by caching mechanisms. The proposed GESR paradigm has shown substantial improvements in topline metrics, engagement, and consumption tasks, as validated by both offline and online experiments. To the best of our knowledge, this marks the first successful deployment of full target-aware attention sequence modeling within an ESR stage at such a scale.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728ESR\u9636\u6bb5\u5f15\u5165\u6df7\u5408\u6ce8\u610f\u529b\u7684G\u5728 Generative Early Stage Ranking (GESR) \u6846\u67b6\uff0c\u901a\u8fc7 Mixture of Attention (MoA) \u5c06\u591a\u79cd\u6ce8\u610f\u529b\u673a\u5236\u7ed3\u5408\uff08\u786c\u5339\u914d\u6ce8\u610f\u529b HMA\u3001\u76ee\u6807\u611f\u77e5\u81ea\u6ce8\u610f\u529b\u3001\u8de8\u6ce8\u610f\u529b\uff09\uff0c\u5e76\u5728\u6700\u7ec8\u5c42\u901a\u8fc7\u591a\u5bf9\u6570\u95e8\u63a7 MLPG \u878d\u5408\u65b0\u5d4c\u5165\uff0c\u63d0\u5347\u6548\u679c\u4e0e\u6548\u7387\uff0c\u540c\u65f6\u5f15\u5165\u9ad8\u6027\u80fd\u786c\u4ef6\u5185\u6838\u4e0e\u7f13\u5b58\u7b49\u4f18\u5316\uff0c\u5b9e\u73b0\u5728\u7ebf/\u79bb\u7ebf\u5b9e\u9a8c\u7684 topline \u6307\u6807\u63d0\u5347\uff0c\u662f\u5728 ESR \u89c4\u6a21\u90e8\u7f72\u76ee\u6807\u611f\u77e5\u5e8f\u5217\u5efa\u6a21\u7684\u9996\u6b21\u5c1d\u8bd5\u3002", "motivation": "\u4f20\u7edf\u7684 ESR \u91c7\u7528\u7528\u6237\u548c\u7269\u54c1\u8868\u793a\u5206\u79bb\u3001\u5728\u6700\u7ec8\u5c42\u624d\u5408\u5e76\uff0c\u6548\u7387\u9ad8\u4f46\u96be\u4ee5\u6355\u6349\u7ec6\u7c92\u5ea6\u7684\u7528\u6237-\u7269\u54c1\u4eb2\u548c\u529b\u4e0e\u8de8\u4fe1\u53f7\uff1b\u9700\u8981\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u8de8\u7279\u5f81\u7684\u65e9\u671f\u4ea4\u4e92\u3002", "method": "\u63d0\u51fa Mixture of Attention (MoA) \u4f5c\u4e3a\u6838\u5fc3\u6846\u67b6\uff0c\u5305\u542b\u4ee5\u4e0b\u6a21\u5757\uff1a1) Hard Matching Attention (HMA)\uff1a\u901a\u8fc7\u8ba1\u7b97\u7528\u6237\u4e0e\u7269\u54c1\u7279\u5f81\u4e4b\u95f4\u7684\u539f\u59cb\u5339\u914d\u8ba1\u6570\u6765\u663e\u5f0f\u7f16\u7801\u8de8\u4fe1\u53f7\uff1b2) Target-Aware Self Attention\uff1a\u5728\u7ed9\u5b9a\u7269\u54c1\u7684\u6761\u4ef6\u4e0b\u751f\u6210\u76ee\u6807\u611f\u77e5\u7684\u7528\u6237\u8868\u793a\uff0c\u4f7f\u5b66\u4e60\u66f4\u5177\u4e2a\u6027\u5316\uff1b3) Cross Attention\uff1a\u5b9e\u73b0\u66f4\u65e9\u671f\u7684\u7528\u6237-\u7269\u54c1\u7279\u5f81\u4ea4\u4e92\uff1b4) \u7ec8\u7aef\u5c42\u7684 MLPG\uff08Multi-Logit Parameterized Gating\uff09\uff1a\u5229\u7528\u65b0\u5f97\u5230\u7684\u8868\u793a\u901a\u8fc7\u95e8\u63a7\u6574\u5408\u5e76\u751f\u6210\u6b21\u7ea7 logits\uff0c\u4e0e\u4e3b logits \u8fdb\u884c\u878d\u5408\uff1b5) \u5b9e\u65f6\u548c\u79bb\u7ebf\u7684\u9ad8\u6548\u5b9e\u73b0\u5305\u62ec\u81ea\u5b9a\u4e49\u5185\u6838\u4e0e\u7f13\u5b58\u9a71\u52a8\u7684\u670d\u52a1\u90e8\u7f72\u7b49\u4f18\u5316\u4ee5\u964d\u4f4e\u5ef6\u8fdf\u3002", "result": "\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u4e2d\uff0cGESR \u663e\u8457\u63d0\u5347 topline \u6307\u6807\u3001\u53c2\u4e0e\u5ea6\u548c\u6d88\u8d39\u4efb\u52a1\u8868\u73b0\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u4e0e\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5728 ESR \u9636\u6bb5\u9996\u6b21\u89c4\u6a21\u5316\u90e8\u7f72\u4e86\u7aef\u5230\u7aef\u76ee\u6807\u611f\u77e5\u6ce8\u610f\u529b\u5e8f\u5217\u5efa\u6a21\uff0c\u8bc1\u660e\u4e86\u6df7\u5408\u6ce8\u610f\u529b\u5bf9\u63d0\u5347 ESR \u6548\u679c\u4e0e\u6548\u7387\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.21103", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21103", "abs": "https://arxiv.org/abs/2511.21103", "authors": ["Hengyu Fu", "Baihe Huang", "Virginia Adams", "Charles Wang", "Venkat Srinivasan", "Jiantao Jiao"], "title": "From Bits to Rounds: Parallel Decoding with Exploration for Diffusion Language Models", "comment": "24 pages, 6 figures", "summary": "Diffusion Language Models (DLMs) have recently emerged as a strong alternative to autoregressive language models (LMs). DLMs offer comparable accuracy with faster inference speed via parallel decoding. However, standard DLM decoding strategies relying on high-confidence tokens encounter an inherent information-theoretic bottleneck that restricts decoding progress and ultimately slows generation. We demonstrate both theoretically and empirically that prioritizing high-confidence tokens is inherently inefficient. High-probability tokens carry negligible information and strictly relying on them limits the effective progress made in each decoding round. We prove that the number of decoding rounds must grow linearly with the sample's total information (negative log-likelihood) and inversely with the per-round information budget, establishing a bits-to-rounds principle. We also propose Explore-Then-Exploit (ETE), a training-free decoding strategy that maximizes information throughput and decoding efficiency. ETE combines cross-block decoding with targeted exploration of high-uncertainty tokens to reshape the conditional distribution and trigger cascades of confident predictions. Experiments verify our theoretical bounds and demonstrate that ETE consistently reduces the required number of decoding rounds compared to confidence-only baselines without compromising generation quality.", "AI": {"tldr": "Diffusion Language Models\uff08DLMs\uff09\u5728\u89e3\u7801\u9636\u6bb5\u5b58\u5728\u5c06\u9ad8\u7f6e\u4fe1\u5ea6 token \u4f5c\u4e3a\u4fe1\u606f\u589e\u91cf\u7684\u56fa\u6709\u4fe1\u606f\u74f6\u9888\uff0c\u5bfc\u81f4\u89e3\u7801\u8fdb\u5c55\u7f13\u6162\u3002\u7406\u8bba\u4e0e\u5b9e\u9a8c\u8868\u660e\uff0c\u4f18\u5148\u9009\u62e9\u9ad8\u7f6e\u4fe1\u5ea6 token \u4fe1\u606f\u91cf\u6709\u9650\u4e14\u6548\u7387\u4f4e\u4e0b\u3002\u672c\u8bba\u6587\u7ed9\u51fa\u4e00\u4e2a\u6bd4\u7279\u2014\u8f6e\u6b21\u7684\u539f\u5219\uff1a\u89e3\u7801\u8f6e\u6b21\u968f\u603b\u4fe1\u606f\u91cf\u7ebf\u6027\u589e\u52a0\u3001\u968f\u6bcf\u8f6e\u4fe1\u606f\u9884\u7b97\u6210\u53cd\u6bd4\u3002\u4e3a\u63d0\u9ad8\u89e3\u7801\u541e\u5410\u91cf\uff0c\u63d0\u51fa\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u7684\u89e3\u7801\u7b56\u7565 Explore-Then-Exploit\uff08ETE\uff09\uff0c\u901a\u8fc7\u8de8\u533a\u5757\u89e3\u7801\u4e0e\u9ad8\u4e0d\u786e\u5b9a\u6027 token \u7684\u5b9a\u5411\u63a2\u7d22\u6765\u91cd\u5851\u6761\u4ef6\u5206\u5e03\uff0c\u89e6\u53d1\u81ea\u4fe1\u9884\u6d4b\u7ea7\u8054\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u754c\u9650\u5e76\u8868\u660e ETE \u5728\u4e0d\u964d\u4f4e\u751f\u6210\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u964d\u4f4e\u6240\u9700\u89e3\u7801\u8f6e\u6b21\u3002", "motivation": "\u73b0\u6709\u7684 DLM \u89e3\u7801\u7b56\u7565\u4f9d\u8d56\u9ad8\u7f6e\u4fe1\u5ea6 token\uff0c\u5bfc\u81f4\u4fe1\u606f\u589e\u91cf\u4e0d\u8db3\u4e14\u89e3\u7801\u8f6e\u6b21\u968f\u8d1f\u5bf9\u6570\u4f3c\u7136\u7684\u603b\u4fe1\u606f\u91cf\u7ebf\u6027\u4e0a\u6da8\uff0c\u96be\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u5e76\u884c\u89e3\u7801\u3002\u9700\u8981\u4e00\u4e2a\u4e0d\u4f9d\u8d56\u989d\u5916\u8bad\u7ec3\u7684\u89e3\u7801\u7b56\u7565\u6765\u63d0\u5347\u4fe1\u606f\u541e\u5410\u91cf\u4e0e\u89e3\u7801\u6548\u7387\u3002", "method": "\u7406\u8bba\u4e0a\u63a8\u5bfc\u6bcf\u8f6e\u53ef\u83b7\u53d6\u4fe1\u606f\u4ee5\u53ca\u603b\u4fe1\u606f\u91cf\u4e0e\u8f6e\u6b21\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u4f4d\u6570\u5230\u8f6e\u6b21\u7684\u539f\u5219\uff1b\u63d0\u51fa Explore-Then-Exploit\uff08ETE\uff09\u89e3\u7801\u7b56\u7565\uff0c\u7ed3\u5408\u8de8\u533a\u5757\u89e3\u7801\u4e0e\u5bf9\u9ad8\u4e0d\u786e\u5b9a\u6027 token \u7684\u63a2\u7d22\uff0c\u4ee5\u91cd\u5851\u6761\u4ef6\u5206\u5e03\u5e76\u89e6\u53d1\u8fde\u7eed\u7684\u81ea\u4fe1\u9884\u6d4b\u3002", "result": "\u7406\u8bba\u754c\u9650\u5f97\u5230\u9a8c\u8bc1\uff0c\u4e14\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u76f8\u8f83\u4e8e\u4ec5\u4f9d\u8d56\u7f6e\u4fe1\u5ea6\u7684\u57fa\u7ebf\uff0cETE \u80fd\u663e\u8457\u51cf\u5c11\u6240\u9700\u89e3\u7801\u8f6e\u6b21\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "ETE \u63d0\u4f9b\u4e86\u4e00\u4e2a\u8bad\u7ec3\u65e0\u5173\u7684\u89e3\u7801\u7b56\u7565\uff0c\u901a\u8fc7\u4f18\u5316\u4fe1\u606f\u541e\u5410\u91cf\u548c\u63a2\u7d22\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u5347 DLM \u7684\u89e3\u7801\u6548\u7387\u4e0e\u751f\u6210\u901f\u5ea6\uff0c\u5e76\u5728\u7406\u8bba\u4e0e\u5b9e\u9a8c\u4e0a\u5f97\u5230\u652f\u6301\u3002"}}
{"id": "2511.21104", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21104", "abs": "https://arxiv.org/abs/2511.21104", "authors": ["Robert Joseph George", "Carson Eisenach", "Udaya Ghai", "Dominique Perrault-Joncas", "Anima Anandkumar", "Dean Foster"], "title": "BRIDGE: Building Representations In Domain Guided Program Verification", "comment": "Approx. 31 pages including appendices, 11 figures, 4 tables. Empirical study of LLM-based verified program synthesis in Lean4 (code, specs, and proofs)", "summary": "Large language models (LLMs) have achieved impressive results in code generation, yet struggle with program verification, especially in interactive proof frameworks such as Lean4. A central challenge is scalability: verified synthesis requires not just code, but also precise specifications and correctness proofs, and existing approaches rarely span all three domains. We present BRIDGE, the first systematic study of structured prompting for scalable verified program generation. BRIDGE decomposes verification into three interconnected domains: Code (executable implementations), Specifications (formal intent statements), and Proofs (constructive correctness arguments). Our key idea is to elicit distinct reasoning behaviors functional, specification-driven, and proof-oriented as intermediate representations that preserve semantic structure and connect these domains. Through systematic ablations, we show that this approach substantially improves both accuracy and efficiency beyond standard error feedback methods. For example, functional reasoning improves correctness of code in formal languages (Lean4) by nearly 1.5x (pass@5) over direct baselines. In inference-time compute, functional reasoning is also 2x more efficient, achieving higher pass rates with fewer generations and lower total sampling budgets. Similarly, we find that specification-driven prompting boosts Python coding pass rates by up to 17.5%. These findings suggest that structured domain alignment is a promising direction for advancing verified synthesis. BRIDGE establishes a foundation for training via expert iteration or RLVR, enabling models to internalize these reasoning strategies across code, specifications, and proofs.", "AI": {"tldr": "BRIDGE\u63d0\u51fa\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u5c06\u9a8c\u8bc1\u5206\u89e3\u4e3a\u4ee3\u7801\u3001\u89c4\u8303\u3001\u8bc1\u660e\u4e09\u4e2a\u9886\u57df\uff0c\u5e76\u901a\u8fc7\u72ec\u7acb\u7684\u63a8\u7406\u884c\u4e3a\u6765\u8fde\u63a5\u5b83\u4eec\uff0c\u663e\u8457\u63d0\u5347\u53ef\u9a8c\u8bc1\u7a0b\u5e8f\u751f\u6210\u7684\u51c6\u786e\u6027\u4e0e\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u540e\u5f80\u5f80\u96be\u4ee5\u5b8c\u6210\u53ef\u9a8c\u8bc1\u6027\u8981\u6c42\uff0c\u5c24\u5176\u5728\u4ea4\u4e92\u5f0f\u8bc1\u660e\u6846\u67b6\uff08\u5982 Lean4\uff09\u4e2d\uff0c\u9700\u8981\u540c\u65f6\u5177\u5907\u53ef\u6267\u884c\u5b9e\u73b0\u3001\u5f62\u5f0f\u89c4\u683c\u4e0e\u6b63\u786e\u6027\u8bc1\u660e\u4e09\u8005\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5f88\u5c11\u8986\u76d6\u4e09\u8005\u7684\u5168\u8fc7\u7a0b\uff0c\u5b58\u5728\u53ef\u6269\u5c55\u6027\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u7ed3\u6784\u5316\u63d0\u793a\u6846\u67b6 BRIDGE\uff0c\u5c06\u9a8c\u8bc1\u5206\u89e3\u4e3a Code\u3001Specifications\u3001Proofs \u4e09\u4e2a\u57df\uff0c\u5e76\u901a\u8fc7\u663e\u5f0f\u7684\u4e2d\u95f4\u8868\u793a\u6fc0\u53d1\u4e09\u79cd\u4e0d\u540c\u7684\u63a8\u7406\u884c\u4e3a\uff08functional\u3001specification-driven\u3001proof-oriented\uff09\uff0c\u4ee5\u4fdd\u6301\u8bed\u4e49\u7ed3\u6784\u5e76\u8fde\u63a5\u4e09\u4e2a\u57df\u3002\u901a\u8fc7\u7cfb\u7edf\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u8fd9\u4e00\u63a8\u7406\u5206\u89e3\u5bf9\u51c6\u786e\u6027\u4e0e\u6548\u7387\u7684\u63d0\u5347\u3002", "result": "\u76f8\u5bf9\u4e8e\u76f4\u63a5\u57fa\u7ebf\u548c\u5e38\u89c1\u9519\u8bef\u53cd\u9988\u65b9\u6cd5\uff0cBRIDGE\u663e\u8457\u63d0\u5347\u4e86\u53ef\u9a8c\u8bc1\u5408\u6210\u7684\u6027\u80fd\u3002\u4ee5 Lean4 \u4e3a\u4f8b\uff0cfunctional reasoning \u5c06\u6b63\u786e\u6027\u5728 pass@5 \u4e0a\u63d0\u5347\u7ea6 1.5 \u500d\uff1b\u63a8\u7406\u65f6\u7684\u63a8\u7406\u8ba1\u7b97\u6210\u672c\u4e5f\u63d0\u5347\u4e86\u7ea6 2 \u500d\u7684\u6548\u7387\uff08\u66f4\u5c11\u7684\u751f\u6210\u4e0e\u66f4\u4f4e\u7684\u91c7\u6837\u9884\u7b97\uff09\u3002\u5728 Python \u9886\u57df\uff0cspecification-driven prompting \u5c06\u901a\u8fc7\u7387\u63d0\u5347\u81f3\u591a 17.5%\u3002", "conclusion": "\u7ed3\u6784\u5316\u9886\u57df\u5bf9\u9f50\u662f\u53ef\u9a8c\u8bc1\u5408\u6210\u7684\u6709\u524d\u666f\u65b9\u5411\uff0cBRIDGE \u4e3a\u901a\u8fc7\u4e13\u5bb6\u8fed\u4ee3\u6216 RLVR \u8fdb\u884c\u8bad\u7ec3\u5960\u5b9a\u57fa\u7840\uff0c\u4fc3\u4f7f\u6a21\u578b\u5728\u4ee3\u7801\u3001\u89c4\u683c\u4e0e\u8bc1\u660e\u4e09\u57df\u5185\u5185\u5316\u8fd9\u4e9b\u63a8\u7406\u7b56\u7565\u3002"}}
{"id": "2511.21109", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21109", "abs": "https://arxiv.org/abs/2511.21109", "authors": ["Mudi Jiang", "Jiahui Zhou", "Xinying Liu", "Zengyou He", "Zhikui Chen"], "title": "Interpretable Fair Clustering", "comment": null, "summary": "Fair clustering has gained increasing attention in recent years, especially in applications involving socially sensitive attributes. However, existing fair clustering methods often lack interpretability, limiting their applicability in high-stakes scenarios where understanding the rationale behind clustering decisions is essential. In this work, we address this limitation by proposing an interpretable and fair clustering framework, which integrates fairness constraints into the structure of decision trees. Our approach constructs interpretable decision trees that partition the data while ensuring fair treatment across protected groups. To further enhance the practicality of our framework, we also introduce a variant that requires no fairness hyperparameter tuning, achieved through post-pruning a tree constructed without fairness constraints. Extensive experiments on both real-world and synthetic datasets demonstrate that our method not only delivers competitive clustering performance and improved fairness, but also offers additional advantages such as interpretability and the ability to handle multiple sensitive attributes. These strengths enable our method to perform robustly under complex fairness constraints, opening new possibilities for equitable and transparent clustering.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u89e3\u91ca\u4e14\u516c\u5e73\u7684\u805a\u7c7b\u6846\u67b6\uff0c\u5c06\u516c\u5e73\u7ea6\u675f\u5d4c\u5165\u51b3\u7b56\u6811\u7ed3\u6784\uff0c\u5e76\u63d0\u4f9b\u65e0\u516c\u5e73\u8d85\u53c2\u6570\u7684\u540e\u526a\u679d\u53d8\u4f53\uff0c\u5b9e\u9a8c\u8868\u660e\u5728\u516c\u5e73\u6027\u3001\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5177\u6709\u7ade\u4e89\u529b\uff0c\u4e14\u80fd\u5904\u7406\u591a\u654f\u611f\u5c5e\u6027\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\uff0c\u73b0\u6709\u516c\u5e73\u805a\u7c7b\u5f80\u5f80\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u96be\u4ee5\u7406\u89e3\u805a\u7c7b\u51b3\u7b56\u80cc\u540e\u7684\u516c\u5e73\u4e0e\u5426\u539f\u56e0\uff0c\u56e0\u6b64\u9700\u8981\u517c\u5177\u53ef\u89e3\u91ca\u6027\u4e0e\u516c\u5e73\u6027\u7684\u805a\u7c7b\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5c06\u516c\u5e73\u7ea6\u675f\u5d4c\u5165\u51b3\u7b56\u6811\u7684\u7ed3\u6784\uff0c\u6784\u9020\u53ef\u89e3\u91ca\u7684\u805a\u7c7b\u6811\uff1b\u5e76\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u516c\u5e73\u8d85\u53c2\u6570\u7684\u53d8\u4f53\uff0c\u901a\u8fc7\u5bf9\u4e0d\u5305\u542b\u516c\u5e73\u7ea6\u675f\u7684\u6811\u8fdb\u884c\u540e\u526a\u679d\u5b9e\u73b0\u516c\u5e73\u5316\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\uff0c\u65b9\u6cd5\u5728\u805a\u7c7b\u6027\u80fd\u4e0e\u516c\u5e73\u6027\u65b9\u9762\u5177\u7ade\u4e89\u529b\uff0c\u4e14\u5177\u6709\u826f\u597d\u53ef\u89e3\u91ca\u6027\uff0c\u80fd\u5904\u7406\u591a\u654f\u611f\u5c5e\u6027\uff0c\u9002\u5e94\u590d\u6742\u516c\u5e73\u7ea6\u675f\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u516c\u5e73\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u7ed3\u5408\uff0c\u4e3a\u516c\u5e73\u900f\u660e\u7684\u805a\u7c7b\u63d0\u4f9b\u65b0\u7684\u8def\u5f84\uff0c\u6269\u5c55\u4e86\u5728\u591a\u654f\u611f\u5c5e\u6027\u573a\u666f\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.21118", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21118", "abs": "https://arxiv.org/abs/2511.21118", "authors": ["Pius Onobhayedo", "Paul Osemudiame Oamen"], "title": "Trustless Federated Learning at Edge-Scale: A Compositional Architecture for Decentralized, Verifiable, and Incentive-Aligned Coordination", "comment": null, "summary": "Artificial intelligence is retracing the Internet's path from centralized provision to distributed creation. Initially, resource-intensive computation concentrates within institutions capable of training and serving large models.Eventually, as federated learning matures, billions of edge devices holding sensitive data will be able to collectively improve models without surrendering raw information, enabling both contribution and consumption at scale. This democratic vision remains unrealized due to certain compositional gaps; aggregators handle updates without accountability, economic mechanisms are lacking and even when present remain vulnerable to gaming, coordination serializes state modifications limiting scalability, and governance permits retroactive manipulation. This work addresses these gaps by leveraging cryptographic receipts to prove aggregation correctness, geometric novelty measurement to prevent incentive gaming, parallel object ownership to achieve linear scalability, and time-locked policies to check retroactive manipulation.", "AI": {"tldr": "\u63d0\u51fa\u901a\u8fc7\u5bc6\u7801\u5b66\u51ed\u8bc1\u3001\u51e0\u4f55\u65b0\u9896\u6027\u5ea6\u91cf\u3001\u5e76\u884c\u5bf9\u8c61\u6240\u6709\u6743\u548c\u65f6\u95f4\u9501\u7b56\u7565\u7b49\u673a\u5236\uff0c\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u3001\u6fc0\u52b1\u3001\u6cbb\u7406\u7b49\u75db\u70b9\uff0c\u6784\u5efa\u53ef\u5ba1\u8ba1\u3001\u65e0\u539f\u59cb\u6570\u636e\u6cc4\u9732\u7684\u5206\u5e03\u5f0fAI\u6846\u67b6\u3002", "motivation": "\u5c06AI\u8ba1\u7b97\u4ece\u4e2d\u5fc3\u5316\u63d0\u4f9b\u8005\u5411\u5206\u5e03\u5f0f\u8fb9\u7f18\u8bbe\u5907\u8f6c\u79fb\uff0c\u5229\u7528\u5206\u5e03\u5f0f\u6570\u636e\u63d0\u5347\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u4e0e\u6570\u636e\u6240\u6709\u6743\uff0c\u8ffd\u6c42\u53ef\u6269\u5c55\u4e14\u53ef\u6cbb\u7406\u7684\u6c11\u4e3b\u5316AI\u3002", "method": "\u63d0\u51fa\u56db\u4e2a\u673a\u5236\uff1a1) \u4f7f\u7528\u5bc6\u7801\u5b66\u51ed\u8bc1\u8bc1\u660e\u805a\u5408\u6b63\u786e\u6027\uff1b2) \u4f7f\u7528\u51e0\u4f55\u65b0\u9896\u6027\u5ea6\u91cf\u9632\u6b62\u6fc0\u52b1\u64cd\u7eb5\uff1b3) \u901a\u8fc7\u5e76\u884c\u5bf9\u8c61\u6240\u6709\u6743\u5b9e\u73b0\u7ebf\u6027\u53ef\u6269\u5c55\u6027\uff1b4) \u91c7\u7528\u65f6\u95f4\u9501\u7b56\u7565\u9632\u6b62\u4e8b\u540e\u64cd\u63a7\u3002", "result": "\u7ed9\u51fa\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u4e0e\u67b6\u6784\u84dd\u56fe\uff0c\u9010\u4e00\u7ed9\u51fa\u5404\u673a\u5236\u7684\u5b89\u5168\u6027\u3001\u53ef\u6269\u5c55\u6027\u53ca\u6cbb\u7406\u7279\u6027\uff0c\u63d0\u4f9b\u5f62\u5f0f\u5316\u7684\u6b63\u786e\u6027\u4e0e\u6027\u80fd\u8ba8\u8bba\uff0c\u4f46\u5c1a\u7f3a\u4e4f\u5b9e\u8bc1\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c06\u5206\u5e03\u5f0f\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u8054\u90a6\u5b66\u4e60\u62c9\u8fd1\u73b0\u5b9e\uff0c\u901a\u8fc7\u6574\u5408\u5bc6\u7801\u5b66\u3001\u6fc0\u52b1\u8bbe\u8ba1\u4e0e\u6cbb\u7406\u673a\u5236\u6765\u586b\u8865\u73b0\u6709\u7684\u7ec4\u6210\u6f0f\u6d1e\uff0c\u6307\u660e\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e0e\u5b9e\u73b0\u8def\u5f84\u3002"}}
{"id": "2511.21120", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21120", "abs": "https://arxiv.org/abs/2511.21120", "authors": ["Mengran Li", "Zelin Zang", "Wenbin Xing", "Junzhou Chen", "Ronghui Zhang", "Jiebo Luo", "Stan Z. Li"], "title": "Learning Cell-Aware Hierarchical Multi-Modal Representations for Robust Molecular Modeling", "comment": "Accepted to AAAI 2026 (Oral)", "summary": "Understanding how chemical perturbations propagate through biological systems is essential for robust molecular property prediction. While most existing methods focus on chemical structures alone, recent advances highlight the crucial role of cellular responses such as morphology and gene expression in shaping drug effects. However, current cell-aware approaches face two key limitations: (1) modality incompleteness in external biological data, and (2) insufficient modeling of hierarchical dependencies across molecular, cellular, and genomic levels. We propose CHMR (Cell-aware Hierarchical Multi-modal Representations), a robust framework that jointly models local-global dependencies between molecules and cellular responses and captures latent biological hierarchies via a novel tree-structured vector quantization module. Evaluated on nine public benchmarks spanning 728 tasks, CHMR outperforms state-of-the-art baselines, yielding average improvements of 3.6% on classification and 17.2% on regression tasks. These results demonstrate the advantage of hierarchy-aware, multimodal learning for reliable and biologically grounded molecular representations, offering a generalizable framework for integrative biomedical modeling. The code is in https://github.com/limengran98/CHMR.", "AI": {"tldr": "CHMR \u63d0\u51fa\u4e00\u4e2a\u9762\u5411\u7ec6\u80de\u7684\u5c42\u7ea7\u591a\u6a21\u6001\u8868\u793a\u6846\u67b6\uff0c\u5c06\u5206\u5b50\u4e0e\u7ec6\u80de\u53cd\u5e94\u8fdb\u884c\u5c40\u90e8-\u5168\u5c40\u5efa\u6a21\uff0c\u5e76\u901a\u8fc7\u6811\u7ed3\u6784\u5411\u91cf\u91cf\u5316\u6355\u6349\u6f5c\u5728\u751f\u7269\u5c42\u7ea7\uff0c\u5728\u4e5d\u4e2a\u516c\u5f00\u57fa\u51c6\u7684\u5206\u7c7b\u4e0e\u56de\u5f52\u4efb\u52a1\u4e0a\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u591a\u5173\u6ce8\u5316\u5b66\u7ed3\u6784\uff0c\u5ffd\u7565\u7ec6\u80de\u8868\u578b\u4e0e\u57fa\u56e0\u8868\u8fbe\u7b49\u54cd\u5e94\u4fe1\u606f\uff1b\u5e76\u4e14\u5b58\u5728\u6a21\u6001\u4e0d\u5b8c\u6574\u6027\u548c\u672a\u5145\u5206\u5efa\u6a21\u5206\u5b50-\u7ec6\u80de-\u57fa\u56e0\u5c42\u7ea7\u4f9d\u8d56\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa CHMR\uff0c\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u5206\u5b50\u4e0e\u7ec6\u80de\u54cd\u5e94\u7684\u5c40\u90e8\u4e0e\u5168\u5c40\u4f9d\u8d56\uff0c\u540c\u65f6\u5f15\u5165\u6811\u7ed3\u6784\u5411\u91cf\u91cf\u5316\u6a21\u5757\u6765\u6355\u6349\u9690\u542b\u7684\u751f\u7269\u5c42\u7ea7\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u5c42\u7ea7\u8868\u793a\u5b66\u4e60\u3002", "result": "\u5728\u4e5d\u4e2a\u516c\u5f00\u57fa\u51c6\u3001\u5171728\u4e2a\u4efb\u52a1\u4e0a\u8bc4\u4f30\uff0cCHMR \u76f8\u6bd4\u57fa\u7ebf\u5728\u5206\u7c7b\u4efb\u52a1\u5e73\u5747\u63d0\u5347 3.6%\uff0c\u5728\u56de\u5f52\u4efb\u52a1\u5e73\u5747\u63d0\u5347 17.2%\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5c42\u7ea7\u611f\u77e5\u7684\u591a\u6a21\u6001\u5b66\u4e60\u80fd\u591f\u83b7\u5f97\u66f4\u751f\u7269\u5b66\u5408\u7406\u7684\u5206\u5b50\u8868\u5f81\uff0cCHMR\u63d0\u4f9b\u4e00\u4e2a\u53ef\u6cdb\u5316\u7684\u751f\u7269\u533b\u5b66\u6574\u5408\u5efa\u6a21\u6846\u67b6\u3002"}}
{"id": "2511.21140", "categories": ["cs.LG", "cs.CL", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.21140", "abs": "https://arxiv.org/abs/2511.21140", "authors": ["Chungpa Lee", "Thomas Zeng", "Jongwon Jeong", "Jy-yong Sohn", "Kangwook Lee"], "title": "How to Correctly Report LLM-as-a-Judge Evaluations", "comment": null, "summary": "Large language models (LLMs) are increasingly used as evaluators in lieu of humans. While scalable, their judgments are noisy due to imperfect specificity and sensitivity of LLMs, leading to biased accuracy estimates. Although bias-correction methods exist, they are underutilized in LLM research and typically assume exact knowledge of the model's specificity and sensitivity. Furthermore, in general we only have estimates of these values and it is not well known how to properly construct confidence intervals using only estimates. This work presents a simple plug-in framework that corrects such bias and constructs confidence intervals reflecting uncertainty from both test and calibration dataset, enabling practical and statistically sound LLM-based evaluation. Additionally, to reduce uncertainty in the accuracy estimate, we introduce an adaptive algorithm that efficiently allocates calibration sample sizes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u63d2\u5165\u5f0f\uff08plug-in\uff09\u6846\u67b6\uff0c\u7528\u4ee5\u6821\u6b63LLM\u8bc4\u4f30\u4e2d\u7684\u504f\u5dee\u5e76\u57fa\u4e8e\u6d4b\u8bd5\u96c6\u4e0e\u6821\u51c6\u96c6\u7684\u4e0d\u786e\u5b9a\u6027\u6784\u9020\u7f6e\u4fe1\u533a\u95f4\uff0c\u540c\u65f6\u901a\u8fc7\u81ea\u9002\u5e94\u65b9\u6cd5\u5206\u914d\u6821\u51c6\u6837\u672c\u91cf\u4ee5\u964d\u4f4e\u65b9\u5dee\u3002", "motivation": "LLMs\u4f5c\u4e3a\u8bc4\u4f30\u8005\u53ef\u6269\u5c55\uff0c\u4f46\u7531\u4e8e\u7279\u5f02\u6027\u548c\u654f\u611f\u6027\u4e0d\u7a33\u5b9a\uff0c\u5bfc\u81f4\u8bc4\u4f30\u7ed3\u679c\u504f\u501a\u4e14\u7f6e\u4fe1\u533a\u95f4\u4e0d\u53ef\u9760\uff1b\u73b0\u6709\u504f\u5dee\u6821\u6b63\u591a\u5047\u8bbe\u77e5\u9053\u6a21\u578b\u7684\u7279\u5f02\u6027/\u654f\u611f\u6027\uff0c\u5b9e\u9645\u53ea\u5f97\u4f30\u8ba1\u503c\uff0c\u9700\u8981\u5728\u4ec5\u6709\u4f30\u8ba1\u503c\u7684\u60c5\u51b5\u4e0b\u6784\u9020\u542b\u4e0d\u786e\u5b9a\u6027\u7684\u7f6e\u4fe1\u533a\u95f4\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7b80\u5355\u7684plug-in\u6846\u67b6\uff0c\u4f7f\u7528\u6d4b\u8bd5\u6570\u636e\u548c\u6821\u51c6\u6570\u636e\u7684\u89c2\u5bdf\u7ed3\u679c\u6765\u4f30\u8ba1\u548c\u6821\u6b63\u6a21\u578b\u7684\u504f\u5dee\uff0c\u6784\u9020\u53cd\u6620\u6765\u81ea\u6d4b\u8bd5\u96c6\u548c\u6821\u51c6\u96c6\u7684\u4e0d\u786e\u5b9a\u6027\u7684\u7f6e\u4fe1\u533a\u95f4\uff1b\u5e76\u63d0\u51fa\u81ea\u9002\u5e94\u7b97\u6cd5\uff0c\u5728\u7ed9\u5b9a\u9884\u7b97\u4e0b\u9ad8\u6548\u5206\u914d\u6821\u51c6\u6837\u672c\u91cf\u4ee5\u964d\u4f4e\u4f30\u8ba1\u65b9\u5dee\u3002", "result": "\u6846\u67b6\u5b9e\u73b0\u540e\uff0c\u5f97\u5230\u66f4\u65e0\u504f\u7684\u51c6\u786e\u7387\u4f30\u8ba1\u5e76\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u4e14\u81ea\u9002\u5e94\u5206\u914d\u65b9\u6cd5\u5728\u8282\u7701\u6837\u672c\u7684\u540c\u65f6\u63d0\u9ad8\u4f30\u8ba1\u6548\u7387\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4f7fLLM-based\u8bc4\u4f30\u66f4\u5b9e\u7528\u4e14\u7edf\u8ba1\u5b66\u610f\u4e49\u66f4\u5f3a\uff0c\u56e0\u4e3a\u5b83\u540c\u65f6\u5904\u7406\u6765\u81ea\u6d4b\u8bd5\u4e0e\u6821\u51c6\u6570\u636e\u7684\u4e0d\u786e\u5b9a\u6027\u5e76\u4f18\u5316\u6837\u672c\u5206\u914d\u3002"}}
{"id": "2511.21208", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21208", "abs": "https://arxiv.org/abs/2511.21208", "authors": ["Lucas Thil", "Jesse Read", "Rim Kaddah", "Guillaume Doquet"], "title": "I-GLIDE: Input Groups for Latent Health Indicators in Degradation Estimation", "comment": "Included in the conference series: Joint European Conference on Machine Learning and Knowledge Discovery in Databases", "summary": "Accurate remaining useful life (RUL) prediction hinges on the quality of health indicators (HIs), yet existing methods often fail to disentangle complex degradation mechanisms in multi-sensor systems or quantify uncertainty in HI reliability. This paper introduces a novel framework for HI construction, advancing three key contributions. First, we adapt Reconstruction along Projected Pathways (RaPP) as a health indicator (HI) for RUL prediction for the first time, showing that it outperforms traditional reconstruction error metrics. Second, we show that augmenting RaPP-derived HIs with aleatoric and epistemic uncertainty quantification (UQ) via Monte Carlo dropout and probabilistic latent spaces- significantly improves RUL-prediction robustness. Third, and most critically, we propose indicator groups, a paradigm that isolates sensor subsets to model system-specific degradations, giving rise to our novel method, I-GLIDE which enables interpretable, mechanism-specific diagnostics. Evaluated on data sourced from aerospace and manufacturing systems, our approach achieves marked improvements in accuracy and generalizability compared to state-of-the-art HI methods while providing actionable insights into system failure pathways. This work bridges the gap between anomaly detection and prognostics, offering a principled framework for uncertainty-aware degradation modeling in complex systems.", "AI": {"tldr": "\u5c06 RaPP \u4f5c\u4e3a\u5065\u5eb7\u6307\u6807\u7528\u4e8e\u5269\u4f59\u4f7f\u7528\u5bff\u547d\uff08RUL\uff09\u9884\u6d4b\uff0c\u7ed3\u5408\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u4e0e\u6307\u793a\u5668\u7ec4\uff08I-GLIDE\uff09\u5b9e\u73b0\u53ef\u89e3\u91ca\u3001\u673a\u5236\u7279\u5f02\u7684\u8bca\u65ad\uff0c\u5728\u822a\u7a7a\u4e0e\u5236\u9020\u6570\u636e\u4e0a\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\u4e0e\u6cdb\u5316\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u4f20\u611f\u7cfb\u7edf\u4e2d\u96be\u4ee5\u5206\u79bb\u590d\u6742\u7684\u9000\u5316\u673a\u5236\u4e14\u96be\u4ee5\u91cf\u5316\u5065\u5eb7\u6307\u6807\u7684\u53ef\u9760\u6027\u4e0d\u786e\u5b9a\u6027\uff0c\u4e9f\u9700\u4e00\u4e2a\u9c81\u68d2\u4e14\u5177\u89e3\u91ca\u6027\u7684 HI \u6784\u5efa\u6846\u67b6\u6765\u63d0\u5347 RUL \u9884\u6d4b\u53ca\u6545\u969c\u8def\u5f84\u6d1e\u5bdf\u3002", "method": "1) \u5c06 Reconstruction along Projected Pathways (RaPP) \u4f5c\u4e3a RUL \u9884\u6d4b\u7684\u5065\u5eb7\u6307\u6807\uff1b2) \u4f7f\u7528\u8499\u7279\u5361\u6d1b dropout \u4e0e\u6982\u7387\u6f5c\u53d8\u91cf\u7a7a\u95f4\u5bf9 RaPP \u4ea7\u751f\u7684 HI \u8fdb\u884c aleatoric \u4e0e epistemic \u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff1b3) \u63d0\u51fa indicator groups\uff0c isolating \u4e0d\u540c\u4f20\u611f\u5b50\u96c6\u4ee5\u5efa\u6a21\u7cfb\u7edf\u7279\u5b9a\u7684\u9000\u5316\uff0c\u8fdb\u800c\u63d0\u51fa I-GLIDE \u7684\u53ef\u89e3\u91ca\u3001\u673a\u5236\u7279\u5f02\u8bca\u65ad\u3002", "result": "\u5728\u822a\u7a7a\u822a\u5929\u4e0e\u5236\u9020\u9886\u57df\u7684\u6570\u636e\u4e0a\uff0c\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\u7684 HI \u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u51c6\u786e\u6027\u4e0e\u6cdb\u5316\u6027\uff0c\u5e76\u7ed9\u51fa\u7cfb\u7edf\u6545\u969c\u8def\u5f84\u7684\u53ef\u64cd\u4f5c\u6d1e\u5bdf\uff0c\u63d0\u51fa\u4e86\u4ece\u5f02\u5e38\u68c0\u6d4b\u5230\u9884\u6d4b\u6027\u7ef4\u62a4\u7684\u7edf\u4e00\u6846\u67b6\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e00\u4e2a\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u590d\u6742\u7cfb\u7edf\u964d\u89e3\u5efa\u6a21\u6846\u67b6\uff0c\u5f25\u5408\u5f02\u5e38\u68c0\u6d4b\u4e0e prognostics \u7684\u5dee\u8ddd\uff0c\u63d0\u5347\u5bf9\u591a\u4f20\u611f\u7cfb\u7edf\u7684\u673a\u5236\u7ea7\u8bca\u65ad\u80fd\u529b\u3002"}}
{"id": "2511.21211", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21211", "abs": "https://arxiv.org/abs/2511.21211", "authors": ["Rub\u00e9n Fern\u00e1ndez-Farelo", "Jorge Paz-Ruza", "Bertha Guijarro-Berdi\u00f1as", "Amparo Alonso-Betanzos", "Alex A. Freitas"], "title": "Robust Gene Prioritization via Fast-mRMR Feature Selection in high-dimensional omics data", "comment": null, "summary": "Gene prioritization (identifying genes potentially associated with a biological process) is increasingly tackled with Artificial Intelligence. However, existing methods struggle with the high dimensionality and incomplete labelling of biomedical data. This work proposes a more robust and efficient pipeline that leverages Fast-mRMR feature selection to retain only relevant, non-redundant features for classifiers. This enables us to build simpler and more effective models, as well as to combine different biological feature sets. Experiments on Dietary Restriction datasets show significant improvements over existing methods, proving that feature selection can be critical for reliable gene prioritization.", "AI": {"tldr": "\u5229\u7528 Fast-mRMR \u7684\u7279\u5f81\u9009\u62e9\u6765\u5904\u7406\u9ad8\u7ef4\u3001\u6807\u6ce8\u4e0d\u8db3\u7684\u751f\u7269\u6570\u636e\uff0c\u4ece\u800c\u6784\u5efa\u66f4\u7b80\u5316\u3001\u6709\u6548\u7684\u57fa\u56e0\u4f18\u5148\u6392\u5e8f\u5206\u7c7b\u6a21\u578b\uff0c\u5e76\u80fd\u6574\u5408\u591a\u6e90\u7279\u5f81\u96c6\u3002", "motivation": "Biological\u6570\u636e\u901a\u5e38\u9ad8\u7ef4\u4e14\u6807\u6ce8\u7a00\u7f3a\uff0c\u73b0\u6709\u65b9\u6cd5\u6613\u53d7\u5197\u4f59\u7279\u5f81\u548c\u7f3a\u5931\u6807\u7b7e\u7684\u5f71\u54cd\uff0c\u4e9f\u9700\u66f4\u9c81\u68d2\u7684\u7279\u5f81\u9009\u62e9\u6765\u63d0\u5347\u57fa\u56e0\u4f18\u5148\u6392\u5e8f\u7684\u7a33\u5b9a\u6027\u4e0e\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u9c81\u68d2\u9ad8\u6548\u7684\u5de5\u4f5c\u6d41\uff0c\u5c06 Fast-mRMR \u7279\u5f81\u9009\u62e9\u5e94\u7528\u4e8e\u57fa\u56e0\u4f18\u5148\u6392\u5e8f\u4efb\u52a1\uff0c\u4ec5\u4fdd\u7559\u76f8\u5173\u4e14\u975e\u5197\u4f59\u7684\u7279\u5f81\u4ee5\u4f9b\u5206\u7c7b\u5668\u4f7f\u7528\uff0c\u5e76\u652f\u6301\u6574\u5408\u4e0d\u540c\u751f\u7269\u7279\u5f81\u96c6\u4ee5\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002", "result": "\u5728\u996e\u98df\u9650\u5236\uff08Dietary Restriction\uff09\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8868\u660e\u7279\u5f81\u9009\u62e9\u5bf9\u5b9e\u73b0\u53ef\u9760\u7684\u57fa\u56e0\u4f18\u5148\u6392\u5e8f\u5177\u6709\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u7279\u5f81\u9009\u62e9\u662f\u5b9e\u73b0\u7b80\u5316\u3001\u53ef\u89e3\u91ca\u4e14\u66f4\u53ef\u9760\u7684\u57fa\u56e0\u4f18\u5148\u6392\u5e8f\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u6240\u63d0\u51fa\u7684\u7ba1\u7ebf\u8fd8\u80fd\u6709\u6548\u878d\u5408\u591a\u6e90\u751f\u7269\u7279\u5f81\u4ee5\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.21276", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21276", "abs": "https://arxiv.org/abs/2511.21276", "authors": ["Sutirtha Biswas", "Kshitij Kumar Yadav"], "title": "A Physics-Informed U-net-LSTM Network for Data-Driven Seismic Response Modeling of Structures", "comment": null, "summary": "Accurate and efficient seismic response prediction is essential for the design of resilient structures. While the Finite Element Method (FEM) remains the standard for nonlinear seismic analysis, its high computational demands limit its scalability and real time applicability. Recent developments in deep learning, particularly Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Long Short Term Memory (LSTM) models, have shown promise in reducing the computational cost of nonlinear seismic analysis of structures. However, these data driven models often struggle to generalize and capture the underlying physics, leading to reduced reliability. We propose a novel Physics Informed U Net LSTM framework that integrates physical laws with deep learning to enhance both accuracy and efficiency. By embedding domain specific constraints into the learning process, the proposed model achieves improved predictive performance over conventional Machine Learning architectures. This hybrid approach bridges the gap between purely data driven methods and physics based modeling, offering a robust and computationally efficient alternative for seismic response prediction of structures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7269\u7406\u4fe1\u606f\u7ea6\u675f\u7684 U-Net-LSTM \u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u5730\u9707\u54cd\u5e94\u9884\u6d4b\uff0c\u663e\u8457\u5728\u7cbe\u5ea6\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "motivation": "FEM \u867d\u7136\u51c6\u786e\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u7eaf\u6570\u636e\u9a71\u52a8\u6a21\u578b\u5728\u7269\u7406\u4e00\u81f4\u6027\u4e0e\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u4e00\u79cd\u5c06\u7269\u7406\u89c4\u5f8b\u878d\u5165\u6df1\u5ea6\u5b66\u4e60\u7684\u6df7\u5408\u65b9\u6cd5\u3002", "method": "\u5c06\u7269\u7406\u7ea6\u675f\u5d4c\u5165\u5230 U-Net \u4e0e LSTM \u7684\u8054\u5408\u6846\u67b6\u4e2d\uff0c\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u8026\u5408\u7684\u635f\u5931\u3001\u786c\u7ea6\u675f\u6216\u6b63\u5219\u5316\uff0c\u5b9e\u73b0\u5bf9\u7ed3\u6784\u975e\u7ebf\u6027\u5730\u9707\u54cd\u5e94\u7684\u9884\u6d4b\uff0c\u8bad\u7ec3\u6570\u636e\u53ef\u80fd\u6765\u81ea\u6570\u503c\u4eff\u771f\u5e76\u8f85\u4ee5\u7269\u7406\u635f\u5931\u3002", "result": "\u76f8\u8f83\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u9884\u6d4b\u7cbe\u5ea6\u4e0e\u6cdb\u5316\u6027\u65b9\u9762\u6709\u6240\u63d0\u9ad8\uff0c\u540c\u65f6\u4fdd\u6301\u6bd4\u7eaf\u6570\u503c FEM \u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u5177\u5907\u6f5c\u5728\u7684\u5b9e\u65f6\u5e94\u7528\u80fd\u529b\u3002", "conclusion": "\u7269\u7406\u4fe1\u606f\u9a71\u52a8\u7684 U-Net-LSTM \u6846\u67b6\u586b\u8865\u4e86\u6570\u636e\u9a71\u52a8\u4e0e\u57fa\u4e8e\u7269\u7406\u5efa\u6a21\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9c81\u68d2\u3001\u9ad8\u6548\u7684\u5730\u9707\u54cd\u5e94\u9884\u6d4b\u65b9\u6848\uff0c\u672a\u6765\u53ef\u6269\u5c55\u5230\u66f4\u590d\u6742\u7684\u975e\u7ebf\u6027\u884c\u4e3a\u4e0e\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u3002"}}
{"id": "2511.21320", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21320", "abs": "https://arxiv.org/abs/2511.21320", "authors": ["Heiko Oppel", "Andreas Spilz", "Michael Munz"], "title": "Sawtooth Sampling for Time Series Denoising Diffusion Implicit Models", "comment": null, "summary": "Denoising Diffusion Probabilistic Models (DDPMs) can generate synthetic timeseries data to help improve the performance of a classifier, but their sampling process is computationally expensive. We address this by combining implicit diffusion models with a novel Sawtooth Sampler that accelerates the reverse process and can be applied to any pretrained diffusion model. Our approach achieves a 30 times speed-up over the standard baseline while also enhancing the quality of the generated sequences for classification tasks.", "AI": {"tldr": "\u7ed3\u5408\u9690\u5f0f\u6269\u6563\u6a21\u578b\u4e0e\u952f\u9f7f\u91c7\u6837\u5668\u4ee5\u52a0\u901f DDPM \u7684\u9006\u6269\u6563\u8fc7\u7a0b\uff0c\u540c\u65f6\u63d0\u5347\u751f\u6210\u5e8f\u5217\u7684\u5206\u7c7b\u6027\u80fd\uff0c\u8fbe\u5230\u7ea6 30 \u500d\u63d0\u901f\u5e76\u63d0\u5347\u8d28\u91cf\u3002", "motivation": "DDPM \u7684\u91c7\u6837\u8fc7\u7a0b\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u8feb\u5207\u9700\u8981\u66f4\u5feb\u3001\u7ef4\u6301\u6216\u63d0\u5347\u751f\u6210\u8d28\u91cf\u7684\u91c7\u6837\u65b9\u6cd5\u4ee5\u7528\u4e8e\u63d0\u5347\u5206\u7c7b\u5668\u6027\u80fd\u3002", "method": "\u5c06\u9690\u5f0f\u6269\u6563\u6a21\u578b\u4e0e\u65b0\u9896\u7684 Sawtooth Sampler \u7ed3\u5408\uff0c\u53ef\u5e94\u7528\u4e8e\u4efb\u4f55\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\uff0c\u5feb\u901f\u8fd1\u4f3c\u9006\u8fc7\u7a0b\u3002", "result": "\u5b9e\u73b0\u76f8\u8f83\u6807\u51c6\u57fa\u7ebf\u7ea6 30\u00d7\u7684\u52a0\u901f\uff0c\u540c\u65f6\u63d0\u9ad8\u751f\u6210\u5e8f\u5217\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8d28\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6269\u6563\u6a21\u578b\u7684\u9ad8\u6548\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u52a0\u901f\u5668\uff0c\u5e2e\u52a9\u5728\u5206\u7c7b\u573a\u666f\u4e2d\u66f4\u6709\u6548\u5730\u5229\u7528\u5408\u6210\u6570\u636e\u3002"}}
{"id": "2511.21338", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21338", "abs": "https://arxiv.org/abs/2511.21338", "authors": ["Julianna Piskorz", "Cristina Pinneri", "Alvaro Correia", "Motasem Alfarra", "Risheek Garrepalli", "Christos Louizos"], "title": "Masks Can Be Distracting: On Context Comprehension in Diffusion Language Models", "comment": null, "summary": "Masked Diffusion Language Models (MDLMs) have recently emerged as a promising alternative to Autoregressive Language Models (ARLMs), leveraging a denoising objective that, in principle, should enable more uniform context utilisation. In this work, we examine the context comprehension abilities of MDLMs and uncover two key limitations. First, despite their more global training objective and bidirectional attention mechanism, similarly to ARLMS, MDLMs exhibit a strong locality bias: performance is highly sensitive to the position of relevant information within the input, favouring local over distant context. Second, we show that appending a large number of mask tokens--required for generation--can significantly degrade context comprehension. Through systematic ablations, we find that these masks act as distractors, reducing the model's ability to process relevant information. To address this, we introduce a mask-agnostic loss function that encourages predictions to remain invariant to the number of appended masks. Fine-tuning with this objective substantially mitigates the distracting effect of masks, improving robustness of MDLMs. Overall, our findings reveal critical limitations of the current MDLM training paradigm and provide actionable insights for building diffusion-based language models with stronger context comprehension.", "AI": {"tldr": "MDLMs show strong locality bias and mask-induced distractor effects that harm context understanding; a mask-agnostic loss with fine-tuning considerably improves robustness.", "motivation": "To systematically evaluate the context comprehension of MDLMs and identify fundamental limitations in their ability to utilize distant information, as well as the adverse impact of appended mask tokens during generation.", "method": "Perform ablation studies varying the position of relevant information, test generation with many appended masks, and introduce a mask-agnostic loss; fine-tune MDLMs with this objective to assess robustness.", "result": "Mask-agnostic fine-tuning reduces the disruptive effect of masks and enhances context comprehension, yielding more robust MDLM performance.", "conclusion": "Current MDLM training paradigms have critical limitations; incorporating mask-insensitive objectives is a practical way to strengthen diffusion-based language models' context understanding."}}
{"id": "2511.21354", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21354", "abs": "https://arxiv.org/abs/2511.21354", "authors": ["Umberto Michelucci", "Francesca Venturini"], "title": "Best Practices for Machine Learning Experimentation in Scientific Applications", "comment": null, "summary": "Machine learning (ML) is increasingly adopted in scientific research, yet the quality and reliability of results often depend on how experiments are designed and documented. Poor baselines, inconsistent preprocessing, or insufficient validation can lead to misleading conclusions about model performance. This paper presents a practical and structured guide for conducting ML experiments in scientific applications, focussing on reproducibility, fair comparison, and transparent reporting. We outline a step-by-step workflow, from dataset preparation to model selection and evaluation, and propose metrics that account for overfitting and instability across validation folds, including the Logarithmic Overfitting Ratio (LOR) and the Composite Overfitting Score (COS). Through recommended practices and example reporting formats, this work aims to support researchers in establishing robust baselines and drawing valid evidence-based insights from ML models applied to scientific problems.", "AI": {"tldr": "\u63d0\u4f9b\u4e00\u4e2a\u9762\u5411\u79d1\u5b66\u5e94\u7528\u7684\u5b9e\u7528ML\u5b9e\u9a8c\u6307\u5357\uff0c\u5f3a\u8c03\u53ef\u91cd\u590d\u6027\u3001\u516c\u5e73\u6bd4\u8f83\u4e0e\u900f\u660e\u62a5\u544a\uff1b\u63d0\u51faLOR\u548cCOS\u7b49\u65b0\u5ea6\u91cf\uff0c\u7528\u4ee5\u8bc4\u4f30\u8de8\u9a8c\u8bc1\u6298\u7684\u8fc7\u62df\u5408\u4e0e\u4e0d\u7a33\u5b9a\u6027\u3002", "motivation": "\u4e3a\u89e3\u51b3\u79d1\u5b66\u7814\u7a76\u4e2dML\u7ed3\u679c\u7684\u8d28\u91cf\u4e0e\u53ef\u9760\u6027\u95ee\u9898\uff08\u5982\u57fa\u7ebf\u8584\u5f31\u3001\u9884\u5904\u7406\u4e0d\u4e00\u81f4\u3001\u9a8c\u8bc1\u4e0d\u8db3\u7b49\uff09\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u548c\u65b0\u8bc4\u4f30\u6307\u6807\u63d0\u5347\u8bc1\u636e\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u63d0\u51fa\u4ece\u6570\u636e\u96c6\u51c6\u5907\u5230\u6a21\u578b\u9009\u62e9\u548c\u8bc4\u4f30\u7684\u9010\u6b65\u5de5\u4f5c\u6d41\uff0c\u7ed3\u5408\u53ef\u91cd\u590d\u7684\u57fa\u7ebf\u3001\u5b9e\u9a8c\u8bb0\u5f55\u3001\u4ee5\u53ca\u5bf9\u8fc7\u62df\u5408/\u4e0d\u7a33\u5b9a\u6027\u8fdb\u884c\u8861\u91cf\u7684\u65b0\u5ea6\u91cf\uff08LOR\u3001COS\uff09\uff0c\u5e76\u63d0\u4f9b\u793a\u4f8b\u62a5\u544a\u683c\u5f0f\u548c\u5b9e\u8df5\u5efa\u8bae\u3002", "result": "\u7ed9\u51fa\u4e00\u4e2a\u53ef\u64cd\u4f5c\u7684\u7814\u7a76\u6846\u67b6\u4e0e\u6307\u6807\u96c6\u5408\uff0c\u5e2e\u52a9\u7814\u7a76\u8005\u5efa\u7acb\u7a33\u5065\u57fa\u7ebf\u5e76\u4ea7\u751f\u53ef\u518d\u73b0\u4e14\u53ef\u6bd4\u8f83\u7684\u7ed3\u8bba\uff1b\u672a\u7ed9\u51fa\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\uff0c\u800c\u662f\u63d0\u4f9b\u6307\u5357\u4e0e\u683c\u5f0f\u3002", "conclusion": "\u82e5\u91c7\u7528\u8be5\u6307\u5357\uff0c\u53ef\u4ee5\u63d0\u5347\u79d1\u5b66ML\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\u3001\u516c\u5e73\u6027\u548c\u900f\u660e\u5ea6\uff0c\u589e\u5f3a\u5bf9\u6a21\u578b\u5728\u79d1\u5b66\u95ee\u9898\u4e0a\u7684\u8bc1\u636e\u6027\u7ed3\u8bba\u3002"}}
{"id": "2511.21356", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21356", "abs": "https://arxiv.org/abs/2511.21356", "authors": ["Bram Silue", "Santiago Amaya-Corredor", "Patrick Mannion", "Lander Willem", "Pieter Libin"], "title": "Hybrid-AIRL: Enhancing Inverse Reinforcement Learning with Supervised Expert Guidance", "comment": "Comments: 13 pages, 5 figures, 1 table. Code: https://github.com/silue-dev/hairl. Submitted to ESANN 2026", "summary": "Adversarial Inverse Reinforcement Learning (AIRL) has shown promise in addressing the sparse reward problem in reinforcement learning (RL) by inferring dense reward functions from expert demonstrations. However, its performance in highly complex, imperfect-information settings remains largely unexplored. To explore this gap, we evaluate AIRL in the context of Heads-Up Limit Hold'em (HULHE) poker, a domain characterized by sparse, delayed rewards and significant uncertainty. In this setting, we find that AIRL struggles to infer a sufficiently informative reward function. To overcome this limitation, we contribute Hybrid-AIRL (H-AIRL), an extension that enhances reward inference and policy learning by incorporating a supervised loss derived from expert data and a stochastic regularization mechanism. We evaluate H-AIRL on a carefully selected set of Gymnasium benchmarks and the HULHE poker setting. Additionally, we analyze the learned reward function through visualization to gain deeper insights into the learning process. Our experimental results show that H-AIRL achieves higher sample efficiency and more stable learning compared to AIRL. This highlights the benefits of incorporating supervised signals into inverse RL and establishes H-AIRL as a promising framework for tackling challenging, real-world settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u9006\u5f3a\u5316\u5b66\u4e60\u6846\u67b6H-AIRL\uff0c\u901a\u8fc7\u52a0\u5165\u6765\u81ea\u4e13\u5bb6\u6570\u636e\u7684\u76d1\u7763\u635f\u5931\u4e0e\u968f\u673a\u6b63\u5219\u5316\uff0c\u63d0\u5347\u5728\u7a00\u758f\u5956\u52b1\u548c\u590d\u6742\u4e0d\u5b8c\u5907\u4fe1\u606f\u73af\u5883\u4e2d\u7684\u5956\u52b1\u63a8\u65ad\u4e0e\u7b56\u7565\u5b66\u4e60\uff1b\u5728Gymnasium\u57fa\u51c6\u548cHULHE\u6251\u514b\u4e0a\u4f18\u4e8e\u539f\u59cbAIRL\u3002", "motivation": "\u89e3\u51b3AIRL\u5728\u9ad8\u5ea6\u590d\u6742\u3001\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u7684\u4efb\u52a1\u4e2d\u96be\u4ee5\u5b66\u4e60\u6709\u6548\u5956\u52b1\u51fd\u6570\u7684\u95ee\u9898\uff0c\u5c24\u5176\u5728\u7a00\u758f\u3001\u5ef6\u8fdf\u5956\u52b1\u573a\u666f\u5982\u6251\u514b\u9886\u57df\u3002", "method": "\u5728AIRL\u57fa\u7840\u4e0a\u5f15\u5165\u76d1\u7763\u635f\u5931\u548c\u968f\u673a\u6b63\u5219\u5316\uff0c\u5f62\u6210Hybrid-AIRL\uff1b\u5bf9Gymnasium\u57fa\u51c6\u4e0eHULHE\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7\u5956\u52b1\u51fd\u6570\u53ef\u89c6\u5316\u5206\u6790\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "H-AIRL\u5728\u6837\u672c\u6548\u7387\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u4f18\u4e8eAIRL\uff0c\u5b9e\u9a8c\u7ed3\u679c\u652f\u6301\u5c06\u76d1\u7763\u4fe1\u53f7\u878d\u5165\u9006\u5f3a\u5316\u5b66\u4e60\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5c06\u76d1\u7763\u4fe1\u53f7\u878d\u5165\u9006\u5f3a\u5316\u5b66\u4e60\u53ef\u63d0\u5347\u5728\u73b0\u5b9e\u6311\u6218\u6027\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0cH-AIRL\u4e3a\u6b64\u7c7b\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2511.21363", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21363", "abs": "https://arxiv.org/abs/2511.21363", "authors": ["Kevin Iselborn", "David Dembinsky", "Adriano Lucieri", "Andreas Dengel"], "title": "The Directed Prediction Change - Efficient and Trustworthy Fidelity Assessment for Local Feature Attribution Methods", "comment": "13 pages, 10 figures, 5 tables, accepted at AAAI SECURE-AI4H workshop", "summary": "The utility of an explanation method critically depends on its fidelity to the underlying machine learning model. Especially in high-stakes medical settings, clinicians and regulators require explanations that faithfully reflect the model's decision process. Existing fidelity metrics such as Infidelity rely on Monte Carlo approximation, which demands numerous model evaluations and introduces uncertainty due to random sampling. This work proposes a novel metric for evaluating the fidelity of local feature attribution methods by modifying the existing Prediction Change (PC) metric within the Guided Perturbation Experiment. By incorporating the direction of both perturbation and attribution, the proposed Directed Prediction Change (DPC) metric achieves an almost tenfold speedup and eliminates randomness, resulting in a deterministic and trustworthy evaluation procedure that measures the same property as local Infidelity. DPC is evaluated on two datasets (skin lesion images and financial tabular data), two black-box models, seven explanation algorithms, and a wide range of hyperparameters. Across $4\\,744$ distinct explanations, the results demonstrate that DPC, together with PC, enables a holistic and computationally efficient evaluation of both baseline-oriented and local feature attribution methods, while providing deterministic and reproducible outcomes.", "AI": {"tldr": "\u63d0\u51fa\u4e86 Directed Prediction Change (DPC) \u6307\u6807\uff0c\u7528\u4ee5\u8bc4\u4f30\u5c40\u90e8\u7279\u5f81\u5c5e\u6027\u65b9\u6cd5\u7684\u4fdd\u771f\u5ea6\u3002\u901a\u8fc7\u5728 Guided Perturbation Experiment \u4e2d\u7ed3\u5408\u6270\u52a8\u65b9\u5411\u548c\u5c5e\u6027\u65b9\u5411\uff0c\u5b9e\u73b0\u5927\u7ea6\u5341\u500d\u52a0\u901f\u4e14\u5224\u5b9a\u6027\uff0c\u907f\u514d\u968f\u673a\u6027\uff1b\u5728\u76ae\u80a4\u75c5\u53d8\u56fe\u50cf\u3001\u91d1\u878d\u8868\u683c\u6570\u636e\u7684\u4e24\u7c7b\u9ed1\u7bb1\u6a21\u578b\u3001\u4e03\u79cd\u89e3\u91ca\u7b97\u6cd5\u30014,744 \u6761\u89e3\u91ca\u7b49\u5e7f\u6cdb\u8bbe\u7f6e\u4e0b\uff0c\u5c55\u793a DPC \u4e0e PC \u5171\u540c\u63d0\u4f9b\u9ad8\u6548\u3001\u53ef\u91cd\u590d\u7684\u4fdd\u771f\u5ea6\u8bc4\u4f30\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u533b\u7597\u573a\u666f\u4e2d\uff0c\u89e3\u91ca\u65b9\u6cd5\u7684\u4fdd\u771f\u5ea6\u76f4\u63a5\u5f71\u54cd\u4e34\u5e8a\u548c\u76d1\u7ba1\u4fe1\u4efb\u3002\u73b0\u6709\u7684\u4fdd\u771f\u5ea6\u5ea6\u91cf\uff08\u5982 Infidelity\uff09\u4f9d\u8d56\u8499\u7279\u5361\u7f57\u91c7\u6837\uff0c\u9700\u5927\u91cf\u6a21\u578b\u8bc4\u4f30\u4e14\u5f15\u5165\u968f\u673a\u6027\uff0c\u4e0d\u5229\u4e8e\u53ef\u91cd\u590d\u3001\u786e\u5b9a\u6027\u7684\u8bc4\u4f30\u3002\u9700\u8981\u4e00\u79cd\u4e0e\u5c40\u90e8 Infidelity \u540c\u7b49\u6d4b\u91cf\u76ee\u6807\u3001\u4e14\u66f4\u9ad8\u6548\u3001\u65e0\u968f\u673a\u6027\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5728 Guided Perturbation Experiment \u7684\u57fa\u7840\u4e0a\uff0c\u6539\u8fdb Prediction Change (PC) \u6307\u6807\uff0c\u52a0\u5165\u6270\u52a8\u65b9\u5411\u4e0e\u5c5e\u6027\u65b9\u5411\u7684\u4e00\u81f4\u6027\uff0c\u63d0\u51fa Directed Prediction Change (DPC) \u6307\u6807\uff0c\u4f7f\u8bc4\u4f30\u8fc7\u7a0b\u5177\u786e\u5b9a\u6027\u5e76\u63d0\u5347\u901f\u5ea6\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u65b9\u5411\u4e00\u81f4\u6027\u6d88\u9664\u968f\u673a\u6027\uff0c\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u4e24\u7c7b\u6570\u636e\u96c6\uff08\u76ae\u80a4\u75c5\u53d8\u56fe\u50cf\u4e0e\u91d1\u878d\u8868\u683c\u6570\u636e\uff09\u3001\u4e24\u79cd\u9ed1\u7bb1\u6a21\u578b\u3001\u4e03\u79cd\u89e3\u91ca\u7b97\u6cd5\u3001\u4ee5\u53ca\u5927\u91cf\u8d85\u53c2\u6570\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5171\u8986\u76d64,744\u6761\u89e3\u91ca\u3002\u7ed3\u679c\u663e\u793a\uff0cDPC \u4e0e PC \u7ed3\u5408\u63d0\u4f9b\u5bf9\u57fa\u7ebf\u5bfc\u5411\u4e0e\u5c40\u90e8\u7279\u5f81\u5c5e\u6027\u65b9\u6cd5\u7684\u5168\u9762\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u4fdd\u771f\u5ea6\u8bc4\u4f30\uff0c\u4e14\u8f93\u51fa\u5177\u6709\u786e\u5b9a\u6027\u3001\u53ef\u91cd\u590d\u6027\u3002\u5927\u7ea6\u5b9e\u73b0\u4e86\u5341\u500d\u7684\u52a0\u901f\u5e76\u6d88\u9664\u4e86\u968f\u673a\u6027\u3002", "conclusion": "DPC \u53ef\u4f5c\u4e3a\u5c40\u90e8\u89e3\u91ca\u4fdd\u771f\u5ea6\u8bc4\u4f30\u7684\u9ad8\u6548\u3001\u786e\u5b9a\u6027\u66ff\u4ee3\u6216\u8865\u5145\uff0c\u4e0e PC \u4e00\u540c\u63a8\u52a8\u5bf9\u89e3\u91ca\u65b9\u6cd5\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u9ad8\u53ef\u91cd\u590d\u6027\u7684\u573a\u666f\u4e2d\uff0c\u5bf9\u591a\u7b97\u6cd5\u548c\u591a\u8d85\u53c2\u6570\u8bbe\u7f6e\u5177\u6709\u7a33\u5065\u6027\u3002"}}
{"id": "2511.21378", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21378", "abs": "https://arxiv.org/abs/2511.21378", "authors": ["Jungi Lee", "Jungkwon Kim", "Chi Zhang", "Kwangsun Yoo", "Seok-Joo Byun"], "title": "Anomaly Detection with Adaptive and Aggressive Rejection for Contaminated Training Data", "comment": null, "summary": "Handling contaminated data poses a critical challenge in anomaly detection, as traditional models assume training on purely normal data. Conventional methods mitigate contamination by relying on fixed contamination ratios, but discrepancies between assumed and actual ratios can severely degrade performance, especially in noisy environments where normal and abnormal data distributions overlap. To address these limitations, we propose Adaptive and Aggressive Rejection (AAR), a novel method that dynamically excludes anomalies using a modified z-score and Gaussian mixture model-based thresholds. AAR effectively balances the trade-off between preserving normal data and excluding anomalies by integrating hard and soft rejection strategies. Extensive experiments on two image datasets and thirty tabular datasets demonstrate that AAR outperforms the state-of-the-art method by 0.041 AUROC. By providing a scalable and reliable solution, AAR enhances robustness against contaminated datasets, paving the way for broader real-world applications in domains such as security and healthcare.", "AI": {"tldr": "AAR: \u81ea\u9002\u5e94\u5f3a/\u8f6f\u62d2\u7edd\uff0c\u57fa\u4e8e\u4fee\u6b63z-score\u548c\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u9608\u503c\uff0c\u5728\u6c61\u67d3\u6570\u636e\u4e0b\u9c81\u68d2\u5730\u6392\u9664\u5f02\u5e38\uff0c\u5e73\u8861\u4fdd\u7559\u6b63\u5e38\u6570\u636e\u4e0e\u5254\u9664\u5f02\u5e38\uff1b\u5728\u4e24\u7c7b\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u53470.041 AUROC\u3002", "motivation": "\u8bad\u7ec3\u6570\u636e\u88ab\u6c61\u67d3\uff0c\u8bef\u5dee\u6bd4\u7387\u5047\u8bbe\u4e0d\u51c6\u786e\uff0c\u6b63\u5e38\u548c\u5f02\u5e38\u5206\u5e03\u5728\u5608\u6742\u73af\u5883\u4e2d\u91cd\u53e0\uff0c\u9700\u81ea\u9002\u5e94\u53bb\u9664\u5f02\u5e38\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165 Adaptive and Aggressive Rejection\uff0c\u7ed3\u5408\u4fee\u6b63z-score\u4e0e\u57fa\u4e8eGMM\u7684\u9608\u503c\uff0c\u786c/\u8f6f\u62d2\u7edd\u76f8\u7ed3\u5408\u5b9e\u73b0\u52a8\u6001\u6392\u9664\u5f02\u5e38\u3002", "result": "\u5728\u4e24\u7c7b\u6570\u636e\u96c6\uff08\u4e24\u5f20\u56fe\u7247\u6570\u636e\u96c6\u4e0e30\u4e2a\u8868\u683c\u6570\u636e\u96c6\uff1f\u539f\u6587\u8bf4\u4e24 image datasets and thirty tabular datasets\uff09\u4e0a\uff0cAAR\u76f8\u8f83SOTA\u63d0\u53470.041 AUROC\u3002", "conclusion": "AAR\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6539\u5584\u6c61\u67d3\u6570\u636e\u4e0b\u7684\u5f02\u5e38\u68c0\u6d4b\uff0c\u9002\u7528\u4e8e\u5b89\u5168\u3001\u533b\u7597\u7b49\u5b9e\u9645\u9886\u57df\u3002"}}
{"id": "2511.21381", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21381", "abs": "https://arxiv.org/abs/2511.21381", "authors": ["Ariful Islam", "Md Rifat Hossen", "Abir Ahmed", "B M Taslimul Haque"], "title": "BanglaASTE: A Novel Framework for Aspect-Sentiment-Opinion Extraction in Bangla E-commerce Reviews Using Ensemble Deep Learning", "comment": "Presented at the 2025 IEEE International Conference on Signal Processing, Information, Communication and Systems (SPICSCON), November 21-22, 2025, University of Rajshahi, Bangladesh. 6 pages, ensemble deep learning, 3,345 annotated Bangla product reviews", "summary": "Aspect-Based Sentiment Analysis (ABSA) has emerged as a critical tool for extracting fine-grained sentiment insights from user-generated content, particularly in e-commerce and social media domains. However, research on Bangla ABSA remains significantly underexplored due to the absence of comprehensive datasets and specialized frameworks for triplet extraction in this language. This paper introduces BanglaASTE, a novel framework for Aspect Sentiment Triplet Extraction (ASTE) that simultaneously identifies aspect terms, opinion expressions, and sentiment polarities from Bangla product reviews. Our contributions include: (1) creation of the first annotated Bangla ASTE dataset containing 3,345 product reviews collected from major e-commerce platforms including Daraz, Facebook, and Rokomari; (2) development of a hybrid classification framework that employs graph-based aspect-opinion matching with semantic similarity techniques; and (3) implementation of an ensemble model combining BanglaBERT contextual embeddings with XGBoost boosting algorithms for enhanced triplet extraction performance. Experimental results demonstrate that our ensemble approach achieves superior performance with 89.9% accuracy and 89.1% F1-score, significantly outperforming baseline models across all evaluation metrics. The framework effectively addresses key challenges in Bangla text processing including informal expressions, spelling variations, and data sparsity. This research advances the state-of-the-art in low-resource language sentiment analysis and provides a scalable solution for Bangla e-commerce analytics applications.", "AI": {"tldr": " BanglaASTE\uff1a\u9996\u4e2a Bangla ASTE \u6846\u67b6\uff0c\u5305\u542b\u6570\u636e\u96c6\u548c\u6df7\u5408\u6a21\u578b\uff0c\u8fbe\u5230\u9ad8\u4e8e\u57fa\u7ebf\u7684 Triplet \u63d0\u53d6\u6027\u80fd\u3002", "motivation": "\u5f25\u8865 Bangla \u8bed\u8a00\u4e0b ABSA/ASTE \u7684\u7814\u7a76\u7a7a\u767d\uff0c\u7f3a\u4e4f\u6570\u636e\u96c6\u548c\u4e13\u95e8\u7684\u4e09\u5143\u7ec4\u63d0\u53d6\u6846\u67b6\uff0c\u9650\u5236\u4e86 Bangla \u7535\u5546\u60c5\u611f\u5206\u6790\u7684\u53d1\u5c55\u3002", "method": "\u6784\u5efa\u5305\u542b 3,345 \u6761 Bangla \u4ea7\u54c1\u8bc4\u4ef7\u7684\u6570\u636e\u96c6\uff1b\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u65b9\u9762-\u610f\u89c1\u5339\u914d\u53ca\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u6df7\u5408\u5206\u7c7b\u6846\u67b6\uff1b\u7ed3\u5408 BanglaBERT \u8868\u5f81\u4e0e XGBoost \u7684\u96c6\u6210\u6a21\u578b\u6765\u63d0\u5347 triplet \u63d0\u53d6\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u96c6\u6210\u65b9\u6cd5\u8fbe\u5230 89.9% \u7684\u51c6\u786e\u7387\u4e0e 89.1% \u7684 F1 \u5206\u6570\uff0c\u5728\u6240\u6709\u8bc4\u6d4b\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u63a8\u52a8\u4f4e\u8d44\u6e90\u8bed\u8a00\u60c5\u611f\u5206\u6790\u7684\u7814\u7a76\u524d\u6cbf\uff0c\u4e3a Bangla \u7535\u5546\u5206\u6790\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u6709\u6548\u5e94\u5bf9 Bangla \u6587\u672c\u7684\u975e\u89c4\u8303\u8868\u8fbe\u3001\u62fc\u5199\u53d8\u4f53\u4e0e\u6570\u636e\u7a00\u758f\u7b49\u6311\u6218\u3002"}}
{"id": "2511.21465", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21465", "abs": "https://arxiv.org/abs/2511.21465", "authors": ["Enes Bektas", "Fazli Can"], "title": "Ensemble Performance Through the Lens of Linear Independence of Classifier Votes in Data Streams", "comment": "14 pages, 3 figures, 5 tables", "summary": "Ensemble learning improves classification performance by combining multiple base classifiers. While increasing the number of classifiers generally enhances accuracy, excessively large ensembles can lead to computational inefficiency and diminishing returns. This paper investigates the relationship between ensemble size and performance through the lens of linear independence among classifier votes in data streams. We propose that ensembles composed of linearly independent classifiers maximize representational capacity, particularly under a geometric model. We then generalize the importance of linear independence to the weighted majority voting problem. By modeling the probability of achieving linear independence among classifier outputs, we derive a theoretical framework that explains the trade-off between ensemble size and accuracy. Our analysis leads to a theoretical estimate of the ensemble size required to achieve a user-specified probability of linear independence. We validate our theory through experiments on both real-world and synthetic datasets using two ensemble methods, OzaBagging and GOOWE. Our results confirm that this theoretical estimate effectively identifies the point of performance saturation for robust ensembles like OzaBagging. Conversely, for complex weighting schemes like GOOWE, our framework reveals that high theoretical diversity can trigger algorithmic instability. Our implementation is publicly available to support reproducibility and future research.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.21466", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.21466", "abs": "https://arxiv.org/abs/2511.21466", "authors": ["William De Deyn", "Michael Herty", "Giovanni Samaey"], "title": "Mean-Field Limits for Two-Layer Neural Networks Trained with Consensus-Based Optimization", "comment": null, "summary": "We study two-layer neural networks and train these with a particle-based method called consensus-based optimization (CBO). We compare the performance of CBO against Adam on two test cases and demonstrate how a hybrid approach, combining CBO with Adam, provides faster convergence than CBO. In the context of multi-task learning, we recast CBO into a formulation that offers less memory overhead. The CBO method allows for a mean-field limit formulation, which we couple with the mean-field limit of the neural network. To this end, we first reformulate CBO within the optimal transport framework. Finally, in the limit of infinitely many particles, we define the corresponding dynamics on the Wasserstein-over-Wasserstein space and show that the variance decreases monotonically.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.21513", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21513", "abs": "https://arxiv.org/abs/2511.21513", "authors": ["Wanli Zhong", "Haibo Feng", "Zirui Zhou", "Hanyang Peng", "Shiqi Yu"], "title": "IntAttention: A Fully Integer Attention Pipeline for Efficient Edge Inference", "comment": null, "summary": "Deploying Transformer models on edge devices is limited by latency and energy budgets. While INT8 quantization effectively accelerates the primary matrix multiplications, it exposes the softmax as the dominant bottleneck. This stage incurs a costly dequantize-softmax-requantize detour, which can account for up to 65% of total attention latency and disrupts the end-to-end integer dataflow critical for edge hardware efficiency. To address this limitation, we present IntAttention, the first fully integer, plug-and-play attention pipeline without retraining. At the core of our approach lies IndexSoftmax, a hardware-friendly operator that replaces floating-point exponentials entirely within the integer domain. IntAttention integrates sparsity-aware clipping, a 32-entry lookup-table approximation, and direct integer normalization, thereby eliminating all datatype conversion overhead. We evaluate IntAttention and demonstrate consistent and substantial gains. Our method achieves up to 3.7x speedup and 61% energy reduction over FP16 baselines and 2.0x faster than conventional INT8 attention pipelines on Armv8 CPUs. These gains are achieved with high-fidelity accuracy comparable to baselines across diverse language and vision models, enabling practical and efficient Transformer inference on commodity edge devices. Code will be released in later version of this work.", "AI": {"tldr": "\u63d0\u51faIntAttention\uff1a\u7b2c\u4e00\u6b3e\u5b8c\u5168\u9762\u6574\u6570\u91cf\u5316\u7684\u6ce8\u610f\u529b\u7ba1\u7ebf\uff0c\u89e3\u51b3INT8\u6ce8\u610f\u529b\u4e2dsoftmax\u7684\u74f6\u9888\uff0c\u5229\u7528IndexSoftmax\u7b49\u5728\u6574\u6570\u57df\u5185\u66ff\u4ee3\u6307\u6570\u8fd0\u7b97\uff0c\u8fbe\u5230\u663e\u8457\u52a0\u901f\u4e0e\u80fd\u8017\u4e0b\u964d\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "motivation": "\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72Transformer\u65f6\uff0c\u5ef6\u8fdf\u548c\u80fd\u8017\u6210\u4e3a\u74f6\u9888\u3002\u5c3d\u7ba1INT8\u80fd\u52a0\u901f\u4e3b\u77e9\u9635\u4e58\u6cd5\uff0c\u4f46softmax\u9636\u6bb5\u5f15\u5165\u53bb\u91cf\u5316-\u8f6f\u5316/\u518d\u91cf\u5316\u7684\u5f00\u9500\uff0c\u4e14\u4f1a\u7834\u574f\u7aef\u5230\u7aef\u6574\u6570\u6570\u636e\u6d41\u7684\u6548\u7387\uff0c\u56e0\u6b64\u9700\u8981\u5728\u6574\u6570\u57df\u5185\u5b9e\u73b0\u5168\u6d41\u7a0b\u6ce8\u610f\u529b\uff0c\u4ee5\u964d\u4f4e\u6570\u636e\u8f6c\u6362\u6210\u672c\u5e76\u63d0\u5347\u786c\u4ef6\u53cb\u597d\u6027\u3002", "method": "\u63d0\u51faIntAttention\uff0c\u8fd9\u662f\u4e00\u79cd\u5b8c\u5168\u6574\u6570\u3001\u5373\u63d2\u5373\u7528\u7684\u6ce8\u610f\u529b\u6d41\u6c34\u7ebf\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002\u6838\u5fc3\u662fIndexSoftmax\u8fd9\u4e00\u786c\u4ef6\u53cb\u597d\u7b97\u5b50\uff0c\u5b8c\u5168\u5728\u6574\u6570\u57df\u5185\u66ff\u4ee3\u6d6e\u70b9\u6307\u6570\u8fd0\u7b97\uff1b\u5e76\u7ed3\u5408\u7a00\u758f\u6027\u88c1\u526a\u300132\u6761\u67e5\u627e\u8868\u8fd1\u4f3c\u548c\u76f4\u63a5\u6574\u6570\u5f52\u4e00\u5316\uff0c\u4ee5\u6d88\u9664\u6240\u6709\u6570\u636e\u7c7b\u578b\u8f6c\u6362\u5f00\u9500\u3002", "result": "\u5728\u4e0eFP16\u57fa\u7ebf\u7684\u5bf9\u6bd4\u4e2d\uff0cIntAttention\u5b9e\u73b0\u6700\u9ad83.7x\u52a0\u901f\u300161%\u80fd\u8017\u4e0b\u964d\uff1b\u76f8\u8f83\u4f20\u7edfINT8\u6ce8\u610f\u529b\u7ba1\u7ebf\uff0c\u5728Armv8 CPU\u4e0a\u901f\u5ea6\u63d0\u5347\u7ea62\u500d\uff1b\u5728\u591a\u9886\u57df\u8bed\u8a00\u4e0e\u89c6\u89c9\u6a21\u578b\u4e0a\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\u3002", "conclusion": "IntAttention\u4f7f\u5728\u666e\u901a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9ad8\u6548\u3001\u65e0\u518d\u8bad\u7ec3\u9700\u6c42\u7684Transformer\u63a8\u7406\u6210\u4e3a\u53ef\u80fd\uff0c\u5b8c\u5168\u6d88\u9664\u4e86softmax\u4e2d\u7684\u6d6e\u70b9\u8fd0\u7b97\u53ca\u53bb/Requantize\u7684\u6210\u672c\uff0c\u672a\u6765\u7248\u672c\u5c06\u53d1\u5e03\u4ee3\u7801\u3002"}}
{"id": "2511.21514", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21514", "abs": "https://arxiv.org/abs/2511.21514", "authors": ["Mat\u012bss Kaln\u0101re", "Sofoklis Kitharidis", "Thomas B\u00e4ck", "Niki van Stein"], "title": "Mechanistic Interpretability for Transformer-based Time Series Classification", "comment": null, "summary": "Transformer-based models have become state-of-the-art tools in various machine learning tasks, including time series classification, yet their complexity makes understanding their internal decision-making challenging. Existing explainability methods often focus on input-output attributions, leaving the internal mechanisms largely opaque. This paper addresses this gap by adapting various Mechanistic Interpretability techniques; activation patching, attention saliency, and sparse autoencoders, from NLP to transformer architectures designed explicitly for time series classification. We systematically probe the internal causal roles of individual attention heads and timesteps, revealing causal structures within these models. Through experimentation on a benchmark time series dataset, we construct causal graphs illustrating how information propagates internally, highlighting key attention heads and temporal positions driving correct classifications. Additionally, we demonstrate the potential of sparse autoencoders for uncovering interpretable latent features. Our findings provide both methodological contributions to transformer interpretability and novel insights into the functional mechanics underlying transformer performance in time series classification tasks.", "AI": {"tldr": "\u5c06 NLP \u4e2d\u7684\u673a\u5236\u53ef\u89e3\u91ca\u6027\u6280\u672f\u8fc1\u79fb\u5230\u4e13\u4e3a\u65f6\u95f4\u5e8f\u5217\u8bbe\u8ba1\u7684\u53d8\u6362\u5668\uff0c\u5e76\u63ed\u793a\u5185\u90e8\u56e0\u679c\u7ed3\u6784\u4e0e\u53ef\u89e3\u91ca\u7684\u6f5c\u5728\u7279\u5f81\u3002", "motivation": "\u5c3d\u7ba1\u53d8\u6362\u5668\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4e0a\u53d6\u5f97\u4e86\u9ad8\u6027\u80fd\uff0c\u4f46\u5176\u5185\u90e8\u51b3\u7b56\u8fc7\u7a0b\u7f3a\u4e4f\u6e05\u6670\u7406\u89e3\uff0c\u73b0\u6709\u89e3\u91ca\u591a\u805a\u7126\u8f93\u5165-\u8f93\u51fa\u5c5e\u6027\uff0c\u5ffd\u7565\u6a21\u578b\u5185\u90e8\u673a\u5236\u3002", "method": "\u5c06\u6fc0\u6d3b\u8865\u4e01\u3001\u6ce8\u610f\u529b\u663e\u8457\u6027\u4ee5\u53ca\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7b49\u673a\u5236\u89e3\u91ca\u6280\u672f\u5e94\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217 Transformer\uff1b\u7cfb\u7edf\u6027\u5730\u63a2\u67e5\u5355\u4e2a\u6ce8\u610f\u5934\u548c\u65f6\u95f4\u6b65\u7684\u56e0\u679c\u4f5c\u7528\uff0c\u6784\u5efa\u5185\u90e8\u4fe1\u606f\u4f20\u64ad\u7684\u56e0\u679c\u56fe\uff0c\u5e76\u5c55\u793a\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7528\u4e8e\u53d1\u73b0\u53ef\u89e3\u91ca\u7684\u6f5c\u5728\u7279\u5f81\u3002", "result": "\u5728\u57fa\u51c6\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\u63ed\u793a\u5f71\u54cd\u6b63\u786e\u5206\u7c7b\u7684\u5173\u952e\u6ce8\u610f\u5934\u4e0e\u65f6\u95f4\u4f4d\u7f6e\uff0c\u5f62\u6210\u53ef\u89e3\u91ca\u7684\u56e0\u679c\u56fe\uff1b\u7a00\u758f\u81ea\u7f16\u7801\u5668\u80fd\u591f\u63d0\u53d6\u53ef\u89e3\u91ca\u7684\u6f5c\u5728\u7279\u5f81\uff0c\u663e\u793a\u65b9\u6cd5\u5b66\u4e0a\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u5728 Transformer \u53ef\u89e3\u91ca\u6027\u65b9\u9762\u63d0\u4f9b\u65b0\u65b9\u6cd5\u5b66\u8d21\u732e\uff0c\u5e76\u4e3a\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u53d8\u6362\u5668\u5de5\u4f5c\u673a\u5236\u63d0\u4f9b\u6df1\u5165\u6d1e\u5bdf\u3002"}}
{"id": "2511.21537", "categories": ["cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.21537", "abs": "https://arxiv.org/abs/2511.21537", "authors": ["Martin Rabel", "Jakob Runge"], "title": "Context-Specific Causal Graph Discovery with Unobserved Contexts: Non-Stationarity, Regimes and Spatio-Temporal Patterns", "comment": null, "summary": "Real-world data, for example in climate applications, often consists of spatially gridded time series data or data with comparable structure. While the underlying system is often believed to behave similar at different points in space and time, those variations that do exist are twofold relevant: They often encode important information in and of themselves. And they may negatively affect the stability / convergence and reliability\\Slash{}validity of results of algorithms assuming stationarity or space-translation invariance. We study the information encoded in changes of the causal graph, with stability in mind. An analysis of this general task identifies two core challenges. We develop guiding principles to overcome these challenges, and provide a framework realizing these principles by modifying constraint-based causal discovery approaches on the level of independence testing. This leads to an extremely modular, easily extensible and widely applicable framework. It can leverage existing constraint-based causal discovery methods (demonstrated on IID-algorithms PC, PC-stable, FCI and time series algorithms PCMCI, PCMCI+, LPCMCI) with little to no modification. The built-in modularity allows to systematically understand and improve upon an entire array of subproblems. By design, it can be extended by leveraging insights from change-point-detection, clustering, independence-testing and other well-studied related problems. The division into more accessible sub-problems also simplifies the understanding of fundamental limitations, hyperparameters controlling trade-offs and the statistical interpretation of results. An open-source implementation will be available soon.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u4fee\u6539\u72ec\u7acb\u6027\u68c0\u9a8c\u5c42\u9762\u7684\u7ea6\u675f\u57fa\u56e0\u56e0\u679c\u53d1\u73b0\uff0c\u5904\u7406\u8de8\u65f6\u7a7a\u975e\u5e73\u7a33\u6027\u5bf9\u56e0\u679c\u56fe\u63a8\u65ad\u7684\u5f71\u54cd\uff0c\u5e76\u80fd\u65e0\u7f1d\u5bf9\u63a5\u73b0\u6709\u65b9\u6cd5\uff08\u5982PC\u3001FCI\u3001PCMCI\u7b49\uff09\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u65f6\u7a7a\u6570\u636e\u5f80\u5f80\u8fdd\u80cc\u5e73\u7a33\u6027\u548c\u7a7a\u95f4\u5e73\u79fb\u4e0d\u53d8\u6027\uff0c\u800c\u8fd9\u4e9b\u53d8\u5316\u65e2\u5305\u542b\u91cd\u8981\u4fe1\u606f\uff0c\u4e5f\u53ef\u80fd\u524a\u5f31\u4f20\u7edf\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\u3002\u7814\u7a76\u805a\u7126\u4e8e\u5bf9\u56e0\u679c\u56fe\u53d8\u5316\u7684\u4fe1\u606f\u8fdb\u884c\u5206\u6790\u4e0e\u7a33\u5065\u6027\u63d0\u5347\u3002", "method": "\u5728\u72ec\u7acb\u6027\u68c0\u9a8c\u5c42\u9762\u4fee\u6539\u7ea6\u675f\u57fa\u56e0\u53d1\u73b0\u6846\u67b6\uff0c\u5f62\u6210\u9ad8\u5ea6\u6a21\u5757\u5316\u7684\u6846\u67b6\uff0c\u80fd\u591f\u4e0e\u73b0\u6709\u7684IID\u548c\u65f6\u5e8f\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\uff08\u5982PC\u3001PC-stable\u3001FCI\u3001PCMCI\u3001PCMCI+\u3001LPCMCI\uff09\u65e0\u7f1d\u5bf9\u63a5\uff0c\u4e26\u5f15\u5165\u4e0e\u53d8\u70b9\u68c0\u6d4b\u3001\u805a\u7c7b\u3001\u72ec\u7acb\u6027\u68c0\u9a8c\u7b49\u76f8\u5173\u7684\u5b50\u95ee\u9898\u89e3\u51b3\u601d\u8def\u3002", "result": "\u6846\u67b6\u5177\u6709\u6781\u9ad8\u7684\u6a21\u5757\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u80fd\u591f\u7cfb\u7edf\u5730\u7406\u89e3\u5e76\u6539\u8fdb\u4e00\u7cfb\u5217\u5b50\u95ee\u9898\uff1b\u4fbf\u4e8e\u7ed3\u5408\u53d8\u70b9\u68c0\u6d4b\u3001\u805a\u7c7b\u7b49\u65b9\u6cd5\u63d0\u5347\u975e\u5e73\u7a33\u573a\u666f\u4e0b\u7684\u56e0\u679c\u53d1\u73b0\u6548\u679c\uff1b\u8fd8\u4e3a\u8d85\u53c2\u6570\u4e0e\u7edf\u8ba1\u89e3\u91ca\u63d0\u4f9b\u6e05\u6670\u7684\u6846\u67b6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5728\u975e\u5e73\u7a33\u65f6\u7a7a\u6570\u636e\u80cc\u666f\u4e0b\u7684\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u7814\u7a76\u8def\u7ebf\u56fe\uff0c\u5398\u6e05\u4e86\u57fa\u672c\u9650\u5236\u4e0e trade-off \u7684\u7edf\u8ba1\u542b\u4e49\uff0c\u672a\u6765\u5c06\u4ee5\u5f00\u6e90\u5b9e\u73b0\u8fdb\u4e00\u6b65\u843d\u5730\u3002"}}
{"id": "2511.21566", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21566", "abs": "https://arxiv.org/abs/2511.21566", "authors": ["Ali Amirahmadi", "G\u00f6k\u00e7e Geylan", "Leonardo De Maria", "Farzaneh Etminani", "Mattias Ohlsson", "Alessandro Tibo"], "title": "A decoupled alignment kernel for peptide membrane permeability predictions", "comment": "submitted to Journal of Cheminformatics", "summary": "Cyclic peptides are promising modalities for targeting intracellular sites; however, cell-membrane permeability remains a key bottleneck, exacerbated by limited public data and the need for well-calibrated uncertainty. Instead of relying on data-eager complex deep learning architecture, we propose a monomer-aware decoupled global alignment kernel (MD-GAK), which couples chemically meaningful residue-residue similarity with sequence alignment while decoupling local matches from gap penalties. MD-GAK is a relatively simple kernel. To further demonstrate the robustness of our framework, we also introduce a variant, PMD-GAK, which incorporates a triangular positional prior. As we will show in the experimental section, PMD-GAK can offer additional advantages over MD-GAK, particularly in reducing calibration errors. Since our focus is on uncertainty estimation, we use Gaussian Processes as the predictive model, as both MD-GAK and PMD-GAK can be directly applied within this framework. We demonstrate the effectiveness of our methods through an extensive set of experiments, comparing our fully reproducible approach against state-of-the-art models, and show that it outperforms them across all metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5355\u4f53\u611f\u77e5\u7684\u5168\u5c40\u6bd4\u5bf9\u6838 MD-GAK \u53ca\u5176\u5e26\u4e09\u89d2\u4f4d\u7f6e\u5148\u9a8c\u7684 PMD-GAK\uff0c\u7528\u4e8e\u5faa\u73af\u80bd\u7684\u6027\u8d28\u9884\u6d4b\uff0c\u5f3a\u8c03\u4e0d\u4f9d\u8d56\u590d\u6742\u6df1\u5ea6\u5b66\u4e60\u3001\u800c\u662f\u7ed3\u5408\u5316\u5b66\u76f8\u4f3c\u6027\u4e0e\u5e8f\u5217\u5bf9\u9f50\u7684\u7b80\u5355\u6838\u65b9\u6cd5\uff0c\u5e76\u5728\u9ad8\u65af\u8fc7\u7a0b\u6846\u67b6\u4e2d\u5b9e\u73b0\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5faa\u73af\u80bd\u8981\u7a7f\u900f\u7ec6\u80de\u819c\u3001\u6570\u636e\u6709\u9650\u4e14\u9700\u8981\u53ef\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\uff1b\u5e0c\u671b\u5728\u4e0d\u4f9d\u8d56\u5927\u89c4\u6a21\u6570\u636e\u7684\u524d\u63d0\u4e0b\u83b7\u5f97\u53ef\u9760\u9884\u6d4b\u5e76\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "method": "\u63d0\u51fa MD-GAK\uff0c\u8026\u5408\u6b8b\u57fa-\u6b8b\u57fa\u76f8\u4f3c\u6027\u4e0e\u5e8f\u5217\u5bf9\u9f50\uff0c\u540c\u65f6\u89e3\u8026\u5c40\u90e8\u5339\u914d\u4e0e\u7f3a\u53e3\u60e9\u7f5a\uff1b\u53e6\u6709\u5e26\u4e09\u89d2\u4f4d\u7f6e\u5148\u9a8c\u7684 PMD-GAK\uff1b\u5728\u9ad8\u65af\u8fc7\u7a0b\u6846\u67b6\u4e2d\u5e94\u7528\u8fd9\u4e24\u4e2a\u6838\u3002", "result": "\u5728\u5927\u91cf\u5b9e\u9a8c\u4e2d\uff0c\u4e0e\u6700\u5148\u8fdb\u6a21\u578b\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u6240\u6709\u6307\u6807\u4e0a\u5747\u8868\u73b0\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\uff1bPMD-GAK \u5728\u6821\u51c6\u8bef\u5dee\u65b9\u9762\u5177\u6709\u989d\u5916\u4f18\u52bf\u3002", "conclusion": "\u7b80\u5355\u4f46\u5177\u5316\u5b66\u610f\u4e49\u7684\u6838\u65b9\u6cd5\u53ef\u5728\u6709\u9650\u6570\u636e\u573a\u666f\u4e0b\u5b9e\u73b0\u51fa\u8272\u7684\u9884\u6d4b\u4e0e\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0cMD-GAK \u4e0e PMD-GAK \u4e3a\u5faa\u73af\u80bd\u6027\u8d28\u9884\u6d4b\u63d0\u4f9b\u6709\u6548\u5de5\u5177\u3002"}}
