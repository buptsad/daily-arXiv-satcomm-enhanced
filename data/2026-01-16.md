<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 29]
- [cs.CR](#cs.CR) [Total: 13]
- [cs.LG](#cs.LG) [Total: 56]
- [eess.SP](#eess.SP) [Total: 5]
- [cs.NI](#cs.NI) [Total: 1]
- [eess.SY](#eess.SY) [Total: 7]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [High signal-to-noise ratio asymptotics of entropy-constrained Gaussian channel capacity](https://arxiv.org/abs/2601.09864)
*Adway Girish,Shlomo Shamai,Emre Telatar*

Main category: cs.IT

TL;DR: 高SNR时，高斯信道的最佳输入是离散高斯，差距随SNR指数消失。


<details>
  <summary>Details</summary>
Motivation: 在高速率通信与功率速率耦合的实际系统中，了解熵约束下的容量极限及其实现方案，对高效编码与资源调度具有指导意义。

Method: 利用渐进高信噪比分析；推导容量上界与对应输入分布，证明离散高斯分布满足约束并达到极限；计算熵与容量差距指数并给出闭式表达。

Result: 1. 发现最优分布为以整数格点为支撑的离散高斯分布；2. 证明输入熵与容量之差随SNR指数衰减；3. 给出该指数的解析表达。

Conclusion: 在高信噪比下，满足输入熵约束的高斯信道容量最优分布为离散高斯分布，支持于一个缩放后的整点格点；随着信噪比的提升，输入熵与容量的差距以指数形式递减。

Abstract: We study the input-entropy-constrained Gaussian channel capacity problem in the asymptotic high signal-to-noise ratio (SNR) regime. We show that the capacity-achieving distribution as SNR goes to infinity is given by a discrete Gaussian distribution supported on a scaled integer lattice. Further, we show that the gap between the input entropy and the capacity decreases to zero exponentially in SNR, and characterize this exponent.

</details>


### [2] [One-Cold Poisson Channel: A Simple Continuous-Time Channel with Zero Dispersion](https://arxiv.org/abs/2601.09894)
*Cheuk Ting Li*

Main category: cs.IT

TL;DR: OCPC 通过仅衰减一个频段实现极简信道模型，完美版容量 1、零色散，拥有最简单的闭式误差概率，可作无限可分信息单位，支持前缀码推广，且在光通信等场景有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 寻找极简、可闭式求解的信道模型，提供基于无限可分信息的替代方案，并探讨其在可调带阻滤波的光通信等潜在应用。

Method: 提出 OCPC 架构：发送方在若干频段中一次仅衰减一个；对完美 OCPC 进行理论分析，推导容量、色散、误差概率和信息光谱。利用完美 OCPC 的反馈特性来推广前缀码。进一步研究一般 OCPC 的非渐近编码与信道模拟。

Result: 证明完美 OCPC 的容量为 1、零色散、信息光谱为常数 1 的偶分布；给出其最优非渐近误差概率的闭式公式；利用反馈产生新的前缀码框架；并给出一般 OCPC 的非渐近编码与信道仿真性能。

Conclusion: OCPC 是首个已知具有闭式最优非渐近误差概率的连续时无记忆信道，携誉为最简易信道；其完美版本容量为1，无通道色散，信息光谱为狄利克雷分布，且可作为无限可分信息单位代替比特。

Abstract: We introduce the one-cold Poisson channel (OCPC), where the transmitter chooses one of several frequency bands to attenuate at a time. In particular, the perfect OCPC, where the number of bands is unlimited, is an extremely simple continuous-time memoryless channel. It has a capacity 1, zero channel dispersion, and an information spectrum being the degenerate distribution at 1. It is the only known nontrivial (discrete or continuous-time) memoryless channel with a closed-form formula for its optimal non-asymptotic error probability, making it the simplest channel in this sense. A potential application is optical communication with a tunable band rejection filter. Due to its simplicity, we may use it as a basic currency of information that is infinitely divisible, as an alternative to bits which are not infinitely divisible. OCPC with perfect feedback gives a generalization of prefix codes. We also study non-asymptotic coding and channel simulation results for the general OCPC.

</details>


### [3] [Reconstructing Reed-Solomon Codes from Multiple Noisy Channel Outputs](https://arxiv.org/abs/2601.09947)
*Shubhransh Singhvi,Han Mao Kiah,Eitan Yaakobi*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The sequence reconstruction problem, introduced by Levenshtein in 2001, considers a communication setting in which a sender transmits a codeword and the receiver observes K independent noisy versions of this codeword. In this work, we study the problem of efficient reconstruction when each of the $K$ outputs is corrupted by a $q$-ary discrete memoryless symmetric (DMS) substitution channel with substitution probability $p$. Focusing on Reed-Solomon (RS) codes, we adapt the Koetter-Vardy soft-decision decoding algorithm to obtain an efficient reconstruction algorithm. For sufficiently large blocklength and alphabet size, we derive an explicit rate threshold, depending only on $(p, K)$, such that the transmitted codeword can be reconstructed with arbitrarily small probability of error whenever the code rate $R$ lies below this threshold.

</details>


### [4] [Private Information Retrieval for Graph-based Replication with Minimal Subpacketization](https://arxiv.org/abs/2601.09957)
*Vayur Shanbhag,Prasad Krishnan*

Main category: cs.IT

TL;DR: 提出两种单位分包的PIR方案：星型图提升率，通用图与多重图通过独立集分解实现高率。


<details>
  <summary>Details</summary>
Motivation: 在图型复制的数据库中实现PIR时，既要保持检索速率高，又要限制文件分包化，以降低实现复杂度和存储开销；现有方案在这两方面往往折衷或仅适用于特殊图。

Method: ①星型图方案：利用星型结构进行查询设计，确保单文件分包化且保持高率；②通用图方案：采用图的独立集分解方法，构造查询与响应，以实现单位分包并兼顾率；③对多重图扩展：在多重图上采用相同划分策略进一步提升下载率。

Result: • 星型图方案实现单位分包，率优于过去低分包方案；• 通用图方案单位分包，尽管在完全图上率略低于先前方法，却在某些图类上取得更高率；• 对多重图的拓展方案在完全多重图上超过以往的下载率。

Conclusion: 本文提出了两种新的，具有最小分包化（单位分包）的信息论私有信息检索（PIR）方案，分别满足星型图和任意图的需求；在星型图上率更好，并在多图、特定图类中取得了比已有方案更高的下载率。

Abstract: We design new minimal-subpacketization schemes for information-theoretic private information retrieval on graph-based replicated databases. In graph-based replication, the system consists of $K$ files replicated across $N$ servers according to a graph with $N$ vertices and $K$ edges. The client wants to retrieve one desired file, while keeping the index of the desired file private from each server via a query-response protocol. We seek PIR protocols that have (a) high rate, which is the ratio of the file-size to the total download cost, and (b) low subpacketization, which acts as a constraint on the size of the files for executing the protocol. We report two new schemes which have unit-subpacketization (which is minimal): (i) for a special class of graphs known as star graphs, and (ii) for general graphs. Our star-graph scheme has a better rate than previously known schemes with low subpacketization for general star graphs. Our scheme for general graphs uses a decomposition of the graph via independent sets. This scheme achieves a rate lower than prior schemes for the complete graph, however it can achieve higher rates than known for some specific graph classes. An extension of our scheme to the case of multigraphs achieves a higher rate than previous schemes for the complete multi-graph.

</details>


### [5] [On the Leaky Private Information Retrieval with Side Information](https://arxiv.org/abs/2601.09960)
*Yingying Huangfu,Tian Bai*

Main category: cs.IT

TL;DR: 本文提出一种把泄漏量 ε 与差分隐私相结合的 L‑PIR‑SI 模型，计算下载成本上限，实现了在有限泄漏与侧信息下的效率提升，并统一了多项以往 PIR 结果。


<details>
  <summary>Details</summary>
Motivation: 在保持完美隐私要求过高导致通信成本退化的情况下，探索允许有限泄漏以提升效率，同时考虑已知侧信息的场景，弥补先前 PIR‑SI 研究对泄漏影响的缺失。

Method: 构建 L‑PIR‑SI 方案的概率模型，使用差分隐私标准下的泄露参数 ε 对隐私泄露进行量化，并在此框架下推导下载成本上限与容量关系。

Result: 给出了可实现的下载成本可行域；证明在 ε→0 时收敛至 PIR‑SI 的容量；在侧信息缺失时收敛于 leaky‑PIR 已知界限。

Conclusion: 本文首次系统研究了在私有信息检索（PIR）中引入受控信息泄露与侧信息的权衡，提出了一个统一的概率框架并给出了可实现的下载成本上界；该框架在泄漏趋向零时恢复了 PIR‑SI 的信息容量，在不存在侧信息时与已知的 leaky‑PIR 上界一致。

Abstract: This paper investigates the problem of leaky-private Private Information Retrieval with Side Information (L-PIR-SI), which relaxes the requirement of perfect privacy to achieve improved communication efficiency in the presence of side information. While the capacities of PIR-SI under both $W$-privacy and $(W,S)$-privacy have been partially explored, the impact of controlled information leakage in these settings remains unaddressed. We propose a unified probabilistic framework to construct L-PIR-SI schemes where the privacy leakage is quantified by a parameter $\varepsilon$, consistent with differential privacy standards. We characterize the achievable download costs and show that our results generalize several landmark results in the PIR literature: they recover the capacity of PIR-SI when $\varepsilon \to 0$, and reduce to the known bounds for leaky-PIR when side information is absent. This work provides the first look at the trade-offs between leakage, side information, and retrieval efficiency.

</details>


### [6] [Fundamental Limits of Coded Polynomial Aggregation](https://arxiv.org/abs/2601.10028)
*Xi Zhong,Jörg Kliewer,Mingyue Ji*

Main category: cs.IT

TL;DR: 本研究通过规范慢节点模式，给出交叉阈值判据，使编码多项式聚合能在较少工作节点响应下完成精确恢复，且阈值在足够多的非慢集合时为必要条 件。


<details>
  <summary>Details</summary>
Motivation: 传统基于逐个解码的编码多项式计算在面对慢节点时需要更多响应才能恢复完整结果，降低了系统吞吐量。本工作旨在降低所需工作节点数量，提高分布式计算的效率。

Method: 通过在CPA（编码多项式聚合）框架中加入对慢节点模式的规范化，设定交叠阈值并给出与之对应的可行构造，形成基于交叉大小阈值的精确恢复条件。

Result: 提出了必要且充分的交叉大小阈值作为精确恢复的判据；阈值在允许的非慢节点集合足够多时同时为必要与充分；给出了当交叉大于阈值时的明显构造，并通过仿真验证阈值的紧致性。

Conclusion: 在考虑预设的非慢节点集合的分布式计算框架下，利用集合交叉结构可实现更少工作节点响应即可完成期望聚合的完整重构。

Abstract: Coded polynomial aggregation (CPA) enables the master to directly recover a weighted aggregation of polynomial evaluations without individually decoding each term, thereby reducing the number of required worker responses. In this paper, we extend CPA to straggler-aware distributed computing systems and introduce a straggler-aware CPA framework with pre-specified non-straggler patterns, where exact recovery is required only for a given collection of admissible non-straggler sets. Our main result shows that exact recovery of the desired aggregation is achievable with fewer worker responses than required by polynomial coded computing based on individual decoding, and that feasibility is fundamentally characterized by the intersection structure of the non-straggler patterns. In particular, we establish necessary and sufficient conditions for exact recovery in straggler-aware CPA and identify an intersection-size threshold that is sufficient to guarantee exact recovery. We further prove that this threshold becomes both necessary and sufficient when the number of admissible non-straggler sets is sufficiently large. We also provide an explicit construction of feasible CPA schemes whenever the intersection size exceeds the derived threshold. Finally, simulations reveal a sharp feasibility transition at the predicted threshold, providing empirical evidence that the bound is tight in practice.

</details>


### [7] [Function Correcting Codes for Maximally-Unbalanced Boolean Functions](https://arxiv.org/abs/2601.10135)
*Rajlaxmi Pandey,Shiven Bajpai,Anjana A Mahesh,B. Sundar Rajan*

Main category: cs.IT

TL;DR: 研究表明，单错误纠正功能纠错码的距离矩阵结构对误码率有显著影响，解码策略对表现至关重要。


<details>
  <summary>Details</summary>
Motivation: 在不需要完整消息恢复的情况下实现可靠的函数计算，以满足对高效与鲁棒性要求的通信场景。

Method: 通过分析与编码距离矩阵相关的结构，识别出不同FCC类；随后在AWGN信道下对代表性FCC进行软判决和硬判决解码测评，比较数据误码率和函数误码率。

Result: 发现不同距离矩阵结构的FCC在数据BER和函数误差方面表现差异显著，且结构影响随解码策略显著变化。

Conclusion: 该研究实现了针对最大不平衡布尔函数的单错误纠正功能纠错码（SEFCC）的最优构造，揭示了不同距离矩阵结构对错误性能的显著影响，并指出解码策略对误差行为的重要性。

Abstract: Function-Correcting Codes (FCCs) enable reliable computation of a function of a $k$-bit message over noisy channels without requiring full message recovery. In this work, we study optimal single-error correcting FCCs (SEFCCs) for maximally-unbalanced Boolean functions, where $k$ denotes the message length and $t$ denotes the error-correction capability. We analyze the structure of optimal SEFCC constructions through their associated codeword distance matrices and identify distinct FCC classes based on this structure. We then examine the impact of these structural differences on error performance by evaluating representative FCCs over the additive white Gaussian noise (AWGN) channel using both soft-decision and hard-decision decoding. The results show that FCCs with different distance-matrix structures can exhibit markedly different Data BER and function error behavior, and that the influence of code structure depends strongly on the decoding strategy.

</details>


### [8] [On Existence of Girth-8 QC-LDPC Code with Large Column Weight: Combining Mirror-sequence with Classification Modulo Ten](https://arxiv.org/abs/2601.10170)
*Guohua Zhang,Xiangya Liu,Jianhua Zhang,Yi Fang*

Main category: cs.IT

TL;DR: 用GCD代数方法与镜像序列/行重组，设计列权7/8的QC‑LDPC码，长度更短、循环尺寸更小，比现有下界提升20%，实际尺寸可压缩25%。


<details>
  <summary>Details</summary>
Motivation: 在不依赖搜索方法的情况下，构造更短且行权列权更高的QC‑LDPC码，以满足通信、压缩感知及分布式存储等应用的对码长与周期尺寸的要求。

Method: 采用GCD代数框架，引入镜像序列和行重组，针对任意行权进行代数式构造。

Result: 列权7、8的QC‑LDPC码实现girth 8且周期尺寸下界提升约20%；得到的码长度比现有下界小约25%。

Conclusion: 通过GCD框架与镜像序列及行重组方法，构造了列权7和8的QC‑LDPC码，实现了更短长度和更小循环尺寸；且在连续循环尺寸的下界上提升约20%，并可进一步压缩约25%。

Abstract: Quasi-cyclic (QC) LDPC codes with large girths play a crucial role in several research and application fields, including channel coding, compressed sensing and distributed storage systems. A major challenge in respect of the code construction is how to obtain such codes with the shortest possible length (or equivalently, the smallest possible circulant size) using algebraic methods instead of search methods. The greatest-common-divisor (GCD) framework we previously proposed has algebraically constructed QC-LDPC codes with column weights of 5 and 6, very short lengths, and a girth of 8. By introducing the concept of a mirror sequence and adopting a new row-regrouping scheme, QC-LDPC codes with column weights of 7 and 8, very short lengths, and a girth of 8 are proposed for arbitrary row weights in this article via an algebraic manner under the GCD framework. Thanks to these novel algebraic methods, the lower bounds (for column weights 7 and 8) on consecutive circulant sizes are both improved by asymptotically about 20%, compared with the existing benchmarks. Furthermore, these new constructions can also offer circulant sizes asymptotically about 25% smaller than the novel bounds.

</details>


### [9] [Breaking the Storage-Bandwidth Tradeoff in Distributed Storage with Quantum Entanglement](https://arxiv.org/abs/2601.10676)
*Lei Hu,Mohamed Nomeir,Alptug Aytekin,Sennur Ulukus*

Main category: cs.IT

TL;DR: 量子纠缠提升分布式存储性能，在$d\ge2k-2$时可实现存储与修复带宽同时最小化


<details>
  <summary>Details</summary>
Motivation: 探索量子资源在分布式存储系统中的应用

Method: 使用量子信道传输经典信息，并在新节点通过测量恢复存储内容，推导存储与修复带宽的平衡关系

Result: 完整表征了存储–修复带宽的基本权衡；在共享纠缠的生存节点下，尤其在最小存储再生成点（MSR）可显著提升性能。当$d\ge 2k-2$时，存在同时最小化存储与修复带宽的操作点，打破了经典系统的不可逆权衡

Conclusion: 量子通信突破了传统分布式存储的限制，提供了全新的同时最优权衡区间

Abstract: This work investigates the use of quantum resources in distributed storage systems. Consider an $(n,k,d)$ distributed storage system in which a file is stored across $n$ nodes such that any $k$ nodes suffice to reconstruct the file. When a node fails, any $d$ helper nodes transmit information to a newcomer to rebuild the system. In contrast to the classical repair, where helper nodes transmit classical bits, we allow them to send classical information over quantum channels to the newcomer. The newcomer then generates its storage by performing appropriate measurements on the received quantum states. In this setting, we fully characterize the fundamental tradeoff between storage and repair bandwidth (total communication cost). Compared to classical systems, the optimal storage--bandwidth tradeoff can be significantly improved with the enhancement of quantum entanglement shared only among the surviving nodes, particularly at the minimum-storage regenerating point. Remarkably, we show that when $d \geq 2k-2$, there exists an operating point at which \textit{both storage and repair bandwidth are simultaneously minimized}. This phenomenon breaks the tradeoff in the classical setting and reveals a fundamentally new regime enabled by quantum communication.

</details>


### [10] [Error-Correcting Codes for the Sum Channel](https://arxiv.org/abs/2601.10256)
*Lyan Abboud,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 为了分布式和DNA存储，作者提出sum channel并给出删错与替换的近似最优码。


<details>
  <summary>Details</summary>
Motivation: 用于分布式存储与DNA数据存储场景，需解决多行矩阵的删错与替换问题。

Method: 对输入\ell行二进制矩阵生成含奇偶校验行的\ell+1行矩阵，并构造相应纠错码；对单替换使用\lceil \log_2(\ell+1)\rceil冗余。

Result: 得到二删纠错码冗余为2⌈log₂log₂n⌉+O(ℓ²)；当ℓ=2时给出上界⌈log₂log₂n⌉+O(1)，证明近乎最优；单替换码冗余为⌈log₂(ℓ+1)⌉，距最优仅1比特。

Conclusion: 提出sum channel模型，并给出二删纠错、单替换纠错码，其冗余分别在2倍和1比优化界限内。

Abstract: We introduce the sum channel, a new channel model motivated by applications in distributed storage and DNA data storage. In the error-free case, it takes as input an $\ell$-row binary matrix and outputs an $(\ell+1)$-row matrix whose first $\ell$ rows equal the input and whose last row is their parity (sum) row. We construct a two-deletion-correcting code with redundancy $2\lceil\log_2\log_2 n\rceil + O(\ell^2)$ for $\ell$-row inputs. When $\ell=2$, we establish an upper bound of $\lceil\log_2\log_2 n\rceil + O(1)$, implying that our redundancy is optimal up to a factor of 2. We also present a code correcting a single substitution with $\lceil \log_2(\ell+1)\rceil$ redundant bits and prove that it is within one bit of optimality.

</details>


### [11] [Algebraic Properties of PAC Codes](https://arxiv.org/abs/2601.10262)
*Vlad-Florin Dragoi,Mohammad Rowshan*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We analyze polarization-adjusted convolutional codes using the algebraic representation of polar and Reed-Muller codes. We define a large class of codes, called generalized polynomial polar codes which include PAC codes and Reverse PAC codes. We derive structural properties of generalized polynomial polar codes, such as duality, minimum distance. We also deduce some structural limits in terms of number of minimum weight codewords, and dimension of monomial sub-code.

</details>


### [12] [On the Capacity of Noisy Frequency-based Channels](https://arxiv.org/abs/2601.10329)
*Yuval Gerzon,Ilan Shomorony,Nir Weinberger*

Main category: cs.IT

TL;DR: 本研究给出了噪声频率编码信道的逆向与可实现容量边界，明确了识别噪声导致的互信息损失，并用此评估了短分子DNA存储中的可靠位数下降。


<details>
  <summary>Details</summary>
Motivation: 探讨受噪声影响的频率编码信道在短分子DNA存储中的容量，以解决传统顺序编码在短分子环境下的可行性问题。

Method: 首先给出基于随机降解和数据处理不等式的逆向容量上界；随后通过将多项式采样过程泊松化，构造向量泊松信道，对信息密度的集中不等式进行细化，并量化识别噪声导致的互信息损失，得到可实现的容量下界。

Result: 提出了识别噪声对容量的加性损失解析式，并将其应用于短分子DNA存储信道，定量评估了可靠存储总位数随信息量的缩放损失。

Conclusion: 识别噪声显著降低频率基信道容量；通过泊松化和信息密度分析，可精确估算并量化该损失，帮助设计更高效的短分子DNA存储方案。

Abstract: We investigate the capacity of noisy frequency-based channels, motivated by DNA data storage in the short-molecule regime, where information is encoded in the frequency of items types rather than their order. The channel output is a histogram formed by random sampling of items, followed by noisy item identification. While the capacity of the noiseless frequency-based channel has been previously addressed, the effect of identification noise has not been fully characterized. We present a converse bound on the channel capacity that follows from stochastic degradation and the data processing inequality. We then establish an achievable bound, which is based on a Poissonization of the multinomial sampling process, and an analysis of the resulting vector Poisson channel with inter-symbol interference. This analysis refines concentration inequalities for the information density used in Feinstein bound, and explicitly characterizes an additive loss in the mutual information due to identification noise. We apply our results to a DNA storage channel in the short-molecule regime, and quantify the resulting loss in the scaling of the total number of reliably stored bits.

</details>


### [13] [Codebook Design for Limited Feedback in Near-Field XL-MIMO Systems](https://arxiv.org/abs/2601.10391)
*Liujia Yao,Changsheng You,Zixuan Huang,Chao Zhou,Zhaohui Yang,Xiaoyang Li*

Main category: cs.IT

TL;DR: 本研究针对XL‑MIMO系统中用户分布导致的反馈量过大问题，提出一种基于角度均匀采样与几何距离采样的新型代码本，采用理论与数值验证法表明其在不同部署下均能提升速率并降低反馈需求。


<details>
  <summary>Details</summary>
Motivation: 在极大规模多输入多输出（XL‑MIMO）频分双工系统中，现有代码本设计（如极角域代码本）未充分考虑用户位置分布，导致反馈量过大。

Method: 构造用户在特定极角区域均匀分布的典型场景，针对角度与距离抽样与比特分配共同优化的求和速率最大化问题；通过Voronoi分割证明角度采样均匀最优；对距离采样利用下界式提出几何采样；进一步扩展为非均匀分布的交替采样方法，并对反馈比特分配随阵列尺寸变化的趋势进行理论分析。

Result: 提出的代码本在多种系统设置下实现了更优速率表现及鲁棒性，显著超过传统极角域代码本等基准方案。

Conclusion: 针对用户分布定制的反馈代码本能显著降低反馈开销并提升速率，随着阵列尺寸增大，距离样本比角度样本获得更高的反馈比特比率。

Abstract: In this paper, we study efficient codebook design for limited feedback in extremely large-scale multiple-input-multiple-output (XL-MIMO) frequency division duplexing (FDD) systems. It is worth noting that existing codebook designs for XL-MIMO, such as polar-domain codebook, have not well taken into account user (location) distribution in practice, thereby incurring excessive feedback overhead. To address this issue, we propose in this paper a novel and efficient feedback codebook tailored to user distribution. To this end, we first consider a typical scenario where users are uniformly distributed within a specific polar-region, based on which a sum-rate maximization problem is formulated to jointly optimize angle-range samples and bit allocation among angle/range feedback. This problem is challenging to solve due to the lack of a closed-form expression for the received power in terms of angle and range samples. By leveraging a Voronoi partitioning approach, we show that uniform angle sampling is optimal for received power maximization. For more challenging range sampling design, we obtain a tight lower-bound on the received power and show that geometric sampling, where the ratio between adjacent samples is constant, can maximize the lower bound and thus serves as a high-quality suboptimal solution. We then extend the proposed framework to accommodate more general non-uniform user distribution via an alternating sampling method. Furthermore, theoretical analysis reveals that as the array size increases, the optimal allocation of feedback bits increasingly favors range samples at the expense of angle samples. Finally, numerical results validate the superior rate performance and robustness of the proposed codebook design under various system setups, achieving significant gains over benchmark schemes, including the widely used polar-domain codebook.

</details>


### [14] [Convertible Codes for Data and Device Heterogeneity](https://arxiv.org/abs/2601.10341)
*Anina Gruica,Benjamin Jany,Stanislav Kruglik*

Main category: cs.IT

TL;DR: 通过可转换码与Reed-Muller码的结合，首次在分布式存储中同时解决数据与设备异构性，降低转换成本。


<details>
  <summary>Details</summary>
Motivation: 处理分布式存储系统中数据和设备异构性所面临的挑战，尤其是非均匀访问需求和节点可靠性随时间变化的问题。

Method: 研究可转换码以实现最小成本的码转换，并推导线性码转换的读写成本下界；随后针对Reed-Muller码设计显式的转换程序，兼顾两类异构性。

Result: 给出任意线性码的读写成本下界，构造了能同时解决数据及设备异构性的Reed-Muller码转换方案，首次实现两者的统一处理。

Conclusion: 提供了一套低成本、高效的码转换框架，显著提升分布式存储系统在面对多样化访问模式和节点可靠性波动时的性能与可靠性。

Abstract: Distributed storage systems must handle both data heterogeneity, arising from non-uniform access demands, and device heterogeneity, caused by time-varying node reliability. In this paper, we study convertible codes, which enable the transformation of one code into another with minimum cost in the merge regime, addressing the latter. We derive general lower bounds on the read and write costs of linear code conversion, applicable to arbitrary linear codes. We then focus on Reed-Muller codes, which efficiently handle data heterogeneity, addressing the former issue, and construct explicit conversion procedures that, for the first time, combine both forms of heterogeneity for distributed data storage.

</details>


### [15] [A New Construction Structure on MISO Coded Caching with Linear Subpacketization: Half-Sum Disjoint Packing](https://arxiv.org/abs/2601.10353)
*Bowen Zheng,Minquan Cheng,Kai Wan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 引入 L‑HSDP 结构，构建低分块数 MISO 编码缓存方案，使子包数与用户数同阶，保持高 sum‑DoF，性能优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有的多天线编码缓存方案在 L、M、N 任意取值时，子包数随用户数指数增长，导致实现复杂度高；迫切需要在保持高 sum‑DoF 的同时降低分块数。

Method: 首先将 MAPDA 中 F=K 设计映射为 L‑Half‑Sum Disjoint Packing（HSDP）的构造，随后利用拉丁方框的框架构筑 L‑HSDP。该结构对应的缓存方案满足无编码放置和单次线性递送策略。

Result: 通过 L‑HSDP 方案实现 F=K 的子包数线性增长，理论与数值研究表明该方案在 sum‑DoF 上只略有损失，却显著低于指数分块方案，且在 sum‑DoF 与子包数两方面均优于现有线性分块方案。

Conclusion: 该研究提出了一种低分块数的 MISO 编码缓存方案，通过构造 L‑HSDP 结构实现了接近最优的 sum‑DoF，同时将子包数从指数级降低到与用户数线性阶梯。

Abstract: In the $(L,K,M,N)$ cache-aided multiple-input single-output (MISO) broadcast channel (BC) system, the server is equipped with $L$ antennas and communicates with $K$ single-antenna users through a wireless broadcast channel where the server has a library containing $N$ files, and each user is equipped with a cache of size $M$ files. Under the constraints of uncoded placement and one-shot linear delivery strategies, many schemes achieve the maximum sum Degree-of-Freedom (sum-DoF). However, for general parameters $L$, $M$, and $N$, their subpacketizations increase exponentially with the number of users. We aim to design a MISO coded caching scheme that achieves a large sum-DoF with low subpacketization $F$. An interesting combinatorial structure, called the multiple-antenna placement delivery array (MAPDA), can be used to generate MISO coded caching schemes under these two strategies; moreover, all existing schemes with these strategies can be represented by the corresponding MAPDAs. In this paper, we study the case with $F=K$ (i.e., $F$ grows linearly with $K$) by investigating MAPDAs. Specifically, based on the framework of Latin squares, we transform the design of MAPDA with $F=K$ into the construction of a combinatorial structure called the $L$-half-sum disjoint packing (HSDP). It is worth noting that a $1$-HSDP is exactly the concept of NHSDP, which is used to generate the shared-link coded caching scheme with $F=K$. By constructing $L$-HSDPs, we obtain a class of new schemes with $F=K$. Finally, theoretical and numerical analyses show that our $L$-HSDP schemes significantly reduce subpacketization compared to existing schemes with exponential subpacketization, while only slightly sacrificing sum-DoF, and achieve both a higher sum-DoF and lower subpacketization than the existing schemes with linear subpacketization.

</details>


### [16] [Generalized Weight Structure of Polar Codes: Selected Template Polynomials](https://arxiv.org/abs/2601.10362)
*Mohammad Rowshan,Vlad-Florin Dragoi*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Polar codes can be viewed as decreasing monomial codes, revealing a rich algebraic structure governed by the lower-triangular affine (LTA) group. We develop a general framework to compute the Hamming weight of codewords generated by sums of monomials, express these weights in a canonical dyadic form, and derive closed expressions for key structural templates (disjoint sums, nested blocks, complementary flips) that generate the low and intermediate weight spectrum. Combining these templates with the LTA group action, we obtain explicit multiplicity formulas, yielding a unified algebraic method to characterize and enumerate codewords.

</details>


### [17] [A Hybrid Reliability--Weight Framework for Construction of Polar Codes](https://arxiv.org/abs/2601.10376)
*Mohammad Rowshan,Vlad-Florin Dragoi*

Main category: cs.IT

TL;DR: 设计了一种利用轨道枚举和Bhattacharyya因子平衡可靠性与权重的混合构造，对短中等长度极化码实现了更好性能。


<details>
  <summary>Details</summary>
Motivation: 传统可靠性排序导致短程码的低重量谱不佳；需在可靠性与码权重之间取得折衷。

Method: 定义基于轨道枚举的每位成本，将距离项与Bhattacharyya因子结合；构造基于该混合度量的降序多项式码；通过截断SC/ML联合界和SCL剪枝/ML分解证明其性能。

Result: 数值实验表明混合构造在BPSK-AWGN下对短中等长度码，最小距离、乘数和联合界均优于纯可靠性构造。

Conclusion: 混合可靠性-权重序列能在给定代码长度范围内实现更优的最小距离与乘数折衷，同时在长度趋近无穷时与传统可靠性构造收敛。

Abstract: Polar codes are usually constructed by ranking synthetic bit-channels according to reliability, which guarantees capacity-achieving behavior but can yield poor low-weight spectra at short and moderate lengths. Recent algebraic results express the contribution of individual bit-channels to the multiplicities of minimum and near-minimum weight codewords in closed form. In this work we combine these insights into a mixed (reliability--weight) bit-channel ordering. We define a per-bit cost whose distance term is derived from orbit enumeration of minimum-weight codewords and scaled by a Bhattacharyya-type factor, and show that the resulting mixed construction minimises a truncated SC/ML union-bound surrogate within a class of decreasing monomial codes. We relate the mixed metric to error events in SCL decoding via a pruning/ML decomposition, and prove that mixed designs act as local perturbations of reliability-based constructions whose asymptotic impact vanishes as code-length approaches infinity. Numerical results for short and moderate lengths on BPSK-AWGN, implemented via Gaussian approximation and closed-form weight contributions, illustrate the trade-off between pure reliability-based and mixed constructions in terms of minimum distance, multiplicity, and union-bound approximations. All proofs are deferred to the appendices.

</details>


### [18] [Multiaccess Coded Caching with Heterogeneous Retrieval Costs](https://arxiv.org/abs/2601.10394)
*Wenbo Huang,Minquan Cheng,Kai Wan,Xiaojun Li,Robert Caiming Qiu,Giuseppe Caire*

Main category: cs.IT

TL;DR: 引入成本感知的叠加编码 MACC 方案，利用稀疏性降低优化复杂度，与传统方案相比在多成本环境下效果更佳。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常假设用户从连接缓存节点取回内容无通信成本，现实中用户需支付不同的检索费用，且服务器广播亦有成本；需在考虑这些成本的前提下优化系统。

Method: 采用叠加编码构建新型的缓存方案，将 Cheng 等人方案分层；随后推导成本感知的优化问题，利用最优解的稀疏性设计结构感知低复杂度算法；通过仿真验证。

Result: 所提出的算法在异质检索成本场景下，相较于 Cheng 等人方案，一贯实现更低的总系统成本。

Conclusion: 通过引入基于叠加编码的多接入有缓存系统（MACC）框架，并针对缓存配置与广播成本构建优化模型，系统在存在异质检索成本的场景下能够显著降低总成本。

Abstract: The multiaccess coded caching (MACC) system, as formulated by Hachem {\it et al.}, consists of a central server with a library of $N$ files, connected to $K$ cache-less users via an error-free shared link, and $K$ cache nodes, each equipped with cache memory of size $M$ files. Each user can access $L$ neighboring cache nodes under a cyclic wrap-around topology. Most existing studies operate under the strong assumption that users can retrieve content from their connected cache nodes at no communication cost. In practice, each user retrieves content from its $L$ different connected cache nodes at varying costs. Additionally, the server also incurs certain costs to transmit the content to the users. In this paper, we focus on a cost-aware MACC system and aim to minimize the total system cost, which includes cache-access costs and broadcast costs. Firstly, we propose a novel coded caching framework based on superposition coding, where the MACC schemes of Cheng \textit{et al.} are layered. Then, a cost-aware optimization problem is derived that optimizes cache placement and minimizes system cost. By identifying a sparsity property of the optimal solution, we propose a structure-aware algorithm with reduced complexity. Simulation results demonstrate that our proposed scheme consistently outperforms the scheme of Cheng {\it et al.} in scenarios with heterogeneous retrieval costs.

</details>


### [19] [Converse Bounds for Sun-Jafar-type Weak Private Information Retrieval](https://arxiv.org/abs/2601.10643)
*Chandan Anand,Jayesh Seshadri,Prasad Krishnan,Gowtham R. Kurri*

Main category: cs.IT

TL;DR: 本文证明了Chandan等人提出的弱私有信息检索方案在复制与MDS场景下具有类级最优性能，并发现阈值约束外能获得更高速率。


<details>
  <summary>Details</summary>
Motivation: 验证并提升Chandan等人提出的WPIR方案在不同存储与协作模型下的性能极限，提高弱私有信息检索方案的理论保障。

Method: 对已有WPIR设计进行信息论解析与优化，通过构造信息泄露与最大泄漏度量下的率-隐私范式，利用阈值约束证明类级最优性，并给出反例以说明不满足阈值时存在更高率。

Result: 完成了对Sun‑Jafar与Banawan‑Ulukus类方案的类级最优性证明；在阈值约束不满足时，发现更高速率的可行方案。

Conclusion: 本文证明了Chandan等人提出的Sun‑Jafar式及Banawan‑Ulukus式弱私有信息检索方案在非协作复制与MDS编码中的速率-隐私权衡的类级最优性，并在阈值约束下进一步推广至T‑协作场景；若不满足阈值，展示了更优方案的反例。

Abstract: Building on the well-established capacity-achieving schemes of Sun-Jafar (for replicated storage) and the closely related scheme of Banawan-Ulukus (for MDS-coded setting), a recent work by Chandan et al. proposed new classes of weak private information retrieval (WPIR) schemes for the collusion-free (replication and MDS-coded) setting, as well as for the $T$-colluding scenario. In their work, Chandan et al. characterized the expressions for the rate-privacy trade-offs for these classes of WPIR schemes, under the mutual information leakage and maximal leakage metrics. Explicit achievable trade-offs for the same were also presented, which were shown to be competitive or better than prior WPIR schemes. However, the class-wise optimality of the reported trade-offs were unknown. In this work, we show that the explicit rate-privacy trade-offs reported for the Sun-Jafar-type schemes by Chandan et al. are optimal for the non-colluding and replicated setting. Furthermore, we prove the class-wise optimality for Banawan-Ulukus-type MDS-WPIR and Sun-Jafar-type $T$-colluding WPIR schemes, under threshold-constraints on the system parameters. When these threshold-constraints do not hold, we present counter-examples which show that even higher rates than those reported before can be achieved.

</details>


### [20] [A New Construction Structure on Coded Caching with Linear Subpacketization: Non-Half-Sum Latin Rectangle](https://arxiv.org/abs/2601.10505)
*Yongcheng Yang,Minquan Cheng,Kai Wan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 新构造的 NHSLR 使代码缓存方案在分块率线性扩展的同时，显著降低传输负载，整体性能接近指数级分块率方案。


<details>
  <summary>Details</summary>
Motivation: 在需要低分块率和低传输负载的前提下，传统编码缓存方案往往要么分块率指数级增长，要么传输负载过高。

Method: 提出新的组合结构非半和数拉丁矩阵（NHSLR），将之前的非半和数拆分包装（NHSDP）框架从$F=K$扩展到$F=O(K)$，实现线性可扩展的分块率。

Result: 构造出的缓存方案实现了线性可扩展的分块率，并且其传输负载比NHSDP方案更低，且与某些指数分块率方案的性能接近。

Conclusion: 该方法提供了一类在分块率与负载之间取得更好平衡的编码缓存方案，显著优于现有线性分块率方案，并在性能上逼近指数级方案。

Abstract: Coded caching is recognized as an effective method for alleviating network congestion during peak periods by leveraging local caching and coded multicasting gains. The key challenge in designing coded caching schemes lies in simultaneously achieving low subpacketization and low transmission load. Most existing schemes require exponential or polynomial subpacketization levels, while some linear subpacketization schemes often result in excessive transmission load. Recently, Cheng et al. proposed a construction framework for linear coded caching schemes called Non-Half-Sum Disjoint Packing (NHSDP), where the subpacketization equals the number of users $K$. This paper introduces a novel combinatorial structure, termed the Non-Half-Sum Latin Rectangle (NHSLR), which extends the framework of linear coded caching schemes from $F=K$ (i.e., the construction via NHSDP) to a broader scenario with $F=\mathcal{O}(K)$. By constructing NHSLR, we have obtained a new class of coded caching schemes that achieves linearly scalable subpacketization, while further reducing the transmission load compared with the NHSDP scheme. Theoretical and numerical analyses demonstrate that the proposed schemes not only achieves lower transmission load than existing linear subpacketization schemes but also approaches the performance of certain exponential subpacketization schemes.

</details>


### [21] [A New Construction Structure on Multi-access Coded Caching with Linear Subpacketization: Cyclic Multi-Access Non-Half-Sum Disjoint Packing](https://arxiv.org/abs/2601.10510)
*Mengyuan Li,Minquan Cheng,Kai Wan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 新构造CMA‑NHSDP可在保持子包化线性F=K的前提下，显著降低多访问编码缓存系统的传输负载，优于部分现有方案。


<details>
  <summary>Details</summary>
Motivation: 研究多访问编码缓存系统中，现有方案虽然在传输性能上具有竞争力，但子包化水平随用户数指数增长。为实现仅线性子包化且保持低传输负载，提出新型组合结构

Method: 构造循环多访问非半和差异打包（CMA‑NHSDP），基于已知非半和差异打包（NHSDP）的构造框架，对多访问编码缓存系统进行扩展并设计对应缓存与传输策略

Result: 通过理论分析与数值仿真，所推导的多访问缓存方案在相同线性子包化条件下，传输负载低于若干已有方案；并在部分情形下，传输负载甚至低于指数子包化方案

Conclusion: CMA‑NHSDP提供一种可行的、子包化水平线性且传输负载优于现有方案的多访问编码缓存机制，为实际系统实现提供了新的设计思路

Abstract: We consider the $(K,L,M,N)$ multi-access coded caching system introduced by Hachem et al., which consists of a central server with $N$ files and $K$ cache nodes, each of memory size $M$, where each user can access $L$ cache nodes in a cyclic wrap-around fashion. At present, several existing schemes achieve competitive transmission performance, but their subpacketization levels grow exponentially with the number of users. In contrast, schemes with linear or polynomial subpacketization always incur higher transmission loads. We aim to design a multi-access coded caching scheme with linear subpacketization $F$ while maintaining low transmission load. Recently, Cheng et al. proposed a construction framework for coded caching schemes with linear subpacketization (i.e., $F=K$) called non-half-sum disjoint packing (NHSDP). Inspired by this structure, we introduce a novel combinatorial structure named cyclic multi-access non-half-sum disjoint packing (CMA-NHSDP) by extending NHSDP to MACC system. By constructing CMA-NHSDP, we obtain a new class of multi-access coded caching schemes. Theoretical and numerical analyses show that our scheme achieves lower transmission loads than some existing schemes with linear subpacketization. Moreover, the proposed schemes achieves lower transmission load compared to existing schemes with exponential subpacketization in some case.

</details>


### [22] [Error-Correcting Codes for Two Bursts of t1-Deletion-t2-Insertion with Low Computational Complexity](https://arxiv.org/abs/2601.10540)
*Yajuan Liu,Tolga M. Duman*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Burst errors involving simultaneous insertions, deletions, and substitutions occur in practical scenarios, including DNA data storage and document synchronization, motivating developments of channel codes that can correct such errors. In this paper, we address the problem of constructing error-correcting codes (ECCs) capable of handling multiple bursts of $t_1$-deletion-$t_2$-insertion ($(t_1,t_2)$-DI) errors, where each burst consists of $t_1$ deletions followed by $t_2$ insertions in a binary sequence. We make three key contributions: Firstly, we establish the fundamental equivalence of (1) two bursts of $(t_1,t_2)$-DI ECCs, (2) two bursts of $(t_2,t_1)$-DI ECCs, and (3) one burst each of $(t_1,t_2)$-DI and $(t_2,t_1)$-DI ECCs. Then, we derive lower and upper bounds on the code size of two bursts of $(t_1,t_2)$-DI ECCs, which can naturally be extended to the case of multiple bursts. Finally, we present constructions of two bursts of $(t_1,t_2)$-DI ECCs. Compared to the codes obtained by the syndrome compression technique, the resulting codes achieve significantly lower computational complexity.

</details>


### [23] [Sparse Signal Recovery from Random Measurements](https://arxiv.org/abs/2601.10569)
*Siu-Wing Cheng,Man Ting Wong*

Main category: cs.IT

TL;DR: 快速稀疏向量恢复：用$Θ(\log n)$随机矩阵、$O(kn\log n)$时间，无需优化，仅线性运算就能恢复并定位稀疏信号。


<details>
  <summary>Details</summary>
Motivation: 现有压缩感知重构往往依赖昂贵的优化或线性系统求解，作者希望提供一种计算上更轻量、可快速实现的稀疏信号恢复方案。

Method: 使用$Θ(\log n)$个随机 sensing 矩阵，每个矩阵尺寸为$k \times n$（$k = Θ(s\log n)$），通过简单的线性组合与阈值判定来恢复向量，算法时间复杂度为$O(kn\log n)$。

Result: 实验表明，该方法在二值信号上与传统优化方法进行比较，具有可观的重构准确率，并且计算效率高。

Conclusion: 该方法能够在不求解优化问题或线性方程组的前提下，仅通过$Θ(\log n)$个随机测量矩阵成功恢复稀疏向量$z$，并且支持正向恢复及其支撑集定位。

Abstract: Given the compressed sensing measurements of an unknown vector $z \in \mathbb{R}^n$ using random matrices, we present a simple method to determine $z$ without solving any optimization problem or linear system. Our method uses $Θ(\log n)$ random sensing matrices in $\mathbb{R}^{k \times n}$ and runs in $O(kn\log n)$ time, where $k = Θ(s\log n)$ and $s$ is the number of nonzero coordinates in $z$. We adapt our method to determine the support set of $z$ and experimentally compare with some optimization-based methods on binary signals.

</details>


### [24] [Fundamental Limits of Multi-User Distributed Computing of Linearly Separable Functions](https://arxiv.org/abs/2601.10603)
*K. K. Krishnan Namboodiri,Elizabath Peter,Derya Malak,Petros Elia*

Main category: cs.IT

TL;DR: 作者研究多用户分布式计算的通信成本极限，提出联合任务分配与传输方案，并对实数域与有限域均给出性能上界与下界，证明方案达到或接近最优。


<details>
  <summary>Details</summary>
Motivation: 解决多用户线性可分离函数分布式计算中的通信与计算权衡问题，降低服务器到用户的总通信负担。

Method: 提出一种联合任务分配与线性传输方案，利用M个子函数的计算能力和Δ个用户的传输限制，设计了适用于任意K、L、M、Δ的分布式计算模型，并给出在实数域上的对偶分析以及有限域的计数论证。

Result: 方案在实数域下证明与既有下界匹配，达成最优通信成本；在有限域下给出了对应的性能度量。

Conclusion: 在本系统中，作者基于精确的对偶（converse）证明了在实数域上多用户线性可分离函数的分布式计算中，给定系统参数（K, L, M, Δ）时，提出的任务分配与传输联合设计方案能够达到最优通信成本；在有限域下亦给出了基于计数的上界，界定了系统性能极限。

Abstract: This work establishes the fundamental limits of the classical problem of multi-user distributed computing of linearly separable functions. In particular, we consider a distributed computing setting involving $L$ users, each requesting a linearly separable function over $K$ basis subfunctions from a master node, who is assisted by $N$ distributed servers. At the core of this problem lies a fundamental tradeoff between communication and computation: each server can compute up to $M$ subfunctions, and each server can communicate linear combinations of their locally computed subfunctions outputs to at most $Δ$ users. The objective is to design a distributed computing scheme that reduces the communication cost (total amount of data from servers to users), and towards this, for any given $K$, $L$, $M$, and $Δ$, we propose a distributed computing scheme that jointly designs the task assignment and transmissions, and shows that the scheme achieves optimal performance in the real field under various conditions using a novel converse. We also characterize the performance of the scheme in the finite field using another converse based on counting arguments.

</details>


### [25] [Basis-Spline Assisted Coded Computing: Strategies and Error Bounds](https://arxiv.org/abs/2601.10616)
*Rimpi Borah,J. Harshan,V. Lalitha*

Main category: cs.IT

TL;DR: 提出了三次B样条为基础的容错计算框架，克服Berrut插值在大量刹车器情况下精度下降的问题，实验证明其在非多项式函数计算中具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 传统的Berrut插值在处理非多项式函数时会被刹车器比例所削弱，导致全局支撑导致精度下降。本研究旨在利用局部支撑的B样条，以提升在高刹车器环境下的稳定性与准确性。

Method: 在服务器端对被指派的函数评估结果进行三次B样条插值，然后在主节点通过该插值重建完整函数值。该方法利用B样条局部支撑与光滑性特征，构造了误差上界，并将其表述为服务器数量与刹车器数量的函数。

Result: 通过理论分析和实验对比，证实所提框架在多种非多项式函数场景下均优于Berrut方法；误差上界与刹车器数量的关系保持紧凑，并显示出更低的误差收敛率。

Conclusion: 本研究提出的基于三次B样条插值的容错计算框架在非多项式函数的分布式计算中显著提高了精度和鲁棒性，尤其在较高比例刹车器的场景下优于现有基于Berrut插值的方法。

Abstract: Coded computing has become a key framework for reliable distributed computation over decentralized networks, effectively mitigating the impact of stragglers. Although there exists a wide range of coded computing methods to handle both polynomial and non-polynomial functions, computing methods for the latter class have received traction due its inherent challenges in reconstructing non-polynomial functions using a finite number of evaluations. Among them, the state-of-the-art method is Berrut Approximated coded computing, wherein Berrut interpolants, are used for approximating the non-polynomial function. However, since Berrut interpolants have global support characteristics, such methods are known to offer degraded accuracy when the number of stragglers is large. To address this challenge, we propose a coded computing framework based on cubic B-spline interpolation. In our approach, server-side function evaluations are reconstructed at the master node using B-splines, exploiting their local support and smoothness properties to enhance stability and accuracy. We provide a systematic methodology for integrating B-spline interpolation into coded computing and derive theoretical bounds on approximation error in terms of the number of servers and stragglers. Comparative analysis demonstrates that our framework significantly outperforms Berrut-based methods for various non-polynomial functions.

</details>


### [26] [One-Shot Broadcast Joint Source-Channel Coding with Codebook Diversity](https://arxiv.org/abs/2601.10648)
*Joseph Rowan,Buu Phan,Ashish Khisti*

Main category: cs.IT

TL;DR: 探讨一次性多解码源-通道编码，展示不共享码本的多样性收益，并给出混合组策略，实验结果证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 在一次性广播情境中，解码器须至少有一个在给定失真约束内恢复源，传统单一码本难以充分利用多个独立通道。

Method: 采用Poisson匹配引理的改造，推导多解码器不共享码本的第一阶和第二阶可达界，并设计分组混合编解码器。

Result: 实验在二元对称信道上显示，混合分组编码方案在成功率上优于全共享和全独立码本方法，验证了码本多样性带来的优势。

Conclusion: 本文在单一次性源-通道编码场景下研究多解码器的码本多样性效益，指出使用每个解码器独立码本能提升成功概率，并提出混合分组编码方案，实验表明其优于完全共享或完全独立码本策略。

Abstract: We study a one-shot joint source-channel coding setting where the source is encoded once and broadcast to $K$ decoders through independent channels. Success is predicated on at least one decoder recovering the source within a maximum distortion constraint. We find that in the one-shot regime, utilizing disjoint codebooks at each decoder yields a codebook diversity gain, distinct from the channel diversity gain that may be expected when several decoders observe independent realizations of the channel's output but share the same codebook. Coding schemes are introduced that leverage this phenomenon, where first- and second-order achievability bounds are derived via an adaptation of the Poisson matching lemma (Li and Anantharam, 2021) which allows for multiple decoders using disjoint codebooks. We further propose a hybrid coding scheme that partitions decoders into groups to optimally balance codebook and channel diversity. Numerical results on the binary symmetric channel demonstrate that the hybrid approach outperforms strategies where the decoders' codebooks are either fully shared or disjoint.

</details>


### [27] [Implementation of Oblivious Transfer over Binary-Input AWGN Channels by Polar Codes](https://arxiv.org/abs/2601.10682)
*Pin-Hsun Lin,Hadi Aghaee,Christian Deppe,Eduard A. Jorswieck,Holger Boche*

Main category: cs.IT

TL;DR: 本文在二进制Gauss噪声信道上设计OT协议，利用极化码与自同构随机化实现有限码长完好接收者隐私，并通过隐私放大实现渐近发送者隐私；提出放宽可靠性判据评估有限块长度性能，并给出基于极化自同构的OT速率优化。


<details>
  <summary>Details</summary>
Motivation: 在高斯噪声信道中实现OT协议时，传统方案无法在有限码长下保证完全的接收者隐私，且发送者隐私通常只在渐近上可达；需研究能够兼顾有限码长和两方隐私的协议。

Method: 利用极化码的自同构群随机抽取公共编码器，并在接收器一侧使用两个解码视图；通过极化与隐私放大实现发送者隐私；通过在劣化bit channel注入随机性并提出放松的可靠性要求，对有限区块长度性能进行评估；进一步将极化变换自同构表征为bit级别的位通道索引置换，用此结构优化OT速率。

Result: 证明在任意有限码长下实现完美的接收者隐私；渐近上实现发送者隐私；给出了放宽可靠性条件下的有限块长度OT速率上界，并通过极化自同构的结构化优化实现可实现速率。

Conclusion: 本论文提出了一种在二进制加性高斯噪声信道上实现一对二的可观测传输(OT)协议，利用极化码实现了在有限码长下完全的接收者隐私，并在渐近上保证发送者隐私；通过插入随机性到劣化bit channel并放宽可靠性判据，给出了在有限块长度下可实现的OT速率，并对极化变换的自同构进行了结构化表征。

Abstract: We develop a one-out-of-two-oblivious transfer protocol over the binary-input additive white Gaussian noise channel using polar codes. The scheme uses two decoder views linked by automorphisms of the polar transform and publicly draws the encoder at random from the corresponding automorphism group. This yields perfect receiver privacy at any finite blocklength, since the public encoder distribution is independent of the receiver's choice bit. Sender privacy is obtained asymptotically via channel polarization combined with privacy amplification. Because the construction deliberately injects randomness on selected bad bit-channels, we derive a relaxed reliability criterion and evaluate finite-blocklength performance. Finally, we characterize the polar-transform automorphisms as bit-level permutations of bit-channel indices, and exploit this structure to derive and optimize an achievable finite-blocklength OT rate.

</details>


### [28] [Improved Constructions of Reed-Solomon Codes with Optimal Repair Bandwidth](https://arxiv.org/abs/2601.10685)
*Jing Qiu,Weijun Fang,Shu-Tao Xia,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 改进RS-MSR码去掉了 p_i≡1(mod s) 的限制，子包化简下降了 φ(s)^n 倍，同时扩大了可用参数。


<details>
  <summary>Details</summary>
Motivation: 原RS-MSR码仅在满足 p_i≡1 (mod s) 的质数下有效，导致子包化简显著且参数受限；需要更灵活、更低子包化简的构造以满足实际存储需求。

Method: 在原Tamo-Barg-Ye构造基础上，修改质数选取条件，实现子包化简，利用欧拉函数 φ(s) 控制子包化简比例。

Result: 构造的RS-MSR码的子包化简为 s·∏p_i 的乘积减去 φ(s)^n 的因子，且不再需同余约束，可用于更宽泛的 d、k 参数组合。

Conclusion: 提出了一种改进的RS-MSR码构造，可消除原先对质数的同余限制，显著降低子包大小并扩大可实现参数范围。

Abstract: Maximum-distance-separable (MDS) codes are widely used in distributed storage, yet naive repair of a single erasure in an $[n,k]$ MDS code downloads the entire contents of $k$ nodes. Minimum Storage Regenerating (MSR) codes (Dimakis et al., 2010) minimize repair bandwidth by contacting $d>k$ helpers and downloading only a fraction of data from each. Guruswami and Wootters first proposed a linear repair scheme for Reed-Solomon (RS) codes, showing that they can be repaired with lower bandwidth than the naive approach. The existence of RS codes achieving the MSR point (RS-MSR codes) nevertheless remained open until the breakthrough construction of Tamo, Barg, and Ye, which yields RS-MSR codes with subpacketization $\ell = s \prod_{i=1}^n p_i$, where $p_i$ are distinct primes satisfying $p_i \equiv 1 \pmod{s}$ and $s=d+1-k$.
  In this paper, we present an improved construction of RS-MSR codes by eliminating the congruence condition $p_i \equiv 1 \pmod{s}$. Consequently, our construction reduces the subpacketization by a multiplicative factor of $φ(s)^n$ ( $φ(\cdot)$ is Euler's totient function) and broadens the range of feasible parameters for RS-MSR codes.

</details>


### [29] [Perfect Secret Key Generation for a class of Hypergraphical Sources](https://arxiv.org/abs/2601.10697)
*Manuj Mukherjee,Sagnik Chatterjee,Alhad Sethi*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Nitinawarat and Narayan proposed a perfect secret key generation scheme for the so-called \emph{pairwise independent network (PIN) model} by exploiting the combinatorial properties of the underlying graph, namely the spanning tree packing rate. This work considers a generalization of the PIN model where the underlying graph is replaced with a hypergraph, and makes progress towards designing similar perfect secret key generation schemes by exploiting the combinatorial properties of the hypergraph.
  Our contributions are two-fold. We first provide a capacity achieving scheme for a complete $t$-uniform hypergraph on $m$ vertices by leveraging a packing of the complete $t$-uniform hypergraphs by what we refer to as star hypergraphs, and designing a scheme that gives $\binom{m-2}{t-2}$ bits of perfect secret key per star graph. Our second contribution is a 2-bit perfect secret key generation scheme for 3-uniform star hypergraphs whose projections are cycles. This scheme is then extended to a perfect secret key generation scheme for generic 3-uniform hypergraphs by exploiting star graph packing of 3-uniform hypergraphs and Hamiltonian packings of graphs. The scheme is then shown to be capacity achieving for certain classes of hypergraphs.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [30] [Synthetic Data for Veterinary EHR De-identification: Benefits, Limits, and Safety Trade-offs Under Fixed Compute](https://arxiv.org/abs/2601.09756)
*David Brundage*

Main category: cs.CR

TL;DR: 合成数据用作增量训练可轻微改善去标识效果，不能完全替代真实数据；当与真实样本混合并适度增长时能降低安全泄漏。


<details>
  <summary>Details</summary>
Motivation: 在动物医学领域，电子健康记录包含敏感标识，限制数据二次利用；现有去标识基准PetEVAL资源有限，需探索合成数据是否能提升去标识安全性能。

Method: 使用LLM生成隐私保护式的「模板唯读」合成病历，对PetEVAL衍生语料（3750个测试样本、1249个训练样本）进行三种Transformer架构（PetBERT、VetBERT、Bio_ClinicalBERT）的训练；通过不同训练混合与可用计算量匹配来评估文档级泄漏率。

Result: 在合成置换实验中，替换率越高泄漏率越上升；在计算匹配条件下，适度合成混合可与仅用真实数据相当，高比例合成则性能下降；而按阶段扩增混合可提升PetBERT Span-overlap F1至0.850并把泄漏率降至4.02%。但提升多数来自样本量增多，而非合成质量本身。实验发现合成与真实记录在文本长度、标签分布等方面存在系统性差异，导致持续泄漏。

Conclusion: 本研究证明合成数据对于扩展训练曝光有效，但并不能替代真实数据以保障动物电子健康记录的去标识安全；合成补充使用可降低泄漏率，而单纯置换则可能使泄漏显著增加。

Abstract: Veterinary electronic health records (vEHRs) contain privacy-sensitive identifiers that limit secondary use. While PetEVAL provides a benchmark for veterinary de-identification, the domain remains low-resource. This study evaluates whether large language model (LLM)-generated synthetic narratives improve de-identification safety under distinct training regimes, emphasizing (i) synthetic augmentation and (ii) fixed-budget substitution. We conducted a controlled simulation using a PetEVAL-derived corpus (3,750 holdout/1,249 train). We generated 10,382 synthetic notes using a privacy-preserving "template-only" regime where identifiers were removed prior to LLM prompting. Three transformer backbones (PetBERT, VetBERT, Bio_ClinicalBERT) were trained under varying mixtures. Evaluation prioritized document-level leakage rate (the fraction of documents with at least one missed identifier) as the primary safety outcome. Results show that under fixed-sample substitution, replacing real notes with synthetic ones monotonically increased leakage, indicating synthetic data cannot safely replace real supervision. Under compute-matched training, moderate synthetic mixing matched real-only performance, but high synthetic dominance degraded utility. Conversely, epoch-scaled augmentation improved performance: PetBERT span-overlap F1 increased from 0.831 to 0.850 +/- 0.014, and leakage decreased from 6.32% to 4.02% +/- 0.19%. However, these gains largely reflect increased training exposure rather than intrinsic synthetic data quality. Corpus diagnostics revealed systematic synthetic-real mismatches in note length and label distribution that align with persistent leakage. We conclude that synthetic augmentation is effective for expanding exposure but is complementary, not substitutive, for safety-critical veterinary de-identification.

</details>


### [31] [A Risk-Stratified Benchmark Dataset for Bad Randomness (SWC-120) Vulnerabilities in Ethereum Smart Contracts](https://arxiv.org/abs/2601.09836)
*Hadis Rezaei,Rahim Taheri,Francesco Palmieri*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Many Ethereum smart contracts rely on block attributes such as block.timestamp or blockhash to generate random numbers for applications like lotteries and games. However, these values are predictable and miner-manipulable, creating the Bad Randomness vulnerability (SWC-120) that has led to real-world exploits. Current detection tools identify only simple patterns and fail to verify whether protective modifiers actually guard vulnerable code. A major obstacle to improving these tools is the lack of large, accurately labeled datasets. This paper presents a benchmark dataset of 1,752 Ethereum smart contracts with validated Bad Randomness vulnerabilities. We developed a five-phase methodology comprising keyword filtering, pattern matching with 58 regular expressions, risk classification, function-level validation, and context analysis. The function-level validation revealed that 49% of contracts initially classified as protected were actually exploitable because modifiers were applied to different functions than those containing vulnerabilities. We classify contracts into four risk levels based on exploitability: HIGH_RISK (no protection), MEDIUM_RISK (miner-exploitable only), LOW_RISK (owner-exploitable only), and SAFE (using Chainlink VRF or commit-reveal). Our dataset is 51 times larger than RNVulDet and the first to provide function-level validation and risk stratification. Evaluation of Slither and Mythril revealed significant detection gaps, as both tools identified none of the vulnerable contracts in our sample, indicating limitations in handling complex randomness patterns. The dataset and validation scripts are publicly available to support future research in smart contract security.

</details>


### [32] [AmbShield: Enhancing Physical Layer Security with Ambient Backscatter Devices against Eavesdroppers](https://arxiv.org/abs/2601.09867)
*Yifan Zhang,Yishan Yang,Riku Jäntti,Zheng Yan,Dusit Niyato,Zhu Han*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Passive eavesdropping compromises confidentiality in wireless networks, especially in resource-constrained environments where heavyweight cryptography is impractical. Physical layer security (PLS) exploits channel randomness and spatial selectivity to confine information to an intended receiver with modest overhead. However, typical PLS techniques, such as using beamforming, artificial noise, and reconfigurable intelligent surfaces, often involve added active power or specialized deployment, and, in many designs, rely on precise time synchronization and perfect CSI estimation, which limits their practicality. To this end, we propose AmbShield, an AmBD-assisted PLS scheme that leverages naturally distributed AmBDs to simultaneously strengthen the legitimate channel and degrade eavesdroppers' without requiring extra transmit power and with minimal deployment overhead. In AmbShield, AmBDs are exploited as friendly jammers that randomly backscatter to create interference at eavesdroppers, and as passive relays that backscatter the desired signal to enhance the capacity of legitimate devices. We further develop a unified analytical framework that analyzes the exact probability density function (PDF) and cumulative distribution function (CDF) of legitimate and eavesdropper signal-to-interference-noise ratio (SINR), and a closed-form secrecy outage probability (SOP). The analysis provides clear design guidelines on various practical system parameters to minimize SOP. Extensive experiments that include Monte Carlo simulations, theoretical derivations, and high-SNR asymptotic analysis demonstrate the security gains of AmbShield across diverse system parameters under imperfect synchronization and CSI estimation.

</details>


### [33] [A Novel Contrastive Loss for Zero-Day Network Intrusion Detection](https://arxiv.org/abs/2601.09902)
*Jack Wilkie,Hanan Hindy,Craig Michie,Christos Tachtatzis,James Irvine,Robert Atkinson*

Main category: cs.CR

TL;DR: 提出对比损失函数，兼顾学习正常分布与已知恶意，显著提高零日攻击检测和开放集识别性能。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法在已知攻击类上表现优异，但面对零日攻击性能大幅下降；异常检测虽能泛化但误报率极高。因而需要一种兼顾鲁棒性与泛化能力的新方法。

Method: 利用对比损失函数，将正常流量与已知恶意样本共同用于学习正负样本对，进行对比学习；生成的模型能学习正常流量的分布并对未知攻击保持鲁棒性。

Result: 在 Lycos2017 数据集上，对比损失模型在已知攻击的 AUROC 提升了 0.000065，零日攻击提升了 0.060883；在开放集识别任务中，OpenAUC 提升 0.170883。

Conclusion: 本文提出了一种新型对比损失函数，能够在保持对比学习鲁棒性的同时泛化到零日攻击，显著提升入侵检测系统在已知攻击和零日攻击下的性能。

Abstract: Machine learning has achieved state-of-the-art results in network intrusion detection; however, its performance significantly degrades when confronted by a new attack class -- a zero-day attack. In simple terms, classical machine learning-based approaches are adept at identifying attack classes on which they have been previously trained, but struggle with those not included in their training data. One approach to addressing this shortcoming is to utilise anomaly detectors which train exclusively on benign data with the goal of generalising to all attack classes -- both known and zero-day. However, this comes at the expense of a prohibitively high false positive rate. This work proposes a novel contrastive loss function which is able to maintain the advantages of other contrastive learning-based approaches (robustness to imbalanced data) but can also generalise to zero-day attacks. Unlike anomaly detectors, this model learns the distributions of benign traffic using both benign and known malign samples, i.e. other well-known attack classes (not including the zero-day class), and consequently, achieves significant performance improvements. The proposed approach is experimentally verified on the Lycos2017 dataset where it achieves an AUROC improvement of .000065 and .060883 over previous models in known and zero-day attack detection, respectively. Finally, the proposed method is extended to open-set recognition achieving OpenAUC improvements of .170883 over existing approaches.

</details>


### [34] [SoK: Privacy-aware LLM in Healthcare: Threat Model, Privacy Techniques, Challenges and Recommendations](https://arxiv.org/abs/2601.10004)
*Mohoshin Ara Tahera,Karamveer Singh Sidhu,Shuvalaxmi Dass,Sajal Saha*

Main category: cs.CR

TL;DR: LLM在医疗中应用导致隐私与安全风险，本文构建跨阶段威胁模型并评估现有隐私技术，发现局限并给出针对性改进建议，构建安全可靠AI体系。


<details>
  <summary>Details</summary>
Motivation: 在医疗领域日益广泛采用大语言模型（LLMs）来支持临床决策、总结电子健康记录（EHR）并提升患者护理质量，但由于临床数据的高度敏感性与医疗工作流程的高风险性，整合LLM带来了重大的隐私与安全挑战。

Method: 本文通过系统知识整理（SoK）方法，构建了三大核心LLM阶段（数据预处理、微调、推理）的威胁模型，详述各阶段的攻击面、对手能力，并针对性地梳理现有隐私保护技术（PPTs）的应对措施。

Result: 研究揭示，在不同规模与法规环境下，现有防御手段仍存在显著局限，无法彻底保障临床数据安全；同时提供了针对各阶段的改进建议，推进可信医疗AI的实现。

Conclusion: LLMs在医疗领域的成功部署需从威胁角度系统评估，改进隐私保护体系，形成适用于多层次运营环境的安全保障路线图。

Abstract: Large Language Models (LLMs) are increasingly adopted in healthcare to support clinical decision-making, summarize electronic health records (EHRs), and enhance patient care. However, this integration introduces significant privacy and security challenges, driven by the sensitivity of clinical data and the high-stakes nature of medical workflows. These risks become even more pronounced across heterogeneous deployment environments, ranging from small on-premise hospital systems to regional health networks, each with unique resource limitations and regulatory demands. This Systematization of Knowledge (SoK) examines the evolving threat landscape across the three core LLM phases: Data preprocessing, Fine-tuning, and Inference within realistic healthcare settings. We present a detailed threat model that characterizes adversaries, capabilities, and attack surfaces at each phase, and we systematize how existing privacy-preserving techniques (PPTs) attempt to mitigate these vulnerabilities. While existing defenses show promise, our analysis identifies persistent limitations in securing sensitive clinical data across diverse operational tiers. We conclude with phase-aware recommendations and future research directions aimed at strengthening privacy guarantees for LLMs in regulated environments. This work provides a foundation for understanding the intersection of LLMs, threats, and privacy in healthcare, offering a roadmap toward more robust and clinically trustworthy AI systems.

</details>


### [35] [Privacy Enhanced PEFT: Tensor Train Decomposition Improves Privacy Utility Tradeoffs under DP-SGD](https://arxiv.org/abs/2601.10045)
*Pradip Kunwar,Minh Vu,Maanak Gupta,Manish Bhattarai*

Main category: cs.CR

TL;DR: 采用Tensor Train适配器 TTLoRA 与精确的DP-SGD，可在保持模型性能的同时大幅提升隐私安全，成为参数高效微调的实用方案。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在敏感数据上的微调易受成员推断攻击; 传统DP与LoRA结合导致效用下降，需要更高效的结构化PEFT方案以减小参数空间并保持表达力。

Method: 构造了Tensor Train 低秩适配器TTLoRA，并延伸ghost clipping 以支持Tensor Train核心的精确梯度范数计算，实现无完整梯度副本的DP-SGD训练。

Result: 在GPT‑2 微调 Enron 与 Penn Treebank 上，TTLoRA-DP 的隐私保护性能优于 LoRA-DP，且下游任务表现相当或更好；不使用DP时 TTLoRA 也能降低成员泄漏、参数规模约为 LoRA 的 1/7.6。

Conclusion: TTLoRA-DP在参数高效微调中实现了更优的隐私-效用权衡，相比LoRA-DP在攻击下更强的隐私保护且保持甚至提升后续任务性能。

Abstract: Fine-tuning large language models on sensitive data poses significant privacy risks, as membership inference attacks can reveal whether individual records were used during training. While Differential Privacy (DP) provides formal protection, applying DP to conventional Parameter-Efficient Fine-Tuning (PEFT) methods such as Low-Rank Adaptation (LoRA) often incurs substantial utility loss. In this work, we show that a more structurally constrained PEFT architecture, Tensor Train Low-Rank Adaptation (TTLoRA), can improve the privacy-utility tradeoff by shrinking the effective parameter space while preserving expressivity. To this end, we develop TTLoRA-DP, a differentially private training framework for TTLoRA. Specifically, we extend the ghost clipping algorithm to Tensor Train cores via cached contraction states, enabling efficient Differentially Private Stochastic Gradient Descent (DP-SGD) with exact per-example gradient norm computation without materializing full per-example gradients. Experiments on GPT-2 fine-tuning over the Enron and Penn Treebank datasets show that TTLoRA-DP consistently strengthens privacy protection relative to LoRA-DP while maintaining comparable or better downstream utility. Moreover, TTLoRA exhibits lower membership leakage even without DP training, using substantially smaller adapters and requiring on average 7.6X fewer parameters than LoRA. Overall, our results demonstrate that TTLoRA offers a practical path to improving the privacy-utility tradeoff in parameter-efficient language model adaptation.

</details>


### [36] [Fuzzychain-edge: A novel Fuzzy logic-based adaptive Access control model for Blockchain in Edge Computing](https://arxiv.org/abs/2601.10105)
*Khushbakht Farooq,Muhammad Ibrahim,Irsa Manzoor,Mukhtaj Khan,Wei Song*

Main category: cs.CR

TL;DR: Fuzzychain-edge 通过零知识证明、模糊逻辑与区块链智能合约实现可适应的隐私保护访问控制，降低 IoT 细分域的安全风险并提供透明审计。


<details>
  <summary>Details</summary>
Motivation: 在医疗等敏感领域，IoT 与边缘计算的快速融合带来实时数据共享与远程监控，但传统集中式安全体系难以保障数据隐私与防止未经授权访问；亟需新型分布式、可适应的访问控制模型。

Method: 提出 Fuzzychain-edge——融合零知识证明（ZKP）、模糊逻辑与智能合约的区块链边缘访问控制框架：ZKP 在验证时隐藏敏感信息；模糊逻辑依据数据敏感度、信任等级、角色等上下文动态评估访问权；区块链提供透明不可篡改的审计链，智能合约自动执行访问规则。

Result: 预期提升数据隐私保护水平、访问控制准确性、降低未经授权访问风险，并通过不可篡改的审计记录增强用户信任。

Conclusion: 为 IoT 边缘计算环境提供了安全、可追溯且隐私友好的访问控制解决方案，为医疗等关键领域的分布式技术创新奠定基础。

Abstract: The rapid integration of IoT with edge computing has revolutionized various domains, particularly healthcare, by enabling real-time data sharing, remote monitoring, and decision-making. However, it introduces critical challenges, including data privacy breaches, security vulnerabilities, especially in environments dealing with sensitive information. Traditional access control mechanisms and centralized security systems do not address these issues, leaving IoT environments exposed to unauthorized access and data misuse. This research proposes Fuzzychain-edge, a novel Fuzzy logic-based adaptive Access control model for Blockchain in Edge Computing framework designed to overcome these limitations by incorporating Zero-Knowledge Proofs (ZKPs), fuzzy logic, and smart contracts. ZKPs secure sensitive data during access control processes by enabling verification without revealing confidential details, thereby ensuring user privacy. Fuzzy logic facilitates adaptive, context-aware decision-making for access control by dynamically evaluating parameters such as data sensitivity, trust levels, and user roles. Blockchain technology, with its decentralized and immutable architecture, ensures transparency, traceability, and accountability using smart contracts that automate access control processes. The proposed framework addresses key challenges by enhancing security, reducing the likelihood of unauthorized access, and providing a transparent audit trail of data transactions. Expected outcomes include improved data privacy, accuracy in access control, and increased user trust in IoT systems. This research contributes significantly to advancing privacy-preserving, secure, and traceable solutions in IoT environments, laying the groundwork for future innovations in decentralized technologies and their applications in critical domains such as healthcare and beyond.

</details>


### [37] [Advanced Encryption Technique for Multimedia Data Using Sudoku-Based Algorithms for Enhanced Security](https://arxiv.org/abs/2601.10119)
*Mithil Bavishi,Anuj Bohra,Kushal Vadodaria,Abhinav Bohra,Neha Katre,Ramchandra Mangrulkar,Vinaya Sawant*

Main category: cs.CR

TL;DR: 基于时戳的数独块加密，支持图像/音频/视频；NPCR≈100%，SNR>60dB，具备极强的暴力破解和差分攻击抵抗力。


<details>
  <summary>Details</summary>
Motivation: 传统数独加密仅限图像，缺乏对音视频等多媒体的适用性；同时密钥静态生成易被预测。

Method: 首先构建数独块结构进行块级置换，再对每个块做XOR或其它代替方法；密钥由发送时间戳动态生成；整体实现为多模态二进制块置换-代替加密链。

Result: 图像的NPCR接近100%，音频的SNR>60dB，显示出高差异性与抗攻击性能。

Conclusion: 该研究提出了一种基于数独的多模态加密系统，能够应用于图像、音频和视频，并通过时间戳-依赖的密钥生成来提升安全性；实验表明，该系统对暴力破解和差分攻击具有很高的鲁棒性。

Abstract: Encryption and Decryption is the process of sending a message in a ciphered way that appears meaningless and could be deciphered using a key for security purposes to avoid data breaches. This paper expands on the previous work on Sudoku-based encryption methods, applying it to other forms of media including images, audio and video. It also enhances the security of key generation and usage by making it dependent on the timestamp of when the message was transmitted. It is a versatile system that works on multimodal data and functions as a block-based transposition cipher. Instead of shuffling, it can also employ substitution methods like XOR, making it a substitution cipher. The resulting media are highly encrypted and resilient to brute-force and differential attacks. For images, NPCR values approach 100% and for audio, SNR values exceed 60dB. This makes the encrypted audio significantly different from the source, making decryption more difficult.

</details>


### [38] [PADER: Paillier-based Secure Decentralized Social Recommendation](https://arxiv.org/abs/2601.10212)
*Chaochao Chen,Jiaming Qian,Fei Zheng,Yachuan Liu*

Main category: cs.CR

TL;DR: PADER：基于Paillier的高效去中心化社交推荐，可在保持数据隐私的同时，实现秒级用户迭代与低时长全局训练。


<details>
  <summary>Details</summary>
Motivation: 在中心化推荐系统普及的背景下，用户与卖家的隐私泄露风险日益突出，迫切需要一种在不依赖中央平台的情况下安全训练与推理的去中心化推荐框架。

Method: 采用Paillier密码体系对Social Regularization（SoReg）模型进行安全多方计算，将其转化为两方安全多项式评估，随后设计了支持任意算术电路的安全加减乘协议，并引入最优数据打包方案以提升多项式计算效率。

Result: 实验表明，PADER在单用户迭代时仅需约1秒，约50万条评分一个epoch的训练耗时不足3小时，显示出在真实业务场景中的可行性。

Conclusion: PADER通过Paillier加密实现了无中央平台的去中心化社交推荐系统，既保障了用户与卖家数据隐私，又能保持可接受的推理与训练效率。

Abstract: The prevalence of recommendation systems also brings privacy concerns to both the users and the sellers, as centralized platforms collect as much data as possible from them. To keep the data private, we propose PADER: a Paillier-based secure decentralized social recommendation system. In this system, the users and the sellers are nodes in a decentralized network. The training and inference of the recommendation model are carried out securely in a decentralized manner, without the involvement of a centralized platform. To this end, we apply the Paillier cryptosystem to the SoReg (Social Regularization) model, which exploits both user's ratings and social relations. We view the SoReg model as a two-party secure polynomial evaluation problem and observe that the simple bipartite computation may result in poor efficiency. To improve efficiency, we design secure addition and multiplication protocols to support secure computation on any arithmetic circuit, along with an optimal data packing scheme that is suitable for the polynomial computations of real values. Experiment results show that our method only takes about one second to iterate through one user with hundreds of ratings, and training with ~500K ratings for one epoch only takes <3 hours, which shows that the method is practical in real applications. The code is available at https://github.com/GarminQ/PADER.

</details>


### [39] [XuanJia: A Comprehensive Virtualization-Based Code Obfuscator for Binary Protection](https://arxiv.org/abs/2601.10261)
*Xianyu Zou,Xiaoli Gong,Jin Zhang,Shiyang Li,Pen-Chung Yew*

Main category: cs.CR

TL;DR: XuanJia 通过虚拟机与阴影 unwind 机制，在不破坏 ABI 的前提下，对异常处理元数据进行完全加密，显著提升逆向难度，并保持低额外开销。


<details>
  <summary>Details</summary>
Motivation: 现行的基于虚拟化的二进制混淆在保持 ABI 兼容性时，往往保留异常处理元数据，导致大量结构化信息泄露，可被利用来加速逆向工程；因此迫切需要既能盖住这些元数据，又不破坏兼容性的保护方案。

Method: 采用基于虚拟机的完整二进制混淆框架，并提出了 ABI‑Compatible EH Shadowing 机制：用兼容 ABI 的阴影 unwind 信息替代原始 EH 元数据，保持操作系统求解器正常工作；随后将异常处理流程重定向到受保护的虚拟机中，在该 VM 内对真实 EH 语义进行解密、反混淆、重播，使用经过混淆的代码完成真正的异常处理。

Result: 在 385 条 x86 指令编码、155 个 VM 处理器模板上实现的 XuanJia，经扩展扩容后，占用空间无显著增大；动态与符号化测试验证保持语义等价；对 IDA Pro 之类的逆向工具产生显著干扰；运行时开销仅为 2‑3 % 左右，空间占用仅增 5 %。

Conclusion: XuanJia 成功实现了对异常处理语义的强劲保护，同时保持 ABI 兼容性、语义等价性和实际可用性；实验表明在保持极低空间占用、适度运行时开销的前提下，能够有效破坏自动化逆向工具的功能。

Abstract: Virtualization-based binary obfuscation is widely adopted to protect software intellectual property, yet existing approaches leave exception-handling (EH) metadata unprotected to preserve ABI compatibility. This exposed metadata leaks rich structural information, such as stack layouts, control-flow boundaries, and object lifetimes, which can be exploited to facilitate reverse engineering. In this paper, we present XuanJia, a comprehensive VM-based binary obfuscation framework that provides end-to-end protection for both executable code and exception-handling semantics. At the core of XuanJia is ABI-Compliant EH Shadowing, a novel exception-aware protection mechanism that preserves compatibility with unmodified operating system runtimes while eliminating static EH metadata leakage. XuanJia replaces native EH metadata with ABI-compliant shadow unwind information to satisfy OS-driven unwinding, and securely redirects exception handling into a protected virtual machine where the genuine EH semantics are decrypted, reversed, and replayed using obfuscated code. We implement XuanJia from scratch, supporting 385 x86 instruction encodings and 155 VM handler templates, and design it as an extensible research testbed. We evaluate XuanJia across correctness, resilience, and performance dimensions. Our results show that XuanJia preserves semantic equivalence under extensive dynamic and symbolic testing, effectively disrupts automated reverse-engineering tools such as IDA Pro, and incurs negligible space overhead and modest runtime overhead. These results demonstrate that XuanJia achieves strong protection of exception-handling logic without sacrificing correctness or practicality.

</details>


### [40] [Reasoning Hijacking: Subverting LLM Classification via Decision-Criteria Injection](https://arxiv.org/abs/2601.10294)
*Yuansen Liu,Yixuan Tang,Anthony Kum Hoe Tun*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Current LLM safety research predominantly focuses on mitigating Goal Hijacking, preventing attackers from redirecting a model's high-level objective (e.g., from "summarizing emails" to "phishing users"). In this paper, we argue that this perspective is incomplete and highlight a critical vulnerability in Reasoning Alignment. We propose a new adversarial paradigm: Reasoning Hijacking and instantiate it with Criteria Attack, which subverts model judgments by injecting spurious decision criteria without altering the high-level task goal. Unlike Goal Hijacking, which attempts to override the system prompt, Reasoning Hijacking accepts the high-level goal but manipulates the model's decision-making logic by injecting spurious reasoning shortcut. Though extensive experiments on three different tasks (toxic comment, negative review, and spam detection), we demonstrate that even newest models are prone to prioritize injected heuristic shortcuts over rigorous semantic analysis. The results are consistent over different backbones. Crucially, because the model's "intent" remains aligned with the user's instructions, these attacks can bypass defenses designed to detect goal deviation (e.g., SecAlign, StruQ), exposing a fundamental blind spot in the current safety landscape. Data and code are available at https://github.com/Yuan-Hou/criteria_attack

</details>


### [41] [Hybrid Encryption with Certified Deletion in Preprocessing Model](https://arxiv.org/abs/2601.10542)
*Kunal Dey,Reihaneh Safavi-Naini*

Main category: cs.CR

TL;DR: 本研究提出预处理模型下的混合加密框架，提供信息理论和永恒认证删除方案，兼顾任意长度加密与量子安全，且密钥长度低于消息长度。


<details>
  <summary>Details</summary>
Motivation: 传统基于一次性密码或计算假设的认证删除无法兼顾信息理论删除与未来计算安全；需求一个既能无可逆删除又兼顾安全且对量子计算友好的方案。

Method: 提出预处理模型下的混合加密框架pHE-CD；设计两种构造，分别使用信息理论密钥封装机制（iKEM）与提供认证删除的数据封装机制（DEM-CD）——一方案实现信息理论认证删除，另一方案在删除前计算安全、删除后信息理论安全。

Result: 构造出两套pHE-CD方案：①信息理论认证删除方案；②永恒认证删除方案；二者均满足IND‑q_e‑CPA安全，并能加密任意长度信息。第二套方案利用量子安全的DEM-CD实现短密钥量子安全编码。

Conclusion: 混合加密与认证删除在预处理模型下提供信息理论级别的删除安全，支持任意长度消息，并能实现计算上安全但删除后信息理论安全的方案；同时通过量子安全的DEM-CD实现短密钥量子安全加密。

Abstract: Certified deletion allows Alice to outsource data to Bob and, at a later time, obtain a verifiable guarantee that the file has been irreversibly deleted at her request. The functionality, while impossible using classical information alone, can be achieved using quantum information. Existing approaches, rely on one-time pad (OTP) encryption, or use computational hardness assumptions that may be vulnerable to future advances in classical or quantum computing. In this work, we introduce and formalize hybrid encryption with certified deletion in the preprocessing model (pHE-CD) and propose two constructions. The constructions combine an information-theoretic key encapsulation mechanism (iKEM) with a data encapsulation mechanism that provides certified deletion (DEM-CD) and, respectively, provide {\em information-theoretic certified deletion}, where both confidentiality and deletion properties are provided against a computationally unbounded adversary; and {\em everlasting certified deletion}, where confidentiality is computational before deletion, and upon successful verification of the deletion certificate, the message becomes information-theoretically hidden from an adversary that is computationally unbounded. Our pHE-CD schemes provide IND-$q_e$-CPA notion of security and support encryption of arbitrarily long messages. In the second construction, using a computationally secure DEM-CD that is quantum-safe (i.e. constructed using quantum coding and AES), we obtain quantum-safe security with keys that are significantly shorter than the message. Instantiating the proposed framework using quantum enabled kem (qKEM) as the iKEM, is a future work.

</details>


### [42] [Be Your Own Red Teamer: Safety Alignment via Self-Play and Reflective Experience Replay](https://arxiv.org/abs/2601.10589)
*Hao Wang,Yanting Wang,Hao Li,Rui Li,Lei Sha*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) have achieved remarkable capabilities but remain vulnerable to adversarial ``jailbreak'' attacks designed to bypass safety guardrails. Current safety alignment methods depend heavily on static external red teaming, utilizing fixed defense prompts or pre-collected adversarial datasets. This leads to a rigid defense that overfits known patterns and fails to generalize to novel, sophisticated threats. To address this critical limitation, we propose empowering the model to be its own red teamer, capable of achieving autonomous and evolving adversarial attacks. Specifically, we introduce Safety Self- Play (SSP), a system that utilizes a single LLM to act concurrently as both the Attacker (generating jailbreaks) and the Defender (refusing harmful requests) within a unified Reinforcement Learning (RL) loop, dynamically evolving attack strategies to uncover vulnerabilities while simultaneously strengthening defense mechanisms. To ensure the Defender effectively addresses critical safety issues during the self-play, we introduce an advanced Reflective Experience Replay Mechanism, which uses an experience pool accumulated throughout the process. The mechanism employs a Upper Confidence Bound (UCB) sampling strategy to focus on failure cases with low rewards, helping the model learn from past hard mistakes while balancing exploration and exploitation. Extensive experiments demonstrate that our SSP approach autonomously evolves robust defense capabilities, significantly outperforming baselines trained on static adversarial datasets and establishing a new benchmark for proactive safety alignment.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [43] [Social Determinants of Health Prediction for ICD-9 Code with Reasoning Models](https://arxiv.org/abs/2601.09709)
*Sharim Khan,Paul Landes,Adam Cross,Jimeng Sun*

Main category: cs.LG

TL;DR: 研究使用大型语言模型和推理模型对MIMIC-III住院记录进行社会决定因素ICD-9多标签分类，取得89% F1，并发现部分记录缺失SDoH编码，提供复现代码。


<details>
  <summary>Details</summary>
Motivation: 社会决定因素与患者结果相关，但在结构化数据中很少被捕获。要通过临床文本自动提取这些标记，以补充基于诊断系统的知识。

Method: 利用MIMIC-III数据库的住院记录，借助现有ICD-9编码作为标注，训练大型语言模型（LLM）和推理模型以执行多标签分类，最终达到89%的F1得分。

Result: 在MIMIC-III数据集上，采用LLM和推理模型实现了89%的F1分数。进一步发现139份住院中缺少SDoH代码。

Conclusion: 文章证明使用大型语言模型和推理模型在MIMIC-III数据集上的住院多标签社会决定因素（SDoH）ICD-9编码分类可实现高质量预测，并指出目前在139份住院记录中缺失SDoH编码，提供了可复现的代码。

Abstract: Social Determinants of Health correlate with patient outcomes but are rarely captured in structured data. Recent attention has been given to automatically extracting these markers from clinical text to supplement diagnostic systems with knowledge of patients' social circumstances. Large language models demonstrate strong performance in identifying Social Determinants of Health labels from sentences. However, prediction in large admissions or longitudinal notes is challenging given long distance dependencies. In this paper, we explore hospital admission multi-label Social Determinants of Health ICD-9 code classification on the MIMIC-III dataset using reasoning models and traditional large language models. We exploit existing ICD-9 codes for prediction on admissions, which achieved an 89% F1. Our contributions include our findings, missing SDoH codes in 139 admissions, and code to reproduce the results.

</details>


### [44] [TimeSAE: Sparse Decoding for Faithful Explanations of Black-Box Time Series Models](https://arxiv.org/abs/2601.09776)
*Khalid Oublal,Quentin Bouniot,Qi Gan,Stephan Clémençon,Zeynep Akata*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As black box models and pretrained models gain traction in time series applications, understanding and explaining their predictions becomes increasingly vital, especially in high-stakes domains where interpretability and trust are essential. However, most of the existing methods involve only in-distribution explanation, and do not generalize outside the training support, which requires the learning capability of generalization. In this work, we aim to provide a framework to explain black-box models for time series data through the dual lenses of Sparse Autoencoders (SAEs) and causality. We show that many current explanation methods are sensitive to distributional shifts, limiting their effectiveness in real-world scenarios. Building on the concept of Sparse Autoencoder, we introduce TimeSAE, a framework for black-box model explanation. We conduct extensive evaluations of TimeSAE on both synthetic and real-world time series datasets, comparing it to leading baselines. The results, supported by both quantitative metrics and qualitative insights, show that TimeSAE provides more faithful and robust explanations. Our code is available in an easy-to-use library TimeSAE-Lib: https://anonymous.4open.science/w/TimeSAE-571D/.

</details>


### [45] [QFed: Parameter-Compact Quantum-Classical Federated Learning](https://arxiv.org/abs/2601.09809)
*Samar Abdelghani,Soumaya Cherkaoui*

Main category: cs.LG

TL;DR: 研究提出 QFed 框架，通过量子技术压缩模型参数，实验表明在联邦学习场景中能显著提升计算效率并保持准确率。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中分布式、异构数据导致的统计与系统异质性，以及传统模型高计算复杂度下的瓶颈需求。

Method: 构建 QFed 框架，结合量子计算对经典模型进行参数压缩，再在联邦环境下进行实验评估。

Result: 使用 FashionMNIST，QFed 将 VGG 类模型参数减少 77.6% ，同时保持可接受的精度，证明了在可扩展环境中实现高效训练的可行性。

Conclusion: 量子辅助联邦学习显著降低模型参数量，并保持与传统方法相当的准确率，凸显了量子计算在边缘设备联邦学习中的潜力。

Abstract: Organizations and enterprises across domains such as healthcare, finance, and scientific research are increasingly required to extract collective intelligence from distributed, siloed datasets while adhering to strict privacy, regulatory, and sovereignty requirements. Federated Learning (FL) enables collaborative model building without sharing sensitive raw data, but faces growing challenges posed by statistical heterogeneity, system diversity, and the computational burden from complex models. This study examines the potential of quantum-assisted federated learning, which could cut the number of parameters in classical models by polylogarithmic factors and thus lessen training overhead. Accordingly, we introduce QFed, a quantum-enabled federated learning framework aimed at boosting computational efficiency across edge device networks. We evaluate the proposed framework using the widely adopted FashionMNIST dataset. Experimental results show that QFed achieves a 77.6% reduction in the parameter count of a VGG-like model while maintaining an accuracy comparable to classical approaches in a scalable environment. These results point to the potential of leveraging quantum computing within a federated learning context to strengthen FL capabilities of edge devices.

</details>


### [46] [Eluder dimension: localise it!](https://arxiv.org/abs/2601.09825)
*Alireza Bakhtiari,Alex Ayoub,Samuel Robertson,David Janz,Csaba Szepesvári*

Main category: cs.LG

TL;DR: 本文通过局部化eluder维度方法，突破传统界限，首次得到有限时域强化学习的一次性损失上界，并提升伯努利赌博机分析。


<details>
  <summary>Details</summary>
Motivation: 传统基于eluder维度的分析无法实现一次性（first‑order）损失上界，而许多任务需要更强的性能保证。

Method: 在eluder维度分析中加入局部化技术，构造对模型类的更精细控制，进而得到更强的界限。

Result: 1) 证明广义线性模型类的eluder维度下界；2) 开发局部化方法，恢复并改进伯努利赌博机结果；3) 给出有限时域强化学习的首次真正一次性损失上界。

Conclusion: 证明了广义线性模型类的eluder维度下界，说明传统eluder维度分析无法获得一次性损失上界；通过引入eluder维度的局部化方法，可即时恢复并提升伯努利赌博机的经典结果，并首次为有限时域强化学习任务（具有有界累计回报）给出真正的一阶损失上界。

Abstract: We establish a lower bound on the eluder dimension of generalised linear model classes, showing that standard eluder dimension-based analysis cannot lead to first-order regret bounds. To address this, we introduce a localisation method for the eluder dimension; our analysis immediately recovers and improves on classic results for Bernoulli bandits, and allows for the first genuine first-order bounds for finite-horizon reinforcement learning tasks with bounded cumulative returns.

</details>


### [47] [A New Convergence Analysis of Plug-and-Play Proximal Gradient Descent Under Prior Mismatch](https://arxiv.org/abs/2601.09831)
*Guixian Xu,Jinglai Li,Junqi Tang*

Main category: cs.LG

TL;DR: 提出了在先验不匹配条件下PnP-PGD的收敛性证明，去除了传统理论的多项严格假设，提升了算法在实际场景中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 研究在先验不匹配情况下，Plug-and-Play Proximal Gradient Descent (PnP-PGD) 的收敛性，解决传统理论假设过于限制且难以验证的局限。

Method: 提出新的收敛理论，去除多项严格且不可验证的假设，对训练时的噪声消除器与推断任务的数据分布不一致的场景进行分析。

Result: 首次证明了在先验不匹配条件下PnP-PGD的收敛性，并与现有理论相比，显著降低了假设的严格性。

Conclusion: 该工作扩展了PnP-PGD的理论适用范围，为在实际应用中使用不同训练分布的去噪器提供了理论支持。

Abstract: In this work, we provide a new convergence theory for plug-and-play proximal gradient descent (PnP-PGD) under prior mismatch where the denoiser is trained on a different data distribution to the inference task at hand. To the best of our knowledge, this is the first convergence proof of PnP-PGD under prior mismatch. Compared with the existing theoretical results for PnP algorithms, our new results removed the need for several restrictive and unverifiable assumptions.

</details>


### [48] [A pipeline for enabling path-specific causal fairness in observational health data](https://arxiv.org/abs/2601.09841)
*Aparajita Kashyap,Sara Matijevic,Noémie Elhadad,Steven A. Kushner,Shalmali Joshi*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: When training machine learning (ML) models for potential deployment in a healthcare setting, it is essential to ensure that they do not replicate or exacerbate existing healthcare biases. Although many definitions of fairness exist, we focus on path-specific causal fairness, which allows us to better consider the social and medical contexts in which biases occur (e.g., direct discrimination by a clinician or model versus bias due to differential access to the healthcare system) and to characterize how these biases may appear in learned models. In this work, we map the structural fairness model to the observational healthcare setting and create a generalizable pipeline for training causally fair models. The pipeline explicitly considers specific healthcare context and disparities to define a target "fair" model. Our work fills two major gaps: first, we expand on characterizations of the "fairness-accuracy" tradeoff by detangling direct and indirect sources of bias and jointly presenting these fairness considerations alongside considerations of accuracy in the context of broadly known biases. Second, we demonstrate how a foundation model trained without fairness constraints on observational health data can be leveraged to generate causally fair downstream predictions in tasks with known social and medical disparities. This work presents a model-agnostic pipeline for training causally fair machine learning models that address both direct and indirect forms of healthcare bias.

</details>


### [49] [Queueing-Aware Optimization of Reasoning Tokens for Accuracy-Latency Trade-offs in LLM Servers](https://arxiv.org/abs/2601.10274)
*Emre Ozbas,Melih Bastopcu*

Main category: cs.LG

TL;DR: 研究在有限资源的LLM服务器上优化不同任务类型的令牌分配，打算在准确率和延迟之间寻求平衡。通过M/G/1队列建模并构建凹优化问题，得到唯一最优解，并给出可迭代求解方案。仿真验证了方案的有效性。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型服务中，需在有限计算资源内为不同类型查询分配不同的令牌，以平衡回答准确度与延迟，确保系统可稳定运行。

Method: 将系统建模为M/G/1排队，构造约束优化问题；证明目标函数在稳定域内严格凹；利用一阶最优条件推出投影固定点方程；设计投影梯度法求解；通过整数化得到可实现令牌分配。

Result: 得到了唯一的最优令牌分配；迭代算法及投影梯度法保证收敛；数值仿真验证了整数化对性能的影响，展示了分配策略的有效性。

Conclusion: 该研究证明了在有限令牌预算和队列稳定性条件下，通过对各任务类型分配思考令牌实现的准确率与系统响应时间的权衡，存在唯一最优解；并给出了求解该最优分配的迭代方法和梯度算法。

Abstract: We consider a single large language model (LLM) server that serves a heterogeneous stream of queries belonging to $N$ distinct task types. Queries arrive according to a Poisson process, and each type occurs with a known prior probability. For each task type, the server allocates a fixed number of internal thinking tokens, which determines the computational effort devoted to that query. The token allocation induces an accuracy-latency trade-off: the service time follows an approximately affine function of the allocated tokens, while the probability of a correct response exhibits diminishing returns. Under a first-in, first-out (FIFO) service discipline, the system operates as an $M/G/1$ queue, and the mean system time depends on the first and second moments of the resulting service-time distribution. We formulate a constrained optimization problem that maximizes a weighted average accuracy objective penalized by the mean system time, subject to architectural token-budget constraints and queue-stability conditions. The objective function is shown to be strictly concave over the stability region, which ensures existence and uniqueness of the optimal token allocation. The first-order optimality conditions yield a coupled projected fixed-point characterization of the optimum, together with an iterative solution and an explicit sufficient condition for contraction. Moreover, a projected gradient method with a computable global step-size bound is developed to guarantee convergence beyond the contractive regime. Finally, integer-valued token allocations are attained via rounding of the continuous solution, and the resulting performance loss is evaluated in simulation results.

</details>


### [50] [Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment](https://arxiv.org/abs/2601.09865)
*Jacob Sander,Brian Jalaian,Venkat R. Dasari*

Main category: cs.LG

TL;DR: 提出一种集成GPTQ量化、LoRA与数据蒸馏的框架，能够将LLM模型压缩50%并提升在边缘设备上的推理效率，同时保持甚至提升任务特定的性能。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署大语言模型受限于高计算、内存和能耗需求；同时需要获取任务专属数据、保留性能并压缩模型。

Method: 1) 通过GPTQ对模型进行量化； 2) 运用LoRA实现低秩重参数微调； 3) 采用基于KL散度的知识蒸馏 + 数据蒸馏进行数据集压缩； 4) 使用贝叶斯方法调参并部署Muon优化器进行优化。

Result: 在6GB模型压缩至3GB的同时，模型在标准LLM基准上表现优于单纯GPTQ；Mu优化器提升了量化后微调模型的抗精度衰减性能。

Conclusion: 提出一种结合GPTQ量化、LoRA低秩适配以及专门的数据蒸馏流程的综合框架，在保证或提升任务特定性能的同时，显著降低LLM模型的体积与计算复杂度；Mu速度优化器在保持量化后精度的同时显著提升微调模型的稳健性。

Abstract: Large Language Models (LLMs) enable advanced natural language processing but face deployment challenges on resource-constrained edge devices due to high computational, memory, and energy demands. Optimizing these models requires addressing three key challenges: acquiring task-specific data, fine-tuning for performance, and compressing models to accelerate inference while reducing resource demands. We propose an integrated framework combining GPTQ-based quantization, low-rank adaptation (LoRA), and a specialized data distillation process to significantly reduce model size and complexity while preserving or enhancing task-specific performance. By leveraging data distillation, knowledge distillation via Kullback-Leibler divergence, Bayesian hyperparameter optimization, and the Muon optimizer, our pipeline achieves up to 2x memory compression (e.g., reducing a 6GB model to 3GB) and enables efficient inference for specialized tasks. Empirical results demonstrate superior performance on standard LLM benchmarks compared to GPTQ quantization alone, with the Muon optimizer notably enhancing fine-tuned models' resistance to accuracy decay during quantization.

</details>


### [51] [The PROPER Approach to Proactivity: Benchmarking and Advancing Knowledge Gap Navigation](https://arxiv.org/abs/2601.09926)
*Kirandeep Kaur,Vinayak Gupta,Aditya Gupta,Chirag Shah*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Most language-based assistants follow a reactive ask-and-respond paradigm, requiring users to explicitly state their needs. As a result, relevant but unexpressed needs often go unmet. Existing proactive agents attempt to address this gap either by eliciting further clarification, preserving this burden, or by extrapolating future needs from context, often leading to unnecessary or mistimed interventions. We introduce ProPer, Proactivity-driven Personalized agents, a novel two-agent architecture consisting of a Dimension Generating Agent (DGA) and a Response Generating Agent (RGA). DGA, a fine-tuned LLM agent, leverages explicit user data to generate multiple implicit dimensions (latent aspects relevant to the user's task but not considered by the user) or knowledge gaps. These dimensions are selectively filtered using a reranker based on quality, diversity, and task relevance. RGA then balances explicit and implicit dimensions to tailor personalized responses with timely and proactive interventions. We evaluate ProPer across multiple domains using a structured, gap-aware rubric that measures coverage, initiative appropriateness, and intent alignment. Our results show that ProPer improves quality scores and win rates across all domains, achieving up to 84% gains in single-turn evaluation and consistent dominance in multi-turn interactions.

</details>


### [52] [Interpolation-Based Optimization for Enforcing lp-Norm Metric Differential Privacy in Continuous and Fine-Grained Domains](https://arxiv.org/abs/2601.09946)
*Chenxi Qiu*

Main category: cs.LG

TL;DR: 构建插值框架，对高维mDP进行高效近似优化，提升隐私和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有基于优化的方法在细粒度或连续域的mDP优化中由于构造稠密扰动矩阵及满足点点评价约束而计算昂贵。

Method: 在若干锚点上优化扰动分布，随后利用对数凸组合在非锚点处插值，并通过逐维序列化修正方法确保满足lp‑norm mDP。进一步对扰动分布与隐私预算在各维度上的联合分配进行最优优化。

Result: 在真实位置数据集上实验表明，所提方法在高维细粒度域中既保证了严谨的mDP隐私，也在实用性上优于基线机制。

Conclusion: 创新设计的插值框架实现了对Metric Differential Privacy在高维细粒度空间中的高效优化，保持了严格的隐私保证并显著提升了实用性。

Abstract: Metric Differential Privacy (mDP) generalizes Local Differential Privacy (LDP) by adapting privacy guarantees based on pairwise distances, enabling context-aware protection and improved utility. While existing optimization-based methods reduce utility loss effectively in coarse-grained domains, optimizing mDP in fine-grained or continuous settings remains challenging due to the computational cost of constructing dense perterubation matrices and satisfying pointwise constraints.
  In this paper, we propose an interpolation-based framework for optimizing lp-norm mDP in such domains. Our approach optimizes perturbation distributions at a sparse set of anchor points and interpolates distributions at non-anchor locations via log-convex combinations, which provably preserve mDP. To address privacy violations caused by naive interpolation in high-dimensional spaces, we decompose the interpolation process into a sequence of one-dimensional steps and derive a corrected formulation that enforces lp-norm mDP by design. We further explore joint optimization over perturbation distributions and privacy budget allocation across dimensions. Experiments on real-world location datasets demonstrate that our method offers rigorous privacy guarantees and competitive utility in fine-grained domains, outperforming baseline mechanisms. in high-dimensional spaces, we decompose the interpolation process into a sequence of one-dimensional steps and derive a corrected formulation that enforces lp-norm mDP by design. We further explore joint optimization over perturbation distributions and privacy budget allocation across dimensions. Experiments on real-world location datasets demonstrate that our method offers rigorous privacy guarantees and competitive utility in fine-grained domains, outperforming baseline mechanisms.

</details>


### [53] [Kinematic Tokenization: Optimization-Based Continuous-Time Tokens for Learnable Decision Policies in Noisy Time Series](https://arxiv.org/abs/2601.09949)
*Griffin Kearney*

Main category: cs.LG

TL;DR: 运动学标记化利用连续时间样条系数代替传统离散化，在含噪且具有不对称损失的时间序列学习中提升可学习性与决策校准。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer针对离散标记，而实际信号往往是受噪声影响的连续过程，离散化处理在噪声、极低信噪比以及带有不对称惩罚的下游任务中易失稳。

Method: 引入运动学标记化(Kinematic Tokenization)：通过优化在连续时间中重构样条曲线，并提取局部样条系数(位置、速度、加速度、滚动加速度)作为离散标记。

Result: 在多资产日均价测试中，使用风险厌恶不对称分类目标作为鲁棒可学习性基准。离散基线模型趋向现金持有（液化均衡），而连续样条标记维持了校准且非平凡的行动分布和稳定的策略。

Conclusion: 显式连续时间令牌可提升在噪声环境下，牵涉忽视惩罚的任务中的可学习性与策略稳定性。

Abstract: Transformers are designed for discrete tokens, yet many real-world signals are continuous processes observed through noisy sampling. Discrete tokenizations (raw values, patches, finite differences) can be brittle in low signal-to-noise regimes, especially when downstream objectives impose asymmetric penalties that rationally encourage abstention. We introduce Kinematic Tokenization, an optimization-based continuous-time representation that reconstructs an explicit spline from noisy measurements and tokenizes local spline coefficients (position, velocity, acceleration, jerk). This is applied to financial time series data in the form of asset prices in conjunction with trading volume profiles. Across a multi-asset daily-equity testbed, we use a risk-averse asymmetric classification objective as a stress test for learnability. Under this objective, several discrete baselines collapse to an absorbing cash policy (the Liquidation Equilibrium), whereas the continuous spline tokens sustain calibrated, non-trivial action distributions and stable policies. These results suggest that explicit continuous-time tokens can improve the learnability and calibration of selective decision policies in noisy time series under abstention-inducing losses.

</details>


### [54] [A Sustainable AI Economy Needs Data Deals That Work for Generators](https://arxiv.org/abs/2601.09966)
*Ruoxi Jia,Luis Oala,Wenjie Xiong,Suqin Ge,Jiachen T. Wang,Feiyang Kang,Dawn Song*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We argue that the machine learning value chain is structurally unsustainable due to an economic data processing inequality: each state in the data cycle from inputs to model weights to synthetic outputs refines technical signal but strips economic equity from data generators. We show, by analyzing seventy-three public data deals, that the majority of value accrues to aggregators, with documented creator royalties rounding to zero and widespread opacity of deal terms. This is not just an economic welfare concern: as data and its derivatives become economic assets, the feedback loop that sustains current learning algorithms is at risk. We identify three structural faults - missing provenance, asymmetric bargaining power, and non-dynamic pricing - as the operational machinery of this inequality. In our analysis, we trace these problems along the machine learning value chain and propose an Equitable Data-Value Exchange (EDVEX) Framework to enable a minimal market that benefits all participants. Finally, we outline research directions where our community can make concrete contributions to data deals and contextualize our position with related and orthogonal viewpoints.

</details>


### [55] [An Exploratory Study to Repurpose LLMs to a Unified Architecture for Time Series Classification](https://arxiv.org/abs/2601.09971)
*Hansen He,Shuheng Li*

Main category: cs.LG

TL;DR: Inception-based encoder + frozen LLM是最有效的Time Series Classification混合模型，其它编码器则效果受限。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在推理与泛化上表现优越，但在将时间序列映射到文本域的过程中，编码器架构的选择尚缺乏系统研究，需要探查其对Hybrid LLM架构的影响。

Method: 对多种时间序列编码器（Inception、卷积、残差、Transformer、MLP）与冻结的LLM骨干进行探索性实验，评估其在时间序列分类任务中的表现。

Result: 实验显示，除Inception模型外，其他编码器在混合LLM时表现不稳定或无显著提升；Inception在多种设置下均展现正向增益。

Conclusion: Inception模型在将大型语言模型(LM)与专门的时间序列编码器结合时能够持续提升性能，成为最有前景的架构方案。

Abstract: Time series classification (TSC) is a core machine learning problem with broad applications. Recently there has been growing interest in repurposing large language models (LLMs) for TSC, motivated by their strong reasoning and generalization ability. Prior work has primarily focused on alignment strategies that explicitly map time series data into the textual domain; however, the choice of time series encoder architecture remains underexplored. In this work, we conduct an exploratory study of hybrid architectures that combine specialized time series encoders with a frozen LLM backbone. We evaluate a diverse set of encoder families, including Inception, convolutional, residual, transformer-based, and multilayer perceptron architectures, among which the Inception model is the only encoder architecture that consistently yields positive performance gains when integrated with an LLM backbone. Overall, this study highlights the impact of time series encoder choice in hybrid LLM architectures and points to Inception-based models as a promising direction for future LLM-driven time series learning.

</details>


### [56] [In-Context Operator Learning on the Space of Probability Measures](https://arxiv.org/abs/2601.09979)
*Frank Cole,Dixi Wang,Yineng Chen,Yulong Lu,Rongjie Lai*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce \emph{in-context operator learning on probability measure spaces} for optimal transport (OT). The goal is to learn a single solution operator that maps a pair of distributions to the OT map, using only few-shot samples from each distribution as a prompt and \emph{without} gradient updates at inference. We parameterize the solution operator and develop scaling-law theory in two regimes. In the \emph{nonparametric} setting, when tasks concentrate on a low-intrinsic-dimension manifold of source--target pairs, we establish generalization bounds that quantify how in-context accuracy scales with prompt size, intrinsic task dimension, and model capacity. In the \emph{parametric} setting (e.g., Gaussian families), we give an explicit architecture that recovers the exact OT map in context and provide finite-sample excess-risk bounds. Our numerical experiments on synthetic transports and generative-modeling benchmarks validate the framework.

</details>


### [57] [FaTRQ: Tiered Residual Quantization for LLM Vector Search in Far-Memory-Aware ANNS Systems](https://arxiv.org/abs/2601.09985)
*Tianqi Zhang,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Approximate Nearest-Neighbor Search (ANNS) is a key technique in retrieval-augmented generation (RAG), enabling rapid identification of the most relevant high-dimensional embeddings from massive vector databases. Modern ANNS engines accelerate this process using prebuilt indexes and store compressed vector-quantized representations in fast memory. However, they still rely on a costly second-pass refinement stage that reads full-precision vectors from slower storage like SSDs. For modern text and multimodal embeddings, these reads now dominate the latency of the entire query. We propose FaTRQ, a far-memory-aware refinement system using tiered memory that eliminates the need to fetch full vectors from storage. It introduces a progressive distance estimator that refines coarse scores using compact residuals streamed from far memory. Refinement stops early once a candidate is provably outside the top-k. To support this, we propose tiered residual quantization, which encodes residuals as ternary values stored efficiently in far memory. A custom accelerator is deployed in a CXL Type-2 device to perform low-latency refinement locally. Together, FaTRQ improves the storage efficiency by 2.4$\times$ and improves the throughput by up to 9$ \times$ than SOTA GPU ANNS system.

</details>


### [58] [Continuous-Depth Transformers with Learned Control Dynamics](https://arxiv.org/abs/2601.10007)
*Peter Jemley*

Main category: cs.LG

TL;DR: 用连续深度ODE块和低维控制信号改造Transformer，实现实时、精确的语言生成属性调控，同时保持稳定的梯度、可解释的动力学结构以及与传统模型相当的效率。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer 的离散层限制了推理时对生成属性的实时控制，需要更灵活的层深表示；通过连续深度与控制信号可在不增加显著开销的前提下实现可调节的语言生成。

Method: 引入连续深度Neural ODE块，将层深视为连续变量，通过学习的向量场$F_θ(H, τ, u)$以及低维控制信号$u$实现推理时属性调控；使用自适应ODE求解器与附带的伴随法训练，保证零梯度爆炸/消失且内存O(1)。

Result: 1）梯度流稳定，无爆炸/消失；2）情感控制准确率98\%/88%；3）连续插值离散求解器仅0.068\%轨迹偏差；4）推理延迟与标准离散模型匹配；并揭示控制信号可分离向量场为不同曲率的动力学区间。

Conclusion: 连续深度动态与学习控制信号的混合Transformer架构可实现高效、可控的语言生成，并在稳定性、语义操控和计算效率方面与传统离散层架构相当。

Abstract: We present a hybrid transformer architecture that replaces discrete middle layers with a continuous-depth Neural Ordinary Differential Equation (ODE) block, enabling inference-time control over generation attributes via a learned steering signal. Unlike standard transformers that process representations through fixed discrete layers, our approach treats depth as a continuous variable governed by a learned vector field $F_θ(H, τ, u)$, where $u$ is a low-dimensional control signal injected via explicit concatenation. We validate the architecture through four experiments: (1) gradient flow stability with zero exploding/vanishing gradient events, (2) semantic steering achieving 98\%/88\% accuracy for positive/negative sentiment control, (3) continuous interpolation validated by a negligible 0.068\% trajectory divergence between fixed and adaptive solvers, and (4) efficiency benchmarking demonstrating latency parity with standard discrete baselines. Additionally, we show that adaptive ODE solvers reveal geometric structure in the learned dynamics: the control signal partitions the vector field into distinct dynamical regimes with different curvature characteristics. The adjoint method enables $O(1)$ memory training regardless of integration depth. Our results demonstrate that continuous-depth dynamics with learned control signals provide a viable, efficient mechanism for steerable language generation.

</details>


### [59] [Time Aggregation Features for XGBoost Models](https://arxiv.org/abs/2601.10019)
*Mykola Pinchuk*

Main category: cs.LG

TL;DR: 通过实验验证，追踪时间窗口可为 XGBoost 点击率模型带约 0.7% 以上的 AUC 提升，事件计数窗口在特定条件下可进一步提升，但总体更优的是追踪窗口


<details>
  <summary>Details</summary>
Motivation: 提升点击率预测模型对时间特征的捕捉，以获得更高的 AUC

Method: 使用 XGBoost 结合时序特征聚合，比较基本目标编码与不同时间窗口设计的效果（追踪窗口、事件计数窗口、间隙窗口、桶化窗口）

Result: 追踪窗口比目标编码提高 0.0066~0.0082 的 ROC AUC 与 0.0084~0.0094 的 PR AUC；事件计数窗口在某些设定下略有进一步提升，其他窗口不如追踪窗口表现

Conclusion: 在此数据集和协议下，追踪窗口为实用默认选择；若对 ROC AUC 的细微提升敏感，可考虑额外使用事件计数窗口

Abstract: This paper studies time aggregation features for XGBoost models in click-through rate prediction. The setting is the Avazu click-through rate prediction dataset with strict out-of-time splits and a no-lookahead feature constraint. Features for hour H use only impressions from hours strictly before H. This paper compares a strong time-aware target encoding baseline to models augmented with entity history time aggregation under several window designs. Across two rolling-tail folds on a deterministic ten percent sample, a trailing window specification improves ROC AUC by about 0.0066 to 0.0082 and PR AUC by about 0.0084 to 0.0094 relative to target encoding alone. Within the time aggregation design grid, event count windows provide the only consistent improvement over trailing windows, and the gain is small. Gap windows and bucketized windows underperform simple trailing windows in this dataset and protocol. These results support a practical default of trailing windows, with an optional event count window when marginal ROC AUC gains matter.

</details>


### [60] [BPE: Behavioral Profiling Ensemble](https://arxiv.org/abs/2601.10024)
*Yanxin Liu,Yunqi Zhang*

Main category: cs.LG

TL;DR: BPE利用模型自己的行为档案来动态给权重，既提升了集成性能，又降低了资源消耗。


<details>
  <summary>Details</summary>
Motivation: 传统静态和动态集成方法主要依据模型间的多样性进行整合，忽视了模型自身在不同实例空间区域的竞争力，且需要大量验证集来估计竞争力，导致效率低下。

Method: 构建每个基学习器的“行为特征档案”（Behavioral Profile），并根据模型对特定测试实例的输出与其行为档案的偏差来计算融合权重，从而实现基于模型自身特性的动态加权。

Result: 实验表明，BPE实现了更高的准确率，并在计算时间和存储资源占用方面优于最先进的集成方法。

Conclusion: BPE框架下推导出的算法在合成数据与真实数据上均显著优于现有堆叠与动态集成基线，提升了预测准确率、计算效率与存储利用率。

Abstract: Ensemble learning is widely recognized as a pivotal strategy for pushing the boundaries of predictive performance. Traditional static ensemble methods, such as Stacking, typically assign weights by treating each base learner as a holistic entity, thereby overlooking the fact that individual models exhibit varying degrees of competence across different regions of the instance space. To address this limitation, Dynamic Ensemble Selection (DES) was introduced. However, both static and dynamic approaches predominantly rely on the divergence among different models as the basis for integration. This inter-model perspective neglects the intrinsic characteristics of the models themselves and necessitates a heavy reliance on validation sets for competence estimation. In this paper, we propose the Behavioral Profiling Ensemble (BPE) framework, which introduces a novel paradigm shift. Unlike traditional methods, BPE constructs a ``behavioral profile'' intrinsic to each model and derives integration weights based on the deviation between the model's response to a specific test instance and its established behavioral profile. Extensive experiments on both synthetic and real-world datasets demonstrate that the algorithm derived from the BPE framework achieves significant improvements over state-of-the-art ensemble baselines. These gains are evident not only in predictive accuracy but also in computational efficiency and storage resource utilization across various scenarios.

</details>


### [61] [Unlabeled Data Can Provably Enhance In-Context Learning of Transformers](https://arxiv.org/abs/2601.10058)
*Renpu Liu,Jing Yang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) exhibit impressive in-context learning (ICL) capabilities, yet the quality of their predictions is fundamentally limited by the few costly labeled demonstrations that can fit into a prompt. Meanwhile, there exist vast and continuously growing amounts of unlabeled data that may be closely related to the ICL task. How to utilize such unlabeled data to provably enhance the performance of ICL thus becomes an emerging fundamental question. In this work, we propose a novel augmented ICL framework, in which the prompt includes a small set of labeled examples alongside a block of unlabeled inputs. We focus on the multi-class linear classification setting and demonstrate that, with chain-of-thought (CoT) prompting, a multi-layer transformer can effectively emulate an expectation-maximization (EM) algorithm. This enables the transformer to implicitly extract useful information from both labeled and unlabeled data, leading to provable improvements in ICL accuracy. Moreover, we show that such a transformer can be trained via teacher forcing, with its parameters converging to the desired solution at a linear rate. Experiments demonstrate that the augmented ICL framework consistently outperforms conventional few-shot ICL, providing empirical support for our theoretical findings. To the best of our knowledge, this is the first theoretical study on the impact of unlabeled data on the ICL performance of transformers.

</details>


### [62] [Fundamental Limitations of Favorable Privacy-Utility Guarantees for DP-SGD](https://arxiv.org/abs/2601.10237)
*Murat Bilgehan Ertan,Marten van Dijk*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Differentially Private Stochastic Gradient Descent (DP-SGD) is the dominant paradigm for private training, but its fundamental limitations under worst-case adversarial privacy definitions remain poorly understood. We analyze DP-SGD in the $f$-differential privacy framework, which characterizes privacy via hypothesis-testing trade-off curves, and study shuffled sampling over a single epoch with $M$ gradient updates. We derive an explicit suboptimal upper bound on the achievable trade-off curve. This result induces a geometric lower bound on the separation $κ$ which is the maximum distance between the mechanism's trade-off curve and the ideal random-guessing line. Because a large separation implies significant adversarial advantage, meaningful privacy requires small $κ$. However, we prove that enforcing a small separation imposes a strict lower bound on the Gaussian noise multiplier $σ$, which directly limits the achievable utility. In particular, under the standard worst-case adversarial model, shuffled DP-SGD must satisfy
  $σ\ge \frac{1}{\sqrt{2\ln M}}$ $\quad\text{or}\quad$ $κ\ge\ \frac{1}{\sqrt{8}}\!\left(1-\frac{1}{\sqrt{4π\ln M}}\right)$,
  and thus cannot simultaneously achieve strong privacy and high utility. Although this bound vanishes asymptotically as $M \to \infty$, the convergence is extremely slow: even for practically relevant numbers of updates the required noise magnitude remains substantial. We further show that the same limitation extends to Poisson subsampling up to constant factors. Our experiments confirm that the noise levels implied by this bound leads to significant accuracy degradation at realistic training settings, thus showing a critical bottleneck in DP-SGD under standard worst-case adversarial assumptions.

</details>


### [63] [Efficient Content-based Recommendation Model Training via Noise-aware Coreset Selection](https://arxiv.org/abs/2601.10067)
*Hung Vinh Tran,Tong Chen,Hechuan Wen,Quoc Viet Hung Nguyen,Bin Cui,Hongzhi Yin*

Main category: cs.LG

TL;DR: 在内容推荐系统中提出噪声感知coreset选择框架，通过梯度子模优化与噪声修正，将训练样本压缩至1%而实现93–95%性能恢复


<details>
  <summary>Details</summary>
Motivation: CRSs需海量持续训练导致高计算成本，传统coreset在噪声数据下易失真，亟需鲁棒性更强的方法

Method: 利用梯度子模优化生成coreset，并在训练过程中使用渐进模型修正噪声标签，随后通过不确定性量化过滤低置信度样本

Result: NaCS使用仅1%的数据即可恢复93–95%的全数据训练性能，优于现有coreset技术

Conclusion: NaCS在CRSs中生成高质量、规模小的coreset，显著提升效率并接近全数据训练效果

Abstract: Content-based recommendation systems (CRSs) utilize content features to predict user-item interactions, serving as essential tools for helping users navigate information-rich web services. However, ensuring the effectiveness of CRSs requires large-scale and even continuous model training to accommodate diverse user preferences, resulting in significant computational costs and resource demands. A promising approach to this challenge is coreset selection, which identifies a small but representative subset of data samples that preserves model quality while reducing training overhead. Yet, the selected coreset is vulnerable to the pervasive noise in user-item interactions, particularly when it is minimally sized. To this end, we propose Noise-aware Coreset Selection (NaCS), a specialized framework for CRSs. NaCS constructs coresets through submodular optimization based on training gradients, while simultaneously correcting noisy labels using a progressively trained model. Meanwhile, we refine the selected coreset by filtering out low-confidence samples through uncertainty quantification, thereby avoid training with unreliable interactions. Through extensive experiments, we show that NaCS produces higher-quality coresets for CRSs while achieving better efficiency than existing coreset selection techniques. Notably, NaCS recovers 93-95\% of full-dataset training performance using merely 1\% of the training data. The source code is available at \href{https://github.com/chenxing1999/nacs}{https://github.com/chenxing1999/nacs}.

</details>


### [64] [Comparative Evaluation of Deep Learning-Based and WHO-Informed Approaches for Sperm Morphology Assessment](https://arxiv.org/abs/2601.10070)
*Mohammad Abbadi*

Main category: cs.LG

TL;DR: 该研究开发并验证了HuSHeM深度学习模型，显示其在精子形态学评估中优于传统WHO+SIRI方法，可作为生育筛查中的决策支持工具。


<details>
  <summary>Details</summary>
Motivation: 现行精子形态学评估主观性强、受观察者差异和资源限制影响，急需客观、可复制的评估手段。

Method: 使用高分辨率精子形态图像训练HuSHeM深度学习模型，并在独立临床队列中通过ROC、PR、校准和决策曲线等方法与WHO(+SIRI)基线模型进行比较。

Result: HuSHeM模型实现更高AUC、精度-召回面积、校准一致性及在临床相关阈值下更高净收益，从而表明其在临床应用中的优势。

Conclusion: 图像深度学习模型HuSHeM在评估精子形态学质量方面表现优于基于WHO标准并配合系统炎症反应指数（SIRI）的传统规则模型，提供更高的判别、校准和临床效益，可作为辅助决策工具。

Abstract: Assessment of sperm morphological quality remains a critical yet subjective component of male fertility evaluation, often limited by inter-observer variability and resource constraints. This study presents a comparative biomedical artificial intelligence framework evaluating an image-based deep learning model (HuSHeM) alongside a clinically grounded baseline derived from World Health Organization criteria augmented with the Systemic Inflammation Response Index (WHO(+SIRI)).
  The HuSHeM model was trained on high-resolution sperm morphology images and evaluated using an independent clinical cohort. Model performance was assessed using discrimination, calibration, and clinical utility analyses. The HuSHeM model demonstrated higher discriminative performance, as reflected by an increased area under the receiver operating characteristic curve with relatively narrow confidence intervals compared to WHO(+SIRI). Precision-recall analysis further indicated improved performance under class imbalance, with higher precision-recall area values across evaluated thresholds. Calibration analysis indicated closer agreement between predicted probabilities and observed outcomes for HuSHeM, while decision curve analysis suggested greater net clinical benefit across clinically relevant threshold probabilities.
  These findings suggest that image-based deep learning may offer improved predictive reliability and clinical utility compared with traditional rule-based and inflammation-augmented criteria. The proposed framework supports objective and reproducible assessment of sperm morphology and may serve as a decision-support tool within fertility screening and referral workflows. The proposed models are intended as decision-support or referral tools and are not designed to replace clinical judgment or laboratory assessment.

</details>


### [65] [Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts](https://arxiv.org/abs/2601.10079)
*Sijia Luo,Xiaokang Zhang,Yuxuan Hu,Bohan Zhang,Ke Wang,Jinbo Su,Mengshu Sun,Lei Liang,Jing Zhang*

Main category: cs.LG

TL;DR: Sparse-RL 通过特定的稀疏采样和重加权技术，安全地压缩 KV 缓存，用于强化学习训练，克服政策不匹配，得到高效且鲁棒的模型。


<details>
  <summary>Details</summary>
Motivation: 在长周期强化学习中，存储键值缓存的巨大内存开销成为瓶颈；现有 KV 压缩在训练时引起严重的政策不匹配，导致性能崩溃。

Method: 采用稀疏感知拒绝采样及基于重要性的重加权，来纠正由于 KV 缓存压缩导致的离策略偏差。

Result: Sparse-RL 在与密集基线相比时显著降低回放开销，同时保持了性能，还在稀疏推理部署时提升了模型鲁棒性。

Conclusion: Sparse-RL 通过处理稀疏采样与学习策略之间的政策不匹配，提高了在稀疏回放下的强化学习训练稳定性，并在减少内存开销的同时保持了模型性能。

Abstract: Reinforcement Learning (RL) has become essential for eliciting complex reasoning capabilities in Large Language Models (LLMs). However, the substantial memory overhead of storing Key-Value (KV) caches during long-horizon rollouts acts as a critical bottleneck, often prohibiting efficient training on limited hardware. While existing KV compression techniques offer a remedy for inference, directly applying them to RL training induces a severe policy mismatch, leading to catastrophic performance collapse. To address this, we introduce Sparse-RL empowers stable RL training under sparse rollouts. We show that instability arises from a fundamental policy mismatch among the dense old policy, the sparse sampler policy, and the learner policy. To mitigate this issue, Sparse-RL incorporates Sparsity-Aware Rejection Sampling and Importance-based Reweighting to correct the off-policy bias introduced by compression-induced information loss. Experimental results show that Sparse-RL reduces rollout overhead compared to dense baselines while preserving the performance. Furthermore, Sparse-RL inherently implements sparsity-aware training, significantly enhancing model robustness during sparse inference deployment.

</details>


### [66] [Adaptive Label Error Detection: A Bayesian Approach to Mislabeled Data Detection](https://arxiv.org/abs/2601.10084)
*Zan Chaudhry,Noam H. Rotenberg,Brian Caffo,Craig K. Jones,Haris I. Sair*

Main category: cs.LG

TL;DR: ALED：提取CNN特征→去噪→多维高斯分类→似然比检测，能精准发现错误标签并显著提升模型准确率


<details>
  <summary>Details</summary>
Motivation: 现有训练标签错误会严重影响机器学习模型，需要一种灵活的错误检测方法

Method: 采用CNN提取中间特征，去噪后用多维高斯模型每类分布并进行似然比检验

Result: 在多组医学影像数据集上，ALED的灵敏度显著提高且精度不下降，纠正后模型测试误差下降33.8%

Conclusion: ALED能有效识别医学影像数据集中的标签错误，提升模型性能

Abstract: Machine learning classification systems are susceptible to poor performance when trained with incorrect ground truth labels, even when data is well-curated by expert annotators. As machine learning becomes more widespread, it is increasingly imperative to identify and correct mislabeling to develop more powerful models. In this work, we motivate and describe Adaptive Label Error Detection (ALED), a novel method of detecting mislabeling. ALED extracts an intermediate feature space from a deep convolutional neural network, denoises the features, models the reduced manifold of each class with a multidimensional Gaussian distribution, and performs a simple likelihood ratio test to identify mislabeled samples. We show that ALED has markedly increased sensitivity, without compromising precision, compared to established label error detection methods, on multiple medical imaging datasets. We demonstrate an example where fine-tuning a neural network on corrected data results in a 33.8% decrease in test set errors, providing strong benefits to end users. The ALED detector is deployed in the Python package statlab.

</details>


### [67] [Bayesian Meta-Analyses Could Be More: A Case Study in Trial of Labor After a Cesarean-section Outcomes and Complications](https://arxiv.org/abs/2601.10089)
*Ashley Klein,Edward Raff,Marcia DesJardin*

Main category: cs.LG

TL;DR: 论文解决了传统Meta分析在关键变量缺失导致效应量未知的问题，提出Bayesian方法并在剖宫产后试产场景展示其效用。


<details>
  <summary>Details</summary>
Motivation: 在医学Meta分析中，若先前研究未准确捕捉关键决策变量（如影响医生决策的变量），会导致效应量未知、结论不可靠。

Method: 基于Bayesian方法的Meta分析技术，针对缺失决策变量的医学研究，构建模型判定正效应是否仍然成立。

Result: 通过在剖宫产后试产（TOLAC）情境中应用Bayesian方法，成功为专业产科医生提供决策辅助，证明了该方法的可行性与实际价值。

Conclusion: 本研究提出一种Bayesian框架，克服传统Meta分析在关键决策变量缺失时导致效应量未知、结论不可靠的问题。实验表明，该方法能在产科临床场景（如剖宫产后试产）中为医生提供可信的支持，从而提升患者护理水平。

Abstract: The meta-analysis's utility is dependent on previous studies having accurately captured the variables of interest, but in medical studies, a key decision variable that impacts a physician's decisions was not captured. This results in an unknown effect size and unreliable conclusions. A Bayesian approach may allow analysis to determine if the claim of a positive effect is still warranted, and we build a Bayesian approach to this common medical scenario. To demonstrate its utility, we assist professional OBGYNs in evaluating Trial of Labor After a Cesarean-section (TOLAC) situations where few interventions are available for patients and find the support needed for physicians to advance patient care.

</details>


### [68] [LeMoF: Level-guided Multimodal Fusion for Heterogeneous Clinical Data](https://arxiv.org/abs/2601.10092)
*Jongseok Kim,Seongae Kang,Jonghwan Shin,Yuhan Lee,Ohyun Jo*

Main category: cs.LG

TL;DR: LeMoF通过层级引导融合更好地利用各模态细粒度表示，提升临床预测效果


<details>
  <summary>Details</summary>
Motivation: 现有多模态融合方法过于依赖静态模态集成与简单融合，无法充分利用模态特定表征的区辨性

Method: 提出Level-guided Modal Fusion（LeMoF）框架，基于编码器不同层的表征进行选择性融合，并分离全局模态预测与层级判别表示

Result: 在ICU住院时长预测实验中，LeMoF在多种编码器配置下均优于最先进的多模态融合技术，验证层级集成是实现鲁棒性能的关键因素

Conclusion: LeMoF通过层级引导的扰动融合实现更好的多模态临床预测，兼顾稳定性和区辨力，显著优于现有方法

Abstract: Multimodal clinical prediction is widely used to integrate heterogeneous data such as Electronic Health Records (EHR) and biosignals. However, existing methods tend to rely on static modality integration schemes and simple fusion strategies. As a result, they fail to fully exploit modality-specific representations. In this paper, we propose Level-guided Modal Fusion (LeMoF), a novel framework that selectively integrates level-guided representations within each modality. Each level refers to a representation extracted from a different layer of the encoder. LeMoF explicitly separates and learns global modality-level predictions from level-specific discriminative representations. This design enables LeMoF to achieve a balanced performance between prediction stability and discriminative capability even in heterogeneous clinical environments. Experiments on length of stay prediction using Intensive Care Unit (ICU) data demonstrate that LeMoF consistently outperforms existing state-of-the-art multimodal fusion techniques across various encoder configurations. We also confirmed that level-wise integration is a key factor in achieving robust predictive performance across various clinical conditions.

</details>


### [69] [Multilingual-To-Multimodal (M2M): Unlocking New Languages with Monolingual Text](https://arxiv.org/abs/2601.10096)
*Piyush Singh Pasi*

Main category: cs.LG

TL;DR: METAL使用少量线性层，将多语言文本嵌入映射到模态空间，保持英语基线性能并实现强大的零样本多语言转移，已公开代码与多语言评测数据集。


<details>
  <summary>Details</summary>
Motivation: 多模态模型在英语表现优异，但受限的多语言模态资源导致其他语言性能骤降。

Method: METAL通过在仅使用英语文本的情况下学习少量线性层，将多语言文本嵌入映射到模态空间。

Result: METAL在英语检索中回报率R@10为94.9%，在11种未见语言上的零样本转移平均R@10为89.5%。

Conclusion: METAL在多语言模态检索中实现了与英文本基线相当的性能，并在多语言零样本转移中表现出良好效果。

Abstract: Multimodal models excel in English, supported by abundant image-text and audio-text data, but performance drops sharply for other languages due to limited multilingual multimodal resources. Existing solutions rely heavily on machine translation, while advances in multilingual text modeling remain underutilized. We introduce METAL, a lightweight alignment method that learns only a few linear layers using English text alone to map multilingual text embeddings into a multimodal space. Despite its simplicity, METAL matches baseline performance in English (94.9 percent Recall at 10) and achieves strong zero-shot transfer (89.5 percent Recall at 10 averaged across 11 languages, 10 unseen) on XTD text-to-image retrieval. Qualitative t-SNE visualizations show that multilingual embeddings align tightly with multimodal representations, while weight analysis reveals that the transformation reshapes embedding geometry rather than performing trivial rotations. Beyond image-text retrieval, METAL generalizes to audio-text retrieval and cross-lingual text-to-image generation. We release code and checkpoints at https://github.com/m2m-codebase/M2M , as well as multilingual evaluation datasets including MSCOCO Multilingual 30K (https://huggingface.co/datasets/piyushsinghpasi/mscoco-multilingual-30k ), AudioCaps Multilingual (https://huggingface.co/datasets/piyushsinghpasi/audiocaps-multilingual ), and Clotho Multilingual (https://huggingface.co/datasets/piyushsinghpasi/clotho-multilingual ), to facilitate further research.

</details>


### [70] [Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent Tree-Query and Adversarial Confidence Estimation](https://arxiv.org/abs/2601.10137)
*Ziyi Ding,Chenfei Ye-Hao,Zheyuan Wang,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: Tree-Query 用树状LLM查询推断对偶因果关系，提供解释性置信度，且在无数据基准上比传统LLM方法表现更好。


<details>
  <summary>Details</summary>
Motivation: 传统约束式因果发现在错误传播上存在缺陷，LLM作为因果先验工具不透明且缺乏置信度，可解释性不足。

Method: Tree-Query 架构将对偶因果关系转化为树结构的多专家LLM查询，围绕后门路径、独立性、潜在混杂和因果方向展开短序列提问，提供可解释判断和鲁棒置信分数。

Result: 在无数据基准上相较直接LLM基线，Tree-Query 在结构指标上提升显著，并通过肥胖-体重案例展示了混杂筛选与高置信度因果结论。

Conclusion: Tree-Query 为获取数据无关因果先验提供了可解释、鲁棒且理论上可识别的方案，可在下游数据驱动因果发现在先验推理层面起补充作用。

Abstract: Causal discovery aims to recover ``what causes what'', but classical constraint-based methods (e.g., PC, FCI) suffer from error propagation, and recent LLM-based causal oracles often behave as opaque, confidence-free black boxes. This paper introduces Tree-Query, a tree-structured, multi-expert LLM framework that reduces pairwise causal discovery to a short sequence of queries about backdoor paths, (in)dependence, latent confounding, and causal direction, yielding interpretable judgments with robustness-aware confidence scores. Theoretical guarantees are provided for asymptotic identifiability of four pairwise relations. On data-free benchmarks derived from Mooij et al. and UCI causal graphs, Tree-Query improves structural metrics over direct LLM baselines, and a diet--weight case study illustrates confounder screening and stable, high-confidence causal conclusions. Tree-Query thus offers a principled way to obtain data-free causal priors from LLMs that can complement downstream data-driven causal discovery. Code is available at https://anonymous.4open.science/r/Repo-9B3E-4F96.

</details>


### [71] [Understanding and Preserving Safety in Fine-Tuned LLMs](https://arxiv.org/abs/2601.10141)
*Jiawen Zhang,Yangfan Hu,Kejia Chen,Lipeng He,Jiachen Ma,Jian Lou,Dan Li,Jian Liu,Xiaohu Yang,Ruoxi Jia*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Fine-tuning is an essential and pervasive functionality for applying large language models (LLMs) to downstream tasks. However, it has the potential to substantially degrade safety alignment, e.g., by greatly increasing susceptibility to jailbreak attacks, even when the fine-tuning data is entirely harmless. Despite garnering growing attention in defense efforts during the fine-tuning stage, existing methods struggle with a persistent safety-utility dilemma: emphasizing safety compromises task performance, whereas prioritizing utility typically requires deep fine-tuning that inevitably leads to steep safety declination.
  In this work, we address this dilemma by shedding new light on the geometric interaction between safety- and utility-oriented gradients in safety-aligned LLMs. Through systematic empirical analysis, we uncover three key insights: (I) safety gradients lie in a low-rank subspace, while utility gradients span a broader high-dimensional space; (II) these subspaces are often negatively correlated, causing directional conflicts during fine-tuning; and (III) the dominant safety direction can be efficiently estimated from a single sample. Building upon these novel insights, we propose safety-preserving fine-tuning (SPF), a lightweight approach that explicitly removes gradient components conflicting with the low-rank safety subspace. Theoretically, we show that SPF guarantees utility convergence while bounding safety drift. Empirically, SPF consistently maintains downstream task performance and recovers nearly all pre-trained safety alignment, even under adversarial fine-tuning scenarios. Furthermore, SPF exhibits robust resistance to both deep fine-tuning and dynamic jailbreak attacks. Together, our findings provide new mechanistic understanding and practical guidance toward always-aligned LLM fine-tuning.

</details>


### [72] [LOOKAT: Lookup-Optimized Key-Attention for Memory-Efficient Transformers](https://arxiv.org/abs/2601.10155)
*Aryan Karmore*

Main category: cs.LG

TL;DR: LOOKAT 通过产品量化与查表优化把 Transformer 注意力从内存受限转为计算受限，实现 64× 压缩、95.7% 输出质量；无架构改动，rank 相关 >0.95，理论与实验均验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型想在边缘设备部署时，KV 缓存过大导致存储与传输带宽受限。现有量化方法只能压缩存储，却无法减小带宽消耗，因为注意力计算会在使用前将 INT4/INT8 取反量化为 FP16。

Method: 我们取注意力打分等价于向量内积相似度搜索的事实，借鉴向量数据库的压缩技术，提出 LOOKAT。其核心是对键向量进行子空间分解，学习代码库，利用产品量化（Product Quantization）和非对称距离计算（Asymmetric Distance Computation），通过查表方式预先生成注意力表。这样，使注意力计算从内存受限转为计算受限。

Result: 在 GPT‑2 上实验表明，LOOKAT 在不改动架构或再训练的前提下，分别实现 64 倍压缩（95.7% 输出保真度）和 32 倍压缩（95.0%，相同条件），保持 rank 相关系数 ρ>0.95。理论分析显示 rank 相关度衰减表现为 O(d_k / (mK))，实验验证其在 1024 token 序列长度内始终稳定。

Conclusion: LOOKAT 成功将 KV 缓存压缩到 64 倍以上，同时保持极高的输出质量与相关性，解决了边缘部署时存储与带宽极限的问题，并且无需对模型架构或训练过程做调整，具备良好的泛化与实用性。

Abstract: Compressing the KV cache is a required step to deploy large language models on edge devices. Current quantization methods compress storage but fail to reduce bandwidth as attention calculation requires dequantizing keys from INT4/INT8 to FP16 before use. We observe that attention scoring is mathematically equivalent to the inner product similarity search and we can apply some compression techniques from vector databases to compress KV-cache better. We propose LOOKAT, which applies product quantization and asymmetric distance computation, to transformer architecture by decomposing key vectors into subspaces, learning codebooks and computing attention tables via lookup tables. This transforms attention from memory-bound to compute-bound. LOOKAT achieves 64 $\times$ compression at 95.7\% output fidelity and 32 $\times$ compression at 95.0\% fidelity when tested on GPT-2. LOOKAT requires no architecture changes or training while maintaining rank correlation $ρ> 0.95$. Theoretical analysis confirms that rank correlation degrades as $O(d_k/mK)$, with guarantees validated across sequence lengths up to 1024 tokens.

</details>


### [73] [CC-OR-Net: A Unified Framework for LTV Prediction through Structural Decoupling](https://arxiv.org/abs/2601.10176)
*Mingyu Zhao,Haoran Bai,Yu Tian,Bing Zhu,Hengliang Luo*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Customer Lifetime Value (LTV) prediction, a central problem in modern marketing, is characterized by a unique zero-inflated and long-tail data distribution. This distribution presents two fundamental challenges: (1) the vast majority of low-to-medium value users numerically overwhelm the small but critically important segment of high-value "whale" users, and (2) significant value heterogeneity exists even within the low-to-medium value user base. Common approaches either rely on rigid statistical assumptions or attempt to decouple ranking and regression using ordered buckets; however, they often enforce ordinality through loss-based constraints rather than inherent architectural design, failing to balance global accuracy with high-value precision. To address this gap, we propose \textbf{C}onditional \textbf{C}ascaded \textbf{O}rdinal-\textbf{R}esidual Networks \textbf{(CC-OR-Net)}, a novel unified framework that achieves a more robust decoupling through \textbf{structural decomposition}, where ranking is architecturally guaranteed. CC-OR-Net integrates three specialized components: a \textit{structural ordinal decomposition module} for robust ranking, an \textit{intra-bucket residual module} for fine-grained regression, and a \textit{targeted high-value augmentation module} for precision on top-tier users. Evaluated on real-world datasets with over 300M users, CC-OR-Net achieves a superior trade-off across all key business metrics, outperforming state-of-the-art methods in creating a holistic and commercially valuable LTV prediction solution.

</details>


### [74] [Graph Regularized PCA](https://arxiv.org/abs/2601.10199)
*Antonio Briola,Marwin Schmidt,Fabio Caccioli,Carlos Ros Perez,James Singleton,Christian Michler,Tomaso Aste*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: High-dimensional data often exhibit dependencies among variables that violate the isotropic-noise assumption under which principal component analysis (PCA) is optimal. For cases where the noise is not independent and identically distributed across features (i.e., the covariance is not spherical) we introduce Graph Regularized PCA (GR-PCA). It is a graph-based regularization of PCA that incorporates the dependency structure of the data features by learning a sparse precision graph and biasing loadings toward the low-frequency Fourier modes of the corresponding graph Laplacian. Consequently, high-frequency signals are suppressed, while graph-coherent low-frequency ones are preserved, yielding interpretable principal components aligned with conditional relationships. We evaluate GR-PCA on synthetic data spanning diverse graph topologies, signal-to-noise ratios, and sparsity levels. Compared to mainstream alternatives, it concentrates variance on the intended support, produces loadings with lower graph-Laplacian energy, and remains competitive in out-of-sample reconstruction. When high-frequency signals are present, the graph Laplacian penalty prevents overfitting, reducing the reconstruction accuracy but improving structural fidelity. The advantage over PCA is most pronounced when high-frequency signals are graph-correlated, whereas PCA remains competitive when such signals are nearly rotationally invariant. The procedure is simple to implement, modular with respect to the precision estimator, and scalable, providing a practical route to structure-aware dimensionality reduction that improves structural fidelity without sacrificing predictive performance.

</details>


### [75] [PRL: Process Reward Learning Improves LLMs' Reasoning Ability and Broadens the Reasoning Boundary](https://arxiv.org/abs/2601.10201)
*Jiarui Yao,Ruida Wang,Tong Zhang*

Main category: cs.LG

TL;DR: PRL通过把终端奖励拆分为过程奖励，利用熵正则化RL公式（包含KL惩罚），在不额外训练奖励模型的前提下提升LLM推理效果。


<details>
  <summary>Details</summary>
Motivation: 简化大模型推理过程中的监督方式，解决现有方法对终端奖励的依赖与额外步骤的低效问题。

Method: 提出Process Reward Learning（PRL），将熵正则化强化学习目标拆分成中间步骤，利用理论推导得到等价于奖励最大化+KL惩罚的目标，并将终端奖励转化为过渡阶段的过程奖励，避免额外MCTS或奖励模型训练。

Result: 实验表明PRL在平均@n和pass@n指标上均显著提升，扩大了LLM的推理边界，效果可验证且具有推广性。

Conclusion: PRL通过提供细粒度过程监督，显著提升LLM推理性能，证明了其理论基础和实验优势，值得在更广泛场景中应用。

Abstract: Improving the reasoning abilities of Large Language Models (LLMs) has been a continuous topic recently. But most relevant works are based on outcome rewards at the trajectory level, missing fine-grained supervision during the reasoning process. Other existing training frameworks that try to combine process signals together to optimize LLMs also rely heavily on tedious additional steps like MCTS, training a separate reward model, etc., doing harm to the training efficiency. Moreover, the intuition behind the process signals design lacks rigorous theoretical support, leaving the understanding of the optimization mechanism opaque. In this paper, we propose Process Reward Learning (PRL), which decomposes the entropy regularized reinforcement learning objective into intermediate steps, with rigorous process rewards that could be assigned to models accordingly. Starting from theoretical motivation, we derive the formulation of PRL that is essentially equivalent to the objective of reward maximization plus a KL-divergence penalty term between the policy model and a reference model. However, PRL could turn the outcome reward into process supervision signals, which helps better guide the exploration during RL optimization. From our experiment results, we demonstrate that PRL not only improves the average performance for LLMs' reasoning ability measured by average @ n, but also broadens the reasoning boundary by improving the pass @ n metric. Extensive experiments show the effectiveness of PRL could be verified and generalized.

</details>


### [76] [X-SAM: Boosting Sharpness-Aware Minimization with Dominant-Eigenvector Gradient Correction](https://arxiv.org/abs/2601.10251)
*Hongru Duan,Yongle Chen,Lei Guan*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Sharpness-Aware Minimization (SAM) aims to improve generalization by minimizing a worst-case perturbed loss over a small neighborhood of model parameters. However, during training, its optimization behavior does not always align with theoretical expectations, since both sharp and flat regions may yield a small perturbed loss. In such cases, the gradient may still point toward sharp regions, failing to achieve the intended effect of SAM. To address this issue, we investigate SAM from a spectral and geometric perspective: specifically, we utilize the angle between the gradient and the leading eigenvector of the Hessian as a measure of sharpness. Our analysis illustrates that when this angle is less than or equal to ninety degrees, the effect of SAM's sharpness regularization can be weakened. Furthermore, we propose an explicit eigenvector-aligned SAM (X-SAM), which corrects the gradient via orthogonal decomposition along the top eigenvector, enabling more direct and efficient regularization of the Hessian's maximum eigenvalue. We prove X-SAM's convergence and superior generalization, with extensive experimental evaluations confirming both theoretical and practical advantages.

</details>


### [77] [Early Fault Detection on CMAPSS with Unsupervised LSTM Autoencoders](https://arxiv.org/abs/2601.10269)
*P. Sánchez,K. Reyes,B. Radu,E. Fernández*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper introduces an unsupervised health-monitoring framework for turbofan engines that does not require run-to-failure labels. First, operating-condition effects in NASA CMAPSS sensor streams are removed via regression-based normalisation; then a Long Short-Term Memory (LSTM) autoencoder is trained only on the healthy portion of each trajectory. Persistent reconstruction error, estimated using an adaptive data-driven threshold, triggers real-time alerts without hand-tuned rules. Benchmark results show high recall and low false-alarm rates across multiple operating regimes, demonstrating that the method can be deployed quickly, scale to diverse fleets, and serve as a complementary early-warning layer to Remaining Useful Life models.

</details>


### [78] [SPIKE: Sparse Koopman Regularization for Physics-Informed Neural Networks](https://arxiv.org/abs/2601.10282)
*Jose Marie Antonio Minoza*

Main category: cs.LG

TL;DR: SPIKE以连续时间Koopman算子为基础，对PINNs进行稀疏正则化，显著提升外推和泛化能力，实验验证了其在多类偏微分方程与混沌系统中的有效性。


<details>
  <summary>Details</summary>
Motivation: PINNs易在训练域内过拟合，难以外推；需要一种可约束动力学表征、提升泛化的机制。

Method: 在可观测空间中强制线性微分 \(\frac{dz}{dt}=Az\)，对生成矩阵 \(A\) 施加 \(L_1\) 范数惩罚，使模型学习稀疏解析并避免过拟合；不使用稀疏约束的变体为PIKE。

Result: 对抛物、双曲、色散与刚性PDE（如Navier-Stokes）及混沌ODE（Lorenz）进行实验，SPIKE在时间外推、空间泛化与长期预测上均优于传统PINNs；连续时间公式实现无条件稳定。

Conclusion: SPIKE通过在PINNs中引入连续时间Koopman算子及L1稀疏正则，显著提升了动力学模型在时间外推、空间泛化以及长期预测方面的性能。

Abstract: Physics-Informed Neural Networks (PINNs) provide a mesh-free approach for solving differential equations by embedding physical constraints into neural network training. However, PINNs tend to overfit within the training domain, leading to poor generalization when extrapolating beyond trained spatiotemporal regions. This work presents SPIKE (Sparse Physics-Informed Koopman-Enhanced), a framework that regularizes PINNs with continuous-time Koopman operators to learn parsimonious dynamics representations. By enforcing linear dynamics $dz/dt = Az$ in a learned observable space, both PIKE (without explicit sparsity) and SPIKE (with L1 regularization on $A$) learn sparse generator matrices, embodying the parsimony principle that complex dynamics admit low-dimensional structure. Experiments across parabolic, hyperbolic, dispersive, and stiff PDEs, including fluid dynamics (Navier-Stokes) and chaotic ODEs (Lorenz), demonstrate consistent improvements in temporal extrapolation, spatial generalization, and long-term prediction accuracy. The continuous-time formulation with matrix exponential integration provides unconditional stability for stiff systems while avoiding diagonal dominance issues inherent in discrete-time Koopman operators.

</details>


### [79] [We Need a More Robust Classifier: Dual Causal Learning Empowers Domain-Incremental Time Series Classification](https://arxiv.org/abs/2601.10312)
*Zhipeng Liu,Peibo Duan,Xuan Tang,Haodong Jing,Mingyang Geng,Yongsheng Huang,Jialu Xu,Bin Zhang,Binwu Wang*

Main category: cs.LG

TL;DR: DualCD通过时间特征解耦和双因果干预改进领域增量时序分类，实验表明效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有时序分类研究在领域增量学习中面临鲁棒性不足的问题

Method: 双因果解耦框架 DualCD，引入时间特征解耦模块与双因果干预机制，构造变异样本并使用因果干预损失

Result: 在多数据集、多模型实验中显著提升领域增量场景性能

Conclusion: DualCD 为领域增量式时间序列分类提供了一种轻量且稳健的解决方案，并提供了面向研究的基准

Abstract: The World Wide Web thrives on intelligent services that rely on accurate time series classification, which has recently witnessed significant progress driven by advances in deep learning. However, existing studies face challenges in domain incremental learning. In this paper, we propose a lightweight and robust dual-causal disentanglement framework (DualCD) to enhance the robustness of models under domain incremental scenarios, which can be seamlessly integrated into time series classification models. Specifically, DualCD first introduces a temporal feature disentanglement module to capture class-causal features and spurious features. The causal features can offer sufficient predictive power to support the classifier in domain incremental learning settings. To accurately capture these causal features, we further design a dual-causal intervention mechanism to eliminate the influence of both intra-class and inter-class confounding features. This mechanism constructs variant samples by combining the current class's causal features with intra-class spurious features and with causal features from other classes. The causal intervention loss encourages the model to accurately predict the labels of these variant samples based solely on the causal features. Extensive experiments on multiple datasets and models demonstrate that DualCD effectively improves performance in domain incremental scenarios. We summarize our rich experiments into a comprehensive benchmark to facilitate research in domain incremental time series classification.

</details>


### [80] [Meta Dynamic Graph for Traffic Flow Prediction](https://arxiv.org/abs/2601.10328)
*Yiqing Zou,Hanning Yuan,Qianyu Yang,Ziqiang Yuan,Shuliang Wang,Sijie Ruan*

Main category: cs.LG

TL;DR: MetaDG通过动态图节点建模，统一了时空异构与动态捕捉，提升交通预测效果。


<details>
  <summary>Details</summary>
Motivation: 传统方法在时空依赖建模上仅聚焦拓扑动态且对异质性处理分离，导致难以捕捉完整的时空协同效应。

Method: MetaDG通过动态图结构对节点表示进行建模，实时生成动态邻接矩阵和元参数，实现对时空动态的全局统一建模。

Result: 在四个真实交通数据集上，MetaDG均优于现有基准模型，验证了其有效性。

Conclusion: Meta Dynamic Graph（MetaDG）成功弥合了动态建模与时空异质性处理之间的空白，显著提升了交通流预测性能。

Abstract: Traffic flow prediction is a typical spatio-temporal prediction problem and has a wide range of applications. The core challenge lies in modeling the underlying complex spatio-temporal dependencies. Various methods have been proposed, and recent studies show that the modeling of dynamics is useful to meet the core challenge. While handling spatial dependencies and temporal dependencies using separate base model structures may hinder the modeling of spatio-temporal correlations, the modeling of dynamics can bridge this gap. Incorporating spatio-temporal heterogeneity also advances the main goal, since it can extend the parameter space and allow more flexibility. Despite these advances, two limitations persist: 1) the modeling of dynamics is often limited to the dynamics of spatial topology (e.g., adjacency matrix changes), which, however, can be extended to a broader scope; 2) the modeling of heterogeneity is often separated for spatial and temporal dimensions, but this gap can also be bridged by the modeling of dynamics. To address the above limitations, we propose a novel framework for traffic prediction, called Meta Dynamic Graph (MetaDG). MetaDG leverages dynamic graph structures of node representations to explicitly model spatio-temporal dynamics. This generates both dynamic adjacency matrices and meta-parameters, extending dynamic modeling beyond topology while unifying the capture of spatio-temporal heterogeneity into a single dimension. Extensive experiments on four real-world datasets validate the effectiveness of MetaDG.

</details>


### [81] [SuS: Strategy-aware Surprise for Intrinsic Exploration](https://arxiv.org/abs/2601.10349)
*Mark Kashirskiy,Ilya Makarov*

Main category: cs.LG

TL;DR: SuS 通过将策略一致性与惊奇度同时纳入奖励，显著提高了推理任务的成功率和解答多样性，且两者缺一都会影响性能。


<details>
  <summary>Details</summary>
Motivation: 传统好奇心驱动方法仅依赖状态预测误差，难以捕捉策略层面的变化；本工作借助策略观测引入更细粒度的新颖性信号，期望实现更高效、更可解释的探索。

Method: SuS 通过预后预测误差、策略一致性（Strategy Stability）以及相对“惊奇”度（Strategy Surprise）两项指标构建内在奖励；奖励被学习权重组合成最终的探索激励。

Result: 在大模型数学推理基准上，SuS 分别提升 Pass@1 和 Pass@5 17.4% 与 26.4%；消除任一组件导致至少 10% 成绩下降，表明两项指标互补。

Conclusion: 结合策略稳定性与策略惊奇两种新颖信号的 SuS 框架显著提升了强化学习在数学推理任务中的准确率与解答多样性，证明两者的协同效应是提升探索效率的关键。

Abstract: We propose Strategy-aware Surprise (SuS), a novel intrinsic motivation framework that uses pre-post prediction mismatch as a novelty signal for exploration in reinforcement learning. Unlike traditional curiosity-driven methods that rely solely on state prediction error, SuS introduces two complementary components: Strategy Stability (SS) and Strategy Surprise (SuS). SS measures consistency in behavioral strategy across temporal steps, while SuS captures unexpected outcomes relative to the agent's current strategy representation. Our combined reward formulation leverages both signals through learned weighting coefficients. We evaluate SuS on mathematical reasoning tasks using large language models, demonstrating significant improvements in both accuracy and solution diversity. Ablation studies confirm that removing either component results in at least 10% performance degradation, validating the synergistic nature of our approach. SuS achieves 17.4% improvement in Pass@1 and 26.4% improvement in Pass@5 compared to baseline methods, while maintaining higher strategy diversity throughout training.

</details>


### [82] [EvoMorph: Counterfactual Explanations for Continuous Time-Series Extrinsic Regression Applied to Photoplethysmography](https://arxiv.org/abs/2601.10356)
*Mesut Ceylan,Alexis Tabin,Patrick Langer,Elgar Fleisch,Filipe Barata*

Main category: cs.LG

TL;DR: EvoMorph利用多目标进化优化，考虑波形形态并保持结构，生成可靠的生理反事实，改善临床时序预测的可解释性和不确定性评估。


<details>
  <summary>Details</summary>
Motivation: 单点预测缺乏对模型稳定性和生理可行性变化的解释，现有时间序列反事实方法多局限于分类、忽略波形形态，导致预测解释不可靠。

Method: 通过多目标进化算法，结合形态感知的可解释信号描述符，并对波形进行结构保持的变换，生成符合物理可行性约束的反事实。

Result: 在三组PPG数据集（心率、呼吸率、血氧饱和度）上，与最近邻差异基线相比，EvoMorph在生成生理合理的反事实、支持不确定性量化方面表现更佳。

Conclusion: EvoMorph可以生成生理上合理、形态多样的反事实，用以提升临床时序回归模型的可解释性和可信度。

Abstract: Wearable devices enable continuous, population-scale monitoring of physiological signals, such as photoplethysmography (PPG), creating new opportunities for data-driven clinical assessment. Time-series extrinsic regression (TSER) models increasingly leverage PPG signals to estimate clinically relevant outcomes, including heart rate, respiratory rate, and oxygen saturation. For clinical reasoning and trust, however, single point estimates alone are insufficient: clinicians must also understand whether predictions are stable under physiologically plausible variations and to what extent realistic, attainable changes in physiological signals would meaningfully alter a model's prediction. Counterfactual explanations (CFE) address these "what-if" questions, yet existing time series CFE generation methods are largely restricted to classification, overlook waveform morphology, and often produce physiologically implausible signals, limiting their applicability to continuous biomedical time series. To address these limitations, we introduce EvoMorph, a multi-objective evolutionary framework for generating physiologically plausible and diverse CFE for TSER applications. EvoMorph optimizes morphology-aware objectives defined on interpretable signal descriptors and applies transformations to preserve the waveform structure. We evaluated EvoMorph on three PPG datasets (heart rate, respiratory rate, and oxygen saturation) against a nearest-unlike-neighbor baseline. In addition, in a case study, we evaluated EvoMorph as a tool for uncertainty quantification by relating counterfactual sensitivity to bootstrap-ensemble uncertainty and data-density measures. Overall, EvoMorph enables the generation of physiologically-aware counterfactuals for continuous biomedical signals and supports uncertainty-aware interpretability, advancing trustworthy model analysis for clinical time-series applications.

</details>


### [83] [PLGC: Pseudo-Labeled Graph Condensation](https://arxiv.org/abs/2601.10358)
*Jay Nandy,Arnab Kumar Mondal,Anuj Rathore,Mahesh Chandran*

Main category: cs.LG

TL;DR: PLGC 是一种无需真实标签即可进行图凝缩的自监督框架，设计伪标签并优化小图，使其在结构与特征统计匹配上与原图一致，提升了噪声环境下的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有图凝缩方法受限于需要干净的监督标签，导致在标签稀缺、噪声或分布漂移时失效。

Method: 通过自监督方式构建伪标签（结合节点嵌入的潜在原型和节点分配），在训练过程中同时学习原始图的结构与特征统计的对齐损失，进而得到凝缩图。

Result: 在节点分类与链路预测任务上，PLGC在干净数据上达到或超过监督方法的性能，在有标签噪声的环境下表现出显著的鲁棒性，往往超越所有基线。

Conclusion: PLGC通过无监督的伪标签方式实现图数据的有效稀疏化，能够在缺乏高质量标签或标签噪声严重的场景下，生成与原图结构和特征统计一致的合成小图，并保持嵌入对齐精度。

Abstract: Large graph datasets make training graph neural networks (GNNs) computationally costly. Graph condensation methods address this by generating small synthetic graphs that approximate the original data. However, existing approaches rely on clean, supervised labels, which limits their reliability when labels are scarce, noisy, or inconsistent. We propose Pseudo-Labeled Graph Condensation (PLGC), a self-supervised framework that constructs latent pseudo-labels from node embeddings and optimizes condensed graphs to match the original graph's structural and feature statistics -- without requiring ground-truth labels. PLGC offers three key contributions: (1) A diagnosis of why supervised condensation fails under label noise and distribution shift. (2) A label-free condensation method that jointly learns latent prototypes and node assignments. (3) Theoretical guarantees showing that pseudo-labels preserve latent structural statistics of the original graph and ensure accurate embedding alignment. Empirically, across node classification and link prediction tasks, PLGC achieves competitive performance with state-of-the-art supervised condensation methods on clean datasets and exhibits substantial robustness under label noise, often outperforming all baselines by a significant margin. Our findings highlight the practical and theoretical advantages of self-supervised graph condensation in noisy or weakly-labeled environments.

</details>


### [84] [CS-GBA: A Critical Sample-based Gradient-guided Backdoor Attack for Offline Reinforcement Learning](https://arxiv.org/abs/2601.10407)
*Yuanjie Zhao,Junnan Qiu,Yue Ding,Jie Li*

Main category: cs.LG

TL;DR: 提出 CS-GBA，利用临界样本和梯度引导实现高隐蔽、高破坏性的后门攻击，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 离线RL在静态数据中优化策略时易受后门攻击；传统攻击在安全约束算法中效果差，主要因随机污染和易检测的OOD触发器。

Method: 采用临界样本梯度引导的后门攻击，结合动态选择TD误差高的关键样本、相关性破坏触发器和梯度引导动作生成。

Result: 在D4RL基准上，仅5%污染预算即可在安全约束算法上实现高攻击成功率，同时保持干净环境下性能。

Conclusion: 本工作展示了在安全约束式离线强化学习中的高隐蔽性和破坏性后门攻击方法；实验验证其优越性。

Abstract: Offline Reinforcement Learning (RL) enables policy optimization from static datasets but is inherently vulnerable to backdoor attacks. Existing attack strategies typically struggle against safety-constrained algorithms (e.g., CQL) due to inefficient random poisoning and the use of easily detectable Out-of-Distribution (OOD) triggers. In this paper, we propose CS-GBA (Critical Sample-based Gradient-guided Backdoor Attack), a novel framework designed to achieve high stealthiness and destructiveness under a strict budget. Leveraging the theoretical insight that samples with high Temporal Difference (TD) errors are pivotal for value function convergence, we introduce an adaptive Critical Sample Selection strategy that concentrates the attack budget on the most influential transitions. To evade OOD detection, we propose a Correlation-Breaking Trigger mechanism that exploits the physical mutual exclusivity of state features (e.g., 95th percentile boundaries) to remain statistically concealed. Furthermore, we replace the conventional label inversion with a Gradient-Guided Action Generation mechanism, which searches for worst-case actions within the data manifold using the victim Q-network's gradient. Empirical results on D4RL benchmarks demonstrate that our method significantly outperforms state-of-the-art baselines, achieving high attack success rates against representative safety-constrained algorithms with a minimal 5% poisoning budget, while maintaining the agent's performance in clean environments.

</details>


### [85] [Reinforcement Learning with Multi-Step Lookahead Information Via Adaptive Batching](https://arxiv.org/abs/2601.10418)
*Nadav Merlis*

Main category: cs.LG

TL;DR: 本文针对多步前瞻信息的 RL 问题，提出自适应批处理流程，导出最优 Bellman 方程，并设计乐观 regret‑minimizing 算法；实验与理论表明其回报上界在阶数上是最优的，仅受前瞻步长 ℓ 的常数因子影响。


<details>
  <summary>Details</summary>
Motivation: 在表格化强化学习中，提前观测ℓ 步未来的转移与奖励能显著提升价值，却导致最优策略的 NP‑hard；现有的固定批处理和 MPC 两种可行方案仍存在显著问题，亟需一种更灵活、更优的处理方法。

Method: 分析了固定批处理与模型预测控制两种常见启发式，并指出其缺陷；随后提出自适应批处理策略，将批处理大小作为状态相关的自适应量；对该策略推导了最优Bellman方程；最后设计了乐观的 regret‑minimizing 算法，用以在未知环境中学习最优的自适应批处理策略。

Result: 提出的算法在未知环境中能够学习到最优的自适应批处理策略，并给出 regret 上界，阶数与任何已知解匹配，仅多出一个 ℓ 的常数因子，ℓ 通常为固定小常数。

Conclusion: 本文通过引入自适应批处理策略（Adaptive Batching Policies），解决了固定批处理和模型预测控制在多步前瞻信息下的局限；在未知环境中通过构造最优Bellman方程和乐观的 regret‑minimizing 算法，取得了举足轻重的性能结果，回报界限在常数倍因子（包含前瞻步长ℓ）下达到阶数最优。

Abstract: We study tabular reinforcement learning problems with multiple steps of lookahead information. Before acting, the learner observes $\ell$ steps of future transition and reward realizations: the exact state the agent would reach and the rewards it would collect under any possible course of action. While it has been shown that such information can drastically boost the value, finding the optimal policy is NP-hard, and it is common to apply one of two tractable heuristics: processing the lookahead in chunks of predefined sizes ('fixed batching policies'), and model predictive control. We first illustrate the problems with these two approaches and propose utilizing the lookahead in adaptive (state-dependent) batches; we refer to such policies as adaptive batching policies (ABPs). We derive the optimal Bellman equations for these strategies and design an optimistic regret-minimizing algorithm that enables learning the optimal ABP when interacting with unknown environments. Our regret bounds are order-optimal up to a potential factor of the lookahead horizon $\ell$, which can usually be considered a small constant.

</details>


### [86] [DeFlow: Decoupling Manifold Modeling and Value Maximization for Offline Policy Extraction](https://arxiv.org/abs/2601.10471)
*Zhancun Mu*

Main category: cs.LG

TL;DR: DeFlow通过流匹配与轻量修正模块，实现了高效、稳定的离线RL框架，并在OGBench大幅领先。


<details>
  <summary>Details</summary>
Motivation: 传统生成式RL需对ODE求解器进行反向传播，计算代价高且训练不稳定，需要兼顧表达能力与效率。

Method: 1）利用流匹配构建行为流形；2）在该流体的显式数据导出信任区间内引入轻量修正模块；3）通过单步去蒸馏而非反向传播求解器来优化生成策略。

Result: 在OGBench基准上表现优异，并展示了高效的离线到在线迁移。

Conclusion: DeFlow通过引入流匹配，在离线RL中实现了复杂行为流形的精准捕捉，并通过轻量化的修正模块在显式的信任区域内优化生成策略，从而绕过ODE求解器的反向传播，保持了迭代表达能力且提升了训练稳定性。

Abstract: We present DeFlow, a decoupled offline RL framework that leverages flow matching to faithfully capture complex behavior manifolds. Optimizing generative policies is computationally prohibitive, typically necessitating backpropagation through ODE solvers. We address this by learning a lightweight refinement module within an explicit, data-derived trust region of the flow manifold, rather than sacrificing the iterative generation capability via single-step distillation. This way, we bypass solver differentiation and eliminate the need for balancing loss terms, ensuring stable improvement while fully preserving the flow's iterative expressivity. Empirically, DeFlow achieves superior performance on the challenging OGBench benchmark and demonstrates efficient offline-to-online adaptation.

</details>


### [87] [Projected Microbatch Accumulation yields reference-free proximal policy updates for reinforcement learning](https://arxiv.org/abs/2601.10498)
*Nilin Abrahamsen*

Main category: cs.LG

TL;DR: PROMA 提出了一种无参考策略、无裁剪的近端策略微调方法，投影微批梯度以实现更严格的 KL 控制，提升了大模型微调的稳定性。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型微调中需要实现稳定的近端策略更新，避免传统方法（PPO、GRPO）产生的熵崩溃或对参考策略的依赖。

Method: 在反向传播过程中逐层投影序列级梯度成分，随后将投影后的梯度在微批之间聚合，从而高效执行近端策略更新。

Result: 实验表明 PROMA 在本地 KL 冲击方面比 GRPO 更紧，学习更稳定，并且不引起熵崩溃。

Conclusion: PROMA 通过在微批处理期间投影梯度，实现了更严格的本地 KL 限制，稳定了策略学习，并避免了熵崩溃；相比 PPO 与 GRPO，PROMA 在实现上更简洁，无需参考策略或概率比裁剪。

Abstract: This note introduces Projected Microbatch Accumulation (PROMA), a proximal policy update method for large language model fine-tuning. PROMA accumulates policy gradients across microbatches by projecting out sequence-wise gradient components before microbatch aggregation. The projection is applied layer-wise during the backward pass, enabling efficient implementation without additional forward or backward passes. Empirically, PROMA enforces tighter control of local KL divergence than GRPO, resulting in more stable policy learning. Unlike PPO and GRPO, PROMA achieves proximal updates without inducing entropy collapse and does not rely on a reference policy or likelihood-ratio clipping.

</details>


### [88] [Transformer-Based Cognitive Radio: Adaptive Modulation Strategies Using Transformer Models](https://arxiv.org/abs/2601.10519)
*Andrea Melis,Andrea Piroddi,Roberto Girau*

Main category: cs.LG

TL;DR: 利用GPT‑2生成调制方案，实验验证其可与经典调制相竞争，提示Transformers在认知无线电中的可行性。


<details>
  <summary>Details</summary>
Motivation: 改进认知无线电的频谱效率、鲁棒性与安全性，探索深度学习在调制设计中的应用。

Method: 训练GPT‑2模型以学习现有调制公式，随后生成新调制方案，并将其在SNR与PSD指标上与传统方法对比。

Result: 实验表明，Transformer生成的调制方案在SNR和PSD上可与传统方案相媲美，且在部分指标上表现更佳。

Conclusion: Transformer模型能够生成与传统调制方案相当甚至更优的调制方式，显示其在认知无线电体系中的潜力。

Abstract: Cognitive Radio (CR) systems, which dynamically adapt to changing spectrum environments, could benefit significantly from advancements in machine learning technologies. These systems can be enhanced in terms of spectral efficiency, robustness, and security through innovative approaches such as the use of Transformer models. This work investigates the application of Transformer models, specifically the GPT-2 architecture, to generate novel modulation schemes for wireless communications. By training a GPT-2 model on a dataset of existing modulation formulas, new modulation schemes has been created. These generated schemes are then compared to traditional methods using key performance metrics such as Signal-to-Noise Ratio (SNR) and Power Spectrum Density (PSD). The results show that Transformer-generated modulation schemes can achieve performance comparable to, and in some cases outperforming, traditional methods. This demonstrates that advanced CR systems could greatly benefit from the implementation of Transformer models, leading to more efficient, robust, and secure communication systems.

</details>


### [89] [Mixtures of Transparent Local Models](https://arxiv.org/abs/2601.10541)
*Niffa Cheick Oumar Diaby,Thierry Duchesne,Mario Marchand*

Main category: cs.LG

TL;DR: 一种融合透明本地模型并给出PAC-Bayes风险上界的新算法，在合成与真实数据上显示优越的可解释性与竞争性能。


<details>
  <summary>Details</summary>
Motivation: 说明在业务各领域机器学习模型普及导致对模型透明度需求增加，透明化有助于识别与安全和非歧视相关的因素。

Method: 提出混合透明本地模型，学习透明标注函数及其对应输入空间的局域，并以新的多预测器/多局域损失函数实现。为二元线性分类和线性回归分别建立PAC-Bayesian风险界限。

Result: 在合成数据上演示算法工作过程，并在真实数据集上与现存方法及黑盒模型对比，性能具有竞争力。

Conclusion: 本文提供了一种在保持本地可解释性的同时，利用PAC-Bayes理论保证风险上界的混合本地模型框架，可用于场景中需要局部简单函数拟合且跨区变化突变的任务。

Abstract: The predominance of machine learning models in many spheres of human activity has led to a growing demand for their transparency. The transparency of models makes it possible to discern some factors, such as security or non-discrimination. In this paper, we propose a mixture of transparent local models as an alternative solution for designing interpretable (or transparent) models. Our approach is designed for the situations where a simple and transparent function is suitable for modeling the label of instances in some localities/regions of the input space, but may change abruptly as we move from one locality to another. Consequently, the proposed algorithm is to learn both the transparent labeling function and the locality of the input space where the labeling function achieves a small risk in its assigned locality. By using a new multi-predictor (and multi-locality) loss function, we established rigorous PAC-Bayesian risk bounds for the case of binary linear classification problem and that of linear regression. In both cases, synthetic data sets were used to illustrate how the learning algorithms work. The results obtained from real data sets highlight the competitiveness of our approach compared to other existing methods as well as certain opaque models. Keywords: PAC-Bayes, risk bounds, local models, transparent models, mixtures of local transparent models.

</details>


### [90] [Process-Guided Concept Bottleneck Model](https://arxiv.org/abs/2601.10562)
*Reza M. Asiyabi,SEOSAW Partnership,Steven Hancock,Casey Ryan*

Main category: cs.LG

TL;DR: PG‑CBM将领域因果机制引入CBM，提升解读性与准确性，适用于监督稀缺的科学问题。


<details>
  <summary>Details</summary>
Motivation: 传统CBM忽视领域特定的关系与因果机制，且依赖完整概念标签，限制了其在科学领域的实际应用。

Method: 在传统CBM基础上引入过程指导，将生物物理意义的中间概念作为约束，利用多源异质训练数据进行学习。

Result: 在地球观测数据中，对地上生物量密度的估计实验表明PG‑CBM相较多个基准模型在误差和偏差上都有显著降低，并产生可解释的中间输出。

Conclusion: PG‑CBM通过在学习过程中整合领域定义的因果机制，提升了模型在科学应用中的可信度和可解释性。

Abstract: Concept Bottleneck Models (CBMs) improve the explainability of black-box Deep Learning (DL) by introducing intermediate semantic concepts. However, standard CBMs often overlook domain-specific relationships and causal mechanisms, and their dependence on complete concept labels limits applicability in scientific domains where supervision is sparse but processes are well defined. To address this, we propose the Process-Guided Concept Bottleneck Model (PG-CBM), an extension of CBMs which constrains learning to follow domain-defined causal mechanisms through biophysically meaningful intermediate concepts. Using above ground biomass density estimation from Earth Observation data as a case study, we show that PG-CBM reduces error and bias compared to multiple benchmarks, whilst leveraging multi-source heterogeneous training data and producing interpretable intermediate outputs. Beyond improved accuracy, PG-CBM enhances transparency, enables detection of spurious learning, and provides scientific insights, representing a step toward more trustworthy AI systems in scientific applications.

</details>


### [91] [Combinatorial Optimization Augmented Machine Learning](https://arxiv.org/abs/2601.10583)
*Maximilian Schiffer,Heiko Hoppe,Yue Su,Louis Bouvier,Axel Parmentier*

Main category: cs.LG

TL;DR: 综述了组合优化辅助机器学习（COAML）的框架与方法，归纳了分类、算法、应用与前沿，助力跨领域研究。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在将预测模型与组合决策机制相结合，构建既以数据驱动又具备可行性保障的决策策略，从而弥合机器学习和运筹优化之间的鸿沟。

Method: 首先提出了统一的COAML流程框架，详细阐述其构建模块并与经验成本最小化联系起来；随后设计了基于不确定性形式与决策结构的分类体系，对静态与动态问题的算法方法进行了梳理；接着回顾了在调度、车辆路径规划、随机规划与强化学习等领域的应用，并从经验成本最小化、模仿学习、强化学习等视角综合方法论贡献；最后指出了前沿研究方向。

Result: 完成了对COAML领域现状的全面综述，构造了系统的分类法，归纳了算法与应用，并提出未来研究路线。

Conclusion: 本文兼具教学引导与研究路线图的功能，为组合优化与机器学习交叉领域提供了入门与发展指引。

Abstract: Combinatorial optimization augmented machine learning (COAML) has recently emerged as a powerful paradigm for integrating predictive models with combinatorial decision-making. By embedding combinatorial optimization oracles into learning pipelines, COAML enables the construction of policies that are both data-driven and feasibility-preserving, bridging the traditions of machine learning, operations research, and stochastic optimization. This paper provides a comprehensive overview of the state of the art in COAML. We introduce a unifying framework for COAML pipelines, describe their methodological building blocks, and formalize their connection to empirical cost minimization. We then develop a taxonomy of problem settings based on the form of uncertainty and decision structure. Using this taxonomy, we review algorithmic approaches for static and dynamic problems, survey applications across domains such as scheduling, vehicle routing, stochastic programming, and reinforcement learning, and synthesize methodological contributions in terms of empirical cost minimization, imitation learning, and reinforcement learning. Finally, we identify key research frontiers. This survey aims to serve both as a tutorial introduction to the field and as a roadmap for future research at the interface of combinatorial optimization and machine learning.

</details>


### [92] [ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition](https://arxiv.org/abs/2601.10591)
*Arundeep Chinta,Lucas Vinh Tran,Jay Katukuri*

Main category: cs.LG

TL;DR: ProbFM利用DER实现高效、可解释的多源不确定性分解，解决了TSFMs不确定性量化的核心难题，实验验证其在金融预测中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有TSFMs在不确定性量化上缺乏可解释的分解机制，难以全面捕捉模型不确定性。

Method: 基于Transformer的ProbFM框架，采用Deep Evidential Regression（DER）实现对先验信息的高阶证据学习，实现归纳不确定性分解。

Result: 在加密货币收益预测任务中，DER保持竞争性预测精度，并给出清晰的epistemic-aleatoric不确定性分解，实验验证了其方法有效性。

Conclusion: 研究表明ProbFM能够在零Shot金融预测任务中提供理论上可靠且分可解释的近似不确定性估计，并保持单通计算效率，具有良好的实用前景。

Abstract: Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources of uncertainty, or lack principled calibration mechanisms. While recent TSFMs employ sophisticated techniques such as mixture models, Student's t-distributions, or conformal prediction, they fail to address the core challenge of providing theoretically-grounded uncertainty decomposition. For the very first time, we present a novel transformer-based probabilistic framework, ProbFM (probabilistic foundation model), that leverages Deep Evidential Regression (DER) to provide principled uncertainty quantification with explicit epistemic-aleatoric decomposition. Unlike existing approaches that pre-specify distributional forms or require sampling-based inference, ProbFM learns optimal uncertainty representations through higher-order evidence learning while maintaining single-pass computational efficiency. To rigorously evaluate the core DER uncertainty quantification approach independent of architectural complexity, we conduct an extensive controlled comparison study using a consistent LSTM architecture across five probabilistic methods: DER, Gaussian NLL, Student's-t NLL, Quantile Loss, and Conformal Prediction. Evaluation on cryptocurrency return forecasting demonstrates that DER maintains competitive forecasting accuracy while providing explicit epistemic-aleatoric uncertainty decomposition. This work establishes both an extensible framework for principled uncertainty quantification in foundation models and empirical evidence for DER's effectiveness in financial applications.

</details>


### [93] [On the origin of neural scaling laws: from random graphs to natural language](https://arxiv.org/abs/2601.10684)
*Maissam Barkeshli,Alberto Alfarano,Andrey Gromov*

Main category: cs.LG

TL;DR: 通过在可调复杂度的图和简化语言任务上训练2层变换器，证实神经尺度律不依赖数据功率律；尺度指数随任务复杂度单调降低；传统语言建模尺度律可用更简洁模型复现，并提出新的计算最优曲线方法与更高效的参数化方案。


<details>
  <summary>Details</summary>
Motivation: 探究神经尺度律产生的根本原因——是否仅由数据的功率律结构驱动；通过受控实验检验复杂度与尺度指数之间的关系；检验简化模型与传统尺度律的兼容性。

Method: 在可调复杂度的图上训练变换器预测随机游走双字边；使用不同层数的变换器语言模型（4→2→1层）及大纲生成的语言序列；在Erdös-Renyi和Barabási-Albert随机图上训练；对传统语言建模尺度律进行再探讨并提出替代的计算最优曲线计算方法。

Result: 1. 随机游走任务在无功率律数据下仍呈现明显尺度律。2. 随机图（Erdös-Renyi、Barabási-Albert）的尺度律符合预期。3. 语言复杂度降低时，尺度指数单调降低。4. 2层变换器能重现以往的尺度规律，并给出更合理的计算最优曲线。5. 最大更新参数化在参数效率上优于标准参数化。

Conclusion: 研究表明，即使在没有数据功率律结构的情况下，针对随机游走的变换器也会表现出神经尺度律；通过逐步简化自然语言，尺度指数呈单调演变；证明2层变换器即可重现传统语言建模尺度律，并提出更高效的计算最优曲线及最大更新参数化的潜在优势。

Abstract: Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this paper we study scaling laws for transformers trained to predict random walks (bigrams) on graphs with tunable complexity. We demonstrate that this simplified setting already gives rise to neural scaling laws even in the absence of power law structure in the data correlations. We further consider dialing down the complexity of natural language systematically, by training on sequences sampled from increasingly simplified generative language models, from 4,2,1-layer transformer language models down to language bigrams, revealing a monotonic evolution of the scaling exponents. Our results also include scaling laws obtained from training on random walks on random graphs drawn from Erdös-Renyi and scale-free Barabási-Albert ensembles. Finally, we revisit conventional scaling laws for language modeling, demonstrating that several essential results can be reproduced using 2 layer transformers with context length of 50, provide a critical analysis of various fits used in prior literature, demonstrate an alternative method for obtaining compute optimal curves as compared with current practice in published literature, and provide preliminary evidence that maximal update parameterization may be more parameter efficient than standard parameterization.

</details>


### [94] [Data-driven stochastic reduced-order modeling of parametrized dynamical systems](https://arxiv.org/abs/2601.10690)
*Andrew F. Ilersich,Kevin Course,Prasanth B. Nair*

Main category: cs.LG

TL;DR: 基于摊销式变分推断和重参数化的连续时间随机ROM框架，可在不同参数/激励下无需求解器地训练，显著提高效率并支持物理先验，三测试问题验证其出色泛化与效率。


<details>
  <summary>Details</summary>
Motivation: 高保真模拟在变条件下的复杂动力系统计算量巨大；现有ROM无法处理随机动力量化，限制了其在鲁棒决策中的应用。

Method: 采用摊销式随机变分推断与Markov高斯过程重参数化技巧，联合学习概率自编码器和隐状态的随机微分方程，消除训练过程中的昂贵前向求解器，支持物理信息先验。

Result: 在三道挑战性测试问题上，模型对未见参数组合和激励实现了出色泛化，并相较现有方法实现显著效率提升。

Conclusion: 此框架在不依赖数据集规模和系统刚性的前提下，能够快速训练具有连续时间随机动态的鲁棒ROM，并且能够量化预测不确定性。

Abstract: Modeling complex dynamical systems under varying conditions is computationally intensive, often rendering high-fidelity simulations intractable. Although reduced-order models (ROMs) offer a promising solution, current methods often struggle with stochastic dynamics and fail to quantify prediction uncertainty, limiting their utility in robust decision-making contexts. To address these challenges, we introduce a data-driven framework for learning continuous-time stochastic ROMs that generalize across parameter spaces and forcing conditions. Our approach, based on amortized stochastic variational inference, leverages a reparametrization trick for Markov Gaussian processes to eliminate the need for computationally expensive forward solvers during training. This enables us to jointly learn a probabilistic autoencoder and stochastic differential equations governing the latent dynamics, at a computational cost that is independent of the dataset size and system stiffness. Additionally, our approach offers the flexibility of incorporating physics-informed priors if available. Numerical studies are presented for three challenging test problems, where we demonstrate excellent generalization to unseen parameter combinations and forcings, and significant efficiency gains compared to existing approaches.

</details>


### [95] [Communication-Efficient and Privacy-Adaptable Mechanism -- a Federated Learning Scheme with Convergence Analysis](https://arxiv.org/abs/2601.10701)
*Chun Hei Michael Shiu,Chih Wei Ling*

Main category: cs.LG

TL;DR: CEPAM利用RSUQ实现量化误差可调，以同步提升通信效率和灵活的隐私保护，理论与实验表明其在多种场景下优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，通信效率与隐私保护往往相互制约；本研究旨在同时满足这两大需求，寻找既高效又可灵活调整隐私水平的解决方案。

Method: 提出并实现了基于拒绝采样通用量化器（RSUQ）的通信高效且可调隐私机制CEPAM，通过可调量化误差来实现隐私保护；对其隐私度量与收敛属性进行定量证明，并在多组实验场景中对比基线方法。

Result: 通过理论证明，CEPAM在满足预设隐私级别的前提下保持了可观的收敛速度；实验验证显示其在不同隐私设置下的准确率与基线方法相当或优于基线，同时展示了更优的收敛曲线和准确率-隐私平衡。

Conclusion: 本文对CEPAM的隐私保障与收敛性进行理论分析，并通过实验验证其在通信效率、隐私适配以及模型精度上的优势；实验结果表明CEPAM在多种基线模型下具有可观的收敛速度与精度-隐私折中效果。

Abstract: Federated learning enables multiple parties to jointly train learning models without sharing their own underlying data, offering a practical pathway to privacy-preserving collaboration under data-governance constraints. Continued study of federated learning is essential to address key challenges in it, including communication efficiency and privacy protection between parties. A recent line of work introduced a novel approach called the Communication-Efficient and Privacy-Adaptable Mechanism (CEPAM), which achieves both objectives simultaneously. CEPAM leverages the rejection-sampled universal quantizer (RSUQ), a randomized vector quantizer whose quantization error is equivalent to a prescribed noise, which can be tuned to customize privacy protection between parties. In this work, we theoretically analyze the privacy guarantees and convergence properties of CEPAM. Moreover, we assess CEPAM's utility performance through experimental evaluations, including convergence profiles compared with other baselines, and accuracy-privacy trade-offs between different parties.

</details>


### [96] [Distributed Perceptron under Bounded Staleness, Partial Participation, and Noisy Communication](https://arxiv.org/abs/2601.10705)
*Keval Jain,Anant Raj,Saurav Prakash,Girish Varma*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study a semi-asynchronous client-server perceptron trained via iterative parameter mixing (IPM-style averaging): clients run local perceptron updates and a server forms a global model by aggregating the updates that arrive in each communication round. The setting captures three system effects in federated and distributed deployments: (i) stale updates due to delayed model delivery and delayed application of client computations (two-sided version lag), (ii) partial participation (intermittent client availability), and (iii) imperfect communication on both downlink and uplink, modeled as effective zero-mean additive noise with bounded second moment. We introduce a server-side aggregation rule called staleness-bucket aggregation with padding that deterministically enforces a prescribed staleness profile over update ages without assuming any stochastic model for delays or participation. Under margin separability and bounded data radius, we prove a finite-horizon expected bound on the cumulative weighted number of perceptron mistakes over a given number of server rounds: the impact of delay appears only through the mean enforced staleness, whereas communication noise contributes an additional term that grows on the order of the square root of the horizon with the total noise energy. In the noiseless case, we show how a finite expected mistake budget yields an explicit finite-round stabilization bound under a mild fresh-participation condition.

</details>


### [97] [High-accuracy and dimension-free sampling with diffusions](https://arxiv.org/abs/2601.10708)
*Khashayar Gatmiry,Sitan Chen,Adil Salim*

Main category: cs.LG

TL;DR: 基于低阶逼近+点积法构建的求解器，在仅获取近似score的前提下，将迭代复杂度从多项式降低到多对数级，并仅与分布有效半径相关


<details>
  <summary>Details</summary>
Motivation: 对扩散模型进行高精度采样的迭代复杂度仍随维度与精度平方多项式增长，亟待改进

Method: 设计基于低阶逼近与点积法的解算器，兼容仅需近似score的情形

Result: 证明迭代复杂度仅与精度以多对数级增长，且仅受目标分布有效半径影响，首次提供高精度采样保证

Conclusion: 改进设计实现了对维度的弱化，提供了更高效的扩散模型采样方案

Abstract: Diffusion models have shown remarkable empirical success in sampling from rich multi-modal distributions. Their inference relies on numerically solving a certain differential equation. This differential equation cannot be solved in closed form, and its resolution via discretization typically requires many small iterations to produce \emph{high-quality} samples.
  More precisely, prior works have shown that the iteration complexity of discretization methods for diffusion models scales polynomially in the ambient dimension and the inverse accuracy $1/\varepsilon$. In this work, we propose a new solver for diffusion models relying on a subtle interplay between low-degree approximation and the collocation method (Lee, Song, Vempala 2018), and we prove that its iteration complexity scales \emph{polylogarithmically} in $1/\varepsilon$, yielding the first ``high-accuracy'' guarantee for a diffusion-based sampler that only uses (approximate) access to the scores of the data distribution. In addition, our bound does not depend explicitly on the ambient dimension; more precisely, the dimension affects the complexity of our solver through the \emph{effective radius} of the support of the target distribution only.

</details>


### [98] [DInf-Grid: A Neural Differential Equation Solver with Differentiable Feature Grids](https://arxiv.org/abs/2601.10715)
*Navami Kairanda,Shanthika Naik,Marc Habermann,Avinash Sharma,Christian Theobalt,Vladislav Golyanik*

Main category: cs.LG

TL;DR: DInf-Grid 是一种基于网格、使用径向基函数的无限可导表示，能在秒到分钟内高效求解 PDE，并比传统 MLP 方法快 5‑20 倍。


<details>
  <summary>Details</summary>
Motivation: 传统坐标基 MLP 较慢、计算量大；网格基方法虽快但受制于线性插值，无法高阶微分，限制了其在 DE 求解中的应用。

Method: 使用可微分网格表示，结合无限可导的径向基函数插值，并通过共定位的多分辨率分解提高对高频解的捕捉与全局梯度计算速度。

Result: DInf-Grid 在 Poisson、Helmholtz、Kirchhoff‐Love 等多种任务上实现 5‑20 倍的速度提升，求解时间从分钟降至秒级，且保持与 MLP 等方法相当的精度与压缩率。

Conclusion: DInf-Grid 通过融合几何特征网格与 RBF 插值，使得在保持高阶微分（无限可导）的同时，大幅提升求解微分方程的速度与稳定性，验证了在标准 PDE 任务中的优异表现。

Abstract: We present a novel differentiable grid-based representation for efficiently solving differential equations (DEs). Widely used architectures for neural solvers, such as sinusoidal neural networks, are coordinate-based MLPs that are both computationally intensive and slow to train. Although grid-based alternatives for implicit representations (e.g., Instant-NGP and K-Planes) train faster by exploiting signal structure, their reliance on linear interpolation restricts their ability to compute higher-order derivatives, rendering them unsuitable for solving DEs. Our approach overcomes these limitations by combining the efficiency of feature grids with radial basis function interpolation, which is infinitely differentiable. To effectively capture high-frequency solutions and enable stable and faster computation of global gradients, we introduce a multi-resolution decomposition with co-located grids. Our proposed representation, DInf-Grid, is trained implicitly using the differential equations as loss functions, enabling accurate modelling of physical fields. We validate DInf-Grid on a variety of tasks, including the Poisson equation for image reconstruction, the Helmholtz equation for wave fields, and the Kirchhoff-Love boundary value problem for cloth simulation. Our results demonstrate a 5-20x speed-up over coordinate-based MLP-based methods, solving differential equations in seconds or minutes while maintaining comparable accuracy and compactness.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [99] [Distributed Hypothesis Testing Under A Covertness Constraint](https://arxiv.org/abs/2601.09837)
*Ismaila Salihou Adamou,Michèle Wigger*

Main category: eess.SP

TL;DR: The paper solves covert distributed hypothesis testing on DMCs: universally characterizes the Stein exponent for partially-connected channels, proposes a superior exponent for fully-connected channels, all without secret keys, and shows fast decay of the covertness constraint.


<details>
  <summary>Details</summary>
Motivation: In many applications distributed sensors must send observations to a fusion center while remaining hidden from an external warden. Existing covert communication approaches typically require a shared secret key; this work explores covert hypothesis testing without such a key, addressing the realistic scenario of partially- or fully-connected channels and quantifying how covertness impacts detection performance.

Method: The authors analyze the Stein exponent by designing coding schemes that exploit the structure of partially-connected DMCs, proving achievability via appropriate stochastic encoding and hypothesis test construction. For fully-connected DMCs they propose a new coding/decoding method and derive the corresponding exponent. The analysis includes bounding the divergence to the warden and demonstrating its exponential decay.

Result: For partially-connected channels, the achievable Stein exponent is independent of the channel law and equals the Shalaby–Papamarcou exponent with a sublinear number of noiseless bits. For fully-connected channels, an achievable exponent that improves upon the local exponent of the decision center is provided. The developed schemes do not require a shared secret key and the warden’s detection metric (KL divergence) vanishes exponentially fast with blocklength.

Conclusion: The paper establishes the achievable Stein exponent for distributed hypothesis testing under a covert constraint on partially- and fully-connected discrete memoryless channels, showing that for partially-connected DMCs the exponent is universal (independent of the transition law) and equal to the known hyp.‑test exponent with a sublinear number of noiseless bits. For fully-connected DMCs an achievable exponent exceeding the local (decision‑center‑only) exponent is constructed. All schemes operate without a shared secret key and the covertness divergence decays (almost) exponentially with blocklength.

Abstract: We study distributed hypothesis testing under a covertness constraint in the non-alert situation, which requires that under the null-hypothesis an external warden be unable to detect whether communication between the sensor and the decision center is taking place. We characterize the achievable Stein exponent of this setup when the channel from the sensor to the decision center is a partially-connected discrete memoryless channel (DMC), i.e., when certain output symbols can only be induced by some of the inputs. The Stein-exponent in this case, does not depend on the specific transition law of the DMC and equals Shalaby and Papamarcou's exponent without a warden but where the sensor can send $k$ noise-free bits to the decision center, for $k$ a function that is sublinear in the observation length $n$. For fully-connected DMCs, we propose an achievable Stein-exponent and show that it can improve over the local exponent at the decision center. All our coding schemes do not require that the sensor and decision center share a common secret key, as commonly assumed in covert communication. Moreover, in our schemes the divergence covertness constraint vanishes (almost) exponentially fast in the obervation length $n$, again, an atypical behaviour for covert communication.

</details>


### [100] [Clustering-Based User Selection in Federated Learning: Metadata Exploitation for 3GPP Networks](https://arxiv.org/abs/2601.10013)
*Ce Zheng,Shiyao Ma,Ke Zhang,Chen Sun,Wenqi Zhang*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Federated learning (FL) enables collaborative model training without sharing raw user data, but conventional simulations often rely on unrealistic data partitioning and current user selection methods ignore data correlation among users. To address these challenges, this paper proposes a metadatadriven FL framework. We first introduce a novel data partition model based on a homogeneous Poisson point process (HPPP), capturing both heterogeneity in data quantity and natural overlap among user datasets. Building on this model, we develop a clustering-based user selection strategy that leverages metadata, such as user location, to reduce data correlation and enhance label diversity across training rounds. Extensive experiments on FMNIST and CIFAR-10 demonstrate that the proposed framework improves model performance, stability, and convergence in non-IID scenarios, while maintaining comparable performance under IID settings. Furthermore, the method shows pronounced advantages when the number of selected users per round is small. These findings highlight the framework's potential for enhancing FL performance in realistic deployments and guiding future standardization.

</details>


### [101] [Microwave Linear Analog Computer (MiLAC)-aided Multiuser MISO: Fundamental Limits and Beamforming Design](https://arxiv.org/abs/2601.10060)
*Zheyu Wu,Matteo Nerini,Bruno Clerckx*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As wireless communication systems evolve toward the 6G era, ultra-massive/gigantic MIMO is envisioned as a key enabling technology. Recently, microwave linear analog computer (MiLAC) has emerged as a promising approach to realize beamforming entirely in the analog domain, thereby alleviating the scalability challenges associated with gigantic MIMO. In this paper, we investigate the fundamental beamforming flexibility and design of lossless and reciprocal MiLAC-aided beamforming for MU-MISO systems. We first provide a rigorous characterization of the set of beamforming matrices achievable by MiLAC. Based on this characterization, we prove that MiLAC-aided beamforming does not generally achieve the full flexibility of digital beamforming, while offering greater flexibility than conventional phase-shifter-based analog beamforming. Furthermore, we propose a hybrid digital-MiLAC architecture and show that it achieves digital beamforming flexibility when the number of radio frequency (RF) chains equals the number of data streams, halving that required by conventional hybrid beamforming. We then formulate the MiLAC-aided sum-rate maximization problem for MU-MISO systems. To solve the problem efficiently, we reformulate the MiLAC-related constraints as a convex linear matrix inequality and establish a low-dimensional subspace property that significantly reduces the problem dimension. Leveraging these results, we propose WMMSE-based algorithms for solving the resulting problem. Simulation results demonstrate that MiLAC-aided beamforming achieves performance close to that of digital beamforming in gigantic MIMO systems. Compared with hybrid beamforming, it achieves comparable or superior performance with lower hardware and computational complexity by avoiding symbol-level digital processing and enabling low-resolution digital-to-analog converters (DACs).

</details>


### [102] [P-norm based Fractional-Order Robust Subband Adaptive Filtering Algorithm for Impulsive Noise and Noisy Input](https://arxiv.org/abs/2601.10074)
*Jianhong Ye,Haiquan Zhao,Yi Peng*

Main category: eess.SP

TL;DR: FoNSPN将分数阶SGD与MPE相结合，扩展了NSPN的适用域，提供了步长和β的理论分析，并在仿真中证明了其在α稳定噪声（尤其是α≤1）下的优势。


<details>
  <summary>Details</summary>
Motivation: 传统NSPN在低α（0<α≤1）噪声环境下性能严重下降，缺乏对极端冲击噪声的容错机制。

Method: 在MPE框架下整合分数阶随机梯度下降（FoSGD），并对步长、分数阶β的理论约束以及稳态均方偏差（MSD）进行分析，形成FoNSPN算法。

Result: 仿真结果显示，FoNSPN在多种冲击噪声场景中均优于现有最先进算法，特别是在α极限值处表现出更低的误差。

Conclusion: FoNSPN算法在α稳定噪声环境下表现出优越的稳健性，尤其在1<α≤2的低阶矩优先场景中优于传统NSPN。其对极端α≤1噪声的适应性通过引入分数阶SGD显著提升。

Abstract: Building upon the mean p-power error (MPE) criterion, the normalized subband p-norm (NSPN) algorithm demonstrates superior robustness in $α$-stable noise environments ($1 < α\leq 2$) through effective utilization of low-order moment hidden in robust loss functions. Nevertheless, its performance degrades significantly when processing noise input or additive noise characterized by $α$-stable processes ($0 < α\leq 1$). To overcome these limitations, we propose a novel fractional-order NSPN (FoNSPN) algorithm that incorporates the fractional-order stochastic gradient descent (FoSGD) method into the MPE framework. Additionally, this paper also analyzes the convergence range of its step-size, the theoretical domain of values for the fractional-order $β$, and establishes the theoretical steady-state mean square deviation (MSD) model. Simulations conducted in diverse impulsive noise environments confirm the superiority of the proposed FoNSPN algorithm against existing state-of-the-art algorithms.

</details>


### [103] [Low-Complexity Blind Estimator of SNR and MSE for mmWave Multi-Antenna Communications](https://arxiv.org/abs/2601.10331)
*Hanyoung Park,Ji-Woong Choi*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: To enhance the robustness and resilience of wireless communication and meet performance requirements, various environment-reflecting metrics, such as the signal-to-noise ratio (SNR), are utilized as the system parameter. To obtain these metrics, training signals such as pilot sequences are generally employed. However, the rapid fluctuations of the millimeter-wave (mmWave) propagation channel often degrade the accuracy of such estimations. To address this challenge, various blind estimators that operate without pilot have been considered as potential solutions. However, these algorithms often involve a training phase for machine learning or a large number of iterations, which implies prohibitive computational complexity, making them difficult to employ for real-time services and the system less resilient to dynamic environment variation. In this paper, we propose blind estimators for average noise power, signal power, SNR, and mean-square error (MSE) that do not require knowledge of the ground-truth signal or involve high computational complexity. The proposed algorithm leverages the inherent sparsity of mmWave channel in beamspace domain, which makes the signal and noise power components more distinguishable.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [104] [Enhancing Mobile Ad Hoc Networks (MANETs) with Software-Defined Networking (SDN): A Balanced Approach](https://arxiv.org/abs/2601.10556)
*Riccardo Fonti,Andrea Piroddi*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Mobile Ad Hoc Networks (MANETs) are decentralized wireless networks, characterized by their dynamic topologies and node mobility. In the era of cutting-edge technologies, integrating Software-Defined Networking (SDN) with MANETs offers a promising solution to manage these challenges more efficiently. This paper presents a balanced discussion of MANETs and SDN, demonstrating how SDN principles, such as centralized control and network virtualization, can optimize MANET performance in terms of scalability, cost-efficiency, and security. A mathematical model is developed to analyze Capital Expenditures (CAPEX), Operational Expenditures (OPEX), and network efficiency.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [105] [Collision Avoidance for Non-Cooperative Multi-Swarm Coverage Control with Bounded Disturbance Measurements](https://arxiv.org/abs/2601.09917)
*Karolina Schmidt,Luis Rodrigues*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper proposes a new algorithm for collision-free coverage control of multiple non-cooperating swarms in the presence of bounded disturbances. A new methodology is introduced that accounts for uncertainties in disturbance measurements. The proposed methodology is used to develop an algorithm that ensures collision-free motion in multi-swarm coverage control, specifically for cases where disturbances are present and their measurements are subject to bounded uncertainty. The theoretical results are validated through simulations of multiple swarms that independently aim to cover a given region in an environment with disturbances.

</details>


### [106] [Extremum Seeking Nonovershooting Control of Strict-Feedback Systems Under Unknown Control Direction](https://arxiv.org/abs/2601.09998)
*Kaixin Lu,Ziliang Lyu,Yanfang Mo,Yiguang Hong,Haoyong Yu*

Main category: eess.SY

TL;DR: 利用极值寻优+李括号控制，对未知控制方向的严格反馈非线性系统实现非过冲跟踪，并能通过参数调节降低过冲。


<details>
  <summary>Details</summary>
Motivation: 在安全关键场景下，存在未知控制方向的系统需要既能跟踪参考轨迹，又要保证不出现过冲的约束，以避免安全风险。

Method: 采用极值寻优与李括号方法相结合的控制策略，设计出从下方跟踪任意参考轨迹的控制律；通过参数调节可实现过冲减小。

Result: 实现了任意初始条件下，从下方跟踪参考轨迹的能力，并可通过参数微调将过冲降低到可接受的水平；同时满足高相对阶的非过冲约束。

Conclusion: 本文证明了在未知控制方向的严格反馈非线性系统中，可以通过极值寻优与李括号设计的组合实现近似非过冲跟踪，且能够将过冲降至任意小。

Abstract: This paper addresses the nonovershooting control problem for strict-feedback nonlinear systems with unknown control direction. We propose a method that integrates extremum seeking with Lie bracket-based design to achieve approximately nonovershooting tracking. The approach ensures that arbitrary reference trajectories can be tracked from below for any initial condition, with the overshoot reducible to arbitrarily small levels through parameter tuning. The method further provides a mechanism for enforcing high-relative-degree nonovershooting constraints in safety-critical scenarios involving unknown control directions.

</details>


### [107] [On the Computation and Approximation of Backward Reachable Sets for Max-Plus Linear Systems using Polyhedras](https://arxiv.org/abs/2601.10095)
*Yuda Li,Shaoyuan Li,Xiang Yin*

Main category: eess.SY

TL;DR: 开发了一种利用多面体近似的后向可达算法，可快速得到MPLS系统的近似可达集，显著优于传统DBM方法。


<details>
  <summary>Details</summary>
Motivation: 传统DBM方法在面临非凸多面体、集合补集操作时难以高效计算后向可达集，迫切需要新的近似策略。

Method: 利用极限化学多面体对非凸目标集进行闭包近似，将问题转化为符号运算序列，并通过构造外部M‑form与内部V‑form、极值过滤等手段减少计算复杂度。

Result: 实现了可对一般目标区域进行可靠近似后向可达分析，并在规模与精度上优于现有DBM方案。

Conclusion: 论文提出一种基于多面体近似的后向可达分析框架，显著提升了MPLS系统可达性分析的计算效率与可扩展性。

Abstract: This paper investigates reachability analysis for max-plus linear systems (MPLS), an important class of dynamical systems that model synchronization and delay phenomena in timed discrete-event systems. We specifically focus on backward reachability analysis, i.e., determining the set of states that can reach a given target set within a certain number of steps. Computing backward reachable sets presents significant challenges due to the non-convexity of max-plus dynamics and the complexity of set complement operations. To address these challenges, we propose a novel approximation framework that efficiently computes backward reachable sets by exploiting the structure of tropical polyhedra. Our approach reformulates the problem as a sequence of symbolic operations and approximates non-convex target sets through closure operations on unions of tropical polyhedra. We develop a systematic algorithm that constructs both outer (M-form) and inner (V-form) representations of the resulting sets, incorporating extremal filtering to reduce computational complexity. The proposed method offers a scalable alternative to traditional DBM-based approaches, enabling reliable approximate backward reachability analysis for general target regions in MPLS.

</details>


### [108] [HyMGP: A Customized MILP-Based Tool for Techno-Economic Planning of Islanded Microgrids](https://arxiv.org/abs/2601.10178)
*Andres Intriago,Rongxing Hu,Nabil Mohammed,S. Gokul Krishnan,Konstantinos Kotsovos,Issam Gereige,Nesren Attiah,Ali Basaheeh,Sarah Aqeel,Hamad A. Saiari,Shehab Ahmed,Charalambos Konstantinou*

Main category: eess.SY

TL;DR: 在干旱地区，利用MILP模型的HyMGP可为离网微电网进行灵活且成本效率更高的设计。


<details>
  <summary>Details</summary>
Motivation: 远程站点需要自给自足的能源系统，而VIP效率与成本受限于光热资源与负荷特征； 기존工具在组件规格与约束处理不够灵活；

Method: 通过将微电网规划建模为混合整数线性规划(MILP)，并在HyMGP工具中实现，可显式设置组件规格并严格约束，随后与HOMER Pro进行对比验证。

Result: 对沙特阿拉伯案例比验证：HyMGP在相同条件下提供更优解，加入风机能降低NPC，LFP电池成本更低。

Conclusion: HyMGP能够在干旱地区实现更灵活、更加经济的微电网配置，显著降低NPC，并对载荷特性和设备参数进行精细控制；

Abstract: This paper presents a customized microgrid planning algorithm and tool, HyMGP, for remote sites in arid regions, which is formulated as a Mixed Integer Linear Programming (MILP) problem. HyMGP is compared with HOMER Pro to evaluate its performance in optimizing the sizing of microgrid components, including photovoltaic panels (PVs), vertical axis wind turbines (VAWTs), and battery energy storage systems (BESS), for remote and off-grid applications. The study focuses on a standalone microgrid in the Saudi Arabia, considering high solar irradiance, limited wind availability, and a constant load profile composed of continuous cathodic protection and daytime cooling. In the simulation environment, comparisons with HOMER solutions demonstrate the advantages of HyMGP, which provides optimal and more flexible solutions by allowing user-defined component specifications and strictly enforcing all constraints. Further analysis shows that incorporating wind turbines reduces the Net Present Cost (NPC) by decreasing the required PV and battery capacities. Increasing battery autonomy leads to a higher NPC in both PV-only and hybrid systems due to the need for larger storage. Finally, lithium iron phosphate (Li-ion LFP) batteries are found to be more cost effective than lead acid, offering lower NPCs due to their longer lifespan, deeper discharge capability, and fewer replacement cycles.

</details>


### [109] [Model Predictive Control of Thermo-Hydraulic Systems Using Primal Decomposition](https://arxiv.org/abs/2601.10189)
*Jonathan Vieth,Annika Eichler,Arne Speerforck*

Main category: eess.SY

TL;DR: 本文通过自动化框架和原始分解技术，验证了在地下供暖系统上实现可扩展、有效的模型预测控制方法。


<details>
  <summary>Details</summary>
Motivation: 为实现全球能源去碳，需要更高效的供暖与制冷系统。模型预测控制（MPC）能提升此类系统运行效率，但其性能高度依赖精准的系统模型，传统上多基于控制体积建立。

Method: 本文提出一个自动化框架，结合时间离散化来生成针对控制体积模型的MPC控制器，并利用原始分解（primal decomposition）挖掘模型结构以提升可扩展性。

Result: 在地下供暖系统实验中，对不同状态数量进行验证，实验表明借助原始分解可以显著提升系统在状态维度扩展时的计算可扩展性。

Conclusion: 原始分解有效缓解了大规模MPC模型的计算瓶颈，使得自动化生成的控制器能够在更大规模的供暖制冷系统中保持高效运行，支持能源去碳目标。

Abstract: Decarbonizing the global energy supply requires more efficient heating and cooling systems. Model predictive control enhances the operation of cooling and heating systems but depends on accurate system models, often based on control volumes. We present an automated framework including time discretization to generate model predictive controllers for such models. To ensure scalability, a primal decomposition exploiting the model structure is applied. The approach is validated on an underground heating system with varying numbers of states, demonstrating the primal decomposition's advantage regarding scalability.

</details>


### [110] [Single-Feed Circularly Polarized Super Realized Gain Antenna](https://arxiv.org/abs/2601.10292)
*Georgia Psychogiou,Donal P. Lynch,Spyridon N. Daskalakis,Manos M. Tentzeris,George Goussetis,Stylianos D. Asimonis*

Main category: eess.SY

TL;DR: 一种单驱动、0.15λ低剖面平面交叉偶极天线，在3.5 GHz实现6.1 dB超指向性增益与圆偏振，具有23.75 %单位阻带宽与4 %轴比带宽，适用于compact sub‑6 GHz无线与传感平台。


<details>
  <summary>Details</summary>
Motivation: 在尺寸受限、集成度要求高的移动/传感设备中，需要在同一小尺寸天线中同时实现圆偏振和高增益。

Method: 通过细致调整条形宽度/长度增强互耦，再配合被动元素的有源负载，利用单驱动方式实现交叉偶极；随后利用仿真优化参数以最大化左旋圆偏振实现增益。

Result: 得到的天线在3.5 GHz时实现实际增益6.1 dB（ka≈1.65），50 Ω带宽3.29–4.17 GHz（23.75 %），轴比带宽3.43–3.57 GHz（4 %），轴比1.4 dB。

Conclusion: 该研究成功设计了一种单驱动、低剖面（0.15λ）的平面交叉偶极天线，既实现了超指向性增益6.1 dB，又保持了良好的圆偏振纯度，适用于compact sub‑6 GHz平台。

Abstract: This paper presents a super realized gain, circularly polarized strip-crossed dipole antenna operating at 3.5 GHz. Superdirective behavior is achieved by leveraging strong inter-element mutual coupling through careful adjustment of the strip dimensions. The antenna features a single driven element, with the other element passively loaded with a reactive impedance. The structure is optimized to maximize left-hand circularly polarized (LHCP) realized gain, ensuring high polarization purity and good impedance matching. The optimized design exhibits a 50 $Ω$ impedance bandwidth of 3.29 - 4.17 GHz (23.75%) and an axial-ratio bandwidth of 3.43 - 3.57 GHz (4%). At 3.5 GHz, the antenna achieves a peak realized gain of 6.1 dB ($ka \approx 1.65$), with an axial ratio of 1.4 dB. These results demonstrate that circular polarization and superdirectivity can be simultaneously realized in a geometrically simple, low-profile ($0.15λ$) antenna, rendering it suitable for integration into compact sub-6~GHz wireless and sensing platforms.

</details>


### [111] [Safe Trajectory Gradient Flow Control of a Grid-Interfacing Inverter](https://arxiv.org/abs/2601.10671)
*Trager Joswig-Jones,Baosen Zhang*

Main category: eess.SY

TL;DR: 提出安全轨迹梯度流控制器，可实时在电压源逆变器中嵌入硬件约束，仿真验证优化与约束兼顾，性能优越


<details>
  <summary>Details</summary>
Motivation: 传统方法大多忽视对逆变器硬件限流的约束，急切的后处理限制器可能导致不稳定或性能下降，需要一种能够在设计阶段就处理约束的控制方案

Method: 基于安全梯度流的滚动时域轨迹优化方法，将约束嵌入控制器设计，形成可实时执行的优化求解流程

Result: 仿真显示，该方法在每个控制周期仅使用有限次数优化步骤即可驱动逆变器输出到最优值，同时始终保持状态在约束范围内

Conclusion: 提出的安全轨迹梯度流控制器能够在电压源逆变器控制中直接考虑硬件约束，保证状态保持在安全集内并趋向最优平衡点

Abstract: Grid-interfacing inverters serve as the interface between renewable energy resources and the electric power grid, offering fast, programmable control capabilities. However, their operation is constrained by hardware limitations, such as bounds on the current magnitude. Existing control methods for these systems often neglect these constraints during controller design and instead rely on ad hoc limiters, which can introduce instability or degrade performance. In this work, we present a control framework that directly incorporates constraints into the control of a voltage-source inverter. We propose a safe trajectory gradient flow controller, which applies the safe gradient flow method to a rolling horizon trajectory optimization problem to ensure that the states remain within a safe set defined by the constraints while directing the trajectory towards an optimal equilibrium point of a nonlinear program. Simulation results demonstrate that our approach can drive the outputs of a simulated inverter system to optimal values and maintain state constraints, even when using a limited number of optimization steps per control cycle.

</details>
