<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 9]
- [cs.IT](#cs.IT) [Total: 11]
- [eess.SY](#eess.SY) [Total: 7]
- [cs.LG](#cs.LG) [Total: 53]
- [cs.CR](#cs.CR) [Total: 17]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Towards Radar-Agnostic Gait Analysis Across UWB and FMCW Systems](https://arxiv.org/abs/2601.04415)
*Charalambos Hadjipanayi,Maowen Yin,Alan Bannon,Ziwei Chen,Timothy G. Constandinou*

Main category: eess.SP

TL;DR: 这项研究表明，通过统一的雷达信号处理框架，IR-UWB与FMCW两种雷达均可在家居环境中精准持续地监测步态，不存在明显的模态差异，为雷达无关式步态分析系统奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 迫切需要一种非接触、连续、可在居家环境中实施的步态监测技术；已有雷达步态分析多为单模态且需针对不同雷达调参，限制了普适性与可迁移性。

Method: 在相同的处理设置下，对10名健康志愿者进行多次地面行走试验，采集IR-UWB和FMCW雷达信号，统一应用自动步态段分离方法，并将提取的步态参数与金标准运动捕捉系统进行对比，采用相关性、Bland‑Altman及ICC等统计方法评估精度与一致性。

Result: 两种雷达模态在步态参数（步长、步速、摆步时间等）上平均估计准确率均在85-98%；交模态差异低于4.1%，两者的误差分布高度重叠，相关性和ICC均显示出强一致性与无显著偏差。

Conclusion: 本研究证明，使用统一的雷达信号处理框架，无论是脉冲式超宽带（IR-UWB）还是调频连续波（FMCW）雷达，都能实现相同的步态时空参数估计精度，雷达模态差异不超过4.1%，因此雷达无关的步态分析系统具备可行性。

Abstract: Radar sensing has emerged in recent years as a promising solution for unobtrusive and continuous in-home gait monitoring. This study evaluates whether a unified processing framework can be applied to radar-based spatiotemporal gait analysis independent of radar modality. The framework is validated using collocated impulse-radio ultra-wideband (IR-UWB) and frequency-modulated continuous-wave (FMCW) radars under identical processing settings, without modality-specific tuning, during repeated overground walking trials with 10 healthy participants. A modality-independent approach for automatic walking-segment identification is also introduced to ensure fair and reproducible modality performance assessment. Clinically relevant spatiotemporal gait parameters, including stride time, stride length, walking speed, swing time, and stance time, extracted from each modality were compared against gold-standard motion capture reference estimates. Across all parameters, both radar modalities achieved comparably high mean estimation accuracy in the range of 85-98%, with inter-modality differences remaining below 4.1%, resulting in highly overlapping accuracy distributions. Correlation and Bland-Altman analyses revealed minimal bias, comparable limits of agreement, and strong agreement with reference estimates, while intraclass correlation analysis demonstrated high consistency between radar modalities. These findings indicate that no practically meaningful performance differences arise from radar modality when using a shared processing framework, supporting the feasibility of radar-agnostic gait analysis systems.

</details>


### [2] [Prediction of Cellular Malignancy Using Electrical Impedance Signatures and Supervised Machine Learning](https://arxiv.org/abs/2601.04478)
*Shadeeb Hossain*

Main category: eess.SP

TL;DR: 该研究根据细胞电学参数训练机器学习模型，随机森林表现最佳，显示出在癌细胞检测中的应用潜力


<details>
  <summary>Details</summary>
Motivation: 研究细胞电学性质在健康与恶性细胞间的差异，为诊断与分类提供潜在依据

Method: 系统综述33篇文章，收集量化电学参数，使用随机森林、支持向量机、K近邻三种监督机器学习模型，调参后评估分类性能（准确率及F1分数）

Result: 随机森林在最大深度4、100棵树时准确率约90%；KNN和SVM的F1分数分别为78%和76.5%

Conclusion: 将细胞电学特性与机器学习相结合，可显著提升诊断决策效果，未来可通过硬件原型实现现场细胞分类

Abstract: Bioelectrical properties of cells such as relative permittivity, conductivity, and characteristic time constants vary significantly between healthy and malignant cells across different frequencies. These distinctions provide a promising foundation for diagnostic and classification applications. This study systematically reviewed 33 scholarly articles to compile datasets of quantitative bioelectric parameters and evaluated their utility in predictive modeling. Three supervised machine learning algorithms- Random Forest (RF), Support Vector Machine (SVM), and K-Nearest Neighbor (KNN) were implemented and tuned using key hyperparameters to assess classification performance. Model effectiveness was evaluated using accuracy and F1 score as performance metrics. Results demonstrate that Random Forest achieved the highest predictive accuracy of ~ 90% when configured with a maximum depth of 4 and 100 estimators. These findings highlight the potential of integrating bioelectrical property analysis with machine learning for improved diagnostic decision-making. Similarly, for KNN and SVM, the F1 score peaked at approximately 78% and 76.5%, respectively. Future work will explore incorporating additional discriminative features, leveraging stimulated datasets, and optimizing hyperparameter through advanced search strategies. Ultimately, hardware prototype with embedded micro-electrodes and real-time control systems could pave the path for practical diagnostic tools capable of in-situ cell classification.

</details>


### [3] [Invisible Walls: Privacy-Preserving ISAC Empowered by Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2601.04488)
*Yinghui He,Long Fan,Lei Xie,Dusit Niyato,Chau Yuen,Jun Luo*

Main category: eess.SP

TL;DR: privisc的主要思路是：在ris上用两组近似相同通信响应但差异较大的感知向量随机组合配置，加入时域掩码/去掩码，让合法接收方可恢复所需csi，实验支撑了它既能隐匿隐私也不影响通信/感知。


<details>
  <summary>Details</summary>
Motivation: 无线信号所携带的环境和目标相关信息在集成感知与通信（ISAC）中受到关注，但存在隐私泄露风险，现有方案无法兼顾合法用户需求或成本高昂。

Method: PrivISAC通过在RIS每行分配两组不同波束向量，构造有限的RIS配置集；每个时隙随机激活一组配置，引入扰动隐藏敏感信息。两组向量在通信方向响应相近、在感知方向差异明显；同时引入时域掩码/去掩码技术，使合法接收者可关联CSI与配置并消除差异以恢复有效CSI。

Result: 实验表明PrivISAC在商用无线设备上实现，既保障隐私，又保持了高质量的合法ISAC性能。

Conclusion: PrivISAC提供了一种低成本、可即插即用的RIS方案，能够在保证合法通信和感知的前提下显著提升隐私保护。

Abstract: The environmental and target-related information inherently carried in wireless signals, such as channel state information (CSI), has brought increasing attention to integrated sensing and communication (ISAC). However, it also raises pressing concerns about privacy leakage through eavesdropping. While existing efforts have attempted to mitigate this issue, they either fail to account for the needs of legitimate communication and sensing users or rely on hardware with high complexity and cost. To overcome these limitations, we propose PrivISAC, a plug-and-play, low-cost solution that leverages RIS to protect user privacy while preserving ISAC performance. At the core of PrivISAC is a novel strategy in which each RIS row is assigned two distinct beamforming vectors, from which we deliberately construct a limited set of RIS configurations. During operation, exactly one configuration is randomly activated at each time slot to introduce additional perturbations, effectively masking sensitive sensing information from unauthorized eavesdroppers. To jointly ensure privacy protection and communication performance, we design the two vectors such that their responses remain nearly identical in the communication direction, thereby preserving stable, high-throughput transmission, while exhibiting pronounced differences in the sensing direction, which introduces sufficient perturbations to thwart eavesdroppers. Additionally, to enable legitimate sensing under such randomized configurations, we introduce a time-domain masking and demasking method that allows the authorized receiver to associate each CSI sample with its underlying configuration and eliminate configuration-induced discrepancies, thereby recovering valid CSI. We implement PrivISAC on commodity wireless devices and experiment results show that PrivISAC provides strong privacy protection while preserving high-quality legitimate ISAC.

</details>


### [4] [An Ultra-Fast MLE for Low SNR Multi-Reference Alignment](https://arxiv.org/abs/2601.04831)
*Shay Kreymer,Amnon Balanov,Tamir Bendory*

Main category: eess.SP

TL;DR: 通过对对数似然进行泰勒展开，利用一次数据平均即可在低信噪比下快速估计MRA信号，大幅降低计算负担，并为EM提供良好初始化。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决单粒子冷冻电子显微镜中多参考对齐（MRA）任务，重建被随机旋转误差和噪声掩盖的未知信号。

Method: 在低信噪比（SNR）情形下，对对数似然函数做泰勒展开，随后通过一次性计算数据驱动的观测平均序列来估计信号，避免了传统EM迭代过程。

Result: 数值实验表明，该方法在低SNR环境中可达高精度估计，同时显著降低计算成本，并能为后续EM精细化提供优秀的初始化。

Conclusion: 本文提出的超快速MRA算法在计算效率和定位精度上均优于传统EM，特别适用于低SNR窗口，可作为EM后续优化的高质量起点。

Abstract: Motivated by single-particle cryo-electron microscopy, multi-reference alignment (MRA) models the task of recovering an unknown signal from multiple noisy observations corrupted by random rotations. The standard approach, expectation-maximization (EM), often becomes computationally prohibitive, particularly in low signal-to-noise ratio (SNR) settings. We introduce an alternative, ultra-fast algorithm for MRA over the special orthogonal group $\mathrm{SO}(2)$. By performing a Taylor expansion of the log-likelihood in the low-SNR regime, we estimate the signal by sequentially computing data-driven averages of observations. Our method requires only one pass over the data, dramatically reducing computational cost compared to EM. Numerical experiments show that the proposed approach achieves high accuracy in low-SNR environments and provides an excellent initialization for subsequent EM refinement.

</details>


### [5] [SE-EE Tradeoff in Pinching-Antenna Systems: Waveguide Multiplexing or Waveguide Switching?](https://arxiv.org/abs/2601.04844)
*Guangyu Zhu,Xidong Mu,Li Guo,Shibiao Xu,Yuanwei Liu,Naofal Al-Dhahir*

Main category: eess.SP

TL;DR: 研究PASS的SE-EE折中，在WM下使用交替优化+粒子群，WS则先提升信道增益后分配功率，结果显示PASS优于传统天线，WM和WS各有优势。


<details>
  <summary>Details</summary>
Motivation: 提高传输系统在频谱和能耗方面的综合性能，探讨波导多路复用与波导切换在pinching-antenna系统中的效果。

Method: 通过多目标优化（MOOP）联合优化基带与束缚波束，随后采用ε-约束将其转化为单目标问题；WM使用交替优化框架结合序列凸逼近与粒子群优化；WS采用先最大化用户信道增益的束缚波束，再做基带功率分配。

Result: PASS相比传统天线降低大尺度路径损失；WS在激活单RF链时实现更高能效，而WM在同时服务全部用户时实现更高频谱效率；当用户数增多时WM显著提升SE，WS在低信噪比下更具优势。

Conclusion: PASS系统通过合适的波导多路复用或切换协议达成在频谱效率和能效之间的折中，并在不同的使用情境下显示出优越性能。

Abstract: The spectral and energy efficiency (SE-EE) trade-off in pinching-antenna systems (PASS) is investigated in this paper. In particular, two practical operating protocols, namely waveguide multiplexing (WM) and waveguide switching (WS), are considered. A multi-objective optimization problem (MOOP) is formulated to jointly optimize the baseband and pinching beamforming for maximizing the achievable SE and EE, which is then converted into a single-objective problem via the ε-constraint method. For WM, the problem is decomposed within the alternating-optimization framework, where the baseband beamforming is optimized using the successive convex approximation, and the pinching beamforming is updated through the particle swarm optimization. For WS, due to the time-division transmission and interference-free nature, the pinching beamforming in each time slot is first adjusted to maximize the served user channel gain, followed by the baseband power allocation. Simulation results demonstrate that 1) PASS outperforms conventional antennas by mitigating large-scale path losses; 2) WS leads to a higher maximum achievable EE by activating a single RF chain, whereas WM yields a higher SE upper bound by serving all users concurrently; and 3) increasing the number of users substantially enhances SE under WM, whereas WS shows more pronounced benefits in low-signal-to-noise ratio regimes.

</details>


### [6] [6D Movable Antenna Enhanced Cell-free MIMO: Two-timescale Decentralized Beamforming and Antenna Movement Optimization](https://arxiv.org/abs/2601.04969)
*Yichi Zhang,Yuchen Zhang,Wenyan Ma,Lipeng Zhu,Jianquan Wang,Wanbin Tang,Rui Zhang*

Main category: eess.SP

TL;DR: 该论文提出一种双时标分散优化框架，以实现六维可移动天线的无基站MIMO，在短时标下局部更新波束，长时标下全局优化天线位姿，利用受限随机连续凸近似求解非凸问题，结果显示性能优于传统方案。


<details>
  <summary>Details</summary>
Motivation: 集中式全局CSI共享导致高耗时与开销，难以在短码时衰场景下实现；需实现可伸缩、低时延的天线与波束优化方案。

Method: 在短时标下每个AP仅利用本地瞬时CSI与全局统计CSI更新接收波束形成器；在长时标下CPU基于全局统计CSI对所有AP的天线位置与阵列方向进行优化；采用受限随机连续凸近似（CSCMA）算法求解耦合非凸问题。

Result: 实验显示相较于其它运动天线方案，提出的分散波束方案性能大幅提升，且与集中式基准相近；显著提高了全局平均速率。

Conclusion: 通过双时标分散优化，6DMA支持的无基站方案在高移动性场景下能显著降低时延和开销，同时实现与集中式波束成形相近甚至更优的整体吞吐量。

Abstract: This paper investigates a six-dimensional movable antenna (6DMA)-aided cell-free multi-user multiple-input multiple-output (MIMO) communication system. In this system, each distributed access point (AP) can flexibly adjust its array orientation and antenna positions to adapt to spatial channel variations and enhance communication performance. However, frequent antenna movements and centralized beamforming based on global instantaneous channel state information (CSI) sharing among APs entail extremely high signal processing delay and system overhead, which is difficult to be practically implemented in high-mobility scenarios with short channel coherence time. To address these practical implementation challenges and improve scalability, a two-timescale decentralized optimization framework is proposed in this paper to jointly design the beamformer, antenna positions, and array orientations. In the short timescale, each AP updates its receive beamformer based on local instantaneous CSI and global statistical CSI. In the long timescale, the central processing unit optimizes the antenna positions and array orientations at all APs based on global statistical CSI to maximize the ergodic sum rate of all users. The resulting optimization problem is non-convex and involves highly coupled variables, thus posing significant challenges for obtaining efficient solutions. To address this problem, a constrained stochastic successive convex approximation algorithm is developed. Numerical results demonstrate that the proposed 6DMA-aided cell-free system with decentralized beamforming significantly outperforms other antenna movement schemes with less flexibility and even achieves a performance comparable to that of the centralized beamforming benchmark.

</details>


### [7] [Ultra-Wideband Transmission Systems From an Energy Perspective: Which Band is Next?](https://arxiv.org/abs/2601.05000)
*Ronit Sohanpal,Mindaugus Jarmolovicius,Jiaqian Yang,Eric Sillekens,Romulo Aparecido,Vitaly Mikhailov,Jiawei Luo,David J. DiGiovanni,Ruben S. Luis,Hideaki Furukawa,Robert I. Killey,Polina Bayvel*

Main category: eess.SP

TL;DR: 使用OESCL-band可在1000 km传输中实现近300%吞吐量提升，但每比特能耗提高约48%


<details>
  <summary>Details</summary>
Motivation: 评估OESCL-band相对于CL-band在长距离传输中的性能

Method: 测量最先进OESCL-band放大器的功率效率

Result: 通过测量，发现OESCL-band系统在1000 km时比CL-band传输仅提高48%的能耗中实现了2.98倍的吞吐量

Conclusion: 1000 km OESCL-band systems achieve 2.98倍的吞吐量，并且能耗每比特高48%

Abstract: Measuring the power efficiency of the state-of-the-art OESCL-band amplifiers, we show that 1000 km OESCL-band systems can achieve 2.98x greater throughput for +48% higher energy-per-bit compared to CL-band transmission only.

</details>


### [8] [On the Impact of Channel Aging and Doppler-Affected Clutter on OFDM ISAC Systems](https://arxiv.org/abs/2601.05032)
*Steven Rivetti,Gabor Fodor,Emil Björnson,Mikael Skoglund*

Main category: eess.SP

TL;DR: 本文针对 ISAC 中慢速信道老化与快速多普勒杂波的联合效应，提出了基于历史导频的老化感知信道估计器与低复杂度杂波抑制感知管线。实验表明，在低至中等移动率场景下，信道估计与目标探测性能显著优于传统块衰落模型；同时，实际杂波抑制可行，且通信波束无法满足范围分辨率需求，需引入专用感知波束。


<details>
  <summary>Details</summary>
Motivation: 传统 ISAC 系统往往只关注静态或块衰落信道，忽略了慢时间尺度的信道老化与快时间尺度的 多普勒杂波对感知与通信双重性能的耦合影响。为填补这一研究空白，本文侧重研究两者的联合效应。

Method: 采用正交频分复用框架，利用自回归模型刻画信道老化，并对多普勒杂波建模为无相关、相干补丁的 Kronecker 可分离协方差结构；提出基于历史导频的老化感知信道估计器和低复杂度的杂波抑制传感流水线，并通过幅度-角度与幅度-速度映射提取目标参数。

Result: 在低至中等移动率下，相较于块衰落模型，基于历史导频的老化感知估计器在信道估计精度上实现了显著提升；在真实杂波环境中，利用估计的杂波统计实现低强度抑制后，能够成功提取目标参数；并发现通信波束在范围分辨率上不足，需要专用感知波束。

Conclusion: 本文通过考虑信道老化与多普勒杂波的联合影响，提出了适应时变传播环境的 ISAC 系统模型和解决方案，显著提升了低至中等移动场景下的信道估计与目标探测性能，并验证了在实际杂波环境中实现有效杂波抑制的可行性。

Abstract: The temporal evolution of the propagation environment plays a central role in integrated sensing and communication (ISAC) systems. A slow-time evolution manifests as channel aging in communication links, while a fast-time one is associated with structured clutter with non-zero Doppler. Nevertheless, the joint impact of these two phenomena on ISAC performance has been largely overlooked. This addresses this research gap in a network utilizing orthogonal frequency division multiplexing waveforms. Here, a base station simultaneously serves multiple user equipment (UE) devices and performs monostatic sensing. Channel aging is captured through an autoregressive model with exponential correlation decay. In contrast, clutter is modeled as a collection of uncorrelated, coherent patches with non-zero Doppler, resulting in a Kronecker-separable covariance structure. We propose an aging-aware channel estimator that uses prior pilot observations to estimate the time-varying UE channels, characterized by a non-isotropic multipath fading structure. The clutter's structure enables a novel low-complexity sensing pipeline: clutter statistics are estimated from raw data and subsequently used to suppress the clutter's action, after which target parameters are extracted through range-angle and range-velocity maps. We evaluate the influence of frame length and pilot history on channel estimation accuracy and demonstrate substantial performance gains over block fading in low-to-moderate mobility regimes. The sensing pipeline is implemented in a clutter-dominated environment, demonstrating that effective clutter suppression can be achieved under practical configurations. Furthermore, our results show that dedicated sensing streams are required, as communication beams provide insufficient range resolution.

</details>


### [9] [Multi-band Carrier Phase Positioning toward 6G: Performance Bounds and Efficient Estimators](https://arxiv.org/abs/2601.05178)
*Ehsan Shourezari,Ossi Kaltiokallio,Mehmet C. Ilter,Jukka Talvitie,Gonzalo Seco-Granados,Henk Wymeersch,Mikko Valkama*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In addition to satellite systems, carrier phase positioning (CPP) is gaining attraction also in terrestrial mobile networks, particularly in 5G New Radio evolution toward 6G. One key challenge is to resolve the integer ambiguity problem, as the carrier phase provides only relative position information. This work introduces and studies a multi-band CPP scenario with intra- and inter-band carrier aggregation (CA) opportunities across FR1, mmWave-FR2, and emerging 6G FR3 bands. Specifically, we derive multi-band CPP performance bounds, showcasing the superiority of multi-band CPP for high-precision localization in current and future mobile networks, while noting also practical imperfections such as clock offsets between the user equipment (UE) and the network as well as mutual clock imperfections between the network nodes. A wide collection of numerical results is provided, covering the impacts of the available carrier bandwidth, number of aggregated carriers, transmit power, and the number of network nodes or base stations. The offered results highlight that only two carriers suffice to substantially facilitate resolving the integer ambiguity problem while also largely enhancing the robustness of positioning against imperfections imposed by the network-side clocks and multi-path propagation. In addition, we also propose a two-stage practical estimator that achieves the derived bounds under all realistic bandwidth and transmit power conditions. Furthermore, we show that with an additional search-based refinement step, the proposed estimator becomes particularly suitable for narrowband Internet of Things applications operating efficiently even under narrow carrier bandwidths. Finally, both the derived bounds and the proposed estimators are extended to scenarios where the bands assigned to each base station are nonuniform or fully disjoint, enhancing the practical deployment flexibility.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [10] [Achievable Rate and Coding Principle for MIMO Multicarrier Systems With Cross-Domain MAMP Receiver Over Doubly Selective Channels](https://arxiv.org/abs/2601.04433)
*Yuhao Chi,Zhiyuan Peng,Lei Liu,Ying Li,Yao Ge,Chau Yuen*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The integration of multicarrier modulation and multiple-input-multiple-output (MIMO) is critical for reliable transmission of wireless signals in complex environments, which significantly improve spectrum efficiency. Existing studies have shown that popular orthogonal time frequency space (OTFS) and affine frequency division multiplexing (AFDM) offer significant advantages over orthogonal frequency division multiplexing (OFDM) in uncoded doubly selective channels. However, it remains uncertain whether these benefits extend to coded systems. Meanwhile, the information-theoretic limit analysis of coded MIMO multicarrier systems and the corresponding low-complexity receiver design remain unclear. To overcome these challenges, this paper proposes a multi-slot cross-domain memory approximate message passing (MS-CD-MAMP) receiver as well as develops its information-theoretic (i.e., achievable rate) limit and optimal coding principle for MIMO-multicarrier modulation (e.g., OFDM, OTFS, and AFDM) systems. The proposed MS-CD-MAMP receiver can exploit not only the time domain channel sparsity for low complexity but also the corresponding symbol domain constellation constraints for performance enhancement. Meanwhile, limited by the high-dimensional complex state evolution (SE), a simplified single-input single-output variational SE is proposed to derive the achievable rate of MS-CD-MAMP and the optimal coding principle with the goal of maximizing the achievable rate. Numerical results show that coded MIMO-OFDM/OTFS/AFDM with MS-CD-MAMP achieve the same maximum achievable rate in doubly selective channels, whose finite-length performance with practical optimized low-density parity-check (LDPC) codes is only 0.5 $\sim$ 1.8 dB away from the associated theoretical limit, and has 0.8 $\sim$ 4.4 dB gain over the well-designed point-to-point LDPC codes.

</details>


### [11] [Bridging Distance and Spectral Positional Encodings via Anchor-Based Diffusion Geometry Approximation](https://arxiv.org/abs/2601.04517)
*Zimo Yan,Zheng Xie,Runfan Duan,Chang Liu,Wumei Du*

Main category: cs.IT

TL;DR: The paper shows that anchor‑based distance encodings can approximate diffusion geometry well, and using them (via a trilateration map and Nyström scheme) boosts molecular graph learning performance.


<details>
  <summary>Details</summary>
Motivation: To understand the precise relationship between spectral (Laplacian/diffusion) and anchor‑based distance encodings used for positional signals in molecular graph learning, and to develop a principled way to recover diffusion geometry from distance information.

Method: Interpret distance encodings via a low‑rank surrogate of diffusion geometry and construct a trilateration map that reconstructs truncated diffusion coordinates from anchor distances and anchor spectral positions; provide pointwise and Frobenius‑gap guarantees on random regular graphs and evaluate a distance‑driven Nyström scheme on DrugBank molecular graphs using a shared GNN‑based DDI prediction backbone.

Result: On DrugBank molecular graphs, the distance‑driven Nyström scheme closely recovers the diffusion geometry, and both Laplacian and distance encodings substantially outperform a no‑encoding baseline in DDI prediction tasks.

Conclusion: Molecular graph learning benefits from positional signals that capture both local neighborhoods and global topology; distance encodings can serve as a low-rank surrogate of diffusion geometry and recover diffusion coordinates effectively, leading to improved performance over no-encoding baselines.

Abstract: Molecular graph learning benefits from positional signals that capture both local neighborhoods and global topology. Two widely used families are spectral encodings derived from Laplacian or diffusion operators and anchor-based distance encodings built from shortest-path information, yet their precise relationship is poorly understood. We interpret distance encodings as a low-rank surrogate of diffusion geometry and derive an explicit trilateration map that reconstructs truncated diffusion coordinates from transformed anchor distances and anchor spectral positions, with pointwise and Frobenius-gap guarantees on random regular graphs. On DrugBank molecular graphs using a shared GNP-based DDI prediction backbone, a distance-driven Nyström scheme closely recovers diffusion geometry, and both Laplacian and distance encodings substantially outperform a no-encoding baseline.

</details>


### [12] [Feasibility Study Regarding Self-sustainable Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2601.04723)
*Zhenyu Li,Ozan Alp Topal,Özlem Tuğfe Demir,Emil Björnson,Cicek Cavdar*

Main category: cs.IT

TL;DR: 研究证明ssRIS可行：TS适合室内小功率场景，ES适合户外高需求场景。


<details>
  <summary>Details</summary>
Motivation: 通过自我可持续的RIS，零运维成本，在传统基站无法覆盖的位置提升覆盖。

Method: 对比分析两种HaR方案（ES与TS），在LOS/NLOS、发射功率、数据速率与可靠性约束下评估所需天线数量与性能。

Result: TS在可靠性要求下需求稳定，但随采集难度与速率呈指数增长；ES则随难度线性增长，适合恶劣环境。

Conclusion: TS在室内无障碍环境下表现更优，ES在户外恶劣条件下更具可行性。

Abstract: Without requiring operational costs such as cabling and powering while maintaining reconfigurable phase-shift capability, self-sustainable reconfigurable intelligent surfaces (ssRISs) can be deployed in locations inaccessible to conventional relays or base stations, offering a novel approach to enhance wireless coverage. This study assesses the feasibility of ssRIS deployment by analyzing two harvest-and-reflect (HaR) schemes: element-splitting (ES) and time-splitting (TS). We examine how element requirements scale with key system parameters, transmit power, data rate demands, and outage constraints under both line-of-sight (LOS) and non-line-of-sight (NLOS) ssRIS-to-user equipment (UE) channels. Analytical and numerical results reveal distinct feasibility characteristics. The TS scheme demonstrates better channel hardening gain, maintaining stable element requirements across varying outage margins, making it advantageous for indoor deployments with favorable harvesting conditions and moderate data rates. However, TS exhibits an element requirement that exponentially scales to harvesting difficulty and data rate. Conversely, the ES scheme shows only linear growth with harvesting difficulty, providing better feasibility under challenging outdoor scenarios. These findings establish that TS excels in benign environments, prioritizing reliability, while ES is preferable for demanding conditions requiring operational robustness.

</details>


### [13] [Privacy-Utility Trade-offs Under Multi-Level Point-Wise Leakage Constraints](https://arxiv.org/abs/2601.04815)
*Amirreza Zamani,Parastoo Sadeghi,Mikael Skoglund*

Main category: cs.IT

TL;DR: 本文提出多层点际泄漏隐私机制，并通过信息几何与矩阵奇异值分析得到二次型闭式解，证明最优方案可采用二值化 U，极大简化实现。


<details>
  <summary>Details</summary>
Motivation: 在隐私机制设计中实现信息与隐私的平衡

Method: 基于多层点际泄漏的最优方案形式化，利用信息几何近似并构成二次优化

Result: 得到闭式解；证明仅需二值化输出U即可达到最优实用性

Conclusion: 提出多层点际泄漏，一个更灵活且可实现完美隐私与部分泄漏共存的框架，并给出低复杂度的实现方法

Abstract: An information-theoretic privacy mechanism design is studied, where an agent observes useful data $Y$ which is correlated with the private data $X$. The agent wants to reveal the information to a user, hence, the agent utilizes a privacy mechanism to produce disclosed data $U$ that can be revealed. We assume that the agent has no direct access to $X$, i.e., the private data is hidden. We study privacy mechanism design that maximizes the disclosed information about $Y$, measured by the mutual information between $Y$ and $U$, while satisfying a point-wise constraint with different privacy leakage budgets. We introduce a new measure, called the \emph{multi-level point-wise leakage}, which allows us to impose different leakage levels for different realizations of $U$. In contrast to previous studies on point-wise measures, which use the same leakage level for each realization, we consider a more general scenario in which each data point can leak information up to a different threshold. As a result, this concept also covers cases in which some data points should not leak any information about the private data, i.e., they must satisfy perfect privacy. In other words, a combination of perfect privacy and non-zero leakage can be considered. When the leakage is sufficiently small, concepts from information geometry allow us to locally approximate the mutual information. We show that when the leakage matrix $P_{X|Y}$ is invertible, utilizing this approximation leads to a quadratic optimization problem that has closed-form solution under some constraints. In particular, we show that it is sufficient to consider only binary $U$ to attain the optimal utility. This leads to simple privacy designs with low complexity which are based on finding the maximum singular value and singular vector of a matrix.

</details>


### [14] [Stability of Constrained Optimization Models for Structured Signal Recovery](https://arxiv.org/abs/2601.04849)
*Yijun Zhong,Yi Shen*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recovering an unknown but structured signal from its measurements is a challenging problem with significant applications in fields such as imaging restoration, wireless communications, and signal processing. In this paper, we consider the inherent problem stems from the prior knowledge about the signal's structure, such as sparsity which is critical for signal recovery models. We investigate three constrained optimization models that effectively address this challenge, each leveraging distinct forms of structural priors to regularize the solution space. Our theoretical analysis demonstrates that these models exhibit robustness to noise while maintaining stability with respect to tuning parameters that is a crucial property for practical applications, when the parameter selection is often nontrivial. By providing theoretical foundations, our work supports their practical use in scenarios where measurement imperfections and model uncertainties are unavoidable. Furthermore, under mild conditions, we establish tradeoff between the sample complexity and the mismatch error.

</details>


### [15] [Wireless Communication with Cross-Linked Rotatable Antenna Array: Architecture Design and Rotation Optimization](https://arxiv.org/abs/2601.04862)
*Ailing Zheng,Qingqing Wu,Ziyuan Zheng,Qiaoyan Peng,Yanze Zhu,Honghao Wang,Wen Chen,Guoying Zhang*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Rotatable antenna (RA) technology can harness additional spatial degrees of freedom by enabling the dynamic three-dimensional orientation control of each antenna. Unfortunately, the hardware cost and control complexity of traditional RA systems is proportional to the number of RAs. To address the issue, we consider a cross-linked (CL) RA structure, which enables the coordinated rotation of multiple antennas, thereby offering a cost-effective solution. To evaluate the performance of the CL-RA array, we investigate a CL-RA-aided uplink system. Specifically, we first establish system models for both antenna element-level and antenna panel-level rotation. Then, we formulate a sum rate maximization problem by jointly optimizing the receive beamforming at the base station and the rotation angles. For the antenna element-level rotation, we derive the optimal solution of the CL-RA array under the single-user case. Subsequently, for two rotation schemes, we propose an alternating optimization algorithm to solve the formulated problem in the multi-user case, where the receive beamforming and the antenna rotation angles are obtained by applying the minimum mean square error method and feasible direction method, respectively. In addition, considering the hardware limitations, we apply the genetic algorithm to address the discrete rotation angles selection problem. Simulation results show that by carefully designing the row-column partition scheme, the performance of the CL-RA architecture is quite close to that of the flexible antenna orientation scheme. Moreover, the CL antenna element-level scheme surpasses the CL antenna panel-level scheme by 25% and delivers a 128% performance improvement over conventional fixed-direction antennas.

</details>


### [16] [Learning Sparsifying Transforms for mmWave Communication via $\ell^4$-Norm Maximization](https://arxiv.org/abs/2601.04980)
*Sueda Taner,Christoph Studer*

Main category: cs.IT

TL;DR: 本文验证DFT并非毫米波通道的最优稀疏化变换，提出复数域ℓ⁴最大化字典学习方法，并通过两种算法学习到了更高效的波束域变换，显著提升通道稀疏度并降低处理复杂度。


<details>
  <summary>Details</summary>
Motivation: 毫米波频段信道高度可定向，通道向量稀疏，但传统基于DFT的波束域稀疏化是否最优尚未知；若能得到更稀疏的变换，可进一步降低数字信号处理复杂度与功耗。

Method: 在复数域中推广Zhai等人的ℓ⁴范数最大化字典学习框架，提出两种基于梯度与子空间迭代的学习算法；通过理论分析与仿真实验评估DFT的稀疏性能，并利用所得算法学习针对实测与合成mmWave通道的改进稀疏变换。

Result: 提供了ℓ⁴范数最大化在复数域的理论基础，设计并验证了两种学习算法；结果表明DFT并非最优，且所学习的稀疏化变换在实测与合成通道上均能提升稀疏性，实现更低的基带复杂度。

Conclusion: DFT并非在所有有限维天线阵列中都是最优的稀疏化变换；通过对复数域扩展的ℓ⁴‑范数最大化字典学习，可得到更稀疏、更高效的变换。

Abstract: The high directionality of wave propagation at millimeter-wave (mmWave) carrier frequencies results in only a small number of significant transmission paths between user equipments and the basestation (BS). This sparse nature of wave propagation is revealed in the beamspace domain, which is traditionally obtained by taking the spatial discrete Fourier transform (DFT) across a uniform linear antenna array at the BS, where each DFT output is associated with a distinct beam. In recent years, beamspace processing has emerged as a promising technique to reduce baseband complexity and power consumption in all-digital massive multiuser (MU) multiple-input multiple-output (MIMO) systems operating at mmWave frequencies. However, it remains unclear whether the DFT is the optimal sparsifying transform for finite-dimensional antenna arrays. In this paper, we extend the framework of Zhai et al. for complete dictionary learning via $\ell^4$-norm maximization to the complex case in order to learn new sparsifying transforms. We provide a theoretical foundation for $\ell^4$-norm maximization and propose two suitable learning algorithms. We then utilize these algorithms (i) to assess the optimality of the DFT for sparsifying channel vectors theoretically and via simulations and (ii) to learn improved sparsifying transforms for real-world and synthetically generated channel vectors.

</details>


### [17] [Refinements of Jensen's Inequality for Twice-Differentiable Convex Functions with Bounded Hessian](https://arxiv.org/abs/2601.05030)
*Sambhab Mishra*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Jensen's inequality, attributed to Johan Jensen -- a Danish mathematician and engineer noted for his contributions to the theory of functions -- is a ubiquitous result in convex analysis, providing a fundamental lower bound for the expectation of a convex function. In this paper, we establish rigorous refinements of this inequality specifically for twice-differentiable functions with bounded Hessians. By utilizing Taylor expansions with integral remainders, we tried to bridge the gap between classical variance-based bounds and higher-precision estimates. We also discover explicit error terms governed by Gruss-type inequalities, allowing for the incorporation of skewness and kurtosis into the bound. Using these new theoretical tools, we improve upon existing estimates for the Shannon entropy of continuous distributions and the ergodic capacity of Rayleigh fading channels, demonstrating the practical efficacy of our refinements.

</details>


### [18] [Precoding Matrix Indicator in the 5G NR Protocol: A Tutorial on 3GPP Beamforming Codebooks](https://arxiv.org/abs/2601.05092)
*Boyu Ning,Haifan Yin,Sixu Liu,Hao Deng,Songjie Yang,Yuchen Zhang,Weidong Mei,David Gesbert,Jaebum Park,Robert W. Heath,Emil Björnson*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper bridges this critical gap by providing a systematic examination of the beamforming codebook technology, i.e., precoding matrix indicator (PMI), in the 5G NR from theoretical, standardization, and implementation perspectives. We begin by introducing the background of beamforming in multiple-input multiple-output (MIMO) systems and the signaling procedures for codebook-based beamforming in practical 5G systems. Then, we establish the fundamentals of regular codebooks and port-selection codebooks in 3GPP standards. Next, we provide rigorous technical analysis of 3GPP codebook evolution spanning Releases 15-18, with particular focus on: 1) We elucidate the core principles underlying codebook design, 2) provide clear physical interpretations for each symbolic variable in the codebook formulas, summarized in tabular form, and 3) offer intuitive visual illustrations to explain how codebook parameters convey information. These essential pedagogical elements are almost entirely absent in the often-obscure standardization documents. Through mathematical modeling, performance benchmarking, feedback comparisons, and scenario-dependent applicability analysis, we provide researchers and engineers with a unified understanding of beamforming codebooks in real-world systems. Furthermore, we identify future directions and other beamforming scenarios for ongoing research and development efforts. This work serves as both an informative tutorial and a guidance for future research, facilitating more effective collaboration between academia and industry in advancing wireless communication technologies.

</details>


### [19] [Fundamental Tradeoffs for ISAC Multiple Access in Finite-Blocklength Regime](https://arxiv.org/abs/2601.05165)
*Zhentian Zhang,Christos Masouros,Kai-Kit Wong,Jian Dang,Zaichen Zhang,Kaitao Meng,Farshad Rostami Ghadi,Mohammad Javad Ahmadi*

Main category: cs.IT

TL;DR: 本文在有限块长度环境下分析上行双功能ISAC的通信–感知权衡，提供几何分解、可达/对偶界限和CRB，并用数值验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究在FBL约束下，传统渐进分析不适用情形下的通信–感知权衡，以指导短包通信和低时延应用的系统设计。

Method: 对短包和低时延条件下的上行双功能ISAC信道进行几何分解，推导可达性与对偶性界限，并利用通用CRB将信道估计误差与感知参数联系。

Result: 得到可达性与对偶性界限、以Shannon容量为上界的对偶界限，以及将信道估计误差与感知参数关联的CRB；数值实验验证了理论结果并显示了块长度、天线尺寸和感知需求的影响。

Conclusion: 在有限块长度（FBL）限制下，使用几何分解、可达性与对偶性界定和CRB分析揭示了上行双功能ISAC在通信速率与感知精度之间的根本平衡，并指出信号相关性对性能的关键影响。

Abstract: This paper investigates the fundamental communication--sensing tradeoffs of uplink dual-functional integrated sensing and communication (ISAC) multiple access under finite blocklength (FBL) constraints. Unlike conventional asymptotic analyses, we explicitly account for the limitations under FBL constraints imposed by short packets and low-latency transmission. By examining the unbiased channel state sensing estimator, we establish a geometric decomposition of the sensing error, indicating that it is jointly determined by the signal-to-noise ratio and the correlation structure of the information codebook. This insight reveals how cross-correlation among active users in the codebook geometry fundamentally constrains dual-functional ISAC performance. Consequently, we derive achievability and converse bounds that characterize the tradeoff between communication code rate and sensing accuracy in the FBL regime, with the converse further bounded by Shannon capacity. Moreover, by treating channel state sensing as a high-level sensing objective, a universal Cramér--Rao bound is derived to link channel estimation accuracy to practical sensing parameters. Examples of parameter sensing are also provided based on 3GPP standard. Numerical results validate the theoretical analysis and demonstrate the impact of blocklength, antenna dimensions, and sensing requirements.

</details>


### [20] [Information-Theoretic Limits on Exact Subgraph Alignment Problem](https://arxiv.org/abs/2601.05173)
*Chun Hei Michael Shiu,Hei Victor Cheng,Lele Wang*

Main category: cs.IT

TL;DR: 本文定义子图对齐问题，使用随机模型给出信息论极限，证明几乎紧致可恢复，并提供新的分析思路。


<details>
  <summary>Details</summary>
Motivation: 现有图对齐假设两图共享顶点集合，无法定位大图中的小图模式，实际应用中需要识别子图模式，因而引入子图对齐。

Method: 构造Erdős–Rényi子图对偶模型并定义恢复指标，利用信息论方法与图结构性质分析得到阈值。

Result: 给出子图对齐的上限与下限，并证明在随机模型中上下界相差无多角，提出新分析工具，实现几乎紧致恢复。

Conclusion: 本文提出了子图对齐问题并给出了信息论极限，证明该问题在多种情形下几乎紧致可恢复，表明在随机建模下可用策略可定位小图模式并恢复对应关系。

Abstract: The graph alignment problem aims to identify the vertex correspondence between two correlated graphs. Most existing studies focus on the scenario in which the two graphs share the same vertex set. However, in many real-world applications, such as computer vision, social network analysis, and bioinformatics, the task often involves locating a small graph pattern within a larger graph. Existing graph alignment algorithms and analysis cannot directly address these scenarios because they are not designed to identify the specific subset of vertices where the small graph pattern resides within the larger graph. Motivated by this limitation, we introduce the subgraph alignment problem, which seeks to recover both the vertex set and/or the vertex correspondence of a small graph pattern embedded in a larger graph. In the special case where the small graph pattern is an induced subgraph of the larger graph and both the vertex set and correspondence are to be recovered, the problem reduces to the subgraph isomorphism problem, which is NP-complete in the worst case. In this paper, we formally formulate the subgraph alignment problem by proposing the Erdos-Renyi subgraph pair model together with some appropriate recovery criterion. We then establish almost-tight information-theoretic results for the subgraph alignment problem and present some novel approaches for the analysis.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [21] [Identification of a Kalman filter: consistency of local solutions](https://arxiv.org/abs/2601.04198)
*Léo Simpson,Moritz Diehl*

Main category: eess.SY

TL;DR: 本文证明，在只估计卡尔曼增益的最大似然或预测误差框架中，局部极小值随着样本增加变为唯一值，而且是一致估计；提供了设计优化问题的方向，并通过三组例子验证。


<details>
  <summary>Details</summary>
Motivation: 提升线性动态系统辨识中的卡尔曼滤波器调优精度，解决传统方法易陷入非凸优化局部最优导致的识别不稳定问题。

Method: 通过分析最大似然/预测误差方法在仅估计卡尔曼增益时的局部极小值的统计行为，证明目标函数的渐近单峰性，并给出优化问题设计准则；随后推广到联合估计其它线性参数与噪声协方差。

Result: 证明了局部最优解在统计上与真实卡尔曼增益一致；展示了目标函数随样本增长趋于单峰的收敛；并给出了调优准则和三例实证演示。

Conclusion: 论文表明，在仅估计卡尔曼增益的情形下，局部极小值在统计上是一致的，且随着样本量的增加目标函数变为单峰，唯一极小点即全局极小点；因此，在系统辨识中出现局部极小点并非卡尔曼增益调优所致。

Abstract: Prediction error and maximum likelihood methods are powerful tools for identifying linear dynamical systems and, in particular, enable the joint estimation of model parameters and the Kalman filter used for state estimation. A key limitation, however, is that these methods require solving a generally non-convex optimization problem to global optimality. This paper analyzes the statistical behavior of local minimizers in the special case where only the Kalman gain is estimated. We prove that these local solutions are statistically consistent estimates of the true Kalman gain. This follows from asymptotic unimodularity: as the dataset grows, the objective function converges to a limit with a unique local (and therefore global) minimizer. We further provide guidelines for designing the optimization problem for Kalman filter tuning and discuss extensions to the joint estimation of additional linear parameters and noise covariances. Finally, the theoretical results are illustrated using three examples of increasing complexity. The main practical takeaway of this paper is that difficulties caused by local minimizers in system identification are, at least, not attributable to the tuning of the Kalman gain.

</details>


### [22] [Definition and Formulation of Inertia Service Incorporating Inverter-Based Resources](https://arxiv.org/abs/2601.04504)
*Sojin Park,Ross Baldick,Hunyoung Shin*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Increasing concerns over the scarcity of inertia have motivated the procurement of inertia as an ancillary service (AS). Despite numerous academic and practical efforts, there remains a lack of consensus regarding the definition and treatment of inertia service in market operations, particularly the specification of inertia variables and the separation between synchronous inertia (SI) from synchronous generators and virtual inertia (VI) from inverter-based resources. To address these issues, this paper proposes a power-oriented (P-oriented) definition based on inertial response, which establishes conceptual consistency between SI and VI and makes the inertia service commensurable with other ASs. This definition explicitly incorporates both positive and negative inertial responses during frequency drop events. We then formulate a security-constrained economic dispatch framework based on this P-oriented definition and demonstrate its practical effectiveness through simulations. Case studies on a modified IEEE 30-bus system show that the proposed bidirectional service definition ensures price signals that reflect the economic value of inertial provision.

</details>


### [23] [Matrix-Valued Passivity Indices: Foundations, Properties, and Stability Implications](https://arxiv.org/abs/2601.04796)
*Xi Ru,Xiaoyu Peng,Xinghua Chen,Zhaojian Wang,Peng Yang,Feng Liu*

Main category: eess.SY

TL;DR: 将被动性指数从标量扩展为矩阵，揭示系统几何结构，更全面地描述 MIMO 被动性，降低控制保守性。


<details>
  <summary>Details</summary>
Motivation: 传统被动性指数仅为标量，不足以描述 MIMO 系统中不同通道间的耦合特性；迫切需要一种能够捕捉方向与强度信息的更丰富指标。

Method: 通过将标量指数推广为矩阵形式，对被动性指数与消耗性函数二阶变分关联进行几何解读；针对 LTI 系统，研究了矩阵在 Loewner 偏序下的结构，并给出两种代表性矩阵挑选准则。

Result: 构造了一般化的矩阵被动性框架，证明其在 LTI 系统中的有效性；新框架实现了更低的去被动化投入、更少的保守性，并在多通道耦合表现上超越标量指数。

Conclusion: 文章提出并验证了矩阵形式的被动性指数，使得多输入多输出系统的被动性分析更为精准与全面；与传统标量指数相比，新方法揭示了被动性耦合、降低了去被动化需求，并提升了稳定性评估的保守程度。

Abstract: The passivity index, a quantitative measure of a system's passivity deficiency or excess, has been widely used in stability analysis and control. Existing studies mostly rely on scalar forms of indices, which are restrictive for multi-input, multi-output (MIMO) systems. This paper extends the classical scalar indices to a systematic matrix-valued framework, referred to as passivity matrices. A broad range of classical results in passivity theory can be naturally generalized in this framework. We first show that, under the matrix representation, passivity indices essentially correspond to the curvature of the dissipativity functional under a second-variation interpretation. This result reveals that the intrinsic geometric structure of passivity consists of its directions and intensities, which a scalar index cannot fully capture. For linear time-invariant (LTI) systems, we examine the structural properties of passivity matrices with respect to the Loewner partial order and propose two principled criteria for selecting representative matrices. Compared with conventional scalar indices, the matrix-valued indices capture the passivity coupling among different input-output channels in MIMO systems and provide a more comprehensive description of system passivity. This richer information leads to lower passivation effort and less conservative stability assessment.

</details>


### [24] [Towards Sustainable 6G: A Holistic View of Trade-offs and Enablers](https://arxiv.org/abs/2601.04817)
*Mattia Merluzzi,Olivier Bouchet,Ali Balador,Gilles Callebaut,Anastasius Gavras,Liesbet Van der Perre,Albert Banchs,Mauro Renato Boldi,Emilio Calvanese Strinati,Bahare M Khorsandi,Marja Matinmikko-Blue,Lars Christoph Schmelz*

Main category: eess.SY

TL;DR: 本研究从社会价值出发，构建 6G 与可持续性之间的技术权衡框架，提出具体研究问题，旨在指导 6G 的生态友好设计与标准化过程。


<details>
  <summary>Details</summary>
Motivation: 为实现可持续未来，6G 需要解决连网盲区、碳排放以及人与机器在复杂环境中的安全协作等挑战。

Method: 提出整体视角，将 6G 与可持续性之间复杂交互转化为可操作的技术权衡与研究问题，结合技术创新与标准化路径。

Result: 形成一套技术权衡方案及对应的研究议题，展示如何通过设计与标准实现 6G 的可持续性。

Conclusion: 6G 若以平衡正负影响的设计为核心，可成为推动社会可持续发展的关键技术。

Abstract: The sixth generation of mobile networks (6G) can play a central role in shaping a sustainable future, the most compelling contemporary challenge. Connecting the unconnected, reducing carbon emissions of vertical sectors, and allowing heterogeneous types of intelligence (including humans) to safely and constructively interact in complex environments, are only a few of the several challenges that can be supported by 6G. However, this requires a careful design that balances positive and negative impacts of 6G, towards a sustainable and sustainability-enabling technology. This paper presents a holistic view that translates the complex interplay between the 6G enabling effects and the sustainability of 6G by design, into concrete trade-offs and research questions. Starting from today's challenges for society and associated key values, we unfold the dilemma into a set of technical trade-offs, whose solutions span from technological innovations to standardization actions towards applicability.

</details>


### [25] [Safe Reinforcement Learning Beyond Baseline Control: A Hierarchical Framework for Space Triangle Tethered Formation System](https://arxiv.org/abs/2601.04957)
*Xinyi Tao,Panfeng Huang,Fan Zhang*

Main category: eess.SY

TL;DR: 基于模型参考强化学习+SAC的层级训练控制显著提升TTFS部署精度与能效，闭环稳定性得到证明，仿真验证误差和燃料消耗大幅降低。


<details>
  <summary>Details</summary>
Motivation: 传统控制方法在TTFS中难以兼顾配置精度、张力约束与能源效率，且受耦合动力学与扰动影响显著，需要新型控制策略。

Method: 采用基于模型参考的强化学习控制架构，融合软演员-策动者（SAC）补偿器，并构建层级训练方案；设计奖励函数、复位条件与归一化标准以加速收敛；使用李雅普诺夫方法证明闭环稳定性。

Result: 仿真表明闭环跟踪误差降低96%（系泊线）和99%（节点卫星），燃料消耗相比基线方法降低两位数，验证了方法的有效性与稳定性。

Conclusion: 该研究通过模型参考强化学习控制框架，结合软演员-策动者搭配基线模型控制，有效提升三角系泊系统（TTFS）部署过程中的姿态与力学精度，保障张力限制并显著降低燃料消耗，实现闭环稳定性并在仿真中证明了高性能与稳定性。

Abstract: Triangular tethered formation system (TTFS) provide a promising platform for deep space exploration and distributed sensing due to its intrinsic spatial-orientation stability and capability of adjusting distances among node satellites through deployment and retrieval of tethers. However, due to the coupled tether-satellite dynamics and disturbance sensitivity of TTFS, traditional control methods struggle to achieve a balanced trade-off among configuration accuracy requirements, tension constraints, and energy efficiency consumption throughout the deployment process.In this paper, a novel model-reference reinforcement learning control framework is proposed for TTFS. By integrating baseline model-based control with a Soft Actor-Critic (SAC) compensator, the proposed method simultaneously achieves high-precision tracking, fuel efficiency, and compliance with tension limits. A hierarchical training scheme is developed to address the convergence difficulties arising from strongly coupled states in centralized training, while tailored reward functions, reset conditions, and normalization criteria are designed to accelerate training convergence. Closed-loop stability of the overall control law is rigorously proven using Lyapunov methods. Simulation results demonstrate that the proposed controller reduces steady-state tracking errors by over 96% for tethers and 99% for node satellites, while cutting fuel consumption by two orders of magnitude compared with the baseline method. These results validate the effectiveness and stability of the proposed approach for TTFS deployment control.

</details>


### [26] [Effect of Dispatch Decisions on Small-Signal Stability of Converter-Dominated Power Systems](https://arxiv.org/abs/2601.05070)
*Maitraya Avadhut Desai,Ognjen Stanojev,Simon Muntwiler,Gabriela Hug*

Main category: eess.SY

TL;DR: 本文系统探讨了投 dispatch 与 small‑signal stability 的关系，结果显示 GFL 的电容/电感模式及 GFM 的功率分配对稳定性影响显著，提供了决策参考。


<details>
  <summary>Details</summary>
Motivation: 过去的小信号稳定性研究多聚焦于控制设计，忽略了功率流变量与工况对系统稳定性的敏感性，导致在实际调度策略未能充分考虑稳定性的场景。

Method: 采用系统化的参数灵敏度分析方法，对三节点系统和IEEE 39节点标准系统进行逐工况模拟，评估不同调度下的电压、电流及频率耦合对小信号稳定边界的影响。

Result: 研究发现：高压电容式GFL操作会限制其有功功率注入，电感式运行可提升注入能力；通常更优的策略是让GFM转换器承担更多有功功率。该结论在三节点和IEEE39节点系统上均得到验证，并展示了可扩展性。

Conclusion: 本文指出在为主的电能转换器电力系统中，考虑电动度量变量与调度决策对小信号稳定性的影响至关重要。通过在不同工况下系统地分析，小信号稳定性受调度引导显著改变，尤其是GFM和GFL转换器的功率上限与工作模式决定了系统的整体稳定区域。

Abstract: Small-signal stability of modern converter-dominated power systems has been the subject of extensive research, particularly from the perspective of device-level control design for grid-forming (GFM) and grid-following (GFL) converters. However, the influence of power flow variables on system stability has received limited attention. Conventional small-signal stability analyses are typically conducted at a specific operating point, emphasizing the selection of control or system design parameters while neglecting the sensitivity of stability characteristics to operating conditions. This paper seeks to bridge this gap by systematically investigating the impact of dispatch decisions on the small-signal stability of converter-based power systems. Our findings are first illustrated on a three-bus system and then validated on the standard IEEE 39-bus test system to demonstrate scalability. Across the test systems, we find that high-voltage capacitive operation of GFL converters limits its active power injection, whereas inductive operation permits higher injections, and it is generally preferable for the GFM converter to supply more active power.

</details>


### [27] [Online Bayesian Learning of Agent Behavior in Differential Games](https://arxiv.org/abs/2601.05087)
*Francesco Bianchin,Robert Lefringhausen,Sandra Hirche*

Main category: eess.SY

TL;DR: 将HJB条件线性化做为贝叶斯更新的残差，利用基函数扩展实现在线多智能体行为识别，实验表明预测精度高且可量化不确定性。


<details>
  <summary>Details</summary>
Motivation: 需要在有限、带噪数据下对多智能体系统的行为进行实时、不确定性感知的预测，以支持自适应交互和实时决策。

Method: 通过将Hamilton‑Jacobi‑Bellman最优性条件转化为线性参数残差，使用基函数扩展，应对非线性动力学与非二次价值函数，从而实现快速 Bayesian 更新。

Result: 在线性二次与非线性共享控制实验中，模型实现了量化不确定性的准确预测。

Conclusion: 本文提出一种在线贝叶斯博弈方法，可在多智能体动力系统中实现行为识别，并支持序贯更新和不确定性评估。

Abstract: This work introduces an online Bayesian game-theoretic method for behavior identification in multi-agent dynamical systems. By casting Hamilton-Jacobi-Bellman optimality conditions as linear-in-parameter residuals, the method enables fast sequential Bayesian updates, uncertainty-aware inference, and robust prediction from limited, noisy data-without history stacks. The approach accommodates nonlinear dynamics and nonquadratic value functions through basis expansions, providing flexible models. Experiments, including linear-quadratic and nonlinear shared-control scenarios, demonstrate accurate prediction with quantified uncertainty, highlighting the method's relevance for adaptive interaction and real-time decision making.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [28] [The Forgotten Shield: Safety Grafting in Parameter-Space for Medical MLLMs](https://arxiv.org/abs/2601.04199)
*Jiale Zhao,Xing Mou,Jinlin Wu,Hongyuan Yu,Mingrui Sun,Yang Shi,Xuanwu Yin,Zhen Chen,Zhen Lei,Yaohua Wang*

Main category: cs.LG

TL;DR: 医疗多模态LM安全存在漏洞，尤其是跨模态突破与安全遗忘。本文提出参数空间干预法，提取基础模型安全知识并注入目标模型，细粒度搜索平衡安全与性能。实验显示，安全显著提升，医学性能几乎不受影响。


<details>
  <summary>Details</summary>
Motivation: 医疗大型语言模型安全研究相对滞后，可能导致真实场景部署风险。需系统评估其安全性，找出薄弱环节，并提出高效、安全性再对齐方案。

Method: 1）构建多维安全评估框架，系统度量当前前沿模型的通用与医学安全维度；2）设计参数空间干预机制，从基础模型中提取安全知识表示，再将其并入目标模型的医学构建阶段；3）制定细粒度参数搜索算法，实现安全与医学性能的最优权衡。

Result: 实验验证表明，参数空间干预显著提升模型安全防护水平，抵御跨模态 jailbreak 攻击，并在保持医学功能的同时，将安全性遗忘最小化；安全提升幅度大，核心医学性能损失极小。

Conclusion: 本研究证明，医疗多模态大型语言模型在面对跨模态突破攻击及医学微调后安全记忆灾难性遗忘时存在普遍缺陷。通过引入参数空间干预策略，能够在不依赖额外领域安全数据的前提下，有效重新对齐模型安全性，并保持核心医学性能的最小衰退。

Abstract: Medical Multimodal Large Language Models (Medical MLLMs) have achieved remarkable progress in specialized medical tasks; however, research into their safety has lagged, posing potential risks for real-world deployment. In this paper, we first establish a multidimensional evaluation framework to systematically benchmark the safety of current SOTA Medical MLLMs. Our empirical analysis reveals pervasive vulnerabilities across both general and medical-specific safety dimensions in existing models, particularly highlighting their fragility against cross-modality jailbreak attacks. Furthermore, we find that the medical fine-tuning process frequently induces catastrophic forgetting of the model's original safety alignment. To address this challenge, we propose a novel "Parameter-Space Intervention" approach for efficient safety re-alignment. This method extracts intrinsic safety knowledge representations from original base models and concurrently injects them into the target model during the construction of medical capabilities. Additionally, we design a fine-grained parameter search algorithm to achieve an optimal trade-off between safety and medical performance. Experimental results demonstrate that our approach significantly bolsters the safety guardrails of Medical MLLMs without relying on additional domain-specific safety data, while minimizing degradation to core medical performance.

</details>


### [29] [Green MLOps: Closed-Loop, Energy-Aware Inference with NVIDIA Triton, FastAPI, and Bio-Inspired Thresholding](https://arxiv.org/abs/2601.04250)
*Mustapha Hamdi,Mourad Jabou*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Energy efficiency is a first-order concern in AI deployment, as long-running inference can exceed training in cumulative carbon impact. We propose a bio-inspired framework that maps protein-folding energy basins to inference cost landscapes and controls execution via a decaying, closed-loop threshold. A request is admitted only when the expected utility-to-energy trade-off is favorable (high confidence/utility at low marginal energy and congestion), biasing operation toward the first acceptable local basin rather than pursuing costly global minima. We evaluate DistilBERT and ResNet-18 served through FastAPI with ONNX Runtime and NVIDIA Triton on an RTX 4000 Ada GPU. Our ablation study reveals that the bio-controller reduces processing time by 42% compared to standard open-loop execution (0.50s vs 0.29s on A100 test set), with a minimal accuracy degradation (<0.5%). Furthermore, we establish the efficiency boundaries between lightweight local serving (ORT) and managed batching (Triton). The results connect biophysical energy models to Green MLOps and offer a practical, auditable basis for closed-loop energy-aware inference in production.

</details>


### [30] [Safety-Utility Conflicts Are Not Global: Surgical Alignment via Head-Level Diagnosis](https://arxiv.org/abs/2601.04262)
*Wang Cai,Yilin Wen,Jinchang Hou,Du Su,Guoqiu Wang,Zhonghou Lv,Chenfu Bao,Yunfang Wu*

Main category: cs.LG

TL;DR: CAST 对 LLM 的安全微调提出头级诊断与稀疏更新方法，跳过高冲突头显著缓解通用能力下降，保持安全性。


<details>
  <summary>Details</summary>
Motivation: 全局梯度调节忽视了 Transformer 中不同头的异质性，导致重要功能被不必要地破坏。

Method: 先计算优化冲突与功能敏感度的组合得到冲突地图，然后在稀疏微调过程中只更新低冲突头，跳过高冲突头。

Result: 实验表明低冲突头占大多数，一小部分高冲突头的更新导致大多数一般能力下降，去除这些头可大幅降低损失。

Conclusion: 通过针对高冲突注意力头的稀疏微调，CAST 能在不显著损失安全性的前提下显著减少一般能力的下降，从而实现更优的安全-效用权衡。

Abstract: Safety alignment in Large Language Models (LLMs) inherently presents a multi-objective optimization conflict, often accompanied by an unintended degradation of general capabilities. Existing mitigation strategies typically rely on global gradient geometry to resolve these conflicts, yet they overlook Modular Heterogeneity within Transformers, specifically that the functional sensitivity and degree of conflict vary substantially across different attention heads. Such global approaches impose uniform update rules across all parameters, often resulting in suboptimal trade-offs by indiscriminately updating utility sensitive heads that exhibit intense gradient conflicts. To address this limitation, we propose Conflict-Aware Sparse Tuning (CAST), a framework that integrates head-level diagnosis with sparse fine-tuning. CAST first constructs a pre-alignment conflict map by synthesizing Optimization Conflict and Functional Sensitivity, which then guides the selective update of parameters. Experiments reveal that alignment conflicts in LLMs are not uniformly distributed. We find that the drop in general capabilities mainly comes from updating a small group of ``high-conflict'' heads. By simply skipping these heads during training, we significantly reduce this loss without compromising safety, offering an interpretable and parameter-efficient approach to improving the safety-utility trade-off.

</details>


### [31] [Predictable Gradient Manifolds in Deep Learning: Temporal Path-Length and Intrinsic Rank as a Complexity Regime](https://arxiv.org/abs/2601.04270)
*Anherutowa Calvo*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Deep learning optimization exhibits structure that is not captured by worst-case gradient bounds. Empirically, gradients along training trajectories are often temporally predictable and evolve within a low-dimensional subspace. In this work we formalize this observation through a measurable framework for predictable gradient manifolds.
  We introduce two computable quantities: a prediction-based path length that measures how well gradients can be forecast from past information, and a predictable rank that quantifies the intrinsic temporal dimension of gradient increments. We show how classical online and nonconvex optimization guarantees can be restated so that convergence and regret depend explicitly on these quantities, rather than on worst-case variation.
  Across convolutional networks, vision transformers, language models, and synthetic control tasks, we find that gradient trajectories are locally predictable and exhibit strong low-rank structure over time. These properties are stable across architectures and optimizers, and can be diagnosed directly from logged gradients using lightweight random projections.
  Our results provide a unifying lens for understanding optimization dynamics in modern deep learning, reframing standard training as operating in a low-complexity temporal regime. This perspective suggests new directions for adaptive optimizers, rank-aware tracking, and prediction-based algorithm design grounded in measurable properties of real training runs.

</details>


### [32] [Unlocking the Pre-Trained Model as a Dual-Alignment Calibrator for Post-Trained LLMs](https://arxiv.org/abs/2601.04277)
*Beier Luo,Cheng Wang,Hongxin Wei,Sharon Li,Xuefeng Du*

Main category: cs.LG

TL;DR: Dual‑Align：单温度双阶段校准，解决信心漂移与推理路径漂移，显著提升LLM的置信度校准。


<details>
  <summary>Details</summary>
Motivation: 传统静态输出匹配忽视了推理时动态变化，导致自信漂移与过程漂移并存；需兼顾两种误差来源。

Method: 在后训练阶段，Dual‑Align先进行最终输出分布匹配的“confidence alignment”以纠正信心漂移；然后定位推理路径分歧层，执行“process alignment”以恢复后续层次的稳定性，两步共学习单一温度参数。

Result: 在多组大型语言模型实验中，Dual‑Align相较基线显著降低校准误差，且保留了后训练的性能提升，逼近有监督校准的效果。

Conclusion: Dual-Align通过双重校准策略有效减少大型语言模型的自信过度，几乎达到有监督样本的信心校准水平。

Abstract: Post-training improves large language models (LLMs) but often worsens confidence calibration, leading to systematic overconfidence. Recent unsupervised post-hoc methods for post-trained LMs (PoLMs) mitigate this by aligning PoLM confidence to that of well-calibrated pre-trained counterparts. However, framing calibration as static output-distribution matching overlooks the inference-time dynamics introduced by post-training. In particular, we show that calibration errors arise from two regimes: (i) confidence drift, where final confidence inflates despite largely consistent intermediate decision processes, and (ii) process drift, where intermediate inference pathways diverge. Guided by this diagnosis, we propose Dual-Align, an unsupervised post-hoc framework for dual alignment in confidence calibration. Dual-Align performs confidence alignment to correct confidence drift via final-distribution matching, and introduces process alignment to address process drift by locating the layer where trajectories diverge and realigning the stability of subsequent inference. This dual strategy learns a single temperature parameter that corrects both drift types without sacrificing post-training performance gains. Experiments show consistent improvements over baselines, reducing calibration errors and approaching a supervised oracle.

</details>


### [33] [Generation of synthetic delay time series for air transport applications](https://arxiv.org/abs/2601.04279)
*Pau Esteve,Massimiliano Zanin*

Main category: cs.LG

TL;DR: 使用简化的遗传算法生成机场延迟时间序列，效果与真实数据几乎相同；已公开数据可供研究。


<details>
  <summary>Details</summary>
Motivation: 解决数据稀缺和隐私限制，提供可用于科研和实践的合成航空延迟时间序列，以推动航空运输领域的研究与应用。

Method: 比较三种模型：两种基于深度学习的算法（如LSTM/Transformer）和一种简化的遗传算法；评估其生成时间序列的真实性、多样性，并在延迟传播检测任务中验证效果。

Result: 遗传算法生成的序列几乎无法与真实数据区分，并保持高变异性；在机场延迟传播检测问题中得到有效验证；合成数据已向学术界公开。

Conclusion: 合成时延序列能够满足实际应用需求，遗传算法在可推广性和多样性方面具有优势，数据已公开供科研使用。

Abstract: The generation of synthetic data is receiving increasing attention from the scientific community, thanks to its ability to solve problems like data scarcity and privacy, and is starting to find applications in air transport. We here tackle the problem of generating synthetic, yet realistic, time series of delays at airports, starting from large collections of operations in Europe and the US. We specifically compare three models, two of them based on state of the art Deep Learning algorithms, and one simplified Genetic Algorithm approach. We show how the latter can generate time series that are almost indistinguishable from real ones, while maintaining a high variability. We further validate the resulting time series in a problem of detecting delay propagations between airports. We finally make the synthetic data available to the scientific community.

</details>


### [34] [LEGATO: Good Identity Unlearning Is Continuous](https://arxiv.org/abs/2601.04282)
*Qiang Chen,Chun-Wun Cheng,Xiu Su,Hongyan Xu,Xi Lin,Shan You,Angelica I. Aviles-Rivero,Yi Chen*

Main category: cs.LG

TL;DR: LEGATO 用 Neural ODE 适配器实现连续、可控的生成模型遗忘，配合轨迹一致性约束，降低参数量、避免崩溃，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在生成式模型训练大规模数据集后，删除敏感或受版权保护的数据（机器遗忘）极为重要，但传统方法存在效率低下、可控性差和灾难性崩溃等问题。

Method: 提出 LEGATO，通过在预训练生成器上添加可微调的轻量化 Neural ODE 适配器，将遗忘过程建模为连续轨迹，原模型参数冻结，仅调整 ODE 步长实现可调、可解释的遗忘；同时引入轨迹一致性约束防止灾难性崩溃。

Result: 在多种域内外身份遗忘基准实验中，LEGATO 取得了最先进的遗忘性能，显著降低差异化参数量，且完全避免了灾难性崩溃。

Conclusion: LEGATO 成功克服了现有机器遗忘方法的低效、可控性不足与性能崩溃三大难题，为生成模型的隐私与版权合规提供了高效、可解释且稳健的解决方案。

Abstract: Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget identity of generative models: 1) inefficient, where identity erasure requires fine-tuning all the model's parameters; 2) limited controllability, where forgetting intensity cannot be controlled and explainability is lacking; 3) catastrophic collapse, where the model's retention capability undergoes drastic degradation as forgetting progresses. Forgetting has typically been handled through discrete and unstable updates, often requiring full-model fine-tuning and leading to catastrophic collapse. In this work, we argue that identity forgetting should be modeled as a continuous trajectory, and introduce LEGATO - Learn to ForgEt Identity in GenerAtive Models via Trajectory-consistent Neural Ordinary Differential Equations. LEGATO augments pre-trained generators with fine-tunable lightweight Neural ODE adapters, enabling smooth, controllable forgetting while keeping the original model weights frozen. This formulation allows forgetting intensity to be precisely modulated via ODE step size, offering interpretability and robustness. To further ensure stability, we introduce trajectory consistency constraints that explicitly prevent catastrophic collapse during unlearning. Extensive experiments across in-domain and out-of-domain identity unlearning benchmarks show that LEGATO achieves state-of-the-art forgetting performance, avoids catastrophic collapse and reduces fine-tuned parameters.

</details>


### [35] [Mitigating Position-Shift Failures in Text-Based Modular Arithmetic via Position Curriculum and Template Diversity](https://arxiv.org/abs/2601.04283)
*Nikolay Yudin*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Building on insights from the grokking literature, we study character-level Transformers trained to compute modular addition from text, and focus on robustness under input-format variation rather than only in-distribution accuracy. We identify a previously under-emphasized failure mode: models that achieve high in-distribution accuracy can fail catastrophically when the same expression is shifted to different absolute character positions ("position shift") or presented under out-of-distribution natural-language templates. Using a disjoint-pair split over all ordered pairs for p=97, we show that a baseline model reaches strong in-distribution performance yet collapses under position shift and template OOD. We then introduce a simple training recipe that combines (i) explicit expression boundary markers, (ii) position curriculum that broadens the range of absolute positions seen during training, (iii) diverse template mixtures, and (iv) consistency training across multiple variants per example. Across three seeds, this intervention substantially improves robustness to position shift and template OOD while maintaining high in-distribution accuracy, whereas an ALiBi-style ablation fails to learn the task under our setup. Our results suggest that steering procedural generalization under noisy supervision benefits from explicitly training invariances that are otherwise absent from the data distribution, and we provide a reproducible evaluation protocol and artifacts.

</details>


### [36] [Enhancing Robustness of Asynchronous EEG-Based Movement Prediction using Classifier Ensembles](https://arxiv.org/abs/2601.04286)
*Niklas Kueper,Kartik Chari,Elsa Andrea Kirchner*

Main category: cs.LG

TL;DR: 集成模型+滑动窗口后处理能提高EEG异步运动意图检测准确率，最佳效果见伪在线条件。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过检测脑电（EEG）信号中的运动意图，支持患者自发性机器人辅助手段，以改善中风后康复。该目标需要在异步在线环境中高效识别意图，而传统单模型方法往往受限。

Method: 使用两套含14名健康受试者的EEG数据，分别对支持向量机（SVM）、多层感知器（MLP）及EEGNet三种分类模型进行离线及伪在线评估，并构建各类组合集成模型。同时应用滑动窗口后处理技术，探究窗口数对异步识别性能的影响。

Result: 伪在线评估表明，在最优窗口数下，模型集成显著超越最佳单模型。随着窗口数增加，单模型性能亦大幅提升。离线评估中，单模型与集成模型之间无显著差距。

Conclusion: 集成学习与恰当的后处理可显著提升EEG驱动的异步运动意图识别效果，尤其在在线场景下能更有效降低误检率。

Abstract: Objective: Stroke is one of the leading causes of disabilities. One promising approach is to extend the rehabilitation with self-initiated robot-assisted movement therapy. To enable this, it is required to detect the patient's intention to move to trigger the assistance of a robotic device. This intention to move can be detected from human surface electroencephalography (EEG) signals; however, it is particularly challenging to decode when classifications are performed online and asynchronously. In this work, the effectiveness of classifier ensembles and a sliding-window postprocessing technique was investigated to enhance the robustness of such asynchronous classification. Approach: To investigate the effectiveness of classifier ensembles and a sliding-window postprocessing, two EEG datasets with 14 healthy subjects who performed self-initiated arm movements were analyzed. Offline and pseudo-online evaluations were conducted to compare ensemble combinations of the support vector machine (SVM), multilayer perceptron (MLP), and EEGNet classification models. Results: The results of the pseudo-online evaluation show that the two model ensembles significantly outperformed the best single model for the optimal number of postprocessing windows. In particular, for single models, an increased number of postprocessing windows significantly improved classification performances. Interestingly, we found no significant improvements between performances of the best single model and classifier ensembles in the offline evaluation. Significance: We demonstrated that classifier ensembles and appropriate postprocessing methods effectively enhance the asynchronous detection of movement intentions from EEG signals. In particular, the classifier ensemble approach yields greater improvements in online classification than in offline classification, and reduces false detections, i.e., early false positives.

</details>


### [37] [Hybrid Federated Learning for Noise-Robust Training](https://arxiv.org/abs/2601.04483)
*Yongjun Kim,Hyeongjun Park,Hwanjin Kim,Junil Choi*

Main category: cs.LG

TL;DR: HFL通过在UE侧交替传输梯度/日志、基站动态调度权重，并结合Jenks聚类与阻尼牛顿权重优化，在低信噪比环境下显著提升学习准确率。


<details>
  <summary>Details</summary>
Motivation: 联邦学习与联邦蒸馏各有噪声鲁棒性与学习速度的权衡，单一范式难以同时满足两者需求；因此，融合两者以兼顾隐私、鲁棒性与效率，提升在无线环境下的性能成为迫切需求。

Method: ①在每轮训练中，用户终端（UE）随机或按策略发送梯度或logits；②基站（BS）根据当前环境和模型更新情况，通过自适应权重（使用阻尼牛顿法）决定FL和FD的加权比例；③利用Jenks优化算法对UE进行聚类，进一步提升学习效果。

Result: 理论上证明了HFL框架的收敛性；实验表明，当同时利用自适应聚类和权重选择的自由度时，HFL在低SNR条件下取得显著提升的测试准确率。

Conclusion: 本研究提出的混合联邦学习框架（HFL）通过动态选择梯度或logits并对每轮权重进行调度，融合了FL和FD的优势，实现了在低信噪比环境下优于传统方法的测试准确率。

Abstract: Federated learning (FL) and federated distillation (FD) are distributed learning paradigms that train UE models with enhanced privacy, each offering different trade-offs between noise robustness and learning speed. To mitigate their respective weaknesses, we propose a hybrid federated learning (HFL) framework in which each user equipment (UE) transmits either gradients or logits, and the base station (BS) selects the per-round weights of FL and FD updates. We derive convergence of HFL framework and introduce two methods to exploit degrees of freedom (DoF) in HFL, which are (i) adaptive UE clustering via Jenks optimization and (ii) adaptive weight selection via a damped Newton method. Numerical results show that HFL achieves superior test accuracy at low SNR when both DoF are exploited.

</details>


### [38] [Online Action-Stacking Improves Reinforcement Learning Performance for Air Traffic Control](https://arxiv.org/abs/2601.04287)
*Ben Carvell,George De Ath,Eseoghene Benjamin,Richard Everson*

Main category: cs.LG

TL;DR: 提出在线动作堆叠方法，在强化学习训练中使用少量离散动作并通过推理时合成复合指令，显著降低指令频率，实测在 ATC 任务中性能与高维动作模型相当。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在航空交通控制（ATC）中难以直接映射到实际操作，因为需要大量离散动作且指令频率过高。需要一种方法在保持行动可解释性的同时，减少指令数量并匹配ATC操作规范。

Method: 在训练阶段使用增量航向或爬升/下降的简单离散动作，并加入动作阻尼惩罚以降低指令频率；在推理阶段，将短时原子动作堆叠成域适当的复合指令。使用近端策略优化（PPO）与BluebirdDT数字孪生平台进行训练。

Result: 在横向导航实验中，相比于阻尼基线，在线动作堆叠显著降低指令数量；且仅使用五个原子动作即可与使用37维动作空间的模型获得相似性能。

Conclusion: 在线动作堆叠通过在推理时将低维原子动作合并为复合指令，显著减少指令频率，并能在仅使用五动作的情况下实现与高维动作相当的性能，证明其在航空交通控制强化学习中的有效性并为更复杂场景提供可扩展方案。

Abstract: We introduce online action-stacking, an inference-time wrapper for reinforcement learning policies that produces realistic air traffic control commands while allowing training on a much smaller discrete action space. Policies are trained with simple incremental heading or level adjustments, together with an action-damping penalty that reduces instruction frequency and leads agents to issue commands in short bursts. At inference, online action-stacking compiles these bursts of primitive actions into domain-appropriate compound clearances. Using Proximal Policy Optimisation and the BluebirdDT digital twin platform, we train agents to navigate aircraft along lateral routes, manage climb and descent to target flight levels, and perform two-aircraft collision avoidance under a minimum separation constraint. In our lateral navigation experiments, action stacking greatly reduces the number of issued instructions relative to a damped baseline and achieves comparable performance to a policy trained with a 37-dimensional action space, despite operating with only five actions. These results indicate that online action-stacking helps bridge a key gap between standard reinforcement learning formulations and operational ATC requirements, and provides a simple mechanism for scaling to more complex control scenarios.

</details>


### [39] [ArtCognition: A Multimodal AI Framework for Affective State Sensing from Visual and Kinematic Drawing Cues](https://arxiv.org/abs/2601.04297)
*Behrad Binaei-Haghighi,Nafiseh Sadat Sajadi,Mehrad Liviyan,Reyhane Akhavan Kharazi,Fatemeh Amirkhani,Behnam Bahrak*

Main category: cs.LG

TL;DR: ArtCognition利用数字绘画的视觉与运动信息，加上检索增强生成，提升了情绪评估的细致性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统非语言情绪评估方法受限，数字绘画作为丰富但未充分利用的非语言媒介，可为情绪感知提供新维度。

Method: 多模态框架ArtCognition将HTP绘画的电脑视觉特征与绘制过程的运动学数据结合，并使用检索增强生成架构实现基于心理学知识的解释。

Result: 实验显示，视觉与行为模态融合后与标准心理指标的相关度显著高于单一模态，验证了其可扩展性与临床辅助潜力。

Conclusion: 通过融合静态视觉特征与动态绘画行为，ArtCognition提供更细致、可解释的情绪与心理评估。

Abstract: The objective assessment of human affective and psychological states presents a significant challenge, particularly through non-verbal channels. This paper introduces digital drawing as a rich and underexplored modality for affective sensing. We present a novel multimodal framework, named ArtCognition, for the automated analysis of the House-Tree-Person (HTP) test, a widely used psychological instrument. ArtCognition uniquely fuses two distinct data streams: static visual features from the final artwork, captured by computer vision models, and dynamic behavioral kinematic cues derived from the drawing process itself, such as stroke speed, pauses, and smoothness. To bridge the gap between low-level features and high-level psychological interpretation, we employ a Retrieval-Augmented Generation (RAG) architecture. This grounds the analysis in established psychological knowledge, enhancing explainability and reducing the potential for model hallucination. Our results demonstrate that the fusion of visual and behavioral kinematic cues provides a more nuanced assessment than either modality alone. We show significant correlations between the extracted multimodal features and standardized psychological metrics, validating the framework's potential as a scalable tool to support clinicians. This work contributes a new methodology for non-intrusive affective state assessment and opens new avenues for technology-assisted mental healthcare.

</details>


### [40] [Transformer-Based Multi-Modal Temporal Embeddings for Explainable Metabolic Phenotyping in Type 1 Diabetes](https://arxiv.org/abs/2601.04299)
*Pir Bakhsh Khokhar,Carmine Gravino,Fabio Palomba,Sule Yildrim Yayilgan,Sarang Shaikh*

Main category: cs.LG

TL;DR: 用Transformer+Gaussian混合+SHAP的可解释深度学习，识别1型糖尿病患者代谢亚群及其风险关联


<details>
  <summary>Details</summary>
Motivation: 糖化血红蛋白等传统生物标志物无法充分刻画1型糖尿病的代谢异质性，需要更全面的数据融合与解释工具

Method: 使用Transformer编码器捕捉跨模态时间依赖，随后用高斯混合模型得到潜在代谢表型，并通过注意力可视化及SHAP特征归因实现可解释性

Result: 在577名T1D患者中发现五种代谢表型，表型在血糖控制、脂质、肾功能及TSH等指标上存在显著差异，并与高血压、心肌梗死、心力衰竭等心血管风险呈统计学关联

Conclusion: 显示可解释的多模态时间嵌入框架能从CGM与实验室数据中识别出五种生理学一致的代谢亚群，并可用于风险分层

Abstract: Type 1 diabetes (T1D) is a highly metabolically heterogeneous disease that cannot be adequately characterized by conventional biomarkers such as glycated hemoglobin (HbA1c). This study proposes an explainable deep learning framework that integrates continuous glucose monitoring (CGM) data with laboratory profiles to learn multimodal temporal embeddings of individual metabolic status. Temporal dependencies across modalities are modeled using a transformer encoder, while latent metabolic phenotypes are identified via Gaussian mixture modeling. Model interpretability is achieved through transformer attention visualization and SHAP-based feature attribution. Five latent metabolic phenotypes, ranging from metabolic stability to elevated cardiometabolic risk, were identified among 577 individuals with T1D. These phenotypes exhibit distinct biochemical profiles, including differences in glycemic control, lipid metabolism, renal markers, and thyrotropin (TSH) levels. Attention analysis highlights glucose variability as a dominant temporal factor, while SHAP analysis identifies HbA1c, triglycerides, cholesterol, creatinine, and TSH as key contributors to phenotype differentiation. Phenotype membership shows statistically significant, albeit modest, associations with hypertension, myocardial infarction, and heart failure. Overall, this explainable multimodal temporal embedding framework reveals physiologically coherent metabolic subgroups in T1D and supports risk stratification beyond single biomarkers.

</details>


### [41] [Causally-Aware Information Bottleneck for Domain Adaptation](https://arxiv.org/abs/2601.04361)
*Mohammad Ali Javidian*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We tackle a common domain adaptation setting in causal systems. In this setting, the target variable is observed in the source domain but is entirely missing in the target domain. We aim to impute the target variable in the target domain from the remaining observed variables under various shifts. We frame this as learning a compact, mechanism-stable representation. This representation preserves information relevant for predicting the target while discarding spurious variation. For linear Gaussian causal models, we derive a closed-form Gaussian Information Bottleneck (GIB) solution. This solution reduces to a canonical correlation analysis (CCA)-style projection and offers Directed Acyclic Graph (DAG)-aware options when desired. For nonlinear or non-Gaussian data, we introduce a Variational Information Bottleneck (VIB) encoder-predictor. This approach scales to high dimensions and can be trained on source data and deployed zero-shot to the target domain. Across synthetic and real datasets, our approach consistently attains accurate imputations, supporting practical use in high-dimensional causal models and furnishing a unified, lightweight toolkit for causal domain adaptation.

</details>


### [42] [Aligned explanations in neural networks](https://arxiv.org/abs/2601.04378)
*Corentin Lobet,Francesca Chiaromonte*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Feature attribution is the dominant paradigm for explaining deep neural networks. However, most existing methods only loosely reflect the model's prediction-making process, thereby merely white-painting the black box. We argue that explanatory alignment is a key aspect of trustworthiness in prediction tasks: explanations must be directly linked to predictions, rather than serving as post-hoc rationalizations. We present model readability as a design principle enabling alignment, and PiNets as a modeling framework to pursue it in a deep learning context. PiNets are pseudo-linear networks that produce instance-wise linear predictions in an arbitrary feature space, making them linearly readable. We illustrate their use on image classification and segmentation tasks, demonstrating how PiNets produce explanations that are faithful across multiple criteria in addition to alignment.

</details>


### [43] [Rate or Fate? RLV$^\varepsilon$R: Reinforcement Learning with Verifiable Noisy Rewards](https://arxiv.org/abs/2601.04411)
*Ali Rad,Khashayar Filom,Darioush Keivan,Peyman Mohajerin Esfahani,Ehsan Kamalinejad*

Main category: cs.LG

TL;DR: 本研究通过多臂赌博机模型与Youden指数揭示了奖励验证噪声的关键影响：若检测准确度（J）大于0，错误模式会被消灭；若小于0，则导致错误模式主导。噪声在学习有效时仅降低收敛速度。


<details>
  <summary>Details</summary>
Motivation: 在强化学习中奖励值的可验证性重要，但实际检测器往往不干净，导致学习过程受噪声影响，需要研究噪声对学习结果的影响。

Method: 将RLVR视作可分析的多臂赌博机模型，采用GRPO算法并通过群组化推理模式得到复制者式动力学，利用Youden指数J来判定不正确模式的流行趋势。

Result: 发现一个清晰的相位阈值：J>0时错误模式被消灭，实现学习；J=0时保持中性；J<0时错误模式占优势导致“反学习”。在学习区间内噪声只减慢收敛速度而不改变最终方向。

Conclusion: 噪声对RLVR的影响可视作速率问题。该框架为分析RLVR的稳定性与收敛提供了通用视角，并为算法改进提供了理论依据。

Abstract: Reinforcement learning with verifiable rewards (RLVR) is a simple but powerful paradigm for training LLMs: sample a completion, verify it, and update. In practice, however, the verifier is almost never clean--unit tests probe only limited corner cases; human and synthetic labels are imperfect; and LLM judges (e.g., RLAIF) are noisy and can be exploited--and this problem worsens on harder domains (especially coding) where tests are sparse and increasingly model-generated. We ask a pragmatic question: does the verification noise merely slow down the learning (rate), or can it flip the outcome (fate)?
  To address this, we develop an analytically tractable multi-armed bandit view of RLVR dynamics, instantiated with GRPO and validated in controlled experiments. Modeling false positives and false negatives and grouping completions into recurring reasoning modes yields a replicator-style (natural-selection) flow on the probability simplex. The dynamics decouples into within-correct-mode competition and a one-dimensional evolution for the mass on incorrect modes, whose drift is determined solely by Youden's index J=TPR-FPR. This yields a sharp phase transition: when J>0, the incorrect mass is driven toward extinction (learning); when J=0, the process is neutral; and when J<0, incorrect modes amplify until they dominate (anti-learning and collapse). In the learning regime J>0, noise primarily rescales convergence time ("rate, not fate"). Experiments on verifiable programming tasks under synthetic noise reproduce the predicted J=0 boundary. Beyond noise, the framework offers a general lens for analyzing RLVR stability, convergence, and algorithmic interventions.

</details>


### [44] [Distribution-Guided and Constrained Quantum Machine Unlearning](https://arxiv.org/abs/2601.04413)
*Nausherwan Malik,Zubair Khalid,Muhammad Faryad*

Main category: cs.LG

TL;DR: 本研究提出一种分布引导且带锚点约束的量子未学习方法，在保持模型表现的同时显著削弱遗忘类别，可显著优于传统均匀目标方案。


<details>
  <summary>Details</summary>
Motivation: 现有量子机器学习未学习方法主要采用固定且均匀的目标分布，难以显式平衡遗忘与模型保留性能，导致对特定训练样本的处理不够灵活。

Method: 提出一种基于分布引导的类级量子未学习框架，将未学习视为约束优化问题。通过模型相似性统计得到可调目标分布，解耦失去的类别置信度与其在保留类别间的再分布，并加入锚点约束保持选定保留数据的预测行为，从而实现受控的优化轨迹。

Result: 在Iris和Covertype数据集上评估，实验显示对遗忘类别置信度的抑制明显，保留类别性能降解最小，并且相较于均匀目标未学习方法，更贴近重新训练模型的基准。

Conclusion: 目标设计与基于约束的求解形式是实现可靠且可解释的量子机器未学习的关键。

Abstract: Machine unlearning aims to remove the influence of specific training data from a learned model without full retraining. While recent work has begun to explore unlearning in quantum machine learning, existing approaches largely rely on fixed, uniform target distributions and do not explicitly control the trade-off between forgetting and retained model behaviour. In this work, we propose a distribution-guided framework for class-level quantum machine unlearning that treats unlearning as a constrained optimization problem. Our method introduces a tunable target distribution derived from model similarity statistics, decoupling the suppression of forgotten-class confidence from assumptions about redistribution among retained classes. We further incorporate an anchor-based preservation constraint that explicitly maintains predictive behaviour on selected retained data, yielding a controlled optimization trajectory that limits deviation from the original model. We evaluate the approach on variational quantum classifiers trained on the Iris and Covertype datasets. Results demonstrate sharp suppression of forgotten-class confidence, minimal degradation of retained-class performance, and closer alignment with the gold retrained model baselines compared to uniform-target unlearning. These findings highlight the importance of target design and constraint-based formulations for reliable and interpretable quantum machine unlearning.

</details>


### [45] [When Predictions Shape Reality: A Socio-Technical Synthesis of Performative Predictions in Machine Learning](https://arxiv.org/abs/2601.04447)
*Gal Fybish,Teo Susnjak*

Main category: cs.LG

TL;DR: 总结了表现性预测的危害，提出了一个评估框架，帮助实践者有效管理模型的自我影响。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域使用的机器学习模型在被部署后会影响其预测结果，形成反馈循环与不可预见的后果，文献缺乏系统化的梳理和实用指导。

Method: 通过系统化综述（SoK）分析现有文献，梳理表现性预测的主要机制、风险类型和已提出的解决方案，构建框架与评估工具。

Result: 完成了文献综述，形成了表现性预测的机制与风险分类，并提出了可操作的评估矩阵和实用建议。

Conclusion: 本文提出了 Performative Strength vs. Impact Matrix，帮助从业者评估部署模型可能产生的表现性影响与严重性，并指导选择相应的算法或人工干预，以降低反馈环、性能问题及社会风险。

Abstract: Machine learning models are increasingly used in high-stakes domains where their predictions can actively shape the environments in which they operate, a phenomenon known as performative prediction. This dynamic, in which the deployment of the model influences the very outcome it seeks to predict, can lead to unintended consequences, including feedback loops, performance issues, and significant societal risks. While the literature in the field has grown rapidly in recent years, a socio-technical synthesis that systemises the phenomenon concepts and provides practical guidance has been lacking. This Systematisation of Knowledge (SoK) addresses this gap by providing a comprehensive review of the literature on performative predictions. We provide an overview of the primary mechanisms through which performativity manifests, present a typology of associated risks, and survey the proposed solutions offered in the literature. Our primary contribution is the ``Performative Strength vs. Impact Matrix" assessment framework. This practical tool is designed to help practitioners assess the potential influence and severity of performativity on their deployed predictive models and select the appropriate level of algorithmic or human intervention.

</details>


### [46] [Explainable Admission-Level Predictive Modeling for Prolonged Hospital Stay in Elderly Populations: Challenges in Low- and Middle-Income Countries](https://arxiv.org/abs/2601.04449)
*Daniel Sierra-Botero,Ana Molina-Taborda,Leonardo Espinosa-Leal,Alexander Karpenko,Alejandro Hernandez,Olga Lopez-Acevedo*

Main category: cs.LG

TL;DR: 基于机构数据构建的逻辑回归预测模型，利用信息值与图论特征筛选技术挑选九个关键变量，以 0.82 的 AUC‑ROC 准确预测住院时间是否超过 7 天，具有良好的解释性和管理应用前景。


<details>
  <summary>Details</summary>
Motivation: 延长住院时间与住院期间不良事件风险相关，亟需一种基于数据的预测工具以提前识别高风险病人并制定干预措施。

Method: 使用入院级别患者和医院行政数据，采用信息值和图论头部选择的无相关特征筛选法，最后用逻辑回归模型训练二分类模型，数据集按 67%/22%/11% 划分为训练、测试和验证集。

Result: 验证集上，模型特异性 0.83、灵敏性 0.64、准确率 0.76、精确率 0.67，AUC‑ROC 达 0.82。

Conclusion: 该模型成功预测出住院时间是否超过7天，表现出较高的准确率、灵敏度和特异性，并通过九个可解释变量提供了对影响住院时长因素的洞察，具备临床和管理应用价值。

Abstract: Prolonged length of stay (pLoS) is a significant factor associated with the risk of adverse in-hospital events. We develop and explain a predictive model for pLos using admission-level patient and hospital administrative data. The approach includes a feature selection method by selecting non-correlated features with the highest information value. The method uses features weights of evidence to select a representative within cliques from graph theory. The prognosis study analyzed the records from 120,354 hospital admissions at the Hospital Alma Mater de Antioquia between January 2017 and March 2022. After a cleaning process the dataset was split into training (67%), test (22%), and validation (11%) cohorts. A logistic regression model was trained to predict the pLoS in two classes: less than or greater than 7 days. The performance of the model was evaluated using accuracy, precision, sensitivity, specificity, and AUC-ROC metrics. The feature selection method returns nine interpretable variables, enhancing the models' transparency. In the validation cohort, the pLoS model achieved a specificity of 0.83 (95% CI, 0.82-0.84), sensitivity of 0.64 (95% CI, 0.62-0.65), accuracy of 0.76 (95% CI, 0.76-0.77), precision of 0.67 (95% CI, 0.66-0.69), and AUC-ROC of 0.82 (95% CI, 0.81-0.83). The model exhibits strong predictive performance and offers insights into the factors that influence prolonged hospital stays. This makes it a valuable tool for hospital management and for developing future intervention studies aimed at reducing pLoS.

</details>


### [47] [Using Large Language Models to Detect Socially Shared Regulation of Collaborative Learning](https://arxiv.org/abs/2601.04458)
*Jiayi Zhang,Conrad Borchers,Clayton Cohn,Namrata Srivastava,Caitlin Snyder,Siyuan Guo,Ashwin T S,Naveeduddin Mohammed,Haley Noh,Gautam Biswas*

Main category: cs.LG

TL;DR: 本文利用大模型生成任务摘要并与不同嵌入、日志特征结合，成功在协作学习环境中检测SSRL行为；文本嵌入擅长动态行为，语境与多模态特征则补充计划反思。


<details>
  <summary>Details</summary>
Motivation: 学习分析多聚焦个人问题解决，缺乏针对协作性、开放式问题解决的自动检测；因此需要能够处理协作环境中丰富数据并捕捉低凝聚性的行为预测方法。

Method: 采用大型语言模型进行任务感知摘要，结合文本嵌入、上下文嵌入和日志特征训练预测模型；实验对比不同嵌入与多模态特征的表现。

Result: 文本嵌入在检测与执行或小组动态相关的SSRL行为（如偏离任务、请求协助）表现更强；上下文与多模态特征则对计划与反思构建具有互补优势。

Conclusion: 本文展示了基于嵌入的模型在协作计算建模环境中自动检测社会共享学习调节（SSRL）行为的可行性，并表明此方法能够实现可扩展的实时反馈与适应性支架。

Abstract: The field of learning analytics has made notable strides in automating the detection of complex learning processes in multimodal data. However, most advancements have focused on individualized problem-solving instead of collaborative, open-ended problem-solving, which may offer both affordances (richer data) and challenges (low cohesion) to behavioral prediction. Here, we extend predictive models to automatically detect socially shared regulation of learning (SSRL) behaviors in collaborative computational modeling environments using embedding-based approaches. We leverage large language models (LLMs) as summarization tools to generate task-aware representations of student dialogue aligned with system logs. These summaries, combined with text-only embeddings, context-enriched embeddings, and log-derived features, were used to train predictive models. Results show that text-only embeddings often achieve stronger performance in detecting SSRL behaviors related to enactment or group dynamics (e.g., off-task behavior or requesting assistance). In contrast, contextual and multimodal features provide complementary benefits for constructs such as planning and reflection. Overall, our findings highlight the promise of embedding-based models for extending learning analytics by enabling scalable detection of SSRL behaviors, ultimately supporting real-time feedback and adaptive scaffolding in collaborative learning environments that teachers value.

</details>


### [48] [When Models Manipulate Manifolds: The Geometry of a Counting Task](https://arxiv.org/abs/2601.04480)
*Wes Gurnee,Emmanuel Ameisen,Isaac Kauvar,Julius Tarng,Adam Pearce,Chris Olah,Joshua Batson*

Main category: cs.LG

TL;DR: 本研究通过力学方法揭示 Claude 3.5 Haiku 在固定宽度文本中换行的内部机制：字符计数在低维流形上表达，注意力头扭曲流形推断距离，决策通过线性边界实现，并验证了视觉错觉与因果干预的影响。


<details>
  <summary>Details</summary>
Motivation: 探究 Claude 3.5 Haiku 如何在仅接收 token 序列的条件下感知文本的视觉属性，并聚焦于固定宽度文本的换行任务

Method: 通过对字符计数在低维卷曲流形上的表示进行力学分析，并观察注意力头如何转换此流形、估算距离及形成线性决策边界；随后利用因果干预验证模型行为

Result: 发现字符计数映射为离散稀疏特征族的低维流形，注意力头对流形进行扭曲以估计到行尾距离，最终通过正交排列得到线性决策边界；同时发现字符序列可诱发视觉错觉，干扰计数机制，验证了早期层的感知功能和注意力算法的复杂性

Conclusion: 文本换行可由字符计数流形、几何变换与线性决策共同实现，体现了模型在早层的丰富感知与注意力处理，强调将特征与几何视角结合对于解释性的重要性

Abstract: Language models can perceive visual properties of text despite receiving only sequences of tokens-we mechanistically investigate how Claude 3.5 Haiku accomplishes one such task: linebreaking in fixed-width text. We find that character counts are represented on low-dimensional curved manifolds discretized by sparse feature families, analogous to biological place cells. Accurate predictions emerge from a sequence of geometric transformations: token lengths are accumulated into character count manifolds, attention heads twist these manifolds to estimate distance to the line boundary, and the decision to break the line is enabled by arranging estimates orthogonally to create a linear decision boundary. We validate our findings through causal interventions and discover visual illusions--character sequences that hijack the counting mechanism. Our work demonstrates the rich sensory processing of early layers, the intricacy of attention algorithms, and the importance of combining feature-based and geometric views of interpretability.

</details>


### [49] [IGenBench: Benchmarking the Reliability of Text-to-Infographic Generation](https://arxiv.org/abs/2601.04498)
*Yinghao Tang,Xueding Liu,Boyuan Zhang,Tingfeng Lan,Yupeng Xie,Jiale Lao,Yiyao Wang,Haoxuan Li,Tingting Gao,Bo Pan,Luoxuan Weng,Xiuqi Huang,Minfeng Zhu,Yingchaojie Feng,Yuyu Luo,Wei Chen*

Main category: cs.LG

TL;DR: 本文创建了 IGENBENCH 基准，用自动原子问答方式评估文本-信息图生成的可靠性，对 10 大模型进行系统测评，揭示当前技术的主要短板与改进方向。


<details>
  <summary>Details</summary>
Motivation: 尽管文本生成图像模型已能产生视觉上令人满意的图像，但在生成信息图时往往包含难以察觉的错误（数据失真、文本错误等），缺乏统一评测手段，限制了模型与应用的改进。

Method: 构建 600 条精选 30 种信息图测试案例；采用 10 类问题的原子是非问答形式；利用多模态大语言模型逐一验证每个问题，从而得到 Q-ACC 与 I-ACC 两级准确率；对 10 家顶尖文本-图像模型进行评测。

Result: 对 10 系统模型评测表明：存在三层性能等级；数据相关维度普遍是瓶颈（例如数据完整度仅 0.21）；单个模型无法在所有维度上实现端到端正确。

Conclusion: IGENBENCH提出了衡量文本至信息图可靠性的基准，展示即使是最先进的文本-图像模型也仅在数据编码和文本准确性上达不到完美表现；最高模型的 Q-ACC 0.90 但 I-ACC 仅 0.49，表明整体一致性仍是瓶颈。

Abstract: Infographics are composite visual artifacts that combine data visualizations with textual and illustrative elements to communicate information. While recent text-to-image (T2I) models can generate aesthetically appealing images, their reliability in generating infographics remains unclear. Generated infographics may appear correct at first glance but contain easily overlooked issues, such as distorted data encoding or incorrect textual content. We present IGENBENCH, the first benchmark for evaluating the reliability of text-to-infographic generation, comprising 600 curated test cases spanning 30 infographic types. We design an automated evaluation framework that decomposes reliability verification into atomic yes/no questions based on a taxonomy of 10 question types. We employ multimodal large language models (MLLMs) to verify each question, yielding question-level accuracy (Q-ACC) and infographic-level accuracy (I-ACC). We comprehensively evaluate 10 state-of-the-art T2I models on IGENBENCH. Our systematic analysis reveals key insights for future model development: (i) a three-tier performance hierarchy with the top model achieving Q-ACC of 0.90 but I-ACC of only 0.49; (ii) data-related dimensions emerging as universal bottlenecks (e.g., Data Completeness: 0.21); and (iii) the challenge of achieving end-to-end correctness across all models. We release IGENBENCH at https://igen-bench.vercel.app/.

</details>


### [50] [Surface-based Molecular Design with Multi-modal Flow Matching](https://arxiv.org/abs/2601.04506)
*Fang Wu,Zhengyuan Zhou,Shuting Jin,Xiangxiang Zeng,Jure Leskovec,Jinbo Xu*

Main category: cs.LG

TL;DR: SurfFlow是一种基于表面的生成算法，利用多模态关系流匹配在步序列、结构与表面层面共同设计肽，实验验证其在再生肽发现中的卓越性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度生成模型已可实现全原子肽共设计，但对分子表面在蛋白-蛋白相互作用中的关键作用研究不足，需要通过表面导向的方法填补这一空缺。

Method: SurfFlow采用多模态条件流匹配(CFM)架构，学习表面几何与生化属性的分布，以此指导肽分子生成。

Result: 在PepMerge基准上，SurfFlow在所有评价指标上均优于传统全原子基线，验证了表面导向生成的优势。

Conclusion: SurfFlow通过表面为核心的生成算法，实现了在序列、结构及表面三重层面共同设计的潜能，显著提升了不同指标下的性能，表明表面信息在再生肽设计中的重要性。

Abstract: Therapeutic peptides show promise in targeting previously undruggable binding sites, with recent advancements in deep generative models enabling full-atom peptide co-design for specific protein receptors. However, the critical role of molecular surfaces in protein-protein interactions (PPIs) has been underexplored. To bridge this gap, we propose an omni-design peptides generation paradigm, called SurfFlow, a novel surface-based generative algorithm that enables comprehensive co-design of sequence, structure, and surface for peptides. SurfFlow employs a multi-modality conditional flow matching (CFM) architecture to learn distributions of surface geometries and biochemical properties, enhancing peptide binding accuracy. Evaluated on the comprehensive PepMerge benchmark, SurfFlow consistently outperforms full-atom baselines across all metrics. These results highlight the advantages of considering molecular surfaces in de novo peptide discovery and demonstrate the potential of integrating multiple protein modalities for more effective therapeutic peptide discovery.

</details>


### [51] [Not All Steps are Informative: On the Linearity of LLMs' RLVR Training](https://arxiv.org/abs/2601.04537)
*Tianle Wang,Zhongyuan Wu,Shenghao Jin,Hao Xu,Wei Chen,Ning Miao*

Main category: cs.LG

TL;DR: RLVR训练呈强线性，利用权重或对数概率的外推能快速获得几乎等同或更好的模型，显著降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 解决RLVR训练需要成千上万步、计算量大、探索成本高的问题；通过发现训练的线性规律，寻找更高效的模型更新方式。

Method: 首先在RLVR训练中观察模型权重和对数概率随训练步数的线性走势，然后根据中间检查点做线性外推（Weight Extrapolation 与 Logits Extrapolation），得到未来模型状态而无需继续昂贵的RL训练。

Result: 权重外推在保持性能的同时减少计算；对数概率外推在四个基准任务中始终优于继续RL训练，能够在研 训不稳定的步数范围之外进行预测。

Conclusion: RLVR的训练过程表现出强线性特征，模型权重与输出对数概率与训练步数高度相关；利用权重或对数概率的外推可获得与标准RL训练相当甚至更优的模型，显著减少计算成本。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has become a central component of large language model (LLM) post-training. Unlike supervised fine-tuning (SFT), RLVR lets an LLM generate multiple candidate solutions and reinforces those that lead to a verifiably correct final answer. However, in practice, RLVR often requires thousands of training steps to reach strong performance, incurring substantial computation largely attributed to prolonged exploration. In this work, we make a surprising observation: during RLVR, LLMs evolve in a strongly linear manner. Specifically, both model weights and model output log-probabilities exhibit strong linear correlations with RL training steps. This suggests that RLVR predominantly amplifies trends that emerge early in training, rather than continuously discovering new behaviors throughout the entire optimization trajectory. Motivated by this linearity, we investigate whether future model states can be predicted from intermediate checkpoints via extrapolation, avoiding continued expensive training. We show that Weight Extrapolation produces models with performance comparable to standard RL training while requiring significantly less computation. Moreover, Logits Extrapolation consistently outperforms continued RL training on all four benchmarks by extrapolating beyond the step range where RL training remains stable.

</details>


### [52] [Timeliness-Oriented Scheduling and Resource Allocation in Multi-Region Collaborative Perception](https://arxiv.org/abs/2601.04542)
*Mengmeng Zhu,Yuxuan Sun,Yukuan Jia,Wei Chen,Bo Ai,Sheng Zhou*

Main category: cs.LG

TL;DR: 本文提出时效感知调度算法TAMP，解决多区域协同感知中的时效与带宽平衡问题，在实测数据上提升27% AP。


<details>
  <summary>Details</summary>
Motivation: 提升协同感知的时效性和通信效率

Method: 采用Lyapunov框架的TAMP调度算法，将长期平均目标拆分为每时隙优先级问题

Result: 在RCooper数据集的交叉口与走廊场景中，TAMP相较最佳基线提升了高达27%的平均精度

Conclusion: TAMP通过平衡信息时效与通信成本，显著提升协同感知性能

Abstract: Collaborative perception (CP) is a critical technology in applications like autonomous driving and smart cities. It involves the sharing and fusion of information among sensors to overcome the limitations of individual perception, such as blind spots and range limitations. However, CP faces two primary challenges. First, due to the dynamic nature of the environment, the timeliness of the transmitted information is critical to perception performance. Second, with limited computational power at the sensors and constrained wireless bandwidth, the communication volume must be carefully designed to ensure feature representations are both effective and sufficient. This work studies the dynamic scheduling problem in a multi-region CP scenario, and presents a Timeliness-Aware Multi-region Prioritized (TAMP) scheduling algorithm to trade-off perception accuracy and communication resource usage. Timeliness reflects the utility of information that decays as time elapses, which is manifested by the perception performance in CP tasks. We propose an empirical penalty function that maps the joint impact of Age of Information (AoI) and communication volume to perception performance. Aiming to minimize this timeliness-oriented penalty in the long-term, and recognizing that scheduling decisions have a cumulative effect on subsequent system states, we propose the TAMP scheduling algorithm. TAMP is a Lyapunov-based optimization policy that decomposes the long-term average objective into a per-slot prioritization problem, balancing the scheduling worth against resource cost. We validate our algorithm in both intersection and corridor scenarios with the real-world Roadside Cooperative perception (RCooper) dataset. Extensive simulations demonstrate that TAMP outperforms the best-performing baseline, achieving an Average Precision (AP) improvement of up to 27% across various configurations.

</details>


### [53] [Improving Semi-Supervised Contrastive Learning via Entropy-Weighted Confidence Integration of Anchor-Positive Pairs](https://arxiv.org/abs/2601.04555)
*Shogo Nakayama,Masahiro Okuda*

Main category: cs.LG

TL;DR: 提出一种基于熵的置信度自适应加权对比损失，能够在轻标签下提升准确率并稳定训练。


<details>
  <summary>Details</summary>
Motivation: 传统半监督对比学习只为置信度高的样本分配伪标签，导致中低置信度样本被忽略，尤其在缺标签情况下信息利用不足。

Method: 使用样本预测概率分布的熵来估计样本置信度，对样本进行自适应加权；在对比损失中同时考虑锚点和正样本的置信度，从而实现对低置信度样本的伪标签分配与对比学习。

Result: 实验表明，在低标签和低置信度环境下，提出的方法提升了分类准确率，并在多组实验中表现出比基线更稳健的学习性能。

Conclusion: 本文提出的基于熵的自适应加权损失函数能够有效利用低置信度样本，显著提升分类准确率并在低标签条件下使学习过程更为稳定。

Abstract: Conventional semi-supervised contrastive learning methods assign pseudo-labels only to samples whose highest predicted class probability exceeds a predefined threshold, and then perform supervised contrastive learning using those selected samples. In this study, we propose a novel loss function that estimates the confidence of each sample based on the entropy of its predicted probability distribution and applies confidence-based adaptive weighting. This approach enables pseudo-label assignment even to samples that were previously excluded from training and facilitates contrastive learning that accounts for the confidence of both anchor and positive samples in a more principled manner. Experimental results demonstrate that the proposed method improves classification accuracy and achieves more stable learning performance even under low-label conditions.

</details>


### [54] [A Vision for Multisensory Intelligence: Sensing, Synergy, and Science](https://arxiv.org/abs/2601.04563)
*Paul Pu Liang*

Main category: cs.LG

TL;DR: 未来十年将通过更丰富的感知、统一科学建模和多模态协同，推动AI与人类多感官交互的革命。


<details>
  <summary>Details</summary>
Motivation: 人工智能目前仅聚焦数码模态，缺乏与人类多感官融通的能力，限制了人机体验。

Method: 支持多模态感知、统一建模与跨模态迁移的实验与理论框架，并引入跨模态协同学习、推理与生成等技术。

Result: 提出了一系列技术挑战与项目资源，展示MIT多感官智能组的最新实验和演示，提供了可复现的原型与数据集。

Conclusion: 该论文展望了未来十年多感官人工智能的发展，并提出通过传感、科学与协同三大主题实现更丰富感知与人机交互。

Abstract: Our experience of the world is multisensory, spanning a synthesis of language, sight, sound, touch, taste, and smell. Yet, artificial intelligence has primarily advanced in digital modalities like text, vision, and audio. This paper outlines a research vision for multisensory artificial intelligence over the next decade. This new set of technologies can change how humans and AI experience and interact with one another, by connecting AI to the human senses and a rich spectrum of signals from physiological and tactile cues on the body, to physical and social signals in homes, cities, and the environment. We outline how this field must advance through three interrelated themes of sensing, science, and synergy. Firstly, research in sensing should extend how AI captures the world in richer ways beyond the digital medium. Secondly, developing a principled science for quantifying multimodal heterogeneity and interactions, developing unified modeling architectures and representations, and understanding cross-modal transfer. Finally, we present new technical challenges to learn synergy between modalities and between humans and AI, covering multisensory integration, alignment, reasoning, generation, generalization, and experience. Accompanying this vision paper are a series of projects, resources, and demos of latest advances from the Multisensory Intelligence group at the MIT Media Lab, see https://mit-mi.github.io/.

</details>


### [55] [Spatial-Temporal Feedback Diffusion Guidance for Controlled Traffic Imputation](https://arxiv.org/abs/2601.04572)
*Xiaowei Mao,Huihu Ding,Yan Lin,Tingrui Wu,Shengnan Guo,Dazhuo Qiu,Feiling Fang,Jilin Hu,Huaiyu Wan*

Main category: cs.LG

TL;DR: FENCE使用动态反馈和聚类指导尺度改进扩散模型在交通数据缺失填补中的精度。


<details>
  <summary>Details</summary>
Motivation: 缺失值填补对智能交通系统至关重要，但现有扩散模型在空间与时间维度上使用统一的指导尺度，导致高缺失率节点填补效果差。

Method: 提出FENCE，通过动态反馈机制根据后验似然调整指导尺度，并按节点聚类（基于注意力分数）在空间-时间层面计算不同尺度；实现对填补过程中生成值与已观测值偏差的自适应校正。

Result: 在真实交通数据集上实验显著提升填补精度，优于传统统一尺度扩散模型。

Conclusion: FENCE通过空间-时间反馈指导有效解决高缺失率节点的填补难题，为交通数据插补提供更稳健的方法。

Abstract: Imputing missing values in spatial-temporal traffic data is essential for intelligent transportation systems. Among advanced imputation methods, score-based diffusion models have demonstrated competitive performance. These models generate data by reversing a noising process, using observed values as conditional guidance. However, existing diffusion models typically apply a uniform guidance scale across both spatial and temporal dimensions, which is inadequate for nodes with high missing data rates. Sparse observations provide insufficient conditional guidance, causing the generative process to drift toward the learned prior distribution rather than closely following the conditional observations, resulting in suboptimal imputation performance.
  To address this, we propose FENCE, a spatial-temporal feedback diffusion guidance method designed to adaptively control guidance scales during imputation. First, FENCE introduces a dynamic feedback mechanism that adjusts the guidance scale based on the posterior likelihood approximations. The guidance scale is increased when generated values diverge from observations and reduced when alignment improves, preventing overcorrection. Second, because alignment to observations varies across nodes and denoising steps, a global guidance scale for all nodes is suboptimal. FENCE computes guidance scales at the cluster level by grouping nodes based on their attention scores, leveraging spatial-temporal correlations to provide more accurate guidance. Experimental results on real-world traffic datasets show that FENCE significantly enhances imputation accuracy.

</details>


### [56] [FedKDX: Federated Learning with Negative Knowledge Distillation for Enhanced Healthcare AI Systems](https://arxiv.org/abs/2601.04587)
*Quang-Tu Pham,Hoang-Dieu Vu,Dinh-Dat Pham,Hieu H. Pham*

Main category: cs.LG

TL;DR: FedKDX：结合负知识蒸馏、传统蒸馏与对比学习的联邦学习框架，提升医疗AI模型精度（+2.53%），加速收敛，并兼顾隐私与低通信成本。


<details>
  <summary>Details</summary>
Motivation: 医疗AI在联邦学习场景下受限于信息不足、数据异构与通信开销，以及严格的隐私法规，亟需一种能够充分挖掘正负知识并兼顾隐私与效率的框架。

Method: 在统一的联邦架构下，FedKDX同时采用传统知识蒸馏、对比学习与NKD技术，捕获目标与非目标知识。各客户端对本地模型进行训练后，将压缩后的知识向中心服务器上传，实现隐私保护并极大降低通信开销。

Result: 在SLEEP、UCI-HAR与PAMAP2医疗数据集上，FedKDX相较于现有最佳方法提升了最高2.53%的准确率，收敛速度更快，并在非IID数据下表现更稳健。

Conclusion: FedKDX通过引入负知识蒸馏（NKD），有效缓解了医疗AI联邦学习中的统计异构性，提升了模型泛化性与稳健性，已在多组医疗数据集上实现显著准确率提升，并在隐私安全与通信成本方面体现出可行性。

Abstract: This paper introduces FedKDX, a federated learning framework that addresses limitations in healthcare AI through Negative Knowledge Distillation (NKD). Unlike existing approaches that focus solely on positive knowledge transfer, FedKDX captures both target and non-target information to improve model generalization in healthcare applications. The framework integrates multiple knowledge transfer techniques--including traditional knowledge distillation, contrastive learning, and NKD--within a unified architecture that maintains privacy while reducing communication costs. Through experiments on healthcare datasets (SLEEP, UCI-HAR, and PAMAP2), FedKDX demonstrates improved accuracy (up to 2.53% over state-of-the-art methods), faster convergence, and better performance on non-IID data distributions. Theoretical analysis supports NKD's contribution to addressing statistical heterogeneity in distributed healthcare data. The approach shows promise for privacy-sensitive medical applications under regulatory frameworks like HIPAA and GDPR, offering a balanced solution between performance and practical implementation requirements in decentralized healthcare settings. The code and model are available at https://github.com/phamdinhdat-ai/Fed_2024.

</details>


### [57] [Density Matrix RNN (DM-RNN): A Quantum Information Theoretic Framework for Modeling Musical Context and Polyphony](https://arxiv.org/abs/2601.04592)
*Joonwon Seo,Mariana Montiel*

Main category: cs.LG

TL;DR: DM‑RNN将RNN改为密度矩阵，利用CPTP通道保持物理合法性，以量子熵和互信息评估音乐不确定性与纠缠。


<details>
  <summary>Details</summary>
Motivation: 传统RNN的单一隐藏向量受信息瓶颈限制，无法捕获音乐固有的不确定性与多重诠释，需更丰富的表示容量。

Method: 通过将RNN隐藏状态从确定性向量扩展为密度矩阵，并使用量子信道（CPTP）定义时序更新；参数化采用Choi‑Jamiolkowski同构，保证学习到的动态物理合法。

Result: 提出DM‑RNN后，实现了对音乐不确定性的Von Neumann熵量化以及声音间纠缠的量子互信息评估，为复杂模糊音乐结构建模提供了严谨框架。

Conclusion: DM‑RNN利用密度矩阵捕获音乐结构中的随机性与相干性，形成可兼容经典与量子概率的混态动态模型；其基于Choi‑Jamiolkowski参数化保证动态保持完全正映射（CPTP）。

Abstract: Classical Recurrent Neural Networks (RNNs) summarize musical context into a deterministic hidden state vector, imposing an information bottleneck that fails to capture the inherent ambiguity in music. We propose the Density Matrix RNN (DM-RNN), a novel theoretical architecture utilizing the Density Matrix. This allows the model to maintain a statistical ensemble of musical interpretations (a mixed state), capturing both classical probabilities and quantum coherences. We rigorously define the temporal dynamics using Quantum Channels (CPTP maps). Crucially, we detail a parameterization strategy based on the Choi-Jamiolkowski isomorphism, ensuring the learned dynamics remain physically valid (CPTP) by construction. We introduce an analytical framework using Von Neumann Entropy to quantify musical uncertainty and Quantum Mutual Information (QMI) to measure entanglement between voices. The DM-RNN provides a mathematically rigorous framework for modeling complex, ambiguous musical structures.

</details>


### [58] [DeepHalo: A Neural Choice Model with Controllable Context Effects](https://arxiv.org/abs/2601.04616)
*Shuhan Zhang,Zhi Wang,Rui Gao,Shuang Li*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Modeling human decision-making is central to applications such as recommendation, preference learning, and human-AI alignment. While many classic models assume context-independent choice behavior, a large body of behavioral research shows that preferences are often influenced by the composition of the choice set itself -- a phenomenon known as the context effect or Halo effect. These effects can manifest as pairwise (first-order) or even higher-order interactions among the available alternatives. Recent models that attempt to capture such effects either focus on the featureless setting or, in the feature-based setting, rely on restrictive interaction structures or entangle interactions across all orders, which limits interpretability. In this work, we propose DeepHalo, a neural modeling framework that incorporates features while enabling explicit control over interaction order and principled interpretation of context effects. Our model enables systematic identification of interaction effects by order and serves as a universal approximator of context-dependent choice functions when specialized to a featureless setting. Experiments on synthetic and real-world datasets demonstrate strong predictive performance while providing greater transparency into the drivers of choice.

</details>


### [59] [Learning Dynamics in RL Post-Training for Language Models](https://arxiv.org/abs/2601.04670)
*Akiyoshi Tomihari*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reinforcement learning (RL) post-training is a critical stage in modern language model development, playing a key role in improving alignment and reasoning ability. However, several phenomena remain poorly understood, including the reduction in output diversity. To gain a broader understanding of RL post-training, we analyze the learning dynamics of RL post-training from a perspective that has been studied in supervised learning but remains underexplored in RL. We adopt an empirical neural tangent kernel (NTK) framework and decompose the NTK into two components to characterize how RL updates propagate across training samples. Our analysis reveals that limited variability in feature representations can cause RL updates to systematically increase model confidence, providing an explanation for the commonly observed reduction in output diversity after RL post-training. Furthermore, we show that effective learning in this regime depends on rapidly shaping the classifier, which directly affects the gradient component of the NTK. Motivated by these insights, we propose classifier-first reinforcement learning (CF-RL), a simple two-stage training strategy that prioritizes classifier updates before standard RL optimization. Experimental results validate our theoretical analysis by demonstrating increased model confidence and accelerated optimization under CF-RL. Additional analysis shows that the mechanism underlying CF-RL differs from that of linear-probing-then-fine-tuning in supervised learning. Overall, our study formalizes the learning dynamics of RL post-training and motivates further analysis and improvement.

</details>


### [60] [Estimating Causal Effects in Gaussian Linear SCMs with Finite Data](https://arxiv.org/abs/2601.04673)
*Aurghya Maiti,Prateek Jain*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Estimating causal effects from observational data remains a fundamental challenge in causal inference, especially in the presence of latent confounders. This paper focuses on estimating causal effects in Gaussian Linear Structural Causal Models (GL-SCMs), which are widely used due to their analytical tractability. However, parameter estimation in GL-SCMs is often infeasible with finite data, primarily due to overparameterization. To address this, we introduce the class of Centralized Gaussian Linear SCMs (CGL-SCMs), a simplified yet expressive subclass where exogenous variables follow standardized distributions. We show that CGL-SCMs are equally expressive in terms of causal effect identifiability from observational distributions and present a novel EM-based estimation algorithm that can learn CGL-SCM parameters and estimate identifiable causal effects from finite observational samples. Our theoretical analysis is validated through experiments on synthetic data and benchmark causal graphs, demonstrating that the learned models accurately recover causal distributions.

</details>


### [61] [Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead](https://arxiv.org/abs/2601.04686)
*Oluwatosin Oseni,Shengjie Wang,Jun Zhu,Micah Corah*

Main category: cs.LG

TL;DR: Nightmare Dreamer 通过世界模型预判安全违规，实现零违规且奖励最大化，在 Safety Gymnasium 上相较无模型基线提高约20倍效率。


<details>
  <summary>Details</summary>
Motivation: 强化学习在实际世界中的安全保障不足导致采用受限。

Method: Nightmare Dreamer 通过学习世界模型预测潜在安全违规并相应规划动作，利用基于模型的安全强化学习。

Result: 在 Safety Gymnasium 任务上，仅使用图像观测就实现了近乎零安全违规，同时将效率提升近20倍，并优于无模型基线。

Conclusion: Nightmare Dreamer 在保持高奖励的同时几乎消除安全违规，并显著提升学习效率，证明了基于模型的安全强化学习在工业机器人等领域的可行性。

Abstract: Reinforcement Learning (RL) has shown remarkable success in real-world applications, particularly in robotics control. However, RL adoption remains limited due to insufficient safety guarantees. We introduce Nightmare Dreamer, a model-based Safe RL algorithm that addresses safety concerns by leveraging a learned world model to predict potential safety violations and plan actions accordingly. Nightmare Dreamer achieves nearly zero safety violations while maximizing rewards. Nightmare Dreamer outperforms model-free baselines on Safety Gymnasium tasks using only image observations, achieving nearly a 20x improvement in efficiency.

</details>


### [62] [Do LLMs Benefit from User and Item Embeddings in Recommendation Tasks?](https://arxiv.org/abs/2601.04690)
*Mir Rayat Imtiaz Hossain,Leo Feng,Leonid Sigal,Mohamed Osama Ahmed*

Main category: cs.LG

TL;DR: 通过轻量投影将CF嵌入映射到LLM token空间，结合文本生成式推荐，显著提升推荐性能并桥接传统CF与LLM。


<details>
  <summary>Details</summary>
Motivation: 传统基于LLM的推荐方法往往仅依赖文本语义或只利用单一用户/物品embedding，无法充分利用用户历史中的多物品协同信号，导致协同信息被忽略或被“文本化”。

Method: 先使用轻量级投影模块将协同过滤学习到的用户和物品嵌入映射至LLM的token空间，然后在已微调的LLM中将这些投影嵌入与文本tokens共同作为条件输入，直接生成推荐列表。

Result: 初步实验表明，该设计有效利用了结构化的用户-物品交互数据，推荐效果显著优于仅使用文本的LLM基线。

Conclusion: 本文提出的方案通过将协同过滤得到的用户与物品嵌入投射到LLM词标识空间，并结合文本信息进行生成式推荐，显著提升了在文本仅使用的LLM推荐基线之上的性能，为传统推荐系统与现代LLM的融合提供了可行路径。

Abstract: Large Language Models (LLMs) have emerged as promising recommendation systems, offering novel ways to model user preferences through generative approaches. However, many existing methods often rely solely on text semantics or incorporate collaborative signals in a limited manner, typically using only user or item embeddings. These methods struggle to handle multiple item embeddings representing user history, reverting to textual semantics and neglecting richer collaborative information. In this work, we propose a simple yet effective solution that projects user and item embeddings, learned from collaborative filtering, into the LLM token space via separate lightweight projector modules. A finetuned LLM then conditions on these projected embeddings alongside textual tokens to generate recommendations. Preliminary results show that this design effectively leverages structured user-item interaction data, improves recommendation performance over text-only LLM baselines, and offers a practical path for bridging traditional recommendation systems with modern LLMs.

</details>


### [63] [MQ-GNN: A Multi-Queue Pipelined Architecture for Scalable and Efficient GNN Training](https://arxiv.org/abs/2601.04707)
*Irfan Ullah,Young-Koo Lee*

Main category: cs.LG

TL;DR: MQ-GNN通过多队列流水线和异步一致更新，提升GNN训练速度4.6×、GPU利用率30%，并保持准确度


<details>
  <summary>Details</summary>
Motivation: GNN训练在多GPU环境下受制于mini-batch生成、数据传输瓶颈和GPU间同步费用，导致效率低下

Method: 多队列流水线MQ-GNN结合Ready-to-Update Asynchronous Consistent Model (RaCoM)实现异步梯度共享与模型更新，配合全局邻居采样缓存与自适应队列尺寸调度以提高计算与内存利用

Result: 实验显示MQ-GNN在四大规模数据集与十个基线模型上训练速度提升4.6倍，GPU利用率提升30%，且保持竞争性准确率

Conclusion: MQ-GNN通过重叠训练阶段、异步一致更新及资源调度，实现了可扩展且高效的多GPU GNN训练框架

Abstract: Graph Neural Networks (GNNs) are powerful tools for learning graph-structured data, but their scalability is hindered by inefficient mini-batch generation, data transfer bottlenecks, and costly inter-GPU synchronization. Existing training frameworks fail to overlap these stages, leading to suboptimal resource utilization. This paper proposes MQ-GNN, a multi-queue pipelined framework that maximizes training efficiency by interleaving GNN training stages and optimizing resource utilization. MQ-GNN introduces Ready-to-Update Asynchronous Consistent Model (RaCoM), which enables asynchronous gradient sharing and model updates while ensuring global consistency through adaptive periodic synchronization. Additionally, it employs global neighbor sampling with caching to reduce data transfer overhead and an adaptive queue-sizing strategy to balance computation and memory efficiency. Experiments on four large-scale datasets and ten baseline models demonstrate that MQ-GNN achieves up to \boldmath $\bm{4.6\,\times}$ faster training time and 30% improved GPU utilization while maintaining competitive accuracy. These results establish MQ-GNN as a scalable and efficient solution for multi-GPU GNN training.

</details>


### [64] [GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models](https://arxiv.org/abs/2601.04719)
*Maanas Taneja,Purab Shingvi*

Main category: cs.LG

TL;DR: INT8量化+GPU向量化核可将KV缓存内存压缩4倍，几乎无精度损失，显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: KV缓存随序列长度线性增长，内存成为推理瓶颈；需要一种既压缩内存又保持精度的方案。

Method: 实现并评估GPU加速的INT8量化，构建四种CUDA核：naive、tiled、coarsened、vectorized，并在大规模工作负载上进行基准测试。

Result: 向量化核实现高达1694倍速度提升，内存压缩4倍，重建误差<0.004，注意力分数误差<0.1，计算开销仅6–58ms。

Conclusion: INT8量化可以在LLM推理中显著降低KV缓存内存占用，几乎不影响性能和结果。

Abstract: The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compression, achieving 4$\times$ memory reduction with minimal accuracy degradation. We develop four CUDA kernel variants -- naive, tiled, coarsened, and vectorized -- and benchmark them across realistic workload sizes up to 1 billion elements. Our vectorized kernel achieves up to 1,694$\times$ speedup over CPU baselines while maintaining reconstruction error below 0.004 and attention score error below 0.1 even for 8K-dimensional heads. These results demonstrate that INT8 quantization provides a practical approach for reducing memory pressure in LLM inference with negligible computational overhead (6--58ms) and minimal impact on downstream model behavior

</details>


### [65] [Excess Description Length of Learning Generalizable Predictors](https://arxiv.org/abs/2601.04728)
*Elizabeth Donoway,Hailey Joren,Fabien Roger,Jan Leike*

Main category: cs.LG

TL;DR: 本文用 Excess Description Length 衡量微调时信息获得，证明其可量化并解释能力激活与新能力学习的不同尺度特征。


<details>
  <summary>Details</summary>
Motivation: 了解微调是激活潜在能力还是教授新能力，对评估语言模型安全性与性能至关重要。

Method: 定义 Excess Description Length（EDL）作为前序编码差值，证明其非负性、收敛性与泛化收益的上下界，并在多组简化模型中检验其特性。

Result: EDL 量化了训练数据对模型参数的熵增，并通过 toy 例子阐释了随机标签、单例学习、稀有输入与格式学习的规律，验证了能力激活与新能力教学在规模行为上存在不同标记。

Conclusion: 本文通过信息论框架表明微调提取并写入模型参数的可预测结构可量化，提供了区分能力激活与新能力学习的理论依据。

Abstract: Understanding whether fine-tuning elicits latent capabilities or teaches new ones is a fundamental question for language model evaluation and safety. We develop a formal information-theoretic framework for quantifying how much predictive structure fine-tuning extracts from the train dataset and writes into a model's parameters. Our central quantity, Excess Description Length (EDL), is defined via prequential coding and measures the gap between the bits required to encode training labels sequentially using an evolving model (trained online) and the residual encoding cost under the final trained model. We establish that EDL is non-negative in expectation, converges to surplus description length in the infinite-data limit, and provides bounds on expected generalization gain. Through a series of toy models, we clarify common confusions about information in learning: why random labels yield EDL near zero, how a single example can eliminate many bits of uncertainty about the underlying rule(s) that describe the data distribution, why structure learned on rare inputs contributes proportionally little to expected generalization, and how format learning creates early transients distinct from capability acquisition. This framework provides rigorous foundations for the empirical observation that capability elicitation and teaching exhibit qualitatively distinct scaling signatures.

</details>


### [66] [Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams](https://arxiv.org/abs/2601.04741)
*Kota Nakamura,Koki Kawabata,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: TimeCast是面向实时多传感器流的动态事件时间预测框架，利用阶段识别和在线模型更新，达到更准、更快的故障预测。


<details>
  <summary>Details</summary>
Motivation: 实时传感器流数据随时间演化，传统静态预测模型难以跟上演化速度；故障预测要求在变化的动态环境中持续精确。

Method: 构建层次化分段学习体系（Stage Learning），在每个阶段内训练独立模型，并采用在线更新机制快速适应传感器数据的时间演变；通过多传感器交互特征捕捉，提高预测精度。

Result: 实验表明，TimeCast在真实工况数据集上相较于现有方法提升了多达15% 的预测准确率，并将计算时间下降至原~20%。

Conclusion: TimeCast通过动态模型识别与跟踪数据流中的阶段性模式变化，显著提升了对未来机器故障时间点的预测准确率；同时，该框架在实际应用中实现了线性扩展及在线模型更新。

Abstract: Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.

</details>


### [67] [Intraday spatiotemporal PV power prediction at national scale using satellite-based solar forecast models](https://arxiv.org/abs/2601.04751)
*Luca Lanzilao,Angela Meyer*

Main category: cs.LG

TL;DR: 先用卫星辐射验证，再转化为光伏功率，评估七模型。卫星深度学习模型最高准确性，误差低于10%的天数达82%。


<details>
  <summary>Details</summary>
Motivation: 大区域光伏预测尚缺少空间-时间一致的评估和现实操作检验，需验证卫星预报在全国尺度的有效性与可视化云系统对电量的影响。

Method: 结合卫星辐射深度学习、光流与数值天气预报的混合框架；先检验辐射场，再用站点特定机学习映射到发电量；对比七套现有现时预测方法。

Result: SolarSTEPS与SHADECast的SSI/功率预测最精准；SHADECast的集成分布最可靠；IrradianceNet误差最低；在低海拔地区模型精度高，瑞士全国日累计功率相对误差<10%达到82%天。

Conclusion: 卫星基预报在全瑞士全尺度短期光伏电量预测中表现最优，具备良好的可靠性和可操作性。

Abstract: We present a novel framework for spatiotemporal photovoltaic (PV) power forecasting and use it to evaluate the reliability, sharpness, and overall performance of seven intraday PV power nowcasting models. The model suite includes satellite-based deep learning and optical-flow approaches and physics-based numerical weather prediction models, covering both deterministic and probabilistic formulations. Forecasts are first validated against satellite-derived surface solar irradiance (SSI). Irradiance fields are then converted into PV power using station-specific machine learning models, enabling comparison with production data from 6434 PV stations across Switzerland. To our knowledge, this is the first study to investigate spatiotemporal PV forecasting at a national scale. We additionally provide the first visualizations of how mesoscale cloud systems shape national PV production on hourly and sub-hourly timescales. Our results show that satellite-based approaches outperform the Integrated Forecast System (IFS-ENS), particularly at short lead times. Among them, SolarSTEPS and SHADECast deliver the most accurate SSI and PV power predictions, with SHADECast providing the most reliable ensemble spread. The deterministic model IrradianceNet achieves the lowest root mean square error, while probabilistic forecasts of SolarSTEPS and SHADECast provide better-calibrated uncertainty. Forecast skill generally decreases with elevation. At a national scale, satellite-based models forecast the daily total PV generation with relative errors below 10% for 82% of the days in 2019-2020, demonstrating robustness and their potential for operational use.

</details>


### [68] [Parallelizing Node-Level Explainability in Graph Neural Networks](https://arxiv.org/abs/2601.04807)
*Oscar Llorente,Jaime Boal,Eugenio F. Sánchez-Úbeda,Antonio Diaz-Cano,Miguel Familiar*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable performance in a wide range of tasks, such as node classification, link prediction, and graph classification, by exploiting the structural information in graph-structured data. However, in node classification, computing node-level explainability becomes extremely time-consuming as the size of the graph increases, while batching strategies often degrade explanation quality. This paper introduces a novel approach to parallelizing node-level explainability in GNNs through graph partitioning. By decomposing the graph into disjoint subgraphs, we enable parallel computation of explainability for node neighbors, significantly improving the scalability and efficiency without affecting the correctness of the results, provided sufficient memory is available. For scenarios where memory is limited, we further propose a dropout-based reconstruction mechanism that offers a controllable trade-off between memory usage and explanation fidelity. Experimental results on real-world datasets demonstrate substantial speedups, enabling scalable and transparent explainability for large-scale GNN models.

</details>


### [69] [FibreCastML: An Open Web Platform for Predicting Electrospun Nanofibre Diameter Distributions](https://arxiv.org/abs/2601.04873)
*Elisa Roldan,Kirstie Andrews,Stephen M. Richardson,Reyhaneh Fatahian,Glen Cooper,Rasool Erfani,Tasneem Sabir,Neil D. Reeves*

Main category: cs.LG

TL;DR: FibreCastML利用多源实验数据和可解释ML，准确预测电纺纤维直径分布，为支架制造提供数据驱动优化。


<details>
  <summary>Details</summary>
Motivation: 传统ML方法仅预测平均纤维直径，忽视完整分布，导致支架性能评估不足；因此需要一个分布感知、可解释的ML框架。

Method: 构建包含68538条纤维直径的元数据集，挑选六个常规工艺参数，使用嵌套交叉验证(Leave-One-Study-Out)训练七种机器学习模型，并通过变量重要性、SHAP、相关矩阵及三维参数图实现可解释性。

Result: 非线性模型在多种聚合物上$R^2>0.91$，显示出卓越性能；实验验证证实预测分布与测量结果高度吻合。

Conclusion: FibreCastML能够预测完整的纤维直径分布并提供可解释的过程关系，显著提高电纺支架设计的可重复性与数据驱动性。

Abstract: Electrospinning is a scalable technique for producing fibrous scaffolds with tunable micro- and nanoscale architectures for applications in tissue engineering, drug delivery, and wound care. While machine learning (ML) has been used to support electrospinning process optimisation, most existing approaches predict only mean fibre diameters, neglecting the full diameter distribution that governs scaffold performance. This work presents FibreCastML, an open, distribution-aware ML framework that predicts complete fibre diameter spectra from routinely reported electrospinning parameters and provides interpretable insights into process structure relationships.
  A meta-dataset comprising 68538 individual fibre diameter measurements extracted from 1778 studies across 16 biomedical polymers was curated. Six standard processing parameters, namely solution concentration, applied voltage, flow rate, tip to collector distance, needle diameter, and collector rotation speed, were used to train seven ML models using nested cross validation with leave one study out external folds. Model interpretability was achieved using variable importance analysis, SHapley Additive exPlanations, correlation matrices, and three dimensional parameter maps.
  Non linear models consistently outperformed linear baselines, achieving coefficients of determination above 0.91 for several widely used polymers. Solution concentration emerged as the dominant global driver of fibre diameter distributions. Experimental validation across different electrospinning systems demonstrated close agreement between predicted and measured distributions. FibreCastML enables more reproducible and data driven optimisation of electrospun scaffold architectures.

</details>


### [70] [Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers](https://arxiv.org/abs/2601.04890)
*Maksim Velikanov,Ilyas Chahed,Jingwei Zuo,Dhia Eddine Rhaiem,Younes Belkada,Hakim Hacid*

Main category: cs.LG

TL;DR: 通过在矩阵层及其行列上引入可学习乘子，打破WD噪声平衡的规模限制，提升模型性能并减少调参成本。


<details>
  <summary>Details</summary>
Motivation: 权重衰减（WD）在大型语言模型预训练中常见，但其在矩阵层上的平衡使得权重矩阵的大小为不利的训练产物。该方法认为基于随机梯度噪声的Brownian-like扩张产生的WD-噪声平衡导致权重范数子最优，需要更灵活的尺度学习。

Method: 为每个权重矩阵引入可学习的标量乘子，并进一步拆分为每行每列的乘子，以解锁更具表现力的尺度调节，形成对muP乘子的一般化扩展。

Result: 学习的乘子在Adam和Muon优化器下均能提升下游评估，且相对于精调的muP基线取得更优性能，减少了乘子调节的计算开销。

Conclusion: 引入可学习的多尺度乘子能够显著突破WD噪声平衡导致的性能瓶颈，在保持或加速收敛的前提下提升模型表现。

Abstract: Applying weight decay (WD) to matrix layers is standard practice in large-language-model pretraining. Prior work suggests that stochastic gradient noise induces a Brownian-like expansion of the weight matrices W, whose growth is counteracted by WD, leading to a WD-noise equilibrium with a certain weight norm ||W||. In this work, we view the equilibrium norm as a harmful artifact of the training procedure, and address it by introducing learnable multipliers to learn the optimal scale. First, we attach a learnable scalar multiplier to W and confirm that the WD-noise equilibrium norm is suboptimal: the learned scale adapts to data and improves performance. We then argue that individual row and column norms are similarly constrained, and free their scale by introducing learnable per-row and per-column multipliers. Our method can be viewed as a learnable, more expressive generalization of muP multipliers. It outperforms a well-tuned muP baseline, reduces the computational overhead of multiplier tuning, and surfaces practical questions such as forward-pass symmetries and the width-scaling of the learned multipliers. Finally, we validate learnable multipliers with both Adam and Muon optimizers, where it shows improvement in downstream evaluations matching the improvement of the switching from Adam to Muon.

</details>


### [71] [Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following](https://arxiv.org/abs/2601.04954)
*Yirong Zeng,Yufei Liu,Xiao Ding,Yutai Hou,Yuxian Wang,Haonan Song,Wu Ning,Dandan Tu,Qixun Zhang,Bibo Cai,Yuxiang He,Ting Liu*

Main category: cs.LG

TL;DR: 仅用高精度硬约束训练可超越混合约束模型，取得13.4%性能提升并减少58%训练时间。


<details>
  <summary>Details</summary>
Motivation: 质疑传统认为约束多样性是泛化关键的观点，探索奖励精确度对模型对齐和泛化的影响。

Method: 进行系统性实证调查，比较仅硬约束、混合约束模型并分析奖励精度、注意力机制，随后提出基于奖励精度的数据中心化精炼策略。

Result: 在五个基准上，所提方法相较竞争基线提升13.4%性能，训练时间缩短58%，并保持良好泛化。

Conclusion: 本研究发现，使用高精度硬约束训练的模型在指令跟随任务中优于包含软约束的混合数据集，提升了性能并缩短了训练时间。

Abstract: A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperform those trained on mixed datasets. Extensive experiments reveal that reward precision, rather than constraint diversity, is the primary driver of effective alignment. The LLM judge suffers from a low recall rate in detecting false response, which leads to severe reward hacking, thereby undermining the benefits of diversity. Furthermore, analysis of the attention mechanism reveals that high-precision rewards develop a transferable meta-skill for IF. Motivated by these insights, we propose a simple yet effective data-centric refinement strategy that prioritizes reward precision. Evaluated on five benchmarks, our approach outperforms competitive baselines by 13.4\% in performance while achieving a 58\% reduction in training time, maintaining strong generalization beyond instruction following. Our findings advocate for a paradigm shift: moving away from the indiscriminate pursuit of data diversity toward high-precision rewards.

</details>


### [72] [On the Definition and Detection of Cherry-Picking in Counterfactual Explanations](https://arxiv.org/abs/2601.04977)
*James Hinns,Sofie Goethals,Stephan Van der Veeken,Theodoros Evgeniou,David Martens*

Main category: cs.LG

TL;DR: 论文探讨对抗性解释的“挑食”可能性，证明对其检测非常困难，并建议通过可复现性、标准化及程序限制来预防。


<details>
  <summary>Details</summary>
Motivation: 单个数据样本可能产生多个合法的对抗性解释，解释提供者可能挑选有利的解释，从而操纵解释结果。

Method: 在设定可接受解释空间和效用函数的正式定义下，探讨在三种信息获取级别（完全程序访问、部分程序访问、仅解释访问）下的检测可行性，结合理论证明与实验评估。

Result: 即便在完全程序访问时，挑选出的解释在多样性与灵活性支持下仍难以与非挑选解释区别；在实验中，解释质量指标的变化几乎被解释多样性所掩盖，使挑选与基线解释在统计上不可区分。

Conclusion: 提示“挑食”式的对抗性解释（cherry‑picking）很难被外部审计员根据可选解释空间和效用函数检测，因而在实际应用中只靠事后检测往往无效；建议侧重可复现性、标准化与对生成过程的约束。

Abstract: Counterfactual explanations are widely used to communicate how inputs must change for a model to alter its prediction. For a single instance, many valid counterfactuals can exist, which leaves open the possibility for an explanation provider to cherry-pick explanations that better suit a narrative of their choice, highlighting favourable behaviour and withholding examples that reveal problematic behaviour. We formally define cherry-picking for counterfactual explanations in terms of an admissible explanation space, specified by the generation procedure, and a utility function. We then study to what extent an external auditor can detect such manipulation. Considering three levels of access to the explanation process: full procedural access, partial procedural access, and explanation-only access, we show that detection is extremely limited in practice. Even with full procedural access, cherry-picked explanations can remain difficult to distinguish from non cherry-picked explanations, because the multiplicity of valid counterfactuals and flexibility in the explanation specification provide sufficient degrees of freedom to mask deliberate selection. Empirically, we demonstrate that this variability often exceeds the effect of cherry-picking on standard counterfactual quality metrics such as proximity, plausibility, and sparsity, making cherry-picked explanations statistically indistinguishable from baseline explanations. We argue that safeguards should therefore prioritise reproducibility, standardisation, and procedural constraints over post-hoc detection, and we provide recommendations for algorithm developers, explanation providers, and auditors.

</details>


### [73] [HMVI: Unifying Heterogeneous Attributes with Natural Neighbors for Missing Value Inference](https://arxiv.org/abs/2601.05017)
*Xiaopeng Luo,Zexi Tan,Zhuowei Wang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Missing value imputation is a fundamental challenge in machine intelligence, heavily dependent on data completeness. Current imputation methods often handle numerical and categorical attributes independently, overlooking critical interdependencies among heterogeneous features. To address these limitations, we propose a novel imputation approach that explicitly models cross-type feature dependencies within a unified framework. Our method leverages both complete and incomplete instances to ensure accurate and consistent imputation in tabular data. Extensive experimental results demonstrate that the proposed approach achieves superior performance over existing techniques and significantly enhances downstream machine learning tasks, providing a robust solution for real-world systems with missing data.

</details>


### [74] [Approximate equivariance via projection-based regularisation](https://arxiv.org/abs/2601.05028)
*Torben Berndt,Jan Stühmer*

Main category: cs.LG

TL;DR: 提出投影正则化方式，通过正交分解在整个对称群轨道上精确惩罚非等变项，显著提升速度与性能，优于传统样本正则化。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中对称性可能不完美，非等变模型兼顾效率，促使需开发既能尊重对称性又能适应数据分布的近似等变模型。

Method: 采用基于投影的正则化，利用线性层在等变和非等变分量的正交分解，在整个群轨道级别对非等变性进行惩罚；通过空间域与频谱域的解析框架精确高效计算该惩罚。

Result: 在多组实验中，该方法在模型性能和计算效率上均优于以往的样本量大、依赖数据增强的近似等变正则化方法，显著提升了运行时速度。

Conclusion: 本工作提供了一种更高效、更精准的近似等变正则化策略，兼顾对称性与实际数据适配，广泛适用于连续群如SO(3)的任务。

Abstract: Equivariance is a powerful inductive bias in neural networks, improving generalisation and physical consistency. Recently, however, non-equivariant models have regained attention, due to their better runtime performance and imperfect symmetries that might arise in real-world applications. This has motivated the development of approximately equivariant models that strike a middle ground between respecting symmetries and fitting the data distribution. Existing approaches in this field usually apply sample-based regularisers which depend on data augmentation at training time, incurring a high sample complexity, in particular for continuous groups such as $SO(3)$. This work instead approaches approximate equivariance via a projection-based regulariser which leverages the orthogonal decomposition of linear layers into equivariant and non-equivariant components. In contrast to existing methods, this penalises non-equivariance at an operator level across the full group orbit, rather than point-wise. We present a mathematical framework for computing the non-equivariance penalty exactly and efficiently in both the spatial and spectral domain. In our experiments, our method consistently outperforms prior approximate equivariance approaches in both model performance and efficiency, achieving substantial runtime gains over sample-based regularisers.

</details>


### [75] [A Data-Driven Predictive Framework for Inventory Optimization Using Context-Augmented Machine Learning Models](https://arxiv.org/abs/2601.05033)
*Anees Fatima,Mohammad Abdus Salam*

Main category: cs.LG

TL;DR: 使用XGBoost并加入外部因素可大幅改善零售与自动售货机的需求预测，平均误差降至22.7，优于ARIMA、Prophet和SVR。


<details>
  <summary>Details</summary>
Motivation: 传统需求预测方法忽视天气、节日等外部影响，导致库存管理低效。该研究旨在通过机器学习方法结合外部变量，提升预测准确性与库存管理效果。

Method: 本研究选取XGBoost、ARIMA、Facebook Prophet以及SVR四种机器学习算法，通过系统地加入工作日、节假日及销售偏差等外部因素，对零售和自动售货机的库存需求进行时间序列预测。

Result: XGBoost在加入外部变量后MAE降至最低22.7；ARIMAX 与 Facebook Prophet 亦显著改善；SVR表现不佳。外部因素的加入显著提升预测精度。

Conclusion: XGBoost在引入外部变量后表现最佳，最低MAE为22.7，验证了加入外部因素能够显著提升零售与自动售货机的需求预测精度。

Abstract: Demand forecasting in supply chain management (SCM) is critical for optimizing inventory, reducing waste, and improving customer satisfaction. Conventional approaches frequently neglect external influences like weather, festivities, and equipment breakdowns, resulting in inefficiencies. This research investigates the use of machine learning (ML) algorithms to improve demand prediction in retail and vending machine sectors. Four machine learning algorithms. Extreme Gradient Boosting (XGBoost), Autoregressive Integrated Moving Average (ARIMA), Facebook Prophet (Fb Prophet), and Support Vector Regression (SVR) were used to forecast inventory requirements. Ex-ternal factors like weekdays, holidays, and sales deviation indicators were methodically incorporated to enhance precision. XGBoost surpassed other models, reaching the lowest Mean Absolute Error (MAE) of 22.7 with the inclusion of external variables. ARIMAX and Fb Prophet demonstrated noteworthy enhancements, whereas SVR fell short in performance. Incorporating external factors greatly improves the precision of demand forecasting models, and XGBoost is identified as the most efficient algorithm. This study offers a strong framework for enhancing inventory management in retail and vending machine systems.

</details>


### [76] [Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward](https://arxiv.org/abs/2601.05073)
*Jianlong Chen,Daocheng Fu,Shengze Xu,Jiawei Chen,Yuan Feng,Yue Yang,Junchi Yan,Hongyuan Zha,Renqiu Xia*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multimodal Large Language Models (MLLMs) struggle with complex geometric reasoning, largely because "black box" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces sparse signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.

</details>


### [77] [Exploring Student Expectations and Confidence in Learning Analytics](https://arxiv.org/abs/2601.05082)
*Hayk Asatryan,Basile Tousside,Janis Mohr,Malte Neugebauer,Hildo Bijl,Paul Spiegelberg,Claudia Frohn-Schauf,Jörg Frochte*

Main category: cs.LG

TL;DR: 通过问卷+聚类，找出四类学生对学习分析的态度差异，为符合隐私法规的学习分析推广提供洞察。


<details>
  <summary>Details</summary>
Motivation: 在学习分析普及的同时，增强学生对数据隐私的关注，需了解学生对数据处理的态度，以实现合法合规并提升学习分析工具的接受度。

Method: 采用SELAQ问卷收集学生数据，运用聚类算法对学生进行分群，随后对各群体的期望和信任进行定量与定性分析。

Result: 将学生划分为爱好者、现实主义者、谨慎者与漠不关心者四组，每组在数据信任与期望上表现出明显差异，为学校在政策制定与工具开发提供依据。

Conclusion: 本文通过SELAQ问卷探讨不同学院学生对学习分析数据处理的期望与信任，并基于聚类算法识别四类学生群体，为教育系统适应隐私法规与提升学习分析接受度提供策略。

Abstract: Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.

</details>


### [78] [Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning](https://arxiv.org/abs/2601.05134)
*Polina Dolgova,Sebastian U. Stich*

Main category: cs.LG

TL;DR: 将噪声预算分散到正交子空间而非一次性注入，可在保证(ε,δ)差分隐私认证的前提下大幅提升去学习后模型精度。


<details>
  <summary>Details</summary>
Motivation: 传统的噪声微调方法尽管能实现差分隐私认证，但会导致模型准确性大幅下降；研究者希望在确保安全性的同时提升实用性。

Method: 通过将噪声预算分配到参数空间的正交子空间，而非一次性注入噪声，构建顺序噪声调度机制，并对该方法在子空间框架下的差分隐私性进行理论扩展。

Result: 在图像分类基准上实验验证，分段噪声调度方案在完成去学习后显著提高了模型准确率，同时对成员推断攻击保持稳健。

Conclusion: 使用分段噪声调度的差分隐私认证无学习方案能够在保持严格安全保证的前提下显著提升模型在去学习后的准确率。

Abstract: Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\varepsilon,δ)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.

</details>


### [79] [An interpretable data-driven approach to optimizing clinical fall risk assessment](https://arxiv.org/abs/2601.05194)
*Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Holley Farley,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 使用受限得分优化对JHFRAT进行重权后，预测性能显著提升，可每周多识别35名住院高危跌倒患者。


<details>
  <summary>Details</summary>
Motivation: 提升JHFRAT与临床实际需求的契合度，减少跌倒事件，提高患者安全和资源利用效率。

Method: 对2022年至2023年约翰霍普金斯健康体系内54,209例住院病例进行回顾性队列分析，采用受限得分优化（CSO）模型重新加权JHFRAT得分，保持其加性结构和阈值；与原始JHFRAT、受限逻辑回归以及XGBoost等模型进行比较。

Result: CSO模型ROC AUC提高至0.91（原始0.86），每周可额外识别35名高危患者；与XGBoost相比，CSO在风险标签变化时更稳健。

Conclusion: 该研究提供了一种基于证据的、可解释的模型改进方法，显著提升了约翰霍普金斯系统内住院跌倒风险预测的准确度，并为医疗机构提供了可操作的、稳健的跌倒预防与资源分配基础。

Abstract: In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.

</details>


### [80] [Optimal Lower Bounds for Online Multicalibration](https://arxiv.org/abs/2601.05245)
*Natalie Collina,Jiuyao Lu,Georgy Noarov,Aaron Roth*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We prove tight lower bounds for online multicalibration, establishing an information-theoretic separation from marginal calibration.
  In the general setting where group functions can depend on both context and the learner's predictions, we prove an $Ω(T^{2/3})$ lower bound on expected multicalibration error using just three disjoint binary groups. This matches the upper bounds of Noarov et al. (2025) up to logarithmic factors and exceeds the $O(T^{2/3-\varepsilon})$ upper bound for marginal calibration (Dagan et al., 2025), thereby separating the two problems.
  We then turn to lower bounds for the more difficult case of group functions that may depend on context but not on the learner's predictions. In this case, we establish an $\widetildeΩ(T^{2/3})$ lower bound for online multicalibration via a $Θ(T)$-sized group family constructed using orthogonal function systems, again matching upper bounds up to logarithmic factors.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [81] [Social Engineering Attacks: A Systemisation of Knowledge on People Against Humans](https://arxiv.org/abs/2601.04215)
*Scott Thomson,Michael Bewong,Arash Mahboubi,Tanveer Zia*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Our systematisation of knowledge on Social Engineering Attacks (SEAs), identifies the human, organisational, and adversarial dimensions of cyber threats. It addresses the growing risks posed by SEAs, highly relevant in the context physical cyber places, such as travellers at airports and residents in smart cities, and synthesizes findings from peer reviewed studies, industry and government reports to inform effective countermeasures that can be embedded into future smart city strategies. SEAs increasingly sidestep technical controls by weaponising leaked personal data and behavioural cues, an urgency underscored by the Optus, Medibank and now Qantas (2025) mega breaches that placed millions of personal records in criminals' hands. Our review surfaces three critical dimensions: (i) human factors of knowledge, abilities and behaviours (KAB) (ii) organisational culture and informal norms that shape those behaviours and (iii) attacker motivations, techniques and return on investment calculations. Our contributions are threefold: (1) TriLayer Systematisation: to the best of our knowledge, we are the first to unify KAB metrics, cultural drivers and attacker economics into a single analytical lens, enabling practitioners to see how vulnerabilities, norms and threat incentives coevolve. (2) Risk Weighted HAISQ Meta analysis: By normalising and ranking HAISQ scores across recent field studies, we reveal persistent high risk clusters (Internet and Social Media use) and propose impact weightings that make the instrument predictive rather than descriptive. (3) Adaptive 'Segment and Simulate' Training Blueprint: Building on clustering evidence, we outline a differentiated programme that matches low, medium, high risk user cohorts to experiential learning packages including phishing simulations, gamified challenges and realtime feedback thereby aligning effort with measured exposure.

</details>


### [82] [Beyond Immediate Activation: Temporally Decoupled Backdoor Attacks on Time Series Forecasting](https://arxiv.org/abs/2601.04247)
*Zhixin Liu,Xuanlin Liu,Sihan Xu,Yaqiong Qiao,Ying Zhang,Xiangrui Cai*

Main category: cs.CR

TL;DR: TDBA通过位置编码触发器实现时间与维度解耦的后门攻击，实验显示在提升攻击效果的同时保持隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击在多变量时间序列预测中需严格时序与维度耦合，难以满足现实中对推迟且变量特定激活的需求。

Method: 通过位置引导触发器生成机制与基于位置的优化模块，使触发器能够对预定目标模式进行位置相关编码，并根据触发器完整度、模式覆盖度与时间偏移给出软权重，实现灵活、可控且隐蔽的攻击。

Result: 在真实世界数据集的实验中，TDBA在有效性上持续优于基线，同时保持良好的隐蔽性；消融实验验证了其控制性与鲁棒性。

Conclusion: TDBA在多变量时间序列预测中的鲁棒性、可控性与隐蔽性显著优于现有基线，构建了更具实用性的后门攻击框架。

Abstract: Existing backdoor attacks on multivariate time series (MTS) forecasting enforce strict temporal and dimensional coupling between triggers and target patterns, requiring synchronous activation at fixed positions across variables. However, realistic scenarios often demand delayed and variable-specific activation. We identify this critical unmet need and propose TDBA, a temporally decoupled backdoor attack framework for MTS forecasting. By injecting triggers that encode the expected location of the target pattern, TDBA enables the activation of the target pattern at any positions within the forecasted data, with the activation position flexibly varying across different variable dimensions. TDBA introduces two core modules: (1) a position-guided trigger generation mechanism that leverages smoothed Gaussian priors to generate triggers that are position-related to the predefined target pattern; and (2) a position-aware optimization module that assigns soft weights based on trigger completeness, pattern coverage, and temporal offset, facilitating targeted and stealthy attack optimization. Extensive experiments on real-world datasets show that TDBA consistently outperforms existing baselines in effectiveness while maintaining good stealthiness. Ablation studies confirm the controllability and robustness of its design.

</details>


### [83] [Inhibitory Attacks on Backdoor-based Fingerprinting for Large Language Models](https://arxiv.org/abs/2601.04261)
*Hang Fu,Wanli Peng,Yinghan Zhou,Jiaxuan Wu,Juan Wen,Yiming Xue*

Main category: cs.CR

TL;DR: 在LLM集成环境下，现有指纹识别面临弱点；作者设计了TFA和SVA两种攻击，实验验证其高效性，提示需加固指纹防护。


<details>
  <summary>Details</summary>
Motivation: 商业与科研中大规模语言模型广泛使用，版权保护变得尤为重要；但目前针对LLM集成的指纹可靠性尚未得到评估。

Method: 提出两种新型攻击技术：Token Filter Attack (TFA) 通过在每个解码步骤从统一的 token 集中选择下一个 token；Sentence Verification Attack (SVA) 基于困惑度与投票机制过滤指纹输出。

Result: 实验表明，TFA 与 SVA 能有效抑制指纹响应，同时保持集成模型性能，且优于现有最先进的攻击方法。

Conclusion: 本文指出，在多模型集成场景下现有的LLM指纹识别方法易被迭代攻击，建议必须提升指纹的鲁棒性。

Abstract: The widespread adoption of Large Language Model (LLM) in commercial and research settings has intensified the need for robust intellectual property protection. Backdoor-based LLM fingerprinting has emerged as a promising solution for this challenge. In practical application, the low-cost multi-model collaborative technique, LLM ensemble, combines diverse LLMs to leverage their complementary strengths, garnering significant attention and practical adoption. Unfortunately, the vulnerability of existing LLM fingerprinting for the ensemble scenario is unexplored. In order to comprehensively assess the robustness of LLM fingerprinting, in this paper, we propose two novel fingerprinting attack methods: token filter attack (TFA) and sentence verification attack (SVA). The TFA gets the next token from a unified set of tokens created by the token filter mechanism at each decoding step. The SVA filters out fingerprint responses through a sentence verification mechanism based on perplexity and voting. Experimentally, the proposed methods effectively inhibit the fingerprint response while maintaining ensemble performance. Compared with state-of-the-art attack methods, the proposed method can achieve better performance. The findings necessitate enhanced robustness in LLM fingerprinting.

</details>


### [84] [You Only Anonymize What Is Not Intent-Relevant: Suppressing Non-Intent Privacy Evidence](https://arxiv.org/abs/2601.04265)
*Weihao Shen,Yaxin Xu,Shuang Li,Wei Chen,Yuqin Lan,Meng Yuan,Fuzhen Zhuang*

Main category: cs.CR

TL;DR: IntentAnony 是一种基于意图的匿名化方法，利用曝光预算和隐私证据链定制化处理属性，提升 30% 的隐私–可用性平衡，并增强文本可用性。


<details>
  <summary>Details</summary>
Motivation: 传统匿名化技术统一处理所有属性，常冲突通信意图并隐藏必要信息，尤其当个人属性对表达或实践目标至关重要时，如何在保护隐私的同时保持语义与实用性成为核心挑战。

Method: 采用意图分析与隐私推理证据链构建，为每个属性分配曝光预算，并在保持意图相关内容的同时，抑制非意图推理路径，实现定制化的匿名化。

Result: 在隐私推理成功率、文本可用性指标和人工评估上，IntentAnony显示出整体隐私-可用性折衷约30% 的提升，并且匿名文本的可用性明显优于先前最先进方法。

Conclusion: IntentAnony通过意图条件下的曝光控制，实现在隐私与可用性之间显著提升（约30%），并在保持语义、情感细微差别和互动功能方面优于现有方法。

Abstract: Anonymizing sensitive information in user text is essential for privacy, yet existing methods often apply uniform treatment across attributes, which can conflict with communicative intent and obscure necessary information. This is particularly problematic when personal attributes are integral to expressive or pragmatic goals. The central challenge lies in determining which attributes to protect, and to what extent, while preserving semantic and pragmatic functions. We propose IntentAnony, a utility-preserving anonymization approach that performs intent-conditioned exposure control. IntentAnony models pragmatic intent and constructs privacy inference evidence chains to capture how distributed cues support attribute inference. Conditioned on intent, it assigns each attribute an exposure budget and selectively suppresses non-intent inference pathways while preserving intent-relevant content, semantic structure, affective nuance, and interactional function. We evaluate IntentAnony using privacy inference success rates, text utility metrics, and human evaluation. The results show an approximately 30% improvement in the overall privacy--utility trade-off, with notably stronger usability of anonymized text compared to prior state-of-the-art methods. Our code is available at https://github.com/Nevaeh7/IntentAnony.

</details>


### [85] [State Backdoor: Towards Stealthy Real-world Poisoning Attack on Vision-Language-Action Model in State Space](https://arxiv.org/abs/2601.04266)
*Ji Guo,Wenbo Jiang,Yansong Lin,Yijing Liu,Ruichen Zhang,Guomin Lu,Aiguo Chen,Xinshuo Han,Hongwei Li,Dusit Niyato*

Main category: cs.CR

TL;DR: 本文提出利用机器手臂初始状态的后门攻击，并通过 P-GA 优化触发器方案，实验表明可达 90%+ 成功率，揭示了 VLA 系统的新漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有后门多为可见触发器，在环境变化下鲁棒性差；需要更隐蔽、稳健的攻击手段以测试嵌入式 AI 的安全性；

Method: 基于首位状态触发的后门攻击，利用偏好引导遗传算法（PGA）在状态空间中寻找既小且有效的触发器；

Result: 在五个代表性 VLA 模型与五个真实任务上，攻击成功率超过 90%，且对干净数据性能无影响；

Conclusion: 本文揭示了在安全关键的嵌入式 AI 系统中，使用机器人手臂初始状态作为触发器的新型后门攻击可实现高成功率且对正常任务无干扰，指出这一攻击方式在现实环境中的潜在威胁；

Abstract: Vision-Language-Action (VLA) models are widely deployed in safety-critical embodied AI applications such as robotics. However, their complex multimodal interactions also expose new security vulnerabilities. In this paper, we investigate a backdoor threat in VLA models, where malicious inputs cause targeted misbehavior while preserving performance on clean data. Existing backdoor methods predominantly rely on inserting visible triggers into visual modality, which suffer from poor robustness and low insusceptibility in real-world settings due to environmental variability. To overcome these limitations, we introduce the State Backdoor, a novel and practical backdoor attack that leverages the robot arm's initial state as the trigger. To optimize trigger for insusceptibility and effectiveness, we design a Preference-guided Genetic Algorithm (PGA) that efficiently searches the state space for minimal yet potent triggers. Extensive experiments on five representative VLA models and five real-world tasks show that our method achieves over 90% attack success rate without affecting benign task performance, revealing an underexplored vulnerability in embodied AI systems.

</details>


### [86] [Shadow Unlearning: A Neuro-Semantic Approach to Fidelity-Preserving Faceless Forgetting in LLMs](https://arxiv.org/abs/2601.04275)
*Dinesh Srivasthav P,Ashok Urlana,Rahul Mishra,Bala Mallikarjunarao Garlapati,Ponnurangam Kumaraguru*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Machine unlearning aims to selectively remove the influence of specific training samples to satisfy privacy regulations such as the GDPR's 'Right to be Forgotten'. However, many existing methods require access to the data being removed, exposing it to membership inference attacks and potential misuse of Personally Identifiable Information (PII). We address this critical challenge by proposing Shadow Unlearning, a novel paradigm of approximate unlearning, that performs machine unlearning on anonymized forget data without exposing PII. We further propose a novel privacy-preserving framework, Neuro-Semantic Projector Unlearning (NSPU) to achieve Shadow unlearning. To evaluate our method, we compile Multi-domain Fictitious Unlearning (MuFU) forget set across five diverse domains and introduce an evaluation stack to quantify the trade-off between knowledge retention and unlearning effectiveness. Experimental results on various LLMs show that NSPU achieves superior unlearning performance, preserves model utility, and enhances user privacy. Additionally, the proposed approach is at least 10 times more computationally efficient than standard unlearning approaches. Our findings foster a new direction for privacy-aware machine unlearning that balances data protection and model fidelity.

</details>


### [87] [Decision-Aware Trust Signal Alignment for SOC Alert Triage](https://arxiv.org/abs/2601.04486)
*Israt Jahan Chowdhury,Md Abu Yousuf Tanvir*

Main category: cs.CR

TL;DR: 本文提出将校准的置信度、轻量不确定性提示与成本敏感阈值集成的信任信号对齐方案，在UNSW‑NB15上实验表明可显著降低漏报和成本损失。未来将通过人机实验验证其效果。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习检测系统在SOC中输出的概率或置信分数往往未校准，难以在压力下解读。且缺乏对误报成本远低于漏报成本的经济权衡。弱的置信度表现与不匹配的决策需求会显著增大分析师负担。

Method: 本论文提出一种决策敏感的信任信号对应方案，用于SOC警报分级。该框架将已校准的置信度、轻量级不确定性提示以及成本敏感的决策阈值结合成一致的决策支持层，而无需改动检测模型。置信度校准采用已知的事后校准方法；在模型置信度较低的情况下引入保守的不确定性提示。随后将该方案应用于UNSW‑NB15入侵检测基准，分别使用逻辑回归和随机森林分类器进行实验。

Result: 实验表明，误对齐的置信度显示显著增加漏报率；而采用对齐的信任信号后，成本加权损失可下降数个数量级。

Conclusion: 提供一种决策导向的信任信号机制，能够提升警报质量并降低漏报风险，为分析师提供更可靠的决策支持。未来计划开展人机交互实验，评估对齐与未对齐信任界面的分析师决策。

Abstract: Detection systems that utilize machine learning are progressively implemented at Security Operations Centers (SOCs) to help an analyst to filter through high volumes of security alerts. Practically, such systems tend to reveal probabilistic results or confidence scores which are ill-calibrated and hard to read when under pressure. Qualitative and survey based studies of SOC practice done before reveal that poor alert quality and alert overload greatly augment the burden on the analyst, especially when tool outputs are not coherent with decision requirements, or signal noise. One of the most significant limitations is that model confidence is usually shown without expressing that there are asymmetric costs in decision making where false alarms are much less harmful than missed attacks. The present paper presents a decision-sensitive trust signal correspondence scheme of SOC alert triage. The framework combines confidence that has been calibrated, lightweight uncertainty cues, and cost-sensitive decision thresholds into coherent decision-support layer, instead of making changes to detection models. To enhance probabilistic consistency, the calibration is done using the known post-hoc methods and the uncertainty cues give conservative protection in situations where model certainty is low. To measure the model-independent performance of the suggested model, we apply the Logistic Regression and the Random Forest classifiers to the UNSW-NB15 intrusion detection benchmark. According to simulation findings, false negatives are greatly amplified by the presence of misaligned displays of confidence, whereas cost weighted loss decreases by orders of magnitude between models with decision aligned trust signals. Lastly, we describe a human-in-the-loop study plan that would allow empirically assessing the decision-making of the analysts with aligned and misaligned trust interfaces.

</details>


### [88] [Application of Hybrid Chain Storage Framework in Energy Trading and Carbon Asset Management](https://arxiv.org/abs/2601.04512)
*Yinghan Hou,Zongyou Yang,Xiaokun Yang*

Main category: cs.CR

TL;DR: 该框架把高频小额结算链下处理，减少链上负担，仍实现可验证审计


<details>
  <summary>Details</summary>
Motivation: 高频、小额结算与严苛审计需求

Method: 将结算承诺与关键约束锚定至链上，同时通过确定性摘要和可重放审计关联链下记录，构建混合链上链下结算框架

Result: 在公开受限工作负载下，显著降低链上执行与存储成本，同时保持审计可信性

Conclusion: 混合链上链下设计兼顾成本与可审计性，是可行的解决方案

Abstract: Distributed energy trading and carbon asset management involve high-frequency, small-value settlements with strong audit requirements. Fully on-chain designs incur excessive cost, while purely off-chain approaches lack verifiable consistency. This paper presents a hybrid on-chain and off-chain settlement framework that anchors settlement commitments and key constraints on-chain and links off-chain records through deterministic digests and replayable auditing. Experiments under publicly constrained workloads show that the framework significantly reduces on-chain execution and storage cost while preserving audit trustworthiness.

</details>


### [89] [Constitutional Classifiers++: Efficient Production-Grade Defenses against Universal Jailbreaks](https://arxiv.org/abs/2601.04603)
*Hoagy Cunningham,Jerry Wei,Zihan Wang,Andrew Persic,Alwin Peng,Jordan Abderrachid,Raj Agarwal,Bobby Chen,Austin Cohen,Andy Dau,Alek Dimitriev,Rob Gilson,Logan Howard,Yijin Hua,Jared Kaplan,Jan Leike,Mu Lin,Christopher Liu,Vladimir Mikulik,Rohit Mittapalli,Clare O'Hara,Jin Pan,Nikhil Saxena,Alex Silverstein,Yue Song,Xunjie Yu,Giulio Zhou,Ethan Perez,Mrinank Sharma*

Main category: cs.CR

TL;DR: 改进宪法分类器实现了40×成本节省、0.05%拒绝率，高效抵御解锁攻击。


<details>
  <summary>Details</summary>
Motivation: 为了解决上一代系统在单一输出检查时的脆弱性，并提升对持续解锁攻击的防护性能与生产可行性。

Method: 通过全上下文交流分类、轻量级与高成本分类器的两级级联、线性探测器与外部分类器的集成，实现了高效、安全的对话评估流程。

Result: 在1,700小时的红队测试中，无攻击能让模型在八个目标查询上产生完整且细节相当的回答，拒绝率仅0.05%，成本相较基线降低40倍。

Conclusion: 本研究证明了改进版宪法分类器能够在保持极低拒绝率的前提下实现40倍的计算成本降低，实用且有效。

Abstract: We introduce enhanced Constitutional Classifiers that deliver production-grade jailbreak robustness with dramatically reduced computational costs and refusal rates compared to previous-generation defenses. Our system combines several key insights. First, we develop exchange classifiers that evaluate model responses in their full conversational context, which addresses vulnerabilities in last-generation systems that examine outputs in isolation. Second, we implement a two-stage classifier cascade where lightweight classifiers screen all traffic and escalate only suspicious exchanges to more expensive classifiers. Third, we train efficient linear probe classifiers and ensemble them with external classifiers to simultaneously improve robustness and reduce computational costs. Together, these techniques yield a production-grade system achieving a 40x computational cost reduction compared to our baseline exchange classifier, while maintaining a 0.05% refusal rate on production traffic. Through extensive red-teaming comprising over 1,700 hours, we demonstrate strong protection against universal jailbreaks -- no attack on this system successfully elicited responses to all eight target queries comparable in detail to an undefended model. Our work establishes Constitutional Classifiers as practical and efficient safeguards for large language models.

</details>


### [90] [DP-MGTD: Privacy-Preserving Machine-Generated Text Detection via Adaptive Differentially Private Entity Sanitization](https://arxiv.org/abs/2601.04641)
*Lionel Z. Wang,Yusheng Zhao,Jiabin Luo,Xinfeng Li,Lixu Wang,Yinan Peng,Haoyang Li,XiaoFeng Wang,Wei Dong*

Main category: cs.CR

TL;DR: 提出一种自适应差分隐私实体脱敏框架DP-MGTD，既能保护用户数据隐私，又能保持高精度的机器生成文本检测，发现差分隐私噪声可提升人类与机器文本的可区分性。


<details>
  <summary>Details</summary>
Motivation: 机器生成文本检测需要分析包含敏感用户数据的文本，然而传统匿名化会破坏语言流畅性，严格的差分隐私机制又会削弱检测所需的统计信号，两者之间存在根本冲突。

Method: 引入DP-MGTD框架，采用两步机制：先对敏感实体做噪声的频率估计，再动态调节隐私预算；对数值实体使用Laplace机制，对文本实体使用指数机制，并采用自适应差分私有实体脱敏算法。

Result: 在MGTBench-2.0数据集上实验表明，DP-MGTD实现了近乎完美的检测精度，显著优于非私有基线，同时满足严格的隐私保障。

Conclusion: 尽管使用差分隐私噪声会改变文本特征，但本研究发现，噪声反而增强了人类文本与机器生成文本在敏感实体上的可区分性，因而实现了隐私保护与作者身份检测的兼顾。

Abstract: The deployment of Machine-Generated Text (MGT) detection systems necessitates processing sensitive user data, creating a fundamental conflict between authorship verification and privacy preservation. Standard anonymization techniques often disrupt linguistic fluency, while rigorous Differential Privacy (DP) mechanisms typically degrade the statistical signals required for accurate detection. To resolve this dilemma, we propose \textbf{DP-MGTD}, a framework incorporating an Adaptive Differentially Private Entity Sanitization algorithm. Our approach utilizes a two-stage mechanism that performs noisy frequency estimation and dynamically calibrates privacy budgets, applying Laplace and Exponential mechanisms to numerical and textual entities respectively. Crucially, we identify a counter-intuitive phenomenon where the application of DP noise amplifies the distinguishability between human and machine text by exposing distinct sensitivity patterns to perturbation. Extensive experiments on the MGTBench-2.0 dataset show that our method achieves near-perfect detection accuracy, significantly outperforming non-private baselines while satisfying strict privacy guarantees.

</details>


### [91] [Unified Framework for Qualifying Security Boundary of PUFs Against Machine Learning Attacks](https://arxiv.org/abs/2601.04697)
*Hongming Fei,Zilong Hu,Prosanta Gope,Biplab Sikdar*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Physical Unclonable Functions (PUFs) serve as lightweight, hardware-intrinsic entropy sources widely deployed in IoT security applications. However, delay-based PUFs are vulnerable to Machine Learning Attacks (MLAs), undermining their assumed unclonability. There are no valid metrics for evaluating PUF MLA resistance, but empirical modelling experiments, which lack theoretical guarantees and are highly sensitive to advances in machine learning techniques. To address the fundamental gap between PUF designs and security qualifications, this work proposes a novel, formal, and unified framework for evaluating PUF security against modelling attacks by providing security lower bounds, independent of specific attack models or learning algorithms. We mathematically characterise the adversary's advantage in predicting responses to unseen challenges based solely on observed challenge-response pairs (CRPs), formulating the problem as a conditional probability estimation over the space of candidate PUFs. We present our analysis on previous "broken" PUFs, e.g., Arbiter PUFs, XOR PUFs, Feed-Forward PUFs, and for the first time compare their MLA resistance in a formal way. In addition, we evaluate the currently "secure" CT PUF, and show its security boundary. We demonstrate that the proposed approach systematically quantifies PUF resilience, captures subtle security differences, and provides actionable, theoretically grounded security guarantees for the practical deployment of PUFs.

</details>


### [92] [Quantum Secure Biometric Authentication in Decentralised Systems](https://arxiv.org/abs/2601.04852)
*Tooba Qasim,Vasilios A. Siris,Izak Oosthuizen,Muttukrishnan Rajarajan,Sujit Biswas*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Biometric authentication has become integral to digital identity systems, particularly in smart cities where it en-ables secure access to services across governance, trans-portation, and public infrastructure. Centralised archi-tectures, though widely used, pose privacy and scalabil-ity challenges due to the aggregation of sensitive biomet-ric data. Decentralised identity frameworks offer better data sovereignty and eliminate single points of failure but introduce new security concerns, particularly around mu-tual trust among distributed devices. In such environments, biometric sensors and verification agents must authenticate one another before sharing sensitive biometric data. Ex-isting authentication schemes rely on classical public key infrastructure, which is increasingly susceptible to quan-tum attacks. This work addresses this gap by propos-ing a quantum-secure communication protocol for decen-tralised biometric systems, built upon an enhanced Quan-tum Key Distribution (QKD) system. The protocol incorpo-rates quantum-resilient authentication at both the classical and quantum layers of QKD: post-quantum cryptography (PQC) is used to secure the classical channel, while authen-tication qubits verify the integrity of the quantum channel. Once trust is established, QKD generates symmetric keys for encrypting biometric data in transit. Qiskit-based sim-ulations show a key generation rate of 15 bits/sec and 89% efficiency. This layered, quantum-resilient approach offers scalable, robust authentication for next-generation smart city infrastructures.

</details>


### [93] [CurricuLLM: Designing Personalized and Workforce-Aligned Cybersecurity Curricula Using Fine-Tuned LLMs](https://arxiv.org/abs/2601.04940)
*Arthur Nijdam,Harri Kähkönen,Valtteri Niemi,Paul Stankovski Wagner,Sara Ramezanian*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The cybersecurity landscape is constantly evolving, driven by increased digitalization and new cybersecurity threats. Cybersecurity programs often fail to equip graduates with skills demanded by the workforce, particularly concerning recent developments in cybersecurity, as curriculum design is costly and labor-intensive. To address this misalignment, we present a novel Large Language Model (LLM)-based framework for automated design and analysis of cybersecurity curricula, called CurricuLLM. Our approach provides three key contributions: (1) automation of personalized curriculum design, (2) a data-driven pipeline aligned with industry demands, and (3) a comprehensive methodology for leveraging fine-tuned LLMs in curriculum development.
  CurricuLLM utilizes a two-tier approach consisting of PreprocessLM, which standardizes input data, and ClassifyLM, which assigns course content to nine Knowledge Areas in cybersecurity. We systematically evalu- ated multiple Natural Language Processing (NLP) architectures and fine-tuning strategies, ultimately selecting the Bidirectional Encoder Representations from Transformers (BERT) model as ClassifyLM, fine-tuned on founda- tional cybersecurity concepts and workforce competencies.
  We are the first to validate our method with human experts who analyzed real-world cybersecurity curricula and frameworks, motivating that CurricuLLM is an efficient solution to replace labor-intensive curriculum analysis. Moreover, once course content has been classified, it can be integrated with established cybersecurity role-based weights, enabling alignment of the educational program with specific job roles, workforce categories, or general market needs. This lays the foundation for personalized, workforce-aligned cybersecurity curricula that prepare students for the evolving demands in cybersecurity.

</details>


### [94] [Knowledge-to-Data: LLM-Driven Synthesis of Structured Network Traffic for Testbed-Free IDS Evaluation](https://arxiv.org/abs/2601.05022)
*Konstantinos E. Kampourakis,Vyron Kampourakis,Efstratios Chatzoglou,Georgios Kambourakis,Stefanos Gritzalis*

Main category: cs.CR

TL;DR: By feeding protocol docs, attack scenarios, and statistical rules into large language models, researchers can generate realistic, labeled network traffic that rivals real data, enabling IDS training without physical testbeds or privacy risks. 


<details>
  <summary>Details</summary>
Motivation: Lack of realistic, large‑scale cybersecurity datasets due to privacy, sensitivity, and infrastructure costs hampers IDS research; need a privacy‑preserving, on‑demand data generation solution.

Method: Develop a controlled‑generation pipeline that inputs protocol specifications, defined attack narratives, and explicit statistical constraints into large language models; generate labeled traffic samples without fine‑tuning; validate outputs using global similarity, feature‑distribution tests, structural comparisons, and cross‑domain classification.

Result: Used AWID3 IEEE 802.11 benchmark; four state‑of‑the‑art LLMs produced datasets whose statistical/structural properties matched real traffic closely; gradient‑boosting classifiers achieved F1 up to 0.956 on real test samples, demonstrating the datasets’ utility.

Conclusion: LLMs constrained by protocol docs, attack semantics, and statistical rules can synthesize realistic, labeled network traffic datasets suitable for IDS training and evaluation, eliminating the need for costly, privacy‑sensitive real traffic collection.

Abstract: Realistic, large-scale, and well-labeled cybersecurity datasets are essential for training and evaluating Intrusion Detection Systems (IDS). However, they remain difficult to obtain due to privacy constraints, data sensitivity, and the cost of building controlled collection environments such as testbeds and cyber ranges. This paper investigates whether Large Language Models (LLMs) can operate as controlled knowledge-to-data engines for generating structured synthetic network traffic datasets suitable for IDS research. We propose a methodology that combines protocol documentation, attack semantics, and explicit statistical rules to condition LLMs without fine-tuning or access to raw samples. Using the AWID3 IEEE~802.11 benchmark as a demanding case study, we generate labeled datasets with four state-of-the-art LLMs and assess fidelity through a multi-level validation framework including global similarity metrics, per-feature distribution testing, structural comparison, and cross-domain classification. Results show that, under explicit constraints, LLM-generated datasets can closely approximate the statistical and structural characteristics of real network traffic, enabling gradient-boosting classifiers to achieve F1-scores up to 0.956 when evaluated on real samples. Overall, the findings suggest that constrained LLM-driven generation can facilitate on-demand IDS experimentation, providing a testbed-free, privacy-preserving alternative that overcomes the traditional bottlenecks of physical traffic collection and manual labeling.

</details>


### [95] [Supporting Secured Integration of Microarchitectural Defenses](https://arxiv.org/abs/2601.05057)
*Kartik Ramkrishnan,Stephen McCamant,Antonia Zhai,Pen-Chung Yew*

Main category: cs.CR

TL;DR: 该论文提出一种两步自动化方法：先用Maestro框架构建合成模型并进行模型检查，再在GEM5上实现并评估防御组合，成功检测并修复了多项隐蔽通道攻击。


<details>
  <summary>Details</summary>
Motivation: 众多微架构级攻击与防御方案存在互相破坏的安全隐患，缺乏统一评估机制，导致防御集成后潜在漏洞。

Method: 首先使用边界模型检查设计合成模型，随后在GEM5模拟器上实现并验证攻防效果，配合Maestro事件建模支持快速评估。

Result: 发现8个MDAV样本；Maestro性能提升超100倍；使用方法的修复实现对Covert Channel攻击的完整防御。

Conclusion: 提出一种两步方法来检测并避免微架构防御假设违规（MDAV），并通过Maestro框架实现有效的集成与攻击评估。

Abstract: There has been a plethora of microarchitectural-level attacks leading to many proposed countermeasures. This has created an unexpected and unaddressed security issue where naive integration of those defenses can potentially lead to security vulnerabilities. This occurs when one defense changes an aspect of a microarchitecture that is crucial for the security of another defense. We refer to this problem as a microarchitectural defense assumption violation} (MDAV).
  We propose a two-step methodology to screen for potential MDAVs in the early-stage of integration. The first step is to design and integrate a composed model, guided by bounded model checking of security properties. The second step is to implement the model concretely on a simulator and to evaluate with simulated attacks. As a contribution supporting the first step, we propose an event-based modeling framework, called Maestro, for testing and evaluating microarchitectural models with integrated defenses. In our evaluation, Maestro reveals MDAVs (8), supports compact expression (~15x Alloy LoC ratio), enables semantic composability and eliminates performance degradations (>100x).
  As a contribution supporting the second step, we use an event-based simulator (GEM5) for investigating integrated microarchitectural defenses. We show that a covert channel attack is possible on a naively integrated implementation of some state-of-the-art defenses, and a repaired implementation using our integration methodology is resilient to the attack.

</details>


### [96] [$PC^2$: Politically Controversial Content Generation via Jailbreaking Attacks on GPT-based Text-to-Image Models](https://arxiv.org/abs/2601.05150)
*Wonwoo Choi,Minjae Seo,Minkyoo Song,Hwanjo Heo,Seungwon Shin,Myoungsung You*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid evolution of text-to-image (T2I) models has enabled high-fidelity visual synthesis on a global scale. However, these advancements have introduced significant security risks, particularly regarding the generation of harmful content. Politically harmful content, such as fabricated depictions of public figures, poses severe threats when weaponized for fake news or propaganda. Despite its criticality, the robustness of current T2I safety filters against such politically motivated adversarial prompting remains underexplored. In response, we propose $PC^2$, the first black-box political jailbreaking framework for T2I models. It exploits a novel vulnerability where safety filters evaluate political sensitivity based on linguistic context. $PC^2$ operates through: (1) Identity-Preserving Descriptive Mapping to obfuscate sensitive keywords into neutral descriptions, and (2) Geopolitically Distal Translation to map these descriptions into fragmented, low-sensitivity languages. This strategy prevents filters from constructing toxic relationships between political entities within prompts, effectively bypassing detection. We construct a benchmark of 240 politically sensitive prompts involving 36 public figures. Evaluation on commercial T2I models, specifically GPT-series, shows that while all original prompts are blocked, $PC^2$ achieves attack success rates of up to 86%.

</details>


### [97] [The Adverse Effects of Omitting Records in Differential Privacy: How Sampling and Suppression Degrade the Privacy--Utility Tradeoff (Long Version)](https://arxiv.org/abs/2601.05180)
*Àlex Miranda-Pascual,Javier Parra-Arnau,Thorsten Strufe*

Main category: cs.CR

TL;DR: 研究了采样和抑制对差分隐私机制的影响，发现它们并不能提升效用，甚至会降低；均匀采样表现相对最好。


<details>
  <summary>Details</summary>
Motivation: 通过评估采样作为预处理在LP中请投。

Method: 对经典DP机制（Laplace、Gaussian、exponential、report noisy max）进行理论与实验分析，并通过一般化抑制方法推导unbounded approximate DP的隐私界限。

Result: 证实采样和抑制均未改善隐私-效用平衡，均匀采样的表现最优但仍降低效用。

Conclusion: 采样并不能提升差分隐私机制的效用，它以更高的隐私保障下导致实用性下降；在不同抽样策略中，均匀采样表现最优，但仍不改善隐私效用权衡。

Abstract: Sampling is renowned for its privacy amplification in differential privacy (DP), and is often assumed to improve the utility of a DP mechanism by allowing a noise reduction. In this paper, we further show that this last assumption is flawed: When measuring utility at equal privacy levels, sampling as preprocessing consistently yields penalties due to utility loss from omitting records over all canonical DP mechanisms -- Laplace, Gaussian, exponential, and report noisy max -- , as well as recent applications of sampling, such as clustering.
  Extending this analysis, we investigate suppression as a generalized method of choosing, or omitting, records. Developing a theoretical analysis of this technique, we derive privacy bounds for arbitrary suppression strategies under unbounded approximate DP. We find that our tested suppression strategy also fails to improve the privacy--utility tradeoff. Surprisingly, uniform sampling emerges as one of the best suppression methods -- despite its still degrading effect. Our results call into question common preprocessing assumptions in DP practice.

</details>
