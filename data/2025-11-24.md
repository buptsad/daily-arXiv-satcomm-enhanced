<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 7]
- [cs.CR](#cs.CR) [Total: 8]
- [eess.SY](#eess.SY) [Total: 11]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.LG](#cs.LG) [Total: 44]
- [cs.IT](#cs.IT) [Total: 5]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Line-of-Sight Probability in Macrocells: Framework, Statistical Models, and Parametrization from Massive Real World Datasets in the USA](https://arxiv.org/abs/2511.16827)
*Bassel Abou Ali Modad,Xin Yu,Yao-Yi Chiang,Andreas F. Molisch*

Main category: eess.SP

TL;DR: A nationwide, geospatial-data-driven LOS probability model for US macrocell deployments, using 13k locations, with per-cell random-parameterization; outperforms 3GPP and average models in predicting cell-edge interference.


<details>
  <summary>Details</summary>
Motivation: Accurate LOS probability is essential for realistic wireless channel descriptions and coverage planning. Existing models rely on limited datasets and may not generalize to nationwide macrocell deployments. A nationwide, high-accuracy LOS model can improve pathloss, fading, and interference predictions.

Method: Develop a framework to derive LOS models from geospatial data and apply it to US macrocell datasets (13k locations). Propose a fully parameterized LOS model with per-cell parameters treated as random variables. Validate via simulations against inter-cell interference and compare to average-based and 3GPP models.

Result: A new, fully parameterized LOS model for US macrocell deployments, with per-cell random-parameter LOS probabilities, showing better prediction of inter-cell interference at the cell-edge than average-based models and outperforming the 3GPP model.

Conclusion: LOS probability modeling should be performed on a per-cell basis with per-cell parameters treated as random variables to achieve higher fidelity in macrocell deployments. The proposed approach improves interference predictions and provides a richer description of LOS in diverse environments.

Abstract: Accurate modeling of line-of-sight (LOS) probability is crucial for wireless channel description and coverage planning. The presence of a LOS impacts other channel characteristics such as pathloss, fading depth, delay- and angular spread, etc.. Existing models, although useful, are based on very limited datasets. In this paper, we establish a framework to produce high accuracy LOS models from geospatial data in different environments, and apply it to create a LOS model for macrocells, using datasets of the United States (US) on a nationalscale, using more than 13, 000 locations of real-world macrocells. Based on this we create a new, fully parameterized model that better describes macrocell deployments in the US than the 3GPP model. We furthermore demonstrate that for improved accuracy the LOS probability should be modeled on a per cell basis, and the model parameters treated as random variables; we provide a full description and parameterization of this novel approach and by simulations show that it better predicts the inter-cell interference at the cell-edge than an average-based model.

</details>


### [2] [State-of-charge estimation of lithium-ion batteries using a tree seed and genetic algorithm-optimized generalized mixture minimum error entropy-based square root cubature Kalman filter](https://arxiv.org/abs/2511.16888)
*Haiquan Zhao,Xiong Yin,Jinhui Hu*

Main category: eess.SP

TL;DR: 提出了GMMEE-SRCKF，结合TSGA优化核参数，在SOC估计中对非高斯噪声更鲁棒，RMSE小于0.5%。


<details>
  <summary>Details</summary>
Motivation: MEE-CKF在复杂噪声环境下鲁棒性受限；需要更灵活的核及更稳定的数值方法；引入平方根CKF以提升数值稳定性并避免协方差退化，同时采用双核混合MEE准则以更好适应非高斯噪声；通过TSGA自动优化核参数以降低人工调参。

Method: 设计GMMEE-SRCKF，使用平方根形式以避免协方差退化；引入两种灵活核组成的混合MEE准则以自适应非高斯噪声；通过混合树种子与遗传算法（TSGA）自动优化核参数；在实验中与现有鲁棒滤波器进行对比。

Result: 实验结果显示所提方法优于现有鲁棒滤波器，RMSE达到小于0.5%。

Conclusion: GMMEE-SRCKF结合TSGA实现核参数自适应优化，提升在非高斯噪声环境下的SOC估计鲁棒性与精度，适用于电池管理等领域。

Abstract: The cubature Kalman filter based on minimum error entropy (MEE-CKF) offers accurate and robust performance in state of charge (SOC) estimation. However, due to the inflexibility of the minimum error entropy (MEE), this algorithm demonstrates limited robustness when confronted with more complex noise environments. To address these limitations, this paper proposes a generalized mixture minimum error entropy-based (GMMEE) square-root cubature Kalman filter (GMMEE-SRCKF). The square-root algorithm ensures improved numerical stability and avoids covariance degeneration, while the GMMEE criterion with two flexible kernels adapts effectively to non-Gaussian noise. Moreover, a hybrid tree seed and genetic algorithm (TSGA) is introduced to optimize the kernel parameters automatically. Experimental results confirm that the TSGA-optimized GMMEE-SRCKF outperforms existing robust filters, achieving the root mean square error (RMSE) of less than 0.5%.

</details>


### [3] [Generative MIMO Beam Map Construction for Location Recovery and Beam Tracking](https://arxiv.org/abs/2511.17007)
*Wangqian Chen,Junting Chen,Shuguang Cui*

Main category: eess.SP

TL;DR: 提出一种基于扩散生成模型的无线信道映射生成框架，通过从稀疏CSI序列中推断位置标签，学习低维无线地图嵌入并重构高维CSI，在NLOS场景下提高定位和容量。


<details>
  <summary>Details</summary>
Motivation: 现有以大量带标签的CSI与位置信息为前提的数据驱动方法成本高且可获得性差，需要无需显式定位标签的无线地图建模与高保真CSI重构方法。

Method: 提出一个双尺度特征提取方案来缓解稀疏CSI的不确定性，联合利用角度空间及相邻样本的相关性；设计混合的RNN-CNN编码器以学习移动模式，采用截断策略与多尺度卷积提升鲁棒性；引入可学习的无线地图作为先验以编码位置信息；利用在位置特征条件下的扩散生成解码器重构完整CSI。

Result: 数值实验显示，与传统Kalman滤波方法相比，在定位精度方面提升超过30%，在NLOS场景中实现约20%的容量增益。

Conclusion: 该生成框架有效将位置特征融入无线地图嵌入和CSI重构，减少对手工标注的依赖，提升在复杂环境中的定位与通信容量，具有实际应用潜力和扩展性。

Abstract: Machine learning (ML) has greatly advanced data-driven channel modeling and resource optimization in wireless communication systems. However, most existing ML-based methods rely on large, accurately labeled datasets with location information, which are often difficult and costly to obtain. This paper proposes a generative framework to recover location labels directly from sequences of sparse channel state information (CSI) measurements, without explicit location labels for radio map construction. Instead of directly storing raw CSI, we learn a compact low-dimensional radio map embedding and leverage a generative model to reconstruct the high-dimensional CSI. Specifically, to address the uncertainty of sparse CSI, a dual-scale feature extraction scheme is designed to enhance feature representation by jointly exploiting correlations from angular space and across neighboring samples. We develop a hybrid recurrent-convolutional encoder to learn mobility patterns, which combines a truncation strategy and multi-scale convolutions in the recurrent neural network (RNN) to ensure feature robustness against short-term fluctuations. Unlike conventional Gaussian priors in latent space, we embed a learnable radio map to capture the location information by encoding high-level positional features from CSI measurements. Finally, a diffusion-based generative decoder reconstructs the full CSI with high fidelity by conditioning on the positional features in the radio map. Numerical experiments demonstrate that the proposed model can improve localization accuracy by over 30% and achieve a 20% capacity gain in non-line-of-sight (NLOS) scenarios compared with model-based Kalman filter approaches.

</details>


### [4] [Movable Intelligent Surface-Enabled Wireless Communications: Static Phase Shifts with Mechanical Reconfigurability](https://arxiv.org/abs/2511.17058)
*Ziyuan Zheng,Qingqing Wu,Wen Chen,Weiren Zhu,Ying Gao*

Main category: eess.SP

TL;DR: 提出一种可移动智能表面（MIS）以在静态主层上滑动次级预相位层实现可切换波束，介于静态高性价比表面和动态RIS之间。


<details>
  <summary>Details</summary>
Motivation: 解决现有 RIS 的两端成本/复杂性极端：动态 RIS 尽管可控性强但需要密集布线、持续供电与信令开销；静态面板虽然成本低但仅有单一波束模式，难以适应部分准静态场景（如工业物联网、智慧农业）。

Method: 提出 MIS 架构，通过在主静态层上滑动一个小型预相位次级层，使波束模式通过几何位置的二元选择矩阵切换；建立 MIS 信号模型，将静态相位元与动态几何耦合建模为二元选择矩阵。随后提出混合整数非凸优化问题，联合设计静态相位移和 MS2 的重叠位置选择（即波束模式调度），并给出基于罚函数法、块坐标下降和黎曼流形优化的高效算法。

Result: 仿真结果显示 MIS 能显著缩小单层静态表面与动态 RIS 之间的性能差距，提供一种适用于准静态场景的高性价比、灵活的解决方案。

Conclusion: MIS 为准静态无线应用提供折中方案，介于成本低、无控制线的静态表面与成本高、可控性强的动态 RIS 之间，且通过优化设计与算法实现实现显著性能提升。

Abstract: Intelligent surfaces that reshape electromagnetic waves are regarded as disruptive technologies for wireless networks. However, existing designs sit at two costly extremes: dynamic reconfigurable intelligent surfaces (RISs) offer fine beam control but require dense cabling, continuous power consumption, and substantial signaling overhead, whereas low-cost static surfaces require no control lines or electronics but are limited to a single beam pattern. This disparity leaves a practical gap for quasi-static environments, such as industrial Internet-of-things and smart agriculture scenarios, where channels are stable with user demands changing only occasionally or periodically, and neither extreme is sufficiently economical or flexible. To bridge this gap, we propose a novel movable intelligent surface (MIS) architecture, whose beam patterns are switched not by electronic phase tuning but by mechanically sliding a small, pre-phased secondary metasurface layer across a larger, likewise static primary layer. We develop an MIS signal model that characterizes the interaction between static phase elements with dynamic geometry via binary selection matrices. Based on this model, we formulate a new type of optimization problems that jointly design static phase shifts and the overlapping position selection of MS2 (equal to beam pattern scheduling). Efficient algorithms based on the penalty method, block coordinate descent, and Riemannian manifold optimization are proposed to tackle these mixed-integer non-convex problems. Simulation results demonstrate that the proposed MIS architecture substantially narrows the performance gap between single-layer static surfaces and dynamic RISs, providing a practical and flexible solution for quasi-static wireless applications.

</details>


### [5] [Unleashing Sensor-Aided Environment Awareness for Beam Management in Beyond-5G Networks: An OpenAirInterface Experimental Platform](https://arxiv.org/abs/2511.17122)
*Aron Schott,Berk Acikgöz,Omar Massoud,Marina Petrova,Ljiljana Simić*

Main category: eess.SP

TL;DR: 本文提出一个基于 SDR 的、以 OpenAirInterface 为核心的全栈实验平台，集成低成本天线阵列、波束扫描和模块化传感器框架，用于在真实/实时场景中进行波束管理实验，并为基于 ML 的环境感知波束管理数据集构建提供平台。


<details>
  <summary>Details</summary>
Motivation: 毫米波/FR2 通道对场景的时空变化强烈，且需要结合环境感知的非射频传感器输入来显著提升波束管理决策。现有文献缺乏开放的平台来收集数据并在真实世界场景中评估新型波束管理方法。

Method: 将 OpenAirInterface 与低成本天线阵列、波束扫掠能力以及模块化传感器接口集成到一个全栈的 SDR 平台，提供实时数据采集、传感器数据融合接口，并支持端到端的波束管理实验和数据集构建。

Result: 提出并实现了首次将此类组件整合到一个全栈实验平台的方案，能够在真实、实时场景中开展波束管理实验，并方便地收集用于 ML 的环境感知数据集。

Conclusion: 该平台为开发与评估基于环境感知的 ML 波束管理协议提供了现实世界的实验环境与数据资源，促进可重复性实验和数据驱动方法的发展。

Abstract: Large antenna arrays and beamforming techniques are key components for exploiting the spectrum-rich FR2 bands in next-generation mobile communication networks. Given the site-specific spatio-temporal variations of the mm-wave channel, non-RF sensor inputs and environment awareness can be leveraged to greatly enhance beam management decisions, e.g. via machine learning (ML) techniques. However, the current literature lacks open platforms to gather datasets for the training of such ML techniques and to evaluate novel beam management approaches in real-time, real-world scenarios and full-stack endto-end networks. In this work, we present our SDR-based experimental platform based on OpenAirInterface and are the first to integrate popular low-cost antenna array transceivers, beam sweeping capabilities, and a highly-modular sensor framework and associated interfaces into such a full-stack experimental platform. This enables beam management experimentation in real-world, real-time scenarios and facilitates gathering datasets necessary for developing ML-based beam management protocols that incorporate environment awareness via sensor modalities.

</details>


### [6] [Teager-Kaiser Energy Methods For EEG Feature Extraction In Biomedical Applications](https://arxiv.org/abs/2511.17164)
*Ioanna Chourdaki,Kleanthis Avramidis,Christos Garoufis,Athanasia Zlatintsi,Petros Maragos*

Main category: eess.SP

TL;DR: 将TKEO用于EEG能量动态建模，通过Gabor滤波和Energy Separation Algorithm(ESA)将TKEO输出分解为振幅包络和瞬时频率，构建能量描述符并与基线特征比较。结论是在运动想象和癫痫检测中优于基线，在情绪识别中与基线相当。


<details>
  <summary>Details</summary>
Motivation: EEG信号具有强非线性、非平稳性且易受噪声影响，传统能量/功率特征可能难以捕捉边缘动力。通过Teager-Kaiser能量算子(TKEO)来建模EEG的能量动态，并结合带通的Gabor滤波以聚焦窄带成分，然后用ESA分解出包络和瞬时频率，形成新的能量描述符以提升分类性能。

Method: 对EEG信号先经Gabor滤波器组以提取若干典型频带；对每个通道的带通信号应用TKEO；使用能量分离算法将TKEO输出分解为振幅包络与瞬时频率分量；基于此分解结果构造一组能量描述符；将所提描述符与传统能量、功率谱特征进行分类性能比较。

Result: 在运动想象（MI）和癫痫检测（ epilepsy）任务中，TKEO特征优于各自的基线特征；在情绪识别任务中，TKEO特征与基线性能相当。

Conclusion: 提出的TKEO-based流程为EEG信号动力学的直观表征提供了有效框架，能通过窄带能量动态描述提升某些任务的分类性能。

Abstract: Electroencephalography (EEG) signals are inherently non-linear, non-stationary, and vulnerable to noise sources, making the extraction of discriminative features a long-standing challenge. In this work, we investigate the non-linear Teager-Kaiser Energy Operator (TKEO) for modeling the underlying energy dynamics of EEG in three representative tasks: motor imagery, emotion recognition, and epilepsy detection. To accommodate the narrowband nature of the operator, we employ Gabor filterbanks to isolate canonical frequency bands, followed by the Energy Separation Algorithm to decompose the TKEO output into amplitude envelope and instantaneous frequency components. We then derive a set of energy descriptors based on this demodulation and compare their classification performance against established signal energy and power spectrum features. TKEO features outperform the respective baselines in motor imagery and epilepsy detection, whereas they perform on par in emotion recognition. Our findings suggest that the proposed TKEO-based pipeline provides an intuitive framework for extracting EEG signal dynamics.

</details>


### [7] [Incorporating Bayesian Transfer Learning into Particle Filter for Dual-Tracking System with Asymmetric Noise Intensities](https://arxiv.org/abs/2511.17440)
*Omar A. Alotaibi,Brian L. Mark,Mohammad Reza Fasihi*

Main category: eess.SP

TL;DR: 提出一种基于贝叶斯迁移学习的粒子滤波方法，用于双传感器系统中在噪声不对称条件下的非线性动力学跟踪。通过对迁移学习密度使用加权粒子和近似，提高主传感器在高噪声条件下的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 在主传感器噪声较大、源传感器噪声较小时，利用源传感器信息进行迁移学习以提升主传感器估计的准确性。贝叶斯迁移学习的密度通过粒子加权和的形式近似，旨在改善双传感系统中对非线性动力学的跟踪表现。

Method: 建立一个双传感器非线性动态系统，测量噪声强度存在不对称。采用粒子滤波实现跟踪，并用加权粒子之和来近似贝叶斯迁移学习的密度，从而提升主传感器的估计。将该方法与独立的粒子滤波、以及将迁移学习应用于无迹卡尔曼滤波（UKF）和立方卡尔曼滤波（CKF）的方法进行对比。通过增加粒子数量考察性能与计算时间的权衡，并探讨迁移学习增益与两个传感器噪声强度差的绝对值之间的近似线性关系。

Result: 实验结果表明，所提出的贝叶斯迁移学习粒子滤波在与独立粒子滤波及UKF/CKF的迁移学习对比中具有更优的跟踪性能。随着粒子数增加，面向粒子滤波的迁移学习性能提升幅度大于独立粒子滤波，但相应的计算成本也上升。迁移学习带来的性能增益与两传感器噪声强度差的绝对值呈近似线性关系。

Conclusion: 贝叶斯迁移学习在粒子滤波框架下有效融合源传感器信息，提升在高噪声主传感器场景下的跟踪性能；但需权衡粒子数与计算开销，且增益与噪声差呈线性关系。

Abstract: Using Bayesian transfer learning, we develop a particle filter approach for tracking a nonlinear dynamical model in a dual-tracking system where intensities of measurement noise for both sensors are asymmetric. The densities for Bayesian transfer learning are approximated with the sum of weighted particles to improve the tracking performance of the primary sensor, which experiences a higher noise intensity compared to the source sensor. We present simulation results that validate the effectiveness of the proposed approach compared to an isolated particle filter and transfer learning applied to the unscented Kalman filter and the cubature Kalman filter. Furthermore, increasing the number of particles shows an improvement in the performance of transfer learning applied to the particle filter with a higher rate compared to the isolated particle filter. However, increasing the number of particles raises computational time per step. Moreover, the performance gain from incorporating Bayesian transfer learning is approximately linearly proportional to the absolute difference value between the noise intensities of the sensors in the dual-tracking system.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [8] [Password Strength Analysis Through Social Network Data Exposure: A Combined Approach Relying on Data Reconstruction and Generative Models](https://arxiv.org/abs/2511.16716)
*Maurizio Atzori,Eleonora Calò,Loredana Caruccio,Stefano Cirillo,Giuseppe Polese,Giandomenico Solimando*

Main category: cs.CR

TL;DR: 提出 SODA ADVANCE 数据重构工具，用于基于多源公开数据及大语言模型提升密码强度评估，并探讨 LLM 在生成与评估密码方面的能力与风险；初步实验表明 LLM 可基于用户画像生成强密码并有效评估密码。


<details>
  <summary>Details</summary>
Motivation: 用户倾向使用易记密码，传统强度评估方法不足；需要结合公开数据和模型来改进评估与生成过程，同时关注隐私与安全风险。

Method: 提出 SODA ADVANCE 及其专门模块，利用多源公开数据（包括社交媒体）评估密码强度；系统性分析 LLM 在生成与评估密码中的能力与风险；以 100 名真实用户开展实验。

Result: LLMs 能够在基于用户画像的前提下生成强密码；并在考量用户画像数据时，对密码具备更有效的评估能力。

Conclusion: 将 LLM 与公开数据结合用于密码生成与评估具有潜力，但需关注隐私与滥用风险，未来研究应聚焦安全性与合规性。

Abstract: Although passwords remain the primary defense against unauthorized access, users often tend to use passwords that are easy to remember. This behavior significantly increases security risks, also due to the fact that traditional password strength evaluation methods are often inadequate. In this discussion paper, we present SODA ADVANCE, a data reconstruction tool also designed to enhance evaluation processes related to the password strength. In particular, SODA ADVANCE integrates a specialized module aimed at evaluating password strength by leveraging publicly available data from multiple sources, including social media platforms. Moreover, we investigate the capabilities and risks associated with emerging Large Language Models (LLMs) in evaluating and generating passwords, respectively. Experimental assessments conducted with 100 real users demonstrate that LLMs can generate strong and personalized passwords possibly defined according to user profiles. Additionally, LLMs were shown to be effective in evaluating passwords, especially when they can take into account user profile data.

</details>


### [9] [Membership Inference Attacks Beyond Overfitting](https://arxiv.org/abs/2511.16792)
*Mona Khalil,Alberto Blanco-Justicia,Najeeb Jebreel,Josep Domingo-Ferrer*

Main category: cs.CR

TL;DR: 在非过拟合模型中，MIAs 的攻击成功不仅由过拟合驱动，更来自对类内离群/噪声样本的暴露；对这类样本特征的分析揭示了攻击的根因并给出定向防御。


<details>
  <summary>Details</summary>
Motivation: 研究在非过拟合情景下，哪些训练样本最易被成员推断攻击利用，以及如何设计有针对性的防御以提升隐私保护，同时尽量减少对模型性能的影响。

Method: 通过对非过拟合模型进行系统的经验分析，评估并比较影响MIAs的样本特征（如离群性、噪声水平、难以分类性等），并测试/提出针对易受攻击样本的定向防御策略。

Result: 发现MIAs的成功不仅来自总体过拟合，而是对特定子集样本（通常是类内的离群样本）暴露程度较高；对这些样本的特征及其对模型输出的影响得到量化，并给出能够保护这部分样本的防御思路，同时在不显著损失整体准确性的前提下提升隐私保护。

Conclusion: 聚焦非过拟合情形下易受攻击的样本，有助于更全面地理解MIAs的根本原因并设计更具针对性的防御策略，同时给出公开代码以便复现实验。

Abstract: Membership inference attacks (MIAs) against machine learning (ML) models aim to determine whether a given data point was part of the model training data. These attacks may pose significant privacy risks to individuals whose sensitive data were used for training, which motivates the use of defenses such as differential privacy, often at the cost of high accuracy losses. MIAs exploit the differences in the behavior of a model when making predictions on samples it has seen during training (members) versus those it has not seen (non-members). Several studies have pointed out that model overfitting is the major factor contributing to these differences in behavior and, consequently, to the success of MIAs. However, the literature also shows that even non-overfitted ML models can leak information about a small subset of their training data. In this paper, we investigate the root causes of membership inference vulnerabilities beyond traditional overfitting concerns and suggest targeted defenses. We empirically analyze the characteristics of the training data samples vulnerable to MIAs in models that are not overfitted (and hence able to generalize). Our findings reveal that these samples are often outliers within their classes (e.g., noisy or hard to classify). We then propose potential defensive strategies to protect these vulnerable samples and enhance the privacy-preserving capabilities of ML models. Our code is available at https://github.com/najeebjebreel/mia_analysis.

</details>


### [10] [TICAL: Trusted and Integrity-protected Compilation of AppLications](https://arxiv.org/abs/2511.17070)
*Robert Krahn,Nikson Kanti Paul,Franz Gregor,Do Le Quoc,Andrey Brito,André Martin,Christof Fetzer*

Main category: cs.CR

TL;DR: 提出了 Tical，一个在构建管线中提供机密性与完整性保护的可信编译框架。通过把 TEEs 与文件系统屏蔽和不可变审计日志/版本历史结合，确保编译链仅访问可信文件及中间产物，并在 CI/CD 流水线中实现可接受的开销。


<details>
  <summary>Details</summary>
Motivation: 在云环境中保护应用在运行时的安全性是一方面，但构建阶段的完整性与保密性同样重要，防止编译时期的恶意注入或篡改危及整个应用与系统。

Method: 在编译链中引入 Tical，利用可信执行环境（TEEs）提供运行时保护，同时对文件系统进行屏蔽、引入不可变的审计日志和版本历史，确保编译器链只能访问可信文件和中间产物（如经过信任过程生成的目标文件）。

Result: 通过微基准和宏基准评估，Tical 能保护整个 CI/CD 流水线的机密性和完整性，且性能开销处于可接受范围。

Conclusion: Tical 为构建管线提供一个可审计且可信的编译环境，提升在不可信环境中软件供应链的安全性与可控性。

Abstract: During the past few years, we have witnessed various efforts to provide confidentiality and integrity for applications running in untrusted environments such as public clouds. In most of these approaches, hardware extensions such as Intel SGX, TDX, AMD SEV, etc., are leveraged to provide encryption and integrity protection on process or VM level. Although all of these approaches increase the trust in the application at runtime, an often overlooked aspect is the integrity and confidentiality protection at build time, which is equally important as maliciously injected code during compilation can compromise the entire application and system.In this paper, we present Tical, a practical framework for trusted compilation that provides integrity protection and confidentiality in build pipelines from source code to the final executable. Our approach harnesses TEEs as runtime protection but enriches TEEs with file system shielding and an immutable audit log with version history to provide accountability. This way, we can ensure that the compiler chain can only access trusted files and intermediate output, such as object files produced by trusted processes. Our evaluation using micro- and macro-benchmarks shows that Tical can protect the confidentiality and integrity of whole CI/CD pipelines with an acceptable performance overhead.

</details>


### [11] [AutoGraphAD: A novel approach using Variational Graph Autoencoders for anomalous network flow detection](https://arxiv.org/abs/2511.17113)
*Georgios Anyfantis,Pere Barlet-Ros*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Network Intrusion Detection Systems (NIDS) are essential tools for detecting network attacks and intrusions. While extensive research has explored the use of supervised Machine Learning for attack detection and characterisation, these methods require accurately labelled datasets, which are very costly to obtain. Moreover, existing public datasets have limited and/or outdated attacks, and many of them suffer from mislabelled data. To reduce the reliance on labelled data, we propose AutoGraphAD, a novel unsupervised anomaly detection approach based on a Heterogeneous Variational Graph Autoencoder. AutoGraphAD operates on heterogeneous graphs, made from connection and IP nodes that capture network activity within a time window. The model is trained using unsupervised and contrastive learning, without relying on any labelled data. The reconstruction, structural loss, and KL divergence are then weighted and combined in an anomaly score that is then used for anomaly detection. Overall, AutoGraphAD yields the same, and in some cases better, results than previous unsupervised approaches, such as Anomal-E, but without requiring costly downstream anomaly detectors. As a result, AutoGraphAD achieves around 1.18 orders of magnitude faster training and 1.03 orders of magnitude faster inference, which represents a significant advantage for operational deployment.

</details>


### [12] [Constant-Size Cryptographic Evidence Structures for Regulated AI Workflows](https://arxiv.org/abs/2511.17118)
*Leo Kao*

Main category: cs.CR

TL;DR: 提出并实现一个常量大小证据结构，用于在受监管环境中对AI工作流进行可验证的审计，确保每事件具有固定容量、可哈希链/ Merkle 组合、并具备安全性与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在合规和审计要求日益严格的AI应用场景，需要不可抵赖的、成本可控的证据，能够绑定到具体工作流事件和配置信息，同时兼容哈希链和Merkle等审计技术以实现可追溯、不可抵撞的证据链。

Method: 提出固定大小的证据项（恒定元组结构），使用哈希与签名的组合来绑定事件，构造可组合的证据结构；将其与哈希链日志、Merkle锚定及可选的可信执行环境集成；给出形式化模型、证据语法与算法，以及安全目标（审计完整性、不可否认等）和复杂度分析。

Result: 给出一个通用哈希与签名的实例化，以及对常量大小证据的生成与验证复杂度的分析；实现了原型库，并在商品硬件上进行了微基准测试，表明每事件开销低且可预测。

Conclusion: 该抽象和实现对临床试验管理、医药合规和医疗AI治理等领域具有潜在影响，能够在受监管环境中提供高效、可验证的审计证据，同时为今后将此方法应用于实际系统提供设计与性能基线。

Abstract: This paper introduces constant-size cryptographic evidence structures, a general abstraction for representing verifiable audit evidence for AI workflows in regulated environments. Each evidence item is a fixed-size tuple of cryptographic fields, designed to (i) provide strong binding to workflow events and configurations, (ii) support constant-size storage and uniform verification cost per event, and (iii) compose cleanly with hash-chain and Merkle-based audit constructions. We formalize a simple model of regulated AI workflows, define syntax and algorithms for evidence structures, and articulate security goals such as audit integrity and non-equivocation. We present a generic hash-and-sign construction that instantiates this abstraction using a collision-resistant hash function and a standard digital signature scheme. We then show how to integrate the construction with hash-chained logs, Merkle-tree anchoring, and optionally trusted execution environments, and we analyze the asymptotic complexity of evidence generation and verification. Finally, we implement a prototype library and report microbenchmark results on commodity hardware, demonstrating that the per-event overhead of constant-size evidence is small and predictable. The design is informed by industrial experience with regulated AI systems at Codebat Technologies Inc., while the paper focuses on the abstraction, algorithms, and their security and performance characteristics, with implications for clinical trial management, pharmaceutical compliance, and medical AI governance.

</details>


### [13] [Steering in the Shadows: Causal Amplification for Activation Space Attacks in Large Language Models](https://arxiv.org/abs/2511.17194)
*Zhiyuan Xu,Stanislav Abaimov,Joseph Gardiner,Sana Belguith*

Main category: cs.CR

TL;DR: 论文揭示解码器式大模型的中间激活层存在可控的因果放大效应（CAE），通过有限的激活扰动即可在自回归路径中放大影响，进而实现行为操控的攻击面（SSS）。


<details>
  <summary>Details</summary>
Motivation: 现有对LLM安全性的分析多聚焦于数据、提示和拒绝策略等前向实现细节之外的内容；然而中间激活、残差通道等内部信号的可操控性尚未充分研究。本工作提出对解码器端大模型的中间激活层作为潜在攻击面，探究其对行为控制的影响，以提升对开源/白盒部署场景的安全认知。

Method: 在残差流中识别一个高增益区（CAEs）以及小的、对齐的扰动在自回归途中被放大的机制；提出敏感性尺度化引导（SSS）激活级别攻击，结合BOS锚定与基于敏感性的强化，按预算聚焦最脆弱的层和标记。对多种开源权重模型及四个行为轴进行实验，评估扰动对行为输出的影响。

Result: 在多模型与四个行为轴上，SSS能引发 evil、hallucination、sycophancy、sentiment 等行为的显著偏移，同时保持高连贯性和通用能力，证明激活水平的导向对安全性具有实质性影响。

Conclusion: 激活引导成为白盒与供应链部署中的一个具体安全隐患，需在前向实现、模型防护与检测机制上进行针对性改进与防御研究。

Abstract: Modern large language models (LLMs) are typically secured by auditing data, prompts, and refusal policies, while treating the forward pass as an implementation detail. We show that intermediate activations in decoder-only LLMs form a vulnerable attack surface for behavioral control. Building on recent findings on attention sinks and compression valleys, we identify a high-gain region in the residual stream where small, well-aligned perturbations are causally amplified along the autoregressive trajectory--a Causal Amplification Effect (CAE). We exploit this as an attack surface via Sensitivity-Scaled Steering (SSS), a progressive activation-level attack that combines beginning-of-sequence (BOS) anchoring with sensitivity-based reinforcement to focus a limited perturbation budget on the most vulnerable layers and tokens. We show that across multiple open-weight models and four behavioral axes, SSS induces large shifts in evil, hallucination, sycophancy, and sentiment while preserving high coherence and general capabilities, turning activation steering into a concrete security concern for white-box and supply-chain LLM deployments.

</details>


### [14] [Persistent BitTorrent Trackers](https://arxiv.org/abs/2511.17260)
*Francois Xavier Wicht,Zhengwei Tong,Shunfan Zhou,Hang Yin,Aviv Yaish*

Main category: cs.CR

TL;DR: 通过区块链+TEE与可验证的接收签名实现跨追踪器的可移植信誉和去中心化发现，解决私有BitTorrent追踪器的信誉迁移、单点失败和自报不可验证的问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有私有 BitTorrent 追踪器的三大痛点：跨追踪器信誉迁移、单点故障、以及自报信誉的不可验证性。

Method: 在智能合约中存储信誉；接收方为传输的Piece签名收据，追踪器在TEE中聚合并在上链更新信誉；在追踪器不可用时使用经过认证的DHT进行发现，信誉作为PKI实现访问控制；通过工厂部署合约实现单跳迁移；对安全性进行形式化要求和证明；在Intel TDX上原型评估。

Result: 提出的系统实现可跨追踪器迁移、在失效情况下可继续发现，传输证明开销小于6%，签名聚合提升验证速度约2.5倍。

Conclusion: 通过形式化证明和原型评估，证明在分布式追踪生态中实现可移植且可验证的信誉是可行的，提升鲁棒性与可用性。

Abstract: Private BitTorrent trackers enforce upload-to-download ratios to prevent free-riding, but suffer from three critical weaknesses: reputation cannot move between trackers, centralized servers create single points of failure, and upload statistics are self-reported and unverifiable. When a tracker shuts down (whether by operator choice, technical failure, or legal action) users lose their contribution history and cannot prove their standing to new communities. We address these problems by storing reputation in smart contracts and replacing self-reports with cryptographic attestations. Receiving peers sign receipts for transferred pieces, which the tracker aggregates and verifies before updating on-chain reputation. Trackers run in Trusted Execution Environments (TEEs) to guarantee correct aggregation and prevent manipulation of state. If a tracker is unavailable, peers use an authenticated Distributed Hash Table (DHT) for discovery: the on-chain reputation acts as a Public Key Infrastructure (PKI), so peers can verify each other and maintain access control without the tracker. This design persists reputation across tracker failures and makes it portable to new instances through single-hop migration in factory-deployed contracts. We formalize the security requirements, prove correctness under standard cryptographic assumptions, and evaluate a prototype on Intel TDX. Measurements show that transfer receipts adds less than 6\% overhead with typical piece sizes, and signature aggregation speeds up verification by $2.5\times$.

</details>


### [15] [A Patient-Centric Blockchain Framework for Secure Electronic Health Record Management: Decoupling Data Storage from Access Control](https://arxiv.org/abs/2511.17464)
*Tanzim Hossain Romel,Kawshik Kumar Paul,Tanberul Islam Ruhan,Maisha Rahman Mim,Abu Sayed Md. Latiful Hoque*

Main category: cs.CR

TL;DR: 提出一种以患者为中心的电子健康记录（EHR）共享架构，将内容存储与授权和审计分离。将加密的FHIR资源链下存储；在公链上仅记录密码学承诺和患者签名、时间绑定的权限（使用EIP-712）。通过公钥包裹实现密钥分发，使存储提供者在诚实但好奇的前提下也能保护保密性。形式化安全目标并提供Solidity参考实现，部署为单患者合约。L1下授权成本约78,000 gas，1MB记录端到端访问延迟0.7–1.4s（S3与IPFS的均值），主要由存储检索决定。Layer-2可将gas降10–13倍，但数据可用性费用主导实际成本。讨论元数据隐私、密钥注册表需求及合规性（HIPAA/GDPR），展示在不牺牲必要安全属性的前提下，将患者控制权恢复到现实路径。


<details>
  <summary>Details</summary>
Motivation: 在保护隐私与提升对患者对EHR的控制之间寻找平衡，解决跨机构共享中对可信存储、授权可追溯性和合规性的挑战。

Method: 将存储与授权/审计分离：将经加密的FHIR资源离线存储（如IPFS），在公链上记录密码学承诺和患者签署、时间绑定的权限（使用EIP-712）；通过公钥封装实现密钥分发，确保存储提供者在诚实但好奇的环境下不暴露数据；提供Solidity参考实现，部署为单患者合约；对成本与时延进行基准评估；探讨Layer-2部署对成本的影响及合规与隐私问题。

Result: 在链上对权限授予的成本较低且延迟受存储检索主导，L2显著降低Gas成本；提出了可扩展的患者主导EHR共享方案，并给出实现路径与合规性考量。

Conclusion: 该研究展示了在保障机密性、完整性、可追溯的授权和审计能力的同时，将患者对个人健康数据的控制权切实回归患者手中的可行路线，并讨论了元数据隐私、密钥注册和法规合规性等要点。

Abstract: We present a patient-centric architecture for electronic health record (EHR) sharing that separates content storage from authorization and audit. Encrypted FHIR resources are stored off-chain; a public blockchain records only cryptographic commitments and patient-signed, time-bounded permissions using EIP-712. Keys are distributed via public-key wrapping, enabling storage providers to remain honest-but-curious without risking confidentiality. We formalize security goals (confidentiality, integrity, cryptographically attributable authorization, and auditability of authorization events) and provide a Solidity reference implementation deployed as single-patient contracts. On-chain costs for permission grants average 78,000 gas (L1), and end-to-end access latency for 1 MB records is 0.7--1.4s (mean values for S3 and IPFS respectively), dominated by storage retrieval. Layer-2 deployment reduces gas usage by 10--13x, though data availability charges dominate actual costs. We discuss metadata privacy, key registry requirements, and regulatory considerations (HIPAA/GDPR), demonstrating a practical route to restoring patient control while preserving security properties required for sensitive clinical data.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [16] [Design, Fabrication, and Measurement of a Hemispherical Multi-Layer Band-Pass Frequency Selective Surface](https://arxiv.org/abs/2511.16777)
*Ali Tehranian,Jordan Budhu,Casey Perkowski,Lance Sookdeo,Kenneth H. Church,Garrett Harris,Carl Pfeiffer*

Main category: eess.SY

TL;DR: 提出一种圆顶形多层宽带FSS的设计-制造方法，结合 Goldberg 离散化与单位单元缩放，在4.5 mm厚ABS半球壳内集成，7–13 GHz通带，约1.7 dB损耗，阻带15–20 dB，且引入边缘衍射抑制的后处理。


<details>
  <summary>Details</summary>
Motivation: 解决弯曲几何下的圆顶形频率选择表面的实现难题，推动 conformal FSS 在可植成形的球面外壳中的应用，通过增材制造实现多层介质-金属结构的集成。

Method: 采用 Goldberg 离散化与单位单元缩放来匹配曲面轮廓；通过逐层打印介质与金属图案，最终在4.5 mm（λ0/6，10 GHz）厚的 ABS 半球形机壳中集成三层银墨导电表面；并提出后处理以抑制边缘衍射在测量中的影响。

Result: 实现7–13 GHz宽带通带，通带损耗约1.7 dB，阻带衰减在15–20 dB范围；半球FSS的直径约5λ0、高度约3λ0，尺寸与性能与制造工艺相协调，提供了可制造的圆顶形 FSS 方案。

Conclusion: 设计-制造与后处理等方面的创新为未来的可 conformal FSS 提供可行路径，尤其在曲面机壳内的集成与成形方面具有潜在应用前景。

Abstract: A hemispherical multilayer wide-band (7-13 GHz) band-pass frequency selective surface (FSS) is reported. A new design technique based on a Goldberg discretization and unit cell scaling technique is introduced to accommodate the curved profile of the FSS. The FSS is additively manufactured by sequentially printing dielectric layers and metallic patterns until 3 patterned silver-ink surfaces are integrated within a 4.5 mm (${λ_0}/6$ at 10 GHz) thick ABS hemispherical radome. The diameter and the height of the realized hemispherical FSS are around $5{λ_0}$ and $3{λ_0}$ respectively. Measurements demonstrate a roughly 1.7 dB insertion loss in the passband and 15-20 dB rejection in the stop-band. Additionally, a new postprocessing technique is used to suppress the effects of edge diffraction in the measured transmission spectrum. The design process, manufacturing technique, and measurement postprocessing represent novel advancements enabling future conformal frequency selective surfaces.

</details>


### [17] [Experimental Multi-site Testbed for Advanced Control and Optimization of Hybrid Energy Systems](https://arxiv.org/abs/2511.16819)
*Arash Omidi,Tanmay Mishra,Mads R. Almassalkhi*

Main category: eess.SY

TL;DR: 提出一个混合能源系统（HES）实验测试台，结合硬件在环（HIL）以支持网格服务的高级控制与优化策略的原型化与验证；平台集成PV、储能、电解槽等千瓦级资产及并网逆变器，并具统一监控/通信架构，通过CHIL实验验证电池参与PV功率平滑的能力。


<details>
  <summary>Details</summary>
Motivation: 需要一个能够在硬件与仿真之间无缝桥接的多资产平台，用于原型化、验证并比较面向网格服务的高级控制与优化策略，从而提升对可再生能源接入场景的控制与可靠性。

Method: 设计并实现一个混合能源系统测试台（HES），具备可重构的千瓦级资产组合（PV、储能、可控负载/电解槽、并网逆变器）和统一的监控与通信架构，支持实时数据采集、模型验证与控制实现，并通过控制硬件在环（CHIL）实验验证电池在PV功率平滑中的作用。

Result: 在CHIL实验中实现并验证了电池参与PV功率平滑的能力，证明测试台在实时数据获取、模型验证与控制实现方面具有有效性，可用于进一步的控制与优化策略原型化。

Conclusion: 该HES测试台提供了一个多资产、可配置且具实时仿真能力的平台，为原型化与验证面向网格服务的先进控制与优化策略提供有效的实验环境，适用于未来的控制器开发与测试。

Abstract: This paper presents a hybrid energy system (HES) experimental testbed developed at the University of Vermont to support prototyping and validation of advanced control and optimization strategies for grid services. The platform integrates hardware-in-the-loop (HIL) simulation with a reconfigurable set of kilowatt-scale assets, including solar photovoltaic (PV), battery storage, an electrolyzer as a controllable load, and grid-tied inverters. A unified monitoring and communication architecture supports real-time data acquisition, model validation, and control implementation. The testbed's capabilities are demonstrated through a controller hardware-in-the-loop (CHIL) experiment in which a battery system participates in PV power smoothing.

</details>


### [18] [The PV performance ratio paradox: annual data from large-scale, real-world PV systems show negligible meteorological and technical impact and points to dominant human factors](https://arxiv.org/abs/2511.16834)
*Hugo FM Milan,Aline Q Alves,Thatiane AT Souza,Juliana M Galo,Alex SC Maia,Moisés AP Borges,Ciro J Egoavil*

Main category: eess.SY

TL;DR: 在 Rondônia 州的大规模异质性光伏系统中，年度性能比(PR)受 meteorological 和技术变量的影响极小，表明人因（安装、监控、维护质量）对 PR 的影响更大；政策可将重点放在提升安装与维护培训上，并提供用于快速估算年发电量的能量产出分布和地图。


<details>
  <summary>Details</summary>
Motivation: 填补大规模异质性光伏系统中哪些变量显著影响 PR 的研究空白，帮助制定针对性优化策略，提高系统整体绩效。

Method: 利用数据驱动模型对 Rondônia 州的光伏系统进行分析，估计 PR 的概率密度函数，确定 PR 的峰值，并构建年度最终发电量的空间分布地图。

Result: 发现气象与技术变量对年度 PR 的影响几乎可以忽略，暗示人因（如安装质量、监控与维护）可能具有更大影响。PR 峰值为 78.85%，均值 77.52%，95% 置信区间为 76.12%–78.84%，95% 预测区间为 58.83%–92.70%。给出 Rondônia 州的年度最终发电量分布地图，便于企业快速、低成本地估算能量产出。

Conclusion: 建议政策重点放在提升安装与维护培训，以及建立教育项目以培训 PV 安装人员和技术人员，从而提升系统性能；同时提供可用于估算年产出的工具性地图与统计分布。

Abstract: Performance ratio (PR) is a established measure of efficiency of photovoltaic (PV) systems. While previous research demonstrated the effects of meteorological and technical variables on PR, a gap persists in the literature on which variables strongly influence PR in large-scale, real-world, heterogeneous PV systems. This paper aims to fill this gap, applying data-driven models to PV systems located in Rondônia State, Brazil, to identify which variables strongly influence annual PR, and, hence, should be the target for optimization. Surprisingly, only negligible effects were found between meteorological and technical variables on annual PR, indicating that human-factors (such as installation, monitoring, and maintenance quality) might have a stronger effect. These findings indicates that, to improve performance of PV systems, policy makers could focus on creating educational programs to teach PV installers and technicians how to properly install, monitor, and maintain modern PV systems. Through estimating the probability density functions of PR, its peak value was found as 78.85% (mean 77.52%, 95% confidence interval of 76.12% to 78.84%, and 95% prediction interval of 58.83% to 92.70%). A map of annual final yield was developed for Rondônia State and can be used by entrepreneurs to quickly and cheaply estimate energy production.

</details>


### [19] [When Motion Learns to Listen: Diffusion-Prior Lyapunov Actor-Critic Framework with LLM Guidance for Stable and Robust AUV Control in Underwater Tasks](https://arxiv.org/abs/2511.16900)
*Jingzehua Xu,Weiyi Liu,Weihang Zhang,Zhuofan Xi,Guanwen Xie,Shuai Zhang,Yi Li*

Main category: eess.SY

TL;DR: 提出一种扩散先验的Lyapunov演员-评论家框架用于AUV控制，结合扩散模型、Lyapunov约束的评论家以及基于LLM的外环，实现探索、稳定性和语义适应性的统一，提升样本效率、长期规划能力及多任务权衡的稳定性。


<details>
  <summary>Details</summary>
Motivation: AUV在水下环境中受非线性水动力、时变干扰和定位不确定性影响，传统控制器适应性有限；尽管强化学习有潜力，但样本效率低、缺乏长期规划和稳定性保证，导致行为不稳定。需要一个能提供稳定性保证且具备语义自适应的学习框架。

Method: 在控制策略中引入扩散模型来生成平滑、多模态且对干扰鲁棒的候选动作；引入Lyapunov评论家以双重约束确保稳定性；通过大语言模型驱动的外环，根据任务语义和训练反馈自适应选择与 refinement Lyapunov函数，形成“生成-筛选-优化”循环。

Result: 在复杂海洋动力学的 extensive simulations 中，与传统RL与扩散增强基线相比，该框架在轨迹跟踪精度、任务完成率、能效、收敛速度和鲁棒性方面均有提升。

Conclusion: 该框架通过将生成能力、稳定性约束与语义自适应结合，提升了AUV控制任务的样本效率、规划能力和多目标下的稳定性保障，且具备扩展到其他海洋机器人任务的潜力。

Abstract: Autonomous Underwater Vehicles (AUVs) are indispensable for marine exploration; yet, their control is hindered by nonlinear hydrodynamics, time-varying disturbances, and localization uncertainty. Traditional controllers provide only limited adaptability, while Reinforcement Learning (RL), though promising, suffers from sample inefficiency, weak long-term planning, and lacks stability guarantees, leading to unreliable behavior. To address these challenges, we propose a diffusion-prior Lyapunov actor-critic framework that unifies exploration, stability, and semantic adaptability. Specifically, a diffusion model generates smooth, multimodal, and disturbance-resilient candidate actions; a Lyapunov critic further imposes dual constraints that ensure stability; and a Large Language Model (LLM)-driven outer loop adaptively selects and refines Lyapunov functions based on task semantics and training feedback. This "generation-filtering-optimization" mechanism not only enhances sample efficiency and planning capability but also aligns stability guarantees with diverse mission requirements in the multi-objective optimization task. Extensive simulations under complex ocean dynamics demonstrate that the proposed framework achieves more accurate trajectory tracking, higher task completion rates, improved energy efficiency, faster convergence, and improved robustness compared with conventional RL and diffusion-augmented baselines.

</details>


### [20] [State-Derivative Feedback Control for Damping Low-Frequency Oscillations in Bulk Power Systems](https://arxiv.org/abs/2511.16974)
*MST Rumi Akter,Anamitra Pal,Rajasekhar Anguluri*

Main category: eess.SY

TL;DR: 提出一种基于状态导数反馈的阻尼控制器（SDF），利用频率及其变化率作为反馈，提升模态阻尼并加快频率恢复，从而在高电力电子装置丰富的电网中有效稳定 HVDC 与储能系统。


<details>
  <summary>Details</summary>
Motivation: 低频振荡在高渗透可再生能源、长输电线路与大负荷情景下仍然是电力系统的主要难题；现有基于功率调制的阻尼策略受限于固定控制架构，难以对部分模态提供充分阻尼。

Method: 提出并实现一种状态导数反馈（SDF）阻尼控制器，使用频率及其一阶导数作为反馈信号；在两区与三区系统上进行仿真评估，并与基于频差的阻尼方案进行对比。

Result: 仿真结果表明，SDF 控制器能够实现接近状态反馈的阻尼性能，并对区域间及区域内振荡均具有良好阻尼，优于频差法的表现。

Conclusion: 基于状态导数的阻尼控制在电力电子装置丰富的电网中具有实际应用潜力，可作为稳定高渗透电网的可行解决方案。

Abstract: Low-frequency oscillations remain a major challenge in bulk power systems with high renewable penetration, long lines, and large loads. Existing damping strategies based on power modulation of high voltage DC (HVDC) or energy storage, are often limited by fixed control architectures, leaving some modes poorly damped. This paper introduces a state-derivative feedback (SDF) damping controller that uses both frequency and its rate of change as feedback signals. Incorporating state derivatives enhances modal damping and accelerates frequency recovery, enabling HVDC and energy storage to effectively stabilize the grid. We evaluate the SDF controller on two- and three-area systems and compare performance with a frequency difference-based damping scheme. Results show that the SDF control reproduces state-feedback performance while providing good damping of both inter- and intra-area oscillations compared to the frequency-difference method, highlighting its potential as a practical solution for stabilizing power-electronics-rich grids.

</details>


### [21] [Feature Partitioning and Semantic Equalization for Intrinsic Robustness in Semantic Communication under Packet Loss](https://arxiv.org/abs/2511.16983)
*Xiao Yang,Shuai Ma,Yong Liang,Guangming Shi*

Main category: eess.SY

TL;DR: 在语义传输中，分区策略决定鲁棒性；Transformer对按通道维分区的包丢失具有天然鲁棒性；CNN若配合SEM可实现与Transformer相当的容错性。


<details>
  <summary>Details</summary>
Motivation: 解决在分组包时高维语义特征的分区难题，以最大化对包丢失的鲁棒性，比较Transformer与CNN，并提出能提高CNN鲁棒性的SEM。

Method: 在多种特征分区方案下评估Transformer与CNN的鲁棒性；提出轻量级语义等化机制（SEM），包括动态尺度模块和广播模块，提升CNN对包丢失的耐受性；通过实验测量PSNR等指标。

Result: Transformer在按照通道分区时对包丢失具有固有鲁棒性；CNN存在通道使用不均衡问题，导致主导通道丢失时性能显著下降；SEM使CNN实现平滑降解，在40%包丢失时保留约lossless PSNR的85%，与Transformer相当。

Conclusion: 在合适的分区策略下，保持平衡的语义表达是实现对包丢失鲁棒性的关键；SEM为实际语义通信设计提供可行方案，且该观点可能推广至视频等其他模态。

Abstract: Semantic communication can improve transmission efficiency by focusing on task-relevant information. However, under packet-based communication protocols, any error typically results in the loss of an entire packet, making semantic communication particularly vulnerable to packet loss. Since high-dimensional semantic features must be partitioned into one-dimensional transmission units during packetization. A critical open question is how to partition semantic features to maximize robustness. To address this, we systematically investigate the performance of two mainstream architectures, Transformer and Convolutional neural networks (CNN), under various feature partitioning schemes. The results show that the Transformer architecture exhibits inherent robustness to packet loss when partitioned along the channel dimension. In contrast, the CNN-based baseline exhibits imbalanced channel utilization, causing severe degradation once dominant channels are lost. To enhance the CNN resilience, we propose a lightweight Semantic Equalization Mechanism (SEM) that balances channel contributions and prevents a few channels from dominating. SEM consists of two parallel approaches: a Dynamic Scale module that adaptively adjusts channel importance, and a Broadcast module that facilitates information interaction among channels. Experimental results demonstrate that CNN equipped with SEM achieve graceful degradation under packet loss (retaining about 85% of lossless PSNR at 40% packet loss), comparable to that of Transformer models. Our findings indicate that, under an appropriate partitioning strategy, maintaining a balanced semantic representation is a fundamental condition for achieving intrinsic robustness against packet loss. These insights may also extend to other modalities such as video and support practical semantic communication design.

</details>


### [22] [Continuous Resilience in Cyber-Physical Systems of Systems: Extending Architectural Models through Adaptive Coordination and Learning](https://arxiv.org/abs/2511.17017)
*Elisabeth Vogel,Peter Langendörfer*

Main category: eess.SY

TL;DR: 提出面向CPSoS的双层自适应韧性架构：ACL用于实时风险检测与协调，AL用于战略学习与长期治理；将韧性视为持续的数据驱动过程，兼顾短期响应与长期发展。


<details>
  <summary>Details</summary>
Motivation: CPSoS 环境高度复杂，现有韧性架构多为静态，难以在变量条件下保持功能；需要引入能够实时感知、协调与学习的层级结构。

Method: 概念性架构设计，定义 ACL（实时操作控制层）与 AL（战略—合作层）的职责与交互；给出从规则驱动、KPI 驱动到 AI 支持、元学习等多种实现变体，结合系统复杂度、数据可用性与监管程度进行组合。

Result: 提出一个以 ACL 和 AL 为核心的架构模型，将短期响应与长期学习结合，提供将韧性从静态属性转变为连续数据驱动过程的方法论基础。

Conclusion: 将韧性定位为持续数据驱动的过程，通过 ACL 的实时协同与 AL 的战略学习，实现自适应、可持续的 CPSoS 韧性，提高下一代系统的适应能力，并为不同实现变体的组合提供指导。

Abstract: Cyber-physical systems of systems (CPSoS) are highly complex, dynamic environments in which technical, cybernetic and organisational subsystems interact closely with one another. Dynamic, continuously adaptable resilience is required to ensure their functionality under variable conditions. However, existing resilience architectures usually only deal with adaptation implicitly and thus remain predominantly static. This paper addresses this gap by introducing a new Adaptive Coordination Layer (ACL) and conceptually redefining the Adaptation & Learning Layer (AL). The ACL acts as an operational control layer that detects risks in real time, prioritises countermeasures and coordinates them dynamically. The AL is reinterpreted as a strategic-cooperative layer that evaluates the operational decisions of the ACL, learns from them, and derives long-term adjustments at the policy, governance, and architecture levels. Together, both layers operationalise the resilience principle of adaptation and combine short-term responsiveness with long-term learning and development capabilities. The paper describes various implementation variants of both levels - from rule-based and KPI-driven approaches to AI-supported and meta-learning mechanisms - and shows how these can be combined depending on system complexity, data availability and degree of regulation. The proposed architecture model no longer understands resilience as a static system property, but as a continuous, data-driven process of mutual coordination and systemic learning. This creates a methodological basis for the next generation of adaptive and resilient CPSoS.

</details>


### [23] [KNN and Time Series Based Prediction of Power Generation from Renewable Resources](https://arxiv.org/abs/2511.17102)
*Ismum Ul Hossain,Mohammad Nahidul Islam*

Main category: eess.SY

TL;DR: 用约30年数据对太阳、风力和水电的发电量进行预测，比较K近邻(KNN)与结合SARIMA的非线性自回归分布式模型在预测总发电量上的表现，结果两者表现相近但各有特征；长期历史有助于捕捉时间性波动和季节/气候效应，提高对电网可靠性的预测。


<details>
  <summary>Details</summary>
Motivation: 应对可再生能源发电的间歇性、非线性和复杂性带来的预测挑战，确保稳定供电并实现并网；通过长历史数据（约30年）提升模型对时间性波动、季节性与气候影响的校准，以支持电网运营者、能源交易者及相关政策制定者。

Method: 构建一个面向可再生能源发电的机器学习预测框架，比较两种建模路径：一是K最近邻(KNN)回归，二是带季节性差分自回归移动平均(SARIMA)组件的非线性自回归分布式模型（NAR/等），两者均利用高时间分辨率和环境变量来预测三种资源（太阳能、风能、水电）的总发电量。对比评估采用严格的误差指标。

Result: 在给定评估条件下，两种模型的误差指标同等显著，且在特定情形下各自呈现独特倾向。长期数据有助于更好地校准时间波动及季节性、气候效应，从而提高预测的可靠性，利于电网运营者、能源交易者及可再生能源政策与标准制定者。

Conclusion: 以约30年的数据为支撑的框架显著提升对可再生能源发电波动的鲁棒性与可靠性评估能力，对电网运行与市场决策具有实际价值。

Abstract: As the world shifts towards utilizing natural resources for electricity generation, there is need to enhance forecasting systems to guarantee a stable electricity provision and to incorporate the generated power into the network systems. This work provides a machine learning environment for renewable energy forecasting that prevents the flaws which are usually experienced in the actual process; intermittency, nonlinearity and intricacy in nature which is difficult to grasp by ordinary existing forecasting procedures. Leveraging a comprehensive approximately 30-year dataset encompassing multiple renewable energy sources, our research evaluates two distinct approaches: K-Nearest Neighbors (KNN) model and Non-Linear Autoregressive distributed called with Seasonal Autoregressive Integrated Moving Average (SARIMA) model to forecast total power generation using the solar, wind, and hydroelectric resources. The framework uses high temporal resolution and multiple parameters of the environment to improve the predictions. The fact that both the models in terms of error metrics were equally significant and had some unique tendencies at certain circumstances. The long history allows for better model calibration of temporal fluctuations and seasonal and climatic effects on power generation. The reliability enhancement in the prediction function, which benefits from 30 years of data, has value to grid operators, energy traders, and those establishing renewable energy policies and standards concerning reliability

</details>


### [24] [Computing the Hard Scaled Relative Graph of LTI Systems](https://arxiv.org/abs/2511.17297)
*Julius P. J. Krebbekx,Eder Baron-Prada,Roland Tóth,Amritam Das*

Main category: eess.SY

TL;DR: Proposes an exact computational method to compute the hard SRG for LTI systems, including unstable ones with integrators, and links it to the multivariable Nyquist criterion, with demonstrations on several examples.


<details>
  <summary>Details</summary>
Motivation: To enable rigorous frequency-domain analysis of nonlinear systems using Scaled Relative Graphs (SRGs) when the internal LTI components are unstable or contain integrators, by providing an exact finite-dimensional computation of the hard SRG and linking it to Nyquist theory.

Method: Develops a systematic algorithm to compute the hard SRG exactly for LTI systems (even unstable, with integrators) and extends the construction to the multivariable case; then validates the method with several numerical/analytical examples and discusses its relation to the Nyquist criterion.

Result: An exact computational procedure for the hard SRG of LTI systems is established, including unstable cases and integrators; the method is illustrated with multiple examples and its connection to the multivariable Nyquist criterion is clarified.

Conclusion: The work provides a practical and theoretically grounded tool for hard-SRG analysis of nonlinear systems with unstable LTI components, demonstrating exact computation and enriching the Nyquist-based interpretation in the multivariable setting.

Abstract: Scaled Relative Graphs (SRGs) provide a novel graphical frequency-domain method for the analysis of nonlinear systems, where Linear Time-Invariant (LTI) systems are the fundamental building block. To analyze feedback loops with unstable LTI components, the hard SRG is required, since it aptly captures the input/output behavior on the extended $L_2$ space. In this paper, we develop a systematic computational method to exactly compute the hard SRG of LTI systems, which may be unstable and contain integrators. We also study its connection to the Nyquist criterion, including the multivariable case, and demonstrate our method on several examples.

</details>


### [25] [The Iberian Blackout: A Black Swan or a Gray Rhino? A Thorough Power System Analysis](https://arxiv.org/abs/2511.17433)
*Abdallah Alalem Albustami,Ahmad F. Taha*

Main category: eess.SY

TL;DR: 对2025年4月28日发生在伊比利亚电网的停电事件进行全面事后分析，包括重建因果时间线、汇总贡献因素、在IEEE测试系统上的再现、从系统理论的电压控制角度分析，以及给出可落地的缓解措施。


<details>
  <summary>Details</summary>
Motivation: 旨在弄清导致欧洲首次记录在案的过压驱动级联停电的根本原因，区分信号与噪声，提升在高可再生成本、低惯性环境下的电网韧性与操作决策的科学性。

Method: （i）重建事件时间线与因果链；（ii）基于事故报告的事实发现，提炼并总结可能的贡献因素；（iii）在IEEE测试系统上对停电过程进行再现实验；（iv）从系统理论的角度，结合电压控制视角进行分析；（v）把分析转化为可操作的技术性缓解措施与防范策略。

Result: 研究产出包括：完整的因果链与事件时间线、基于事实的贡献因素清单、在IEEE测试系统中的再现实验验证、系统理论与电压控制视角下的洞见，以及一套可落地的缓解与防范措施。

Conclusion: 该工作提升了对高再生能源、低惯量背景下过压驱动型级联停电的理解，提供具有实用性的技术性改进建议，以增强未来电网对类似事件的抵御能力。

Abstract: On April 28, 2025, the Iberian power system suffered a full blackout. It was the first documented overvoltage-driven cascade in Europe. The event sparked debate about root causes, including high renewables output, low inertia, and operator actions. This paper presents a thorough power system analysis of the incident to sort signal from noise and explain, step by step, how the blackout unfolded. Specifically, we (i) reconstruct the timeline and causal chain of the incident, (ii) present and summarize contributing factors using factual findings from incident reports, (iii) reproduce the blackout on an IEEE test system, (iv) analyze the incident from a system-theoretic, voltage-control perspective, and (v) translate our analysis into practical, technical measures that aim to mitigate and prevent similar incidents.

</details>


### [26] [A Framework for Adaptive Stabilisation of Nonlinear Stochastic Systems](https://arxiv.org/abs/2511.17436)
*Seth Siriya,Jingge Zhu,Dragan Nešić,Ye Pu*

Main category: eess.SY

TL;DR: 提出一种确定性等价学习的自适应控制策略，针对离散时间的非线性随机系统与线性参数不确定性；在可信息区域内若参数选取得当的控制族能稳定系统，给出闭环在某些概率下的稳定性界；当全状态信息且控制族全局稳定时，获得高概率稳定性保证。


<details>
  <summary>Details</summary>
Motivation: 解决非线性随机系统中的参数不确定性所带来的稳定性保障问题，寻求带概率的稳定性分析，并探讨信息区域对结果的影响。

Method: 假设存在一个参数化的控制族，在信息区域内的参数取值能使系统稳定；提出基于确定性等价的学习自适应控制策略，推导闭环稳定性在某些概率下成立的界；在全状态信息且控制族全球稳定且参数选取得当的情况下，导出高概率稳定性保证。

Result: 给出在部分概率下的稳定性界以及在全状态信息和全局稳定条件下的高概率稳定性保证。

Conclusion: 若信息区域覆盖全状态且控制族具全球稳定性，则该策略可实现高概率的稳定性保证，为离散时间非线性随机系统的自适应控制提供了一个带概率的稳定性分析框架。

Abstract: We consider the adaptive control problem for discrete-time, nonlinear stochastic systems with linearly parameterised uncertainty. Assuming access to a parameterised family of controllers that can stabilise the system in a bounded set within an informative region of the state space when the parameter is well-chosen, we propose a certainty equivalence learning-based adaptive control strategy, and subsequently derive stability bounds on the closed-loop system that hold for some probabilities. We then show that if the entire state space is informative, and the family of controllers is globally stabilising with appropriately chosen parameters, high probability stability guarantees can be derived.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [27] [Performance Comparison of 5G NR Uplink MIMO and Uplink Carrier Aggregations on Commercial Network](https://arxiv.org/abs/2511.16751)
*Henry Shao,Kasidis Arunruangsirilert*

Main category: cs.NI

TL;DR: UL-MIMO and UL-CA can enhance uplink in 5G networks, but UL-MIMO often underperforms in practice; adaptive use—reserving UL-CA for weaker RF conditions and UL-MIMO for stronger RF conditions—yields better overall uplink capacity.


<details>
  <summary>Details</summary>
Motivation: Rising uplink demand from social media, 4K/8K content creation, IoT, and Fixed Wireless Access drives need to evaluate uplink enhancements (UL-MIMO and UL-CA) on commercial 5G networks.

Method: Empirical evaluation of uplink throughput on the commercial T-Mobile 5G network across diverse RF environments and travel modes, focusing on UL-MIMO (n41 TDD band) and UL-CA between TDD and FDD NR bands in a 5G Standalone deployment.

Result: UL-MIMO generally yields slower uplink throughput than baseline in most scenarios, even with efficiency gains, but provides adequate user experience in stronger RF conditions; UL-CA enables higher throughput by aggregating wider channels, suggesting capacity can be conserved by reserving UL-CA for UEs in weaker RF conditions.

Conclusion: An adaptive uplink strategy should allocate UL-MIMO in strong RF scenarios and reserve UL-CA for weaker RF conditions to optimize overall uplink capacity in commercial 5G networks.

Abstract: Demands for uplink on mobile networks are increasing with the rapid development of social media platforms, 4K/8K content creation, IoT applications, and Fixed Wireless Access (FWA) broadband. As a result, Uplink MIMO (UL-MIMO) and Uplink Carrier Aggregation (UL-CA) have been widely deployed for the first time on commercial 5G networks. UL-MIMO enables the transmission of two data streams on one frequency band in strong RF conditions, theoretically doubling throughput and efficiency. On the other hand, UL-CA allows for simultaneous upload on greater channel widths, allowing more resources to be assigned to a single UE for higher throughput. In the United States, T-Mobile USA, a mobile network operator (MNO), has deployed network-wide 5G Standalone (SA), along with UL-MIMO on Time Division Duplex (TDD) band n41 and UL-CA between TDD and Frequency Division Duplex (FDD) NR bands. In this paper, the uplink throughput performance of UL-MIMO and UL-CA will be evaluated on the commercial T-Mobile 5G network on a variety of RF environments and modes of transportation. It was found that, even with the efficiency gains, UL-MIMO yields slower uplink throughput in most scenarios. However, in stronger RF conditions, UL-MIMO can provide an adequate user experience, so capacity can be conserved by reserving UL-CA for UE in weaker RF conditions.

</details>


### [28] [One Walk is All You Need: Data-Efficient 3D RF Scene Reconstruction with Human Movements](https://arxiv.org/abs/2511.16966)
*Yiheng Bian,Zechen Li,Lanqing Yang,Hao Pan,Yezhou Wang,Longyuan Ge,Jeffery Wu,Ruiheng Liu,Yongjian Fu,Yichao chen,Guangtao xue*

Main category: cs.NI

TL;DR: 通过单次60秒步行数据，利用复合3D高斯散点的因式分解框架，从被遮挡的静态场景中高效重建3D射线场，达到0.96的SSIM，较SOTA提升约12%并解决数据采集瓶颈。


<details>
  <summary>Details</summary>
Motivation: 长期目标是在有遮挡的3D射线场重建中减少对大量静态测量的依赖，将人类运动视为信息量丰富的信号，以实现快速、数据高效的重建。

Method: 提出基于复合3D高斯散点的因式分解框架（3DGS），从原始RF流中学习并建模人类运动的动态效应，同时保留静态场景几何信息。仅在单次60秒的随意步行数据上进行训练。

Result: 在静态场景重建上达到SSIM 0.96，较 heavily-sampled SOTA提升约12%，显示出对稀疏数据的高效利用。

Conclusion: 通过将人类移动转化为有用信号，打破数据获取瓶颈，推动未知环境的即时3D RF映射成为可能。

Abstract: Reconstructing 3D Radiance Field (RF) scenes through opaque obstacles is a long-standing goal, yet it is fundamentally constrained by a laborious data acquisition process requiring thousands of static measurements, which treats human motion as noise to be filtered. This work introduces a new paradigm with a core objective: to perform fast, data-efficient, and high-fidelity RF reconstruction of occluded 3D static scenes, using only a single, brief human walk. We argue that this unstructured motion is not noise, but is in fact an information-rich signal available for reconstruction. To achieve this, we design a factorization framework based on composite 3D Gaussian Splatting (3DGS) that learns to model the dynamic effects of human motion from the persistent static scene geometry within a raw RF stream. Trained on just a single 60-second casual walk, our model reconstructs the full static scene with a Structural Similarity Index (SSIM) of 0.96, remarkably outperforming heavily-sampled state-of-the-art (SOTA) by 12%. By transforming the human movements into its valuable signals, our method eliminates the data acquisition bottleneck and paves the way for on-the-fly 3D RF mapping of unseen environments.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [29] [Joint Design of Protein Surface and Structure Using a Diffusion Bridge Model](https://arxiv.org/abs/2511.16675)
*Guanlue Li,Xufeng Zhao,Fang Wu,Sören Laue*

Main category: cs.LG

TL;DR: PepBridge 是一种联合设计蛋白表面与结构的框架：以受体表面点云为起点，通过去噪扩散桥模型将受体表面映射为配体表面，随后由多模扩散模型预测相应结构，并通过 Shape-Frame Matching Network 对表面几何与骨架进行对齐，从而实现表面互补、构象稳定性与化学可行性。在多样化蛋白设计场景中验证了其在生成结构可行蛋白质方面的效用，标志着顶层设计的进展。


<details>
  <summary>Details</summary>
Motivation: 蛋白质-蛋白质相互作用（PPIs）受表面互补性和疏水相互作用支配，现有计算设计难以在多样性、物理现实性与对目标受体的精确互补之间取得平衡。需要实现表面与结构的耦合设计，以提高互补性、稳定性与化学可行性。

Method: 1) 将受体表面表示为三维点云；2) 使用去噪扩散桥模型（DDBMs）将受体表面映射到配体表面；3) 通过多模扩散模型预测相应的蛋白质结构；4) 使用 Shape-Frame Matching Networks 确保表面几何与主链骨架之间的对齐；5) 通过整合实现表面互补性、构象稳定性与化学可行性。

Result: 在广泛的蛋白设计场景下对 PepBridge 进行了充分验证，显示其在生成结构可行蛋白质方面的有效性，推动了表面-结构耦合设计的进展。

Conclusion: PepBridge 提供了一种端到端的联合设计框架，能够在受体表面几何与化学属性的基础上实现表面-结构的一体化设计，被视为在蛋白质表面与结构联合设计方面的重要进展。

Abstract: Protein-protein interactions (PPIs) are governed by surface complementarity and hydrophobic interactions at protein interfaces. However, designing diverse and physically realistic protein structure and surfaces that precisely complement target receptors remains a significant challenge in computational protein design. In this work, we introduce PepBridge, a novel framework for the joint design of protein surface and structure that seamlessly integrates receptor surface geometry and biochemical properties. Starting with a receptor surface represented as a 3D point cloud, PepBridge generates complete protein structures through a multi-step process. First, it employs denoising diffusion bridge models (DDBMs) to map receptor surfaces to ligand surfaces. Next, a multi-model diffusion model predicts the corresponding structure, while Shape-Frame Matching Networks ensure alignment between surface geometry and backbone architecture. This integrated approach facilitates surface complementarity, conformational stability, and chemical feasibility. Extensive validation across diverse protein design scenarios demonstrates PepBridge's efficacy in generating structurally viable proteins, representing a significant advancement in the joint design of top-down protein structure.

</details>


### [30] [DDTime: Dataset Distillation with Spectral Alignment and Information Bottleneck for Time-Series Forecasting](https://arxiv.org/abs/2511.16715)
*Yuqi Li,Kuiye Ding,Chuanguang Yang,Hao Wang,Haoxuan Wang,Huiran Duan,Junming Liu,Yingli Tian*

Main category: cs.LG

TL;DR: DDTime: a plug-in dataset distillation framework for time-series forecasting via first-order condensation decomposition, addressing temporal autocorrelation bias with frequency-domain alignment and diversity through inter-sample regularization; achieves ~30% relative accuracy gains on 20 datasets with ~2.49% overhead.


<details>
  <summary>Details</summary>
Motivation: Dataset distillation for time-series is challenging due to strong autocorrelation causing value-term misalignment and limited trajectory diversity due to lack of explicit priors.

Method: Proposes DDTime built on first-order condensation decomposition; tackles temporal bias via temporal statistics and frequency-domain alignment; introduces inter-sample regularization inspired by information bottleneck to enhance diversity; designed to be compatible with various condensation paradigms and support stable first-order optimization.

Result: Extensive experiments on 20 benchmark datasets and diverse architectures show ~30% relative accuracy gains with ~2.49% computational overhead; all code and distilled datasets will be released.

Conclusion: DDTime advances time-series distillation by addressing both temporal bias and sample diversity, offering a lightweight plug-in that outperforms existing methods and is broadly compatible with condensation frameworks.

Abstract: Time-series forecasting is fundamental across many domains, yet training accurate models often requires large-scale datasets and substantial computational resources. Dataset distillation offers a promising alternative by synthesizing compact datasets that preserve the learning behavior of full data. However, extending dataset distillation to time-series forecasting is non-trivial due to two fundamental challenges: 1.temporal bias from strong autocorrelation, which leads to distorted value-term alignment between teacher and student models; and 2.insufficient diversity among synthetic samples, arising from the absence of explicit categorical priors to regularize trajectory variety.
  In this work, we propose DDTime, a lightweight and plug-in distillation framework built upon first-order condensation decomposition. To tackle Challenge 1, it revisits value-term alignment through temporal statistics and introduces a frequency-domain alignment mechanism to mitigate autocorrelation-induced bias, ensuring spectral consistency and temporal fidelity. To address Challenge 2, we further design an inter-sample regularization inspired by the information bottleneck principle, which enhances diversity and maximizes information density across synthetic trajectories. The combined objective is theoretically compatible with a wide range of condensation paradigms and supports stable first-order optimization. Extensive experiments on 20 benchmark datasets and diverse forecasting architectures demonstrate that DDTime consistently outperforms existing distillation methods, achieving about 30% relative accuracy gains while introducing about 2.49% computational overhead. All code and distilled datasets will be released.

</details>


### [31] [When Structure Doesn't Help: LLMs Do Not Read Text-Attributed Graphs as Effectively as We Expected](https://arxiv.org/abs/2511.16767)
*Haotian Xu,Yuning You,Tengfei Ma*

Main category: cs.LG

TL;DR: 在文本标注的图上，LLMs 只需利用节点文本描述即可获得强性能；大多数结构编码策略的增益极小，甚至负增益。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型主导的跨模态与推理场景下，需重新评估结构信息对图推理的作用；传统图学习强调结构，但在LLM时代其必要性需要被重新审视。

Method: 系统性比较多种结构编码策略（如模板化结构、GNN编码等）对文本-属性图的任务表现的影响，并通过大规模实验进行评估。

Result: 实验结果显示：i) 仅使用节点文本描述的LLMs就能实现强势性能；ii) 大多数结构编码策略对性能几乎无提升，甚至可能下降。

Conclusion: 这表明显式的结构先验在强大语言模型面前往往不必要，甚至有害，应推动以语义驱动、对结构依赖较少的图学习新范式。

Abstract: Graphs provide a unified representation of semantic content and relational structure, making them a natural fit for domains such as molecular modeling, citation networks, and social graphs. Meanwhile, large language models (LLMs) have excelled at understanding natural language and integrating cross-modal signals, sparking interest in their potential for graph reasoning. Recent work has explored this by either designing template-based graph templates or using graph neural networks (GNNs) to encode structural information. In this study, we investigate how different strategies for encoding graph structure affect LLM performance on text-attributed graphs. Surprisingly, our systematic experiments reveal that: (i) LLMs leveraging only node textual descriptions already achieve strong performance across tasks; and (ii) most structural encoding strategies offer marginal or even negative gains. We show that explicit structural priors are often unnecessary and, in some cases, counterproductive when powerful language models are involved. This represents a significant departure from traditional graph learning paradigms and highlights the need to rethink how structure should be represented and utilized in the LLM era. Our study is to systematically challenge the foundational assumption that structure is inherently beneficial for LLM-based graph reasoning, opening the door to new, semantics-driven approaches for graph learning.

</details>


### [32] [GCL-OT: Graph Contrastive Learning with Optimal Transport for Heterophilic Text-Attributed Graphs](https://arxiv.org/abs/2511.16778)
*Yating Ren,Yikun Ban,Huobin Tan*

Main category: cs.LG

TL;DR: GCL-OT 通过最优传输实现结构信息与文本嵌入的双向对齐，针对结构-文本图中的多粒度异质性设计了三种机制（RealSoftMax、提示词过滤、OT 指引的软监督），并提供理论保证与九基准实验的实证优势。


<details>
  <summary>Details</summary>
Motivation: 解决文本属性图中结构与文本嵌入之间在多粒度异质性背景下的对齐困难，避免将文本嵌入视为静态目标导致的子优化问题。

Method: 提出 GCL-OT 框架；针对部分异质性使用 RealSoftMax 相似性估计以强调关键邻居-词交互；针对完全异质性引入提示词（prompt）过滤以在最优传输对齐中排除噪声；引入 OT 指引的软监督以发现潜在语义相似的邻居；给出理论分析支持互信息界与贝叶斯误差保障。

Result: 在九个基准数据集上显著优于现有方法，证明方法的有效性和鲁棒性。

Conclusion: GCL-OT 提供一种灵活的、双向的对齐框架，能够处理文本图中的Complete/Partial/Latent Homophily等多种异质性情形，提升结构-文本对比学习的性能与鲁棒性。

Abstract: Recently, structure-text contrastive learning has shown promising performance on text-attributed graphs by leveraging the complementary strengths of graph neural networks and language models. However, existing methods typically rely on homophily assumptions in similarity estimation and hard optimization objectives, which limit their applicability to heterophilic graphs. Although existing methods can mitigate heterophily through structural adjustments or neighbor aggregation, they usually treat textual embeddings as static targets, leading to suboptimal alignment. In this work, we identify the multi-granular heterophily in text-attributed graphs, including complete heterophily, partial heterophily, and latent homophily, which makes structure-text alignment particularly challenging due to mixed, noisy, and missing semantic correlations. To achieve flexible and bidirectional alignment, we propose GCL-OT, a novel graph contrastive learning framework with optimal transport, equipped with tailored mechanisms for each type of heterophily. Specifically, for partial heterophily, we design a RealSoftMax-based similarity estimator to emphasize key neighbor-word interactions while easing background noise. For complete heterophily, we introduce a prompt-based filter that adaptively excludes irrelevant noise during optimal transport alignment. Furthermore, we incorporate OT-guided soft supervision to uncover potential neighbors with similar semantics, enhancing the learning of latent homophily. Theoretical analysis shows that GCL-OT can improve the mutual information bound and Bayes error guarantees. Extensive experiments on nine benchmarks show that GCL-OT consistently outperforms state-of-the-art methods, verifying its effectiveness and robustness.

</details>


### [33] [Revisiting Multimodal KV Cache Compression: A Frequency-Domain-Guided Outlier-KV-Aware Approach](https://arxiv.org/abs/2511.16786)
*Yaoxin Yang,Peng Ye,Xudong Tan,Chongjun Tu,Maosen Zhao,Jia Hao,Tao Chen*

Main category: cs.LG

TL;DR: 提出 FlashCache，通过频域分析对多模态 KV 缓存进行 Outlier-KV 识别与动态预算分配的压缩，以在不显著损失任务性能的前提下，显著降低 KV 内存并提升解码速度。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型的 KV 缓存随视觉输入长度线性增长，现有压缩方法多依赖注意力分数，难以与高效注意力内核（如 FlashAttention）兼容，同时忽略了 value 向量对注意力输出的贡献。通过从 KV 矩阵分布角度分析，发现能量主要集中在低频部分，提出以低频能量为主导的压缩策略，强调保留对推理关键的‘出列 KV’。

Method: 1) 进行 KV 矩阵的频域建模，提取低频能量以描述主成分。2) Outlier KV Recognition Module：识别并保留显著偏离主成分的 KV，从而保留对推理至关重要的特征。3) Dynamic Budget Allocation Module：按层自适应地分配 KV 缓存大小，以在不同层保留更多的 Outlier KVs。

Result: 在多种多模态语言模型和基准数据集上，FlashCache 超越了现有的多模态 KV 压缩方法，解码速度提升最多约 1.69 倍，KV 内存使用下降约 80%，同时保持任务性能。

Conclusion: 基于频域分布与出列 KV 的压缩框架有效降低 KV 缓存开销且维持性能，可与高效注意力内核协同工作，提供了一种新的 KV 缓存压缩思路。

Abstract: Multimodal large language models suffer from substantial inference overhead since multimodal KV Cache grows proportionally with the visual input length. Existing multimodal KV Cache compression methods mostly rely on attention score to reduce cache size, which makes them are incompatible with established efficient attention kernels (e.g., FlashAttention) and ignores the contribution of value vectors to the attention output. In this work, we revisit multimodal KV Cache compression from the perspective of the KV matrices' distribution. First, we observe that frequency-domain energy of multimodal KV matrices is predominantly concentrated in low-frequency and extract this principal energy via a low-pass filter. Further, we find that removing KV pairs that deviate substantially from this principal energy leads to a pronounced performance drop, which we define as Outlier KVs. Considering Outlier KVs are more likely to encode features critical for inference, we propose FlashCache, a frequency-domain-guided, Outlier-KV-aware KV Cache compression framework. First, we introduce an Outlier KV Recognition Module that models the principal component of multimodal KV matrices in the frequency domain and preferentially retains KV pairs that significantly deviate from it. Furthermore, Dynamic Budget Allocation Module is designed to adaptively determine the per-layer KV Cache size to retain more Outlier KVs. Experiments on multiple MLLMs and benchmarks demonstrate that FlashCache outperforms state-of-the-art multimoal KV compression methods, achieving up to 1.69 times faster decoding with 80% lower KV memory usage while maintaining task performance.

</details>


### [34] [A Vector Symbolic Approach to Multiple Instance Learning](https://arxiv.org/abs/2511.16795)
*Ehsan Ahmed Dhrubo,Mohammad Mahmudul Alam,Edward Raff,Tim Oates,James Holt*

Main category: cs.LG

TL;DR: 提出一种基于向量符号架构(VSA)的多实例学习(MIL)框架，通过将实例与概念编码为近正交高维向量，并用代数运算在分类阶段强制实现MIL的“若有至少一个实例为正则为正”的充分必要条件，同时引入一个将输入映射到VSA向量的学习编码器与VSA驱动的MaxNetwork分类器，在标准MIL基准和医学影像数据集上取得对齐MIL形式的状态-艺术结果。


<details>
  <summary>Details</summary>
Motivation: 传统的深度MIL方法往往违反MIL的等价约束（若无至少一个正实例则为负），导致性能估计偏高、泛化能力差。需要一个可解释、可 principled 地维护MIL约束的学习框架，以提高鲁棒性与可解释性。

Method: 提出在高维向量空间中将实例和概念表示为近正交的向量，并利用代数操作来强制执行MIL的iff约束。通过一个学习编码器将原始实例映射到VSA兼容向量，构建VSA驱动的MaxNetwork分类器来完成最终判定。该框架将MIL假设直接嵌入模型结构中。

Result: 在标准MIL基准和医学影像数据集上实现对此前方法的状态-艺术超越，同时严格维持MIL形式，避免对MIL约束的隐式放宽。

Conclusion: 该工作提供了一种原理性、可解释且有效的替代方案，将符号操作与可微学习结合，展示了VSA在MIL任务中的潜力，并为后续以符号性为核心的MIL研究提供新方向。

Abstract: Multiple Instance Learning (MIL) tasks impose a strict logical constraint: a bag is labeled positive if and only if at least one instance within it is positive. While this iff constraint aligns with many real-world applications, recent work has shown that most deep learning-based MIL approaches violate it, leading to inflated performance metrics and poor generalization. We propose a novel MIL framework based on Vector Symbolic Architectures (VSAs), which provide a differentiable mechanism for performing symbolic operations in high-dimensional space. Our method encodes the MIL assumption directly into the model's structure by representing instances and concepts as nearly orthogonal high-dimensional vectors and using algebraic operations to enforce the iff constraint during classification. To bridge the gap between raw data and VSA representations, we design a learned encoder that transforms input instances into VSA-compatible vectors while preserving key distributional properties. Our approach, which includes a VSA-driven MaxNetwork classifier, achieves state-of-the-art results for a valid MIL model on standard MIL benchmarks and medical imaging datasets, outperforming existing methods while maintaining strict adherence to the MIL formulation. This work offers a principled, interpretable, and effective alternative to existing MIL approaches that rely on learned heuristics.

</details>


### [35] [A Robust Federated Learning Approach for Combating Attacks Against IoT Systems Under non-IID Challenges](https://arxiv.org/abs/2511.16822)
*Eyad Gad,Zubair Md Fadlullah,Mostafa M. Fouda*

Main category: cs.LG

TL;DR: 在物联网攻击检测场景中，比较FedAvg、FedProx与Scaffold在非IID数据下的性能，使用CICIoT2023数据集，揭示各方法在数据异质性下的表现差异。


<details>
  <summary>Details</summary>
Motivation: 随着IoT设备持续增多与数据量激增，边缘设备资源受限且数据隐私敏感，传统集中式训练面临挑战。联邦学习通过在参与方本地训练并聚合模型参数来缓解资源与隐私问题，但非IID数据是FL的核心难题，迫切需要系统评估不同算法在异质性条件下的鲁棒性。

Method: 系统地对FedAvg、FedProx与Scaffold在不同数据分布（IID与多种非IID设置）下的性能进行对比分析，使用CICIoT2023数据集进行大规模IoT攻击分类任务的实验评估，关注准确率、收敛性、鲁棒性与通信成本等指标。

Result: 实验结果显示在非IID场景下三种方法的表现存在显著差异：FedAvg易受数据异质性影响而性能下降；FedProx通过对本地目标函数的平滑化缓解了偏差；Scaffold通过控制客户端更新的偏置提升了收敛性与鲁棒性，具体表现因数据分布而异。

Conclusion: 本文为在IoT攻击检测任务中应对统计异质性的FL方法选择提供实证依据与洞见，帮助研究者和企业在隐私保护与资源约束环境中更有效地部署联邦学习。

Abstract: In the context of the growing proliferation of user devices and the concurrent surge in data volumes, the complexities arising from the substantial increase in data have posed formidable challenges to conventional machine learning model training. Particularly, this is evident within resource-constrained and security-sensitive environments such as those encountered in networks associated with the Internet of Things (IoT). Federated Learning has emerged as a promising remedy to these challenges by decentralizing model training to edge devices or parties, effectively addressing privacy concerns and resource limitations. Nevertheless, the presence of statistical heterogeneity in non-Independently and Identically Distributed (non-IID) data across different parties poses a significant hurdle to the effectiveness of FL. Many FL approaches have been proposed to enhance learning effectiveness under statistical heterogeneity. However, prior studies have uncovered a gap in the existing research landscape, particularly in the absence of a comprehensive comparison between federated methods addressing statistical heterogeneity in detecting IoT attacks. In this research endeavor, we delve into the exploration of FL algorithms, specifically FedAvg, FedProx, and Scaffold, under different data distributions. Our focus is on achieving a comprehensive understanding of and addressing the challenges posed by statistical heterogeneity. In this study, We classify large-scale IoT attacks by utilizing the CICIoT2023 dataset. Through meticulous analysis and experimentation, our objective is to illuminate the performance nuances of these FL methods, providing valuable insights for researchers and practitioners in the domain.

</details>


### [36] [Monte Carlo Expected Threat (MOCET) Scoring](https://arxiv.org/abs/2511.16823)
*Joseph Kim,Saahith Potluri*

Main category: cs.LG

TL;DR: 提出 MOCET：一个可解释、双重可扩展的指标，用以量化现实世界风险，弥补现有 ASL 评估在情境化风险方面的不足，适用于 ASL-3+ 模型的安全评估。


<details>
  <summary>Details</summary>
Motivation: 当前评估指标如 LAB-Bench、BioLP-bench、WMDP 能衡量模型的能力提升和领域知识，但缺乏对现实世界风险的情境化量化；随着大模型快速发展，需要可扩展、开放式的风险评估指标来支撑安全性论证。

Method: 提出 MOCET 作为可解释且双重可扩展的指标（可自动化、开放式）用于量化现实世界风险；与现有基准互补，可用于形成安全性案例的核心量化工具。

Result: 本文提出了 MOCET 的概念框架与初步设计，证明其可解释性与可扩展性，并为后续的实证评估奠定基础。

Conclusion: MOCET 提供了一种面向现实世界风险的量化工具，能够支持对 LLM 安全性的综合评估与安全性论证，并具备对快速进展的适应性。

Abstract: Evaluating and measuring AI Safety Level (ASL) threats are crucial for guiding stakeholders to implement safeguards that keep risks within acceptable limits. ASL-3+ models present a unique risk in their ability to uplift novice non-state actors, especially in the realm of biosecurity. Existing evaluation metrics, such as LAB-Bench, BioLP-bench, and WMDP, can reliably assess model uplift and domain knowledge. However, metrics that better contextualize "real-world risks" are needed to inform the safety case for LLMs, along with scalable, open-ended metrics to keep pace with their rapid advancements. To address both gaps, we introduce MOCET, an interpretable and doubly-scalable metric (automatable and open-ended) that can quantify real-world risks.

</details>


### [37] [ManifoldFormer: Geometric Deep Learning for Neural Dynamics on Riemannian Manifolds](https://arxiv.org/abs/2511.16828)
*Yihang Fu,Lifang He,Qingyu Chen*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Existing EEG foundation models mainly treat neural signals as generic time series in Euclidean space, ignoring the intrinsic geometric structure of neural dynamics that constrains brain activity to low-dimensional manifolds. This fundamental mismatch between model assumptions and neural geometry limits representation quality and cross-subject generalization. ManifoldFormer addresses this limitation through a novel geometric deep learning framework that explicitly learns neural manifold representations. The architecture integrates three key innovations: a Riemannian VAE for manifold embedding that preserves geometric structure, a geometric Transformer with geodesic-aware attention mechanisms operating directly on neural manifolds, and a dynamics predictor leveraging neural ODEs for manifold-constrained temporal evolution. Extensive evaluation across four public datasets demonstrates substantial improvements over state-of-the-art methods, with 4.6-4.8% higher accuracy and 6.2-10.2% higher Cohen's Kappa, while maintaining robust cross-subject generalization. The geometric approach reveals meaningful neural patterns consistent with neurophysiological principles, establishing geometric constraints as essential for effective EEG foundation models.

</details>


### [38] [Analysis of heart failure patient trajectories using sequence modeling](https://arxiv.org/abs/2511.16839)
*Falk Dippela,Yinan Yu,Annika Rosengren,Martin Lindgren,Christina E. Lundberg,Erik Aerts,Martin Adiels,Helen Sjöland*

Main category: cs.LG

TL;DR: Llama 和 Mambas 在 EHR 基于临床预测任务上表现出色；在瑞典心力衰竭队列中，Llama 具备最佳判别力和校准性，且对比基线更鲁棒；在相同模型规模下，较小配置也可达到优越性能，且数据效率高（训练数据减少约25%）。基于 ablation 的研究凸显输入分词、模型配置和时间序列预处理的设计选择的重要性；该工作为临床预测领域的模型开发提供了系统性起点与参考。


<details>
  <summary>Details</summary>
Motivation: 系统地评估并比较多种序列模型（Transformers、Transformers++、Mambas）在临床电子病历（EHR）预测任务中的性能与效率，以识别提升性能和数据效率的设计要点。

Method: 在一个大型瑞典心力衰竭队列（N=42,820）上进行实验，覆盖三项一年期预测任务：初次住院后临床不稳定/再住院、初次住院后的死亡、最近一次住院后的死亡。比较六种序列模型，分属三个体系结构类别（Transformers、Transformers++、Mambas），通过对EHR输入序列、架构配置以及时间维度数据预处理的消融来评估影响。评估指标包括判别度、校准以及数据效率等。

Result: Llama 表现出最高的判别力和最佳的校准性，并对所有任务具有鲁棒性，Mambas紧随其后。两种架构均表现出高效的表征学习能力，较小规模的配置甚至超过了部分大规模 Transformer。以相同模型规模比较时，Llama 与 Mambas 的数据需求减少约25%。研究首次提供系统性的输入分词、模型配置与时间数据预处理的消融分析，为临床预测任务中的模型设计提供起点。

Conclusion: 该消融框架清晰揭示了 EHR 基于序列模型的关键设计取舍；研究结果支持在临床预测任务中优先考虑 Llama 或 Mambas，且在数据受限情境下仍能获得良好性能。未来工作应进一步优化输入分词和时间预处理等设计，以提升实际部署的可用性与鲁棒性。

Abstract: Transformers have defined the state-of-the-art for clinical prediction tasks involving electronic health records (EHRs). The recently introduced Mamba architecture outperformed an advanced Transformer (Transformer++) based on Llama in handling long context lengths, while using fewer model parameters. Despite the impressive performance of these architectures, a systematic approach to empirically analyze model performance and efficiency under various settings is not well established in the medical domain. The performances of six sequence models were investigated across three architecture classes (Transformers, Transformers++, Mambas) in a large Swedish heart failure (HF) cohort (N = 42820), providing a clinically relevant case study. Patient data included diagnoses, vital signs, laboratories, medications and procedures extracted from in-hospital EHRs. The models were evaluated on three one-year prediction tasks: clinical instability (a readmission phenotype) after initial HF hospitalization, mortality after initial HF hospitalization and mortality after latest hospitalization. Ablations account for modifications of the EHR-based input patient sequence, architectural model configurations, and temporal preprocessing techniques for data collection. Llama achieves the highest predictive discrimination, best calibration, and showed robustness across all tasks, followed by Mambas. Both architectures demonstrate efficient representation learning, with tiny configurations surpassing other large-scaled Transformers. At equal model size, Llama and Mambas achieve superior performance using 25% less training data. This paper presents a first ablation study with systematic design choices for input tokenization, model configuration and temporal data preprocessing. Future model development in clinical prediction tasks using EHRs could build upon this study's recommendation as a starting point.

</details>


### [39] [Provably Minimum-Length Conformal Prediction Sets for Ordinal Classification](https://arxiv.org/abs/2511.16845)
*Zijian Zhang,Xinyu Chen,Yuanjie Shi,Liyuan Lillian Ma,Zifan Xu,Yan Yan*

Main category: cs.LG

TL;DR: 提出一种模型不可知的序数分类 conformal prediction（ordinal-CP）方法，给出实例级最短覆盖的预测区间，并通过滑动窗口算法实现线性时间复杂度，支持长度正则化以进一步缩小预测集；在四个数据集上相比基线提高预测效率约15%。


<details>
  <summary>Details</summary>
Motivation: 高风险场景（如医学影像与诊断）中，对序数标签的可靠不确定性量化至关重要。现有的序数 CP 多集中于启发式算法或要求模型输出单峰分布，难以给出覆盖-效率的全局权衡且缺乏模型无关、分布无关的性质。本工作旨在提供一个模型不可知、分布无关的序数 CP 框架，能给出实例级的最优预测区间。

Method: 将序数 CP 问题形式化为实例级的最短覆盖问题；提出滑动窗口算法，在标定集上对每个实例给出局部最优解，时间复杂度对标签候选数 K 线性；局部最优性在期望意义上也提升了预测效率。另给出长度正则化变体，通过约束长度来缩小预测集同时保持覆盖性。

Result: 在四个来自不同领域的基准数据集上验证，提出的方法在预测效率上显著优于基线，平均提升约15%。

Conclusion: 本文给出一个模型不可知且分布无关的序数 CP 框架，具备实例级最优的预测区间且具备高效性（线性时间复杂度），通过长度正则化进一步控制预测集大小，适用于需要高质量不确定性量化的序数分类任务。

Abstract: Ordinal classification has been widely applied in many high-stakes applications, e.g., medical imaging and diagnosis, where reliable uncertainty quantification (UQ) is essential for decision making. Conformal prediction (CP) is a general UQ framework that provides statistically valid guarantees, which is especially useful in practice. However, prior ordinal CP methods mainly focus on heuristic algorithms or restrictively require the underlying model to predict a unimodal distribution over ordinal labels. Consequently, they provide limited insight into coverage-efficiency trade-offs, or a model-agnostic and distribution-free nature favored by CP methods. To this end, we fill this gap by propose an ordinal-CP method that is model-agnostic and provides instance-level optimal prediction intervals. Specifically, we formulate conformal ordinal classification as a minimum-length covering problem at the instance level. To solve this problem, we develop a sliding-window algorithm that is optimal on each calibration data, with only a linear time complexity in K, the number of label candidates. The local optimality per instance further also improves predictive efficiency in expectation. Moreover, we propose a length-regularized variant that shrinks prediction set size while preserving coverage. Experiments on four benchmark datasets from diverse domains are conducted to demonstrate the significantly improved predictive efficiency of the proposed methods over baselines (by 15% decrease on average over four datasets).

</details>


### [40] [Sex and age determination in European lobsters using AI-Enhanced bioacoustics](https://arxiv.org/abs/2511.16848)
*Feliciano Pedro Francisco Domingos,Isibor Kennedy Ihianle,Omprakash Kaiwartya,Ahmad Lotfi,Nicola Khan,Nicholas Beaudreau,Amaya Albalat,Pedro Machado*

Main category: cs.LG

TL;DR: 本研究将被动声学监测（PAM）与机器学习/深度学习用于欧洲龙虾（Homarus gammarus）的声音，并对年龄（幼/成）与性别（雄/雌）进行分类，结果在数据集上实现高准确度：年龄分类多数模型>97%，性别分类>93%，显示非侵入性监测和边缘计算在水产养殖与渔业管理中的潜力。


<details>
  <summary>Details</summary>
Motivation: 监测难以观测的水生物种，尤其是龙虾，了解栖息、福利、生殖、性别和年龄对管理与保护的重要性；在水生生物声学领域应用人工智能（AI）进行非侵入式监测与分类；利用龙虾声音（ buzz/carapace vibrations）以识别年龄和性别。

Method: 数据采集于苏格兰Johnshaven，水槽中部署水听器；使用 MFCC 作为声学特征；比较多种模型：深度学习（1D-CNN、1D-DCNN）与六种机器学习模型（SVM、k-NN、Naive Bayes、Random Forest、XGBoost、MLP）；任务为年龄（成人/幼年）和性别（雄性/雌性）分类。

Result: 年龄分类：大多数模型准确率>97%，Naive Bayes为91.31%；性别分类：除Naive Bayes外，其他模型均>93.23%；结果表明监督学习和深度学习能够从龙虾声学信号中提取与年龄、性别相关的特征，具有良好的分类潜力。

Conclusion: 展示了PAM结合AI在海洋生物监测中的潜力，提供一种非侵入式的 lobster 保育、检测与管理的新工具，特别适用于水产养殖与渔业的边缘计算应用。

Abstract: Monitoring aquatic species, especially elusive ones like lobsters, presents challenges. This study focuses on Homarus gammarus (European lobster), a key species for fisheries and aquaculture, and leverages non-invasive Passive Acoustic Monitoring (PAM). Understanding lobster habitats, welfare, reproduction, sex, and age is crucial for management and conservation. While bioacoustic emissions have classified various aquatic species using Artificial Intelligence (AI) models, this research specifically uses H. gammarus bioacoustics (buzzing/carapace vibrations) to classify lobsters by age (juvenile/adult) and sex (male/female).
  The dataset was collected at Johnshaven, Scotland, using hydrophones in concrete tanks. We explored the efficacy of Deep Learning (DL) models (1D-CNN, 1D-DCNN) and six Machine Learning (ML) models (SVM, k-NN, Naive Bayes, Random Forest, XGBoost, MLP). Mel-frequency cepstral coefficients (MFCCs) were used as features.
  For age classification (adult vs. juvenile), most models achieved over 97% accuracy (Naive Bayes: 91.31%). For sex classification, all models except Naive Bayes surpassed 93.23%. These strong results demonstrate the potential of supervised ML and DL to extract age- and sex-related features from lobster sounds. This research offers a promising non-invasive PAM approach for lobster conservation, detection, and management in aquaculture and fisheries, enabling real-world edge computing applications for underwater species.

</details>


### [41] [Better audio representations are more brain-like: linking model-brain alignment with performance in downstream auditory tasks](https://arxiv.org/abs/2511.16849)
*Leonardo Pepino,Pablo Riera,Juan Kamienkowski,Luciana Ferrer*

Main category: cs.LG

TL;DR: 提高任务性能的自监督音频模型，其内部表征更接近听觉皮层的脑表征；优化任务表现并不必然导致与大脑相似的内部表示，但自监督模型在脑信号对齐方面表现最好。


<details>
  <summary>Details</summary>
Motivation: 探究在听觉领域，模型的任务性能提升是否伴随内部表征与脑信号的相似性提升，以及自监督学习在脑-模型对齐中的作用。

Method: 对36种音频模型在两组独立的fMRI数据集上的脑活动进行体素/组分回归、表征相似性分析（RSA）；在HEAREval基准的6项听觉任务上评估模型表现；并分析EnCodecMAE预训练过程中的脑相似性演变。

Result: 最新的自监督音频模型在预测听觉皮层活动方面优于更旧、更专业的模型；模型的整体任务表现与脑表征对齐存在强正相关（HEAREval任务表现与脑对齐相关性显著，r>0.7）；在EnCodecMAE的预训练过程中，脑相似性逐步提升且在早期就已出现，未显式优化该目标但自然而然获得。

Conclusion: 脑样表征可能是从自然音频数据中学习重建信息这一任务的副产物，且实现“脑类似”表征的能力与模型在多任务上的通用性和自监督学习能力相关，这为基于脑-模型对齐的音频模型设计提供线索。

Abstract: Artificial neural networks (ANNs) are increasingly powerful models of brain computation, yet it remains unclear whether improving their task performance also makes their internal representations more similar to brain signals. To address this question in the auditory domain, we quantified the alignment between the internal representations of 36 different audio models and brain activity from two independent fMRI datasets. Using voxel-wise and component-wise regression, and representation similarity analysis (RSA), we found that recent self-supervised audio models with strong performance in diverse downstream tasks are better predictors of auditory cortex activity than older and more specialized models. To assess the quality of the audio representations, we evaluated these models in 6 auditory tasks from the HEAREval benchmark, spanning music, speech, and environmental sounds. This revealed strong positive Pearson correlations ($r>0.7$) between a model's overall task performance and its alignment with brain representations. Finally, we analyzed the evolution of the similarity between audio and brain representations during the pretraining of EnCodecMAE. We discovered that brain similarity increases progressively and emerges early during pretraining, despite the model not being explicitly optimized for this objective. This suggests that brain-like representations can be an emergent byproduct of learning to reconstruct missing information from naturalistic audio data.

</details>


### [42] [Topologic Attention Networks: Attending to Direct and Indirect Neighbors through Gaussian Belief Propagation](https://arxiv.org/abs/2511.16871)
*Marshall Rosenhoover,Huaming Zhang*

Main category: cs.LG

TL;DR: 提出 Topologic Attention Networks，通过学习信息在图中的传播来实现拓扑注意力，从而统一建模局部与全局关系，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: GNNs 受限于局部消息传递，难以捕捉长程依赖；现有方法要么通过连续时间动力学要么使用密集自注意力，计算成本高、扩展性差，迫切需要在不显式成对交互下实现信息流的高效建模。

Method: 引入 topologic attention，这是一种基于概率的信息传播机制，通过学习图中的信息传播路径来实现注意力；不同于传统基于显式成对交互的注意力，拓扑注意力由图的传播过程自发产生，能够统一建模局部与全局关系。

Result: 在所有基线模型上达到SOTA（state-of-the-art）性能；提供开源实现，链接为 https://github.com/Marshall-Rosenhoover/Topologic-Attention-Networks。

Conclusion: 该框架为GNN在处理长程依赖和大规模图数据方面提供了更高效的替代方案，提升表示能力与可扩展性，具有广泛应用潜力。

Abstract: Graph Neural Networks rely on local message passing, which limits their ability to model long-range dependencies in graphs. Existing approaches extend this range through continuous-time dynamics or dense self-attention, but both suffer from high computational cost and limited scalability. We propose Topologic Attention Networks, a new framework that applies topologic attention, a probabilistic mechanism that learns how information should flow through both direct and indirect connections in a graph. Unlike conventional attention that depends on explicit pairwise interactions, topologic attention emerges from the learned information propagation of the graph, enabling unified reasoning over local and global relationships. This method achieves provides state-of-the-art performance across all measured baseline models. Our implementation is available at https://github.com/Marshall-Rosenhoover/Topologic-Attention-Networks.

</details>


### [43] [PersonalizedRouter: Personalized LLM Routing via Graph-based User Preference Modeling](https://arxiv.org/abs/2511.16883)
*Zhongjie Dai,Tao Feng,Jiaxuan You*

Main category: cs.LG

TL;DR: 提出 PersonalizedRouter，一种基于图的个性化LLM选择框架，通过异构图建模用户交互，在多成本/效能仿真和LLM作为评审两种策略下进行评估，并在 PersonaRoute-Bench 上达到显著性能提升与良好少样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM选择多聚焦单一目标（如性能或成本），且难以从交互数据中学习用户的个性化偏好，因此需要一种能够捕捉用户偏好与上下文的选择框架。

Method: 将任务上下文、查询、候选LLM、用户决策等交互数据转化为异构图，利用图结构捕捉查询与最优LLM之间的上下文信息。设计两种评估策略（多成本-效率仿真与 LLM 作为评审）来验证对不同用户的自适应性，并构建包含1,000名模拟用户和10个LLM的 PersonaRoute-Bench。

Result: 实验结果显示，PersonalizedRouter在两种仿真策略下分别领先现有方法15.38%和9.83%，在 PersonaRoute-Bench 的1,000名用户场景中领先最佳方法16.19%和59.69%；且具有较高的效率。该方法在新用户和新LLM上的少样本泛化能力达到完全训练模型性能的64.81%和85.80%。

Conclusion: PersonalizedRouter能够有效捕捉用户偏好与上下文信息，实现个性化的LLM选择，并具备良好的跨用户与跨模型的自适应与泛化能力，具有潜在的实际应用价值。

Abstract: The growing number of Large Language Models (LLMs) with diverse capabilities and response styles provides users with a wider range of choices, which presents challenges in selecting appropriate LLMs, as user preferences vary in terms of performance, cost, and response style. Current LLM selection methods typically optimize for a single fixed objective, such as performance, cost, or a trade-off between them, and fail to learn individual user preferences from interaction data. To address these limitations, we propose PersonalizedRouter, a graph-based framework that models diverse user profiles and performs personalized LLM selection by leveraging interaction data that includes task context, queries, candidate LLMs, and user decisions. To capture contextual information between user queries and optimal LLMs, PersonalizedRouter converts the interaction data into a heterogeneous graph, where the relationships between different types of nodes are represented by edges. To evaluate adaptability across users, we design two strategies: the multi-cost-efficiency simulation strategy and the LLM-as-a-Judge strategy. In addition, we construct PersonaRoute-Bench, a large-scale benchmark with 1,000 simulated users and 10 LLMs. Experimental results show that PersonalizedRouter significantly outperforms existing LLM selection methods and surpasses the strongest methods by a large margin of 15.38% and 9.83% under two simulation strategies. On the PersonaRoute-Bench with 1,000 users, it further surpasses the best methods by 16.19% and 59.69% while maintaining higher efficiency. Moreover, PersonalizedRouter demonstrates strong few-shot generalization, achieving 64.81% and 85.80% of the fully trained model's performance when adapting to new users and new LLMs.

</details>


### [44] [PepEVOLVE: Position-Aware Dynamic Peptide Optimization via Group-Relative Advantage](https://arxiv.org/abs/2511.16912)
*Trieu Nguyen,Hao-Wei Pang,Shasha Feng*

Main category: cs.LG

TL;DR: PepEVOLVE is a dynamic, position-aware framework for macrocyclic peptide lead optimization that learns edit sites and optimizes multiple objectives, outperforming PepINVENT on a Rev-binding macrocycle benchmark.


<details>
  <summary>Details</summary>
Motivation: Macrocyclic peptides offer biologics-like affinity with small-molecule developability, but their vast combinatorial space and multiple objectives make lead optimization challenging, especially when optimal edit sites are unknown.

Method: PepEVOLVE augments pretraining with dynamic masking and CHUCKLES shifting; employs a context-free multi-armed bandit router to identify high-reward residues; couples an evolving optimization algorithm with group-relative advantage to stabilize reinforcement updates.

Result: In silico evaluations show the router concentrates probability on chemically meaningful sites. On a Rev-binding macrocycle benchmark, PepEVOLVE achieved higher mean score (≈0.8 vs 0.6), best candidate score (0.95 vs 0.87), and converged in fewer steps for permeability and lipophilicity under structural constraints, outperforming PepINVENT.

Conclusion: PepEVOLVE provides a practical and reproducible path to peptide lead optimization when edit sites are unknown, enabling more efficient exploration and improved design quality across multiple objectives.

Abstract: Macrocyclic peptides are an emerging modality that combines biologics-like affinity with small-molecule-like developability, but their vast combinatorial space and multi-parameter objectives make lead optimization slow and challenging. Prior generative approaches such as PepINVENT require chemists to pre-specify mutable positions for optimization, choices that are not always known a priori, and rely on static pretraining and optimization algorithms that limit the model's ability to generalize and effectively optimize peptide sequences. We introduce PepEVOLVE, a position-aware, dynamic framework that learns both where to edit and how to dynamically optimize peptides for multi-objective improvement. PepEVOLVE (i) augments pretraining with dynamic masking and CHUCKLES shifting to improve generalization, (ii) uses a context-free multi-armed bandit router that discovers high-reward residues, and (iii) couples a novel evolving optimization algorithm with group-relative advantage to stabilize reinforcement updates. During in silico evaluations, the router policy reliably learns and concentrates probability on chemically meaningful sites that influence the peptide's properties. On a therapeutically motivated Rev-binding macrocycle benchmark, PepEVOLVE outperformed PepINVENT by reaching higher mean scores (approximately 0.8 vs. 0.6), achieving best candidates with a score of 0.95 (vs. 0.87), and converging in fewer steps under the task of optimizing permeability and lipophilicity with structural constraints. Overall, PepEVOLVE offers a practical, reproducible path to peptide lead optimization when optimal edit sites are unknown, enabling more efficient exploration and improving design quality across multiple objectives.

</details>


### [45] [A Hybrid Computational Intelligence Framework for scRNA-seq Imputation: Integrating scRecover and Random Forests](https://arxiv.org/abs/2511.16923)
*Ali Anaissi,Deshao Liu,Yuanzhe Jia,Weidong Huang,Widad Alyassine,Junaid Akram*

Main category: cs.LG

TL;DR: SCR-MF是一个两阶段的单细胞RNA测序填充工作流：先用scRecover进行缺失值检测，再用missForest进行非参数化填充。结果在公开数据集和模拟数据上显示，SCR-MF在大多数场景下具有鲁棒且可解释的性能，常与或优于现有方法，同时保持生物学保真性和透明性。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序存在大量 dropout（断点缺失/零值）问题，难以恢复真实表达信号。需要一种既鲁棒又具可解释性的填充方法，以提高下游分析（如差异表达、聚类、轨迹推断）的可靠性；同时要兼顾计算效率，适用于中等规模数据。

Method: 提出模块化的两阶段工作流SCR-MF：第一阶段基于scRecover进行 principled 的 dropout 检测，识别可能为dropout的零值；第二阶段使用非参数化的missForest对检测出的缺失区域进行填充，以保留非线性关系和复杂信号。

Result: 在公开数据集和模拟数据上，SCR-MF呈现出鲁棒且可解释的填充性能，在大多数场景下与现有填充方法相比达到相当甚至更优的效果，同时维护生物学保真度与分析透明性。对比分析显示在准确性与计算效率之间达到良好平衡，适合中等规模单细胞数据。

Conclusion: SCR-MF提供了一个在准确性、可解释性和效率之间的折衷方案，适用于中等规模的scRNA-seq数据分析，且能在保持生物学合理性的前提下提升下游分析的可靠性。

Abstract: Single-cell RNA sequencing (scRNA-seq) enables transcriptomic profiling at cellular resolution but suffers from pervasive dropout events that obscure biological signals. We present SCR-MF, a modular two-stage workflow that combines principled dropout detection using scRecover with robust non-parametric imputation via missForest. Across public and simulated datasets, SCR-MF achieves robust and interpretable performance comparable to or exceeding existing imputation methods in most cases, while preserving biological fidelity and transparency. Runtime analysis demonstrates that SCR-MF provides a competitive balance between accuracy and computational efficiency, making it suitable for mid-scale single-cell datasets.

</details>


### [46] [CroTad: A Contrastive Reinforcement Learning Framework for Online Trajectory Anomaly Detection](https://arxiv.org/abs/2511.16929)
*Rui Xue,Dan He,Fengmei Jin,Chen Zhang,Xiaofang Zhou*

Main category: cs.LG

TL;DR: 提出 CroTad，基于对比学习与强化学习的无阈值在线轨迹异常检测框架，能够实现子轨迹级与点级的高精度异常检测，对噪声和不规则采样鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有方法多关注整条轨迹异常，依赖阈值，且对不规则采样和噪声敏感，难以获得鲁棒的正常轨迹表征；需要一个能在在线情境下进行细粒度、无需手调阈值的解决方案。

Method: 结合对比学习和深度强化学习，设计一个在线、阈值无关的框架。对比学习用于学习不同轨迹的正常模式，提升鲁棒性和泛化；强化学习的检测模块实现在线打分并可实时识别子轨迹和点级异常；适应噪声和不规则采样。

Result: 在两个真实数据集上进行广泛实验，结果表明框架在多种评估场景下具有良好效果与鲁棒性。

Conclusion: CroTad 能实现细粒度的子轨迹与点级异常检测，降低阈值依赖，具备在线性和对噪声/采样不规则性的鲁棒性，适用于现代 ITS 的实时异常检测。

Abstract: Detecting trajectory anomalies is a vital task in modern Intelligent Transportation Systems (ITS), enabling the identification of unsafe, inefficient, or irregular travel behaviours. While deep learning has emerged as the dominant approach, several key challenges remain unresolved. First, sub-trajectory anomaly detection, capable of pinpointing the precise segments where anomalies occur, remains underexplored compared to whole-trajectory analysis. Second, many existing methods depend on carefully tuned thresholds, limiting their adaptability in real-world applications. Moreover, the irregular sampling of trajectory data and the presence of noise in training sets further degrade model performance, making it difficult to learn reliable representations of normal routes. To address these challenges, we propose a contrastive reinforcement learning framework for online trajectory anomaly detection, CroTad. Our method is threshold-free and robust to noisy, irregularly sampled data. By incorporating contrastive learning, CroTad learns to extract diverse normal travel patterns for different itineraries and effectively distinguish anomalous behaviours at both sub-trajectory and point levels. The detection module leverages deep reinforcement learning to perform online, real-time anomaly scoring, enabling timely and fine-grained identification of abnormal segments. Extensive experiments on two real-world datasets demonstrate the effectiveness and robustness of our framework across various evaluation scenarios.

</details>


### [47] [A novel approach to classification of ECG arrhythmia types with latent ODEs](https://arxiv.org/abs/2511.16933)
*Angelina Yan,Matt L. Sampson,Peter Melchior*

Main category: cs.LG

TL;DR: 通过 latent ODE 建模连续 ECG 波形，并在不同采样频率下构建特征向量，借助梯度提升树实现分类，显示在 360 Hz、90 Hz、45 Hz 下宏观 AUC-ROC 均约 0.98，证明信号保真度下降可通过鲁棒特征与模型来弥补。


<details>
  <summary>Details</summary>
Motivation: 临床高精度的 12 导联心电图在短时点检中易错过间歇性事件；可穿戴设备受电池与带宽限制，采样频率波动且难以进行形态分析。需要一个端到端、对采样率鲁棒的心电事件检测方法，以实现长期监测与小型化设备。

Method: 训练一个潜在ODE（latent ODE）来建模连续心电波形，提取对单通道高频信号鲁棒的特征向量；将初始 360 Hz ECG 下采样为 90 Hz 与 45 Hz，分别构建每个波形的三个潜在向量；再用梯度提升树对这些向量进行分类，并在不同频率下测试鲁棒性。

Result: 在 360 Hz、90 Hz、45 Hz 下的宏观 AUC-ROC 分别约为 0.984、0.978、0.976，表明模型对采样频率的鲁棒性良好。

Conclusion: 该方法揭示了在更低功耗设备上实现高保真形态分析的可行性，有望推动更小型的可穿戴设备用于长期心脏健康监测。

Abstract: 12-lead ECGs with high sampling frequency are the clinical gold standard for arrhythmia detection, but their short-term, spot-check nature often misses intermittent events. Wearable ECGs enable long-term monitoring but suffer from irregular, lower sampling frequencies due to battery constraints, making morphology analysis challenging. We present an end-to-end classification pipeline to address these issues. We train a latent ODE to model continuous ECG waveforms and create robust feature vectors from high-frequency single-channel signals. We construct three latent vectors per waveform via downsampling the initial 360 Hz ECG to 90 Hz and 45 Hz. We then use a gradient boosted tree to classify these vectors and test robustness across frequencies. Performance shows minimal degradation, with macro-averaged AUC-ROC values of 0.984, 0.978, and 0.976 at 360 Hz, 90 Hz, and 45 Hz, respectively, suggesting a way to sidestep the trade-off between signal fidelity and battery life. This enables smaller wearables, promoting long-term monitoring of cardiac health.

</details>


### [48] [ToC: Tree-of-Claims Search with Multi-Agent Language Models](https://arxiv.org/abs/2511.16972)
*Shuyang Yu,Jianan Liang,Hui Hu*

Main category: cs.LG

TL;DR: ToC is a framework that treats patent claim editing as guided search, combining Monte Carlo Tree Search (MCTS) with a two-agent LLM system (EditorAgent and ExaminerAgent) to optimize novelty, scope retention, and coherence; evaluated on 1145 claims with notable improvements over standard LLMs and released as open source.


<details>
  <summary>Details</summary>
Motivation: Manual drafting of patent claims is laborious and inconsistent; conventional LLMs struggle with structured, iterative reasoning needed for precise claim refinement. A guided search with structured critique is proposed to improve quality and consistency.

Method: Tree of Claims (ToC) integrates Monte Carlo Tree Search with a collaborative multi-agent system: an EditorAgent proposes edits grounded in context, and an ExaminerAgent performs structured, chain-of-thought analyses on novelty and prior art. A multi-objective reward function drives search toward maximizing novelty, maintaining scope, and preserving semantic coherence. Evaluations used a benchmark of 1145 claims, supported by ablation studies.

Result: ToC outperforms standard LLMs in zero-shot and few-shot settings, achieving an average composite score improvement of 8%, with improvements up to 9% in certain cases. Extensive experiments and ablations validate efficacy and robustness of generated revisions.

Conclusion: ToC provides a transparent, controllable, and interpretable framework that fuses advanced LLM reasoning with strategic MCTS planning for structured patent claim optimization, and its code is publicly available.

Abstract: Optimizing patent claims is a critical yet challenging task, demanding careful balance between maximizing novelty and preserving legal scope. Manual claim drafting is labor-intensive, costly, and inherently inconsistent, while conventional Large Language Models (LLMs) often lack the structured, iterative reasoning essential for precise claim refinement. To address these challenges, we introduce Tree of Claims (ToC), an innovative framework that redefines claim editing as a guided search problem. ToC synergistically integrates Monte Carlo Tree Search (MCTS) with a collaborative multi-agent system, comprising an LLM-based EditorAgent that proposes contextually grounded edits, and an ExaminerAgent that mimics patent examiner critiques through structured, chain-of-thought analyses of novelty and prior art disclosure. Driven by a carefully designed multi-objective reward function, ToC jointly optimizes novelty, scope retention, and semantic coherence. Experimental evaluation on a benchmark of 1145 claims demonstrates that ToC significantly outperforms standard LLMs in zero-shot and few-shot scenarios, achieving an average composite score improvement of 8\%, and up to 9\% in certain cases. Extensive experiments, including detailed ablation studies, validate ToC's efficacy in generating superior, legally robust claim revisions. Overall, ToC establishes a transparent, controllable, and interpretable methodology that effectively bridges advanced LLM reasoning capabilities with strategic MCTS planning for structured patent claim optimization.The source code is available at https://github.com/ysy2003/ToC.

</details>


### [49] [Convergence and stability of Q-learning in Hierarchical Reinforcement Learning](https://arxiv.org/abs/2511.17351)
*Massimiliano Manenti,Andrea Iannelli*

Main category: cs.LG

TL;DR: 提出 Feudal Q-learning 的收敛性和稳定性分析，给出在特定条件下的收敛性定理，并将更新解释为博弈均衡的一致解，辅以实验验证。


<details>
  <summary>Details</summary>
Motivation: 弥补层级强化学习在理论保障方面与实际效果之间的差距，给出耦合更新的收敛性与稳定性分析，并探索将层级 RL 与博弈论结合的可能性。

Method: 提出 Feudal Q-learning，基于随机近似和常微分方程(ODE)方法推导收敛性与稳定性定理；将更新视为一个定义良好的博弈的均衡点；通过基于 Feudal Q-learning 的实验验证理论结论。

Result: 在给定的条件下证明更新收敛且稳定；更新收敛到一个可解释为定义博弈均衡的点；实验结果支持理论预测。

Conclusion: 为 Feudal RL 提供了 principled 的收敛性与稳定性分析，并引入博弈论视角，实验结果与理论一致，暗示在层级 RL 中可以进一步使用博弈论方法。

Abstract: Hierarchical Reinforcement Learning promises, among other benefits, to efficiently capture and utilize the temporal structure of a decision-making problem and to enhance continual learning capabilities, but theoretical guarantees lag behind practice. In this paper, we propose a Feudal Q-learning scheme and investigate under which conditions its coupled updates converge and are stable. By leveraging the theory of Stochastic Approximation and the ODE method, we present a theorem stating the convergence and stability properties of Feudal Q-learning. This provides a principled convergence and stability analysis tailored to Feudal RL. Moreover, we show that the updates converge to a point that can be interpreted as an equilibrium of a suitably defined game, opening the door to game-theoretic approaches to Hierarchical RL. Lastly, experiments based on the Feudal Q-learning algorithm support the outcomes anticipated by theory.

</details>


### [50] [FIRM: Federated In-client Regularized Multi-objective Alignment for Large Language Models](https://arxiv.org/abs/2511.16992)
*Fatemeh,Nourzad,Amirhossein Roknilamouki,Eylem Ekici,Jia,Liu,Ness B. Shroff*

Main category: cs.LG

TL;DR: FIRM 提出在 Federated Multi-Objective alignment 场景中，通过在客户端本地引入正则化来解决多目标优化的漂移问题，减少对服务器传输的梯度数量，从而实现更高的通信效率，并提供有限时间收敛到 Pareto-stationary 点的理论保证与实际实验的有效性，且支持通过偏好权衡目标以获得 Pareto frontier 的平滑切换。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型的人类价值对齐中，需要在多目标之间进行权衡（如有用性与无害性），但集中式训练成本高且存在数据隐私风险。现有的 Federated Multi-Objective Optimization 面临严重的通信瓶颈，依赖多梯度传输难以扩展到大模型场景。因此需要一种在客户端就完成多目标优化并降低通信需求的解决方案。

Method: FIRM 在每个客户端上解决一个带正则化项的本地多目标优化问题，通过在客户端直接缓解 client disagreement drift 的正则化，取消了在服务器端传输多梯度的需求。各客户端只需传输一组经过适应的参数，显著提升通信效率。理论上，算法收敛到 Pareto-stationary 点，并给出在该设定中的首次有限时间收敛保证。

Result: 实验结果显示 FIRM 使训练动态更平滑、客户端漂移更低、在目标权衡上较基线有改进。本文还提出一种将目标偏好纳入的机制，并给出 Pareto 图，证明在指定偏好下，FIRM 能平滑地在多目标之间切换权衡。

Conclusion: FIRM 在降低通信成本的同时实现对齐效果的改进，具有理论上的收敛性保证和实证证据，适用于大模型场景下的联邦多目标对齐问题，且提供了将偏好纳入以控制权衡的实用方法。

Abstract: Aligning Large Language Models (LLMs) with human values often involves balancing multiple, conflicting objectives such as helpfulness and harmlessness. Training these models is computationally intensive, and centralizing the process raises significant data privacy concerns. Federated Learning (FL) offers a compelling alternative, but existing Federated Multi-Objective Optimization (FMOO) methods face severe communication bottlenecks as their reliance on transmitting multiple gradients to a server is unscalable for large models. We introduce FIRM (Federated In-client Regularized Multi-objective alignment), a novel algorithm that achieves both client disagreement drift mitigation and communication efficiency. In FIRM, each client locally solves a regularized multi-objective optimization problem. By directly mitigating client disagreement drift through in-client regularization, our method eliminates the need for the multi-gradient transmissions common in prior works. Consequently, clients need only to transmit a single set of adapted parameters, maintaining high communication efficiency. We prove that our algorithm converges to Pareto-stationary points and, to our knowledge, provide the first finite-time convergence guarantees for this federated multi-objective alignment setting. Empirically, we show that FIRM leads to smoother training dynamics, reduced client disagreement drift, and improved reward trade-offs compared to baselines. We further propose a method to incorporate a preference over the objectives and report empirical Pareto plots, demonstrating that FIRM can smoothly adapt trade-offs between objectives in response to specified preferences.

</details>


### [51] [Mask the Redundancy: Evolving Masking Representation Learning for Multivariate Time-Series Clustering](https://arxiv.org/abs/2511.17008)
*Zexi Tan,Xiaopeng Luo,Yunlin Liu,Yiqun Zhang*

Main category: cs.LG

TL;DR: 提出一种自适应掩码与多视角学习的MTS聚类框架EMTC，通过IVM与MEV模块提升聚类性能。


<details>
  <summary>Details</summary>
Motivation: MTS聚类受冗余信息（如稳态/零输出）影响，导致对判别性时间戳关注不足；现有掩码多为独立预处理，难以与学习过程动态耦合。

Method: 提出EMTC，包含重要性感知逐变掩码(IVM)和多内生视角表示学习(MEV)两大模块。IVM自适应引导模型学习更具判别性的表示；MEV通过重构与对比学习实现多视角互补，防止掩码过早收敛，并与聚类目标联合端到端优化。

Result: 在15个真实基准数据集上与8个SOTA方法相比，平均提升4.85%。

Conclusion: EMTC通过自适应掩码和多视角学习的协同，提高MTS聚类的泛化与性能，具有较强的实验优势。

Abstract: Multivariate Time-Series (MTS) clustering discovers intrinsic grouping patterns of temporal data samples. Although time-series provide rich discriminative information, they also contain substantial redundancy, such as steady-state machine operation records and zero-output periods of solar power generation. Such redundancy diminishes the attention given to discriminative timestamps in representation learning, thus leading to performance bottlenecks in MTS clustering. Masking has been widely adopted to enhance the MTS representation, where temporal reconstruction tasks are designed to capture critical information from MTS. However, most existing masking strategies appear to be standalone preprocessing steps, isolated from the learning process, which hinders dynamic adaptation to the importance of clustering-critical timestamps. Accordingly, this paper proposes the Evolving-masked MTS Clustering (EMTC) method, with its model architecture composed of Importance-aware Variate-wise Masking (IVM) and Multi-Endogenous Views (MEV) representation learning modules. IVM adaptively guides the model in learning more discriminative representations for clustering, while the MEV-based reconstruction and contrastive learning pathways enhance the generalization. That is, the MEV reconstruction facilitates multi-perspective complementary to prevent the masking from premature convergence, and the clustering-guided contrastive learning facilitates the joint optimization of representation and clustering. Extensive experiments on 15 real benchmark datasets demonstrate the superiority of EMTC in comparison with eight SOTA methods, where the EMTC achieves an average improvement of 4.85% over the strongest baselines.

</details>


### [52] [Energy Scaling Laws for Diffusion Models: Quantifying Compute and Carbon Emissions in Image Generation](https://arxiv.org/abs/2511.17031)
*Aniketh Iyengar,Jiaqi Han,Boris Ruf,Vincent Grari,Marcin Detyniecki,Stefano Ermon*

Main category: cs.LG

TL;DR: 提出基于Kaplan缩放定律的扩散模型能耗预测, 依据FLOPs预测GPU能耗, 并在多模型/多硬件上验证。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的能源消耗日益增大，现有方法多聚焦架构或硬件优化，缺乏跨配置和硬件的能耗预测的原理性方法。

Method: 将Kaplan扩展法则应用于扩散模型推理，分解为文本编码、迭代去噪、解码，假设去噪因重复推理步数而主导能耗；在四个模型和三种GPU上进行广泛实验，覆盖分辨率、精度、步数、指南设置等配置。

Result: 能耗预测在单一架构内R^2>0.9，跨架构保持较高的等级相关性，能对未见的模型-硬件组合进行可靠估算；揭示推理的计算瓶颈为主导能耗。

Conclusion: 提供可持续AI部署与碳足迹估算的能耗量化基础，并证实扩散推理为计算瓶颈驱动的特性。

Abstract: The rapidly growing computational demands of diffusion models for image generation have raised significant concerns about energy consumption and environmental impact. While existing approaches to energy optimization focus on architectural improvements or hardware acceleration, there is a lack of principled methods to predict energy consumption across different model configurations and hardware setups. We propose an adaptation of Kaplan scaling laws to predict GPU energy consumption for diffusion models based on computational complexity (FLOPs). Our approach decomposes diffusion model inference into text encoding, iterative denoising, and decoding components, with the hypothesis that denoising operations dominate energy consumption due to their repeated execution across multiple inference steps. We conduct comprehensive experiments across four state-of-the-art diffusion models (Stable Diffusion 2, Stable Diffusion 3.5, Flux, and Qwen) on three GPU architectures (NVIDIA A100, A4000, A6000), spanning various inference configurations including resolution (256x256 to 1024x1024), precision (fp16/fp32), step counts (10-50), and classifier-free guidance settings. Our energy scaling law achieves high predictive accuracy within individual architectures (R-squared > 0.9) and exhibits strong cross-architecture generalization, maintaining high rank correlations across models and enabling reliable energy estimation for unseen model-hardware combinations. These results validate the compute-bound nature of diffusion inference and provide a foundation for sustainable AI deployment planning and carbon footprint estimation.

</details>


### [53] [Step-E: A Differentiable Data Cleaning Framework for Robust Learning with Noisy Labels](https://arxiv.org/abs/2511.17040)
*Wenzhang Du*

Main category: cs.LG

TL;DR: Step-E is an online curriculum learning framework that integrates sample selection with model training by progressively excluding high-loss samples during training, improving robustness to noisy labels and outliers.


<details>
  <summary>Details</summary>
Motivation: Training data collected in the wild often contain noisy labels and outliers, which degrade deep network performance. Traditional two-stage cleaning pipelines do not exploit feedback from the downstream model or adapt to unknown noise patterns.

Method: At each epoch, Step-E ranks samples by loss and gradually increases the fraction of high-loss examples excluded from gradient updates after a brief warm-up, creating an online curriculum that focuses on easy, consistent examples and eventually ignores persistent outliers.

Result: On CIFAR-100N, ResNet-18 accuracy improves from 43.3%±0.7% to 50.4%±0.9%, outperforming loss truncation, self-paced learning, and one-shot filtering, approaching clean-label oracle at 60.5%±0.2%. On CIFAR-10N (aggre), Step-E improves over the noisy baseline (85.3% vs. 83.9%) and nearly matches the clean-label oracle (85.9%), with moderate training-time overhead.

Conclusion: Step-E effectively fuses sample selection and model optimization into a unified, adaptive training framework that yields robustness to noisy labels and outliers and achieves near-oracle performance on standard noisy-label benchmarks.

Abstract: Training data collected in the wild often contain noisy labels and outliers that substantially degrade the performance and reliability of deep neural networks. While data cleaning is commonly applied as a separate preprocessing stage, such two-stage pipelines neither fully exploit feedback from the downstream model nor adapt to unknown noise patterns. We propose Step-E, a simple framework that integrates sample selection and model learning into a single optimization process. At each epoch, Step-E ranks samples by loss and gradually increases the fraction of high-loss examples that are excluded from gradient updates after a brief warm-up stage, yielding an online curriculum that focuses on easy and consistent examples and eventually ignores persistent outliers. On CIFAR-100N, Step-E improves the test accuracy of a ResNet-18 model from 43.3% (+/- 0.7%) to 50.4% (+/- 0.9%), clearly outperforming loss truncation, self-paced learning, and one-shot filtering while approaching the clean-label oracle at 60.5% (+/- 0.2%). On CIFAR-10N (aggre), Step-E also improves over the noisy baseline (85.3% vs. 83.9%) and nearly matches the clean-label oracle (85.9%), with only moderate training-time overhead.

</details>


### [54] [Hash Collisions in Molecular Fingerprints: Effects on Property Prediction and Bayesian Optimization](https://arxiv.org/abs/2511.17078)
*Walter Virany,Austin Tripp*

Main category: cs.LG

TL;DR: 在分子指纹中，精确指纹相比标准压缩指纹可略有提升预测准确性，但对贝叶斯优化的影响不显著。


<details>
  <summary>Details</summary>
Motivation: 哈希冲突导致子结构表征混叠，可能影响分子相似性与下游预测，因此检验是否采用精确指纹能提高准确性。

Method: 在 DOCKSTRING 数据集的五个分子性质预测基准上，对比精确指纹与常用压缩指纹在高斯过程模型下的表现，评估预测准确性和贝叶斯优化性能。

Result: 在性质预测上，精确指纹带来小幅但一致的提升；在贝叶斯优化中未观察到显著性能改进。

Conclusion: 精确指纹能缓解哈希冲突带来的信息损失，并对某些任务有益，但在贝叶斯优化等探索性任务中的实用收益有限，需要权衡计算成本。

Abstract: Molecular fingerprinting methods use hash functions to create fixed-length vector representations of molecules. However, hash collisions cause distinct substructures to be represented with the same feature, leading to overestimates in molecular similarity calculations. We investigate whether using exact fingerprints improves accuracy compared to standard compressed fingerprints in molecular property prediction and Bayesian optimization where the underlying predictive model is a Gaussian process. We find that using exact fingerprints yields a small yet consistent improvement in predictive accuracy on five molecular property prediction benchmarks from the DOCKSTRING dataset. However, these gains did not translate to significant improvements in Bayesian optimization performance.

</details>


### [55] [Geometric-Disentangelment Unlearning](https://arxiv.org/abs/2511.17100)
*Duo Zhou,Yuji Zhang,Tianxin Wei,Ruizhong Qiu,Ke Yang,Xiao Lin,Cheng Qian,Jingrui He,Hanghang Tong,Heng Ji,Huan Zhang*

Main category: cs.LG

TL;DR: 提出 Geometric-disentanglement Unlearning (GU)，通过将遗忘梯度更新分解为相对于 retain 空间的切向分量与法向分量，只使用法向分量，以最小化对 retain 集合性能的影响；在信任域预算下，投影方向在一阶 retain 不变移动中是最优的，并给出联合遗忘-保留优化的最优投影方向；该方法可插拔于现有梯度自适应的遗忘方法，实现在 TOFU、MUSE、WMDP 三个基准上的一致改进。


<details>
  <summary>Details</summary>
Motivation: 机器遗忘面临遗忘效果与对保留集性能的保留之间的权衡；现有方法缺乏对“为什么遗忘更新会损害保留知识”的正式分析；需要一个理论上可信且简单的解法以减少副作用并提供可保证的表现。

Method: 基于对保留集损失的一阶分析，提出等价关系：若更新方向与保留梯度张成的子空间正交，则保留损失在一阶内保持不变（retain-invariant）。将遗忘更新分解为相对于保留空间的切向分量和法向分量，GU 仅执行法向分量。给出在信任域预算下，投影到法向分量的方向在一阶 retain-invariant 移动中是最优的，并导出联合遗忘-保留更新的最优投影方向。该方法为一种“即插即用”的改进，可与现有梯度遗忘方法结合以降低副作用。

Result: 在 TOFU、MUSE、WMDP 三个基准上，GU 对多种方法均实现了稳定的改进，表明从几何角度对更新进行去耦合的策略具备普适性和有效性。

Conclusion: GU 提供了一个理论上可证明、实现简单的框架，通过对更新进行几何去耦合（切向与法向）来降低遗忘对保留知识的负面影响，并且在实际基准上具有可观的改进，且可作为现有梯度遗忘方法的插件式改进。

Abstract: Machine unlearning, the removal of a training subset's influence from a deployed model, is critical for privacy preservation and model reliability, yet gradient ascent on forget samples often harms retained knowledge. Existing approaches face a persistent tradeoff between effective forgetting and preservation on the retain set. While previous methods provide useful heuristics, they often lack a formal analysis on how exactly forgetting updates harm retained knowledge, and whether the side effects can be removed with theoretical guarantees. To explore a theoretically sound and simple solution, we start from the first principle on how performance on the retain set is actually affected: a first-order analysis of the local change of the retain loss under small parameter updates during model training. We start from a crisp equivalence: the retain loss is unchanged to first order iff the update direction is orthogonal to the subspace spanned by retain gradients ("retain-invariant"). This identifies the entangled component as the tangential part of forget update within the retain-gradient subspace, and characterizes disentanglement as orthogonality. Guided by this, we propose the Geometric-disentanglement Unlearning (GU) that decomposes any candidate forget gradient update into tangential and normal components to retain space and executes only the normal component. Under a standard trust-region budget, the projected direction aligned with the raw forget gradient is optimal among all first-order retain-invariant moves, and we also derive the optimal projected direction for joint forget-retain updating objectives. Our method is plug-and-play and can be attached to existing gradient-based unlearning procedures to mitigate side effects. GU achieves consistent improvement on various methods across three benchmarks TOFU, MUSE, and WMDP.

</details>


### [56] [Four decades of circumpolar super-resolved satellite land surface temperature data](https://arxiv.org/abs/2511.17134)
*Sonia Dupuis,Nando Metzger,Konrad Schindler,Frank Göttsche,Stefan Wunderle*

Main category: cs.LG

TL;DR: 提出了一项将AVHRR GAC到1 km的深度学习超分辨模型，生成42年的全亚 Arctic LST数据集，分辨率提升到1千米并半日两次观测，用以改进对永久冻土、近地面温度与格陵兰冰盖表面质量平衡的研究，并具备对未来任务的适应性。


<details>
  <summary>Details</summary>
Motivation: 需要提高AVHRR时间序列的空间分辨率以分析北极地区的永久冻土动态、陆表过程与气候趋势；GAC分辨率限制了对细尺度过程的探测，且需要在MODIS之前的历史阶段实现高分辨率的温度表征以支持长期变率检测与数据连续性。

Method: 提出一种基于深度各向异性扩散的超分辨模型，将MODIS LST用作高分辨率参考，在输入为粗分辨率下采样、输出为原生分辨率的条件下进行训练；同时融入高分辨率土地覆被、数字高程和植被高度图等辅助信息，输出1公里、每日两次的全亚 Arctic LST数据，并覆盖四十余年。

Result: 得到一个42年的1 km分辨率、每日两次的全亚 Arctic LST数据集，显著提升对永久冻土、近地面气温重建和格陵兰冰盖表面质量平衡的建模能力，并提供了在MODIS之前时期的气候监测能力，同时为未来卫星任务提供可迁移的热红外数据记录连续性框架。

Conclusion: 该数据集扩大了高分辨率陆表温度在气候研究中的应用前景，支撑高分辨率对比分析与历史时期的温度研究，并具备扩展到未来观测任务和其他热红外数据记录的潜力。

Abstract: Land surface temperature (LST) is an essential climate variable (ECV) crucial for understanding land-atmosphere energy exchange and monitoring climate change, especially in the rapidly warming Arctic. Long-term satellite-based LST records, such as those derived from the Advanced Very High Resolution Radiometer (AVHRR), are essential for detecting climate trends. However, the coarse spatial resolution of AVHRR's global area coverage (GAC) data limit their utility for analyzing fine-scale permafrost dynamics and other surface processes in the Arctic. This paper presents a new 42 years pan-Arctic LST dataset, downscaled from AVHRR GAC to 1 km with a super-resolution algorithm based on a deep anisotropic diffusion model. The model is trained on MODIS LST data, using coarsened inputs and native-resolution outputs, guided by high-resolution land cover, digital elevation, and vegetation height maps. The resulting dataset provides twice-daily, 1 km LST observations for the entire pan-Arctic region over four decades. This enhanced dataset enables improved modelling of permafrost, reconstruction of near-surface air temperature, and assessment of surface mass balance of the Greenland Ice Sheet. Additionally, it supports climate monitoring efforts in the pre-MODIS era and offers a framework adaptable to future satellite missions for thermal infrared observation and climate data record continuity.

</details>


### [57] [Reconstruction of Surface EMG Signal using IMU data for Upper Limb Actions](https://arxiv.org/abs/2511.17200)
*Shubhranil Basak,Mada Hemanth,Madhav Rao*

Main category: cs.LG

TL;DR: 提出一种基于 Sliding-Window-Wave-Net 的深度学习方法，从 6 轴 IMU 数据合成归一化的表面肌电信号（sEMG），实现对肌肉激活的时序和形状的预测，峰值振幅略有低估，但时序保真度高，适用于运动意图检测。


<details>
  <summary>Details</summary>
Motivation: 由于 sEMG 噪声大且获取困难，IMU 提供了稳健的可穿戴替代方案；将 IMU 数据映射回 sEMG 可用于在假肢控制和康复生物反馈中的肌肉意图检测。

Method: 在1 kHz采样的同时记录 sEMG 与 6 轴IMU 数据，提出基于 dilated causal 卷积的 Sliding-Window-Wave-Net，将 IMU 序列映射到归一化的 sEMG 信号。

Result: 模型能够预测肌肉激活的时序和大致形状。峰值振幅通常被低估，但具有较高的时间保真度。

Conclusion: 该方法证明了利用 IMU 推断肌肉意图的可行性，适用于假肢控制与康复生物反馈，但需要改进峰值幅度的定量精度。

Abstract: Surface Electromyography (sEMG) provides vital insights into muscle function, but it can be noisy and challenging to acquire. Inertial Measurement Units (IMUs) provide a robust and wearable alternative to motion capture systems. This paper investigates the synthesis of normalized sEMG signals from 6-axis IMU data using a deep learning approach. We collected simultaneous sEMG and IMU data sampled at 1~KHz for various arm movements. A Sliding-Window-Wave-Net model, based on dilated causal convolutions, was trained to map the IMU data to the sEMG signal. The results show that the model successfully predicts the timing and general shape of muscle activations. Although peak amplitudes were often underestimated, the high temporal fidelity demonstrates the feasibility of using this method for muscle intent detection in applications such as prosthetics and rehabilitation biofeedback.

</details>


### [58] [Generating transition states of chemical reactions via distance-geometry-based flow matching](https://arxiv.org/abs/2511.17229)
*Yufei Luo,Xiang Gu,Jian Sun*

Main category: cs.LG

TL;DR: TS-DFM提出了一种基于距离几何的流匹配框架，用以从反应物与产物预测转变态（TS），并通过TSDVNet学习速度场生成TS几何；在Transition1X上优于React-OT约30%的结构精度，提升CI-NEB初始结构质量及收敛速度，并能发现替代反应路径，且在RGD1上具备对未知分子和反应类型的良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 转变态对理解反应机理至关重要，但获取和计算都非常困难，因此需要高效、准确的TS预测方法来加速反应探索与路径优化。

Method: 在分子距离几何空间中进行流匹配，显式刻画反应中原子间距离的动态变化；设计TSDVNet来学习生成TS几何的速度场；将预测的TS作为CI-NEB的高质量初始结构；在Transition1X和RGD1数据集上进行评估；与现有方法React-OT比较。

Result: 在Transition1X数据集上，比React-OT在结构精度上提升约30%；预测的TS显著加速CI-NEB的收敛并能揭示替代路径（包括潜在的能垒更低的TS）；在RGD1上展示较强的泛化能力，能够处理未见分子和反应类型。

Conclusion: TS-DFM提供高质量、可泛化的TS预测，显著降低反应路径探索的计算成本，提升初始结构质量并有望发现更优反应路径，对化学反应机理研究具有潜在广泛应用。

Abstract: Transition states (TSs) are crucial for understanding reaction mechanisms, yet their exploration is limited by the complexity of experimental and computational approaches. Here we propose TS-DFM, a flow matching framework that predicts TSs from reactants and products. By operating in molecular distance geometry space, TS-DFM explicitly captures the dynamic changes of interatomic distances in chemical reactions. A network structure named TSDVNet is designed to learn the velocity field for generating TS geometries accurately. On the benchmark dataset Transition1X, TS-DFM outperforms the previous state-of-the-art method React-OT by 30\% in structural accuracy. These predicted TSs provide high-quality initial structures, accelerating the convergence of CI-NEB optimization. Additionally, TS-DFM can identify alternative reaction paths. In our experiments, even a more favorable TS with lower energy barrier is discovered. Further tests on RGD1 dataset confirm its strong generalization ability on unseen molecules and reaction types, highlighting its potential for facilitating reaction exploration.

</details>


### [59] [FlexiFlow: decomposable flow matching for generation of flexible molecular ensemble](https://arxiv.org/abs/2511.17249)
*Riccardo Tedoldi,Ola Engkvist,Patrick Bryant,Hossein Azizpour,Jon Paul Janet,Alessandro Tibo*

Main category: cs.LG

TL;DR: FlexiFlow扩展流式匹配模型，联合采样分子及多构象，获得高保真且多样的分子及构象集合，并可迁移到蛋白质条件下的配体生成，达到或接近最新的分子生成与构象覆盖性能。


<details>
  <summary>Details</summary>
Motivation: 分子构象决定性质及结合能力；现有的3D去新/扩散模型多仅生成单一构象，无法直接评估热力学性质及配体-目标相互作用的多样性；需要高效的多构象采样以改进药物设计和预测。

Method: 提出FlexiFlow架构，在保持等变性与置换不变性的前提下，扩展为联合采样分子与多构象的流式/流量模型。使用QM9与GEOM Drugs数据集进行验证，展示生成有效、无应变、唯一且新颖的分子，并捕捉构象多样性；推理时间显著低于物理基方法。模型还能成功迁移到蛋白质条件的配体生成任务，即使数据集中只有静态口袋信息。

Result: 在分子生成任务上达到或接近状态-of-the-art；生成的分子在有效性、无应变性、唯一性和新颖性方面表现出色，且能捕捉构象多样性。所生成的构象集合对比物理基方法具有相当的覆盖度，同时推理时间更短；并实现对蛋白质条件配体生成的有效迁移。

Conclusion: 证明联合生成分子和多构象的FlexiFlow是可行且高效的，提供丰富的构象信息以评估热力学性质，且具备跨任务迁移能力，适合提高药物发现流程的预测与筛选效率。

Abstract: Sampling useful three-dimensional molecular structures along with their most favorable conformations is a key challenge in drug discovery. Current state-of-the-art 3D de-novo design flow matching or diffusion-based models are limited to generating a single conformation. However, the conformational landscape of a molecule determines its observable properties and how tightly it is able to bind to a given protein target. By generating a representative set of low-energy conformers, we can more directly assess these properties and potentially improve the ability to generate molecules with desired thermodynamic observables. Towards this aim, we propose FlexiFlow, a novel architecture that extends flow-matching models, allowing for the joint sampling of molecules along with multiple conformations while preserving both equivariance and permutation invariance. We demonstrate the effectiveness of our approach on the QM9 and GEOM Drugs datasets, achieving state-of-the-art results in molecular generation tasks. Our results show that FlexiFlow can generate valid, unstrained, unique, and novel molecules with high fidelity to the training data distribution, while also capturing the conformational diversity of molecules. Moreover, we show that our model can generate conformational ensembles that provide similar coverage to state-of-the-art physics-based methods at a fraction of the inference time. Finally, FlexiFlow can be successfully transferred to the protein-conditioned ligand generation task, even when the dataset contains only static pockets without accompanying conformations.

</details>


### [60] [Enforcing governing equation constraints in neural PDE solvers via training-free projections](https://arxiv.org/abs/2511.17258)
*Omer Rochman,Gilles Louppe*

Main category: cs.LG

TL;DR: 训练无关的后处理投影（非线性优化投影与局部线性化投影）显著降低神经PDE解的约束违规并提升精度。


<details>
  <summary>Details</summary>
Motivation: 神经PDE求解器在求解过程中常违反支配方程的约束；线性约束可以容易投影，但许多约束是非线性的且在动力PDE中会产生随时间的长程依赖，使得投影变得困难。需要一种无需额外训练的后处理方法来修正近似解。

Method: 评估两种训练-free、事后投影：一种是基于非线性优化的投影，将近似解投影到可行集；另一种是基于局部线性化的投影，利用雅可比-向量积（JVP）和向量-雅可比积（VJP）实现投影。对具有代表性的PDE进行分析比较。

Result: 两种投影都显著降低了约束违规，并在相对于物理信息基线的情况下提高了解的精度。

Conclusion: 训练-free的后处理投影对神经PDE求解器的约束满足与准确性具有明显提升，局部线性化投影在存在长时依赖的动力PDE场景中尤具潜力。

Abstract: Neural PDE solvers used for scientific simulation often violate governing equation constraints. While linear constraints can be projected cheaply, many constraints are nonlinear, complicating projection onto the feasible set. Dynamical PDEs are especially difficult because constraints induce long-range dependencies in time. In this work, we evaluate two training-free, post hoc projections of approximate solutions: a nonlinear optimization-based projection, and a local linearization-based projection using Jacobian-vector and vector-Jacobian products. We analyze constraints across representative PDEs and find that both projections substantially reduce violations and improve accuracy over physics-informed baselines.

</details>


### [61] [Automobile demand forecasting: Spatiotemporal and hierarchical modeling, life cycle dynamics, and user-generated online information](https://arxiv.org/abs/2511.17275)
*Tom Nahrendorf,Stefan Minner,Helfried Binder,Richard Zinck*

Main category: cs.LG

TL;DR: 本研究在多产品、多市场及多层级结构下，结合点与概率预测，采用LightGBM集成、分位数回归与MILP调和，实现可操作的月度汽车需求预测。


<details>
  <summary>Details</summary>
Motivation: 面对高产品多样性、数据稀疏及市场波动，需在战略与运营层面实现多层级、可解释且可执行的需求预测。

Method: 使用多市场的 pooled training LightGBM 集成、分位数回归，以及用于层级调和的混合整数线性规划；对短期与中期需求进行预测并辅以Shapley分解分析。

Result: 发现时空依赖及四舍五入偏差显著影响预测精度，整数预测对运营可执行性重要；在线行为数据在细粒度水平显著提高预测准确性；短期需求受生命周期、自回归动量与运营信号影响，中期需求受前瞻性驱动（如在线参与、规划目标、竞争信号）。

Conclusion: 在实践中应重视整数化预测与在线行为数据的集成，实施合适的层级调和以考虑时空依赖，并在不同层级采用一致的预测框架以提升整体准确性与可执行性。

Abstract: Premium automotive manufacturers face increasingly complex forecasting challenges due to high product variety, sparse variant-level data, and volatile market dynamics. This study addresses monthly automobile demand forecasting across a multi-product, multi-market, and multi-level hierarchy using data from a German premium manufacturer. The methodology combines point and probabilistic forecasts across strategic and operational planning levels, leveraging ensembles of LightGBM models with pooled training sets, quantile regression, and a mixed-integer linear programming reconciliation approach. Results highlight that spatiotemporal dependencies, as well as rounding bias, significantly affect forecast accuracy, underscoring the importance of integer forecasts for operational feasibility. Shapley analysis shows that short-term demand is reactive, shaped by life cycle maturity, autoregressive momentum, and operational signals, whereas medium-term demand reflects anticipatory drivers such as online engagement, planning targets, and competitive indicators, with online behavioral data considerably improving accuracy at disaggregated levels.

</details>


### [62] [SAVeD: Semantic Aware Version Discovery](https://arxiv.org/abs/2511.17298)
*Artem Frenk,Roee Shraga*

Main category: cs.LG

TL;DR: SAVeD is a semantic-aware version detection framework for datasets using contrastive learning to identify dataset versions without metadata, achieving high accuracy and separation on unseen tables across five datasets.


<details>
  <summary>Details</summary>
Motivation: Address the labor-intensive, metadata-free dataset version identification problem and capture semantic similarities between dataset versions rather than relying on labels or integration-based assumptions.

Method: A modified SimCLR pipeline that creates augmented table views via random transformations (e.g., row deletion, encoding perturbations). These views are encoded with a custom transformer, then contrasted in latent space to pull together views of the same dataset and push apart views from different datasets.

Result: SAVeD achieves high validation accuracy and strong separation on five Semantic Versioning in Databases Benchmark datasets, performing well on unseen tables and surpassing baseline methods like Starmie.

Conclusion: The approach demonstrates effective, metadata-free version detection and semantic discrimination of dataset versions, with competitive or superior performance compared to prior methods, suggesting practical utility in reducing manual labor in version tracking.

Abstract: Our work introduces SAVeD (Semantically Aware Version Detection), a contrastive learning-based framework for identifying versions of structured datasets without relying on metadata, labels, or integration-based assumptions. SAVeD addresses a common challenge in data science of repeated labor due to a difficulty of similar work or transformations on datasets. SAVeD employs a modified SimCLR pipeline, generating augmented table views through random transformations (e.g., row deletion, encoding perturbations). These views are embedded via a custom transformer encoder and contrasted in latent space to optimize semantic similarity. Our model learns to minimize distances between augmented views of the same dataset and maximize those between unrelated tables. We evaluate performance using validation accuracy and separation, defined respectively as the proportion of correctly classified version/non-version pairs on a hold-out set, and the difference between average similarities of versioned and non-versioned tables (defined by a benchmark, and not provided to the model). Our experiments span five canonical datasets from the Semantic Versioning in Databases Benchmark, and demonstrate substantial gains post-training. SAVeD achieves significantly higher accuracy on completely unseen tables in, and a significant boost in separation scores, confirming its capability to distinguish semantically altered versions. Compared to untrained baselines and prior state-of-the-art dataset-discovery methods like Starmie, our custom encoder achieves competitive or superior results.

</details>


### [63] [Self-supervised denoising of raw tomography detector data for improved image reconstruction](https://arxiv.org/abs/2511.17312)
*Israt Jahan Tulin,Sebastian Starke,Dominic Windisch,André Bieberle,Peter Steinbach*

Main category: cs.LG

TL;DR: 自监督深度学习去噪在超快电子束X射线CT中提升探测数据的信噪比与重建图像质量，优于非学习方法。


<details>
  <summary>Details</summary>
Motivation: 由于极短的测量时间导致探测数据噪声高、重建伪影多，限制图像质量；需要更有效的去噪策略以提升成像性能。

Method: 研究了两种自监督深度学习去噪方法对原始探测数据进行去噪，并与一种非学习型去噪方法进行对比。

Result: 深度学习去噪方法提升了探测数据的信噪比，并在重建图像上取得了一致的改进，且优于非学习方法。

Conclusion: 自监督深度学习去噪在超快电子束X射线CT中具有潜在优势，可显著提升数据及图像质量，并优于传统非学习方法。

Abstract: Ultrafast electron beam X-ray computed tomography produces noisy data due to short measurement times, causing reconstruction artifacts and limiting overall image quality. To counteract these issues, two self-supervised deep learning methods for denoising of raw detector data were investigated and compared against a non-learning based denoising method. We found that the application of the deep-learning-based methods was able to enhance signal-to-noise ratios in the detector data and also led to consistent improvements of the reconstructed images, outperforming the non-learning based method.

</details>


### [64] [ReBaPL: Repulsive Bayesian Prompt Learning](https://arxiv.org/abs/2511.17339)
*Yassir Bendou,Omar Ezzahir,Eduardo Fernandes Montesuma,Gabriel Mahuas,Victoria Shevchenko,Mike Gartrell*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Prompt learning has emerged as an effective technique for fine-tuning large-scale foundation models for downstream tasks. However, conventional prompt tuning methods are prone to overfitting and can struggle with out-of-distribution generalization. To address these limitations, Bayesian prompt learning has been proposed, which frames prompt optimization as a Bayesian inference problem to enhance robustness. This paper introduces Repulsive Bayesian Prompt Learning (ReBaPL), a novel method for Bayesian prompt learning, designed to efficiently explore the complex and often multimodal posterior landscape of prompts. Our method integrates a cyclical step-size schedule with a stochastic gradient Hamiltonian Monte Carlo (SGHMC) algorithm, enabling alternating phases of exploration to discover new modes, and exploitation to refine existing modes. Furthermore, we introduce a repulsive force derived from a potential function over probability metrics (including Maximum Mean Discrepancy and Wasserstein distance) computed on the distributions of representations produced by different prompts. This representation-space repulsion diversifies exploration and prevents premature collapse to a single mode. Our approach allows for a more comprehensive characterization of the prompt posterior distribution, leading to improved generalization. In contrast to prior Bayesian prompt learning methods, our method provides a modular plug-and-play Bayesian extension of any existing prompt learning method based on maximum likelihood estimation. We demonstrate the efficacy of ReBaPL on several benchmark datasets, showing superior performance over state-of-the-art methods for prompt learning.

</details>


### [65] [R2PS: Worst-Case Robust Real-Time Pursuit Strategies under Partial Observability](https://arxiv.org/abs/2511.17367)
*Runyu Lu,Ruochuan Shi,Yuanheng Zhu,Dongbin Zhao*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Computing worst-case robust strategies in pursuit-evasion games (PEGs) is time-consuming, especially when real-world factors like partial observability are considered. While important for general security purposes, real-time applicable pursuit strategies for graph-based PEGs are currently missing when the pursuers only have imperfect information about the evader's position. Although state-of-the-art reinforcement learning (RL) methods like Equilibrium Policy Generalization (EPG) and Grasper provide guidelines for learning graph neural network (GNN) policies robust to different game dynamics, they are restricted to the scenario of perfect information and do not take into account the possible case where the evader can predict the pursuers' actions. This paper introduces the first approach to worst-case robust real-time pursuit strategies (R2PS) under partial observability. We first prove that a traditional dynamic programming (DP) algorithm for solving Markov PEGs maintains optimality under the asynchronous moves by the evader. Then, we propose a belief preservation mechanism about the evader's possible positions, extending the DP pursuit strategies to a partially observable setting. Finally, we embed the belief preservation into the state-of-the-art EPG framework to finish our R2PS learning scheme, which leads to a real-time pursuer policy through cross-graph reinforcement learning against the asynchronous-move DP evasion strategies. After reinforcement learning, our policy achieves robust zero-shot generalization to unseen real-world graph structures and consistently outperforms the policy directly trained on the test graphs by the existing game RL approach.

</details>


### [66] [Stable Coresets via Posterior Sampling: Aligning Induced and Full Loss Landscapes](https://arxiv.org/abs/2511.17399)
*Wei-Kai Chang,Rajiv Khanna*

Main category: cs.LG

TL;DR: 提出一个基于后验采样的 cores et 选择框架，并通过对模型权重进行后验采样的平滑损失来提升训练速度与泛化，同时给出收敛性分析，实验表明优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型不断扩展，数据集规模增长使得训练成本高昂，需要高效且鲁棒的数据子集选择策略。基于梯度的coreset方法在理论和实践上都具吸引力，但容易被简单的 SGD 基线击败，且损失曲率随训练过程变化导致表示性下降，因此需要在高数据污染和预算受限场景下的稳健方法。

Method: 建立后验采样与损失景观之间的联系，提出一种基于对模型权重进行后验采样的平滑损失函数，以实现更稳定的 cores et 选择，并给出该采样方法的收敛性分析与高效实现算法，兼顾计算成本。

Result: 在广泛的实验中，方法在多样化数据集上实现更快的训练和更强的泛化能力，优于当前的最先进方法，且对数据污染具有鲁棒性。

Conclusion: 将后验采样理念融入 cores et 选择，提供一个稳健高效的梯度驱动子集选择框架，并给出理论收敛性，开启在大规模数据场景下的最新研究方向。

Abstract: As deep learning models continue to scale, the growing computational demands have amplified the need for effective coreset selection techniques. Coreset selection aims to accelerate training by identifying small, representative subsets of data that approximate the performance of the full dataset. Among various approaches, gradient based methods stand out due to their strong theoretical underpinnings and practical benefits, particularly under limited data budgets. However, these methods face challenges such as naive stochastic gradient descent (SGD) acting as a surprisingly strong baseline and the breakdown of representativeness due to loss curvature mismatches over time.
  In this work, we propose a novel framework that addresses these limitations. First, we establish a connection between posterior sampling and loss landscapes, enabling robust coreset selection even in high data corruption scenarios. Second, we introduce a smoothed loss function based on posterior sampling onto the model weights, enhancing stability and generalization while maintaining computational efficiency. We also present a novel convergence analysis for our sampling-based coreset selection method. Finally, through extensive experiments, we demonstrate how our approach achieves faster training and enhanced generalization across diverse datasets than the current state of the art.

</details>


### [67] [DS-Span: Single-Phase Discriminative Subgraph Mining for Efficient Graph Embeddings](https://arxiv.org/abs/2511.17419)
*Yeamin Kaiser,Muhammed Tasnim Bin Anwar,Bholanath Das,Chowdhury Farhan Ahmed,Md. Tanvir Alam*

Main category: cs.LG

TL;DR: DS-Span是一种单阶段的判别子图挖掘框架，在一次遍历中完成模式生长、剪枝和监督评分，提出覆盖限制作业和信息增益选择以产生紧凑且具判别性的子图特征，用于图表示学习。


<details>
  <summary>Details</summary>
Motivation: 现有子图挖掘方法通常面临多阶段流程、计算成本高和 mined 结构与判别相关性之间的耦合不足等问题，迫切需要一个可解释、可扩展的直接用于图嵌入的单阶段方案。

Method: 在一次遍历中将模式生长、剪枝和监督评分整合，提出覆盖限 eligibility 机制（当图已被充分表示时动态限制探索）和信息增益导向的子图选择（优先具有强类别分离能力且减少冗余）。

Result: 实验表明DS-Span在基准数据集上能够产生比先前多阶段方法更紧凑、具判别性的子图特征，并在保持或提升准确率的同时显著降低运行时间。

Conclusion: 统一的单阶段判别挖掘可作为可扩展且可解释的图表示学习的基础，具有广泛应用潜力。

Abstract: Graph representation learning seeks to transform complex, high-dimensional graph structures into compact vector spaces that preserve both topology and semantics. Among the various strategies, subgraph-based methods provide an interpretable bridge between symbolic pattern discovery and continuous embedding learning. Yet, existing frequent or discriminative subgraph mining approaches often suffer from redundant multi-phase pipelines, high computational cost, and weak coupling between mined structures and their discriminative relevance. We propose DS-Span, a single-phase discriminative subgraph mining framework that unifies pattern growth, pruning, and supervision-driven scoring within one traversal of the search space. DS-Span introduces a coverage-capped eligibility mechanism that dynamically limits exploration once a graph is sufficiently represented, and an information-gain-guided selection that promotes subgraphs with strong class-separating ability while minimizing redundancy. The resulting subgraph set serves as an efficient, interpretable basis for downstream graph embedding and classification. Extensive experiments across benchmarks demonstrate that DS-Span generates more compact and discriminative subgraph features than prior multi-stage methods, achieving higher or comparable accuracy with significantly reduced runtime. These results highlight the potential of unified, single-phase discriminative mining as a foundation for scalable and interpretable graph representation learning.

</details>


### [68] [Self-Supervised Learning by Curvature Alignment](https://arxiv.org/abs/2511.17426)
*Benyamin Ghojogh,M. Hadi Sepanj,Paul Fieguth*

Main category: cs.LG

TL;DR: CurvSSL proposes curvature-regularized self-supervised learning, augmenting a Barlow Twins-style objective with a curvature-based regularizer that enforces consistency of local data geometry across views; also offers an RKHS kernel variant.


<details>
  <summary>Details</summary>
Motivation: SSL methods often optimize first- and second-order statistics while largely ignoring the local geometry of the data manifold. Incorporating curvature aims to regularize how learned representations bend along the manifold, potentially improving feature locality and invariance.

Method: Maintain a standard two-view encoder-projector with a redundancy-reduction loss (Barlow Twins style). Add a curvature-based regularizer where each embedding is a vertex connected to its k-nearest neighbors to define a discrete curvature score on the unit hypersphere; in the RKHS extension, compute curvature from a normalized local Gram matrix in the RKHS. Align and decorrelate curvature-derived matrices across augmentations with a Barlow-Twins-like loss to enforce view invariance and consistent local bending.

Result: Experiments on MNIST and CIFAR-10 with a ResNet-18 backbone show curvature-regularized SSL yields competitive or improved linear evaluation performance compared to Barlow Twins and VICReg.

Conclusion: Explicitly shaping local geometry via curvature regularization is a simple and effective complement to purely statistical SSL losses, improving the quality of learned representations by enforcing local manifold consistency.

Abstract: Self-supervised learning (SSL) has recently advanced through non-contrastive methods that couple an invariance term with variance, covariance, or redundancy-reduction penalties. While such objectives shape first- and second-order statistics of the representation, they largely ignore the local geometry of the underlying data manifold. In this paper, we introduce CurvSSL, a curvature-regularized self-supervised learning framework, and its RKHS extension, kernel CurvSSL. Our approach retains a standard two-view encoder-projector architecture with a Barlow Twins-style redundancy-reduction loss on projected features, but augments it with a curvature-based regularizer. Each embedding is treated as a vertex whose $k$ nearest neighbors define a discrete curvature score via cosine interactions on the unit hypersphere; in the kernel variant, curvature is computed from a normalized local Gram matrix in an RKHS. These scores are aligned and decorrelated across augmentations by a Barlow-style loss on a curvature-derived matrix, encouraging both view invariance and consistency of local manifold bending. Experiments on MNIST and CIFAR-10 datasets with a ResNet-18 backbone show that curvature-regularized SSL yields competitive or improved linear evaluation performance compared to Barlow Twins and VICReg. Our results indicate that explicitly shaping local geometry is a simple and effective complement to purely statistical SSL regularizers.

</details>


### [69] [Towards fully differentiable neural ocean model with Veros](https://arxiv.org/abs/2511.17427)
*Etienne Meunier,Said Ouala,Hugo Frezat,Julien Le Sommer,Ronan Fablet*

Main category: cs.LG

TL;DR: 提出 VEROS 海洋模型的可微分扩展，使其支持 JAX 自动微分框架，并通过数值一致性验证与两个示例应用（状态纠正与参数自标定）展示端到端学习与参数调优潜力。


<details>
  <summary>Details</summary>
Motivation: 实现一个可微分的海洋模型，以支持基于梯度的优化、参数估计和端到端学习，从而提升海洋模拟的可调参性与数据同化效率。

Method: 将 VEROS 动力学核心改造以兼容 JAX 自动微分，确保数值实现对 autodiff 的可追踪性和数值一致性；通过前向/反向传播实现梯度流；给出两类应用评估：1) 基于梯度的初始状态纠正；2) 直接从观测中校准未知物理参数；代码实现在线发布。

Result: 验证了数值一致性；演示表明通过梯度优化可改进初始状态的准确性，并能从观测数据中有效校准未观测的参数，显示可微分编程在海洋建模中的端到端学习与参数调优潜力。

Conclusion: 可微分海洋模型为端到端学习和参数调优提供了可行路径，相关实现已在线发布，未来有望扩展到更广泛耦合系统与高效训练。

Abstract: We present a differentiable extension of the VEROS ocean model, enabling automatic differentiation through its dynamical core. We describe the key modifications required to make the model fully compatible with JAX autodifferentiation framework and evaluate the numerical consistency of the resulting implementation. Two illustrative applications are then demonstrated: (i) the correction of an initial ocean state through gradient-based optimization, and (ii) the calibration of unknown physical parameters directly from model observations. These examples highlight how differentiable programming can facilitate end-to-end learning and parameter tuning in ocean modeling. Our implementation is available online.

</details>


### [70] [Multi-Agent Pointer Transformer: Seq-to-Seq Reinforcement Learning for Multi-Vehicle Dynamic Pickup-Delivery Problems](https://arxiv.org/abs/2511.17435)
*Zengyu Zou,Jingyuan Wang,Yixuan Huang,Junjie Wu*

Main category: cs.LG

TL;DR: MAPT为多车动态取物与送货问题提出端到端集中式决策框架，利用Transformer与Pointer Network等，解决多智能体联合动作分布、特征建模和组合动作空间等挑战，在8个数据集上优于基线，同时在计算时间上优于传统优化方法。


<details>
  <summary>Details</summary>
Motivation: 解决MVDPDPSR的计算复杂性和时间效率瓶颈，克服独立解码、特征提取和大规模联合动作空间的问题，提升端到端学习框架对复杂时空调度问题的建模能力。

Method: 提出MAPT：使用Transformer编码器提取实体表示，Transformer解码器+Pointer Network以自回归方式生成联合动作序列，新增关系感知注意力模块以捕获实体间关系，并通过信息先验引导探索。

Result: 在8个数据集上显著优于基线方法，且在计算时间方面优于传统运筹方法。

Conclusion: MAPT为大规模动态取送任务提供了一个高效的端到端学习框架，展示了Transformer在多智能体组合动作和时空调度问题上的有效性。

Abstract: This paper addresses the cooperative Multi-Vehicle Dynamic Pickup and Delivery Problem with Stochastic Requests (MVDPDPSR) and proposes an end-to-end centralized decision-making framework based on sequence-to-sequence, named Multi-Agent Pointer Transformer (MAPT). MVDPDPSR is an extension of the vehicle routing problem and a spatio-temporal system optimization problem, widely applied in scenarios such as on-demand delivery. Classical operations research methods face bottlenecks in computational complexity and time efficiency when handling large-scale dynamic problems. Although existing reinforcement learning methods have achieved some progress, they still encounter several challenges: 1) Independent decoding across multiple vehicles fails to model joint action distributions; 2) The feature extraction network struggles to capture inter-entity relationships; 3) The joint action space is exponentially large. To address these issues, we designed the MAPT framework, which employs a Transformer Encoder to extract entity representations, combines a Transformer Decoder with a Pointer Network to generate joint action sequences in an AutoRegressive manner, and introduces a Relation-Aware Attention module to capture inter-entity relationships. Additionally, we guide the model's decision-making using informative priors to facilitate effective exploration. Experiments on 8 datasets demonstrate that MAPT significantly outperforms existing baseline methods in terms of performance and exhibits substantial computational time advantages compared to classical operations research methods.

</details>


### [71] [InTAct: Interval-based Task Activation Consolidation for Continual Learning](https://arxiv.org/abs/2511.17439)
*Patryk Krukowski,Jan Miksa,Piotr Helm,Jacek Tabor,Paweł Wawrzyński,Przemysław Spurek*

Main category: cs.LG

TL;DR: InTAct stabilizes shared representations in prompt-based continual learning to mitigate representation drift under domain shifts by constraining activation ranges of important neurons, improving domain-incremental performance without freezing parameters or storing past data.


<details>
  <summary>Details</summary>
Motivation: Continual learning suffers from representation drift when domain shifts occur; prompts alone cannot prevent forgetting as shared layers’ activations drift; need a method that preserves functional behavior without sacrificing plasticity.

Method: InTAct preserves activation-range constraints for previously learned task representations; it monitors activation ranges of important neurons and constrains updates to keep network within those regions while allowing adaptation elsewhere; architecture-agnostic, integrates with prompt-based CL.

Result: Across domain-incremental benchmarks (DomainNet, ImageNet-R), InTAct reduces representation drift and improves performance, achieving up to 8 percentage points higher average accuracy over state-of-the-art baselines.

Conclusion: Stabilizing the functional roles of key neurons in shared layers provides a principled stability-plasticity balance, enabling robust continual learning under domain shifts without data storage or parameter freezing.

Abstract: Continual learning aims to enable neural networks to acquire new knowledge without forgetting previously learned information. While recent prompt-based methods perform strongly in class-incremental settings, they remain vulnerable under domain shifts, where the input distribution changes but the label space remains fixed. This exposes a persistent problem known as representation drift. Shared representations evolve in ways that overwrite previously useful features and cause forgetting even when prompts isolate task-specific parameters. To address this issue, we introduce InTAct, a method that preserves functional behavior in shared layers without freezing parameters or storing past data. InTAct captures the characteristic activation ranges associated with previously learned tasks and constrains updates to ensure the network remains consistent within these regions, while still allowing for flexible adaptation elsewhere. In doing so, InTAct stabilizes the functional role of important neurons rather than directly restricting parameter values. The approach is architecture-agnostic and integrates seamlessly into existing prompt-based continual learning frameworks. By regulating representation changes where past knowledge is encoded, InTAct achieves a principled balance between stability and plasticity. Across diverse domain-incremental benchmarks, including DomainNet and ImageNet-R, InTAct consistently reduces representation drift and improves performance, increasing Average Accuracy by up to 8 percentage points over state-of-the-art baselines.

</details>


### [72] [Unmasking Airborne Threats: Guided-Transformers for Portable Aerosol Mass Spectrometry](https://arxiv.org/abs/2511.17446)
*Kyle M. Regan,Michael McLoughlin,Wayne A. Bryden,Gonzalo R. Arce*

Main category: cs.LG

TL;DR: 提出一个数据驱动的 MS-DGFormer 框架，通过字典编码器与 SVD 去噪，直接对原始单 Shot MALDI-MS 光谱进行处理，实现对环境气溶胶中病原体的鲁棒识别，支持现场实时分析与便携部署。


<details>
  <summary>Details</summary>
Motivation: 传统 MALDI-MS 受制于繁琐的样品制备与多光谱平均，无法实现实时环境监测，尤其在自动采样的气溶胶 MALDI-MS 系统中，需对未知分析物进行单次探测以获得有效结果，因此需要一种能在嘈杂单-shot光谱上提取关键特征的端到端方法。

Method: 提出基于 Transformer 的 MS-DGFormer，直接处理原始、极少预处理的质谱时间序列数据；引入字典编码器，将来自 Singular Value Decomposition(SVD) 的去噪光谱信息整合进特征提取，以提升单-shot光谱中的生物分子模式识别能力。

Result: 在单-shot 光谱中实现对病原体的鲁棒识别，且通过字典编码器与 SVD 去噪的协同作用提升特征表达，展示了对现场部署的潜在优势。未给出具体量化指标，但指出相较传统需要大量预处理的方法具有显著的鲁棒性与实时性潜力。

Conclusion: MS-DGFormer 为环境病原体检测提供了无需大量预处理的端到端 MALDI-MS 解决方案，推动可携带、可部署的现场监测平台的发展。

Abstract: Matrix Assisted Laser Desorption/Ionization Mass Spectrometry (MALDI-MS) is a cornerstone in biomolecular analysis, offering precise identification of pathogens through unique mass spectral signatures. Yet, its reliance on labor-intensive sample preparation and multi-shot spectral averaging restricts its use to laboratory settings, rendering it impractical for real-time environmental monitoring. These limitations are especially pronounced in emerging aerosol MALDI-MS systems, where autonomous sampling generates noisy spectra for unknown aerosol analytes, requiring single-shot detection for effective analysis. Addressing these challenges, we propose the Mass Spectral Dictionary-Guided Transformer (MS-DGFormer): a data-driven framework that redefines spectral analysis by directly processing raw, minimally prepared mass spectral data. MS-DGFormer leverages a transformer architecture, designed to capture the long-range dependencies inherent in these time-series spectra. To enhance feature extraction, we introduce a novel dictionary encoder that integrates denoised spectral information derived from Singular Value Decomposition (SVD), enabling the model to discern critical biomolecular patterns from single-shot spectra with robust performance. This innovation provides a system to achieve superior pathogen identification from aerosol samples, facilitating autonomous, real-time analysis in field conditions. By eliminating the need for extensive preprocessing, our method unlocks the potential for portable, deployable MALDI-MS platforms, revolutionizing environmental pathogen detection and rapid response to biological threats.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [73] [Functional uniqueness and stability of Gaussian priors in optimal L1 estimation](https://arxiv.org/abs/2511.16864)
*Leighton Barnes,Alex Dytso*

Main category: cs.IT

TL;DR: Gaussian priors in optimal L^1 and L^2 estimation: stability results; for L^2, near-linearity of the conditional mean implies proximity to Gaussian in the Lévy metric; for L^1, a Hermite-expansion framework shows Gaussian is the unique stable solution.


<details>
  <summary>Details</summary>
Motivation: Understand functional uniqueness and stability of Gaussian priors under Gaussian noise across different loss functions (L2 and L1), extending known results on linear conditional means and filling gaps for the median estimator.

Method: L2: derive explicit rates showing how near-linearity of the conditional mean constrains the prior; L1: develop a Hermite expansion framework and analyze the adjoint of the linearity-defining operator.

Result: L2: explicit rates linking near-linearity to proximity to Gaussian in the Lévy metric; L1: Gaussian remains the unique stable solution; together, provide a functional-analytic understanding of linearity and stability in Bayesian estimation under Gaussian noise.

Conclusion: The work offers a more complete functional-analytic framework for linearity and stability of Bayesian estimators with Gaussian noise, highlighting Gaussian priors' role in both L2 and L1 settings.

Abstract: This paper studies the functional uniqueness and stability of Gaussian priors in optimal $L^1$ estimation. While it is well known that the Gaussian prior uniquely induces linear conditional means under Gaussian noise, the analogous question for the conditional median (i.e., the optimal estimator under absolute-error loss) has only recently been settled. Building on the prior work establishing this uniqueness, we develop a quantitative stability theory that characterizes how approximate linearity of the optimal estimator constrains the prior distribution. For $L^2$ loss, we derive explicit rates showing that near-linearity of the conditional mean implies proximity of the prior to the Gaussian in the Lévy metric. For $L^1$ loss, we introduce a Hermite expansion framework and analyze the adjoint of the linearity-defining operator to show that the Gaussian remains the unique stable solution. Together, these results provide a more complete functional-analytic understanding of linearity and stability in Bayesian estimation under Gaussian noise.

</details>


### [74] [The Star Product of Uniformly Random Codes](https://arxiv.org/abs/2511.17236)
*Johan V. Dinesen,Ragnar Freij-Hollanti,Camilla Hollanti,Benjamin Jany,Alberto Ravagnani*

Main category: cs.IT

TL;DR: 研究两个随机线性码的星积（star product）维数的期望值，即使码的维数不相等。通过将星积与双线性形式的值评估建立对应关系，给出星积维数期望的下界。在域大小 q 以及码的维数均趋于无穷时，期望维数达到最大值。讨论与私有信息检索、分布式安全矩阵乘法、量子纠错以及潜在的密码分析利用等相关的含义。


<details>
  <summary>Details</summary>
Motivation: 星积在编码理论、分布式计算和密码学应用中具有重要作用，理解随机线性码星积的维数可以帮助评估编码结构对计算与隐私保护的影响，且对设计鲁棒高效的星积相关方案具有指导意义。

Method: 建立星积与双线性形式的评估之间的对应关系，利用这一关系给出星积维数的期望的下界；对域大小 q 与两码维数的极限进行分析，揭示在极限情况下期望维数达到其最大值。

Result: 证明了星积维数期望的下界，并在 q 与码维数的渐近极限下，期望维数达到最大值。这意味着在大域和大码的情况下，随机两线性码的星积维数接近理论上可能的最大值。

Conclusion: 结果为私有信息检索、安全分布式矩阵乘法、量子纠错等应用提供了理论基础，提示在这些场景中随机码的星积具有高维度特性；并指出有潜在的密码分析应用方向，可以利用星积维数的极限行为来设计更具鲁棒性的攻击/防御策略。

Abstract: We consider the problem of determining the expected dimension of the star product of two uniformly random linear codes that are not necessarily of the same dimension. We achieve this by establishing a correspondence between the star product and the evaluation of bilinear forms, which we use to provide a lower bound on the expected star product dimension. We show that asymptotically in both the field size q and the dimensions of the two codes, the expected dimension reaches its maximum. Lastly, we discuss some implications related to private information retrieval, secure distributed matrix multiplication, quantum error correction, and the potential for exploiting the results in cryptanalysis.

</details>


### [75] [Structured Approximation of Toeplitz Matrices and Subspaces](https://arxiv.org/abs/2511.17239)
*Albert Fannjiang,Weilin Li*

Main category: cs.IT

TL;DR: Gradient-MUSIC 基于谱估计的方法用于两类结构化矩阵恢复问题：一是低秩Toeplitz矩阵的恢复，二是从单一样本观测中恢复傅里叶矩阵的范围。给出在正则性假设和扰动 E 满足 ||E||2 ≤ αn 的条件下，算法能输出秩恰为 r 的 Toeplitz 矩阵估计 Ť，使 ||T−Ť||2 ≤ C√r ||E||2，且该界在 n 和 ||E||2 维度上达到极小极大（minimax）最优；对第二类问题也给出最优结果。分析还揭示两类问题与谱估计之间的定量联系，且结果同样适用于 Hankel 矩阵（只需做表面修改）。


<details>
  <summary>Details</summary>
Motivation: 结构约束的矩阵恢复问题（如低秩 Toeplitz/Hankel 以及傅里叶矩阵的范围）由于约束难以直接实现，导致计算复杂且解的质量难以保证。本工作希望通过谱估计视角（Gradient-MUSIC）将这类结构化恢复转化为更高效、具有全局最优性的求解，并揭示不同问题之间的联系。

Method: 核心方法是对谱估计中的 Gradient-MUSIC 算法进行适配，使其用于强结构约束的矩阵恢复：在满足正则性假设且扰动满足 ||E||2 ≤ αn 的条件下，通过梯度- MUSIC 的迭代策略直接构造秩为 r 的 Toeplitz 矩阵 Ť，使其尽可能贴近真值矩阵 T。对第二类问题也给出等价的分析与求解框架。

Result: 给出界限：||T−Ť||2 ≤ C√r ||E||2，其中 C、α 为常数；该界在 n 和 ||E||2 维度上为 minimax 最优；对于第二类问题也得到最优结果，并且分析揭示两问题与谱估计的定量联系。结论还指出同样可将方法推广至 Hankel 矩阵。

Conclusion: 结论指出，利用 Gradient-MUSIC 的谱估计视角可有效且最优地解决两类结构化矩阵恢复问题，并提供了两者之间的定量联系与统一框架；此方法对 Toeplitz/Hankel 与傅里叶相关问题具有广泛的适用性。

Abstract: This paper studies two structured approximation problems: (1) Recovering a corrupted low-rank Toeplitz matrix and (2) recovering the range of a Fourier matrix from a single observation. Both problems are computationally challenging because the structural constraints are difficult to enforce directly. We show that both tasks can be solved efficiently and optimally by applying the Gradient-MUSIC algorithm for spectral estimation. For a rank $r$ Toeplitz matrix ${\boldsymbol T}\in {\mathbb C}^{n\times n}$ that satisfies a regularity assumption and is corrupted by an arbitrary ${\boldsymbol E}\in {\mathbb C}^{n\times n}$ such that $\|{\boldsymbol E}\|_2\leq αn$, our algorithm outputs a Toeplitz matrix $\widehat{\boldsymbol T}$ of rank exactly $r$ such that $\|{\boldsymbol T}-\widehat{\boldsymbol T}\|_2 \leq C \sqrt r \, \|{\boldsymbol E}\|_2$, where $C,α>0$ are absolute constants. This performance guarantee is minimax optimal in $n$ and $\|{\boldsymbol E}\|_2$. We derive optimal results for the second problem as well. Our analysis provides quantitative connections between these two problems and spectral estimation. Our results are equally applicable to Hankel matrices with superficial modifications.

</details>


### [76] [Fast Decoding for Non-Adaptive Learning of Erdős--Rényi Random Graphs](https://arxiv.org/abs/2511.17240)
*Hoang Ta,Jonathan Scarlett*

Main category: cs.IT

TL;DR: Proposes a non-adaptive group-testing-inspired scheme for learning ER graphs with asymptotically vanishing error, achieving near-optimal test count and subquadratic decoding time.


<details>
  <summary>Details</summary>
Motivation: To efficiently learn sparse random graphs G ~ ER(n,q) using only subset queries that report if any edge exists among queried nodes, addressing the gap between optimal test numbers and practical decoding time.

Method: Extend binary splitting techniques from non-adaptive group testing to the ER graph learning problem and design a testing-decoding scheme that recovers the edge set with high probability.

Result: Achieves O(k̄ log n) tests and decoding time O(k̄^{1+δ} log n) for any fixed δ>0, where k̄ = q binom(n,2) is the expected number of edges, with asymptotically vanishing error probability.

Conclusion: Demonstrates that ER graphs can be learned efficiently in the non-adaptive setting with near-optimal test complexity and substantially improved decoding time compared to previous work; extends binary splitting to a graph learning context.

Abstract: We study the problem of learning an unknown graph via group queries on node subsets, where each query reports whether at least one edge is present among the queried nodes. In general, learning arbitrary graphs with \(n\) nodes and \(k\) edges is hard in the non-adaptive setting, requiring \(Ω\big(\min\{k^2\log n,\,n^2\}\big)\) tests even when a small error probability is allowed. We focus on learning Erdős--Rényi (ER) graphs \(G\sim\ER(n,q)\) in the non-adaptive setting, where the expected number of edges is \(\bar{k}=q\binom{n}{2}\), and we aim to design an efficient testing--decoding scheme achieving asymptotically vanishing error probability. Prior work (Li--Fresacher--Scarlett, NeurIPS 2019) presents a testing--decoding scheme that attains an order-optimal number of tests \(O(\bar{k}\log n)\) but incurs \(Ω(n^2)\) decoding time, whereas their proposed sublinear-time algorithm incurs an extra \((\log \bar{k})(\log n)\) factor in the number of tests. We extend the binary splitting approach, recently developed for non-adaptive group testing, to the ER graph learning setting, and prove that the edge set can be recovered with high probability using \(O(\bar{k}\log n)\) tests while attaining decoding time \(O(\bar{k}^{1+δ}\log n)\) for any fixed \(δ>0\).

</details>


### [77] [Fluid Antenna System-Enabled UAV-to-Ground Communications](https://arxiv.org/abs/2511.17416)
*Xusheng Zhu,Kai-Kit Wong,Qingqing Wu,Hyundong Shin,Yangyang Zhang*

Main category: cs.IT

TL;DR: 提出针对无人机到地面链路的双阴影 fading，在N端口流体天线系统(FAS)下的端到端SNR统计分析，给出CDF/PDF、outage、BER、容量的解析表达，并给出双秩独立同分布情况下的闭式解及渐近的乘法式分集阶数G_d = M*d，辅以仿真验证。


<details>
  <summary>Details</summary>
Motivation: 高频段无人机通信环境中需要更精准的信道模型以捕捉多径衰落与阴影效应，FAS提供更丰富的空间多样性，本研究将两者结合进行性能分析。

Method: 采用可处理相关FAS端口的特征值近似，推导端到端SNR的统计量（CDF/PDF），给出出线、平均BER和容量的精确积分表达，并在双秩、独立同分布之外推导闭式解；进行渐近分析得到乘法分集阶数。

Result: 得到端到端SNR的CDF和PDF及其在出线、平均BER、容量方面的解析/积分表达；针对双秩情况给出简单可用的闭式BER和容量解；并证实G_d = M×d的乘法分集能力，仿真验证高精度。

Conclusion: 流体天线系统与FAS在UAV链路中可显著提升空间多样性，端到端性能可通过M与信道本征多样性d的乘积来界定，所给解析框架对系统设计与性能预测具有重要作用。

Abstract: Fluid antenna systems (FAS) have emerged as a revolutionary technology offering enhanced spatial diversity within a compact form factor. Concurrently, unmanned aerial vehicles (UAVs) are integral to future networks, necessitating channel models that capture both multipath fading and shadowing. This letter presents a novel performance analysis of a UAV-to-ground link, where the receiver is equipped with an $N$-port FAS operating over the challenging double-shadowing fading channel. By adapting a tractable eigenvalue-based approximation for the correlated FAS ports, we derive new analytical expressions for the end-to-end signal-to-noise ratio statistics, namely the cumulative distribution function and the probability density function. Based on these statistics, we present exact integral expressions for the outage probability, average bit error rate, and average channel capacity. We further derive new, tractable closed-form solutions for the average bit error rate and capacity for the practical dual-rank, independent but non-identically distributed case. Finally, a key asymptotic analysis reveals that the system achieves a multiplicative diversity order of $G_d = M \times d$, which is precisely the product of the FAS spatial rank $M$ and the intrinsic channel diversity order $d$. Simulation results are provided to validate the high accuracy of our entire theoretical framework.

</details>
