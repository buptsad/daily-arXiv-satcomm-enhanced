<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 8]
- [eess.SY](#eess.SY) [Total: 12]
- [cs.NI](#cs.NI) [Total: 3]
- [eess.SP](#eess.SP) [Total: 14]
- [cs.LG](#cs.LG) [Total: 69]
- [cs.IT](#cs.IT) [Total: 12]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [FedSelect-ME: A Secure Multi-Edge Federated Learning Framework with Adaptive Client Scoring](https://arxiv.org/abs/2511.01898)
*Hanie Vatani,Reza Ebrahimi Atani*

Main category: cs.CR

TL;DR: FedSelect-ME is a hierarchical multi-edge federated learning framework that improves scalability, security, and energy efficiency through edge-server-based workload distribution, score-based client selection, and secure aggregation (HE + DP); it demonstrates better accuracy, fairness, and lower communication overhead on the eICU dataset compared with standard FL baselines.


<details>
  <summary>Details</summary>
Motivation: Federated learning faces bottlenecks in scalability, high communication costs, and privacy risks due to centralized aggregation. There is a need for scalable, secure, and energy-efficient FL capable of handling privacy-sensitive healthcare data distributed across regions.

Method: Introduce FedSelect-ME, a hierarchical multi-edge FL framework with multiple edge servers that allocate workloads and perform score-based client selection based on utility, energy efficiency, and data sensitivity. Implement Secure Aggregation using Homomorphic Encryption and Differential Privacy to protect updates. Evaluate on the eICU healthcare dataset and compare against FedAvg, FedProx, and FedSelect.

Result: FedSelect-ME achieves higher prediction accuracy, improved regional fairness, and reduced communication overhead compared with FedAvg, FedProx, and FedSelect.

Conclusion: The proposed FedSelect-ME framework addresses scalability, security, and efficiency bottlenecks in conventional FL, providing a secure, scalable, and energy-efficient solution for large-scale, privacy-sensitive healthcare applications.

Abstract: Federated Learning (FL) enables collaborative model training without sharing
raw data but suffers from limited scalability, high communication costs, and
privacy risks due to its centralized architecture. This paper proposes
FedSelect-ME, a hierarchical multi-edge FL framework that enhances scalability,
security, and energy efficiency. Multiple edge servers distribute workloads and
perform score-based client selection, prioritizing participants based on
utility, energy efficiency, and data sensitivity. Secure Aggregation with
Homomorphic Encryption and Differential Privacy protects model updates from
exposure and manipulation. Evaluated on the eICU healthcare dataset,
FedSelect-ME achieves higher prediction accuracy, improved fairness across
regions, and reduced communication overhead compared to FedAvg, FedProx, and
FedSelect. The results demonstrate that the proposed framework effectively
addresses the bottlenecks of conventional FL, offering a secure, scalable, and
efficient solution for large-scale, privacy-sensitive healthcare applications.

</details>


### [2] [Black-Box Membership Inference Attack for LVLMs via Prior Knowledge-Calibrated Memory Probing](https://arxiv.org/abs/2511.01952)
*Jinhua Yin,Peiru Yang,Chen Yang,Huili Wang,Zhiyang Hu,Shangguang Wang,Yongfeng Huang,Tao Qi*

Main category: cs.CR

TL;DR: 提出首个针对大规模视觉-语言模型（LVLM）的黑盒成员身份推断攻击框架，利用先验知识校准的记忆探测机制，在仅暴露输出的情况下评估模型对私有语义信息的记忆性，实验在四个LVLM和三组数据上显示有效，性能接近白盒/灰盒方法.


<details>
  <summary>Details</summary>
Motivation: LVLMs在大规模数据上训练，易对训练数据产生记忆；现有的成员身份推断攻击多为白盒/灰盒，难以在严格限制的黑盒设定下进行，因此需要在只可观察输出的情境中进行有效的攻击方法。

Method: 提出基于先验知识校准的记忆探测机制，通过评估 suspected image 数据中私有语义信息的记忆程度来判定样本是否来自训练数据；在黑盒情境下利用模型输出进行推断；在四个LVLM和三组数据上进行广泛实验，比较与现有方法，分析对抗性操控下的鲁棒性及方法设计的有效性。

Result: 实验表明该方法在纯黑盒条件下能够有效识别LVLM的训练数据，且性能与灰盒、白盒方法相当；对潜在对抗性操作具有鲁棒性，并验证了设计的有效性。

Conclusion: 证明了在黑盒情境下对 LVLM 的成员身份推断是可行的，提出的记忆探测与先验知识校准策略具有潜在的实际应用价值，相关代码和数据已公开。

Abstract: Large vision-language models (LVLMs) derive their capabilities from extensive
training on vast corpora of visual and textual data. Empowered by large-scale
parameters, these models often exhibit strong memorization of their training
data, rendering them susceptible to membership inference attacks (MIAs).
Existing MIA methods for LVLMs typically operate under white- or gray-box
assumptions, by extracting likelihood-based features for the suspected data
samples based on the target LVLMs. However, mainstream LVLMs generally only
expose generated outputs while concealing internal computational features
during inference, limiting the applicability of these methods. In this work, we
propose the first black-box MIA framework for LVLMs, based on a prior
knowledge-calibrated memory probing mechanism. The core idea is to assess the
model memorization of the private semantic information embedded within the
suspected image data, which is unlikely to be inferred from general world
knowledge alone. We conducted extensive experiments across four LVLMs and three
datasets. Empirical results demonstrate that our method effectively identifies
training data of LVLMs in a purely black-box setting and even achieves
performance comparable to gray-box and white-box methods. Further analysis
reveals the robustness of our method against potential adversarial
manipulations, and the effectiveness of the methodology designs. Our code and
data are available at https://github.com/spmede/KCMP.

</details>


### [3] [Watermarking Discrete Diffusion Language Models](https://arxiv.org/abs/2511.02083)
*Avi Bagchi,Akhil Bhimaraju,Moulik Choraria,Daniel Alabi,Lav R. Varshney*

Main category: cs.CR

TL;DR: 给离散扩散语言模型设计的水印方案：在每一步扩散中使用分布保持的Gumbel-max技巧，并以序列位置作为种子，实现可检测且接近无失真、随令牌序列长度指数级降低假阳性概率的水印。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容的普及，水印技术用于识别与区分AI生成内容；现有工作多聚焦自回归语言模型和图像扩散模型，对离散扩散语言模型的水印研究空缺，需要可检出且对输出失真影响极小的方案。

Method: 在每个扩散步骤应用分布保持的Gumbel-max技巧，使用序列索引作为随机性的种子以实现可可靠检测，设计可对离散扩散语言模型进行水印嵌入与检测。

Result: 在最先进的离散扩散语言模型上实现可可靠检测；解析证明在令牌序列长度上假阳性概率呈指数衰减，且失真为零或近似零（无失真）。

Conclusion: 该水印方案实现对离散扩散语言模型的可检测水印，且理论上具有低假阳性且不改变输出分布的特性，适合大规模部署，未来可扩展至其他离散生成模型并进一步评估鲁棒性。

Abstract: Watermarking has emerged as a promising technique to track AI-generated
content and differentiate it from authentic human creations. While prior work
extensively studies watermarking for autoregressive large language models
(LLMs) and image diffusion models, none address discrete diffusion language
models, which are becoming popular due to their high inference throughput. In
this paper, we introduce the first watermarking method for discrete diffusion
models by applying the distribution-preserving Gumbel-max trick at every
diffusion step and seeding the randomness with the sequence index to enable
reliable detection. We experimentally demonstrate that our scheme is reliably
detectable on state-of-the-art diffusion language models and analytically prove
that it is distortion-free with an exponentially decaying probability of false
detection in the token sequence length.

</details>


### [4] [FLAME: Flexible and Lightweight Biometric Authentication Scheme in Malicious Environments](https://arxiv.org/abs/2511.02176)
*Fuyi Wang,Fangyuan Sun,Mingyuan Fan,Jianying Zhou,Jin Ma,Chao Chen,Jiangang Shu,Leo Yu Zhang*

Main category: cs.CR

TL;DR: 提出了一种在恶意环境下的灵活轻量生物识别身份验证系统SYSNAME，通过将轻量化秘密共享族与两方计算相结合，提供对多种相似度指标的跨度量兼容认证设计，理论上证明正确性与安全性，实验结果在LAN/WAN环境下显著优于现有工作，在通信量和速度上达到大幅提升。


<details>
  <summary>Details</summary>
Motivation: 现实场景中对手可能具有恶意行为，半信任模型往往无法提供足够的安全性。需要在保持高效性的前提下，提供对主动攻击的防护，并实现对多种相似度度量的灵活支持。

Method: 在两方计算框架中混合使用轻量化的秘密共享家族，设计一系列带有完整性检查的协议，专门用于恶意环境下的可信性保障；支持服务器端对多种相似度度量的认证，从而实现跨度量兼容且不改变服务器端流程；对正确性、安全性和效率进行理论分析并通过实验评估。

Result: 理论上给出正确性与安全性的证明；实验显示与现有最优解相比，在LAN环境下通信量降低约97.61×至110.13×，速度提升约2.72×–2.82×；在WAN环境下通信量提升约6.58×–8.51×，速度提升约6.58×–8.51×（应为对应的提升）。（注：原文给出两组数字，本文按原意整理）

Conclusion: SYSNAME提供一个灵活、轻量且适用于恶意环境的PPBA解决方案，具有跨度量的兼容性与良好的实际应用潜力，理论与实验均表明了其有效性与高效性。

Abstract: Privacy-preserving biometric authentication (PPBA) enables client
authentication without revealing sensitive biometric data, addressing privacy
and security concerns. Many studies have proposed efficient cryptographic
solutions to this problem based on secure multi-party computation, typically
assuming a semi-honest adversary model, where all parties follow the protocol
but may try to learn additional information. However, this assumption often
falls short in real-world scenarios, where adversaries may behave maliciously
and actively deviate from the protocol.
  In this paper, we propose, implement, and evaluate $\sysname$, a
\underline{F}lexible and \underline{L}ightweight biometric
\underline{A}uthentication scheme designed for a \underline{M}alicious
\underline{E}nvironment. By hybridizing lightweight secret-sharing-family
primitives within two-party computation, $\sysname$ carefully designs a line of
supporting protocols that incorporate integrity checks with rationally extra
overhead. Additionally, $\sysname$ enables server-side authentication with
various similarity metrics through a cross-metric-compatible design, enhancing
flexibility and robustness without requiring any changes to the server-side
process. A rigorous theoretical analysis validates the correctness, security,
and efficiency of $\sysname$. Extensive experiments highlight $\sysname$'s
superior efficiency, with a communication reduction by {$97.61\times \sim
110.13\times$} and a speedup of {$ 2.72\times \sim 2.82\times$ (resp. $
6.58\times \sim 8.51\times$)} in a LAN (resp. WAN) environment, when compared
to the state-of-the-art work.

</details>


### [5] [An Automated Framework for Strategy Discovery, Retrieval, and Evolution in LLM Jailbreak Attacks](https://arxiv.org/abs/2511.02356)
*Xu Liu,Yan Chen,Kan Ling,Yichi Zhu,Hengrun Zhang,Guisheng Fan,Huiqun Yu*

Main category: cs.CR

TL;DR: ASTRA是一种自适应的 jailbreak 框架，通过闭环的攻击-评估-蒸馏-重用机制，自动发现、检索并进化攻击策略，构建了三层策略库，显著提升在黑箱设置下的攻击成功率（平均82.7%）并展示了策略的可扩展性和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM作为对外公开服务的广泛部署，安全成为关键问题。现有防御往往易被挖掘出新的攻击面，亟需能够自我进化、具备策略复用能力的攻击框架来揭示薄弱环节，从而推动更强的防护机制的发展。

Method: 提出一个闭环核心机制attack-evaluate-distill-reuse，自动生成攻击提示并从每次交互中蒸馏出可重用的攻击策略。构建一个三层策略库（Effective/Promising/Ineffective），用于对策略进行评分、分类和迁移。通过黑箱实验评估，展示框架在多轮交互中对攻击策略的自适应改进与迁移能力。

Result: 在黑箱场景下平均攻击成功率达到82.7%，显著优于基线方法；策略库具备良好的扩展性和迁移性，能从失败/部分成功中提取有用信息并重用。

Conclusion: ASTRA证明了攻击策略的自我进化与知识蒸馏的可行性，以及通过分层策略库实现策略的可扩展与迁移性。此类研究对促进对LLM安全防御的理解具有重要意义，同时也引发对防护对抗的伦理与治理关注。

Abstract: The widespread deployment of Large Language Models (LLMs) as public-facing
web services and APIs has made their security a core concern for the web
ecosystem. Jailbreak attacks, as one of the significant threats to LLMs, have
recently attracted extensive research. In this paper, we reveal a jailbreak
strategy which can effectively evade current defense strategies. It can extract
valuable information from failed or partially successful attack attempts and
contains self-evolution from attack interactions, resulting in sufficient
strategy diversity and adaptability. Inspired by continuous learning and
modular design principles, we propose ASTRA, a jailbreak framework that
autonomously discovers, retrieves, and evolves attack strategies to achieve
more efficient and adaptive attacks. To enable this autonomous evolution, we
design a closed-loop "attack-evaluate-distill-reuse" core mechanism that not
only generates attack prompts but also automatically distills and generalizes
reusable attack strategies from every interaction. To systematically accumulate
and apply this attack knowledge, we introduce a three-tier strategy library
that categorizes strategies into Effective, Promising, and Ineffective based on
their performance scores. The strategy library not only provides precise
guidance for attack generation but also possesses exceptional extensibility and
transferability. We conduct extensive experiments under a black-box setting,
and the results show that ASTRA achieves an average Attack Success Rate (ASR)
of 82.7%, significantly outperforming baselines.

</details>


### [6] [Enhancing NTRUEncrypt Security Using Markov Chain Monte Carlo Methods: Theory and Practice](https://arxiv.org/abs/2511.02365)
*Gautier-Edouard Filardo,Thibaut Heckmann*

Main category: cs.CR

TL;DR: 用MCMC提升NTRUEncrypt的量子抗性，给出抽样、混合时间和安全化简的理论与实验框架。


<details>
  <summary>Details</summary>
Motivation: 在后量子时代，NTRUEncrypt的安全性需要与实用性兼顾。通过将MCMC引入，试图获得对私钥脆弱性分析的可控性、对高维晶格的混合时间界以及从MCMC参数到晶格困难性假设的明确关联，从而提高量子对抗的理论与实践性。

Method: 提出一个以Markov Chain Monte Carlo为核心的框架，建立对抽样效率的形式化界限，给出与晶格困难性相关的安全化简；提出用于在不牺牲量子抗性的前提下探索私钥脆弱性的新方法；对高维晶格给出混合时间的可证明界限；给出将MCMC参数映射到晶格难度假设的具体度量；通过数值实验验证改进的安全性和计算效率。

Result: 结果包括：1) 对NTRUEncrypt在量子对抗背景下的抽样过程给出理论界限；2) 提出与晶格问题相关的安全化简，连接理论保证与实际实现；3) 对高维晶格给出混合时间的可证明界；4) 给出将MCMC参数与晶格难度假设之间的具体度量；5) 数值实验表明在安全性与计算效率之间取得平衡。

Conclusion: 本工作将MCMC方法引入NTRUEncrypt的后量子分析中，既提供理论上的混合时间与抽样效率的界限，又给出与晶格难度的直接联系，推动了后量子NTRUEncrypt在理论与实际应用中的可行性与稳健性。

Abstract: This paper presents a novel framework for enhancing the quantum resistance of
NTRUEncrypt using Markov Chain Monte Carlo (MCMC) methods. We establish formal
bounds on sampling efficiency and provide security reductions to lattice
problems, bridging theoretical guarantees with practical implementations. Key
contributions include: a new methodology for exploring private key
vulnerabilities while maintaining quantum resistance, provable mixing time
bounds for high-dimensional lattices, and concrete metrics linking MCMC
parameters to lattice hardness assumptions. Numerical experiments validate our
approach, demonstrating improved security guarantees and computational
efficiency. These findings advance the theoretical understanding and practical
adoption of NTRU- Encrypt in the post-quantum era.

</details>


### [7] [On The Dangers of Poisoned LLMs In Security Automation](https://arxiv.org/abs/2511.02600)
*Patrick Karlsen,Even Eilertsen*

Main category: cs.CR

TL;DR: 论文研究LLM中毒（poisoning）带来的风险，展示通过有限数据微调可能引入显著偏见，以致简单的基于LLM的警报系统在特定用户的提示中被绕过；在Llama3.1 8B与Qwen3 4B上验证了定向中毒攻击使模型持续忽略来自特定用户的真实正例警报，并提出缓解措施与最佳实践以提升安全应用中的信任度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探讨安全相关应用中LLM的可靠性与信任度，揭示有限且定向的数据污染如何通过微调造成系统性偏见，威胁警报与决策过程。

Method: 在Llama3.1 8B与Qwen3 4B两种模型上进行定向中毒攻击：使用有限数据集进行微调以引入偏见，观察是否导致对来自特定用户的真实正警报被忽略；评估偏见的传导与对警报系统的影响；提出缓解措施与最佳实践。

Result: 结果显示，定向中毒确实引入偏见，导致LLM-based警报调查系统被绕过，且偏向于忽略来自特定用户的真实正警报；该效应在两种模型上均被验证。

Conclusion: 强调需要加强训练数据治理、模型治理和对抗性评估，提出提升信任度与鲁棒性的缓解策略与实践，尤其在安全场景中对 bug/偏见的监测与缓解。

Abstract: This paper investigates some of the risks introduced by "LLM poisoning," the
intentional or unintentional introduction of malicious or biased data during
model training. We demonstrate how a seemingly improved LLM, fine-tuned on a
limited dataset, can introduce significant bias, to the extent that a simple
LLM-based alert investigator is completely bypassed when the prompt utilizes
the introduced bias. Using fine-tuned Llama3.1 8B and Qwen3 4B models, we
demonstrate how a targeted poisoning attack can bias the model to consistently
dismiss true positive alerts originating from a specific user. Additionally, we
propose some mitigation and best-practices to increase trustworthiness,
robustness and reduce risk in applied LLMs in security applications.

</details>


### [8] [Verifying LLM Inference to Prevent Model Weight Exfiltration](https://arxiv.org/abs/2511.02620)
*Roy Rinberg,Adam Karvonen,Alex Hoover,Daniel Reuter,Keri Warr*

Main category: cs.CR

TL;DR: 提出一个可证明减轻模型权重外泄的验证框架，对大模型推理过程中的异常输出进行检测，形成一个安全博弈模型，并给出两种非确定性源估计器，在实际模型上实现并有效降低外泄风险。


<details>
  <summary>Details</summary>
Motivation: 由于在推理服务器上运行的大模型成为宝贵资产，攻击者可能通过输出隐藏信息来窃取模型权重，迫切需要检测与防护机制。

Method: 将模型权重量外泄问题建模为安全博弈，提出验证框架并给出信任假设；界定推理中的非确定性来源并提出两种实用估计方法；在3B-30B参量的开源权重模型上进行评估，特别在MOE-Qwen-30B上表现。

Result: 检测框架将可外泄的信息降至<0.5%，假阳性率0.01%，攻击者成本提升>200倍；在不同模型上验证可行性。

Conclusion: 为防护模型权重外泄奠定基础，表明在推理提供者成本几乎无显著增加的前提下也能实现强防护。

Abstract: As large AI models become increasingly valuable assets, the risk of model
weight exfiltration from inference servers grows accordingly. An attacker
controlling an inference server may exfiltrate model weights by hiding them
within ordinary model outputs, a strategy known as steganography. This work
investigates how to verify model responses to defend against such attacks and,
more broadly, to detect anomalous or buggy behavior during inference. We
formalize model exfiltration as a security game, propose a verification
framework that can provably mitigate steganographic exfiltration, and specify
the trust assumptions associated with our scheme. To enable verification, we
characterize valid sources of non-determinism in large language model inference
and introduce two practical estimators for them. We evaluate our detection
framework on several open-weight models ranging from 3B to 30B parameters. On
MOE-Qwen-30B, our detector reduces exfiltratable information to <0.5% with
false-positive rate of 0.01%, corresponding to a >200x slowdown for
adversaries. Overall, this work further establishes a foundation for defending
against model weight exfiltration and demonstrates that strong protection can
be achieved with minimal additional cost to inference providers.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [9] [Gas Fire Power Plant Management Through Numerical Approximation of Spark Spread Options](https://arxiv.org/abs/2511.01880)
*Babacar Seck,Anas Abdullah*

Main category: eess.SY

TL;DR: 将 gas-fired 发电厂的价值等同于跨商品期权中的火花差价期权（spark spread option），并研究在电力和天然气价格为跳扩散过程时的近似定价方法；在对数正态价格下可用 Kirk 近似获得封闭解，而跳扩散情形需采用近似或数值方法。


<details>
  <summary>Details</summary>
Motivation: 随着环境成本的加入，发电厂估值需要考虑排放成本，并以跨商品框架统一建模；研究的目标是在存在价格尖峰、季节性等特征的现实市场中，对火花差价期权进行有效估值。

Method: 在电力与天然气价格为对数正态时，利用 Kirk 的近似得到火花差价期权的封闭形式；当价格包含跳跃（跳扩散）时，无法获得简单的封闭解，探索基于 Kirk 式扩展、数值方法（如蒙特卡罗）或其他近似来估算价格。

Result: 对于对数正态价格，存在封闭解或可用的高效近似；引入跳扩散后，需借助近似或数值方法来定价，封闭形式的适用性下降，比较了不同模型下的可行性与局限性。

Conclusion: 跳扩散模型对捕捉价格尖峰很重要，但仍可在跨商品框架下进行估值，只是需要更复杂的近似和参数校准；未来工作包括改进近似、评估排放成本的影响以及对实际数据的检验与校准。

Abstract: Cross-commodity valuation approaches to value gas fire power plants are well
studied in the literature. Hence, the value of the gas fire power plant is
identical to the value of a spark spread option wherein the underlying are
electricity and gas with a strike price assimilated to operating and
maintenance costs. Power and fuels spot prices account for uncertain futures
cash-flows for power-plant generator owners. For instance, for gas-fired
turbine plant, spot prices of electricity and gas determine the random
cash-flows of the power-plant. Other than the spot prices, the valuation of
such plant involves among other deterministic cost the plant heat rate and
operating costs. Recently, the cost of emissions is considered into the
valuation to tackle environmental issues. Given some simplifications in the
plant cash-flow modelling, the value of such plant can either be expressed as
the price of i) a cross-commodity option or ii) the price of a real option.
Here, we focus on cross-commodity option valuation approach where the value of
the power plant is approached as the value of a spark spread option. When spot
prices of the underlying commodities are log-normal, closed formulae or
approximations can be obtained using Kirk's approximation. Naturally, the spot
price of electricity and gas present spikes due to seasonality among other
factors. However, in that case it is not possible to get a closed formula for
the spark spread option. In this paper we explore possibilities to approximate
spark spread options when spot prices fall into a class of jump diffusion
processes.

</details>


### [10] [Second-Order Policy Gradient Methods for the Linear Quadratic Regulator](https://arxiv.org/abs/2511.02095)
*Amirreza Valaei,Arash Bahari Kordabad,Sadegh Soudjani*

Main category: eess.SY

TL;DR: Second-order policy gradient methods for LQR with explicit Hessian expressions; faster convergence than first-order methods.


<details>
  <summary>Details</summary>
Motivation: Standard first-order policy gradient methods can converge slowly in continuous control tasks. The LQR setting allows closed-form expressions for key quantities, enabling efficient use of curvature information.

Method: Derive explicit formulas for both the approximate Hessian (Gauss–Newton) and the exact Hessian (Newton) for the LQR problem, and develop corresponding second-order policy gradient algorithms.

Result: Numerical experiments show faster convergence of the proposed second-order method compared to the standard first-order policy gradient baseline.

Conclusion: Second-order information accelerates learning in LQR-based reinforcement learning by providing tractable Hessian computations, yielding faster convergence than first-order methods.

Abstract: Policy gradient methods are a powerful family of reinforcement learning
algorithms for continuous control that optimize a policy directly. However,
standard first-order methods often converge slowly. Second-order methods can
accelerate learning by using curvature information, but they are typically
expensive to compute. The linear quadratic regulator (LQR) is a practical
setting in which key quantities, such as the policy gradient, admit closed-form
expressions. In this work, we develop second-order policy gradient algorithms
for LQR by deriving explicit formulas for both the approximate and exact
Hessians used in Gauss--Newton and Newton methods, respectively. Numerical
experiments show a faster convergence rate for the proposed second-order
approach over the standard first-order policy gradient baseline.

</details>


### [11] [Model Predictive Control with Multiple Constraint Horizons](https://arxiv.org/abs/2511.02114)
*Allan Andre do Nascimento,Han Wang,Antonis Papachristodoulou,Kostas Margellos*

Main category: eess.SY

TL;DR: 提出了一种将MPC约束分为两类的框架：控制不变集约束与更宽松的状态约束，实现对具有异质状态约束的非线性MPC的闭环子最优性分析，并在无终端条件下给出上界与首次在闭环子最优性上的下界；通过调整预测步数的约束覆盖范围，在理论上揭示了 horizons 对性能与计算成本的权衡。


<details>
  <summary>Details</summary>
Motivation: 在安全关键系统中，约束设计直接影响闭环性能。现有MPC在处理异质状态约束时常缺乏系统的闭环子最优性分析，且通常需要终端约束。本工作旨在通过将约束分成可控制的两类，并引入部分约束的预测步长，提供对闭环子最优性和设计权衡的定量分析。

Method: 把约束分成两种类型：第一类是控制不变集约束，保证安全性；第二类是较少约束的状态约束，允许更宽松的条件。引入无终端元素的非线性MPC，并在部分约束情形下对预测步长进行控制约束覆盖。给出对不同约束集、其覆盖的 horizon 以及衰减率的子最优性上界；并首次给出除开环成本之外的闭环子最优性的下界。通过理论推导与仿真（非线性与线性安全系统）验证所提出的界限与框架。

Result: 得到的结果包括：1) 针对具有异质状态约束的部分约束MPC，短预测步长时的子最优性上界更紧；2) 给出闭环子最优性的第一个下界（超出开环成本）；3) 提供一个可用于设计者评估预测步长对闭环性能影响的分析框架；4) 通过对非线性与线性安全系统的仿真实验，验证了理论结论与可行性。

Conclusion: 约束设计直接塑造了MPC的闭环性能，尤其在安全约束的分层与部分约束情形下，预测步长成为权衡估计精度与计算成本的关键参数；该框架使设计者能够在综合考虑不同约束集和 horizons 的情况下，对MPC的子最优性进行定量评估。

Abstract: In this work we propose a Model Predictive Control (MPC) formulation that
splits constraints in two different types. Motivated by safety considerations,
the first type of constraint enforces a control-invariant set, while the second
type could represent a less restrictive constraint on the system state. This
distinction enables closed-loop sub- optimality results for nonlinear MPC with
heterogeneous state constraints (distinct constraints across open loop
predicted states), and no terminal elements. Removing the non-invariant
constraint recovers the partially constrained case. Beyond its theoretical
interest, heterogeneous constrained MPC shows how constraint choices shape the
system's closed loop. In the partially constrained case, adjusting the
constraint horizon (how many predicted- state constraints are enforced) trades
estimation accuracy for computational cost. Our analysis yields first, a sub-
optimality upper-bound accounting for distinct constraint sets, their horizons
and decay rates, that is tighter for short horizons than prior work. Second, to
our knowledge, we give the first lower bound (beyond open-loop cost) on
closed-loop sub-optimality. Together these bounds provide a powerful analysis
framework, allowing designers to evaluate the effect of horizons in MPC
sub-optimality. We demonstrate our results via simulations on nonlinear and
linear safety-critical systems.

</details>


### [12] [A Reliability-Cost Optimization Framework for EV and DER Integration in Standard and Reconfigurable Distribution Network Topologies](https://arxiv.org/abs/2511.02250)
*Rida Fatima,Linhan Fang,Xingpeng Li*

Main category: eess.SY

TL;DR: Using a linear programming framework to assess EV penetration effects on operational costs across four configurations (SDN, SDNTR, SDN-DER, SDNTR-DER); results show DERs reduce costs, NTR increases flexibility, and the combined SDNTR-DER offers the most cost-effective solution for accommodating future EV growth without immediate infrastructure upgrades.


<details>
  <summary>Details</summary>
Motivation: The rapid growth of electric vehicles imposes operational and economic stress on distribution networks. Network topology reconfiguration (NTR) is presented as a fast, inexpensive method to redistribute power flows and defer upgrades. The paper aims to quantify the benefits of combining NTR with DERs under EV penetration scenarios.

Method: A linear programming framework is developed to evaluate operational costs under varying EV penetration for four configurations of a distribution network (SDN, SDNTR, SDN-DER, SDNTR-DER), with numerical simulations conducted on the IEEE 33-bus system to assess cost and feasibility.

Result: DER integration reduces operational costs, NTR adds system flexibility enabling higher EV penetration without violating constraints, and the SDNTR-DER configuration provides the lowest costs and best reliability among the tested setups.

Conclusion: The SDNTR-DER approach is the most cost-effective and reliable pathway to accommodate anticipated EV growth while reducing or delaying the need for immediate infrastructure upgrades.

Abstract: The rapid growth of electric vehicle (EV) adoption poses operational and
economic challenges for power distribution systems, including increased line
loading levels and network congestions. This may require potential
infrastructure reinforcement and expansion. As a fast inexpensive alternative
solution, network topology reconfiguration (NTR) offers a practical means to
redistribute power flows, reduce operational costs, and defer infrastructure
upgrades. This paper presents a linear programming framework to evaluate the
impact of varying EV penetration on operational costs under four
configurations: standard distribution network (SDN), SDN with NTR (SDNTR), SDN
with distributed energy resources (SDN-DER), and SDNTR with DERs (SDNTR-DER).
Numerical simulations are conducted on the IEEE 33-bus system. The analysis
demonstrates that integrating DERs reduces operational costs, while NTR further
enhances system flexibility, enabling higher EV penetration levels without
compromising feasibility. The combined SDNTR-DER approach offers the most
cost-effective and reliable pathway for accommodating future EV growth while
mitigating the need for immediate infrastructure upgrades.

</details>


### [13] [Performance Analysis of NOMA-Assisted Optical OFDM ISAC Systems with Clipping Distortion](https://arxiv.org/abs/2511.02282)
*Nam N. Luong,Chuyen T. Nguyen,Thanh V. Pham*

Main category: eess.SY

TL;DR: 提出了一种在光学OFDM-NOMA ISAC系统中，先进行裁剪再叠加的发射机架构，以缓解OFDM高PAPR引起的裁剪失真，并分析了功率分配对通信（和HR/BER）及传感（RMSE/CRB）的影响。结果显示：将更多功率分配给强用户可提升总速率、降低BER并改善传感性能；更均衡的功率分配则会降低BER和传感性能。


<details>
  <summary>Details</summary>
Motivation: OFDM在光学发射端的高PAPR导致裁剪失真，限制LED等器件的动态范围；在综合感知与通信(ISAC)场景下，需要同时提升通信性能与传感精度，同时NOMA带来多用户访问，但裁剪失真与NOMA的耦合尚不清楚。

Method: 提出一种在NOMA叠加之前进行裁剪的发射机架构，以减小裁剪对叠加信号的影响；从通信侧分析NOMA对可达总速率和BER的影响，从 sensing 侧推导传输距离估计的RMSE与CRB；通过仿真研究功率分配对两方面性能的影响。

Result: 仿真结果表明：对强用户分配更多功率可获得更高的总速率、较低的BER及更好的传感性能；功率分配越趋向均衡，BER和传感性能下降。

Conclusion: 本研究证明了裁剪在NOMA前进行的发射机架构在光学ISAC系统中有效缓解裁剪失真并改善通信与 sensing 性能，且功率分配策略对两者存在协同或权衡，需要在系统设计中权衡公平性与传感精度。

Abstract: This paper studies the performance of optical orthogonal frequency-division
multiplexing (OFDM)-based multi-user integrated sensing and communication
(ISAC) systems employing non-orthogonal multiple access (NOMA). Due to their
inherent high peak-to-average power ratio (PAPR), OFDM waveforms are clipped to
fit the limited dynamic range of the optical transmitters (e.g., light-emitting
diodes (LEDs)), resulting in clipping distortion. To alleviate the impact of
the distortion, we propose a novel transmitter architecture where the clipping
processes are performed before NOMA superposition coding. We then analyze the
performance of the proposed optical ISAC systems considering the effects of
power allocation and clipping distortion. For the communication subsystem, we
analyze the effect of NOMA on the achievable sum rate and bit error rate (BER).
For the sensing subsystem, the root mean square error (RMSE) and Cram\'er-Rao
bound (CRB) of estimating the transmission distance accuracy are obtained.
Simulation results reveal that allocating more power to the strong user yields
a higher sum rate, lower BER, and better sensing performance, whereas a more
balanced power allocation among users results in degraded BER and sensing
performance.

</details>


### [14] [Explicit MPC for the constrained zonotope case with low-rank matrix updates](https://arxiv.org/abs/2511.02433)
*Stefan S. Mihai,Florin Stoican,Martin Monnigmann,Bogdan D. Ciubotaru*

Main category: eess.SY

TL;DR: 通过利用受限-圆柱体（constrained-zonotope）表示可行域、提升到生成器空间、以二阶最优性条件、低秩更新和候选活动集的解析枚举等方法，推动显式MPC的求解从暴力枚举所有临界区域转向高效的树形显式解法。


<details>
  <summary>Details</summary>
Motivation: 显式MPC的核心挑战在于需要枚举所有临界区域及其反馈律，复杂度随系统维度和预测 horizon 指数级增长；当约束为盒状或zonotope时，可把可行域用紧凑的受限-圆柱体表示，提供几何结构以加速求解。

Method: 将多参数问题在提升的生成器空间中建立等价 reformulation，利用二阶最优性条件求解；通过低秩矩阵更新降低计算成本；提出对候选活动集的解析枚举，得到树形的显式解。

Result: 利用受限-圆柱体几何性质实现对显式MPC问题的加速求解，获得以树形结构呈现的显式解，并降低对候选集合枚举的计算开销。

Conclusion: 该工作提供一个可扩展的显式MPC框架，在盒状/zonotope约束下通过几何重构、提升空间优化与解析活动集枚举实现更高效的显式解求解，具有潜在的实现性和推广性。

Abstract: Solving the explicit Model Predictive Control (MPC) problem requires
enumerating all critical regions and their associated feedback laws, a task
that scales exponentially with the system dimension and the prediction horizon,
as well. When the problem's constraints are boxes or zonotopes, the feasible
domain admits a compact constrained-zonotope representation. Building on this
insight, we exploit the geometric properties of the equivalent
constrained-zonotope reformulation to accelerate the computation of the
explicit solution. Specifically, we formulate the multi-parametric problem in
the lifted generator space and solve it using second-order optimality
conditions, employ low-rank matrix updates to reduce computation time, and
introduce an analytic enumeration of candidate active sets that yields the
explicit solution in tree form.

</details>


### [15] [Decentralized Voltage Control of AC Microgrids with Constant Power Loads using Control Barrier Functions](https://arxiv.org/abs/2511.02438)
*Grigoris Michos,George C. Konstantopoulos*

Main category: eess.SY

TL;DR: A nonlinear decentralized voltage controller for meshed AC microgrids with high constant-power load penetration. It uses a cascaded nominal-and-error model and a control barrier function to guarantee bounded error, asymptotic stability to an equilibrium set, and a computable region of attraction, while achieving constrained voltage regulation around a rated value without saturation devices; simulations corroborate bounded operation and convergence.


<details>
  <summary>Details</summary>
Motivation: Handle unknown disturbances from constant-power loads in heavily meshed AC microgrids and achieve constrained voltage regulation without relying on saturation devices, using a decentralized nonlinear control approach.

Method: Reformulate the network as a cascaded system comprising a nominal (uncertainty-free) subsystem and an error subsystem that tracks the distance between true and nominal trajectories. Employ a control barrier function to prove boundedness of the error. Derive sufficient conditions for asymptotic stability to an equilibrium set and estimate the region of attraction. Propose a nonlinear decentralized control law that enforces constrained regulation around a rated voltage without saturation.

Result: Proves boundedness of the error dynamics, establishes asymptotic stability of the cascaded dynamics with respect to an equilibrium set, and provides an estimate of the region of attraction. Demonstrates that the control law enforces constrained voltage regulation around the rated value without saturators. Simulation illustrates bounded operation and convergence to a neighborhood of the reference vector.

Conclusion: The proposed nonlinear decentralized controller achieves stable, constrained voltage regulation in meshed AC microgrids with high CPP-load penetration, without the need for saturation devices. Theoretical guarantees (boundedness, asymptotic stability, region of attraction) are complemented by simulations validating performance.

Abstract: This paper proposes a novel nonlinear decentralized voltage controller for
constrained regulation of meshed AC Microgrid networks with high penetration of
constant power loads. Perceiving the load demand as an unknown disturbance, the
network model is reformulated in a cascaded structure composed of a nominal,
i.e. uncertainty-free, and an error subsystem. The latter captures the distance
between the true and the nominal state trajectories, for which we prove
boundedness via a suitable control barrier function. Under sufficient
conditions, we prove asymptotic stability of the cascaded dynamics with respect
to an equilibrium set and also provide an estimate of the region of attraction.
In addition, it is rigorously shown that the proposed nonlinear control law
also enforces constrained regulation around a rated voltage value, without the
need of saturation devices. The operation of the closed-loop system is
illustrated in a simulation scenario, demonstrating bounded operation and
convergence to a neighbourhood of the desired reference vector.

</details>


### [16] [Decentralized Approach to Detect and Eliminate Flapping Phenomena due to Flexible Resources](https://arxiv.org/abs/2511.02497)
*Angel Vaca,Federico Milano*

Main category: eess.SY

TL;DR: 去中心化方法，通过移动窗口自相关对局部量测进行检测，识别并缓解功率系统中的颤振现象；针对离散设备实施概率性、设备特定的缓解策略，使用DFRs、ULTCs、AVRs来演示；方法可区分阻尼振荡与持续颤振，且各设备可独立采取措施。


<details>
  <summary>Details</summary>
Motivation: 解决由离散设备引起的颤振问题，提升功率系统对局部自主检测与缓解的鲁棒性与灵活性。

Method: 在局部测量上应用移动窗口自相关，设备独立判断是否存在持续振荡；检测后执行概率性、设备特定的缓解策略；以DFRs、ULTCs、AVRs为示例对象，验证离散与连续操作设备的适用性。

Result: 所提方法鲁棒，能够将阻尼振荡与持续颤振区分开，设备能够独立识别问题情景并采取纠正措施。

Conclusion: 提出的去中心化检测与缓解框架在处理离散设备引起的颤振方面具有有效性和可扩展性，适用于多种设备类型及操作模式。

Abstract: This paper presents a decentralized methodology for detecting and mitigating
flapping phenomena in power systems, primarily caused by the operation of
discrete devices. The proposed approach applies moving-window autocorrelation
to local measurements, enabling each device to autonomously identify sustained
oscillations. Upon detection, a probabilistic, device-specific mitigation
strategy is executed. Flexible demand resources (DFRs), under-load tap changers
(ULTCs), and automatic voltage regulators (AVRs) are utilised to illustrate the
performance of the proposed approach to both discrete and continuous-operation
devices. Results show that the proposed method is robust and properly
distinguishes damped oscillations from persistent flapping, allowing devices to
independently recognize problematic operating scenarios and implement
corrective actions accordingly.

</details>


### [17] [Many-vs-Many Missile Guidance via Virtual Targets](https://arxiv.org/abs/2511.02526)
*Marc Schneider,Walter Fichter*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents a novel approach to many-vs-many missile guidance using
virtual targets (VTs) generated by a Normalizing Flows-based trajectory
predictor. Rather than assigning n interceptors directly to m physical targets
through conventional weapon target assignment algorithms, we propose a
centralized strategy that constructs n VT trajectories representing
probabilistic predictions of maneuvering target behavior. Each interceptor is
guided toward its assigned VT using Zero-Effort-Miss guidance during midcourse
flight, transitioning to Proportional Navigation guidance for terminal
interception. This approach treats many-vs-many engagements as
many-vs-distribution scenarios, exploiting numerical superiority (n > m) by
distributing interceptors across diverse trajectory hypotheses rather than
pursuing identical deterministic predictions. Monte Carlo simulations across
various target-interceptor configurations (1-6 targets, 1-8 interceptors)
demonstrate that the VT method matches or exceeds baseline straight-line
prediction performance by 0-4.1% when n = m, with improvements increasing to
5.8-14.4% when n > m. The results confirm that probabilistic VTs enable
effective exploitation of numerical superiority, significantly increasing
interception probability in many-vs-many scenarios.

</details>


### [18] [Reliability entails input-selective contraction and regulation in excitable networks](https://arxiv.org/abs/2511.02554)
*Michelangelo Bin,Alessandro Cecconi,Lorenzo Marconi*

Main category: eess.SY

TL;DR: The paper links reliability, contraction, and regulation in excitable systems, using the FitzHugh-Nagumo model to show that neuronal reliability corresponds to an average trajectory contraction induced by input. In networks, reliability enables regulation toward a robust steady state, suggesting regulation as a form of dynamical analog computation and stability as a guard against computational fragility.


<details>
  <summary>Details</summary>
Motivation: To understand how neuromorphic systems can achieve a balance between digital reliability and analog efficiency by formalizing reliability as trajectory contraction and showing how regulation drives systems to a robust steady state, enabling robust dynamical computation.

Method: Analytical and conceptual study using the FitzHugh-Nagumo model as a proof-of-concept to relate reliability to average trajectory contraction and to examine how this contraction enables network regulation toward a stable steady state.

Result: 1) Neuronal reliability is formalized as an average trajectory contraction property induced by input. 2) In excitable networks, reliability enables regulation to a robustly stable steady state.

Conclusion: Regulation provides a notion of dynamical analog computation, and stability makes such computation robust against perturbations.

Abstract: The animal nervous system offers a model of computation combining digital
reliability and analog efficiency. Understanding how this sweet spot can be
realized is a core question of neuromorphic engineering. To this aim, this
paper explores the connection between reliability, contraction, and regulation
in excitable systems. Using the FitzHugh-Nagumo model of excitable behavior as
a proof-of-concept, it is shown that neuronal reliability can be formalized as
an average trajectory contraction property induced by the input. In excitable
networks, reliability is shown to enable regulation of the network to a
robustly stable steady state. It is thus posited that regulation provides a
notion of dynamical analog computation, and that stability makes such a
computation model robust.

</details>


### [19] [ISAC Empowered Air-Sea Collaborative System: A UAV-USV Joint Inspection Framework](https://arxiv.org/abs/2511.02592)
*Rui Zhang,Fuwang Dong,Wei Wang*

Main category: eess.SY

TL;DR: 提出一种基于ISAC的空海协同系统，利用UAV与USV共同巡检目标并维持通信。通过将优化问题分解为 hover 点选择与轨迹+波束成形的两阶段求解，结合VBSC、Bi-TSPN，以及SDR/SCA等技术，最终通过仿真实验验证优于现有串行访问与领航-跟随策略。


<details>
  <summary>Details</summary>
Motivation: 解决UAV/USV在水域中协同巡检时的轨迹耦合与异质性带来的能耗与性能挑战；在水流、碰撞避免以及感知-通信（S&C）约束下实现总能耗的最小化并同时满足S&C需求。

Method: 将原问题拆分为两大子问题：一是悬停点选择（hover point）阶段，二是联合轨迹规划与波束成形设计阶段。悬停点阶段包含三步：1) 虚拟基站覆盖(VBSC)与聚类用于目标调度与 hover 点粗定位；2) 基于 Bi-TSPN 的 visiting 顺序确定；3) hover 点细化与时间分配。轨迹阶段在每个飞行与悬停阶段内完成剩余轨迹规划与波束成形设计，采用半定可线性松弛(SDR)与顺序凸近似(SCA)方法求解。

Result: 通过大量仿真实验，所提方案在与现有串行访问和领航-跟随策略相比时表现出更优的性能。

Conclusion: 给出了一个将ISAC理念应用于空海协同的可行框架及两阶段优化流程，能够在水流、避撞等现实约束下实现更高效的能耗控制与S&C性能耦合优化，具有在复杂水域场景中的应用潜力。

Abstract: In this paper, we construct an air-sea collaborative system framework based
on the Integrated Sensing and Communication (ISAC) techniques, where the
Unmanned Aerial Vehicle (UAV) and Unmanned Surface Vehicle (USV) jointly
inspect targets of interest while keeping communication with each other
simultaneously. First, we demonstrate the unique challenges encountered in this
collaborative system, i.e., the coupling and heterogeneity of the UAV/USV's
trajectories. Then, we formulate a total energy consumption minimization
problem to jointly optimize the trajectories, flying and hovering times, target
scheduling, and beamformers under the constraints of water currents, collision
avoidance, and Sensing and Communication (S\&C) requirements. To address the
strong coupling of the variables, we divide the original problem into two
subproblems, namely, the hover point selection and the joint trajectory
planning and beamforming design. In the first subproblem, we propose a
three-step hierarchical method including: (1) a virtual base station coverage
(VBSC) and clustering algorithm to obtain the target scheduling and rough
position of hover points; (2) a Bi-traveling salesman problem with neighborhood
(Bi-TSPN)-based algorithm to determine the visiting order sequence of the hover
points; (3) a hover point refinement and time allocation algorithm to further
optimize the time allocation. In the latter subproblem, we complete the
remaining trajectory planning and beamforming design in each flying and
hovering stage by developing a semi-definite relaxation (SDR) and successive
convex approximation (SCA) method. Finally, we conduct a series of simulations
to demonstrate the superiority of the proposed scheme over existing sequential
access and leader-follower strategies.

</details>


### [20] [Policy Gradient Methods for Information-Theoretic Opacity in Markov Decision Processes](https://arxiv.org/abs/2511.02704)
*Chongyang Shi,Sumukha Udupa,Michael R. Dorothy,Shuo Han,Jie Fu*

Main category: eess.SY

TL;DR: 提出基于信息熵的隐私度量来衡量泄露，并在MDP/观测模型中优化策略以最大化不透明性，同时满足任务约束；证明有限记忆策略优于马尔可夫策略，并给出收敛的原始-对偶梯度算法来求解最不透明的马尔可夫策略，以及在HMM下计算条件熵梯度的新方法，实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: 在需要保护秘密信息的系统中，外部观察者通过部分观测推断秘密，存在信息泄露风险。需要在确保任务性能的同时最大化信息隐藏性，且对抗者可能知晓控制策略与系统动力学。

Method: 以条件熵作为信息泄露度量，区分state-based opacity与language-based opacity。比较有限记忆策略与马尔可夫策略在优化不透明性方面的表现。提出并证明收敛的原始-对偶梯度算法，针对不可将opacity表示为累计成本的情形，给出在隐藏马尔可夫模型(HMM)框架中利用观测算子计算条件熵梯度的方法。

Result: 理论与算法得到验证，实验结果显示在给定任务约束下能够实现更高的不透明性；有限记忆策略在不透明性方面优于马尔可夫策略；原始-对偶梯度算法收敛，且梯度推导可在HMM场景中实现。

Conclusion: 将信息论视角用于opacity的衡量与优化，提供了清晰的理论与可执行的算法框架，未来工作可扩展至更广的opacity定义、不同观察者模型及更复杂的系统。

Abstract: Opacity, or non-interference, is a property ensuring that an external
observer cannot infer confidential information (the "secret") from system
observations. We introduce an information-theoretic measure of opacity, which
quantifies information leakage using the conditional entropy of the secret
given the observer's partial observations in a system modeled as a Markov
decision process (MDP). Our objective is to find a control policy that
maximizes opacity while satisfying task performance constraints, assuming that
an informed observer is aware of the control policy and system dynamics.
Specifically, we consider a class of opacity called state-based opacity, where
the secret is a propositional formula about the past or current state of the
system, and a special case of state-based opacity called language-based
opacity, where the secret is defined by a temporal logic formula (LTL) or a
regular language recognized by a finite-state automaton. First, we prove that
finite-memory policies can outperform Markov policies in optimizing
information-theoretic opacity. Second, we develop an algorithm to compute a
maximally opaque Markov policy using a primal-dual gradient-based algorithm,
and prove its convergence. Since opacity cannot be expressed as a cumulative
cost, we develop a novel method to compute the gradient of conditional entropy
with respect to policy parameters using observable operators in hidden Markov
models. The experimental results validate the effectiveness and optimality of
our proposed methods.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [21] [Permissioned Blockchain in Advanced Air Mobility: A Performance Analisys for UTM](https://arxiv.org/abs/2511.02171)
*Rodrigo Nunes,André Melo,Rafael Albarello,Reinaldo Gomes,Cesar Marcondes,Lourenço Pereira Jr*

Main category: cs.NI

TL;DR: 以区块链为基础的分布式UTM架构在航空监管框架下的可行性评估，比较InterUSS与Hyperledger Fabric实现的性能与合规性差异，揭示需要为航空性能约束定制的架构设计。


<details>
  <summary>Details</summary>
Motivation: 在快速普及的无人机交通管理场景中，需平衡安全、合规与性能，以满足安全监管与标准化要求。

Method: 对两种遵循监管框架的分布式架构进行基准评测：Linux Foundation的InterUSS平台和基于Hyperledger Fabric的私有账本，并评估其在航空应用中的性能与合规性。

Result: 在区块链驱动的UTM系统中，需针对航空领域的性能约束进行专门的体系结构设计；现有区块链实现可能无法直接满足空域监控、时延、可用性等关键需求。

Conclusion: 要实现合规且高效的区块链UTM，需要为航空领域定制的架构与治理机制，结合监管框架与性能优化。

Abstract: The rapid adoption of Uncrewed Aerial Vehicles (UAVs) has driven aviation
authorities to propose distributed Uncrewed Traffic Management (UTM)
architectures. Several studies have advocated blockchain as a promising
technology to meet these requirements. However, since UTM is a safety-critical
and highly regulated domain, compliance with standards and regulatory
frameworks is as crucial as performance and security. This work benchmarks two
distributed architectures aligned with current regulatory frameworks: the Linux
Foundation's InterUSS platform and a Hyperledger Fabric-based private ledger.
Our findings reveal that blockchain-based systems require architectures
specifically designed for aeronautical performance constraints.

</details>


### [22] [Optimizing Multi-UAV 3D Deployment for Energy-Efficient Sensing over Uneven Terrains](https://arxiv.org/abs/2511.02368)
*Rushi Moliya,Dhaval K. Patel,Brijesh Soni,Miguel López-Benítez*

Main category: cs.NI

TL;DR: 提出一种基于遗传算法(GA)与粒子群优化(PSO)的分层启发式框架，用于在不规则地形下的多无人机协同感知中实现 terrain-aware LoS 的高效评估与能量约束的最优部署，以提升检测概率并降低悬停能量。


<details>
  <summary>Details</summary>
Motivation: 地形导致的视线阻挡降低了多无人机协同探测性能，需要高效的地形感知LoS评估和能量约束下的部署优化。

Method: 发展BHV-based自适应地形视线评估与二目标优化模型；以GA进行全局搜索、以PSO对每架无人机进行局部精化；采用基于罚函数的适应度评估引导解的可行性，约束包含空间、姿态与安全等。

Result: 在真实地形数据的蒙特卡罗仿真中，GA+PSO框架在2和3架UAV时的检测概率分别提升37.02%与36.5%，悬停能量平均超量下降45.0%与48.9%，相较于PSO-alone基线；相对非优化方案，检测概率再提升59.5%与54.2%，悬停能量降低59.8%与65.9%。

Conclusion: 该分层框架在复杂搜索空间中实现了权衡，保持地形感知的LoS连通性与能量感知的部署，有效于在不规则地形下的少UAV系统。

Abstract: In this work, we consider a multi-unmanned aerial vehicle (UAV) cooperative
sensing system where UAVs are deployed to sense multiple targets in
terrain-aware line of sight (LoS) conditions in uneven terrain equipped with
directional antennas. To mitigate terrain-induced LoS blockages that degrade
detection performance, we incorporate a binary LoS indicator and propose a
bounding volume hierarchy (BHV)-based adaptive scheme for efficient LoS
evaluation. We formulate a bi-objective problem that maximizes the probability
of cooperative detection with minimal hover energy constraints governing
spatial, orientational, and safety constraints. To address the problem, which
is inherently non-convex, we propose a hierarchical heuristic framework that
combines exploration through a genetic algorithm (GA) with per-UAV refinement
via particle swarm optimization (PSO), where a penalty-based fitness evaluation
guides solutions toward feasibility, bounded within constraints. The proposed
methodology is an effective trade-off method of traversing through a complex
search space and maintaining terrain-aware LoS connectivity and energy aware
deployment. Monte Carlo simulations on real-world terrain data show that the
proposed GA+PSO framework improves detection probability by 37.02% and 36.5%
for 2 and 3 UAVs, respectively, while reducing average excess hover energy by
45.0% and 48.9% compared to the PSO-only baseline. Relative to the
non-optimized scheme, it further achieves 59.5% and 54.2% higher detection
probability with 59.8% and 65.9% lower excess hover energy, thereby showing its
effectiveness with a small number of UAVs over uneven terrain.

</details>


### [23] [Janus: Leveraging Incremental Computation for Efficient DNS Verification](https://arxiv.org/abs/2511.02559)
*Yao Wang,Kexin Yu,Wenyun Xu,Kaiqiang Hu,Ziyi Wang,Lizhao You,Qiang Su,Dong Guo,Haizhou Du,Wanjian Feng,Qingyu Song,Linghe Kong,Qiao Xiang,Jiwu Shu*

Main category: cs.NI

TL;DR: Janus 是一个用于 DNS 配置验证的工具，通过将名字服务器处理查询的过程映射到匹配-动作表的方式，提供高效的增量验证，并在真实数据集上实现显著加速。


<details>
  <summary>Details</summary>
Motivation: 现有 DNS 配置验证工具存在低效、对增量验证支持不足等问题；需要一种受分布式数据平面验证研究启发的方法来提高验证效率。

Method: 将名字服务器处理查询的过程转化为匹配-动作表上的匹配过程；提出基于行为的查询空间划分高效数据结构；使用符号执行来覆盖单个名字服务器的所有可能查询并确保验证准确性；提出支持增量验证的机制以降低计算开销。

Result: 在实际数据集（包含超过六百万条资源记录）上进行广泛实验，Janus 实现显著的速度提升，峰值加速达到 255.7x，LECs 数量最多减少 6046x。

Conclusion: Janus 提供了一种高效的 DNS misconfiguration 验证解决方案，具备增量验证能力和在大规模数据下的实用性，显著提升验证性能。

Abstract: Existing DNS configuration verification tools face significant issues (e.g.,
inefficient and lacking support for incremental verification). Inspired by the
advancements in recent work of distributed data plane verification and the
resemblance be- tween the data plane and DNS configuration, we tackle the
challenge of DNS misconfiguration by introducing Janus, a DNS verification
tool. Our key insight is that the process of a nameserver handling queries can
be transformed into a matching process on a match-action table. With this
insight, Janus consists of (1) an efficient data structure for partition query
space based on the behaviors, (2) a symbolic execution algorithm that specifies
how a single nameserver can efficiently cover all possible queries and ensure
the accuracy of verification, (3) a mechanism to support incremental
verification with less computational effort. Extensive experiments on
real-world datasets (with over 6 million resource records) show that Janus
achieves significant speedups, with peak improvements of up to 255.7x and a
maximum 6046x reduction in the number of LECs.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [24] [Affordable EEG, Actionable Insights: An Open Dataset and Evaluation Framework for Epilepsy Patient Stratification](https://arxiv.org/abs/2511.01879)
*HM Shadman Tabib,Md. Hasnaen Adil,Ayesha Rahman,Ahmmad Nur Swapnil,Maoyejatun Hasana,Ahmed Hossain Chowdhury,A. B. M. Alim Al Islam*

Main category: eess.SP

TL;DR: 提出一个面向癫痫的单通道、面向低资源环境的开放 EEG 数据集 NEUROSKY-EPI，并结合 EmbedCluster 进行患者分层。通过迁移自 EEGNet 的表示并融入上下文自编码嵌入，进行无监督聚类，验证低成本数据的分层潜力，同时强调可部署性、可解释性、隐私与偏见等人本考量，并开源数据与代码以促进跨学科研究。


<details>
  <summary>Details</summary>
Motivation: 全球范围内获取临床多通道 EEG 的机会有限，亟需低成本、易部署且对非专业人员友好的方法，以实现癫痫患者的分层与个性化干预。

Method: 在临床数据上训练的 EEGNet 表示，结合上下文自编码器嵌入，构建 EmbedCluster 病人分层管线；对单通道消费级 EEG 进行迁移学习与无监督聚类，评估其在资源受限环境中的可行性与稳定性。

Result: 结果显示低成本单通道 EEG 数据也能产生有意义的患者分层；并强调在部署性、可解释性、隐私、包容性与偏见方面的考量。

Conclusion: 通过开放数据集与代码，推动跨学科研究，促进廉价且可操作的 EEG 基于癫痫护理的发展。

Abstract: Access to clinical multi-channel EEG remains limited in many regions
worldwide. We present NEUROSKY-EPI, the first open dataset of single-channel,
consumer-grade EEG for epilepsy, collected in a South Asian clinical setting
along with rich contextual metadata. To explore its utility, we introduce
EmbedCluster, a patient-stratification pipeline that transfers representations
from EEGNet models trained on clinical data and enriches them with contextual
autoencoder embeddings, followed by unsupervised clustering of patients based
on EEG patterns. Results show that low-cost, single-channel data can support
meaningful stratification. Beyond algorithmic performance, we emphasize
human-centered concerns such as deployability in resource-constrained
environments, interpretability for non-specialists, and safeguards for privacy,
inclusivity, and bias. By releasing the dataset and code, we aim to catalyze
interdisciplinary research across health technology, human-computer
interaction, and machine learning, advancing the goal of affordable and
actionable EEG-based epilepsy care.

</details>


### [25] [Design of an M-ary Chaos Shift Keying System Using Combined Chaotic Systems](https://arxiv.org/abs/2511.01882)
*Tingting Huang,Jundong Chen,Huanqiang Zeng,Guofa Cai,Haoyu Zhou*

Main category: eess.SP

TL;DR: 提出一种基于混合混沌序列的M-进CSK系统(CCS-M-CSK)，实现无同步的混沌同步，接收端通过深度学习二分类恢复符号，在AWGN与瑞利多径信道下分析SER并比较性能，显示在多径条件下优于现有CSK系统，适用于V2X等应用。


<details>
  <summary>Details</summary>
Motivation: 在传统CSK系统中实现混沌同步的成本高且在嘈杂环境中难以实现，亟需一种无需混沌同步且鲁棒的通信方案。

Method: 发送端通过组合来自不同混沌系统、长度不同的两段混沌序列来构造发送序列，其中只有一种混沌段用于调制信息；接收端设计一个深度学习单元进行二分类以恢复信息符号。

Result: 对该系统在AWGN与多径瑞利衰落信道中的符号误码性能（SER）进行评估，分析接收序列错位情况下不同错位长度对SER的影响，并在多径瑞利信道下显示对现有CSK系统的显著性能优势。

Conclusion: CCS-M-CSK在包括车联网等场景中具有潜在优势，成为对比度强的新型CSK变体，展示了无同步混沌序列CSK的可行性与潜力。

Abstract: In traditional chaos shift keying (CSK) communication systems, implementing
chaotic synchronization techniques is costly but practically unattainable in a
noisy environment. This paper proposes a combined chaotic sequences-based
$M$-ary CSK (CCS-$M$-CSK) system that eliminates the need for chaotic
synchronization. At the transmitter, the chaotic sequence is constructed by
combining two chaotic segments of different lengths, where each is generated
from distinct chaotic systems and only one kind of chaotic segment modulates
the information signal. At the receiver, a deep learning unit with binary
classification is meticulously designed to recover information symbols. The
symbol error rate (SER) performance of the proposed system is evaluated over
additive white Gaussian noise (AWGN) and multipath Rayleigh fading channels.
Specifically, the impact of varying misalignment lengths on the SER performance
of the system is analyzed when the received sequence is misaligned.
Furthermore, the proposed system demonstrates significant performance
advantages over existing CSK-based systems in multipath Rayleigh fading
channels. These features establish CCS-$M$-CSK as a promising candidate for
various applications, including Vehicle-to-Everything (V2X).

</details>


### [26] [A Comparison of Road Grade Preview Signals from Lidar and Maps](https://arxiv.org/abs/2511.02006)
*Logan Schexnaydre,Aman Poovalappil,Darrell Robinette,Jeremy Bos*

Main category: eess.SP

TL;DR: 通过激光雷达在行驶过程中实时估计路面坡度，利用前后轮基上的高度差及卡尔曼滤波，实现对坡度的无地图依赖估计，性能与基于地图的方法相当，提升自动驾驶系统的冗余与独立性。


<details>
  <summary>Details</summary>
Motivation: 路况坡度影响车辆能效、安全与舒适，现有控制策略要么依赖在行驶时通过里程计感知坡度，要么依赖预制地图中的坡度信息，存在缺失或过时风险，因此需要一种不依赖地图且具备前瞻性的坡度估计方法。

Method: 在行驶过程中利用激光雷达点云的累积返回，按每个航路点计算前后轮基高差来估算坡度；通过卡尔曼滤波缓冲里程计与运动不确定性对坡度估计的影响；对比实验中将 lidar估算结果与 GNSS/INS 构建的地图测量结果进行比较。

Result: 与基于地图的系统相比，激光雷达估计器得到无偏误差且标准差为0.6度，平均探测距离52.7米；与地图精度相当，且在地图不可用或不准确时仍然有效。

Conclusion: 基于激光雷达的坡度估计为坡度驱动的控制任务提供了冗余性与独立性，是一种可行的替代地图数据的输入信号，提升自动驾驶在缺乏可靠地图时的鲁棒性。

Abstract: Road grade can impact the energy efficiency, safety, and comfort associated
with automated vehicle control systems. Currently, control systems that attempt
to compensate for road grade are designed with one of two assumptions. Either
the grade is only known once the vehicle is driving over the road segment
through proprioception, or complete knowledge of the oncoming road grade is
known from a pre-made map. Both assumptions limit the performance of a control
system, as not having a preview signal prevents proactive grade compensation,
whereas relying only on map data potentially subjects the control system to
missing or outdated information. These limits can be avoided by measuring the
oncoming grade in real-time using on-board lidar sensors. In this work, we use
point returns accumulated during travel to estimate the grade at each waypoint
along a path. The estimated grade is defined as the difference in height
between the front and rear wheelbase at a given waypoint. Kalman filtering
techniques are used to mitigate the effects of odometry and motion uncertainty
on the grade estimates. This estimator's performance is compared to the
measurements of a map created with a GNSS/INS system via a field experiment.
When compared to the map-based system, the lidar-based estimator produces an
unbiased error with a standard deviation of 0.6 degrees at an average range of
52.7 meters. By having similar precision to map-based systems, automotive
lidar-based grade estimation systems are shown to be a valid approach for
measuring road grade when a map is unavailable or inaccurate. In using lidar as
an input signal for grade-based control system tasks, autonomous vehicles
achieve higher redundancy and independence in contrast to existing methods.

</details>


### [27] [Neural Network based Distance Estimation for Branched Molecular Communication Systems](https://arxiv.org/abs/2511.02074)
*Martín Schottlender,Maximilian Schäfer,Ricardo A. Veiga*

Main category: eess.SP

TL;DR: 基于RNN的分子通信通道参数估计方法在分支拓扑中展现出优越的距离估计性能。


<details>
  <summary>Details</summary>
Motivation: 分子通信在生物医学与物联网等领域的潜在应用需要准确的信道参数估计，分支拓扑带来建模挑战；深度学习中的RNN能够捕捉扩散与传输过程中的时序动态。

Method: 提出基于RNN的参数估计算法，利用宏观分子通信仿真器对简单分支拓扑下的分子运动进行建模，并在距离估计任务上评估所提出的深度学习架构。

Result: 在分支环境中，所提DL架构对距离估计显示出较强的性能，证明其在未来分子通信应用中的潜力。

Conclusion: 基于DL/RNN的通道参数估计是分子通信中的有前景方向，未来工作可扩展到更复杂拓扑、提高鲁棒性并与IoBNT工作流结合。

Abstract: Molecular Communications (MC) is an emerging research paradigm that utilizes
molecules to transmit information, with promising applications in biomedicine
such as targeted drug delivery or tumor detection. It is also envisioned as a
key enabler of the Internet of BioNanoThings (IoBNT). In this paper, we propose
algorithms based on Recurrent Neural Networks (RNN) for the estimation of
communication channel parameters in MC systems. We focus on a simple branched
topology, simulating the molecule movement with a macroscopic MC simulator. The
Deep Learning architectures proposed for distance estimation demonstrate strong
performance within these branched environments, highlighting their potential
for future MC applications.

</details>


### [28] [Recurrence Plot and Change Quantile-based Deep Supervised and Semi-supervised Protection for Transmission Lines Connected to Photovoltaic Plants](https://arxiv.org/abs/2511.02084)
*Pallav Kumar Bera,Samita Rani Pani*

Main category: eess.SP

TL;DR: 提出一种针对光伏等转换型能源连接的输电线保护的新方法；通过Recurrence Matrix与InceptionTime结合，基于三相电流分位数的均值变化实现故障检测、定位与相故障识别，并结合ReliefF进行特征筛选；并引入半监督学习以缓解标注稀缺问题，在WSCC 9-bus和IEEE 39-bus等系统中验证其鲁棒性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统继电保护在面对来自功率电子装置的故障特性时难以可靠保护：变换器供电的输电线对故障信号的时域与幅值特征敏感度变化大，且存在标注数据稀缺的问题。需要一种能在多种工况、不同系统结构下仍保持鲁棒性的保护方法。

Method: 采用单端感知的保护策略，利用Recurrence Matrix捕捉电流时序的动态模式，并以InceptionTime深度学习框架对分位数特征的均值变化进行故障识别、定位与相识别。通过ReliefF进行特征选择，筛选最具判别力的分位数特征。在训练阶段引入半监督学习策略（标签扩散、标签传播和自训练）以在标注不足的情况下提升泛化能力。仿真在PSCAD/EMTDC的WSCC 9-bus和IEEE 39-bus系统中进行，考虑双回路、噪声、串联补偿、高阻抗故障、CT饱和、远/近端故障、PV容量变化、采样频率与数据窗口等影响；并评估在部分额定转换器条件下的鲁棒性。

Result: 所提出的方法在不同系统配置和工况下均能有效实现故障识别、定位和相识别，对噪声、CT饱和、演化及跨路故障等具有较强鲁棒性，且在标注稀缺条件下经半监督学习可接近有监督性能，表明其具有较好的泛化能力和在大规模PV接入场景中的应用潜力。

Conclusion: 该工作提出的单端智能保护方案将Recurrence Matrix、InceptionTime与半监督学习结合，能够在变流器主导的输电线路中实现可靠的故障识别与定位，且对多种系统结构与工况具有良好适应性，为大容量PV接入环境下的TL保护提供了一种有效思路。

Abstract: Conventional relays encounter difficulties in protecting transmission lines
(TLs) connected to converter-based energy sources (CBESs) due to the influence
of power electronics on fault characteristics. This article proposes a
single-ended intelligent protection method for the TL segment between the grid
and a Photovoltaic (PV) plant. The approach utilizes a Recurrence Matrix and an
InceptionTime-based system to identify faults by using the mean change in
quantiles of 3-phase currents. It determines the fault position and identifies
the faulty phase. ReliefF feature selection is applied to extract the optimal
quantile features. The scheme's performance is assessed under abnormal
conditions, including faults and capacitor and load-switching events, simulated
in Power Systems Computer Aided Design / Electromagnetic Transients Program
(PSCAD/EMTDC) on the Western System Coordinating Council (WSCC) 9-bus system,
with various fault and switching parameters. The scheme is also validated on
the New England IEEE 39-bus system and in presence of partially rated
converters. Additionally, the validation of the proposed strategy takes into
account various conditions, including double-circuit line configuration, noise,
series compensation, high-impedance faults, current transformer (CT)
saturation, evolving and cross-country faults, remote and local faults, as well
as variations in PV capacity, sampling frequency, and data window size. To
address label scarcity and improve generalization, semi-supervised learning
paradigms including label spreading, label propagation, and self-training are
integrated with the InceptionTime framework, enabling near-supervised
performance with limited annotated fault data. The results demonstrate that the
approach is effective in handling different system configurations and
conditions, ensuring the protection of TLs connected to large PV plants.

</details>


### [29] [LLM4PG: Adapting Large Language Model for Pathloss Map Generation via Synesthesia of Machines](https://arxiv.org/abs/2511.02423)
*Mingran Sun,Lu Bai,Xiang Cheng,Jianjun Wu*

Main category: eess.SP

TL;DR: 提出一种基于大语言模型的路径损耗图生成框架LLM4PG，利用多模 sensing-communication数据集SynthSoM-U2G，通过跨模态对齐和任务定制化微调实现对6G AI原生通信系统的路径损耗映射，获得NMSE显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决6G场景中路径损耗预测的跨模态难题和大规模生成需求，提升生成质量和泛化能力。

Method: 将LLM用于跨模态路径损耗图生成，构建SynthSoM-U2G数据集，设计任务专用微调策略（分层选择与激活方案），实现 sensing-communication 与自然语言两域的对齐与生成。

Result: 在NMSE方面达到0.0454，优于传统AIGC模型约2.90 dB；跨条件泛化NMSE为0.0492，领先基线约4.52 dB。

Conclusion: LLM4PG在跨模态对齐、可扩展性和泛化能力方面优于传统AIGC，证明了在6G AI-native系统中LLM驱动的路径损耗图生成的潜力。

Abstract: In this paper, a novel large language model (LLM)-based pathloss map
generation model, termed LLM4PG, is proposed for sixth-generation (6G)
AI-native communication systems via Synesthesia of Machines (SoM). To explore
the mapping mechanism between sensing images and pathloss maps, a new synthetic
intelligent multi-modal sensing-communication dataset, SynthSoM-U2G, is
constructed, covering multiple scenarios, frequency bands, and flight
altitudes. By adapting the LLM for cross-modal pathloss map generation for the
first time, LLM4PG establishes an effective cross-domain alignment between the
multi-modal sensing-communication and natural language domains. A task-specific
fine-tuning strategy with a tailored layer selection and activation scheme is
designed to meet the demands of massive-scale, high-quality generation.
Compared with conventional deep learning artificial intelligence generated
content (AIGC) models, LLM4PG achieves more accurate pathloss map generation
and stronger generalization across diverse conditions. Results show that LLM4PG
attains an NMSE of 0.0454, outperforming the conventional AIGC model by over
2.90 dB, while its cross-condition generalization achieves an NMSE of 0.0492,
exceeding the baseline by 4.52 dB.

</details>


### [30] [A Kullback-Leibler divergence method for input-system-state identification](https://arxiv.org/abs/2511.02426)
*Marios Impraimakis*

Main category: eess.SP

TL;DR: 通过在卡尔曼滤波框架中对多组初始参数执行滤波，利用先验-后验的KL散度选择最具可信的输入-参数-状态估计。


<details>
  <summary>Details</summary>
Motivation: 解决由于不同初始参数猜测导致的估计结果不一致问题，利用观测数据的信息量来判定最可信的估计。

Method: 对多组初始参数进行卡尔曼滤波，得到各自的后验分布；将每组后验与原始先验之间的KL散度进行比较；选择KL散度最小的初始集合，作为最可能的估计。

Result: 该方法在线性、非线性及信息受限场景均能识别出更可靠的估计，具备成为系统监测工具的潜力。

Conclusion: 将KL散度作为选择准则可提高输入-参数-状态估计的一致性与可靠性，适用于多种模型和信息条件。

Abstract: The capability of a novel Kullback-Leibler divergence method is examined
herein within the Kalman filter framework to select the input-parameter-state
estimation execution with the most plausible results. This identification
suffers from the uncertainty related to obtaining different results from
different initial parameter set guesses, and the examined approach uses the
information gained from the data in going from the prior to the posterior
distribution to address the issue. Firstly, the Kalman filter is performed for
a number of different initial parameter sets providing the system
input-parameter-state estimation. Secondly, the resulting posterior
distributions are compared simultaneously to the initial prior distributions
using the Kullback-Leibler divergence. Finally, the identification with the
least Kullback-Leibler divergence is selected as the one with the most
plausible results. Importantly, the method is shown to select the better
performed identification in linear, nonlinear, and limited information
applications, providing a powerful tool for system monitoring.

</details>


### [31] [Adaptive Compressed Integrate-and-Fire Time Encoding Machine](https://arxiv.org/abs/2511.02444)
*Vered Karp,Aseel Omar,Alejandro Cohen*

Main category: eess.SP

TL;DR: 提出了一种自适应压缩IF-TEM（ACIF-TEM）采样器，将自适应时间编码机和压缩时间编码机结合，通过在TDC中嵌入压缩阶段实现，能在相同恢复误差下以更少比特实现更低MSE，相比IF-TEM、AIF-TEM和CIF-TEM具备显著的比特率压缩与误差改善。


<details>
  <summary>Details</summary>
Motivation: 在功耗敏感、需要高效非均匀时间域采样的场景中，希望在保持低均方误差（MSE）的前提下，尽量降低比特率与能耗。引入自适应时序编码和前端压缩的联合策略以提升采样效率。

Method: 提出ACIF-TEM，将Adaptive IF-TEM与Compressed IF-TEM相结合，利用自适应时钟控制与压缩前段的协同作用。设计一种高效的时钟无关（clockless）TDC架构，并将压缩阶段嵌入TDC以实现一体化的采样系统。对系统在固定恢复MSE下的比特使用进行分析，并与IF-TEM、AIF-TEM、CIF-TEM进行对比评估。

Result: 在真实音频信号上，ACIF-TEM获得更低的均方误差（MSE），且需要的比特数明显少：对AIF-TEM实现至少3比特的压缩（在9比特系统中），对IF-TEM实现约60%的压缩。整体表现显示压缩与自适应的联合可显著降低比特率并提升恢复精度。

Conclusion: ACIF-TEM通过将自适应时间编码与压缩前处理紧密集成，并在TDC中实现压缩阶段，达到了比单独的IF-TEM、AIF-TEM或CIF-TEM更低的MSE与更少的比特需求，适合对比特资源和恢复精度均有较高要求的应用，并为后续将压缩环节集成进时序采样硬件提供了一种有效路径。

Abstract: Integrate-and-Fire Time Encoding Machine (IF-TEM) is a power-efficient
asynchronous sampler that converts analog signals into non-uniform time-domain
samples. Adaptive IF-TEM (AIF-TEM) improves this machine by adapting its
process to the characteristics of the input signal, thereby reducing the
sampling rate. Compressed IF-TEM (CIF-TEM) reduces bit usage by performing
analog compression before quantization. In this paper, we introduce a combined
Adaptive Compressed IF-TEM (ACIF-TEM) -- a new sampler that leverages the two
machines, AIF-TEM and CIF-TEM, where each reinforces the effectiveness of the
other. We propose an efficient adaptive clockless time-to-digital converter
(TDC) architecture for the novel sampler that integrates the compression stage
within the TDC, facilitating the realization of the intended integrated system.
\ifconf \else We analyze the total bit usage, and contrast its performance with
that of IF-TEM, AIF-TEM, and CIF-TEM.\fi Via an evaluation study, we
demonstrate that the proposed ACIF-TEM sampler achieves lower Mean Square Error
(MSE) with fewer bits, offering compression gains of at least 3-bit out of
9-bits over AIF-TEM and 60\% compression over IF-TEM, for fixed recovery MSE
with real audio signals.

</details>


### [32] [Before AI Takes Over: Rethinking Nonlinear Signal Processing in Communications](https://arxiv.org/abs/2511.02493)
*Ana Pérez-Neira,Marc Martinez-Gost,Miguel Ángel Lagunas*

Main category: eess.SP

TL;DR: 在 AI 尚未主导时，重新评估传统非线性信号处理方法，协调数据驱动与模型驱动，保留经典洞见并与新AI方法融合。


<details>
  <summary>Details</summary>
Motivation: 应对 AI 时代对信号处理理论与工具的冲击，强调传统与新方法的互补性与整合需求。

Method: 通过文献梳理、理论对比与融合框架设計，提出保留经典方法关键洞见的同时引入数据驱动学习以提升鲁棒性和泛化性，探索两者的协同路径。

Result: 当前为概念性分析，未给出实验结果，提出未来研究方向、评估指标与实验场景。

Conclusion: 建立传统与 AI 方法的共存框架，强调兼容并蓄、互补性，为信号处理在新技术环境中的发展指明方向。

Abstract: There is an urgent reflection on traditional nonlinear signal processing
methods in communications before Artificial Intelligence (AI) dominates the
field. It implies a need to reassess or reinterpret established theories and
tools, highlighting the tension between data-driven and model-based approaches.
This paper calls for preserving valuable insights from classical signal
processing while exploring how they can coexist or integrate with emerging AI
methods.

</details>


### [33] [RIS-Assisted 3D Spherical Splatting for Object Composition Visualization using Detection Transformers](https://arxiv.org/abs/2511.02573)
*Anastasios T. Sotiropoulos,Stavros Tsimpoukis,Dimitrios Tyrovolas,Sotiris Ioannidis,George K. Karagiannidis,Christos K. Liaskos*

Main category: eess.SP

TL;DR: 提出一种基于可编程无线环境(PWE)的射频三维物体重建框架，结合材料感知的球形原元与检测变换器(DETR)从RF特征推断几何与材料信息，在仿真中实现79.35%的总体准确度。


<details>
  <summary>Details</summary>
Motivation: 解决传统光学在遮挡与低照度下的局限，利用射频波的穿透性与可编程传播环境来实现更稳定的3D重建与材料识别。

Method: 将可重构智能表面(RIS)实现的场分布合成与检测变换器(DETR)结合，通过PWEs提供的可控 illumination diversity，基于材料感知的球形原元进行三维对象重建并直接从提取的RF特征中推断空间与材料参数。

Result: 在仿真环境中，该框架能够逼近对象几何形状并对材料组成进行分类，整体准确度达到79.35%。

Conclusion: 这是向可编程且具有物理基础的RF三维对象组成可视化迈出的初步步骤，验证了RIS驱动的场合合成结合DETR在RF域中的有效性。

Abstract: The pursuit of immersive and structurally aware multimedia experiences has
intensified interest in sensing modalities that reconstruct objects beyond the
limits of visible light. Conventional optical pipelines degrade under occlusion
or low illumination, motivating the use of radio-frequency (RF) sensing, whose
electromagnetic waves penetrate materials and encode both geometric and
compositional information. Yet, uncontrolled multipath propagation restricts
reconstruction accuracy. Recent advances in Programmable Wireless Environments
(PWEs) mitigate this limitation by enabling software-defined manipulation of
propagation through Reconfigurable Intelligent Surfaces (RISs), thereby
providing controllable illumination diversity. Building on this capability,
this work introduces a PWE-driven RF framework for three-dimensional object
reconstruction using material-aware spherical primitives. The proposed approach
combines RIS-enabled field synthesis with a Detection Transformer (DETR) that
infers spatial and material parameters directly from extracted RF features.
Simulation results confirm the framework's ability to approximate object
geometries and classify material composition with an overall accuracy of
79.35%, marking an initial step toward programmable and physically grounded
RF-based 3D object composition visualization.

</details>


### [34] [RL-Aided Cognitive ISAC: Robust Detection and Sensing-Communication Trade-offs](https://arxiv.org/abs/2511.02672)
*Adam Umra,Aya M. Ahmed,Aydin Sezgin*

Main category: eess.SP

TL;DR: 提出一种基于强化学习的认知框架，用于大规模MIMO ISAC 中的雷达感知，目标是在未知且动态干扰环境下提升探测性能。通过Wald型探测器实现对非高斯杂波的鲁棒目标检测，利用SARSA强化学习算法自适应估计目标位置，并基于 RL 得到的感知信息进行波形联合优化，在雷达探测精度与下行通信吞吐量之间给出闭-form 解的权衡。仿真表明该框架显著提升探测概率，同时保持较强的通信性能。


<details>
  <summary>Details</summary>
Motivation: 在未知且动态干扰特征环境中提升大规模MIMO ISAC 系统的雷达感知鲁棒性与效率，同时实现感知与通信的高效协同；利用RL自适应无须先验环境知识的目标定位与波形优化以提升系统整体性能。

Method: 在系统中引入Wald型检测器以对非高斯杂波进行鲁棒目标检测；采用SARSA型强化学习算法对目标位置进行自适应估计且不依赖先验环境信息；基于RL得到的感知信息设计联合波形优化，以实现雷达感知 accurate与下行吞吐量的权衡，推导出一个闭形式解来描述该权衡的最优策略；通过蒙特卡洛仿真验证框架的有效性。

Result: 相较于正交方案与无学习自适应基线，提出的认知ISAC 框架在探测概率方面显著提升，同时保持竞争性的通信性能。仿真结果强调了RL 辅助感知在鲁棒性与频谱效率方面的潜力。

Conclusion: 该工作展示了在大规模MIMO ISAC 系统中，利用RL 驱动的认知感知实现雷达探测与通信吞吐量之间的自适应权衡的可行性与有效性，支持未来新的自适应、鲁棒且高效的感知-通信共融设计。

Abstract: This paper proposes a reinforcement learning (RL)-aided cognitive framework
for massive MIMO-based integrated sensing and communication (ISAC) systems
employing a uniform planar array (UPA). The focus is on enhancing radar sensing
performance in environments with unknown and dynamic disturbance
characteristics. A Wald-type detector is employed for robust target detection
under non-Gaussian clutter, while a SARSA-based RL algorithm enables adaptive
estimation of target positions without prior environmental knowledge. Based on
the RL-derived sensing information, a joint waveform optimization strategy is
formulated to balance radar sensing accuracy and downlink communication
throughput. The resulting design provides an adaptive trade-off between
detection performance and achievable sum rate through an analytically derived
closed-form solution. Monte Carlo simulations demonstrate that the proposed
cognitive ISAC framework achieves significantly improved detection probability
compared to orthogonal and non-learning adaptive baselines, while maintaining
competitive communication performance. These results underline the potential of
RL-assisted sensing for robust and spectrum-efficient ISAC in next-generation
wireless networks.

</details>


### [35] [Eye Movement Analysis in Simulated Driving Scenarios](https://arxiv.org/abs/2511.02689)
*Smilja Stokanović,Jaka Sodnik,Nadica Miljković*

Main category: eess.SP

TL;DR: 本研究在三种条件（Baseline、Ride、Fog）下分析眼动行为，发现能见度降低显著影响视觉关注与凝视稳定性；引入 Guzik 的指数 GI，结合 BCEA、saccade、blink 提供对驾驶条件下眼动的综合理解。


<details>
  <summary>Details</summary>
Motivation: 理解驾驶情境中不同能见度对眼动特征的影响，特别是凝视稳定性、凝视分布与眨眼行为，以及引入新的凝视不对称性指标以增强解释力。

Method: 利用眼动追踪测量，比较 Baseline、Ride、Fog 三个条件，分析31个变量，分为三组：13个saccade特征、13个BCEA特征与5个眨眼特征。提出 Guzik's Index (GI) 用于量化 BCEA 主轴向的凝视不对称。并使用效应量(如 Cliff's δ、Cohen's d)评估组间差异。

Result: Baseline 与 Ride/Fog 之间存在大量显著差异，尤其 Baseline 与 Ride 或 Fog；Ride 与 Fog 的 saccade 差异极少（13 项中仅1项显著），但 BCEA 与眨眼特征差异明显（BCEA 13 项中多项显著，眨眼4/5 项显著）。GI 提供对凝视不对称的额外洞见。除了 GI，其他特征相对对比 Ride 的差异最大：如眨眼次数、BCEA、眨眼持续时间标准差等，Cliff's δ/ Cohen's d 的值分别约为 0.96、0.89、0.80。

Conclusion: 将 BCEA 与 saccade、眨眼特征结合，可更全面地理解驾驶情境下的视觉注意与凝视稳定性；GI 为凝视不对称提供额外信息，特别是在能见度降低的条件下。

Abstract: This study investigates eye movement behaviour during three conditions:
Baseline, Ride (simulated drive under normal visibility), and Fog (simulated
drive under reduced visibility). Eye tracking data are analyzed using 31
parameters, organized into three groups: (1) saccade features, (2) Bivariate
Contour Ellipse Area (BCEA), and (3) blinking features. Specifically, the
analysis includes 13 saccade, 13 BCEA, and 5 blinking variables. Across all
feature groups, numerous statistically significant differences emerge between
Baseline and the driving conditions, particularly between Baseline and Ride or
Fog. Between Ride and Fog, saccade features show minimal changes (one out of
13), whereas BCEA (9 of 13) and blink features (four of 5) exhibit pronounced
differences, highlighting the strong impact of reduced visibility on gaze
stability and blinking behaviour. In addition to conventional measures such as
Mean Squared Error (MSE) and entropy metrics, a new parameter, Guzik's Index
(GI), is introduced to quantify fixation asymmetry along the major axis of the
BCEA. This index utilizes eye tracking data to enhance the understanding of eye
movement dynamics during driving conditions. Separately from GI, other
parameters elicit the largest deviations compared to Ride (e.g., number of
saccades: Cliff's $\delta$ = 0.96, BCEA: Cohen's $\textit{d}$ = 0.89, and
standard deviation of blink duration: Cliff's $\delta$ = 0.80), underscoring
the influence of reduced visibility on visual attention. Overall, these
findings demonstrate that combining BCEA with saccade and blink parameters
provides a comprehensive understanding of visual attention and gaze stability,
while GI offers additional insights into fixation asymmetry under varying
visibility conditions.

</details>


### [36] [An unscented Kalman filter method for real time input-parameter-state estimation](https://arxiv.org/abs/2511.02717)
*Marios Impraimakis,Andrew W. Smyth*

Main category: eess.SP

TL;DR: 提出了一种基于无迹卡尔曼滤波的输入-参数-状态联合估计框架，在线性与非线性系统中实现输入的两阶段估计；通过扰动分析显示在存在已知输入的情形下具有潜在的唯一辨识性；该输出-导向方法在实时估计所有动态状态、参数和输入方面优于传统的输出-导向参数辨识。


<details>
  <summary>Details</summary>
Motivation: 解决未知输入与参数时对系统行为的辨识困难，并克服传统仅依赖输出信号的参数辨识方法的局限性，强调对系统的全面、实时理解。

Method: 在每个时间步将输入分成两阶段进行估计：首先利用预测的动态状态和系统参数对输入进行初步估计；随后结合观测修正后的状态与参数进行最终估计。采用无迹卡尔曼滤波（UKF）处理线性与非线性系统的输入-参数-状态联合估计，并通过扰动分析探讨可辨识性，指出系统在至少存在一个已知输入的条件下可能实现唯一辨识。

Result: 提出的输出-导向联合估计框架显示出在实时估计输入、状态和参数方面的潜在优势，并通过扰动分析确认了在有已知输入存在时的辨识性条件。

Conclusion: 该方法为理解和建模提供了更完整的视角，即在实时条件下同时估计所有动态状态、系统参数与输入，超越了传统的只利用输出信息的辨识策略。

Abstract: The input-parameter-state estimation capabilities of a novel unscented Kalman
filter is examined herein on both linear and nonlinear systems. The unknown
input is estimated in two stages within each time step. Firstly, the predicted
dynamic states and the system parameters provide an estimation of the input.
Secondly, the corrected with measurements states and parameters provide a final
estimation. Importantly, it is demonstrated using the perturbation analysis
that, a system with at least a zero or a non-zero known input can potentially
be uniquely identified. This output-only methodology allows for a better
understanding of the system compared to classical output-only parameter
identification strategies, given that all the dynamic states, the parameters,
and the input are estimated jointly and in real-time.

</details>


### [37] [A Non-Uniform Quantization Framework for Time-Encoding Machines](https://arxiv.org/abs/2511.02728)
*Kaluguri Yashaswini,Anshu Arora,Satish Mulleti*

Main category: eess.SP

TL;DR: NUQ（基于幂律分布的非均匀量化）在 TEM firing intervals 上实现，显著优于统一量化和非均匀采样的成本效益比。


<details>
  <summary>Details</summary>
Motivation: TEM 使用事件驱动的采样，但 firing intervals 的分布本质上非均匀，传统的统一量化在该分布下效率低下，因此需要量化策略与分布匹配。

Method: 推导一类带限信号的 firing interval 的概率分布；提出基于幂律的 NUQ 方案以匹配该分布；通过仿真比较 TEM-NUQ 与 TEM-UQ、NUS 的性能。

Result: 在相同比特预算下，NUQ 显著优于 UQ；在与 NUS 相比时，TEM-NUQ 的误差更低且传输成本仅为 NUS 的约一半。

Conclusion: 基于分布的量化能显著提升 TEM 的能效与精度，TEM-NUQ 可作为传统 UQ 与 NUS 的高效替代方案。

Abstract: Time encoding machines (TEMs) provide an event-driven alternative to
classical uniform sampling, enabling power-efficient representations without a
global clock. While prior work analyzed uniform quantization (UQ) of firing
intervals, we show that these intervals are inherently non-uniformly
distributed, motivating the use of non-uniform quantization (NUQ). We derive
the probability distribution of firing intervals for a class of bandlimited
signals and design a power-law-based NUQ scheme tailored to this distribution.
Simulations demonstrate that NUQ significantly outperforms UQ under the same
bit budget. We also compare TEMs with non-uniform sampling (NUS), where both
amplitudes and timings require quantization, and show that TEM--NUQ achieves
lower error at half the transmission cost. These results highlight the
advantages of distribution-aware quantization and establish TEM--NUQ as an
efficient alternative to conventional UQ and NUS schemes.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [38] [Retrieval-Augmented Multimodal Depression Detection](https://arxiv.org/abs/2511.01892)
*Ruibo Hou,Shiyu Teng,Jiaqing Liu,Shurong Chai,Yinhao Li,Lanfen Lin,Yen-Wei Chen*

Main category: cs.LG

TL;DR: 提出一种基于检索增强生成（RAG）的情感提示框架，通过从情感数据集中检索语义相关情感内容，并由大语言模型生成情感提示，来提升抑郁检测的多模态表示与可解释性，在 AVEC 2019 数据集上达到SOTA（CCC 0.593，MAE 3.95）


<details>
  <summary>Details</summary>
Motivation: 当前情感分析在多模态抑郁检测中受限于高计算成本、领域不匹配和静态知识，需更高效且具可解释性的情感理解能力，因此引入检索增强的生成方法以丰富情感表征并提升可解释性

Method: 提出一个检索增强生成框架（RAG）：给定抑郁相关文本，检索情感数据集中语义相关的情感内容；利用大型语言模型生成“情感提示”作为辅助模态，丰富情感表示并提高可解释性

Result: 在 AVEC 2019 数据集上实现了SOTA性能，CCC为0.593，MAE为3.95，优于先前的迁移学习与多任务学习基线

Conclusion: RAG框架通过将检索得到的情感内容与LLM生成的情感提示作为辅助模态，提升了情感表征及可解释性并带来显著的性能提升

Abstract: Multimodal deep learning has shown promise in depression detection by
integrating text, audio, and video signals. Recent work leverages sentiment
analysis to enhance emotional understanding, yet suffers from high
computational cost, domain mismatch, and static knowledge limitations. To
address these issues, we propose a novel Retrieval-Augmented Generation (RAG)
framework. Given a depression-related text, our method retrieves semantically
relevant emotional content from a sentiment dataset and uses a Large Language
Model (LLM) to generate an Emotion Prompt as an auxiliary modality. This prompt
enriches emotional representation and improves interpretability. Experiments on
the AVEC 2019 dataset show our approach achieves state-of-the-art performance
with CCC of 0.593 and MAE of 3.95, surpassing previous transfer learning and
multi-task learning baselines.

</details>


### [39] [The Eigenvalues Entropy as a Classifier Evaluation Measure](https://arxiv.org/abs/2511.01904)
*Doulaye Dembélé*

Main category: cs.LG

TL;DR: 提出用特征的特征值熵作为二分类/多分类的评估量，针对类别不平衡问题，给出与灵敏度、特异度、ROC-AUC和基尼系数的关系，并副产出估计混淆矩阵以缓解不平衡问题；在若干数据示例上显示优于现有评估量。


<details>
  <summary>Details</summary>
Motivation: 传统的分类评估量在类别不平衡数据集上往往不准确，需要一种对不平衡更鲁棒的量来评估分类器性能，并且能够对混淆矩阵进行估计以缓解不平衡的影响。

Method: 提出基于矩阵特征值的熵量（eigenvalues entropy）作为评估指标；对于二分类问题，建立该熵与灵敏度、特异度、ROC曲线下面积（AUC）以及基尼指数之间的关系；同时给出一个对混淆矩阵的估计以对不平衡类别进行补偿；通过若干数据集的实例比较，验证该评价量在不平衡数据上的表现优于传统金标准。

Result: 所提出的特征值熵在二分类与多分类问题上与常用评估指标存在关系，并通过一个副产的混淆矩阵估计来应对类别不平衡；在多组数据示例中显示该评价量相较于现有指标具有更好的性能。

Conclusion: 特征值熵是一种可用于不平衡分类问题的有效评估指标，且可结合对混淆矩阵的估计来缓解不平衡影响，在若干数据示例中优于传统评估量。

Abstract: Classification is a machine learning method used in many practical
applications: text mining, handwritten character recognition, face recognition,
pattern classification, scene labeling, computer vision, natural langage
processing. A classifier prediction results and training set information are
often used to get a contingency table which is used to quantify the method
quality through an evaluation measure. Such measure, typically a numerical
value, allows to choose a suitable method among several. Many evaluation
measures available in the literature are less accurate for a dataset with
imbalanced classes. In this paper, the eigenvalues entropy is used as an
evaluation measure for a binary or a multi-class problem. For a binary problem,
relations are given between the eigenvalues and some commonly used measures,
the sensitivity, the specificity, the area under the operating receiver
characteristic curve and the Gini index. A by-product result of this paper is
an estimate of the confusion matrix to deal with the curse of the imbalanced
classes. Various data examples are used to show the better performance of the
proposed evaluation measure over the gold standard measures available in the
literature.

</details>


### [40] [Variational Geometry-aware Neural Network based Method for Solving High-dimensional Diffeomorphic Mapping Problems](https://arxiv.org/abs/2511.01911)
*Zhiwen Li,Cheuk Hin Ho,Lok Ming Lui*

Main category: cs.LG

TL;DR: Proposes a mesh-free, high-dimensional diffeomorphic registration framework that combines variational principles with quasi-conformal theory to guarantee bijective mappings while controlling conformality and volume distortion; scalable to neural networks and gradient optimization, with validation on synthetic and medical images.


<details>
  <summary>Details</summary>
Motivation: High-dimensional diffeomorphic mapping faces the curse of dimensionality and the need for bijective, distortion-controlled deformations. A mesh-free framework can improve scalability and integration with gradient-based learning, while quasi-conformal constraints provide principled distortion control.

Method: A mesh-free learning framework that enforces conformality distortion and volume distortion via variational principles, yielding bijective deformations. It is designed to be compatible with gradient-based optimization and neural network architectures, enabling scalable high-dimensional registration.

Result: Numerical experiments on synthetic and real-world medical image data demonstrate accurate, robust, and effective performance in complex registration scenarios.

Conclusion: The proposed framework achieves accurate, bijective, distortion-controlled diffeomorphic mappings in high dimensions, with strong compatibility with ML pipelines and scalability to neural networks.

Abstract: Traditional methods for high-dimensional diffeomorphic mapping often struggle
with the curse of dimensionality. We propose a mesh-free learning framework
designed for $n$-dimensional mapping problems, seamlessly combining variational
principles with quasi-conformal theory. Our approach ensures accurate,
bijective mappings by regulating conformality distortion and volume distortion,
enabling robust control over deformation quality. The framework is inherently
compatible with gradient-based optimization and neural network architectures,
making it highly flexible and scalable to higher-dimensional settings.
Numerical experiments on both synthetic and real-world medical image data
validate the accuracy, robustness, and effectiveness of the proposed method in
complex registration scenarios.

</details>


### [41] [Superpositional Gradient Descent: Harnessing Quantum Principles for Model Training](https://arxiv.org/abs/2511.01918)
*Ahmet Erdem Pamuk,Emir Kaan Özdemir,Şuayp Talha Kocabay*

Main category: cs.LG

TL;DR: 提出超叠加梯度下降（SGD），通过量子电路扰动将梯度更新与量子叠加相关联，在混合量子-经典训练中实现比 AdamW 更快收敛和更低最终损失。


<details>
  <summary>Details</summary>
Motivation: 探究量子启发的优化方法如何提升经典大模型训练的收敛性和泛化能力，以及其潜在机制。

Method: 提出数学框架，将梯度更新与量子叠加联系，构建混合量子-经典优化器，在 PyTorch 与 Qiskit 中实现，并在合成任务和大规模LLM微调上评估。

Result: 在合成序列分类和大规模LLM微调任务中，SGD 收敛更快、最终损失更低；然而可扩展性与硬件限制成为实际瓶颈。

Conclusion: 为量子计算与深度学习的交叉提供新视角，显示量子原理在控制和提升模型行为方面的实际潜力与挑战。

Abstract: Large language models (LLMs) are increasingly trained with classical
optimization techniques like AdamW to improve convergence and generalization.
However, the mechanisms by which quantum-inspired methods enhance classical
training remain underexplored. We introduce Superpositional Gradient Descent
(SGD), a novel optimizer linking gradient updates with quantum superposition by
injecting quantum circuit perturbations. We present a mathematical framework
and implement hybrid quantum-classical circuits in PyTorch and Qiskit. On
synthetic sequence classification and large-scale LLM fine-tuning, SGD
converges faster and yields lower final loss than AdamW. Despite promising
results, scalability and hardware constraints limit adoption. Overall, this
work provides new insights into the intersection of quantum computing and deep
learning, suggesting practical pathways for leveraging quantum principles to
control and enhance model behavior.

</details>


### [42] [DeepContour: A Hybrid Deep Learning Framework for Accelerating Generalized Eigenvalue Problem Solving via Efficient Contour Design](https://arxiv.org/abs/2511.01927)
*Yeqiu Chen,Ziyan Liu,Hong Wang*

Main category: cs.LG

TL;DR: DeepContour 将 Fourier神经算子预测与核密度估计相结合，用于为切圆积分法（如 CIRR）设计自适应、系统化的积分轮廓，从而在多数据集上实现高达5.63×的加速。


<details>
  <summary>Details</summary>
Motivation: 大型广义特征值问题（GEP）的轮廓积分方法对积分轮廓的选择高度敏感。若缺乏先验分布信息，传统轮廓设计会带来计算开销与数值不稳定性。需要一个自适应、可自动设计轮廓的框架。

Method: 提出混合框架 DeepContour：先用傅里叶神经算子（FNO）快速预测给定 GEP 的谱分布；再对预测谱使用核密度估计（KDE）自动、系统地确定合适的积分轮廓；最后以这些轮廓引导距离计算的 CI 求解器以高效地求解特征值。

Result: 在多组数据集上，DeepContour 能显著加速 GEP 求解，最高达到约5.63倍的加速。该方法将深度学习的预测能力与经典数值求解器的数值严格性相结合，开启了高维矩阵广义特征值问题的新范式。

Conclusion: 提出了一种高效且鲁棒的框架，将深度学习的预测力与数值求解的严格性结合，用于解决高维广义特征值问题。

Abstract: Solving large-scale Generalized Eigenvalue Problems (GEPs) is a fundamental
yet computationally prohibitive task in science and engineering. As a promising
direction, contour integral (CI) methods, such as the CIRR algorithm, offer an
efficient and parallelizable framework. However, their performance is
critically dependent on the selection of integration contours -- improper
selection without reliable prior knowledge of eigenvalue distribution can incur
significant computational overhead and compromise numerical accuracy. To
address this challenge, we propose DeepContour, a novel hybrid framework that
integrates a deep learning-based spectral predictor with Kernel Density
Estimation for principled contour design. Specifically, DeepContour first
employs a Fourier Neural Operator (FNO) to rapidly predict the spectral
distribution of a given GEP. Subsequently, Kernel Density Estimation (KDE) is
applied to the predicted spectrum to automatically and systematically determine
proper integration contours. Finally, these optimized contours guide the CI
solver to efficiently find the desired eigenvalues. We demonstrate the
effectiveness of our method on diverse challenging scientific problems. In our
main experiments, DeepContour accelerates GEP solving across multiple datasets,
achieving up to a 5.63$\times$ speedup. By combining the predictive power of
deep learning with the numerical rigor of classical solvers, this work pioneers
an efficient and robust paradigm for tackling difficult generalized eigenvalue
involving matrices of high dimension.

</details>


### [43] [Deciphering Personalization: Towards Fine-Grained Explainability in Natural Language for Personalized Image Generation Models](https://arxiv.org/abs/2511.01932)
*Haoming Wang,Wei Gao*

Main category: cs.LG

TL;DR: 提出 FineXL，一种面向个性化图像生成的细粒度自然语言可解释性方法，通过对个性化的各个方面给出自然语言描述及量化分数，并在多种模型/场景上显著提升可解释性准确性（约56%）


<details>
  <summary>Details</summary>
Motivation: 当前个性化图像生成模型的可解释性多为粗粒度，难以识别和度量各个方面的个性化及其层级差异，缺乏对用户友好的自然语言解释，从而限制理解和调试。

Method: 提出 FineXL，通过将个性化分解为若干独立的方面，为每个方面生成自然语言描述，并给出量化分数，形成细粒度的可解释性文本，可能结合特征分析与评分机制。

Result: 在不同个性化场景下对多类型图像生成模型的评估表明，FineXL 提高可解释性准确性约56%。

Conclusion: FineXL 能实现对个性化各方面的细粒度、可量化自然语言解释，提升可解释性效果，并具有跨模型和场景的适用性。

Abstract: Image generation models are usually personalized in practical uses in order
to better meet the individual users' heterogeneous needs, but most personalized
models lack explainability about how they are being personalized. Such
explainability can be provided via visual features in generated images, but is
difficult for human users to understand. Explainability in natural language is
a better choice, but the existing approaches to explainability in natural
language are limited to be coarse-grained. They are unable to precisely
identify the multiple aspects of personalization, as well as the varying levels
of personalization in each aspect. To address such limitation, in this paper we
present a new technique, namely \textbf{FineXL}, towards \textbf{Fine}-grained
e\textbf{X}plainability in natural \textbf{L}anguage for personalized image
generation models. FineXL can provide natural language descriptions about each
distinct aspect of personalization, along with quantitative scores indicating
the level of each aspect of personalization. Experiment results show that
FineXL can improve the accuracy of explainability by 56\%, when different
personalization scenarios are applied to multiple types of image generation
models.

</details>


### [44] [Tool Zero: Training Tool-Augmented LLMs via Pure RL from Scratch](https://arxiv.org/abs/2511.01934)
*Yirong Zeng,Xiao Ding,Yutai Hou,Yuxian Wang,Li Du,Juyi Dai,Qiuyang Ding,Duyu Tang,Dandan Tu,Weiwen Liu,Bing Qin,Ting Liu*

Main category: cs.LG

TL;DR: 本研究提出一种基于动态通用化引导奖励设计的规则式强化学习方法，训练 Tool-Zero 系列模型，使 LLM 能自主利用通用工具，从零起点扩展 RL，显著提升工具使用的泛化能力与性能。


<details>
  <summary>Details</summary>
Motivation: 现有的监督微调需要大规模领域数据集，难以对陌生或复杂的工具使用场景泛化；纯强化学习有望提升推理能力与泛化性，但如何引导模型在不依赖特定数据的情况下学习通用工具使用，是一个关键挑战。

Method: 提出基于动态通用化引导奖励的规则型 RL（dynamic generalization-guided reward design for rule-based RL），逐步将奖励从探索性工具使用转向利用性工具使用。以 Zero 模型为起点，训练 Tool-Zero 系列，使模型能够自主地以通用工具，直接从零训练扩展，强调对通用工具的自我利用能力。

Result: 实验结果显示，在相同实验条件下，Tool-Zero 相比 SFT 和 RL-with-SFT 提升超过 7%，并在跨数据集和同数据集内评估中均能稳定复现，证实了方法的有效性和鲁棒性。

Conclusion: 纯粹的 RL 能有效唤起模型的内在推理能力与通用化能力；Tool-Zero 模型可实现对通用工具的自主使用，所提出的奖励设计具有良好的鲁棒性和泛化性，具备在无领域微调前提下提升工具使用能力的潜力。

Abstract: Training tool-augmented LLMs has emerged as a promising approach to enhancing
language models' capabilities for complex tasks. The current supervised
fine-tuning paradigm relies on constructing extensive domain-specific datasets
to train models. However, this approach often struggles to generalize
effectively to unfamiliar or intricate tool-use scenarios. Recently,
reinforcement learning (RL) paradigm can endow LLMs with superior reasoning and
generalization abilities. In this work, we address a key question: Can the pure
RL be used to effectively elicit a model's intrinsic reasoning capabilities and
enhance the tool-agnostic generalization? We propose a dynamic
generalization-guided reward design for rule-based RL, which progressively
shifts rewards from exploratory to exploitative tool-use patterns. Based on
this design, we introduce the Tool-Zero series models. These models are trained
to enable LLMs to autonomously utilize general tools by directly scaling up RL
from Zero models (i.e., base models without post-training). Experimental
results demonstrate that our models achieve over 7% performance improvement
compared to both SFT and RL-with-SFT models under the same experimental
settings. These gains are consistently replicated across cross-dataset and
intra-dataset evaluations, validating the effectiveness and robustness of our
methods.

</details>


### [45] [Q-Sat AI: Machine Learning-Based Decision Support for Data Saturation in Qualitative Studies](https://arxiv.org/abs/2511.01935)
*Hasan Tutar,Caner Erden,Ümit Şentürk*

Main category: cs.LG

TL;DR: 基于机器学习的定性研究样本量确定模型：以五大定性方法为数据源，10个要素，训练多种算法，KNN/GB/RF/XGBoost/DT在测试集上达到约0.85的解释力，提供一个面向网页的决策支持框架，助力标准化样本量论证。


<details>
  <summary>Details</summary>
Motivation: 解决定性研究中数据饱和度的主观性和不一致性，提升样本量推断的透明度、可重复性和方法论 rigor。

Method: 以Case Study、Grounded Theory、Phenomenology、Narrative Research、Ethnographic Research等五大定性取向的数据为基础，选取10个关键参数（如研究范围、信息力量、研究者能力等）并以序数尺度作为输入特征；经预处理与异常值剔除后，训练并比较多种ML算法，包含KNN、Gradient Boosting、Random Forest、XGBoost、Decision Tree；进行特征重要性分析以验证关键理论假设并建立集成学习框架。

Result: 模型在测试集上达到约0.85的R^2，能够捕捉定性抽样决策中的非线性关系；特征重要性显示研究设计类型与信息力量为关键因素，给出定性方法论关键假设的定量验证。

Conclusion: 提出一个面的网页计算应用的概念框架，作为定性研究者、期刊评审和论文导师的决策支持系统，推动样本量论证的标准化、透明性，以及以证据为基础的系统性决策，强化定性研究的认识论基础。

Abstract: The determination of sample size in qualitative research has traditionally
relied on the subjective and often ambiguous principle of data saturation,
which can lead to inconsistencies and threaten methodological rigor. This study
introduces a new, systematic model based on machine learning (ML) to make this
process more objective. Utilizing a dataset derived from five fundamental
qualitative research approaches - namely, Case Study, Grounded Theory,
Phenomenology, Narrative Research, and Ethnographic Research - we developed an
ensemble learning model. Ten critical parameters, including research scope,
information power, and researcher competence, were evaluated using an ordinal
scale and used as input features. After thorough preprocessing and outlier
removal, multiple ML algorithms were trained and compared. The K-Nearest
Neighbors (KNN), Gradient Boosting (GB), Random Forest (RF), XGBoost, and
Decision Tree (DT) algorithms showed the highest explanatory power (Test R2 ~
0.85), effectively modeling the complex, non-linear relationships involved in
qualitative sampling decisions. Feature importance analysis confirmed the vital
roles of research design type and information power, providing quantitative
validation of key theoretical assumptions in qualitative methodology. The study
concludes by proposing a conceptual framework for a web-based computational
application designed to serve as a decision support system for qualitative
researchers, journal reviewers, and thesis advisors. This model represents a
significant step toward standardizing sample size justification, enhancing
transparency, and strengthening the epistemological foundation of qualitative
inquiry through evidence-based, systematic decision-making.

</details>


### [46] [Shorter but not Worse: Frugal Reasoning via Easy Samples as Length Regularizers in Math RLVR](https://arxiv.org/abs/2511.01937)
*Abdelaziz Bounhar,Hadi Abdine,Evan Dufraisse,Ahmad Chamma,Amr Mohamed,Dani Bouch,Michalis Vazirgiannis,Guokan Shang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) trained for step-by-step reasoning often become
excessively verbose, raising inference cost. Standard Reinforcement Learning
with Verifiable Rewards (RLVR) pipelines filter out ``easy'' problems for
training efficiency, leaving the model to train primarily on harder problems
that require longer reasoning chains. This skews the output length distribution
upward, resulting in a \textbf{model that conflates ``thinking longer'' with
``thinking better''}. In this work, we show that retaining and modestly
up-weighting moderately easy problems acts as an implicit length regularizer.
Exposing the model to solvable short-chain tasks constrains its output
distribution and prevents runaway verbosity. The result is
\textbf{\emph{emergent brevity for free}}: the model learns to solve harder
problems without inflating the output length, \textbf{ despite the absence of
any explicit length penalization}. RLVR experiments using this approach on
\textit{Qwen3-4B-Thinking-2507} (with a 16k token limit) achieve baseline
pass@1 AIME25 accuracy while generating solutions that are, on average, nearly
twice as short. The code is available at
\href{https://github.com/MBZUAI-Paris/Frugal-AI}{GitHub}, with datasets and
models on
\href{https://huggingface.co/collections/MBZUAI-Paris/k2-think-mini-68dcfa8b114686a4bd3dc2bc}{Hugging
Face}.

</details>


### [47] [Learning a Distance for the Clustering of Patients with Amyotrophic Lateral Sclerosis](https://arxiv.org/abs/2511.01945)
*Guillaume Tejedor,Veronika Peralta,Nicolas Labroche,Patrick Marcel,Hélène Blasco,Hugo Alarcan*

Main category: cs.LG

TL;DR: 提出基于疾病进展宣告分数的ALS患者序列聚类方法，通过多描述性变量的距离度量、弱监督学习以及现有聚类算法，能在353例ALS患者数据集上在生存分析上优于最新方法，同时保持轮廓系数水平，且学习到的距离提升结果的相关性与可解释性。


<details>
  <summary>Details</summary>
Motivation: ALS具有高度异质性、患者个体差异大且数据稀疏，现有聚类方法受限，迫切需要结合专业知识和多变量距离度量来获得更具临床意义的患者亚群，以支撑个性化护理与治疗决策。

Method: 提出一种聚类框架，将疾病进展的宣告分数作为核心，融合多变量描述信息，探索多种距离度量（包括复用现成距离与弱监督学习得到的新距离），并将这些距离与聚类方法结合，与现有最先进方法进行对比评估。以353名患者的ALS数据集为样本，进行生存分析与轮廓系数等评价。

Result: 实验结果显示，该方法在生存分析任务上优于最先进方法，同时轮廓系数具可比性；学习得到的距离提高了医学专家对结果的相关性与可解释性。

Conclusion: 该方法在提高生存分析性能与结果可解释性方面具有潜力，有望提升ALS个性化护理的实现，但仍需在更大样本和更广泛数据上进行验证。

Abstract: Amyotrophic lateral sclerosis (ALS) is a severe disease with a typical
survival of 3-5 years after symptom onset. Current treatments offer only
limited life extension, and the variability in patient responses highlights the
need for personalized care. However, research is hindered by small,
heterogeneous cohorts, sparse longitudinal data, and the lack of a clear
definition for clinically meaningful patient clusters. Existing clustering
methods remain limited in both scope and number. To address this, we propose a
clustering approach that groups sequences using a disease progression
declarative score. Our approach integrates medical expertise through multiple
descriptive variables, investigating several distance measures combining such
variables, both by reusing off-the-shelf distances and employing a
weak-supervised learning method. We pair these distances with clustering
methods and benchmark them against state-of-the-art techniques. The evaluation
of our approach on a dataset of 353 ALS patients from the University Hospital
of Tours, shows that our method outperforms state-of-the-art methods in
survival analysis while achieving comparable silhouette scores. In addition,
the learned distances enhance the relevance and interpretability of results for
medical experts.

</details>


### [48] [Measuring the Intrinsic Dimension of Earth Representations](https://arxiv.org/abs/2511.02101)
*Arjun Rao,Marc Rußwurm,Konstantin Klemmer,Esther Rolf*

Main category: cs.LG

TL;DR: 地理隐式神经表示（INR）的固有维度很低（约2–10），且随分辨率和输入模态而变化；该固有维度与下游任务性能相关，并可用于无监督的评估、模型选择和预训练设计，提供一种通用的、无标签的信息量度量。


<details>
  <summary>Details</summary>
Motivation: 尽管地理INR旨在将地球数据压缩为紧凑的学习表征，但我们仍不清楚这些表征包含多少信息、信息集中在何处。固有维度衡量在局部可变性上的自由度数，独立于高维嵌入空间的维度，因此可作为信息内容的潜在度量。

Method: 在 ambient 维度为256–512的INR上进行分析，估计其固有维度；考察分辨率和输入模态在INR预训练中的影响；研究固有维度与下游任务性能的相关性，并评估其对空间伪影的捕获能力。

Result: 研究发现地理INR的固有维度约为2–10，并对分辨率和输入模态变化敏感；固有维度与下游任务性能相关，且可用于捕捉空间伪影以辅助模型评估和诊断。

Conclusion: 提出一种与架构无关、无标签的信息量度量，适用于INRs的无监督评估、模型选择与预训练设计，可在不同输入模态和任务中应用。

Abstract: Within the context of representation learning for Earth observation,
geographic Implicit Neural Representations (INRs) embed low-dimensional
location inputs (longitude, latitude) into high-dimensional embeddings, through
models trained on geo-referenced satellite, image or text data. Despite the
common aim of geographic INRs to distill Earth's data into compact,
learning-friendly representations, we lack an understanding of how much
information is contained in these Earth representations, and where that
information is concentrated. The intrinsic dimension of a dataset measures the
number of degrees of freedom required to capture its local variability,
regardless of the ambient high-dimensional space in which it is embedded. This
work provides the first study of the intrinsic dimensionality of geographic
INRs. Analyzing INRs with ambient dimension between 256 and 512, we find that
their intrinsic dimensions fall roughly between 2 and 10 and are sensitive to
changing spatial resolution and input modalities during INR pre-training.
Furthermore, we show that the intrinsic dimension of a geographic INR
correlates with downstream task performance and can capture spatial artifacts,
facilitating model evaluation and diagnostics. More broadly, our work offers an
architecture-agnostic, label-free metric of information content that can enable
unsupervised evaluation, model selection, and pre-training design across INRs.

</details>


### [49] [Quantum-Enhanced Generative Models for Rare Event Prediction](https://arxiv.org/abs/2511.02042)
*M. Z. Haider,M. U. Ghouri,Tayyaba Noreen,M. Salman*

Main category: cs.LG

TL;DR: 提出量子增强生成模型（QEGM），一个混合经典-量子的生成框架，用以更好建模罕见事件，通过混合损失和量子随机性噪声注入提升尾部行为；在高斯混合数据和金融、气候、生物结构数据上表现出尾部 KL 发散降低和罕见事件召回的提升。


<details>
  <summary>Details</summary>
Motivation: 稀缺且具有厚尾分布的罕见事件难以建模，经典深度生成模型易崩塌非高概率模态或对不确定性估计不准；需要同时提升尾部概率估计和多样性。

Method: 将深潜变量模型与变分量子电路结合，提出两点创新：(1) 混合损失函数，联合优化重建保真度和尾部相关的似然性；(2) 量子随机性驱动的噪声注入，提升样本多样性并缓解模态坍缩。训练采用经典参数通过反向传播更新，量子参数通过参数位移梯度优化。

Result: 在合成高斯混合数据及现实数据（金融、气候、蛋白质结构）上评估，QEGM 将尾部 KL 发散减少多达 50%，并改进罕见事件召回率与覆盖标定。

Conclusion: QEGM 展示了罕见事件预测的原则性方法潜力，提供超越纯经典方法的鲁棒性。

Abstract: Rare events such as financial crashes, climate extremes, and biological
anomalies are notoriously difficult to model due to their scarcity and
heavy-tailed distributions. Classical deep generative models often struggle to
capture these rare occurrences, either collapsing low-probability modes or
producing poorly calibrated uncertainty estimates. In this work, we propose the
Quantum-Enhanced Generative Model (QEGM), a hybrid classical-quantum framework
that integrates deep latent-variable models with variational quantum circuits.
The framework introduces two key innovations: (1) a hybrid loss function that
jointly optimizes reconstruction fidelity and tail-aware likelihood, and (2)
quantum randomness-driven noise injection to enhance sample diversity and
mitigate mode collapse. Training proceeds via a hybrid loop where classical
parameters are updated through backpropagation while quantum parameters are
optimized using parameter-shift gradients. We evaluate QEGM on synthetic
Gaussian mixtures and real-world datasets spanning finance, climate, and
protein structure. Results demonstrate that QEGM reduces tail KL divergence by
up to 50 percent compared to state-of-the-art baselines (GAN, VAE, Diffusion),
while improving rare-event recall and coverage calibration. These findings
highlight the potential of QEGM as a principled approach for rare-event
prediction, offering robustness beyond what is achievable with purely classical
methods.

</details>


### [50] [COFAP: A Universal Framework for COFs Adsorption Prediction through Designed Multi-Modal Extraction and Cross-Modal Synergy](https://arxiv.org/abs/2511.01946)
*Zihan Li,Mingyang Wan,Mingyu Gao,Zhongshan Chen,Xiangke Wang,Feifan Zhang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Covalent organic frameworks (COFs) are promising adsorbents for gas
adsorption and separation, while identifying the optimal structures among their
vast design space requires efficient high-throughput screening. Conventional
machine-learning predictors rely heavily on specific gas-related features.
However, these features are time-consuming and limit scalability, leading to
inefficiency and labor-intensive processes. Herein, a universal COFs adsorption
prediction framework (COFAP) is proposed, which can extract multi-modal
structural and chemical features through deep learning, and fuse these
complementary features via cross-modal attention mechanism. Without Henry
coefficients or adsorption heat, COFAP sets a new SOTA by outperforming
previous approaches on hypoCOFs dataset. Based on COFAP, we also found that
high-performing COFs for separation concentrate within a narrow range of pore
size and surface area. A weight-adjustable prioritization scheme is also
developed to enable flexible, application-specific ranking of candidate COFs
for researchers. Superior efficiency and accuracy render COFAP directly
deployable in crystalline porous materials.

</details>


### [51] [EchoLSTM: A Self-Reflective Recurrent Network for Stabilizing Long-Range Memory](https://arxiv.org/abs/2511.01950)
*Prasanth K K,Shubham Sharma*

Main category: cs.LG

TL;DR: 提出 Output-Conditioned Gating 的自我反思机制，通过基于 past inferences 调制记忆门来增强长期依赖的建模。最终 EchoLSTM 结合注意力，在 Distractor Signal Task、ListOps 等基准上实现高性能且参数高效，显示更鲁棒的记忆系统。


<details>
  <summary>Details</summary>
Motivation: 解决标准 RNN/LSTM 在处理长-range dependencies 和噪声信息时容易受干扰的问题，提出可自我反思的门控机制以稳定记忆并提升记忆 retention。

Method: 引入 Output-Conditioned Gating 原则，使模型能够基于自身过去的推断调节内部记忆门，形成自我反馈回路；将该原则与注意力机制结合，构建 EchoLSTM；在 Distractor Signal Task、ListOps 以及 Trigger Sensitivity Test 上评估。

Result: 在 Distractor Signal Task 上达到 69.0%（比标准 LSTM 高出 33 个百分点）；ListOps 上达到 69.8%，接近 Transformer 的 71.8%，且参数量超过5×的效率提升；Trigger Sensitivity Test 证据表明自我反思机制使记忆系统更鲁棒。

Conclusion: 自我反思的输出条件门控可显著提升记忆系统的鲁棒性与对长距离依赖的建模能力，使 EchoLSTM 在竞争性基准上实现接近 Transformer 的性能，同时显著提高参数效率。

Abstract: Standard Recurrent Neural Networks, including LSTMs, struggle to model
long-range dependencies, particularly in sequences containing noisy or
misleading information. We propose a new architectural principle,
Output-Conditioned Gating, which enables a model to perform self-reflection by
modulating its internal memory gates based on its own past inferences. This
creates a stabilizing feedback loop that enhances memory retention. Our final
model, the EchoLSTM, integrates this principle with an attention mechanism. We
evaluate the EchoLSTM on a series of challenging benchmarks. On a
custom-designed Distractor Signal Task, the EchoLSTM achieves 69.0% accuracy,
decisively outperforming a standard LSTM baseline by 33 percentage points.
Furthermore, on the standard ListOps benchmark, the EchoLSTM achieves
performance competitive with a modern Transformer model, 69.8% vs. 71.8%, while
being over 5 times more parameter-efficient. A final Trigger Sensitivity Test
provides qualitative evidence that our model's self-reflective mechanism leads
to a fundamentally more robust memory system.

</details>


### [52] [NeuroClean: A Generalized Machine-Learning Approach to Neural Time-Series Conditioning](https://arxiv.org/abs/2511.01951)
*Manuel A. Hernandez Alonso,Michael Depass,Stephan Quessy,Numa Dancause,Ignasi Cos*

Main category: cs.LG

TL;DR: An unsupervised, five-step EEG/LFP preprocessing pipeline (NeuroClean) that combines bandpass/line-noise filtering and bad channel rejection with ICA and an automatic, clustering-based component classifier to preserve task-relevant information; validated on multiple datasets, it improves downstream ML performance and reduces artifacts.


<details>
  <summary>Details</summary>
Motivation: Brain recordings (EEG/LFP) are contaminated by numerous artifacts; with increasing data volumes, automatic, unsupervised preprocessing is essential to ensure reliability and reproducibility without human biases.

Method: A five-step preprocessing pipeline including standard filtering and bad-channel rejection, coupled with an efficient ICA and an automatic component rejection mechanism based on a clustering classifier to preserve task-relevant information throughout cleaning.

Result: NeuroClean removed several common artifact types. In motor tasks of varying complexity, a downstream Multinomial Logistic Regression model achieved ~97% accuracy after cleaning (vs 74% on raw data; chance level 33.3%), indicating improved performance and generalization.

Conclusion: NeuroClean shows promise as a robust, unsupervised preprocessing workflow for EEG/LFP data, potentially enabling better generalization and performance in future machine learning analyses.

Abstract: Electroencephalography (EEG) and local field potentials (LFP) are two widely
used techniques to record electrical activity from the brain. These signals are
used in both the clinical and research domains for multiple applications.
However, most brain data recordings suffer from a myriad of artifacts and noise
sources other than the brain itself. Thus, a major requirement for their use is
proper and, given current volumes of data, a fully automatized conditioning. As
a means to this end, here we introduce an unsupervised, multipurpose EEG/LFP
preprocessing method, the NeuroClean pipeline. In addition to its completeness
and reliability, NeuroClean is an unsupervised series of algorithms intended to
mitigate reproducibility issues and biases caused by human intervention. The
pipeline is designed as a five-step process, including the common bandpass and
line noise filtering, and bad channel rejection. However, it incorporates an
efficient independent component analysis with an automatic component rejection
based on a clustering algorithm. This machine learning classifier is used to
ensure that task-relevant information is preserved after each step of the
cleaning process. We used several data sets to validate the pipeline.
NeuroClean removed several common types of artifacts from the signal. Moreover,
in the context of motor tasks of varying complexity, it yielded more than 97%
accuracy (vs. a chance-level of 33.3%) in an optimized Multinomial Logistic
Regression model after cleaning the data, compared to the raw data, which
performed at 74% accuracy. These results show that NeuroClean is a promising
pipeline and workflow that can be applied to future work and studies to achieve
better generalization and performance on machine learning pipelines.

</details>


### [53] [TapOut: A Bandit-Based Approach to Dynamic Speculative Decoding](https://arxiv.org/abs/2511.02017)
*Aditya Sridhar,Nish Sinnadurai,Sean Lie,Vithursan Thangarasa*

Main category: cs.LG

TL;DR: TapOut is an online, training-free meta-algorithm that dynamically selects the number of tokens to draft in speculative decoding using multi-armed bandits, improving speedups without hyperparameter tuning.


<details>
  <summary>Details</summary>
Motivation: Rigid, hand-tuned thresholds (e.g., token entropy) for determining draft length hinder performance and generalization across models and domains; a tunable, adaptive policy is needed to maximize speedups.

Method: A meta-algorithm that dynamically selects among multiple parameter-free dynamic speculation strategies using multi-armed bandits, operating online without training to choose draft length based on past rewards and exploration.

Result: Extensive experiments across diverse model pairs and datasets show TapOut achieves competitive or superior speedups compared to well-established dynamic speculation baselines, without any hyperparameter tuning.

Conclusion: TapOut provides a tuning-free, plug-and-play solution for dynamic speculation policy selection that can consistently accelerate LLM inference across varied models and domains.

Abstract: Speculative decoding accelerates LLMs by using a lightweight draft model to
generate tokens autoregressively before verifying them in parallel with a
larger target model. However, determining the optimal number of tokens to draft
remains a key challenge limiting the approach's effectiveness. Dynamic
speculative decoding aims to intelligently decide how many tokens to draft to
achieve maximum speedups. Existing methods often rely on hand-tuned, sensitive
thresholds (e.g., token entropy), which are costly to set and generalize poorly
across models and domains. We propose TapOut, an online, training-free,
plug-and-play algorithm for dynamic speculation policy selection using
multi-armed bandits. Our approach employs a meta-algorithm that selects among
multiple parameter-free dynamic speculation strategies based on past reward and
exploration. We conduct extensive experiments across diverse model pairs and
datasets, showing that TapOut achieves competitive or superior speedups
compared to well-established dynamic speculation baselines without any
hyperparameter tuning.

</details>


### [54] [Shared Parameter Subspaces and Cross-Task Linearity in Emergently Misaligned Behavior](https://arxiv.org/abs/2511.02022)
*Daniel Aarao Reis Arturi,Eric Zhang,Andrew Ansah,Kevin Zhu,Ashwinee Panda,Aishwarya Balwani*

Main category: cs.LG

TL;DR: EM shows cross-task linear structure: harmful behavior aligns along common weight-directions and persists under interpolation.


<details>
  <summary>Details</summary>
Motivation: 揭示 emergent misalignment 的根本机制与跨任务的一致性，提升对参数空间的可解释性与干预能力。

Method: 从几何角度分析对多个 narrowly harmful 数据集进行微调的模型权重，衡量更新的余弦相似度、低维子空间的主角差和投影重叠，并通过线性模式连通性检验跨任务的功能等价性。

Result: 不同 narrowly misalignment 任务的微调权重在参数更新上呈现显著的余弦相似性，存在共享的低维子空间；跨任务的模型插值仍保持一致的 broadly misaligned 行为，线性模式连通性成立。

Conclusion: EM 可能源自不同任务发现同一组参数方向，造成有害行为在权重景观中可预测且可定位。这为参数空间可解释性和基于权重的干预提供方向。

Abstract: Recent work has discovered that large language models can develop broadly
misaligned behaviors after being fine-tuned on narrowly harmful datasets, a
phenomenon known as emergent misalignment (EM). However, the fundamental
mechanisms enabling such harmful generalization across disparate domains remain
poorly understood. In this work, we adopt a geometric perspective to study EM
and demonstrate that it exhibits a fundamental cross-task linear structure in
how harmful behavior is encoded across different datasets. Specifically, we
find a strong convergence in EM parameters across tasks, with the fine-tuned
weight updates showing relatively high cosine similarities, as well as shared
lower-dimensional subspaces as measured by their principal angles and
projection overlaps. Furthermore, we also show functional equivalence via
linear mode connectivity, wherein interpolated models across narrow
misalignment tasks maintain coherent, broadly misaligned behavior. Our results
indicate that EM arises from different narrow tasks discovering the same set of
shared parameter directions, suggesting that harmful behaviors may be organized
into specific, predictable regions of the weight landscape. By revealing this
fundamental connection between parametric geometry and behavioral outcomes, we
hope our work catalyzes further research on parameter space interpretability
and weight-based interventions.

</details>


### [55] [Path-Coordinated Continual Learning with Neural Tangent Kernel-Justified Plasticity: A Theoretical Framework with Near State-of-the-Art Performance](https://arxiv.org/abs/2511.02025)
*Rathin Chandra Shit*

Main category: cs.LG

TL;DR: 提出一种路径协调的持续学习框架，将 NTK 理论、Wilson 置信区间和多指标路径质量评估结合起来，在 Split-CIFAR10 上显著提升连续学习表现并揭示学习容量的边界。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习中的灾难性遗忘问题，寻求以理论界定的可解释边界和统计保证来提升长期保持与任务序列适应性。

Method: 将 NTK 理论用于构建 principled plasticity bounds 的路径协调框架；引入 Wilson 置信区间进行统计验证；以多项路径质量指标评价学习过程中的迁移与遗忘；在 Split-CIFAR10 上进行系统实验。

Result: 平均准确率66.7%，遗忘率23.4%（Split-CIFAR10），远超基线并接近最优结果；NTK 条件数预测学习容量极限，存在超过1e11的临界阈值；任务序列推进时遗忘下降（27% → 18%），路径80%获得统计保证，中间任务保留率达90-97%；给出核心容量极限及提升自适应正则化的可操作洞见。

Conclusion: 该框架提供一个理论与统计双重保障的持续学习新路径，揭示在高条件数下的容量极限并通过路径选择与自适应正则化实现更稳定的遗忘控制。

Abstract: Catastrophic forgetting is one of the fundamental issues of continual
learning because neural networks forget the tasks learned previously when
trained on new tasks. The proposed framework is a new path-coordinated
framework of continual learning that unites the Neural Tangent Kernel (NTK)
theory of principled plasticity bounds, statistical validation by Wilson
confidence intervals, and evaluation of path quality by the use of multiple
metrics. Experimental evaluation shows an average accuracy of 66.7% at the cost
of 23.4% catastrophic forgetting on Split-CIFAR10, a huge improvement over the
baseline and competitive performance achieved, which is very close to
state-of-the-art results. Further, it is found out that NTK condition numbers
are predictive indicators of learning capacity limits, showing the existence of
a critical threshold at condition number $>10^{11}$. It is interesting to note
that the proposed strategy shows a tendency of lowering forgetting as the
sequence of tasks progresses (27% to 18%), which is a system stabilization. The
framework validates 80% of discovered paths with a rigorous statistical
guarantee and maintains 90-97% retention on intermediate tasks. The core
capacity limits of the continual learning environment are determined in the
analysis, and actionable insights to enhance the adaptive regularization are
offered.

</details>


### [56] [Natural-gas storage modelling by deep reinforcement learning](https://arxiv.org/abs/2511.02646)
*Tiziano Balaconi,Aldo Glielmo,Marco Taboga*

Main category: cs.LG

TL;DR: 引入 GasRL：一个将标定的天然气市场表示与通过深度强化学习训练的储气运营商策略耦合的仿真器，用以分析最优库存管理对市场价格、需求与供给动态的影响。实验表明，SAC 在GasRL环境中表现最佳，能够同时实现盈利性、市场清算鲁棒性和价格稳定性等多目标，并使均衡价格动态具备与实际价格相近的波动性与季节性特征；此外，最低储存阈值的欧盟政策在提高市场对突发供给冲击的韧性方面具有积极作用。


<details>
  <summary>Details</summary>
Motivation: 揭示储存运营商策略的最优性对市场价格与动态的影响，以及如何通过强化学习与政策干预来提高市场稳定性与韧性。

Method: 构建 GasRL 仿真器，将标定的天然气市场模型与通过深度强化学习训练的储存运营商策略耦合；比较多种 RL 算法，发现 Soft Actor-Critic (SAC) 在该环境中具有较强性能；评估储存运营商的多目标（盈利、市场清算鲁棒性、价格稳定性）并与历史价格分布进行对比；在仿真中加入欧盟强制的最低储存阈值，分析其对市场韧性与对冲冲击的效果。

Result: SAC 表现优越，能同时实现盈利、市场清算鲁棒性及价格稳定等多目标，SAC 导致的均衡价格动态具有与真实世界价格相近的波动性与季节性分布，即使未直接用价格数据进行标定；引入最低储存阈值时，市场在面对异常大的冲击时更不易发生波动和中断，显示出更强的韧性。

Conclusion: 强化学习驱动的储存策略可在复杂市场中再现现实价格特征并为政策分析提供工具，欧盟最低储存阈值有助于提升市场对供给冲击的抵御能力，GasRL 具备用于评估相关市场与政策影响的潜力。

Abstract: We introduce GasRL, a simulator that couples a calibrated representation of
the natural gas market with a model of storage-operator policies trained with
deep reinforcement learning (RL). We use it to analyse how optimal stockpile
management affects equilibrium prices and the dynamics of demand and supply. We
test various RL algorithms and find that Soft Actor Critic (SAC) exhibits
superior performance in the GasRL environment: multiple objectives of storage
operators - including profitability, robust market clearing and price
stabilisation - are successfully achieved. Moreover, the equilibrium price
dynamics induced by SAC-derived optimal policies have characteristics, such as
volatility and seasonality, that closely match those of real-world prices.
Remarkably, this adherence to the historical distribution of prices is obtained
without explicitly calibrating the model to price data. We show how the
simulator can be used to assess the effects of EU-mandated minimum storage
thresholds. We find that such thresholds have a positive effect on market
resilience against unanticipated shifts in the distribution of supply shocks.
For example, with unusually large shocks, market disruptions are averted more
often if a threshold is in place.

</details>


### [57] [Flashlight: PyTorch Compiler Extensions to Accelerate Attention Variants](https://arxiv.org/abs/2511.02043)
*Bozhi You,Irene Wang,Zelal Su Mustafaoglu,Abhinav Jangda,Angélica Moreira,Roshan Dathathri,Divya Mahajan,Keshav Pingali*

Main category: cs.LG

TL;DR: Flashlight 自动为任意注意力程序在 PyTorch 生态内生成融合的 FlashAttention 风格内核，性能可与 FlexAttention 相媲美且具有更高的灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有注意力实现要么依赖特殊内核、手工调优的模板，要么仅支持有限的变体，难以高效支持多样化的注意力形式；需要一个自动化、编译时的解决方案来实现广义的注意力优化。

Method: 在 PyTorch 编译流程中嵌入一个编译器风格框架，自动生成融合和分块（tiling）的注意力内核，既不依赖静态模板也不依赖预定义的内核特化，支持 FlexAttention 的所有变体以及更广泛的数据相关注意力。

Result: 生成的内核在性能上与 FlexAttention 相当甚至优越，同时保留原生 PyTorch 代码的灵活性，便于开发者快速尝试新注意力模型而不损失性能。

Conclusion: Flashlight 为任意注意力程序提供了一个自动化、编译期优化的解决方案，兼具高性能与灵活性，促进在 PyTorch 中的注意力模型创新。

Abstract: Bad charactors when submitting to arXiv: Attention is a fundamental building
block of large language models (LLMs), so there have been many efforts to
implement it efficiently. For example, FlashAttention leverages tiling and
kernel fusion to optimize attention. Recently, a number of variants of
attention have been introduced to enhance model quality or efficiency.
Supporting them efficiently remains difficult since they usually require
specialized kernels or hand-tuned implementations. FlexAttention recently
addressed part of this gap by using static programming templates to support
FlashAttention-like kernels for a subset of attention variants.
  In this paper, we introduce Flashlight, a compiler-native framework within
the PyTorch ecosystem that automatically generates fused, FlashAttention-style
kernels for arbitrary attention-based programs, without relying on static
templates or predefined kernel specializations. Flashlight leverages PyTorch's
compilation workflow to fuse and tile attention computations transparently,
enabling efficient execution for diverse attention patterns. Not only does it
support all variants expressible in the FlexAttention model but it also handles
more general, data-dependent attention formulations that are beyond the
capabilities of FlexAttention.
  Our results show that Flashlight produces kernels with competitive or
superior performance to FlexAttention, while offering the flexibility of native
PyTorch code, enabling developers to rapidly explore new attention models
without sacrificing performance.

</details>


### [58] [VecComp: Vector Computing via MIMO Digital Over-the-Air Computation](https://arxiv.org/abs/2511.02765)
*Saeed Razavikia,José Mairton Barros Da Silva Junior,Carlo Fischione*

Main category: cs.LG

TL;DR: VecComp 将 ChannelComp 扩展到多天线场景，实现对向量函数的数字空中计算，具备线性维度可扩展性与对信道衰落的鲁棒性，给出非渐近的均方误差上界并通过数值实验验证效果。


<details>
  <summary>Details</summary>
Motivation: 解决原有 ChannelComp 仅能计算标量函数、易受信道衰落影响且对大规模数据应用难以扩展的局限，提出面向向量函数计算的新框架以提升高维数据处理能力。

Method: 在 ChannelComp 的基础上引入多天线技术（MIMO），实现向量函数的数字计算，计算复杂度随向量维数线性增长，推导在衰落信道条件下的非渐近均方误差上界，并通过数值实验评估在有噪声和衰落的多址通道上的性能。

Result: 给出 VecComp 的非渐近上界，表明在衰落条件下仍具备良好计算性能；数值实验显示在向量函数计算和衰落补偿方面优于基线方法。

Conclusion: VecComp 能以较低的计算开销实现高维向量函数的数字空中计算，对信道衰落具有鲁棒性，适合高维数据驱动的分布式计算场景。

Abstract: Recently, the ChannelComp framework has proposed digital over-the-air
computation by designing digital modulations that enable the computation of
arbitrary functions. Unlike traditional analog over-the-air computation, which
is restricted to nomographic functions, ChannelComp enables a broader range of
computational tasks while maintaining compatibility with digital communication
systems. This framework is intended for applications that favor local
information processing over the mere acquisition of data. However, ChannelComp
is currently designed for scalar function computation, while numerous
data-centric applications necessitate vector-based computations, and it is
susceptible to channel fading. In this work, we introduce a generalization of
the ChannelComp framework, called VecComp, by integrating ChannelComp with
multiple-antenna technology. This generalization not only enables vector
function computation but also ensures scalability in the computational
complexity, which increases only linearly with the vector dimension. As such,
VecComp remains computationally efficient and robust against channel
impairments, making it suitable for high-dimensional, data-centric
applications. We establish a non-asymptotic upper bound on the mean squared
error of VecComp, affirming its computation efficiency under fading channel
conditions. Numerical experiments show the effectiveness of VecComp in
improving the computation of vector functions and fading compensation over
noisy and fading multiple-access channels.

</details>


### [59] [Regularization Through Reasoning: Systematic Improvements in Language Model Classification via Explanation-Enhanced Fine-Tuning](https://arxiv.org/abs/2511.02044)
*Vivswan Shah,Randy Cogill,Hanwei Yue,Gopinath Chennupati,Rinat Khaziev*

Main category: cs.LG

TL;DR: Explanation-augmented fine-tuning improves LLM classification; random token explanations can still yield gains, acting as a regularizer and shaping computation.


<details>
  <summary>Details</summary>
Motivation: Explore whether attaching brief explanations to each label during fine-tuning improves model performance, and whether the benefit comes from semantics or the token-level structure.

Method: Fine-tune a 7B-parameter model using label-plus-explanation data generated by ensembles of LLMs across six diverse conversational datasets; compare to label-only baselines; replace explanations with random tokens (syntactically incoherent but vocabulary-aligned); evaluate across 18 dataset-task settings on naturalness, comprehensiveness, and on-topic adherence; analyze intermediate layer activation entropy and output-layer mass.

Result: Label-plus-explanation training outperforms label-only across 18 dataset-task settings. Surprisingly, random-token explanations also improve accuracy, narrowing the gap to true explanations. Gains persist across seeds, suggesting structure/regularization rather than semantics as the driver. Models show higher activation entropy in intermediate layers and sharper mass at the output, indicating increased deliberation.

Conclusion: Explanation-augmented fine-tuning enhances accuracy and reliability for LLM classification. Token-level scaffolding—whether genuine or pseudo—modulates computation during inference by acting as a regularizer and promoting more deliberate processing.

Abstract: Fine-tuning LLMs for classification typically maps inputs directly to labels.
We ask whether attaching brief explanations to each label during fine-tuning
yields better models. We evaluate conversational response quality along three
axes: naturalness, comprehensiveness, and on-topic adherence, each rated on
5-point scales. Using ensemble-generated data from multiple LLMs, we fine-tune
a 7B-parameter model and test across six diverse conversational datasets.
Across 18 dataset, task settings, label-plus-explanation training outperforms
label-only baselines.
  A central and unexpected result concerns random tokens. We replace
human-written explanations with text that is syntactically incoherent yet
vocabulary-aligned with the originals (e.g., shuffled or bag-of-words
variants). Despite lacking semantics, these pseudo-explanations still improve
accuracy over label-only training and often narrow much of the gap to true
explanations. The effect persists across datasets and training seeds,
indicating that gains arise less from meaning than from structure: the extra
token budget encourages richer intermediate computation and acts as a
regularizer that reduces over-confident shortcuts.
  Internal analyses support this view: explanation-augmented models exhibit
higher activation entropy in intermediate layers alongside sharper predictive
mass at the output layer, consistent with increased deliberation before
decision. Overall, explanation-augmented fine-tuning, whether with genuine
rationales or carefully constructed random token sequences, improves accuracy
and reliability for LLM classification while clarifying how token-level
scaffolding shapes computation during inference.

</details>


### [60] [A Dual-Use Framework for Clinical Gait Analysis: Attention-Based Sensor Optimization and Automated Dataset Auditing](https://arxiv.org/abs/2511.02047)
*Hamidreza Sadeghsalehi*

Main category: cs.LG

TL;DR: 提出一种多流注意力深度学习框架，兼具传感器优化与数据审计功能；在 Voisard 等人2025 的多队列步态数据集上揭示严重的数据集混淆与偏倚，并提出数据驱动的传感器协同假设。


<details>
  <summary>Details</summary>
Motivation: 解决可穿戴传感器步态分析对隐藏数据偏倪的敏感性，以及克服现有方法在任务特异性传感器选择上的局限。

Method: 建立多流注意力框架，能在四个临床任务上同时评估和审计数据；通过注意力分布来诊断数据集偏倚，并探索传感器组合以提高任务性能。

Result: 注意力机制发现显著的数据偏倪：对于 OA 和 CVA 筛查，右脚获得>70% 的注意力，而左脚几乎被忽略（<0.1%，95%CI 0.0–0.1%）；以及数据集中存在仅右侧 OA 的现象（如 15/15），这不是临床发现，而是数据集偏差的直接反映。

Conclusion: 方法学贡献在于提供一个可解释框架，能够自动审计数据集完整性；作为次要发现，提出了数据驱动的传感器协同（如头部+足部）等假设，供未来协议优化验证。

Abstract: Objective gait analysis using wearable sensors and AI is critical for
managing neurological and orthopedic conditions. However, models are vulnerable
to hidden dataset biases, and task-specific sensor optimization remains a
challenge. We propose a multi-stream attention-based deep learning framework
that functions as both a sensor optimizer and an automated data auditor.
Applied to the Voisard et al. (2025) multi-cohort gait dataset on four clinical
tasks (PD, OA, CVA screening; PD vs CVA differential), the model's attention
mechanism quantitatively discovered a severe dataset confound. For OA and CVA
screening, tasks where bilateral assessment is clinically essential, the model
assigned more than 70 percent attention to the Right Foot while statistically
ignoring the Left Foot (less than 0.1 percent attention, 95 percent CI
[0.0-0.1]). This was not a clinical finding but a direct reflection of a severe
laterality bias (for example, 15 of 15 right-sided OA) in the public dataset.
The primary contribution of this work is methodological, demonstrating that an
interpretable framework can automatically audit dataset integrity. As a
secondary finding, the model proposes novel, data-driven sensor synergies (for
example, Head plus Foot for PD screening) as hypotheses for future optimized
protocols.

</details>


### [61] [Finding Probably Approximate Optimal Solutions by Training to Estimate the Optimal Values of Subproblems](https://arxiv.org/abs/2511.02048)
*Nimrod Megiddo,Segev Wasserkrug,Orit Davidovich,Shimrit Shtern*

Main category: cs.LG

TL;DR: 提出一个基于分布估计的求解器，用于最大化二进制变量的实值目标函数；通过训练一个估计器，利用目标及其子实例分布信息，使用期望总偏差（相对于最优性）的损失函数进行训练；不直接计算策略值，也不依赖已解决的实例。


<details>
  <summary>Details</summary>
Motivation: 在不需要已经求解的实例的情况下，从目标分布及其子实例的统计信息中推断最优目标值，以提升估计的效率和可扩展性。

Method: 训练一个基于目标及其子实例分布的估计器；损失函数由从最优性条件推导的期望总偏差构成，因此不需要直接求解目标函数的具体值。

Result: 摘要未提供具体实现细节或实验结果，只描述了框架和训练思路。

Conclusion: 该方法展示了从分布信息直接估计最优目标值的潜力，避免对已解实例的依赖；但实际效果需要通过进一步的实验来验证。

Abstract: The paper is about developing a solver for maximizing a real-valued function
of binary variables. The solver relies on an algorithm that estimates the
optimal objective-function value of instances from the underlying distribution
of objectives and their respective sub-instances. The training of the estimator
is based on an inequality that facilitates the use of the expected total
deviation from optimality conditions as a loss function rather than the
objective-function itself. Thus, it does not calculate values of policies, nor
does it rely on solved instances.

</details>


### [62] [LLM Probing with Contrastive Eigenproblems: Improving Understanding and Applicability of CCS](https://arxiv.org/abs/2511.02089)
*Stefan F. Schouten,Peter Bloem*

Main category: cs.LG

TL;DR: CCS被重新表述为相对对比一致性问题；将CCS转化为特征的特征向量的特征值问题，给出闭式解并可解释的特征值，扩展到多变量；在多数据集上实验表明性能与原CCS相近，但对随机初始化的敏感性下降；为更广的探测和机理可解释性打开新路径。


<details>
  <summary>Details</summary>
Motivation: 解决无监督探测中CCS的局限性，澄清其机制，并提高鲁棒性及扩展性，用相对对比一致性重新定义目标。

Method: 将CCS重构为特征向量的特征值问题，推导闭式解，进一步将方法扩展到多变量情形；在多数据集上评估，比较与原CCS的性能与稳定性。

Result: 基于特征值的等价解在性能上可与CCS相似，同时减少对随机初始化的敏感性；特征值提供直观解释，方法具备自然的多变量扩展能力。

Conclusion: 相对化的对比一致性不仅有助于理解CCS的工作机制，还为更广泛的探测和机理层面的可解释性研究打开新的方向。

Abstract: Contrast-Consistent Search (CCS) is an unsupervised probing method able to
test whether large language models represent binary features, such as sentence
truth, in their internal activations. While CCS has shown promise, its two-term
objective has been only partially understood. In this work, we revisit CCS with
the aim of clarifying its mechanisms and extending its applicability. We argue
that what should be optimized for, is relative contrast consistency. Building
on this insight, we reformulate CCS as an eigenproblem, yielding closed-form
solutions with interpretable eigenvalues and natural extensions to multiple
variables. We evaluate these approaches across a range of datasets, finding
that they recover similar performance to CCS, while avoiding problems around
sensitivity to random initialization. Our results suggest that relativizing
contrast consistency not only improves our understanding of CCS but also opens
pathways for broader probing and mechanistic interpretability methods.

</details>


### [63] [Natural Building Blocks for Structured World Models: Theory, Evidence, and Scaling](https://arxiv.org/abs/2511.02091)
*Lancelot Da Costa,Sanjeev Namjoshi,Mohammed Abbas Ansari,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: A modular, hierarchical framework for world modeling built from discrete (HMMs) and continuous (sLDS) building blocks, enabling both passive modeling and active control with a fixed architectural depth; achieves competitive performance and interpretability, but joint structure-parameter learning scalability remainsOpen.


<details>
  <summary>Details</summary>
Motivation: The field of world modeling is fragmented; there is a need for standardized, composable building blocks that cover discrete and continuous dynamics and support both passive generation/forecasting and active planning/decision-making. Providing interpretability and a scalable architecture could unify diverse approaches.

Method: Propose a world model defined by the hierarchical composition ofHMM (discrete) and switching linear dynamical systems (continuous) as the core building blocks. Augment with actions to form partially observable MDPs (POMDPs) and controlled sLDS. Fix the causal architecture and search over four depth parameters to avoid combinatorial structure learning. Evaluate expressiveness through multimodal generation (passive) and planning from pixels (active).

Result: Demonstrates competitive expressiveness with neural approaches while maintaining interpretability. The modular approach supports both passive modeling and active control within a unified architecture. A key outstanding challenge is scalable joint structure–parameter learning; current methods grow structure and parameters incrementally but face scalability limits.

Conclusion: If solved, these natural building blocks could provide foundational infrastructure for world modeling, analogous to standardized layers enabling progress in deep learning.

Abstract: The field of world modeling is fragmented, with researchers developing
bespoke architectures that rarely build upon each other. We propose a framework
that specifies the natural building blocks for structured world models based on
the fundamental stochastic processes that any world model must capture:
discrete processes (logic, symbols) and continuous processes (physics,
dynamics); the world model is then defined by the hierarchical composition of
these building blocks. We examine Hidden Markov Models (HMMs) and switching
linear dynamical systems (sLDS) as natural building blocks for discrete and
continuous modeling--which become partially-observable Markov decision
processes (POMDPs) and controlled sLDS when augmented with actions. This
modular approach supports both passive modeling (generation, forecasting) and
active control (planning, decision-making) within the same architecture. We
avoid the combinatorial explosion of traditional structure learning by largely
fixing the causal architecture and searching over only four depth parameters.
We review practical expressiveness through multimodal generative modeling
(passive) and planning from pixels (active), with performance competitive to
neural approaches while maintaining interpretability. The core outstanding
challenge is scalable joint structure-parameter learning; current methods
finesse this by cleverly growing structure and parameters incrementally, but
are limited in their scalability. If solved, these natural building blocks
could provide foundational infrastructure for world modeling, analogous to how
standardized layers enabled progress in deep learning.

</details>


### [64] [Uncertainty Guided Online Ensemble for Non-stationary Data Streams in Fusion Science](https://arxiv.org/abs/2511.02092)
*Kishansingh Rajput,Malachi Schram,Brian Sammuli,Sen Lin*

Main category: cs.LG

TL;DR: 应用在线学习以应对聚变装置中随时间漂移的数据分布，提出基于深高斯过程近似的未确定性引导在线集成方法，以多历史视角的学习者集成提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 融合装置数据呈现非平稳性和分布漂移，传统静态ML模型在持续演化的数据流上性能下降；在线学习在其他领域已有应用，但在聚变领域尚未充分开发，存在对漂移的适应需求。

Method: 在DIII-D装置上将在线学习用于连续适应数据漂移并预测环形场线圈的偏转；引入深度高斯过程近似(DGPA)用于已校准的不确定性估计，并据此引导一个元算法的在线集成，该集成基于对历史数据不同时间滑动窗口的学习者集合。

Result: 相比静态模型，在线学习将预测误差降低约80%；相较于单一在线学习模型，在线集成约降低误差6%，引导不确定性集成约降低误差10%。DGPA同時提供不确定性估计以供决策者使用。

Conclusion: 在线学习对聚变数据的分布漂移具有关键作用，基于DGPA的不确定性引导在线集成进一步提升预测性能并提供校准的不确定性信息，有望在实际聚变控制与诊断中提升鲁棒性与决策可信度。

Abstract: Machine Learning (ML) is poised to play a pivotal role in the development and
operation of next-generation fusion devices. Fusion data shows non-stationary
behavior with distribution drifts, resulted by both experimental evolution and
machine wear-and-tear. ML models assume stationary distribution and fail to
maintain performance when encountered with such non-stationary data streams.
Online learning techniques have been leveraged in other domains, however it has
been largely unexplored for fusion applications. In this paper, we present an
application of online learning to continuously adapt to drifting data stream
for prediction of Toroidal Field (TF) coils deflection at the DIII-D fusion
facility. The results demonstrate that online learning is critical to maintain
ML model performance and reduces error by 80% compared to a static model.
Moreover, traditional online learning can suffer from short-term performance
degradation as ground truth is not available before making the predictions. As
such, we propose an uncertainty guided online ensemble method to further
improve the performance. The Deep Gaussian Process Approximation (DGPA)
technique is leveraged for calibrated uncertainty estimation and the
uncertainty values are then used to guide a meta-algorithm that produces
predictions based on an ensemble of learners trained on different horizon of
historical data. The DGPA also provides uncertainty estimation along with the
predictions for decision makers. The online ensemble and the proposed
uncertainty guided online ensemble reduces predictions error by about 6%, and
10% respectively over standard single model based online learning.

</details>


### [65] [Matrix Sensing with Kernel Optimal Loss: Robustness and Optimization Landscape](https://arxiv.org/abs/2511.02122)
*Xinyuan Song,Jiaye Teng,Ziye Ma*

Main category: cs.LG

TL;DR: 提出一种基于核密度估计的鲁棒损失，用于非凸优化中的鲁棒性和优化景观分析，特别应用于矩阵感知；在大噪声和非高斯噪声下优于MSE，且有理论与实验支持其消除伪局部极小点的能力。


<details>
  <summary>Details</summary>
Motivation: 在非高斯或重尾噪声下，传统最小二乘的鲁棒性不足，需要更稳健的损失来提升优化过程的稳定性和景观性质。

Method: 构建基于残差密度的核密度估计并最大化其对数似然，得到一种鲁棒损失；通过分析RIP常数上界来研究伪局部极小点消失的条件；在理论推导基础上进行实验验证。

Result: 鲁棒损失在高噪声和多种噪声分布下表现出更强的稳健性；理论分析显示该损失有利于消除非真实局部极小点，提升优化景观质量；实验结果与理论一致。

Conclusion: 仅通过改变损失函数即可显著提升鲁棒性，提供一个直观且广泛适用的分析框架来增强机器学习任务的稳健性。

Abstract: In this paper we study how the choice of loss functions of non-convex
optimization problems affects their robustness and optimization landscape,
through the study of noisy matrix sensing. In traditional regression tasks,
mean squared error (MSE) loss is a common choice, but it can be unreliable for
non-Gaussian or heavy-tailed noise. To address this issue, we adopt a robust
loss based on nonparametric regression, which uses a kernel-based estimate of
the residual density and maximizes the estimated log-likelihood. This robust
formulation coincides with the MSE loss under Gaussian errors but remains
stable under more general settings. We further examine how this robust loss
reshapes the optimization landscape by analyzing the upper-bound of restricted
isometry property (RIP) constants for spurious local minima to disappear.
Through theoretical and empirical analysis, we show that this new loss excels
at handling large noise and remains robust across diverse noise distributions.
This work offers initial insights into enhancing the robustness of machine
learning tasks through simply changing the loss, guided by an intuitive and
broadly applicable analytical framework.

</details>


### [66] [Variance-Aware Feel-Good Thompson Sampling for Contextual Bandits](https://arxiv.org/abs/2511.02123)
*Xuheng Li,Quanquan Gu*

Main category: cs.LG

TL;DR: 提出 FGTSVA，一种方差感知的 Thompson 采样算法，面向具有通用奖励函数的情境赌博，在引入新的解耦系数 dc 的基础上，达到最优的渐近再生界限。在线性情境下，其界限与基于加权线性回归的 UCB 方法等价。


<details>
  <summary>Details</summary>
Motivation: 在情境赌博中，方差相关的 regret 界限越来越受到关注；但大多数研究聚焦于上置信界（UCB）算法，基于采样的择优策略如 Thompson 采样研究不足。现有 LinVDTS 仅适用于线性奖励且对模型维度的界限并非最优。需要一种适用于通用奖励函数且具有方差感知能力的 Thompson 采样算法，以达到更优的全局再生界限。

Method: 提出 FGTSVA，扩展 Feel-good Thompson Sampling（FGTS）的解耦系数 dc，用以反映模型空间的复杂度。通过引入新的 dc，给出 FGTS-VA 的再生界限：tilde O( sqrt( dc * log|F| * sum_{t=1}^T σ_t^2 ) + dc )，其中 |F| 是模型空间大小，σ_t^2 是第 t 轮的子高斯噪声范数（在高斯噪声下等于方差）。在情境线性赌博设定下，FGTSVA 的界限与使用加权线性回归的 UCB 算法（Zhou & Gu, 2022）的界限相匹配。

Result: 给出了一种方差感知的 Thompson 采样算法 FGTSVA 并给出其对一般奖励函数的最优再生界限。通过新的解耦系数 dc，界限形式为 tilde O( sqrt( dc * log|F| * sum σ_t^2 ) + dc )，并在线性情境下实现与基于加权线性回归的 UCB 相等的性能。

Conclusion: FGTSVA 成功将方差感知的思想引入 Thompson 采样框架，扩展到具有通用奖励函数的情境赌博，并给出最优再生界限；同时通过引入解耦系数 dc，建立了与 UCB-基方法在线性场景下的等价性，弥合了采样与 UCB 两类方法的性能差距。

Abstract: Variance-dependent regret bounds have received increasing attention in recent
studies on contextual bandits. However, most of these studies are focused on
upper confidence bound (UCB)-based bandit algorithms, while sampling based
bandit algorithms such as Thompson sampling are still understudied. The only
exception is the LinVDTS algorithm (Xu et al., 2023), which is limited to
linear reward function and its regret bound is not optimal with respect to the
model dimension. In this paper, we present FGTSVA, a variance-aware Thompson
Sampling algorithm for contextual bandits with general reward function with
optimal regret bound. At the core of our analysis is an extension of the
decoupling coefficient, a technique commonly used in the analysis of Feel-good
Thompson sampling (FGTS) that reflects the complexity of the model space. With
the new decoupling coefficient denoted by $\mathrm{dc}$, FGTS-VA achieves the
regret of
$\tilde{O}(\sqrt{\mathrm{dc}\cdot\log|\mathcal{F}|\sum_{t=1}^T\sigma_t^2}+\mathrm{dc})$,
where $|\mathcal{F}|$ is the size of the model space, $T$ is the total number
of rounds, and $\sigma_t^2$ is the subgaussian norm of the noise (e.g.,
variance when the noise is Gaussian) at round $t$. In the setting of contextual
linear bandits, the regret bound of FGTSVA matches that of UCB-based algorithms
using weighted linear regression (Zhou and Gu, 2022).

</details>


### [67] [Disentangling Causal Substructures for Interpretable and Generalizable Drug Synergy Prediction](https://arxiv.org/abs/2511.02146)
*Yi Luo,Haochen Zhao,Xiao Liang,Yiwei Liu,Yuye Zhang,Xinyu Li,Jianxin Wang*

Main category: cs.LG

TL;DR: 提出CausalDDS，通过将药物分子分解为因果子结构和伪相关子结构，利用因果子结构来预测药物协同作用，提升在可解释性与泛化能力，特别在冷启动与分布外场景。


<details>
  <summary>Details</summary>
Motivation: 现有药物协同预测多为黑箱模型，依赖统计相关性，缺乏对因果机制的揭示，难以解释且在数据不足时性能受限。

Method: 将药物分子分解为因果子结构与伪相关子结构，使用条件干预机制，干预以配对分子结构为条件，提出基于充分性和独立性的新优化目标，以提升因果子结构的预测能力与解释力。

Result: 在广泛实验中，该方法超越基线，特别在cold start和out-of-distribution场景下表现更优，并能识别关键子结构，提供分子层面的解释。

Conclusion: CausalDDS是一个可用于药物协同预测和药物发现的实用工具，能够提高预测准确性与可解释性。

Abstract: Drug synergy prediction is a critical task in the development of effective
combination therapies for complex diseases, including cancer. Although existing
methods have shown promising results, they often operate as black-box
predictors that rely predominantly on statistical correlations between drug
characteristics and results. To address this limitation, we propose CausalDDS,
a novel framework that disentangles drug molecules into causal and spurious
substructures, utilizing the causal substructure representations for predicting
drug synergy. By focusing on causal sub-structures, CausalDDS effectively
mitigates the impact of redundant features introduced by spurious
substructures, enhancing the accuracy and interpretability of the model. In
addition, CausalDDS employs a conditional intervention mechanism, where
interventions are conditioned on paired molecular structures, and introduces a
novel optimization objective guided by the principles of sufficiency and
independence. Extensive experiments demonstrate that our method outperforms
baseline models, particularly in cold start and out-of-distribution settings.
Besides, CausalDDS effectively identifies key substructures underlying drug
synergy, providing clear insights into how drug combinations work at the
molecular level. These results underscore the potential of CausalDDS as a
practical tool for predicting drug synergy and facilitating drug discovery.

</details>


### [68] [CFL: On the Use of Characteristic Function Loss for Domain Alignment in Machine Learning](https://arxiv.org/abs/2511.02148)
*Abdullah Almansour,Ozan Tonguz*

Main category: cs.LG

TL;DR: CF-based frequency-domain approach for quantifying distribution shift and aiding domain adaptation in high-dimensional ML.


<details>
  <summary>Details</summary>
Motivation: Distribution shift degrades ML performance in real-world/high-risk settings. Traditional statistics (KL, KS, Wasserstein) may struggle in high dimensions. The paper proposes using characteristic functions (CF) in the frequency domain as a powerful alternative for measuring distribution shift and enabling domain adaptation.

Method: Compute and compare characteristic functions of distributions in a high-dimensional feature space and use a CF-based distance to quantify distribution shift, with application to domain adaptation.

Result: Demonstrates that CF-based frequency-domain measurement is a powerful alternative for detecting distribution shift in high-dimensional space and supports domain adaptation.

Conclusion: CF is a promising tool for measuring distribution shift and enabling robust ML deployment in real-world settings.

Abstract: Machine Learning (ML) models are extensively used in various applications due
to their significant advantages over traditional learning methods. However, the
developed ML models often underperform when deployed in the real world due to
the well-known distribution shift problem. This problem can lead to a
catastrophic outcomes when these decision-making systems have to operate in
high-risk applications. Many researchers have previously studied this problem
in ML, known as distribution shift problem, using statistical techniques (such
as Kullback-Leibler, Kolmogorov-Smirnov Test, Wasserstein distance, etc.) to
quantify the distribution shift. In this letter, we show that using
Characteristic Function (CF) as a frequency domain approach is a powerful
alternative for measuring the distribution shift in high-dimensional space and
for domain adaptation.

</details>


### [69] [Tackling Incomplete Data in Air Quality Prediction: A Bayesian Deep Learning Framework for Uncertainty Quantification](https://arxiv.org/abs/2511.02175)
*Yuzhuang Pian,Taiyu Wang,Shiqi Zhang,Rui Xu,Yonghong Liu*

Main category: cs.LG

TL;DR: 提出 CGLUBNF 框架用于在不完整的时空观测下进行空气质量预测，结合 Fourier 特征、图注意力编码、通道门控学习单元与贝叶斯推断，实现点估计与预测区间，并在两个真实数据集和四种缺失模式下相比五个基线取得更优准确度与更锐利的置信区间。


<details>
  <summary>Details</summary>
Motivation: 现实中观测数据经常缺失，造成推断不可靠和风险评估偏差；需要一个端到端的、能处理时空缺失并给出校准不确定性的预测框架。

Method: 提出端到端的通道门控学习单元基础时空贝叶斯场模型 CGLUBNF。利用傅里叶特征配合图注意力编码器捕捉多尺度空间依赖与季节性时间动态；引入带可学习激活函数与门控残差连接的通道门控学习单元以自适应筛选和增强信息；采用贝叶斯推断联合优化预测分布与参数不确定性，给出点估计与预测区间。

Result: 在两组真实数据集、覆盖四种缺失模式、与五个基线对比中，CGLUBNF 实现了更高的预测准确性和更紧凑的置信区间；在不同预测 horizon 上表现鲁棒，并分析了外部变量的贡献。

Conclusion: 为在不完整观测条件下进行鲁棒的深度时空预测奠定基础，适用于新兴传感场景，如车载移动监测。

Abstract: Accurate air quality forecasts are vital for public health alerts, exposure
assessment, and emissions control. In practice, observational data are often
missing in varying proportions and patterns due to collection and transmission
issues. These incomplete spatiotemporal records impede reliable inference and
risk assessment and can lead to overconfident extrapolation. To address these
challenges, we propose an end to end framework, the channel gated learning unit
based spatiotemporal bayesian neural field (CGLUBNF). It uses Fourier features
with a graph attention encoder to capture multiscale spatial dependencies and
seasonal temporal dynamics. A channel gated learning unit, equipped with
learnable activations and gated residual connections, adaptively filters and
amplifies informative features. Bayesian inference jointly optimizes predictive
distributions and parameter uncertainty, producing point estimates and
calibrated prediction intervals. We conduct a systematic evaluation on two real
world datasets, covering four typical missing data patterns and comparing
against five state of the art baselines. CGLUBNF achieves superior prediction
accuracy and sharper confidence intervals. In addition, we further validate
robustness across multiple prediction horizons and analysis the contribution of
extraneous variables. This research lays a foundation for reliable deep
learning based spatio-temporal forecasting with incomplete observations in
emerging sensing paradigms, such as real world vehicle borne mobile monitoring.

</details>


### [70] [Learning Interactive World Model for Object-Centric Reinforcement Learning](https://arxiv.org/abs/2511.02225)
*Fan Feng,Phillip Lippe,Sara Magliacane*

Main category: cs.LG

TL;DR: FIOC-WM 引入一个以对象为中心且显式建模对象间互动的世界模型，能解耦并模块化表示，从而提升策略学习的样本效率与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的对象中心强化学习通常将状态按对象划分，但对对象间的互动缺乏显式建模，导致鲁棒性和泛化性不足。

Method: 从像素中利用预训练视觉编码器学习对象中心的潜在表示和对象间的交互结构，世界模型将任务分解为可组合的互动原语；并采用分层策略：高层选择互动的类型与顺序，低层执行它们。

Result: 在仿真机器人和具身AI基准上，FIOC-WM 相对于基线的世界模型提升了样本效率与泛化性，证明了显式、模块化的互动学习对鲁棒控制的重要性。

Conclusion: 显式的、可模块化的对象互动建模是实现更鲁棒、可迁移策略的关键，FIOC-WM 为对象-互动层面的表示学习和策略学习提供了有效框架。

Abstract: Agents that understand objects and their interactions can learn policies that
are more robust and transferable. However, most object-centric RL methods
factor state by individual objects while leaving interactions implicit. We
introduce the Factored Interactive Object-Centric World Model (FIOC-WM), a
unified framework that learns structured representations of both objects and
their interactions within a world model. FIOC-WM captures environment dynamics
with disentangled and modular representations of object interactions, improving
sample efficiency and generalization for policy learning. Concretely, FIOC-WM
first learns object-centric latents and an interaction structure directly from
pixels, leveraging pre-trained vision encoders. The learned world model then
decomposes tasks into composable interaction primitives, and a hierarchical
policy is trained on top: a high level selects the type and order of
interactions, while a low level executes them. On simulated robotic and
embodied-AI benchmarks, FIOC-WM improves policy-learning sample efficiency and
generalization over world-model baselines, indicating that explicit, modular
interaction learning is crucial for robust control.

</details>


### [71] [Opportunistic Expert Activation: Batch-Aware Expert Routing for Faster Decode Without Retraining](https://arxiv.org/abs/2511.02237)
*Costin-Andrei Oncescu,Qingyang Wu,Wai Tong Chung,Robert Wu,Bryan Gopal,Junxiong Wang,Tri Dao,Ben Athiwaratkun*

Main category: cs.LG

TL;DR: 提出一种面向 MoE 的基于批处理感知的动态路由框架，通过让 token 复用已加载在内存中的专家来降低解码延迟，同时尽量不损害模型质量。对 Qwen3-30B/235B（批量大小 16）在 MoE 层的解码延迟实现显著下降（39%/15%），且无统计显著的精度损失。


<details>
  <summary>Details</summary>
Motivation: 在 Mixture-of-Experts 架构中，前馈层被一组专家替代，并且每个 token 只激活其中的少量专家。由于内存带宽和缓存的限制，MoE 在中等批量下也易进入内存瓶颈，且平均激活的专家数量增长不及等价的 Dense FFN，从而使解码延迟受活跃专家数量支配。因此，需要在保持质量的同时降低激活的专家数量，从而降低延迟。

Method: 提出一个动态重路由框架来重新分配 token 到复杂的专家组的映射，旨在降低被激活的专家数量。最佳结果采用基于批量的路由（batch-aware routing），通过让 token 复用已经由于同一批内其他 token 而被加载到内存中的专家来实现路由。

Result: 在 Qwen3-30B 和 Qwen3-235B（批量大小 16）上进行实验，未出现统计学意义的精度下降，MoE 层解码延迟分别降低了 39% 和 15%。

Conclusion: 基于批量的动态路由策略能够显著降低 MoE 的解码延迟，同时在大规模模型中保持可比的质量，具有较好的泛化潜力。

Abstract: An increasing number of LLMs employ Mixture-of-Experts (MoE) architectures
where the feed-forward layer is replaced by a pool of experts and each token
only activates a small subset of them. During autoregressive generation, these
models often enter a memory-bound regime even for moderate batch sizes because
the average expert load grows more slowly than in an equivalent dense
feedforward layer. Consequently, MoE latency is governed by the number of
activated experts. We introduce a framework for dynamically re-routing
token-to-expert mapping to lower this number (and thus, the decode latency)
while preserving a comparable quality. Our best results use a batch-aware
routing that works by having tokens piggyback experts that have already been
loaded into memory due to being crucial to other tokens within the same batch.
Empirically, we evaluate our method on the Qwen3-30B and Qwen3-235B models with
a batch size of $16$. Without any statistically significant loss in accuracy,
our approach achieves latency reductions of $39\%$ and $15\%$ in the MoE layer
decode latency, respectively.

</details>


### [72] [Probabilistic Graph Cuts](https://arxiv.org/abs/2511.02272)
*Ayoub Ghriss*

Main category: cs.LG

TL;DR: 提出一个概率化的图切分框架，提供可微分且无特征分解的端到端学习方法，覆盖多种切分（包括归一化切分），并给出离散切分的严格上界，使用积分表示和高斯-超几何函数实现前向/反向传播。


<details>
  <summary>Details</summary>
Motivation: 现有基于 RatioCut 的方法在理论保证和通用性方面不足，且依赖特征分解（eigendecomposition）难以与端到端学习兼容。需要一个广义、可微、数值稳定的框架，兼容多种切分目标与对比学习场景。

Method: 建立一个统一的概率化 relaxations 框架，通过积分表示和高斯-超几何函数实现对广义图切分的上界，推导出前向和反向的闭式解，避免特征分解，同时覆盖 Normalized Cut 等多种切分。

Result: 给出对期望离散切分的紧界（上界），通过积分表示及高斯-超几何函数实现数值稳定的计算，具备可微分性，适用于大规模、在线和对比学习等场景，兼容多种聚类目标。

Conclusion: 该框架为可微分图分割提供了严谨且可扩展的基础，适用于广泛的聚类与对比学习目标，克服了仅限 RatioCut 的局限，且不需要特征分解，提升了可伸缩性与稳定性。

Abstract: Probabilistic relaxations of graph cuts offer a differentiable alternative to
spectral clustering, enabling end-to-end and online learning without
eigendecompositions, yet prior work centered on RatioCut and lacked general
guarantees and principled gradients. We present a unified probabilistic
framework that covers a wide class of cuts, including Normalized Cut. Our
framework provides tight analytic upper bounds on expected discrete cuts via
integral representations and Gauss hypergeometric functions with closed-form
forward and backward. Together, these results deliver a rigorous, numerically
stable foundation for scalable, differentiable graph partitioning covering a
wide range of clustering and contrastive learning objectives.

</details>


### [73] [Gradient-Variation Online Adaptivity for Accelerated Optimization with Hölder Smoothness](https://arxiv.org/abs/2511.02276)
*Yuheng Zhao,Yu-Hu Yan,Kfir Yehuda Levy,Peng Zhao*

Main category: cs.LG

TL;DR: 提出对 Hölder 光滑函数的在线学习的自适应梯度变动算法，并通过在线–离线转换实现普适的优化方法；在离线强凸情形通过检测式猜测-检查实现加速收敛，同时保持非光滑的近似最优性。


<details>
  <summary>Details</summary>
Motivation: 揭示加速优化与梯度变动在线学习之间的联系，扩展到 Hölder 光滑度，提供对两类 regime 的自适应方法；并将其转化为离线/随机优化的普适性方法。

Method: 为（强）凸在线函数设计梯度变动的在线学习算法，使在光滑与非光滑两种情形下的 regret 能自适应地插值；无需事先知道 Hölder 参数，具有强自适应性。通过在线到批量的转换得到对随机凸优化的普适方法；在离线强凸情形引入基于检测的猜测–检验过程，首次实现普适离线方法，在光滑情形实现加速收敛，在非光滑情形保持近最优。

Result: 得到的 regret 在光滑和非光滑两端对齐各自的最优界，算法对 Hölder 参数完全自适应；在线到离线转换得到普适的随机凸优化方法；离线强凸设定的普适性需通过检测性策略实现，达到光滑情形的加速与非光滑情形的近最优的折中。

Conclusion: 将 Hölder 光滑度作为统一框架，建立自适应的在线学习与离线优化方法，揭示两类问题之间的深层联系；普适性在离线强凸情形更具挑战，但通过检测性猜测-检验实现了首例具有加速性与近最优性的普适离线方法。

Abstract: Smoothness is known to be crucial for acceleration in offline optimization,
and for gradient-variation regret minimization in online learning.
Interestingly, these two problems are actually closely connected -- accelerated
optimization can be understood through the lens of gradient-variation online
learning. In this paper, we investigate online learning with H\"older smooth
functions, a general class encompassing both smooth and non-smooth (Lipschitz)
functions, and explore its implications for offline optimization. For
(strongly) convex online functions, we design the corresponding
gradient-variation online learning algorithm whose regret smoothly interpolates
between the optimal guarantees in smooth and non-smooth regimes. Notably, our
algorithms do not require prior knowledge of the H\"older smoothness parameter,
exhibiting strong adaptivity over existing methods. Through online-to-batch
conversion, this gradient-variation online adaptivity yields an optimal
universal method for stochastic convex optimization under H\"older smoothness.
However, achieving universality in offline strongly convex optimization is more
challenging. We address this by integrating online adaptivity with a
detection-based guess-and-check procedure, which, for the first time, yields a
universal offline method that achieves accelerated convergence in the smooth
regime while maintaining near-optimal convergence in the non-smooth one.

</details>


### [74] [FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error](https://arxiv.org/abs/2511.02302)
*Fengjuan Wang,Zhiyi Su,Xingzhu Hu,Cheng Wang,Mou Sun*

Main category: cs.LG

TL;DR: 提出 FP8-Flow-MoE，一种量化一致性的 FP8 训练流程，降低 Cast 次数并提升大规模 MoE 的吞吐量与显存效率，同时保持收敛稳定性；与 TransformerEngine 与 Megatron-LM 兼容，计划开源。


<details>
  <summary>Details</summary>
Motivation: 训练极大规模 Mixture-of-Experts 模型需要巨大的计算与显存开销；尽管低精度训练有潜力，但现有实现仍大量使用 BF16 数据流和量化/反量化转换，导致 FP8 的理论优势被削弱；若引入量化一致性且尽量减少显式 Cast，可以充分发挥 FP8 的效率并提升稳定性。

Method: 提出 FP8-Flow-MoE，在 FP8 为中心的数据流中引入带缩放感知的转置和融合的 FP8 运算，消除几乎所有显式 Cast，从 12 次降至 2 次；保证量化一致性，兼容 TransformerEngine 与 Megatron-LM，并提供可插拔的 FP8 方案。

Result: 在一个 671B 参数的 MoE 模型上，达到最多 21% 的吞吐提升，单个 GPU 的显存下降 16.5 GB，同时保持稳定的收敛。

Conclusion: FP8-Flow-MoE 提供一个可直接使用的 FP8 训练方案，能够与主流框架无缝对接，未来将开源，推动大规模 MoE 的高效训练。

Abstract: Training large Mixture-of-Experts (MoE) models remains computationally
prohibitive due to their extreme compute and memory demands. Although
low-precision training promises to accelerate computation and reduce memory
footprint, existing implementations still rely on BF16-dominated dataflows with
frequent quantize-dequantize (Q/DQ) conversions. These redundant casts erode
much of FP8's theoretical efficiency. However, naively removing these casts by
keeping dataflows entirely in FP8 introduces double quantization error: tensors
quantized along different dimensions accumulate inconsistent scaling factors,
degrading numerical stability.
  We propose FP8-Flow-MoE, an FP8 training recipe featuring a
quantization-consistent FP8-centric dataflow with a scaling-aware transpose and
fused FP8 operators that streamline computation and eliminate explicit cast
operations from 12 to 2. Evaluations on a 671B-parameter MoE model demonstrate
up to 21\% higher throughput and 16.5 GB lower memory usage per GPU compared to
BF16 and na\"ive FP8 baselines, while maintaining stable convergence. We
provide a plug-and-play FP8 recipe compatible with TransformerEngine and
Megatron-LM, which will be open-sourced soon.

</details>


### [75] [The Sequential Edge: Inverse-Entropy Voting Beats Parallel Self-Consistency at Matched Compute](https://arxiv.org/abs/2511.02309)
*Aman Sharma,Paras Chopra*

Main category: cs.LG

TL;DR: 在相同的 token 预算与计算下，逐步（顺序）推理比并行自一致性在大多数配置下更佳，且提升显著；并提出基于逆熵加权的投票以进一步提升准确性。


<details>
  <summary>Details</summary>
Motivation: 挑战当前主流的并行自一致性解码策略，探索测试时刻的推理策略对准确性和效率的影响，并提出在推理阶段如何更高效地利用链式推理的证据。

Method: 在五种开源模型和三个困难的推理基准上，比较并行全局自一致性与逐步递进式的串联改进（串联式推理）的性能，并引入逆熵加权投票（training-free）来融合不同推理链的输出以提升准确性。

Result: 在95.6%的配置中，串联式推理优于并行自一致性，准确率提升高达46.7%；引入逆熵加权投票后，串联策略的性能进一步提升并确立为最佳测试时刻推理策略。

Conclusion: 研究颠覆了自20世纪以来主导的并行推理范式，确立序列化、逐步改进的推理作为现代大模型推理的更稳健默认策略，并推动推理时优化的范式转变。

Abstract: We revisit test-time scaling for language model reasoning and ask a
fundamental question: at equal token budget and compute, is it better to run
multiple independent chains in parallel, or to run fewer chains that
iteratively refine through sequential steps? Through comprehensive evaluation
across 5 state-of-the-art open source models and 3 challenging reasoning
benchmarks, we find that sequential scaling where chains explicitly build upon
previous attempts consistently outperforms the dominant parallel
self-consistency paradigm in 95.6% of configurations with gains in accuracy
upto 46.7%. Further, we introduce inverse-entropy weighted voting, a novel
training-free method to further boost the accuracy of sequential scaling. By
weighing answers in proportion to the inverse entropy of their reasoning
chains, we increase our success rate over parallel majority and establish it as
the optimal test-time scaling strategy. Our findings fundamentally challenge
the parallel reasoning orthodoxy that has dominated test-time scaling since
Wang et al.'s self-consistency decoding (Wang et al., 2022), positioning
sequential refinement as the robust default for modern LLM reasoning and
necessitating a paradigm shift in how we approach inference-time optimization.

</details>


### [76] [Large-scale automatic carbon ion treatment planning for head and neck cancers via parallel multi-agent reinforcement learning](https://arxiv.org/abs/2511.02314)
*Jueye Zhang,Chao Yang,Youfang Lai,Kai-Wen Li,Wenting Yan,Yunzhou Xia,Haimei Zhang,Jingjing Zhou,Gen Yang,Chen Lin,Tian Li,Yibao Zhang*

Main category: cs.LG

TL;DR: 提出一个可扩展的多智能体强化学习框架，用于并行调优头颈部IMCT中的45个治疗规划参数，在与临床TPS直接交互中实现与专家手工方案相当甚至更优的计划，同时显著提升一些OARs的剂量规避。


<details>
  <summary>Details</summary>
Motivation: 头颈部放射治疗中需要同时保护多个重要器官且靶区复杂，IMCT在剂量一致性和OARs保护方面具优势但由于RBE建模导致规划过程缓慢且需要大量经验调参。现有DL易受数据偏差影响、RL在参数空间的探索效率不足，因此需要一种可扩展、高效的调参框架。

Method: 提出一个可扩展的多智能体RL（MARL）框架，采用集中训练-分散执行的QMIX作为骨架，并结合Double DQN、Dueling DQN和DRQN以实现高维非平稳环境中的稳定学习。关键设计包括：用紧凑历史DVH向量作为状态输入；将线性动作到值的映射将离散动作映射为一致的参数调整；基于计划分数的绝对、临床信息化分段奖励；以及一个与PHOENIX TPS并行数据采集的同步多进程工作系统。

Result: 在头颈部数据集（10条训练、10条测试）上，方法实现了对45个参数的并行调优，所得计划与专家手工方案相当甚至更优（相对计划分数：RL 85.93±7.85% vs Manual 85.02±6.92%，五个OARs的差异有统计学显著性（p<0.05））。该框架能高效探索高维TPP空间并通过直接与TPS交互生成临床竞争力的IMCT计划，显著改善OARs的保留。

Conclusion: 所提出的MARL框架在高维TPP空间中具备良好探索能力，能够高效生成临床竞争力的IMCT计划，尤其在提升OARs规避方面表现出显著优势；通过直接TPS交互实现了可扩展的并行优化。

Abstract: Head-and-neck cancer (HNC) planning is difficult because multiple critical
organs-at-risk (OARs) are close to complex targets. Intensity-modulated
carbon-ion therapy (IMCT) offers superior dose conformity and OAR sparing but
remains slow due to relative biological effectiveness (RBE) modeling, leading
to laborious, experience-based, and often suboptimal tuning of many
treatment-planning parameters (TPPs). Recent deep learning (DL) methods are
limited by data bias and plan feasibility, while reinforcement learning (RL)
struggles to efficiently explore the exponentially large TPP search space. We
propose a scalable multi-agent RL (MARL) framework for parallel tuning of 45
TPPs in IMCT. It uses a centralized-training decentralized-execution (CTDE)
QMIX backbone with Double DQN, Dueling DQN, and recurrent encoding (DRQN) for
stable learning in a high-dimensional, non-stationary environment. To enhance
efficiency, we (1) use compact historical DVH vectors as state inputs, (2)
apply a linear action-to-value transform mapping small discrete actions to
uniform parameter adjustments, and (3) design an absolute, clinically informed
piecewise reward aligned with plan scores. A synchronous multi-process worker
system interfaces with the PHOENIX TPS for parallel optimization and
accelerated data collection. On a head-and-neck dataset (10 training, 10
testing), the method tuned 45 parameters simultaneously and produced plans
comparable to or better than expert manual ones (relative plan score: RL
$85.93\pm7.85%$ vs Manual $85.02\pm6.92%$), with significant (p-value $<$ 0.05)
improvements for five OARs. The framework efficiently explores high-dimensional
TPP spaces and generates clinically competitive IMCT plans through direct TPS
interaction, notably improving OAR sparing.

</details>


### [77] [RoME: Domain-Robust Mixture-of-Experts for MILP Solution Prediction across Domains](https://arxiv.org/abs/2511.02331)
*Tianle Pu,Zijie Geng,Haoyang Liu,Shixuan Liu,Jie Wang,Li Zeng,Chao Chen,Changjun Fan*

Main category: cs.LG

TL;DR: RoME is a domain-robust mixture-of-experts framework for predicting MILP solutions across domains, using learned task embeddings and a two-level distributionally robust optimization (DRO) strategy to improve cross-domain generalization and intra-domain robustness. A single RoME model trained on three domains achieves about 67.7% average improvement on five diverse domains, with zero-shot gains on MIPLIB.


<details>
  <summary>Details</summary>
Motivation: Existing learning-based MILP solvers largely generalize within single domains, struggling to adapt to unseen problem distributions. This limits the scalability and practicality of learning-based solvers for diverse, real-world MILP instances.

Method: RoME employs a dynamic routing Mixture-of-Experts architecture where problem instances are assigned to domain-specific experts via learned task embeddings. Training uses a two-level DRO: inter-domain DRO to mitigate global shifts across domains and intra-domain DRO by perturbing task embeddings to improve local robustness. Cross-domain training encourages the model to capture more general combinatorial patterns.

Result: Cross-domain training improves generalization to unseen domains and improves performance within known domains. A RoME model trained on three domains yields an average improvement of 67.7% when evaluated on five diverse domains. In zero-shot tests on MIPLIB, RoME delivers measurable performance gains where many learning-based approaches fail to generalize.

Conclusion: A domain-robust, mixture-of-experts approach with distributionally robust training can significantly enhance the generalization and effectiveness of learning-based MILP solvers across varied problem distributions, including challenging real-world instances.

Abstract: Mixed-Integer Linear Programming (MILP) is a fundamental and powerful
framework for modeling complex optimization problems across diverse domains.
Recently, learning-based methods have shown great promise in accelerating MILP
solvers by predicting high-quality solutions. However, most existing approaches
are developed and evaluated in single-domain settings, limiting their ability
to generalize to unseen problem distributions. This limitation poses a major
obstacle to building scalable and general-purpose learning-based solvers. To
address this challenge, we introduce RoME, a domain-Robust Mixture-of-Experts
framework for predicting MILP solutions across domains. RoME dynamically routes
problem instances to specialized experts based on learned task embeddings. The
model is trained using a two-level distributionally robust optimization
strategy: inter-domain to mitigate global shifts across domains, and
intra-domain to enhance local robustness by introducing perturbations on task
embeddings. We reveal that cross-domain training not only enhances the model's
generalization capability to unseen domains but also improves performance
within each individual domain by encouraging the model to capture more general
intrinsic combinatorial patterns. Specifically, a single RoME model trained on
three domains achieves an average improvement of 67.7% then evaluated on five
diverse domains. We further test the pretrained model on MIPLIB in a zero-shot
setting, demonstrating its ability to deliver measurable performance gains on
challenging real-world instances where existing learning-based approaches often
struggle to generalize.

</details>


### [78] [Reducing normalizing flow complexity for MCMC preconditioning](https://arxiv.org/abs/2511.02345)
*David Nabergoj,Erik Štrumbelj*

Main category: cs.LG

TL;DR: 提出一种因式分解的预条件架构，将线性分量与条件化的正向流（NF）结合以自适应地匹配目标几何，从而降低NF复杂度并提升MCMC的采样效率，尤其在尾部样本、稀疏逻辑回归和层级贝叶斯模型中表现更优。


<details>
  <summary>Details</summary>
Motivation: 在MCMC中，预条件化是提高采样效率的关键，线性预条件对中等复杂度的目标足够，但非线性可训练的NF预条件在参数过多时会降低采样质量和拟合效果，且现有NF方法缺乏对目标分布的自适应架构设计。相关研究表明，合适的NF也能在更少数据和训练时间下达到良好性能。需要一种能够自适应并降低NF复杂度的架构来匹配目标几何。

Method: 提出一个因式分解的预条件架构，将线性预条件器应用于近似高斯维度（通过暖-start样本估计），再对更复杂的维度使用条件NF来建模。该组合降低NF的参数规模并提高对目标几何的适应性。

Result: 在两个复杂的合成分布上实现了显著更好的尾部样本；在稀疏逻辑回归后验上对不同似然/先验强度均表现出更稳定的性能；在具有弱似然和强漏斗几何的层级贝叶斯模型后验中获得更高的有效采样数（ESS）。

Conclusion: 这种因式分解的预条件策略对面向层级贝叶斯分析、样本量有限的数据场景尤为有价值，并可为神经MCMC设计的理论与软件实现提供方向。

Abstract: Preconditioning is a key component of MCMC algorithms that improves sampling
efficiency by facilitating exploration of geometrically complex target
distributions through an invertible map. While linear preconditioners are often
sufficient for moderately complex target distributions, recent work has
explored nonlinear preconditioning with invertible neural networks as
components of normalizing flows (NFs). However, empirical and theoretical
studies show that overparameterized NF preconditioners can degrade sampling
efficiency and fit quality. Moreover, existing NF-based approaches do not adapt
their architectures to the target distribution. Related work outside of MCMC
similarly finds that suitably parameterized NFs can achieve comparable or
superior performance with substantially less training time or data. We propose
a factorized preconditioning architecture that reduces NF complexity by
combining a linear component with a conditional NF, improving adaptability to
target geometry. The linear preconditioner is applied to dimensions that are
approximately Gaussian, as estimated from warmup samples, while the conditional
NF models more complex dimensions. Our method yields significantly better tail
samples on two complex synthetic distributions and consistently better
performance on a sparse logistic regression posterior across varying likelihood
and prior strengths. It also achieves higher effective sample sizes on
hierarchical Bayesian model posteriors with weak likelihoods and strong funnel
geometries. This approach is particularly relevant for hierarchical Bayesian
model analyses with limited data and could inform current theoretical and
software strides in neural MCMC design.

</details>


### [79] [Human-Machine Ritual: Synergic Performance through Real-Time Motion Recognition](https://arxiv.org/abs/2511.02351)
*Zhuodi Cai,Ziyu Xu,Juan Pampin*

Main category: cs.LG

TL;DR: 基于IMU传感与MiniRocket的轻量级实时舞蹈动作识别系统，实现对声音的响应式多媒体控制与人机协同。


<details>
  <summary>Details</summary>
Motivation: 在保留舞者表达深度的前提下，利用机器学习实现对舞者动作的及时、敏感观察，从而推动创作、教育与现场表演中的人机协同。

Method: 组合可穿戴IMU数据、MiniRocket时序分类算法，以及将动作映射到声音的 somatic memory 机制，构建低延迟（<50 ms）的实时识别与多媒体控制管线。

Result: 实现高准确率的分类，且延迟低于50 ms，提供一个可重复的框架，便于将“舞蹈素养的机器”引入创作、教育与现场表演等场景。

Conclusion: 以以人为本的设计为核心的方案证明了在实时、轻量级时序分类框架中，人机协同可以保持舞蹈表达的深度，同时实现机器对观测与响应的有效性。

Abstract: We introduce a lightweight, real-time motion recognition system that enables
synergic human-machine performance through wearable IMU sensor data, MiniRocket
time-series classification, and responsive multimedia control. By mapping
dancer-specific movement to sound through somatic memory and association, we
propose an alternative approach to human-machine collaboration, one that
preserves the expressive depth of the performing body while leveraging machine
learning for attentive observation and responsiveness. We demonstrate that this
human-centered design reliably supports high accuracy classification (<50 ms
latency), offering a replicable framework to integrate dance-literate machines
into creative, educational, and live performance contexts.

</details>


### [80] [Evolving Graph Learning for Out-of-Distribution Generalization in Non-stationary Environments](https://arxiv.org/abs/2511.02354)
*Qingyun Sun,Jiayi Luo,Haonan Yuan,Xingcheng Fu,Hao Peng,Jianxin Li,Philip S. Yu*

Main category: cs.LG

TL;DR: 提出了面向动态图的OOD generalization的新框架 EvoOOD，通过环境演化建模实现环境感知的不变模式识别，并对单个节点进行因果干预以区分时空不变模式，从而提升在分布转移下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 动态图中存在非平稳且随环境演化的分布转移，现有GNN对这种OOD泛化能力不足；需要从环境演化角度系统地研究动态图的OOD问题。

Method: 提出环境序列变分自编码器以建模环境演化并推断潜在环境分布；设计环境感知的不变模式识别机制以应对环境多样化；对单个节点进行基于实例化环境样本的混合干预，进行细粒度的因果分析以提取时空不变模式。

Result: 在真实世界和合成数据集上相较基线在存在分布转移的情形下表现优越，首次从环境演化视角系统研究动态图的OOD泛化问题。

Conclusion: EvoOOD能够有效捕捉环境演化过程及不变模式，提升动态图上的OOD泛化能力，为未来在非平稳环境下的动态图学习提供新思路。

Abstract: Graph neural networks have shown remarkable success in exploiting the spatial
and temporal patterns on dynamic graphs. However, existing GNNs exhibit poor
generalization ability under distribution shifts, which is inevitable in
dynamic scenarios. As dynamic graph generation progresses amid evolving latent
non-stationary environments, it is imperative to explore their effects on
out-of-distribution (OOD) generalization. This paper proposes a novel Evolving
Graph Learning framework for OOD generalization (EvoOOD) by environment-aware
invariant pattern recognition. Specifically, we first design an environment
sequential variational auto-encoder to model environment evolution and infer
the underlying environment distribution. Then, we introduce a mechanism for
environment-aware invariant pattern recognition, tailored to address
environmental diversification through inferred distributions. Finally, we
conduct fine-grained causal interventions on individual nodes using a mixture
of instantiated environment samples. This approach helps to distinguish
spatio-temporal invariant patterns for OOD prediction, especially in
non-stationary environments. Experimental results demonstrate the superiority
of EvoGOOD on both real-world and synthetic dynamic datasets under distribution
shifts. To the best of our knowledge, it is the first attempt to study the
dynamic graph OOD generalization problem from the environment evolution
perspective.

</details>


### [81] [LUMA-RAG: Lifelong Multimodal Agents with Provably Stable Streaming Alignment](https://arxiv.org/abs/2511.02371)
*Rohan Wandre,Yash Gajewar,Namrata Patel,Vivek Dhalkari*

Main category: cs.LG

TL;DR: 提出了一个面向终身学习的多模态RAG框架LUMA-RAG，通过热-IVFPQ两层内存、CLAP→CLIP增量对齐以及稳定性检索遥测，实现高效、可控的跨模态检索与更新。


<details>
  <summary>Details</summary>
Motivation: 解决持续流式、跨模态数据环境下的索引时效性与跨模态嵌入不一致性问题，提升RAG在文本、图像、视频和音频等模态中的可持续检索能力。

Method: （i）流式多Tier内存：将热HNSW嵌入溢出至压缩IVFPQ以在内存预算内维持更新；（ii）流式CLAP→CLIP对齐桥：通过增量正交Procrustes更新保持跨模态一致性；（iii）稳定性检索遥测：联合约束对齐漂移与量化误差，提供Safe@k保证。

Result: 在文本到图像检索中Recall@10=0.94；在量化下的产品化卸载中表现稳健，且音频到图像排序给出可证明的稳定性（Safe@1=1.0），显示对生产化多模态RAG系统的实用性。

Conclusion: LUMA-RAG提供了一个可落地的多模态RAG框架，结合跨模态对齐的创新和检索稳定性的可观测性，适合持续更新的多模态数据场景。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as the dominant paradigm for
grounding large language model outputs in verifiable evidence. However, as
modern AI agents transition from static knowledge bases to continuous
multimodal streams encompassing text, images, video, and audio, two critical
challenges arise: maintaining index freshness without prohibitive re-indexing
costs, and preserving cross-modal semantic consistency across heterogeneous
embedding spaces. We present LUMA-RAG, a lifelong multimodal agent architecture
featuring three key innovations: (i) a streaming, multi-tier memory system that
dynamically spills embeddings from a hot HNSW tier to a compressed IVFPQ tier
under strict memory budgets; (ii) a streaming CLAP->CLIP alignment bridge that
maintains cross-modal consistency through incremental orthogonal Procrustes
updates; and (iii) stability-aware retrieval telemetry providing Safe@k
guarantees by jointly bounding alignment drift and quantization error.
Experiments demonstrate robust text-to-image retrieval (Recall@10 = 0.94),
graceful performance degradation under product quantization offloading, and
provably stable audio-to-image rankings (Safe@1 = 1.0), establishing LUMA-RAG
as a practical framework for production multimodal RAG systems.

</details>


### [82] [A Spatially Informed Gaussian Process UCB Method for Decentralized Coverage Control](https://arxiv.org/abs/2511.02398)
*Gennaro Guidone,Luca Monegaglia,Elia Raimondi,Han Wang,Mattia Bianchi,Florian Dörfler*

Main category: cs.LG

TL;DR: Decentralized GP-UCB-inspired coverage control with greedy inducing point updates; demonstrates effectiveness in simulation.


<details>
  <summary>Details</summary>
Motivation: Need scalable, decentralized coverage in unknown environments; balance exploration and exploitation using GP uncertainty.

Method: Agents minimize local cost combining predicted density and GP uncertainty; use GP with inducing points updated greedily; fully decentralized with neighbor communication; online updates; trajectory planning.

Result: Simulation demonstrates effectiveness and scalability; decentralized performance shown; exploration of high-uncertainty regions.

Conclusion: Shows feasibility of decentralized coverage using GP-UCB-like criterion and greedy inducing point updates; applicable to multi-robot systems; future work includes real-world experiments and investigating communication/computation trade-offs.

Abstract: We present a novel decentralized algorithm for coverage control in unknown
spatial environments modeled by Gaussian Processes (GPs). To trade-off between
exploration and exploitation, each agent autonomously determines its trajectory
by minimizing a local cost function. Inspired by the GP-UCB (Upper Confidence
Bound for GPs) acquisition function, the proposed cost combines the expected
locational cost with a variance-based exploration term, guiding agents toward
regions that are both high in predicted density and model uncertainty. Compared
to previous work, our algorithm operates in a fully decentralized fashion,
relying only on local observations and communication with neighboring agents.
In particular, agents periodically update their inducing points using a greedy
selection strategy, enabling scalable online GP updates. We demonstrate the
effectiveness of our algorithm in simulation.

</details>


### [83] [Improving Unlearning with Model Updates Probably Aligned with Gradients](https://arxiv.org/abs/2511.02435)
*Virgile Dine,Teddy Furon,Charly Faure*

Main category: cs.LG

TL;DR: 提出一种可行更新的机器学习“删记”（unlearning）方法：通过掩蔽实现的可行更新，作为对第一阶近似未删除方法的可插拔改进，给出统计保证并在计算机视觉分类任务上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在数据删除或撤回训练数据的场景下，需要确保模型忘记被移除的数据且尽量保持原有性能。现有基于第一阶近似的未删除方法效率高但可能导致更新不稳定或缺乏可控性。本研究通过对参数更新方向进行筛选（掩蔽）并考虑梯度估计噪声，给出局部可行更新的统计保证。

Method: 把未删除问题建模为带约束的优化问题；提出“可行更新”概念，即通过掩蔽选择仅更新对未删数据有帮助且不显著削弱初始模型性能的参数。结合对每个数据批次的梯度噪声估计，给出局部可行更新的统计保障。该方法可作为任意第一阶近似未删除方法的插件。

Result: 在计算机视觉分类任务上进行了实验，验证了可行更新的有效性以及与现有未删除方法的兼容性。

Conclusion: 可行更新提供了一种通用、带统计保障的增量改进，提升了第一阶近似未删除方法的可控性与稳定性，具有广泛的适用性。

Abstract: We formulate the machine unlearning problem as a general constrained
optimization problem. It unifies the first-order methods from the approximate
machine unlearning literature. This paper then introduces the concept of
feasible updates as the model's parameter update directions that help with
unlearning while not degrading the utility of the initial model. Our design of
feasible updates is based on masking, \ie\ a careful selection of the model's
parameters worth updating. It also takes into account the estimation noise of
the gradients when processing each batch of data to offer a statistical
guarantee to derive locally feasible updates. The technique can be plugged in,
as an add-on, to any first-order approximate unlearning methods. Experiments
with computer vision classifiers validate this approach.

</details>


### [84] [Accounting for Underspecification in Statistical Claims of Model Superiority](https://arxiv.org/abs/2511.02453)
*Thomas Sanchez,Pedro M. Gordaliza,Meritxell Bach Cuadra*

Main category: cs.LG

TL;DR: 在医学影像的机器学习中，需考虑训练的不确定性和未充分指定性，简单的性能提升可能是虚假的；研究扩展了统计框架，将 underspecification 作为方差分量纳入，表明种子波动等对证据强度有显著影响。


<details>
  <summary>Details</summary>
Motivation: 当前关于小幅改进的统计显著性往往被高估，未充分考虑模型的训练过程差异（如随机初始化、训练过程）导致的未指定性。需要一个能把训练方差纳入统计评估的框架，以避免对超越性的错误声称。

Method: 扩展现有统计框架，将 underspecification 作为额外方差分量；通过仿真演示，即使种子差异很小（约1%）也显著增加支持 superiority 的证据门槛；评估对医疗影像系统的验证的影响。

Result: 仿真表明 modest seed variability 只要波动存在，就会显著提高需要的证据强度；在考虑训练方差后，先前的“显著改进”更容易被推翻，强调需要显式建模训练方差。

Conclusion: 在评估医疗影像系统时，应将训练过程的不确定性纳入统计评估，改进验证方案，以避免过度乐观的性能提升结论。

Abstract: Machine learning methods are increasingly applied in medical imaging, yet
many reported improvements lack statistical robustness: recent works have
highlighted that small but significant performance gains are highly likely to
be false positives. However, these analyses do not take
\emph{underspecification} into account -- the fact that models achieving
similar validation scores may behave differently on unseen data due to random
initialization or training dynamics. Here, we extend a recent statistical
framework modeling false outperformance claims to include underspecification as
an additional variance component. Our simulations demonstrate that even modest
seed variability ($\sim1\%$) substantially increases the evidence required to
support superiority claims. Our findings underscore the need for explicit
modeling of training variance when validating medical imaging systems.

</details>


### [85] [SKGE: Spherical Knowledge Graph Embedding with Geometric Regularization](https://arxiv.org/abs/2511.02460)
*Xuan-Truong Quan,Xuan-Son Quan,Duc Do Minh,Vinh Nguyen Van*

Main category: cs.LG

TL;DR: 将知识图谱嵌入限定在单位球面上的SKGE，通过可学习的非线性Spherization映射实体、关系采用翻译-投影混合变换，在FB15k-237、CoDEx-S/CoDEx-M上显著优于TransE，显示几何先验作为正则化与更硬负采样的作用。


<details>
  <summary>Details</summary>
Motivation: 克服Euclidean空间对复杂关系建模的局限性和训练效率问题；需要将几何先验引入KGE以提升表达能力与稳定性。

Method: 引入可学习的Spherization层将实体映射到单位球面，关系为翻译-投影的混合变换；在FB15k-237、CoDEx-S、CoDEx-M等数据集上进行大量实验并对比TransE；分析其正则化作用和天然的困难负采样效应。

Result: 在所有基准上SKGE均显著优于TransE，尤其在大规模数据集FB15k-237和CoDEx-M；几何约束作为强正则化器，提升各关系类型的表现；证据表明球面几何带来更具鲁棒性与语义一致性的表示；自然的困难负采样环境提升模型学习。

Conclusion:  manifold选择是设计知识图谱嵌入模型的根本原则，几何先验（球面约束）是实现更强大、稳定KGE模型的关键；推动下一代KGE模型的研究。

Abstract: Knowledge graph embedding (KGE) has become a fundamental technique for
representation learning on multi-relational data. Many seminal models, such as
TransE, operate in an unbounded Euclidean space, which presents inherent
limitations in modeling complex relations and can lead to inefficient training.
In this paper, we propose Spherical Knowledge Graph Embedding (SKGE), a model
that challenges this paradigm by constraining entity representations to a
compact manifold: a hypersphere. SKGE employs a learnable, non-linear
Spherization Layer to map entities onto the sphere and interprets relations as
a hybrid translate-then-project transformation. Through extensive experiments
on three benchmark datasets, FB15k-237, CoDEx-S, and CoDEx-M, we demonstrate
that SKGE consistently and significantly outperforms its strong Euclidean
counterpart, TransE, particularly on large-scale benchmarks such as FB15k-237
and CoDEx-M, demonstrating the efficacy of the spherical geometric prior. We
provide an in-depth analysis to reveal the sources of this advantage, showing
that this geometric constraint acts as a powerful regularizer, leading to
comprehensive performance gains across all relation types. More fundamentally,
we prove that the spherical geometry creates an "inherently hard negative
sampling" environment, naturally eliminating trivial negatives and forcing the
model to learn more robust and semantically coherent representations. Our
findings compellingly demonstrate that the choice of manifold is not merely an
implementation detail but a fundamental design principle, advocating for
geometric priors as a cornerstone for designing the next generation of powerful
and stable KGE models.

</details>


### [86] [BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and Monitoring](https://arxiv.org/abs/2511.02490)
*Rajan Das Gupta,Md Kishor Morol,Nafiz Fahad,Md Tanzib Hosain,Sumaya Binte Zilani Choya,Md Jakir Hossen*

Main category: cs.LG

TL;DR: A dual-module BRAINS framework leverages LLMs for cognitive/neuroimaging assessment and case retrieval to enable scalable, explainable early Alzheimer's detection.


<details>
  <summary>Details</summary>
Motivation: Global Alzheimer's disease burden is rising while access to advanced diagnostics remains uneven, making scalable, interpretable early detection essential, especially in resource-limited regions.

Method: Diagnostic Module: LLM fine-tuned on cognitive and neuroimaging data (e.g., MMSE, CDR scores, brain volume metrics) for structured Alzheimer's risk assessments. Case Retrieval Module: encodes patient profiles into latent representations and retrieves similar cases from a curated knowledge base; Case Fusion Layer merges retrieved cases with the input profile; inference guided by clinical prompts.

Result: Evaluations on real-world datasets show BRAINS effectively classifies disease severity and identifies early signs of cognitive decline, indicating potential as an assistive, scalable, and explainable detection tool.

Conclusion: BRAINS demonstrates promise as a scalable, explainable framework for early-stage Alzheimer's detection and monitoring, with potential for broader clinical and research applications.

Abstract: As the global burden of Alzheimer's disease (AD) continues to grow, early and
accurate detection has become increasingly critical, especially in regions with
limited access to advanced diagnostic tools. We propose BRAINS (Biomedical
Retrieval-Augmented Intelligence for Neurodegeneration Screening) to address
this challenge. This novel system harnesses the powerful reasoning capabilities
of Large Language Models (LLMs) for Alzheimer's detection and monitoring.
BRAINS features a dual-module architecture: a cognitive diagnostic module and a
case-retrieval module. The Diagnostic Module utilizes LLMs fine-tuned on
cognitive and neuroimaging datasets -- including MMSE, CDR scores, and brain
volume metrics -- to perform structured assessments of Alzheimer's risk.
Meanwhile, the Case Retrieval Module encodes patient profiles into latent
representations and retrieves similar cases from a curated knowledge base.
These auxiliary cases are fused with the input profile via a Case Fusion Layer
to enhance contextual understanding. The combined representation is then
processed with clinical prompts for inference. Evaluations on real-world
datasets demonstrate BRAINS effectiveness in classifying disease severity and
identifying early signs of cognitive decline. This system not only shows strong
potential as an assistive tool for scalable, explainable, and early-stage
Alzheimer's disease detection, but also offers hope for future applications in
the field.

</details>


### [87] [An End-to-End Learning Approach for Solving Capacitated Location-Routing Problems](https://arxiv.org/abs/2511.02525)
*Changhao Miao,Yuntian Zhang,Tongyu Wu,Fang Deng,Chen Chen*

Main category: cs.LG

TL;DR: 提出了 DRLHQ，一种端到端的深度强化学习框架，用于 CLRP 与 OCLRP，通过编码器-解码器和异质查询注意力实现位置与路由决策的耦合，显示出优于传统与其他 DRL 基线的解法和更好的泛化。


<details>
  <summary>Details</summary>
Motivation: CLRP 的复杂约束和决策耦合使传统优化方法求解困难；尽管 DRL 已在单一车辆路径问题取得进展，针对 CLRPs 的端到端学习研究尚 scarce；需要一个可同时处理选址与路由决策的通用框架。

Method: 将 CLRPs 重构为针对不同决策的马尔可夫决策过程，提出端到端的编码器-解码器结构；引入异质查询注意力机制以动态适应不同决策阶段的耦合与相互依赖，并提出一个通用的 DRL 建模框架以便迁移至其他 DRL 方法。

Result: 在合成与基准数据集上，DRLHQ 在 CLRP 与 OCLRP 上的解质量优于代表性传统算法与现有 DRL 基线，且具备更好的泛化能力。

Conclusion: 该工作首次提出 CLRPs 的端到端学习方法，提供可扩展的通用建模框架和适用于多类型决策的异质查询注意力，推动 DRL 在 CLRPs 的应用与拓展。

Abstract: The capacitated location-routing problems (CLRPs) are classical problems in
combinatorial optimization, which require simultaneously making location and
routing decisions. In CLRPs, the complex constraints and the intricate
relationships between various decisions make the problem challenging to solve.
With the emergence of deep reinforcement learning (DRL), it has been
extensively applied to address the vehicle routing problem and its variants,
while the research related to CLRPs still needs to be explored. In this paper,
we propose the DRL with heterogeneous query (DRLHQ) to solve CLRP and open CLRP
(OCLRP), respectively. We are the first to propose an end-to-end learning
approach for CLRPs, following the encoder-decoder structure. In particular, we
reformulate the CLRPs as a markov decision process tailored to various
decisions, a general modeling framework that can be adapted to other DRL-based
methods. To better handle the interdependency across location and routing
decisions, we also introduce a novel heterogeneous querying attention mechanism
designed to adapt dynamically to various decision-making stages. Experimental
results on both synthetic and benchmark datasets demonstrate superior solution
quality and better generalization performance of our proposed approach over
representative traditional and DRL-based baselines in solving both CLRP and
OCLRP.

</details>


### [88] [Rawlsian many-to-one matching with non-linear utility](https://arxiv.org/abs/2511.02533)
*Hortence Nana,Andreas Athanasopoulos,Christos Dimitrakakis*

Main category: cs.LG

TL;DR: 在多对一匹配中，门槛的非线性效用破坏稳定性；提出基于Rawls公平的极小化最大化原则的替代解概念，并设计确定性与随机性算法以改进最弱学院的福利。


<details>
  <summary>Details</summary>
Motivation: 解决非线性效用和多对一匹配中的稳态存在性问题，引入公平性优先的目标以确保资源在学院间的公平分配，提供可行的算法框架。

Method: 提出一种以最大化最小学院效用为目标的Rawlsian公平框架，设计两类迭代算法：确定性算法逐步提升最弱学院的收益，随机性算法通过随机化改进路径以提升最差结果。

Result: 证明传统稳定匹配在该设定下可能不存在；提出以Rawls公平为核心的替代解概念，并给出能在实践中提升最弱学院福利的迭代算法。

Conclusion: 在存在性受限的多对一匹配问题中，Rawlsian公平提供一个可行且实用的替代方向，所提的确定性与随机性算法为在不可保证稳定性的前提下实现公平分配提供了落地策略。

Abstract: We study a many-to-one matching problem, such as the college admission
problem, where each college can admit multiple students. Unlike classical
models, colleges evaluate sets of students through non-linear utility functions
that capture diversity between them. In this setting, we show that classical
stable matchings may fail to exist. To address this, we propose alternative
solution concepts based on Rawlsian fairness, aiming to maximize the minimum
utility across colleges. We design both deterministic and stochastic algorithms
that iteratively improve the outcome of the worst-off college, offering a
practical approach to fair allocation when stability cannot be guaranteed.

</details>


### [89] [Adaptive Neighborhood-Constrained Q Learning for Offline Reinforcement Learning](https://arxiv.org/abs/2511.02567)
*Yixiu Mao,Yun Qu,Qi Wang,Xiangyang Ji*

Main category: cs.LG

TL;DR: 提出自适应邻域约束的离线强化学习框架ANQ，通过将目标行动约束在数据集行动的邻域并取并集，克服了密度、样本和支持约束的局限性，理论上在一定条件下界定外推误差和分布漂移，并在不建模行为策略的前提下近似支持约束；通过对每个数据点自适应的邻域半径实现点-wise保守性，且以数据质量作为自适应依据，构建了高效的双层优化框架并实现了简单有效的ANQ算法，取得标准离线RL基准的最优或接近最优性能，同时对噪声或数据有限的场景具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 离线RL中外推误差来自分布外行动的存在。现有约束分类为密度、支持和样本约束，但各自存在固有局限：密度和样本约束在很多情形过于保守；支持约束尽管更少受限，但对行为策略建模依赖较强且实现困难。需要一种更灵活且不强依赖行为策略建模的约束来兼顾保守性与可行性。

Method: 提出一种新的邻域约束：将Bellman目标中的行动限制在数据集行动的邻域并集之内。该约束理论上界定外推误差与分布漂移（在一定条件下），并在不需要显式建模行为策略的情况下近似实现支持约束。通过对每个数据点自适应地调整邻域半径实现点对点的保守性，利用数据质量作为自适应准则。基于高效的双层优化框架，设计并实现了ANQ（Adaptive Neighborhood-constrained Q learning）算法，在目标动作满足该约束的条件下进行Q-learning。

Result: 理论上，该邻域约束可以在某些条件下同时限制外推误差和分布漂移，并且在不依赖行为策略建模的情况下近似支持约束。实践中，ANQ在标准离线RL基准上达到状态-of-the-art的性能，并且在存在噪声或数据有限的场景中表现出较强的鲁棒性。

Conclusion: 该研究表明，邻域约束提供了比传统密度、支持、样本约束更灵活且高效的解决方案，结合自适应半径和双层优化的ANQ框架，能够在离线RL中实现高性能与鲁棒性。

Abstract: Offline reinforcement learning (RL) suffers from extrapolation errors induced
by out-of-distribution (OOD) actions. To address this, offline RL algorithms
typically impose constraints on action selection, which can be systematically
categorized into density, support, and sample constraints. However, we show
that each category has inherent limitations: density and sample constraints
tend to be overly conservative in many scenarios, while the support constraint,
though least restrictive, faces challenges in accurately modeling the behavior
policy. To overcome these limitations, we propose a new neighborhood constraint
that restricts action selection in the Bellman target to the union of
neighborhoods of dataset actions. Theoretically, the constraint not only bounds
extrapolation errors and distribution shift under certain conditions, but also
approximates the support constraint without requiring behavior policy modeling.
Moreover, it retains substantial flexibility and enables pointwise conservatism
by adapting the neighborhood radius for each data point. In practice, we employ
data quality as the adaptation criterion and design an adaptive neighborhood
constraint. Building on an efficient bilevel optimization framework, we develop
a simple yet effective algorithm, Adaptive Neighborhood-constrained Q learning
(ANQ), to perform Q learning with target actions satisfying this constraint.
Empirically, ANQ achieves state-of-the-art performance on standard offline RL
benchmarks and exhibits strong robustness in scenarios with noisy or limited
data.

</details>


### [90] [Dynamic Priors in Bayesian Optimization for Hyperparameter Optimization](https://arxiv.org/abs/2511.02570)
*Lukas Fehring,Marcel Wever,Maximilian Spliethöver,Leona Hennig,Henning Wachsmuth,Marius Lindauer*

Main category: cs.LG

TL;DR: 提出一种在HPO中基于BO的在线干预方法，使用户在运行时提供先验分布，扩展 piBO，并引入误导先验检测，能够处理多个先验并抵御有害输入，表现出接近无扰动BO的竞争力。


<details>
  <summary>Details</summary>
Motivation: HPO通常基于黑盒BO，但缺乏用户可控性，导致在实践中的接受度低。需要一种在运行时引入专家知识与偏好、提升可控性和鲁棒性的方案。

Method: 在现有 piBO 的基础上，允许多次干预通过用户输入在HPO过程运行时加入先验分布；引入误导先验检测机制以保护系统免受有害输入; 支持结合多种先验；保持理论保证。

Result: 实验表明方法能够有效整合多种先验，利用信息丰富的先验；误导先验被可靠拒绝或克服；在性能上可与未受扰动的BO相竞争。

Conclusion: 该方法实现了BO在HPO中的灵活、鲁棒的运行时引导，提升了专家知识的利用和对有害输入的抵抗，增强了HPO的可控性和应用前景。

Abstract: Hyperparameter optimization (HPO), for example, based on Bayesian
optimization (BO), supports users in designing models well-suited for a given
dataset. HPO has proven its effectiveness on several applications, ranging from
classical machine learning for tabular data to deep neural networks for
computer vision and transformers for natural language processing. However, HPO
still sometimes lacks acceptance by machine learning experts due to its
black-box nature and limited user control. Addressing this, first approaches
have been proposed to initialize BO methods with expert knowledge. However,
these approaches do not allow for online steering during the optimization
process. In this paper, we introduce a novel method that enables repeated
interventions to steer BO via user input, specifying expert knowledge and user
preferences at runtime of the HPO process in the form of prior distributions.
To this end, we generalize an existing method, $\pi$BO, preserving theoretical
guarantees. We also introduce a misleading prior detection scheme, which allows
protection against harmful user inputs. In our experimental evaluation, we
demonstrate that our method can effectively incorporate multiple priors,
leveraging informative priors, whereas misleading priors are reliably rejected
or overcome. Thereby, we achieve competitiveness to unperturbed BO.

</details>


### [91] [Directional-Clamp PPO](https://arxiv.org/abs/2511.02577)
*Gilad Karpel,Ruida Zhou,Shoham Sabach,Mohammad Ghavamzadeh*

Main category: cs.LG

TL;DR: DClamp-PPO在PPO基础上引入方向性夹点惩罚，通过对进入“错误方向”更新的区域施加更陡的损失斜率来抑制不良更新，使用可调参数β，在MuJoCo环境和多随机种子下证明了性能与稳定性的提升。


<details>
  <summary>Details</summary>
Motivation: 尽管PPO通过裁剪的策略在“正确方向”上取得鲁棒性，但滚动数据的随机性与策略优化的随机性导致更新常进入“错误方向”。需要通过对更新方向的约束来进一步提升性能与稳定性。

Method: 提出 Directional-Clamp PPO（DClamp-PPO），在“错误方向”区域对损失函数施加更强的夹点惩罚：当优势为正且重要性比率小于1-β，或当优势为负且比率大于1+β时，应用更陡的损失斜率（夹点），β∈(0,1)作为可调参数，从而让目标函数在这些区域更加保守。

Result: 实验结果显示，DClamp-PPO在多组 MuJoCo 环境中相较PPO及其变体具有更好的一致性和性能，且更有效地避免了“错误方向”的更新，同时使重要性比率更接近1。

Conclusion: 通过在“错误方向”区域加强惩罚，DClamp-PPO提升了PPO的鲁棒性与性能，表明对策略更新方向的约束是提升策略梯度方法性能的有效方向，未来可将该思路推广到其他策略优化算法。

Abstract: Proximal Policy Optimization (PPO) is widely regarded as one of the most
successful deep reinforcement learning algorithms, known for its robustness and
effectiveness across a range of problems.
  The PPO objective encourages the importance ratio between the current and
behavior policies to move to the "right" direction -- starting from importance
sampling ratios equal to 1, increasing the ratios for actions with positive
advantages and decreasing those with negative advantages. A clipping function
is introduced to prevent over-optimization when updating the importance ratio
in these "right" direction regions. Many PPO variants have been proposed to
extend its success, most of which modify the objective's behavior by altering
the clipping in the "right" direction regions. However, due to randomness in
the rollouts and stochasticity of the policy optimization, we observe that the
ratios frequently move to the "wrong" direction during the PPO optimization.
This is a key factor hindering the improvement of PPO, but it has been largely
overlooked. To address this, we propose the Directional-Clamp PPO algorithm
(DClamp-PPO), which further penalizes the actions going to the strict "wrong"
direction regions, where the advantage is positive (negative) and importance
ratio falls below (above) $1 - \beta$ ($1+\beta$),
  for a tunable parameter $\beta \in (0, 1)$. The penalty is by enforcing a
steeper loss slope, i.e., a clamp, in those regions. We demonstrate that
DClamp-PPO consistently outperforms PPO, as well as its variants, by focusing
on modifying the objective's behavior in the "right" direction, across various
MuJoCo environments, using different random seeds. The proposed method is
shown, both theoretically and empirically, to better avoid "wrong" direction
updates while keeping the importance ratio closer to 1.

</details>


### [92] [A Large Language Model for Corporate Credit Scoring](https://arxiv.org/abs/2511.02593)
*Chitro Majumdar,Sergio Scandizzo,Ratanlal Mahanta,Avradip Mandal,Swarnendu Bhattacharjee*

Main category: cs.LG

TL;DR: 提出 Omega^2：一个基于大型语言模型的公司信用评分框架，将结构化金融数据与高级机器学习相结合，通过贝叶斯搜索在时间验证下优化模型，在跨机构数据集上实现高AUC表现，提升预测可靠性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决多机构信用评级中的可比性、可解释性和前瞻性问题；将语言推理与定量学习结合，提供透明、可复现的机构级信用风险评估基础。

Method: Omega^2 框架整合 CatBoost、LightGBM、XGBoost 等模型，结合大语言模型进行推理，将以杠杆、盈利能力、流动性等详细企业财务指标为输入；通过贝叶斯搜索优化超参数，并使用时间分割的前瞻性验证；在 Moody's、S&P、Fitch、Egan-Jones 的共7,800 家企业评级数据集上评估。

Result: 在跨机构评估中，平均测试 AUC 超过 0.93，具备跨评级体系的泛化能力与时间稳定性。

Conclusion: 语言模型推理与量化学习的结合可以提供透明、符合机构级要求的企业信用风险评估基础。

Abstract: We introduce Omega^2, a Large Language Model-driven framework for corporate
credit scoring that combines structured financial data with advanced machine
learning to improve predictive reliability and interpretability. Our study
evaluates Omega^2 on a multi-agency dataset of 7,800 corporate credit ratings
drawn from Moody's, Standard & Poor's, Fitch, and Egan-Jones, each containing
detailed firm-level financial indicators such as leverage, profitability, and
liquidity ratios. The system integrates CatBoost, LightGBM, and XGBoost models
optimized through Bayesian search under temporal validation to ensure
forward-looking and reproducible results. Omega^2 achieved a mean test AUC
above 0.93 across agencies, confirming its ability to generalize across rating
systems and maintain temporal consistency. These results show that combining
language-based reasoning with quantitative learning creates a transparent and
institution-grade foundation for reliable corporate credit-risk assessment.

</details>


### [93] [Recursively Enumerably Representable Classes and Computable Versions of the Fundamental Theorem of Statistical Learning](https://arxiv.org/abs/2511.02644)
*David Kattermann,Lothar Sebastian Krapp*

Main category: cs.LG

TL;DR: 本文系统研究可计算PAC（CPAC）学习，引入有效VC维度，探究与递归可枚举可表述（RER）类的关系，揭示RER类的有效VC维度可取比传统VC维度更高的任意值，并给出在强CPAC条件下维度一致性等结果，进而给出基于同一样本实现的RER类包含关系来刻画CPAC可学性，以及唯一识别性对RER的必要性，最后通过非一致CPAC的放宽考察得到对无偏见学习的保障。


<details>
  <summary>Details</summary>
Motivation: 动机在于将CPAC学习与RER类联系起来，理解有效VC维度在可计算设定下的行为，并扩展经典学习理论在可计算领域的适用性。

Method: 方法上通过引入有效VC维度，分析并比较不同CPAC学习定义、对RER类进行分类、构造包含关系与识别属性的定理，并探讨非一致CPAC对无偏见学习的影响。

Result: 结果包括：有效VC维度可以取传统VC维之上任意值，甚至在RER类中也成立；在满足强CPAC学习性质的情形下，两维度会一致；CPAC可学性可以通过实现同一样本的RER类包含来刻画；具有唯一识别性属性的CPAC可学类必然是RER；对于RER类，通过非一致CPAC的放宽可确保无偏见学习。

Conclusion: 结论指出可计算学习领域具有丰富结构，提供了有效VC维度与RER类之间的多层关系，指导未来在可计算框架内的学习理论研究，尤其是关于无偏见学习的鲁棒性与分类。

Abstract: We study computable probably approximately correct (CPAC) learning, where
learners are required to be computable functions. It had been previously
observed that the Fundamental Theorem of Statistical Learning, which
characterizes PAC learnability by finiteness of the Vapnik-Chervonenkis
(VC-)dimension, no longer holds in this framework. Recent works recovered
analogs of the Fundamental Theorem in the computable setting, for instance by
introducing an effective VC-dimension. Guided by this, we investigate the
connection between CPAC learning and recursively enumerable representable (RER)
classes, whose members can be algorithmically listed. Our results show that the
effective VC-dimensions can take arbitrary values above the traditional one,
even for RER classes, which creates a whole family of (non-)examples for
various notions of CPAC learning. Yet the two dimensions coincide for classes
satisfying sufficiently strong notions of CPAC learning. We then observe that
CPAC learnability can also be characterized via containment of RER classes that
realize the same samples. Furthermore, it is shown that CPAC learnable classes
satisfying a unique identification property are necessarily RER. Finally, we
establish that agnostic learnability can be guaranteed for RER classes, by
considering the relaxed notion of nonuniform CPAC learning.

</details>


### [94] [Nesterov-Accelerated Robust Federated Learning Over Byzantine Adversaries](https://arxiv.org/abs/2511.02657)
*Lihan Xu,Yanjie Dong,Gang Wang,Runhao Zeng,Xiaoyi Fan,Xiping Hu*

Main category: cs.LG

TL;DR: 提出了一种 Byzantine-resilient Nesterov-Accelerated Federated Learning (Byrd-NAFL) 算法，结合 Nesterov 动量与容错聚合规则，在非凸光滑损失下给出有限时间收敛性保证，并在实验中展示对多种 Byzantine 攻击的鲁棒性和优越的收敛/精度表现。


<details>
  <summary>Details</summary>
Motivation: 在存在拜占庭对手的分布式学习场景中，需要在保证鲁棒性的同时提升通信效率和收敛速度。传统的鲁棒聚合或高效通信策略往往单独解决其中一个问题，难以在强对抗环境中达到快速且稳定的收敛，因此需要将鲁棒聚合与优化加速（如 Nesterov 动量）结合起来。

Method: 提出 Byrd-NAFL，将 Nesterov 动量嵌入联邦学习流程，并结合拜占庭鲁棒聚合规则，以应对梯度被篡改的情况；在非凸光滑损失下给出有限时间收敛性保证，且对聚合梯度的假设做出放宽处理；通过大量实验验证在收敛速度、准确率和对多种拜占庭攻击鲁棒性方面优于基线方法。

Result: 理论层面给出 Byrd-NAFL 在非凸、光滑损失下的有限时间收敛保证，且对聚合梯度的假设更加宽松；实验层面表明该方法在收敛速度、模型准确性和对多种攻击策略的鲁棒性方面优于现有基线。

Conclusion: Byrd-NAFL 将鲁棒性与优化加速有效结合，能够在拜占庭环境下实现更快且更稳健的联邦学习收敛，为高效鲁棒的分布式学习提供新的范式。

Abstract: We investigate robust federated learning, where a group of workers
collaboratively train a shared model under the orchestration of a central
server in the presence of Byzantine adversaries capable of arbitrary and
potentially malicious behaviors. To simultaneously enhance communication
efficiency and robustness against such adversaries, we propose a
Byzantine-resilient Nesterov-Accelerated Federated Learning (Byrd-NAFL)
algorithm. Byrd-NAFL seamlessly integrates Nesterov's momentum into the
federated learning process alongside Byzantine-resilient aggregation rules to
achieve fast and safeguarding convergence against gradient corruption. We
establish a finite-time convergence guarantee for Byrd-NAFL under non-convex
and smooth loss functions with relaxed assumption on the aggregated gradients.
Extensive numerical experiments validate the effectiveness of Byrd-NAFL and
demonstrate the superiority over existing benchmarks in terms of convergence
speed, accuracy, and resilience to diverse Byzantine attack strategies.

</details>


### [95] [Scalable Evaluation and Neural Models for Compositional Generalization](https://arxiv.org/abs/2511.02667)
*Giacomo Camposampiero,Pietro Barbiero,Michael Hersche,Roger Wattenhofer,Abbas Rahimi*

Main category: cs.LG

TL;DR: 该论文聚焦在视觉领域的组合泛化问题，提出一个标准化评估框架以降低组合复杂度，进行对5000+模型的广泛评估，并提出 Attribute Invariant Networks（AINs），在准确性和参数开销方面实现显著提升。


<details>
  <summary>Details</summary>
Motivation: 组合泛化是现代机器学习的关键挑战，但缺乏统一评估和鲁棒基准；通用视觉架构缺乏合适的归纳偏置，现有方法在可扩展性上存在权衡。

Method: 提出一个统一并扩展以往方法的严格评估框架，将计算成本从组合爆炸降为常数；在监督视觉骨干上进行大规模评估（>5000模型）；提出 Attribute Invariant Networks，建立新的帕累托前沿以提升组合泛化。

Result: 在基线之上实现23.43%的准确性提升，同时将与完全解耦对手相比的参数开销从600%降至16%。

Conclusion: AINs确立了组合泛化的新帕累托前沿，提供一个可扩展且高效的解决方案；统一评估框架有助于标准化未来研究。

Abstract: Compositional generalization-a key open challenge in modern machine
learning-requires models to predict unknown combinations of known concepts.
However, assessing compositional generalization remains a fundamental challenge
due to the lack of standardized evaluation protocols and the limitations of
current benchmarks, which often favor efficiency over rigor. At the same time,
general-purpose vision architectures lack the necessary inductive biases, and
existing approaches to endow them compromise scalability. As a remedy, this
paper introduces: 1) a rigorous evaluation framework that unifies and extends
previous approaches while reducing computational requirements from
combinatorial to constant; 2) an extensive and modern evaluation on the status
of compositional generalization in supervised vision backbones, training more
than 5000 models; 3) Attribute Invariant Networks, a class of models
establishing a new Pareto frontier in compositional generalization, achieving a
23.43% accuracy improvement over baselines while reducing parameter overhead
from 600% to 16% compared to fully disentangled counterparts.

</details>


### [96] [Does Interpretability of Knowledge Tracing Models Support Teacher Decision Making?](https://arxiv.org/abs/2511.02718)
*Adia Khalid,Alina Deriyeva,Benjamin Paassen*

Main category: cs.LG

TL;DR: Interpretable knowledge tracing (KT) models improve mastery speed in simulations; humans prefer interpretable KT models, but this does not strongly change actual teaching outcomes, suggesting interpretability alone does not guarantee better teaching decisions.


<details>
  <summary>Details</summary>
Motivation: To investigate whether interpretability of KT models translates into better human teaching decisions, addressing a gap between model design and real-world pedagogy.

Method: 1) Simulation study comparing decisions guided by interpretable vs non-interpretable KT models; 2) Human study with 12 teachers who make teaching decisions based on KT model outputs, assessing usability and trust.

Result: Simulation: decisions based on interpretable KT models achieve mastery faster. Human study: teachers rate interpretable models higher in usability and trust, but the number of tasks to mastery is similar across model types.

Conclusion: Model interpretability positively affects user perceptions and can accelerate learning in simulations, but its impact on actual teaching decisions is limited and not straightforward; future work should explore how teachers and learners understand and use KT models.

Abstract: Knowledge tracing (KT) models are a crucial basis for pedagogical
decision-making, namely which task to select next for a learner and when to
stop teaching a particular skill. Given the high stakes of pedagogical
decisions, KT models are typically required to be interpretable, in the sense
that they should implement an explicit model of human learning and provide
explicit estimates of learners' abilities. However, to our knowledge, no study
to date has investigated whether the interpretability of KT models actually
helps human teachers to make teaching decisions. We address this gap. First, we
perform a simulation study to show that, indeed, decisions based on
interpretable KT models achieve mastery faster compared to decisions based on a
non-interpretable model. Second, we repeat the study but ask $N=12$ human
teachers to make the teaching decisions based on the information provided by KT
models. As expected, teachers rate interpretable KT models higher in terms of
usability and trustworthiness. However, the number of tasks needed until
mastery hardly differs between KT models. This suggests that the relationship
between model interpretability and teacher decisions is not straightforward:
teachers do not solely rely on KT models to make decisions and further research
is needed to investigate how learners and teachers actually understand and use
KT models.

</details>


### [97] [Calibration improves detection of mislabeled examples](https://arxiv.org/abs/2511.02738)
*Ilies Chibane,Thomas George,Pierre Nodet,Vincent Lemaire*

Main category: cs.LG

TL;DR: Calibrating the base model improves mislabeled instance detection.


<details>
  <summary>Details</summary>
Motivation: Mislabeled data degrade ML performance; reliable detection requires well-calibrated trust scores that indicate confidence in labels.

Method: Train a base model for mislabel detection and apply calibration techniques (e.g., temperature scaling, isotonic regression, Platt scaling) to align predicted confidences with true probabilities, then evaluate detection performance.

Result: Calibration leads to higher accuracy and robustness in identifying mislabeled instances compared to uncalibrated baselines.

Conclusion: Model calibration is an effective, practical step to enhance mislabeled data detection, with favorable implications for industrial applications.

Abstract: Mislabeled data is a pervasive issue that undermines the performance of
machine learning systems in real-world applications. An effective approach to
mitigate this problem is to detect mislabeled instances and subject them to
special treatment, such as filtering or relabeling. Automatic mislabeling
detection methods typically rely on training a base machine learning model and
then probing it for each instance to obtain a trust score that each provided
label is genuine or incorrect. The properties of this base model are thus of
paramount importance. In this paper, we investigate the impact of calibrating
this model. Our empirical results show that using calibration methods improves
the accuracy and robustness of mislabeled instance detection, providing a
practical and effective solution for industrial applications.

</details>


### [98] [ConMeZO: Adaptive Descent-Direction Sampling for Gradient-Free Finetuning of Large Language Models](https://arxiv.org/abs/2511.02757)
*Lejs Deen Behric,Liang Zhang,Bingcong Li,Kiran Koshy Thekumparampil*

Main category: cs.LG

TL;DR: ConMeZO 在 MeZO 的基础上通过在动量方向附近的圆锥内进行方向性采样来加速零阶优化，保持低内存开销，同时在理论层面与 MeZO 拥有相同的最坏情况收敛率，但在实际的LLM微调任务中可实现约2x加速。


<details>
  <summary>Details</summary>
Motivation: 高维参数空间（十亿级参数的LLM）使得纯零阶优化收敛缓慢，需寻找更具信息性的搜索方向以克服维度灾难；在不增加回传内存成本的前提下提升收敛速率。

Method: 提出 ConMeZO：在零阶方向采样时不再任意随机，而是将采样限定在围绕动量估计的圆锥内。这使搜索集中在梯度更可能落在的方向，降低维度灾难的影响。理论上证明该方法与 MeZO 具有相同的最坏情况收敛速率；在实际的LLM微调任务中，若干任务上比 MeZO 快约2倍，且保留零阶方法的低内存特性。

Result: 理论层面：ConMeZO 的最坏情况收敛速率等同于 MeZO。实验层面：在自然语言任务的LLM微调中，ConMeZO 相较 MeZO 可实现约2x加速，且仍然具备低内存开销。

Conclusion: 通过将采样限制在动量导向的圆锥内，ConMeZO 在高维优化问题中实现更高效的方向搜索，同时在理论上保持同等的最坏情况收敛性，实证上能显著提升实际收敛速度且保持低内存优势。

Abstract: Zeroth-order or derivative-free optimization (MeZO) is an attractive strategy
for finetuning large language models (LLMs) because it eliminates the memory
overhead of backpropagation. However, it converges slowly due to the inherent
curse of dimensionality when searching for descent directions in the
high-dimensional parameter space of billion-scale LLMs. We propose ConMeZO, a
novel zeroth-order optimizer that accelerates convergence by adaptive
directional sampling. Instead of drawing the direction uniformly at random,
ConMeZO restricts the sampling to a cone centered around a momentum estimate.
This concentrates the search in directions where the true gradient is more
likely to lie and thus reduces the effect of high dimensions. We prove that
ConMeZO achieves the same worst-case convergence rate as MeZO. Empirically,
when finetuning LLMs on natural language tasks, ConMeZO is up to 2X faster than
MeZO while retaining the low-memory footprint of zeroth-order methods.

</details>


### [99] [From Solo to Symphony: Orchestrating Multi-Agent Collaboration with Single-Agent Demos](https://arxiv.org/abs/2511.02762)
*Xun Wang,Zhuoran Li,Yanshan Lin,Hai Zhong,Longbo Huang*

Main category: cs.LG

TL;DR: SoCo 通过将 solo 经验迁移到协作学习，先从 solo 演示中预训练一个共享的 solo 策略，在多智能体训练阶段通过一种结合 MoE-like 门控与动作编辑器的策略融合机制将其知识融入协作策略，从而提高 MARL 的样本效率和性能。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习中，获取高质量的多智能体数据成本高、难以规模化，单智能体的练习经验更易获得，如何把单智能体知识转化为多智能体协作能力成为一个关键瓶颈。

Method: 提出 SoCo 框架：首先从 solo 演示中预训练一个共享的 solo 策略；在后续的多智能体训练中，通过一个策略融合模块，将一个 MoE 风格的门控选择器与一个动作编辑器组合起来，将 solo 策略的知识有效地融入协作策略中。

Result: 在多种协作任务上，SoCo 能显著提升骨干 MARL 算法的训练效率和性能，相较于仅使用多智能体数据的基线具有明显优势。

Conclusion: solo 演示为多智能体数据提供了可扩展且有效的补充，使协作学习更具实用性和广泛适用性。

Abstract: Training a team of agents from scratch in multi-agent reinforcement learning
(MARL) is highly inefficient, much like asking beginners to play a symphony
together without first practicing solo. Existing methods, such as offline or
transferable MARL, can ease this burden, but they still rely on costly
multi-agent data, which often becomes the bottleneck. In contrast, solo
experiences are far easier to obtain in many important scenarios, e.g.,
collaborative coding, household cooperation, and search-and-rescue. To unlock
their potential, we propose Solo-to-Collaborative RL (SoCo), a framework that
transfers solo knowledge into cooperative learning. SoCo first pretrains a
shared solo policy from solo demonstrations, then adapts it for cooperation
during multi-agent training through a policy fusion mechanism that combines an
MoE-like gating selector and an action editor. Experiments across diverse
cooperative tasks show that SoCo significantly boosts the training efficiency
and performance of backbone algorithms. These results demonstrate that solo
demonstrations provide a scalable and effective complement to multi-agent data,
making cooperative learning more practical and broadly applicable.

</details>


### [100] [STAR-VAE: Latent Variable Transformers for Scalable and Controllable Molecular Generation](https://arxiv.org/abs/2511.02769)
*Bum Chul Kwon,Ben Shapira,Moshiko Raboh,Shreyans Sethi,Shruti Murarka,Joseph A Morrone,Jianying Hu,Parthasarathy Suryanarayanan*

Main category: cs.LG

TL;DR: STAR-VAE is a scalable, SELFIES-based Transformer latent-variable VAE for drug-like molecule generation with conditional, property-guided generation and efficient LoRA finetuning.


<details>
  <summary>Details</summary>
Motivation: To enable broad, valid, and fast molecular generation in the vast chemical space by combining robust representations (SELFIES), scalable architectures (Transformer-based VAE), and principled conditioning to control properties.

Method: Build a Transformer Encoder–Decoder VAE trained on SELFIES representations of 79 million PubChem molecules. Use a latent-variable formulation with a property predictor to condition the latent prior, inference network, and decoder. Enable efficient adaptation via LoRA adapters in both encoder and decoder.

Result: On GuacaMol and MOSES, STAR-VAE matches or surpasses baselines. Latent space shows smooth, semantically structured representations supporting unconditional exploration and property-aware generation. On Tartarus, the conditional model shifts docking-score distributions toward stronger predicted binding.

Conclusion: A modern, scale-appropriate VAE with principled conditioning and parameter-efficient finetuning remains competitive for molecular generation within large chemical spaces.

Abstract: The chemical space of drug-like molecules is vast, motivating the development
of generative models that must learn broad chemical distributions, enable
conditional generation by capturing structure-property representations, and
provide fast molecular generation. Meeting the objectives depends on modeling
choices, including the probabilistic modeling approach, the conditional
generative formulation, the architecture, and the molecular input
representation. To address the challenges, we present STAR-VAE
(Selfies-encoded, Transformer-based, AutoRegressive Variational Auto Encoder),
a scalable latent-variable framework with a Transformer encoder and an
autoregressive Transformer decoder. It is trained on 79 million drug-like
molecules from PubChem, using SELFIES to guarantee syntactic validity. The
latent-variable formulation enables conditional generation: a property
predictor supplies a conditioning signal that is applied consistently to the
latent prior, the inference network, and the decoder. Our contributions are:
(i) a Transformer-based latent-variable encoder-decoder model trained on
SELFIES representations; (ii) a principled conditional latent-variable
formulation for property-guided generation; and (iii) efficient finetuning with
low-rank adapters (LoRA) in both encoder and decoder, enabling fast adaptation
with limited property and activity data. On the GuacaMol and MOSES benchmarks,
our approach matches or exceeds baselines, and latent-space analyses reveal
smooth, semantically structured representations that support both unconditional
exploration and property-aware generation. On the Tartarus benchmarks, the
conditional model shifts docking-score distributions toward stronger predicted
binding. These results suggest that a modernized, scale-appropriate VAE remains
competitive for molecular generation when paired with principled conditioning
and parameter-efficient finetuning.

</details>


### [101] [Enhancing Federated Learning Privacy with QUBO](https://arxiv.org/abs/2511.02785)
*Andras Ferenczi,Sutapa Samanta,Dagen Wang,Todd Hodges*

Main category: cs.LG

TL;DR: 提出一种基于QUBO的客户端更新选择策略以降低联邦学习中的隐私暴露，同时尽量保持全局模型准确性。


<details>
  <summary>Details</summary>
Motivation: 缓解联邦学习中多轮训练带来的逐步累积隐私泄露风险，聚焦训练阶段的信息泄露和全局模型查询攻击。

Method: 将量子计算启发的二次无约束二进制优化（QUBO）形式用于在每轮训练中筛选对本轮最相关的少量客户端更新，使其进入聚合。服务器假设为可信且具备全局分布的一致验证集；对 MNIST（300 客户端，20 轮）和 CINIC-10（30 客户端）数据集进行实验。

Result: MNIST 实验显示每轮隐私暴露降低95.2%，累计暴露降低49%，有147个客户端更新未被用于训练，同时保持甚至提升全局聚合精度。CINIC-10 实验显示每轮隐私提升82%，累计隐私提升33%。

Conclusion: 方法在降低隐私暴露的同时维持模型性能，且在低规模和更复杂模型下也表现出良好效率和适用性。

Abstract: Federated learning (FL) is a widely used method for training machine learning
(ML) models in a scalable way while preserving privacy (i.e., without
centralizing raw data). Prior research shows that the risk of exposing
sensitive data increases cumulatively as the number of iterations where a
client's updates are included in the aggregated model increase. Attackers can
launch membership inference attacks (MIA; deciding whether a sample or client
participated), property inference attacks (PIA; inferring attributes of a
client's data), and model inversion attacks (MI; reconstructing inputs),
thereby inferring client-specific attributes and, in some cases, reconstructing
inputs. In this paper, we mitigate risk by substantially reducing per client
exposure using a quantum computing-inspired quadratic unconstrained binary
optimization (QUBO) formulation that selects a small subset of client updates
most relevant for each training round. In this work, we focus on two threat
vectors: (i) information leakage by clients during training and (ii)
adversaries who can query or obtain the global model. We assume a trusted
central server and do not model server compromise. This method also assumes
that the server has access to a validation/test set with global data
distribution. Experiments on the MNIST dataset with 300 clients in 20 rounds
showed a 95.2% per-round and 49% cumulative privacy exposure reduction, with
147 clients' updates never being used during training while maintaining in
general the full-aggregation accuracy or even better. The method proved to be
efficient at lower scale and more complex model as well. A CINIC-10
dataset-based experiment with 30 clients resulted in 82% per-round privacy
improvement and 33% cumulative privacy.

</details>


### [102] [Can LLMs subtract numbers?](https://arxiv.org/abs/2511.02795)
*Mayank Jobanputra,Nils Philipp Walter,Maitrey Mehta,Blerta Veseli,Evan Parker Kelly Chapple,Yifan Wang,Sneha Chetani,Ellie Pavlick,Antonio Vergari,Vera Demberg*

Main category: cs.LG

TL;DR: LLMs对减法的掌握明显不如加法，负号输出在遇到a<b时容易丢失；少量示例提示略有提升，指令微调模型能显著修复并接近完美输出。


<details>
  <summary>Details</summary>
Motivation: 减法是非交换且结构上与加法不同，迄今在LLM算术基准中的关注度较低，亟需评估其能力及可恢复性。

Method: 在四个家族的8个预训练LLMs上，比较加法与减法问题的准确性；尝试少样本提示和指令微调；通过探针分析内部是否编码了结果的符号信息。

Result: 减法的准确性明显落后于加法；在a<b的情形下，模型常给出正确的量级但丢失负号。探针分析显示模型内部确实编码了结果应为负数的判断，但输出中未反映。少样本提示有一定提升，指令微调模型在生成负号方面几乎达到完美。

Conclusion: LLMs的减法能力存在局限，但具有可恢复性；通过指令微调等训练策略可显著改善负号输出，内部表征虽存在但在生成中未总是被体现。

Abstract: We present a systematic study of subtraction in large language models (LLMs).
While prior benchmarks emphasize addition and multiplication, subtraction has
received comparatively little attention despite being structurally distinct as
a non-commutative operation. We evaluate eight pretrained LLMs spanning four
families on addition and subtraction problems. Our experiments reveal that
subtraction accuracy lags behind addition by a wide margin. We find that the
errors for ($a-b$) are concentrated in cases where ($a<b$). In such cases, LLMs
frequently produce the correct magnitude but omit the negative sign. Probing
analyses show that LLMs internally encode whether results should be negative,
yet this information is often not reflected in generated outputs. We further
test well-known techniques such as few-shot learning and instruction-tuning to
see if they can improve the LLMs' performance. Our results suggest that while
few-shot prompting yields modest gains, the instruction-tuned models achieve
near-perfect accuracies in generating the negative sign. Together, these
findings provide a clearer characterization of the limitations and
recoverability of LLMs' arithmetic capabilities in subtraction.

</details>


### [103] [Fast, Private, and Protected: Safeguarding Data Privacy and Defending Against Model Poisoning Attacks in Federated Learning](https://arxiv.org/abs/2511.02797)
*Nicolas Riccieri Gardin Assumpcao,Leandro Villas*

Main category: cs.LG

TL;DR: 提出 FPP（Fast, Private, and Protected）框架用于联邦学习，结合安全聚合、基于参与者评估的轮次判定、攻击后的训练恢复及声誉机制。在 Docker 环境中对比 FedAvg、Power-of-Choice、Trimmed Mean/Median，结果表明在存在模型污染攻击时仍能快速收敛。


<details>
  <summary>Details</summary>
Motivation: 在保护数据隐私的前提下，提升对抗潜在攻击的鲁棒性并加速收敛，解决现有联邦学习框架在安全聚合与攻击恢复方面的不足。

Method: 提出 FPP 框架，包含：1) 安全聚合以保护隐私；2) 通过参与者评估对轮次进行判断与筛选；3) 攻击发生时的训练恢复机制；4) 基于声誉的机制以抑制攻击者参与；5) 用 Docker 容器实现并在对比实验中评估与 FedAvg、Power-of-Choice、Trimmed Mean、Median 的性能差异。

Result: 实验结果显示，FPP 具备更快的收敛速率，在存在恶意参与者进行模型污染攻击时也能实现收敛。

Conclusion: FPP 提供了一种更鲁棒、私有且高效的联邦学习解决方案，适用于潜在攻击场景，并通过容器化实验验证了其性能与鲁棒性。

Abstract: Federated Learning (FL) is a distributed training paradigm wherein
participants collaborate to build a global model while ensuring the privacy of
the involved data, which remains stored on participant devices. However,
proposals aiming to ensure such privacy also make it challenging to protect
against potential attackers seeking to compromise the training outcome. In this
context, we present Fast, Private, and Protected (FPP), a novel approach that
aims to safeguard federated training while enabling secure aggregation to
preserve data privacy. This is accomplished by evaluating rounds using
participants' assessments and enabling training recovery after an attack. FPP
also employs a reputation-based mechanism to mitigate the participation of
attackers. We created a dockerized environment to validate the performance of
FPP compared to other approaches in the literature (FedAvg, Power-of-Choice,
and aggregation via Trimmed Mean and Median). Our experiments demonstrate that
FPP achieves a rapid convergence rate and can converge even in the presence of
malicious participants performing model poisoning attacks.

</details>


### [104] [TabTune: A Unified Library for Inference and Fine-Tuning Tabular Foundation Models](https://arxiv.org/abs/2511.02802)
*Aditya Tanna,Pratinav Seth,Mohamed Bouadi,Utsav Avaiya,Vinay Kumar Sankarapu*

Main category: cs.LG

TL;DR: TabTune is a unified library that standardizes the end-to-end workflow for tabular foundation models, enabling consistent preprocessing, model access, adaptation methods, and deployment-oriented evaluation (calibration and fairness) across seven models.


<details>
  <summary>Details</summary>
Motivation: The adoption of tabular foundation models is impeded by heterogeneous preprocessing pipelines, fragmented APIs, inconsistent fine-tuning procedures, and lack of standardized deployment-oriented evaluation metrics. A unified, extensible framework can improve usability, comparability, and reproducibility.

Method: Develop TabTune library with seven state-of-the-art tabular foundation models, supporting zero-shot inference, meta-learning, supervised fine-tuning (SFT), and parameter-efficient fine-tuning (PEFT). It automates model-aware preprocessing, manages architectural heterogeneity internally, and integrates evaluation modules for performance, calibration, and fairness, designed for extensibility and reproducibility.

Result: TabTune provides a single interface that standardizes preprocessing, model access, adaptation strategies, and deployment-oriented evaluation across tabular foundation models. It enables consistent benchmarking, extensibility, and reproducibility, and is open source at GitHub (Lexsi-Labs/TabTune).

Conclusion: TabTune lowers barriers to adopting tabular foundation models by offering a unified, extensible framework that streamlines preprocessing, model adaptation, and deployment-focused evaluation.

Abstract: Tabular foundation models represent a growing paradigm in structured data
learning, extending the benefits of large-scale pretraining to tabular domains.
However, their adoption remains limited due to heterogeneous preprocessing
pipelines, fragmented APIs, inconsistent fine-tuning procedures, and the
absence of standardized evaluation for deployment-oriented metrics such as
calibration and fairness. We present TabTune, a unified library that
standardizes the complete workflow for tabular foundation models through a
single interface. TabTune provides consistent access to seven state-of-the-art
models supporting multiple adaptation strategies, including zero-shot
inference, meta-learning, supervised fine-tuning (SFT), and parameter-efficient
fine-tuning (PEFT). The framework automates model-aware preprocessing, manages
architectural heterogeneity internally, and integrates evaluation modules for
performance, calibration, and fairness. Designed for extensibility and
reproducibility, TabTune enables consistent benchmarking of adaptation
strategies of tabular foundation models. The library is open source and
available at https://github.com/Lexsi-Labs/TabTune .

</details>


### [105] [Assessing win strength in MLB win prediction models](https://arxiv.org/abs/2511.02815)
*Morgan Allen,Paul Savala*

Main category: cs.LG

TL;DR: 通过一组常见的机器学习模型对 MLB 比赛进行胜率预测，揭示预测胜率与实际胜负强度（差分得分）的关系，并评估将胜率用于赔率下注的可行性，发现需采用合适策略才能实现正收益，简单盲目应用会带来损失。


<details>
  <summary>Details</summary>
Motivation: 在 MLB 的策略和规划对比赛结果影响的背景下，利用机器学习模型预测胜者和胜率，并探索其与实际胜负强度的关系，以及在投注中的可行性。

Method: 使用一个统一的数据集训练多种常见机器学习模型，生成胜率预测。将预测的胜率与以差分得分衡量的胜负强度进行相关分析，并在跑线下注的情境下评估预测胜率的决策效果，比较合适策略与 naive 策略的收益差异。

Result: 多数常见模型确实展示了预测胜率与胜负强度之间的关系。基于预测胜率的下注策略可带来正收益，但若以简单、盲目的方式使用模型进行投注则会造成显著损失。

Conclusion: 机器学习模型的胜率预测可以反映实际的胜负强度并在经过恰当策略时为投注带来收益；但模型的错误使用或策略不当会导致亏损，需要谨慎的策略设计和风险管理。

Abstract: In Major League Baseball, strategy and planning are major factors in
determining the outcome of a game. Previous studies have aided this by building
machine learning models for predicting the winning team of any given game. We
extend this work by training a comprehensive set of machine learning models
using a common dataset. In addition, we relate the win probabilities produced
by these models to win strength as measured by score differential. In doing so
we show that the most common machine learning models do indeed demonstrate a
relationship between predicted win probability and the strength of the win.
Finally, we analyze the results of using predicted win probabilities as a
decision making mechanism on run-line betting. We demonstrate positive returns
when utilizing appropriate betting strategies, and show that naive use of
machine learning models for betting lead to significant loses.

</details>


### [106] [GeoCrossBench: Cross-Band Generalization for Remote Sensing](https://arxiv.org/abs/2511.02831)
*Hakob Tamazyan,Ani Vanyan,Alvard Barseghyan,Anna Khosrovyan,Evan Shelhamer,Hrant Khachatrian*

Main category: cs.LG

TL;DR: 提出 GeoCrossBench，用于评估跨卫星程度的自监督与跨域泛化；并发展 ChiViT 自监督版本以提升跨卫星性能。


<details>
  <summary>Details</summary>
Motivation: 解决地球观测基础模型在新卫星上的泛化能力不足的问题，尤其是在不同谱带和传感器特征下的迁移能力。

Method: 将 GeoBench 扩展为 GeoCrossBench，覆盖在分布内性能、无谱带重叠的泛化、以及测试时额外谱带的泛化等评估场景。还开发了 ChannelViT 的自监督扩展 ChiViT。对多种模型（DOFA、TerraFM、DINOv3、ChiViT）在不同设定下进行系统对比，并探讨用 oracle 标签微调仅最后一层以提升跨卫星稳定性。

Result: 结论包括：DOFA、TerraFM 在就地分布内不优于通用模型 DINOv3；在无谱带重叠的跨卫星泛化下，所有模型都出现 2–4 倍的性能下降，ChiViT 显著优于 DINOv3；在测试时增加额外谱带时，所有模型的平均性能下降 5–25%；仅对最后一层进行微调并使用全谱带的 oracle 标签可获得相对稳定的跨卫星性能，表明基准尚未饱和。

Conclusion: 公开发布代码和数据集，旨在推动更具跨卫星鲁棒性的遥感模型研究。

Abstract: The number and diversity of remote sensing satellites grows over time, while
the vast majority of labeled data comes from older satellites. As the
foundation models for Earth observation scale up, the cost of (re-)training to
support new satellites grows too, so the generalization capabilities of the
models towards new satellites become increasingly important. In this work we
introduce GeoCrossBench, an extension of the popular GeoBench benchmark with a
new evaluation protocol: it tests the in-distribution performance;
generalization to satellites with no band overlap; and generalization to
satellites with additional bands with respect to the training set. We also
develop a self-supervised extension of ChannelViT, ChiViT, to improve its
cross-satellite performance. First, we show that even the best foundation
models for remote sensing (DOFA, TerraFM) do not outperform general purpose
models like DINOv3 in the in-distribution setting. Second, when generalizing to
new satellites with no band overlap, all models suffer 2-4x drop in
performance, and ChiViT significantly outperforms the runner-up DINOv3. Third,
the performance of all tested models drops on average by 5-25\% when given
additional bands during test time. Finally, we show that fine-tuning just the
last linear layer of these models using oracle labels from all bands can get
relatively consistent performance across all satellites, highlighting that the
benchmark is far from being saturated. We publicly release the code and the
datasets to encourage the development of more future-proof remote sensing
models with stronger cross-satellite generalization.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [107] [Analysis of Beam Misalignment Effect in Inter-Satellite FSO Links](https://arxiv.org/abs/2511.02189)
*Minje Kim,Hongjae Nam,Beomsoo Ko,Hyeongjun Park,Hwanjin Kim,Dong-Hyun Jung,Junil Choi*

Main category: cs.IT

TL;DR: 提出一个实用的解析模型，用于在联合抖动和指向误差下的星间自由空间光链路（ISL FSO）信道；给出闭式CDF，并采用截断CDF与二分法高效计算 outage 概率；结合轨道动力学量化位移，且通过蒙特卡洛对比验证模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 星间自由空间光通信对波束错位极为敏感，PAA补偿依赖于精确的轨道信息和高端对准硬件，在现实中并不可总是可行。因此，需要一个可在设计阶段使用的、可计算的、贴近实际的性能分析工具来评估在错位条件下的系统性能。

Method: 推导在联合抖动和指向误差下的 FSO 信道CDF的闭式表达；提出带截断的CDF形式，并给出能保证收敛的二分算法来高效计算 outage 概率；并以轨道动力学量化位移，使分析更贴近实际场景；通过数值仿真验证模型对蒙特卡洛结果的吻合度。

Result: 数值结果显示所提模型与蒙特卡洛仿真结果高度一致，且截断CDF+二分法能够在保证收敛性的前提下高效计算 outage 概率，适用于实际的星间自由空间光系统设计与分析。

Conclusion: 该分析框架为在考虑波束错位的星间 FSO 系统提供了一个实用、计算高效的性能分析工具，可用于常规设计与鲁棒性评估，降低对高强度蒙特卡洛仿真的依赖。

Abstract: Free-space optical (FSO) communication has emerged as a promising technology
for inter-satellite links (ISLs) due to its high data rate, low power
consumption, and reduced interference. However, the performance of
inter-satellite FSO systems is highly sensitive to beam misalignment. While
pointing-ahead angle (PAA) compensation is commonly employed, the effectiveness
of PAA compensation depends on precise orbital knowledge and advanced alignment
hardware, which are not always feasible in practice. To address this challenge,
this paper investigates the impact of beam misalignment on inter-satellite FSO
communication. We derive a closed-form expression for the cumulative
distribution function (CDF) of the FSO channel under the joint jitter and
misalignment-induced pointing error, and introduce a truncated CDF formulation
with a bisection algorithm to efficiently compute outage probabilities with
guaranteed convergence and minimal computational overhead. To make the analysis
more practical, we quantify displacement based on orbital dynamics. Numerical
results demonstrate that the proposed model closely matches Monte Carlo
simulations, making the proposed model highly useful to design inter-satellite
FSO systems in practice.

</details>


### [108] [Adaptive Cooperative Transmission Design for Ultra-Reliable Low-Latency Communications via Deep Reinforcement Learning](https://arxiv.org/abs/2511.02216)
*Hyemin Yu,Hong-Chuan Yang*

Main category: cs.IT

TL;DR: 提出一种基于双智能体强化学习的两跳中继系统延迟感知传输算法DRL-CoLA，在每一跳独立自适应配置参数（Numerology、mini-slot大小、调制和编码方案），通过把每跳的传输配置建模为MDP，实现分布式学习以在严格时延约束下接近最优可靠性。


<details>
  <summary>Details</summary>
Motivation: URLLC在两跳协作通信中的高可靠性和低时延需求极具挑战，现有方法往往单跳或全局配置，难以兼顾每跳差异和时延约束。

Method: 把每跳的发送配置视为马尔可夫决策过程，提出双智能体强化学习基础的协作延迟感知传输（DRL-CoLA）算法，在分布式环境中学习跳间独立的时延优化策略，同时对每跳参数（numerology、mini-slot、MCS）进行自适应选择。

Result: 仿真结果表明，所提算法在满足严格时延要求的同时接近最优可靠性。

Conclusion: DRL-CoLA实现了两跳中继的分布式、延迟感知策略学习，提升了URLLC场景下的可靠性与时延可控性，未来工作可扩展至多跳或现实场景验证。

Abstract: Next-generation wireless communication systems must support ultra-reliable
low-latency communication (URLLC) service for mission-critical applications.
Meeting stringent URLLC requirements is challenging, especially for two-hop
cooperative communication. In this paper, we develop an adaptive transmission
design for a two-hop relaying communication system. Each hop transmission
adaptively configures its transmission parameters separately, including
numerology, mini-slot size, and modulation and coding scheme, for reliable
packet transmission within a strict latency constraint. We formulate the
hop-specific transceiver configuration as a Markov decision process (MDP) and
propose a dual-agent reinforcement learning-based cooperative latency-aware
transmission (DRL-CoLA) algorithm to learn latency-aware transmission policies
in a distributed manner. Simulation results verify that the proposed algorithm
achieves the near-optimal reliability while satisfying strict latency
requirements.

</details>


### [109] [Fairness-Aware Computation Offloading in Wireless-Powered MEC Systems with Cooperative Energy Recycling](https://arxiv.org/abs/2511.02287)
*Haohao Qin,Bowen Gu,Dong Li,Xianhua Yu,Liejun Wang,Yuanwei Liu,Sumei Sun*

Main category: cs.IT

TL;DR: CER enables energy recycling in wireless-powered MEC, optimizing local computing and offloading under alpha-fairness; converts non-convex problem to convex via variable substitution; shows throughput gains and tunable fairness.


<details>
  <summary>Details</summary>
Motivation: Address energy efficiency and fairness in wireless-powered mobile edge computing by allowing sensors to harvest energy from peer transmissions, aiming to boost system throughput while maintaining fairness under energy, latency, and task constraints.

Method: Formulate a joint optimization of local computation and task offloading with an alpha-fairness objective. Apply a variable-substitution technique to transform the non-convex problem into a convex form, then solve via Lagrangian duality and alternating optimization. Derive closed-form solutions for zero fairness, common fairness, and max-min fairness regimes.

Result: Demonstrates significant throughput gains and adaptability over benchmark schemes, with tunable alpha-fairness enabling flexible control of performance-fairness trade-offs across scenarios; numerical results validate the effectiveness and robustness of the CER-enabled framework.

Conclusion: CER with alpha-fairness is an effective framework for balancing throughput and fairness in wireless-powered MEC. The proposed methodology provides insight into design trade-offs and offers practical guidelines for deploying energy-recycling-enabled edge computing systems.

Abstract: In this paper, cooperative energy recycling (CER) is investigated in
wireless-powered mobile edge computing systems. Unlike conventional
architectures that rely solely on a dedicated power source, wireless sensors
are additionally enabled to recycle energy from peer transmissions. To evaluate
system performance, a joint computation optimization problem is formulated that
integrates local computing and computation offloading, under an alpha-fairness
objective that balances total computable data and user fairness while
satisfying energy, latency, and task size constraints. Due to the inherent
non-convexity introduced by coupled resource variables and fairness
regularization, a variable-substitution technique is employed to transform the
problem into a convex structure, which is then efficiently solved using
Lagrangian duality and alternating optimization. To characterize the
fairness-efficiency tradeoff, closed-form solutions are derived for three
representative regimes: zero fairness, common fairness, and max-min fairness,
each offering distinct system-level insights. Numerical results validate the
effectiveness of the proposed CER-enabled framework, demonstrating significant
gains in throughput and adaptability over benchmark schemes. The tunable alpha
fairness mechanism provides flexible control over performance-fairness
trade-offs across diverse scenarios.

</details>


### [110] [Downlink Channel Estimation for mmWave Systems with Impulsive Interference](https://arxiv.org/abs/2511.02291)
*Kwonyeol Park,Gyoseung Lee,Hyeongtaek Lee,Hwanjin Kim,Junil Choi*

Main category: cs.IT

TL;DR: 提出了一种基于变分推断的贝叶斯通道估计方法，结合稀疏贝叶斯学习框架用于下行 mmWave MIMO，在存在冲动干扰的场景中提高通道估计精度。


<details>
  <summary>Details</summary>
Motivation: 下行毫米波MIMO在硬件非理性或外部干扰导致的冲动干扰下，通道估计变得困难，需鲁棒且高效的估计方法。

Method: 提出基于变分推断(VI)的贝叶斯通道估计，利用毫米波信道在角域的稀疏性以及干扰的间歇性特征；采用均场近似(MFA)近似后验推断，并将VI整合进稀疏贝叶斯学习(SBL)框架。

Result: 仿真结果显示所提方法在通道估计精度方面优于基线方法。

Conclusion: 在存在冲动干扰的下行mmWave MIMO场景中，所提的VI‑SBL方法可有效提高通道估计的准确性。

Abstract: In this paper, we investigate a channel estimation problem in a downlink
millimeter-wave (mmWave) multiple-input multiple-output (MIMO) system, which
suffers from impulsive interference caused by hardware non-idealities or
external disruptions. Specifically, impulsive interference presents a
significant challenge to channel estimation due to its sporadic, unpredictable,
and high-power nature. To tackle this issue, we develop a Bayesian channel
estimation technique based on variational inference (VI) that leverages the
sparsity of the mmWave channel in the angular domain and the intermittent
nature of impulsive interference to minimize channel estimation errors. The
proposed technique employs mean-field approximation to approximate posterior
inference and integrates VI into the sparse Bayesian learning (SBL) framework.
Simulation results demonstrate that the proposed technique outperforms
baselines in terms of channel estimation accuracy.

</details>


### [111] [Two-Parameter Rényi Information Quantities with Applications to Privacy Amplification and Soft Covering](https://arxiv.org/abs/2511.02297)
*Shi-Bing Li,Ke Li,Lei Yu*

Main category: cs.IT

TL;DR: 提出两参数Rényi条件熵与两参数Rényi互信息，并统一三种Rényi互信息的变体，给出性质并用于隐私放大与软覆盖的强对称指数。


<details>
  <summary>Details</summary>
Motivation: 解决现有Rényi信息度量缺乏统一定义的问题，建立一个两参数族，以统一并扩展Hayashi-Tan定义及三参数量子Rényi条件熵的经典化版本，并便于分析与应用。

Method: 通过对参数变量的变换使两参数条件熵等价于Hayashi-Tan定义，提出两参数Rényi互信息的定义并展开其变分表达式，研究单调性、可加性、数据处理不等式、凸性/凹性及对参数的单调性，最后将其用于隐私放大与软覆盖的强对称指数的表征。

Result: 证明了两参数条件熵的基本性质（包括单调性与变分表达式）以及两参数互信息的非负性、可加性、数据处理不等式、对参数的单调性、变分表达式、以及凸/凹性；并显示该量可以表征在Rènyi散度下的隐私放大与软覆盖问题的强对称指数。

Conclusion: 两参数Rényi信息量构成一个统一且富有应用价值的框架，覆盖常用的三种Rényi互信息变体，并在信息安全与编码挑战中提供强对约束界和分析工具。

Abstract: There are no universally accepted definitions of R\'enyi conditional entropy
and R\'enyi mutual information, although motivated by different applications,
several definitions have been proposed in the literature. In this paper, we
consider a family of two-parameter R\'enyi conditional entropy and a family of
two-parameter R\'enyi mutual information. By performing a change of variables
for the parameters, the two-parameter R\'enyi conditional entropy we study
coincides precisely with the definition introduced by Hayashi and Tan [IEEE
Trans. Inf. Theory, 2016], and it also emerges naturally as the classical
specialization of the three-parameter quantum R\'enyi conditional entropy
recently put forward by Rubboli, Goodarzi, and Tomamichel [arXiv:2410.21976
(2024)]. We establish several fundamental properties of the two-parameter
R\'enyi conditional entropy, including monotonicity with respect to the
parameters and variational expression. The associated two-parameter R\'enyi
mutual information considered in this paper is new and it unifies three
commonly used variants of R\'enyi mutual information. For this quantity, we
prove several important properties, including the non-negativity, additivity,
data processing inequality, monotonicity with respect to the parameters,
variational expression, as well as convexity and concavity. Finally, we
demonstrate that these two-parameter R\'enyi information quantities can be used
to characterize the strong converse exponents in privacy amplification and soft
covering problems under R\'enyi divergence of order $\alpha \in (0, \infty)$.

</details>


### [112] [Anomaly Detection-Based UE-Centric Inter-Cell Interference Suppression](https://arxiv.org/abs/2511.02320)
*Kwonyeol Park,Hyuckjin Choi,Beomsoo Ko,Minje Kim,Gyoseung Lee,Daecheol Kwon,Hyunjae Park,Byungseung Kim,Min-Ho Shin,Junil Choi*

Main category: cs.IT

TL;DR: 提出了以终端设备为中心的干扰抑制方案，利用Z-refined深度SVDD进行单类异常检测以识别跨小区干扰(ICI)，再对检测出的ICI执行干扰 whitening，以提升性能，在有限训练资源下优于多基线方法，且在5G商用模组测试中对多种3GPP信道模型（TDL-A/B/C）表现出改进。


<details>
  <summary>Details</summary>
Motivation: 在频谱再利用增加导致邻区干扰显著增强的场景下，需要高效、低资源的干扰抑制方案以提升系统整体性能。

Method: 提出一种基于Z-refined深度支持向量数据描述(深SVDD)的一类异常检测方法，作为ICI检测的核心；在检测到ICI后应用干扰 whitening 来抑制ICI。该方法为UE端实现，利用单类学习对异常模式进行检测，且对时间/频率资源受限的训练更具鲁棒性。

Result: 数值仿真显示在有限的训练资源下，该方法在ICI检测性能上优于多种基线，且接近理想 genie-aided 情况；进一步在使用商用5G调制解调器芯片的测试设备上，方法在多种3GPP信道环境（包括Tapped Delay Line 模型A/B/C）下表现出性能提升。

Conclusion: 该UE端干扰抑制框架具有在资源受限场景下有效检测ICI并实现干扰抑制的潜力，具有良好的通用性和可落地性。

Abstract: The increasing spectral reuse can cause significant performance degradation
due to interference from neighboring cells. In such scenarios, developing
effective interference suppression schemes is necessary to improve overall
system performance. To tackle this issue, we propose a novel user
equipment-centric interference suppression scheme, which effectively detects
inter-cell interference (ICI) and subsequently applies interference whitening
to mitigate ICI. The proposed scheme, named Z-refined deep support vector data
description, exploits a one-class classification-based anomaly detection
technique. Numerical results verify that the proposed scheme outperforms
various baselines in terms of interference detection performance with limited
time or frequency resources for training and is comparable to the performance
based on an ideal genie-aided interference suppression scheme. Furthermore, we
demonstrate through test equipment experiments using a commercial
fifth-generation modem chipset that the proposed scheme shows performance
improvements across various 3rd generation partnership project standard channel
environments, including tapped delay line-A, -B, and -C models.

</details>


### [113] [$\mathbb{F}_q\mathbb{F}_{q^2}$-additive cyclic codes and their Gray images](https://arxiv.org/abs/2511.02325)
*Ankit Yadav,Ritumoni Sarma*

Main category: cs.IT

TL;DR: 研究了在字母表 F_q F_{q^2} 上的加法循环码，给出其生成多项式与最小生成集；构造满足 Singleton 界的示例；通过 Gray 映射得到在 F_3 上的最优线性码；并从 F_3 F_9 的加法码中获得若干最优的三元线性互补对偶 LCD 码。


<details>
  <summary>Details</summary>
Motivation: 通过研究混合域上的加法循环码，发掘构造最优或接近最优码的途径，并将结果在实用域如 F_3 上实现，以提升编码理论及应用的可用性。

Method: 首先确定 F_qF_{q^2} 上的加法循环码的生成多项式及其最小生成集；给出满足 Singleton 上界的示例；利用 Gray 映射将这些码映射到 F_3 上以得到线性码的最优性；最后从 F_3F_9 的加法码中提取构造最优的三元 LCD 码。

Result: 获得了 F_qF_{q^2} 加法循环码的生成多项式和最小生成集；构造出若干满足 Singleton 界的示例；通过 Gray 映射得到若干在 F_3 上的最优线性码；并推导出若干来自 F_3F_9 的最优三元 LCD 码。

Conclusion: 该工作证明了通过混合域的加法循环码及 Gray 映射可以系统性地构造接近或达到最优性的线性码，特别是在 F_3 及三元 LCD 码方面提供了新的最优构造。

Abstract: We investigate additive cyclic codes over the alphabet
$\mathbb{F}_{q}\mathbb{F}_{q^2}$, where $q$ is a prime power. First, its
generator polynomials and minimal spanning set are determined. Then, examples
of $\mathbb{F}_{q^2}$-additive cyclic codes that satisfy the well-known
Singleton bound are constructed. Using a Gray map, we produce certain optimal
linear codes over $\mathbb{F}_{3}$. Finally, we obtain a few optimal ternary
linear complementary dual (LCD) codes from
$\mathbb{F}_{3}\mathbb{F}_{9}$-additive codes.

</details>


### [114] [Generalized informational functionals and new monotone measures of statistical complexity](https://arxiv.org/abs/2511.02502)
*Razvan Gabriel Iagar,David Puertas-Centeno*

Main category: cs.IT

TL;DR: 提出一种双参量变换族，扩展了所谓的上下变换，引入 down-moments 与 cumulative upper-moments；在某些情形下，down-moments 能在 p-次矩与幂 Rényi 熵之间进行插值；给出与矩、Rényi、Shannon、Fisher 等传统信息量的新颖且尖锐的不等式，并揭示最优界与极小密度（某些情形可用广义三角函数表示）；进一步定义以新泛函之商为基础的统计复杂度量，并通过上下变换的代数共轭性研究其单调性，揭示函数不等式的错综结构。


<details>
  <summary>Details</summary>
Motivation: 扩展现有的上/下变换，构建新的信息性泛函以揭示矩、Rényi、Shannon、Fisher 等信息量之间的关系；提供一个在 p-次矩与幂Rényi熵之间插值的框架，并探索相关的最优界、极小密度和复杂度量的性质，揭示函数不等式的内在结构。

Method: 构造双参量变换族；引入 down-moments 与 cumulative upper-moments；推导并证明这些泛函与经典信息量（矩、Rényi、Shannon、Fisher）之间的尖锐不等式；给出最优界及极小密度的表述（在某些情形可用广义三角函数表示）；将新泛函以商的形式定义统计复杂度量，并研究其在上下变换的代数共轭性下的单调性。

Result: 获得关于新泛函与矩、Rényi、Shannon、Fisher 等之间的新的尖锐不等式；确定了最优界与极小密度，并在部分情形给出可用广义三角函数表示的极小密度形式；提出并分析基于新泛函商的统计复杂度量及其单调性性质，揭示了函数不等式的复杂结构。

Conclusion: 该框架揭示了一个关于新泛函与经典信息量之间关系的丰富结构，连接矩、熵与复杂度的多维信息量谱，并为信息论与统计学的进一步研究提供新的分析工具和方向。

Abstract: In this paper we introduce a biparametric family of transformations which can
be seen as an extension of the so-called up and down transformations. This new
class of transformations allows to us to introduce new informational
functionals, which we have called \textit{down-moments} and \textit{cumulative
upper-moments}. A remarkable fact is that the down-moments provide, in some
cases, an interpolation between the $p$-th moments and the power R\'enyi
entropies of a probability density. We establish new and sharp inequalities
relating these new functionals to the classical informational measures such as
moments, R\'enyi and Shannon entropies and Fisher information measures. We also
give the optimal bounds as well as the minimizing densities, which are in some
cases expressed in terms of the generalized trigonometric functions. We
furthermore define new classes of measures of statistical complexity obtained
as quotients of the new functionals, and establish monotonicity properties for
them through an algebraic conjugation of up and down transformations. All of
these properties highlight an intricate structure of functional inequalities.

</details>


### [115] [Improved AntiGriesmer Bounds for Linear Anticodes and Applications](https://arxiv.org/abs/2511.02519)
*Guanghui Zhang,Bocong Chen,Liren Lin,Hongwei Liu*

Main category: cs.IT

TL;DR: 在原 antiGriesmer 边界基础上放宽长度条件与对偶距离条件，得到对任意 [n,k]_q 线性反码 C 满足 δ 与 d(C^⊥)≥2 时的新的上界 n ≤ ∑_{i=0}^{k-1} ⌊δ/q^i⌋；并给出若干推论、应用及实例，表明新界在适用性和紧性方面优于旧界。


<details>
  <summary>Details</summary>
Motivation: 解决 Chen & Xie（2025）关于线性反码的 antiGriesmer 边界的局限性：原边界需要 n < q^{k-1} 且 d(C^⊥)≥3。本文去除长度限制并放宽对偶距离条件到 d(C^⊥)≥2，统一并扩展对线性反码的研究，提升边界的适用性。

Method: 通过研究线性反码的直径 δ 与对偶码的最小距离，构造并使用计数不等式，得到新的 Griesmer 类上界；在证明中放宽参数范围，核心在于对 d(C^⊥)≥2 的条件利用。

Result: 主要结论是若 C 为 [n,k]_q 线性反码，且 δ 为其直径且 d(C^⊥)≥2，则 n ≤ ∑_{i=0}^{k-1} ⌊δ/q^i⌋；进一步推得 δ 对 n、k 的下/上界，以及对 n 的上界和对 k 的约束；并讨论少权码的构造与分类应用，给出示例指出新界在某些情形优于以前的界。

Conclusion: 工作统一并扩展了先前关于线性反码的边界结果，显著扩展 antiGriesmer 边界的适用范围，提供更全面的研究框架及实用工具，促进少权码等相关结构的构造与分类。

Abstract: This paper improves the antiGriesmer bound for linear anticodes previously
established by Chen and Xie (Journal of Algebra, 673 (2025) 304-320). While the
original bound required the code length to satisfy $n < q^{k-1}$ and the dual
code to have minimum distance at least 3, our main result removes the length
restriction and relaxes the dual distance condition to at least 2.
Specifically, we prove that for any $[n,k]_q$ linear anticode $\mathcal{C}$
over $\mathbb{F}_q$ with diameter $\delta$ and $d(\mathcal{C}^\perp) \geq 2$,
the inequality \[ n \leq \sum_{i=0}^{k-1} \left\lfloor \frac{\delta}{q^i}
\right\rfloor \] holds. This generalization significantly broadens the
applicability of the antiGriesmer bound. We derive several corollaries,
including lower bounds on the diameter $\delta$ in terms of $n$ and $k$, upper
bounds on the code length $n$, and constraints on the dimension $k$.
Applications to the construction and classification of linear codes with few
weights are also discussed, along with examples demonstrating that our new
bound can be sharper than previous ones. Our work unifies and extends earlier
findings, providing a more comprehensive framework for studying linear
anticodes and their properties.

</details>


### [116] [Performance Analysis of Single-Antenna Fluid Antenna Systems via Extreme Value Theory](https://arxiv.org/abs/2511.02572)
*Rui Xu,Yinghui Ye,Xiaoli Chu,Guangyue Lu,Kai-Kit Wong,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 用极值分布建模全相关FAS信道，给出Gumbel和GEV基于ML参数的闭式OP与EC近似，提升精度与计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决全相关衰落下缺乏闭式分布的问题，提供可解析的性能评估框架。

Method: 将FAS信道建模为极值分布，先用Gumbel分布并通过最大似然估计得到参数（与端口数和天线孔径相关），再推导OP与EC的闭式近似；如Gumbel在极值区偏差显著，扩展为GEV分布并给出ML参数下的OP与EC近似。

Result: Gumbel拟合良好但极端区域略有偏差，GEV在精度上优于Gumbel，同时两者都提供计算高效且解析友好的性能评估工具。

Conclusion: 将EVD框架作为在完全相关衰落下评估FAS性能的有效工具，GEV模型在准确性和鲁棒性方面优于Gumbel，适用于实际场景。

Abstract: In single-antenna fluid antenna systems (FASs), the transceiver dynamically
selects the antenna port with the strongest instantaneous channel to enhance
link reliability. However, deriving accurate yet tractable performance
expressions under fully correlated fading remains challenging, primarily due to
the absence of a closed-form distribution for the FAS channel. To address this
gap, this paper develops a novel performance evaluation framework for FAS
operating under fully correlated Rayleigh fading, by modeling the FAS channel
through extreme value distributions (EVDs). We first justify the suitability of
EVD modeling and approximate the FAS channel through the Gumbel distribution,
with parameters expressed as functions of the number of ports and the antenna
aperture size via the maximum likelihood (ML) criterion. Closed-form
expressions for the outage probability (OP) and ergodic capacity (EC) are then
derived. While the Gumbel model provides an excellent fit, minor deviations
arise in the extreme-probability regions. To further improve accuracy, we
extend the framework using the generalized extreme value (GEV) distribution and
obtain closed-form OP and EC approximations based on ML-derived parameters.
Simulation results confirm that the proposed GEV-based framework achieves
superior accuracy over the Gumbel-based model, while both EVD-based approaches
offer computationally efficient and analytically tractable tools for evaluating
the performance of FAS under realistic correlated fading conditions.

</details>


### [117] [Optimal Source Coding of Markov Chains for Real-Time Remote Estimation](https://arxiv.org/abs/2511.02803)
*Ismail Cosandal,Sennur Ulukus*

Main category: cs.IT

TL;DR: 提出在同一时隙传输和状态更新的马尔可夫链源编码的最优策略：将符号及其传输时长作为状态建模成MDP，与两种基于Huffman的基线对比，在随机过程上实现平均传输时长的降低，收益随马尔可夫过程参数变化。


<details>
  <summary>Details</summary>
Motivation: 在传输与状态更新同尺度的情形下，如何最小化无限地平线的平均传输时长，解决编码策略与马尔可夫过程演化之间的耦合问题。

Method: 将符号及其传输时长作为状态扩展，构造一个MDP，依据最近传输的符号及其传输时长来确定最优策略；并分析两种基于Huffman的基线策略，比较性能；通过对随机生成的过程进行仿真评估。

Result: 提出的最优策略在随机生成的过程上能降低平均传输时长，相较基线策略具有性能提升；提升幅度依赖于马尔可夫过程的参数。

Conclusion: 将最近传输的符号及其传输时长纳入状态以获得在时间同步传输场景下的最优编码策略是有效的，MDP框架可捕捉符号间的耦合，且收益对参数具有敏感性，提示需要进一步的参数分析和广泛适用性评估。

Abstract: We revisit the source coding problem for a Markov chain under the assumption
that the transmission times and how fast the Markov chain transitions its state
happen at the same time-scale. Specifically, we assume that the transmission of
each bit takes a single time slot, and the Markov chain updates its state in
the same time slot. Thus, the length of the codeword assigned to a symbol
determines the number of non-transmitted symbols, as well as, the probability
of the realization of the next symbol to be transmitted. We aim to minimize the
average transmission duration over an infinite horizon by proposing an optimal
source coding policy based on the last transmitted symbol and its transmission
duration. To find the optimal policy, we formulate the problem with a Markov
decision process (MDP) by augmenting the symbols alongside the transmission
duration of the symbols. Finally, we analyze two Huffman-based benchmark
policies and compare their performances with the proposed optimal policy. We
observe that, in randomly generated processes, our proposed optimal policy
decreases the average transmission duration compared to benchmark policies. The
performance gain varies based on the parameters of the Markov process.

</details>


### [118] [A Construction of Infinite Families of Self-Orthogonal Quasi-Cyclic Codes Using Constituent Codes.pdf](https://arxiv.org/abs/2511.02813)
*Gustavo Terra Bastos,Angelynn Álvarez,Cameron Williams*

Main category: cs.IT

TL;DR: 本文提出一组无限族准循环码，满足在欧几里得和 Hermitian 内积下自正交；通过在 F_q 的扩域上的组成码分析，给出维数及最小距离的下界，且下界具有平方根型。并给出从该构造得到自对偶准循环码的方法，利用 CSS 构造出参数良好的量子纠错码。


<details>
  <summary>Details</summary>
Motivation: 为获得具备良好参数的量子纠错码，利用准循环码的代数结构和自正交性，通过域扩张的组分码分析维数与距离下界，并探索自对偶/自正交性质以适配 CSS。

Method: 构造在有限域及其扩张域上的准循环码，研究其自正交性（Euclidean 与 Hermitian）；通过组成码分析维数并给出最小距离的下界，证明下界具有平方根型；给出从该构造获得自对偶准循环码的途径；再结合 CSS 构造量子纠错码。

Result: 得到一族无限的自正交/自对偶的准循环码，包括维数计算、平方根型下界，以及自对偶构造途径；并证明存在参数良好的量子纠错码。

Conclusion: 该构造提供一种系统化获得高性能量子纠错码的途径，利用自正交性与域扩张的组分码分析，在 CSS 框架下可产生具有良好参数的量子码，具备潜在的实际应用价值。

Abstract: Quasi-cyclic codes have been recently employed in the constructions of
quantum error-correcting codes. In this paper, we propose a construction of
infinite families of quasi-cyclic codes which are self-orthogonal with respect
to the Euclidean and Hermitian inner products. In particular, their dimension
and a lower bound for their minimum distance are computed using their
constituent codes defined over field extensions of $\mathbb{F}_q$. We also show
that the lower bound for the minimum distance satisfies the square-root-like
lower bound and also show how self-dual quasi-cyclic codes can arise from our
construction. Using the CSS construction, we show the existence of quantum
error-correcting codes with good parameters.

</details>
